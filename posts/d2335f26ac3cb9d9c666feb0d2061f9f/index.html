<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>音高修正_使用人声 Auto-Tune 技巧（音高调节，跑调人群有福啦！） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="音高修正_使用人声 Auto-Tune 技巧（音高调节，跑调人群有福啦！）" />
<meta property="og:description" content="本文将讨论人声的自动调音。因此，不知道啥是Auto-Tune的同学请先去脑补；会使用Auto-Tune的同学请备好板砖 ！对于你们中的许多人来说，这将是一篇讨论自动调音在现代音乐中的创造性与实用性的伟大文章。不过从人性的阴暗面来讲，这也可能制造出一些笑柄，给人一千个开喷的理由，比如“自动调音的最佳技巧就是找一个唱歌不跑调的偶像！”
言归正传，对于Auto-Tune这项技术，无论你爱也好，恨也罢！它都已经在那了。因此，有关事宜你还是了解下为好。
两种用途
人声自动调音技术在现代音乐中的应用在我看来主要有两种模式：一是用于锁住一些离调音符，及时修正歌唱时的人声音准；二是把它当作一种创作人声音色的特殊效果，非常类似于移相器、镶边器、混响或者失真的作用。
第一种模式非常简单 - 如果歌手的一个音唱跑了，我们得赶快把它拽回调上来。比较常用的工具如Auto-Tune、Waves Tune、Melodyne等。用过的都知道，在图形模式下使用是最好的，或者你也可以简单地使用自动修音模式并自动化(Bypass)旁路。
第二种模式更有趣 - 它有两种应用场景。一是可以用作后期效果 - 即在录完音后用Auto-Tune去调音；二是在歌手演唱时实时插入并用唱法去操纵Auto-Tune，我是后者的支持者！一个非常优秀的歌手可以控制他们的音高和唱法，使之与Auto-Tune珠联璧合、相得益彰，而且还能从中获得许多有趣的效果，让这种调谐失真变成一个创意工具。
自动增强音色
在当下的音乐环境中，我经常把Auto-Tune当作是一种音色调整工具。多数情况下，我都试图获得一些(或很多)有光泽度的相位失真，这种合成谐波的产生使声音听起来带点合成味儿，或者像个机器人，当然这取决于你用什么方法来调教。 通常人们只是倾向于使用更自动化地调音方式，找到自己觉得合适的retune speeds，然后把他们像煎饼果子一样卷一起。我有点神经质，喜欢更精致的方法。我非常清楚我何时该用Melodyne虐一下；何时又该用当下最潮的Auto-Tune效果来一把；或者再玩回经典教科书式的Auto-Tune音色，正是因为它们有着各自不同的声音特点，所以也各有各的用法。
Melodyne的音色最通透。但它会使人声的中低频部分变薄一点点，这有时反而是件好事。若你虐着点用，它会带来一种特殊的音染，会产生那种分布非常均匀的谐波 - 你知道这种听感很难用语言来表达，或许可以形容为非常“稳定”。
Auto-Tune的最新版本也相当通透，但还是可以做出以前那种标志性的Auto-Tune声音。最典型的就是用Auto-Tune 5.1版本调教出的声音，当我们想起T-Pain(美国另一位Auto-Tune大神)时，我们就会想到那种声音特质- 因为共振峰位移还不够准确。接下来便是我要如何虐、虐多少的问题 – 到底是只为人声增加一点淡淡的光泽，还是干脆搞成机器人的声音。如果我要蜻蜓点水般的感觉，那非常简单 -- 技术上来讲就是把两个Auto-Tune串联，两者都设置为非常慢的retune speeds，等于在被处理的谐波之上再产生一次谐波，从而获得那种轻微且持续的调制味道。 因为我使用慢速调音，这也意味着调音效果相当均匀。
将Melodyne和 Auto-Tune 结合使用
然而，有时我想要让那种更精美的效果始终贯穿于人声， 我发现通过将Melodyne与Auto-Tune结合使用可以获得非常均匀、有质感的声音。不妨听听Ozuna和Akon(阿肯)合作的单曲“Comentale”，这首歌中的人声效果就是我讲的这种感觉，是一个很棒的范例。
这两个人声链是首先在Melodyne插件的图形模式下只让音符尽量靠近中心，然后再挂一个Auto-Tune插件，把retune speeds设置得相当快，用这种方法去创造一种效果音色，当Akon唱出较快的音符时才会作出音调调整，当他这么唱时我喜欢让Auto-Tune带点“小故障”，因为我喜欢这样所产生的那种人声纹理。Kon非常巧妙地把这些“小故障”放在了他的唱法中，这个我过会儿再讲。另外，在录音过程中，Ozuna和Akon都用贴合Auto-Tune Pro的方式去唱歌，以使声音更加融合。Ozuna设置为常规模式；Akon设置为经典模式，整个过程都经过精心设计，其效果比简单地只挂一个Auto-Tune要好很多。
自动化 Auto-Tune
有时候，我不想让Auto-Tune效果在人声中一直保持得太均匀。正如我之前提到的，Akon非常注重怎么将他的声音与Auto-Tune结合着唱。有时为了创造出更迷人的瞬间，他会故意把某处唱跑，而我自然也心领神会，使用自动化Auto-Tune设置来突出他想要的那种效果。
基本上来讲，我只是在他的演唱基础上进行发挥。 很多人将Akon与重型Auto-Tune联系起来，但当我想起他的演唱风格时，我认为他确实是高手中的高手。 他非常仔细地塑造了自己的声音个性，对于有这样能力的艺术家，我实际上并不会把Auto-Tune用的过重。 我心中的默认值是“经典的Auto-Tune”(指5.1版本中的算法所得到的声音)，retune speeds设为12ms(对于严肃点的歌曲可能会更少，对于带有俱乐部取向的歌曲可能会更多)。 我不否认这个速度很快，因为我想要得到那种独特的人声音色。 这可跟T-Pain的标志性声音不同。 在某些实际操作的过程或瞬间，我会把自动化retune speeds设置得非常快，以呈现那种声音质感；或者放慢速度让声音变得更敏感。
手动控制共振峰位移
共振峰位移是一种未被充分利用的效果。 当我们说话时，我们发出的元音是由嘴巴的形状决定的。 由嘴形决定的这些谐振特征被称为共振峰。 为了在调音期间保持声音特点，必须相应地调整共振峰。
音调修正软件通常会自动执行此操作 - 但有时它也不是百分百准确。 因此，大多数调音软件允许我们在需要补偿时手动调整共振峰。 较高的共振峰指的是诸如“a”、“ah”和“e”；较低的共振峰指的是诸如“oo”、“oh”和“uh”之类。 有时候我们其实可以虐一下共振峰，用这种手动控制的方法来创建各种人声纹理也很有趣。 比如我们可以在背景人声中调整一下共振峰，使它区别于主唱音色。 或者我们可以再狠一点，让它听起来像一只会唱歌的花栗鼠或是科学怪人养的小蛮兽。
来一点创意
如果我们没有一点创意，那跟咸鱼又有什么区别？那我写这篇文章又有什么意思？来吧！让我们试着打开脑洞：首先，我想到的是音高修正和混响效果之间的关系。值得注意的是，同一首歌通过后期制作实施Auto-Tune与现场实时Auto-Tune在技术上会有不同。
你可能会问那又怎样？
好吧！两者之间的差异归结为相位旋转 -- 谐波轨迹的微时序变化改变了信号的相位，相位是确定空间性的一个极为重要的方面。因为我经常使用外置混响，我发现如果我把混响返送回来，然后在混响发送后挂上我的Auto-Tune再去设置，人声竟然会感觉更靠前，待断开混响后则会产生一个强烈的从前到后的立体声成像，这听起来有点不可思议。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/d2335f26ac3cb9d9c666feb0d2061f9f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-13T13:56:18+08:00" />
<meta property="article:modified_time" content="2021-01-13T13:56:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">音高修正_使用人声 Auto-Tune 技巧（音高调节，跑调人群有福啦！）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <div class="pgc-img"> 
  <img src="https://images2.imgbox.com/1f/c4/Fd7I5e5y_o.png" alt="3af13864e81101b512542c9aca6f5622.png"> 
 </div> 
 <p>本文将讨论人声的自动调音。因此，不知道啥是Auto-Tune的同学请先去脑补；会使用Auto-Tune的同学请备好板砖 ！对于你们中的许多人来说，这将是一篇讨论自动调音在现代音乐中的创造性与实用性的伟大文章。不过从人性的阴暗面来讲，这也可能制造出一些笑柄，给人一千个开喷的理由，比如“自动调音的最佳技巧就是找一个唱歌不跑调的偶像！”</p> 
 <p>言归正传，对于Auto-Tune这项技术，无论你爱也好，恨也罢！它都已经在那了。因此，有关事宜你还是了解下为好。</p> 
 <p><strong>两种用途</strong></p> 
 <p>人声自动调音技术在现代音乐中的应用在我看来主要有两种模式：一是用于锁住一些离调音符，及时修正歌唱时的人声音准；二是把它当作一种创作人声音色的特殊效果，非常类似于移相器、镶边器、混响或者失真的作用。</p> 
 <p>第一种模式非常简单 - 如果歌手的一个音唱跑了，我们得赶快把它拽回调上来。比较常用的工具如Auto-Tune、Waves Tune、Melodyne等。用过的都知道，在图形模式下使用是最好的，或者你也可以简单地使用自动修音模式并自动化(Bypass)旁路。</p> 
 <p>第二种模式更有趣 - 它有两种应用场景。一是可以用作后期效果 - 即在录完音后用Auto-Tune去调音；二是在歌手演唱时实时插入并用唱法去操纵Auto-Tune，我是后者的支持者！一个非常优秀的歌手可以控制他们的音高和唱法，使之与Auto-Tune珠联璧合、相得益彰，而且还能从中获得许多有趣的效果，让这种调谐失真变成一个创意工具。</p> 
 <p><strong>自动增强音色</strong></p> 
 <p>在当下的音乐环境中，我经常把Auto-Tune当作是一种音色调整工具。多数情况下，我都试图获得一些(或很多)有光泽度的相位失真，这种合成谐波的产生使声音听起来带点合成味儿，或者像个机器人，当然这取决于你用什么方法来调教。 通常人们只是倾向于使用更自动化地调音方式，找到自己觉得合适的retune speeds，然后把他们像煎饼果子一样卷一起。我有点神经质，喜欢更精致的方法。我非常清楚我何时该用Melodyne虐一下；何时又该用当下最潮的Auto-Tune效果来一把；或者再玩回经典教科书式的Auto-Tune音色，正是因为它们有着各自不同的声音特点，所以也各有各的用法。</p> 
 <p>Melodyne的音色最通透。但它会使人声的中低频部分变薄一点点，这有时反而是件好事。若你虐着点用，它会带来一种特殊的音染，会产生那种分布非常均匀的谐波 - 你知道这种听感很难用语言来表达，或许可以形容为非常“稳定”。</p> 
 <p>Auto-Tune的最新版本也相当通透，但还是可以做出以前那种标志性的Auto-Tune声音。最典型的就是用Auto-Tune 5.1版本调教出的声音，当我们想起T-Pain(美国另一位Auto-Tune大神)时，我们就会想到那种声音特质- 因为共振峰位移还不够准确。接下来便是我要如何虐、虐多少的问题 – 到底是只为人声增加一点淡淡的光泽，还是干脆搞成机器人的声音。如果我要蜻蜓点水般的感觉，那非常简单 -- 技术上来讲就是把两个Auto-Tune串联，两者都设置为非常慢的retune speeds，等于在被处理的谐波之上再产生一次谐波，从而获得那种轻微且持续的调制味道。 因为我使用慢速调音，这也意味着调音效果相当均匀。</p> 
 <p><strong>将Melodyne和 Auto-Tune 结合使用</strong></p> 
 <p>然而，有时我想要让那种更精美的效果始终贯穿于人声， 我发现通过将Melodyne与Auto-Tune结合使用可以获得非常均匀、有质感的声音。不妨听听Ozuna和Akon(阿肯)合作的单曲“Comentale”，这首歌中的人声效果就是我讲的这种感觉，是一个很棒的范例。</p> 
 <p>这两个人声链是首先在Melodyne插件的图形模式下只让音符尽量靠近中心，然后再挂一个Auto-Tune插件，把retune speeds设置得相当快，用这种方法去创造一种效果音色，当Akon唱出较快的音符时才会作出音调调整，当他这么唱时我喜欢让Auto-Tune带点“小故障”，因为我喜欢这样所产生的那种人声纹理。Kon非常巧妙地把这些“小故障”放在了他的唱法中，这个我过会儿再讲。另外，在录音过程中，Ozuna和Akon都用贴合Auto-Tune Pro的方式去唱歌，以使声音更加融合。Ozuna设置为常规模式；Akon设置为经典模式，整个过程都经过精心设计，其效果比简单地只挂一个Auto-Tune要好很多。</p> 
 <p><strong>自动化 Auto-Tune</strong></p> 
 <p>有时候，我不想让Auto-Tune效果在人声中一直保持得太均匀。正如我之前提到的，Akon非常注重怎么将他的声音与Auto-Tune结合着唱。有时为了创造出更迷人的瞬间，他会故意把某处唱跑，而我自然也心领神会，使用自动化Auto-Tune设置来突出他想要的那种效果。</p> 
 <p>基本上来讲，我只是在他的演唱基础上进行发挥。 很多人将Akon与重型Auto-Tune联系起来，但当我想起他的演唱风格时，我认为他确实是高手中的高手。 他非常仔细地塑造了自己的声音个性，对于有这样能力的艺术家，我实际上并不会把Auto-Tune用的过重。 我心中的默认值是“经典的Auto-Tune”(指5.1版本中的算法所得到的声音)，retune speeds设为12ms(对于严肃点的歌曲可能会更少，对于带有俱乐部取向的歌曲可能会更多)。 我不否认这个速度很快，因为我想要得到那种独特的人声音色。 这可跟T-Pain的标志性声音不同。 在某些实际操作的过程或瞬间，我会把自动化retune speeds设置得非常快，以呈现那种声音质感；或者放慢速度让声音变得更敏感。</p> 
 <p><strong>手动控制共振峰位移</strong></p> 
 <p>共振峰位移是一种未被充分利用的效果。 当我们说话时，我们发出的元音是由嘴巴的形状决定的。 由嘴形决定的这些谐振特征被称为共振峰。 为了在调音期间保持声音特点，必须相应地调整共振峰。</p> 
 <p>音调修正软件通常会自动执行此操作 - 但有时它也不是百分百准确。 因此，大多数调音软件允许我们在需要补偿时手动调整共振峰。 较高的共振峰指的是诸如“a”、“ah”和“e”；较低的共振峰指的是诸如“oo”、“oh”和“uh”之类。 有时候我们其实可以虐一下共振峰，用这种手动控制的方法来创建各种人声纹理也很有趣。 比如我们可以在背景人声中调整一下共振峰，使它区别于主唱音色。 或者我们可以再狠一点，让它听起来像一只会唱歌的花栗鼠或是科学怪人养的小蛮兽。</p> 
 <p><strong>来一点创意</strong></p> 
 <p>如果我们没有一点创意，那跟咸鱼又有什么区别？那我写这篇文章又有什么意思？来吧！让我们试着打开脑洞：首先，我想到的是音高修正和混响效果之间的关系。值得注意的是，同一首歌通过后期制作实施Auto-Tune与现场实时Auto-Tune在技术上会有不同。</p> 
 <p><strong>你可能会问那又怎样？</strong></p> 
 <p>好吧！两者之间的差异归结为相位旋转 -- 谐波轨迹的微时序变化改变了信号的相位，相位是确定空间性的一个极为重要的方面。因为我经常使用外置混响，我发现如果我把混响返送回来，然后在混响发送后挂上我的Auto-Tune再去设置，人声竟然会感觉更靠前，待断开混响后则会产生一个强烈的从前到后的立体声成像，这听起来有点不可思议。</p> 
 <p>我们还可以用Auto-Tune技术制造一款加倍器！其方法是建立三个声源：一个是保持正中央的源声版本；第二个是平移到声场左侧高出几cent(音分：100音分就是半个音)的版本；第三个是平移到声场右侧降低几音分的版本。 这非常类似于一个传统的加倍器，但由于它带有音调偏移，所以我们得到的是一款可以稍带缩放立体声成像的有特性的相位器。它多了些运动感，这取决于我们想要什么。</p> 
 <p>最后我还想说，我真的很喜欢把延迟效果放进Auto-Tune里来用。 那样可以获得类似发生故障的声音，它听起来很有未来感，而且很酷。是的！很多时候，我们想要带一点科幻味道的声音。</p> 
 <p><strong>结语</strong></p> 
 <p>无论你持何种态度，自动调音都亦然成为音乐制作领域的一部分了。 就我个人而言，我更愿意探寻并拓展这种工具的使用方法，而不是试图对抗这种文化浪潮。请问你在Auto-Tune方面进行过探索吗？ 你为此做过什么尝试吗？</p> 
 <p>译者注：众所周知，Auto-Tune 是一款由Antares公司出品的自动调音软件。由于其强大的影响力，Auto-Tune 在人们口中俨然已经成为人声自动调音的代名词，由于这类软件在功能上的不断拓展升级，因此读者不必过分纠结于应该把它叫成Auto-Tune、自动调音、音高修正还是音调校正什么的，它有时就是一个概念，一种技术手段的绰号，最终还是看你怎么用和用在哪。</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/22290d8cbe35f8351d8c0d2d96528424/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">strapi的使用（二）-- Graphql</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c181973e29ec7fd779597832a0302b68/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">小白成长记（三、SqlSugar的sum用法）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>