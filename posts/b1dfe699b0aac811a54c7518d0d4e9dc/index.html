<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>torch.utils.data.dataloader.DataLoaderIter 无法导入问题 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="torch.utils.data.dataloader.DataLoaderIter 无法导入问题" />
<meta property="og:description" content="torch提供的DataLoader可以提供一个可迭代对象iterable object（注意不是迭代器，iterator），利用python本身良好的生态环境，实现简洁、节省内存资源的数据读取。而DataLoader只是一个iterable object，只能像python list一样用for循环去取，不能像iterator一样，可以使用next方法，在一些场景下缺乏灵活性。
可能就是因为上述原因，torch在历史某个版本使用了DataLoaderIter对象。
这两个clas的具体使用以及其源码解读参考：
PyTorch学习笔记(6)——DataLoader源代码剖析
Pytorch数据读取(Dataset, DataLoader, DataLoaderIter)
为了说明哪些场合可能需要用到DataLoaderIter，下面举个例子
例如：
import torch from torch.utils.data import RandomSampler,DataLoader from utils.dataloader_iter import DataLoaderIter class myDataset(torch.utils.data.Dataset): &#39;&#39;&#39; create my own torch Dataset implement torch.utils.data.Dataset &#39;&#39;&#39; def __init__(self, dataSource): &#39;&#39;&#39; :param dataSource: iterable object like list datasource means a list contain all data sample e.g. [obj1,obj2...] &#39;&#39;&#39; self.dataSource = dataSource def __getitem__(self,index): element = self.dataSource[index] return element def __len__(self): return len(self.dataSource) template = [{&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b1dfe699b0aac811a54c7518d0d4e9dc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-11T18:27:35+08:00" />
<meta property="article:modified_time" content="2021-02-11T18:27:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">torch.utils.data.dataloader.DataLoaderIter 无法导入问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>torch提供的<strong>DataLoader</strong>可以提供一个可迭代对象<code>iterable object</code>（注意不是迭代器，<code>iterator</code>），利用python本身良好的生态环境，实现简洁、节省内存资源的数据读取。而DataLoader只是一个<code>iterable object</code>，只能像python list一样用for循环去取，不能像<code>iterator</code>一样，可以使用next方法，在一些场景下缺乏灵活性。<br> 可能就是因为上述原因，torch在历史某个版本使用了<strong>DataLoaderIter</strong>对象。<br> 这两个clas的具体使用以及其源码解读参考：<br> <a href="https://blog.csdn.net/g11d111/article/details/81504637">PyTorch学习笔记(6)——DataLoader源代码剖析</a><br> <a href="https://zhuanlan.zhihu.com/p/30934236" rel="nofollow">Pytorch数据读取(Dataset, DataLoader, DataLoaderIter)</a></p> 
<p>为了说明哪些场合可能需要用到<strong>DataLoaderIter</strong>，下面举个例子<br> 例如：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> RandomSampler<span class="token punctuation">,</span>DataLoader
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>dataloader_iter <span class="token keyword">import</span> DataLoaderIter

<span class="token keyword">class</span> <span class="token class-name">myDataset</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">''' create my own torch Dataset
    implement torch.utils.data.Dataset
    '''</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataSource<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        :param dataSource: iterable object like list
        datasource means a list contain all data sample
        e.g. [obj1,obj2...]
        '''</span>
        self<span class="token punctuation">.</span>dataSource <span class="token operator">=</span> dataSource

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        element <span class="token operator">=</span> self<span class="token punctuation">.</span>dataSource<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token keyword">return</span> element
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataSource<span class="token punctuation">)</span>

template <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"1"</span><span class="token punctuation">:</span><span class="token string">"so elegant"</span><span class="token punctuation">,</span><span class="token string">"2"</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"3"</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{<!-- --></span><span class="token string">"1"</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"2"</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"3"</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
dataset<span class="token operator">=</span>myDataset<span class="token punctuation">(</span>template<span class="token punctuation">)</span>
sampler <span class="token operator">=</span> RandomSampler<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>sampler<span class="token operator">=</span>sampler<span class="token punctuation">)</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span>
   <span class="token keyword">break</span>

<span class="token keyword">for</span> t <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span>
   <span class="token keyword">break</span>
</code></pre> 
<p>实现上面我自定义了myDataset class继承Dataset,然后构造简单的Dataloader,一般而言for循环已经可以支持大部分实验，但是可以看到<code>train_loader</code>在每次for循环的时候index都会被重置:<br> <img src="https://images2.imgbox.com/c0/6d/GTMLyhSK_o.png" alt="在这里插入图片描述"><br> DataLoaderIter作为DataLoader的又一层封装，就可以实现iterator的特性,即用next取，同时保留index:</p> 
<pre><code class="prism language-python">dataIter<span class="token operator">=</span>DataLoaderIter<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataIter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataIter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/1e/9c/zi0KLhf7_o.png" alt="在这里插入图片描述"></p> 
<p>但是DataLoaderIter在很早的版本就被torch取消了：<br> <img src="https://images2.imgbox.com/28/d7/9MpcLL3V_o.png" alt="在这里插入图片描述"><br> 所以如果想要使用DataLoaderIter得自己取0.3.1的源码copy到自己的file里面<br> <a href="https://pytorch.org/docs/0.3.1/_modules/torch/utils/data/dataloader.html#DataLoader" rel="nofollow">torch 0.3.1 doc</a></p> 
<h3><a id="_63"></a>参考资料：</h3> 
<p><a href="https://pytorch.org/docs/0.3.1/_modules/torch/utils/data/dataloader.html#DataLoader" rel="nofollow">torch 0.3.1 doc</a><br> <a href="https://blog.csdn.net/g11d111/article/details/81504637">PyTorch学习笔记(6)——DataLoader源代码剖析</a><br> <a href="https://zhuanlan.zhihu.com/p/30934236" rel="nofollow">Pytorch数据读取(Dataset, DataLoader, DataLoaderIter)</a><br> <a href="https://stackoverflow.com/questions/54467696/error-with-dataloaderiter-in-torch-utils-data-dataloader" rel="nofollow">Error with _DataLoaderIter in torch.utils.data.dataloader</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c79df10bd138e1ba16b68611f11bb2cb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">虚幻引擎材质系统常用快捷键</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e02cdcad8bd5aed4e6e82d76b54cbefb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">华容道3x3的技巧_数字华容道——无上限解题技巧</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>