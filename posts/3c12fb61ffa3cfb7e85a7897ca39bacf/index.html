<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CUDAåŸºç¡€æ•™ç¨‹æ–‡æ¡£è®°å½• - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CUDAåŸºç¡€æ•™ç¨‹æ–‡æ¡£è®°å½•" />
<meta property="og:description" content="ç›®å½• å‰è¨€0. CUDAåŸºç¡€è¯­æ³•1. CUDAå…±äº«å†…å­˜2. GPUæ¶æ„ç®€ä»‹3. CUDAå†…å­˜å­ç³»ç»Ÿ4. åŸå­/è§„çº¦æ“ä½œå’Œwarp shuffle5. CUDAç»Ÿä¸€å†…å­˜(Managed Memory)6. CUDAæµå’Œå¹¶å‘7. Profileré©±åŠ¨çš„ä¼˜åŒ– å‰è¨€ å­¦ä¹ æ‰‹å†™ AI ä¸­ HY å¤§ä½¬çš„ã€ŠCUDAåŸºç¡€æ•™ç¨‹ã€‹å…«è®²è§†é¢‘ï¼Œç”±äºæ²¡æœ‰æ–‡æ¡£ï¼Œæ‰€ä»¥æ‰‹åŠ¨è®°å½•ä¸‹ï¼Œä»…ä¾›è‡ªå·±å‚è€ƒ
éƒ¨åˆ†å®æˆ˜ä»£ç è®²è§£éƒ¨åˆ†å¹¶æ²¡æœ‰è®°å½•ï¼Œå»ºè®®å¤§å®¶è§‚çœ‹åŸè§†é¢‘ï¼Œè§†é¢‘é“¾æ¥
æ–‡æ¡£é…åˆè§†é¢‘ï¼Œé£Ÿç”¨æ›´ä½³ğŸ¤—
æ„Ÿè°¢ HY å¤§ä½¬çš„åˆ†äº«ğŸ˜„
0. CUDAåŸºç¡€è¯­æ³• CUDA è¯­è¨€ç‰ˆæœ¬ï¼šcuda c&#43;&#43;/cuda Fortran/cuda Python/cuda Matlabï¼Œæœ¬æ–‡æ¡£ cuda è®²è§£ cuda c&#43;&#43;ï¼Œéµå®ˆ c&#43;&#43; æ ‡å‡†
GPU å’Œ CPU å¼‚æ„è®¡ç®—ï¼šè®¡ç®—å¯†é›†å‹ -&gt; GPUï¼Œé€»è¾‘æµæ§åˆ¶ -&gt; CPU
Typical workflow:
a. å…ˆæŠŠæ•°æ®ä» CPU å†…å­˜æ‹·åˆ° GPU æ˜¾å­˜ä¸Šb. æ‰§è¡Œ GPU ç¨‹åºè®¡ç®—ï¼Œä»¥å¤šä¸ªçº¿ç¨‹ (gridDim * blockDim) ä¸€èµ·è®¡ç®— SIMT çš„æ–¹å¼c. æŠŠç»“æœä» GPU æ˜¾å­˜ä¸­æ‹·å› CPU å†…å­˜é‡Œ host å’Œ device å†…å­˜ç‰©ç†ä¸Šæ˜¯éš”ç¦»çš„ï¼Œè®¾å¤‡æŒ‡é’ˆï¼ˆdevice pointer/gpu pointerï¼‰æŒ‡å‘ GPU æ˜¾å­˜åœ°å€ï¼Œæ— æ³•åœ¨ CPU ç«¯è§£å¼•ç”¨ã€‚ä¸»æœºæŒ‡é’ˆï¼ˆhost pointer/cpu pointerï¼‰æŒ‡å‘ CPU å†…å­˜åœ°å€ï¼Œæ— æ³•åœ¨ GPU ç«¯è§£å¼•ç”¨ã€‚éœ€è¦ç”¨ cudaMalloc()ï¼ŒcudaFree()ã€‚cudaMemcpy()â€¦ è¿™äº› CUDA API æ¥å®ç°å¯¹è®¾å¤‡æ˜¾å­˜çš„æ“ä½œã€‚" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3c12fb61ffa3cfb7e85a7897ca39bacf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-21T17:10:35+08:00" />
<meta property="article:modified_time" content="2024-01-21T17:10:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CUDAåŸºç¡€æ•™ç¨‹æ–‡æ¡£è®°å½•</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>ç›®å½•</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">å‰è¨€</a></li><li><a href="#0_CUDA_11" rel="nofollow">0. CUDAåŸºç¡€è¯­æ³•</a></li><li><a href="#1_CUDA_165" rel="nofollow">1. CUDAå…±äº«å†…å­˜</a></li><li><a href="#2_GPU_239" rel="nofollow">2. GPUæ¶æ„ç®€ä»‹</a></li><li><a href="#3_CUDA_352" rel="nofollow">3. CUDAå†…å­˜å­ç³»ç»Ÿ</a></li><li><a href="#4_warp_shuffle_445" rel="nofollow">4. åŸå­/è§„çº¦æ“ä½œå’Œwarp shuffle</a></li><li><a href="#5_CUDAManaged_Memory_628" rel="nofollow">5. CUDAç»Ÿä¸€å†…å­˜(Managed Memory)</a></li><li><a href="#6_CUDA_888" rel="nofollow">6. CUDAæµå’Œå¹¶å‘</a></li><li><a href="#7_Profiler_989" rel="nofollow">7. Profileré©±åŠ¨çš„ä¼˜åŒ–</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>å‰è¨€</h3> 
<blockquote> 
 <p>å­¦ä¹ æ‰‹å†™ AI ä¸­ HY å¤§ä½¬çš„ã€ŠCUDAåŸºç¡€æ•™ç¨‹ã€‹å…«è®²è§†é¢‘ï¼Œç”±äºæ²¡æœ‰æ–‡æ¡£ï¼Œæ‰€ä»¥æ‰‹åŠ¨è®°å½•ä¸‹ï¼Œ<strong>ä»…ä¾›è‡ªå·±å‚è€ƒ</strong></p> 
 <p>éƒ¨åˆ†å®æˆ˜ä»£ç è®²è§£éƒ¨åˆ†å¹¶æ²¡æœ‰è®°å½•ï¼Œå»ºè®®å¤§å®¶è§‚çœ‹åŸè§†é¢‘ï¼Œ<a href="https://www.bilibili.com/video/BV1h64y1K7YY/" rel="nofollow">è§†é¢‘é“¾æ¥</a></p> 
 <p>æ–‡æ¡£é…åˆè§†é¢‘ï¼Œé£Ÿç”¨æ›´ä½³ğŸ¤—</p> 
 <p>æ„Ÿè°¢ HY å¤§ä½¬çš„åˆ†äº«ğŸ˜„</p> 
</blockquote> 
<h3><a id="0_CUDA_11"></a>0. CUDAåŸºç¡€è¯­æ³•</h3> 
<p>CUDA è¯­è¨€ç‰ˆæœ¬ï¼šcuda c++/cuda Fortran/cuda Python/cuda Matlabï¼Œæœ¬æ–‡æ¡£ cuda è®²è§£ cuda c++ï¼Œéµå®ˆ c++ æ ‡å‡†</p> 
<p>GPU å’Œ CPU å¼‚æ„è®¡ç®—ï¼šè®¡ç®—å¯†é›†å‹ -&gt; GPUï¼Œé€»è¾‘æµæ§åˆ¶ -&gt; CPU</p> 
<p>Typical workflow:</p> 
<ul><li><font color="RoyalBlue"><strong>a.</strong></font> å…ˆæŠŠæ•°æ®ä» CPU å†…å­˜æ‹·åˆ° GPU æ˜¾å­˜ä¸Š</li><li><font color="RoyalBlue"><strong>b.</strong></font> æ‰§è¡Œ GPU ç¨‹åºè®¡ç®—ï¼Œä»¥å¤šä¸ªçº¿ç¨‹ (gridDim * blockDim) ä¸€èµ·è®¡ç®— SIMT çš„æ–¹å¼</li><li><font color="RoyalBlue"><strong>c.</strong></font> æŠŠç»“æœä» GPU æ˜¾å­˜ä¸­æ‹·å› CPU å†…å­˜é‡Œ</li></ul> 
<p>host å’Œ device å†…å­˜ç‰©ç†ä¸Šæ˜¯éš”ç¦»çš„ï¼Œè®¾å¤‡æŒ‡é’ˆï¼ˆdevice pointer/gpu pointerï¼‰æŒ‡å‘ GPU æ˜¾å­˜åœ°å€ï¼Œæ— æ³•åœ¨ CPU ç«¯è§£å¼•ç”¨ã€‚ä¸»æœºæŒ‡é’ˆï¼ˆhost pointer/cpu pointerï¼‰æŒ‡å‘ CPU å†…å­˜åœ°å€ï¼Œæ— æ³•åœ¨ GPU ç«¯è§£å¼•ç”¨ã€‚éœ€è¦ç”¨ cudaMalloc()ï¼ŒcudaFree()ã€‚cudaMemcpy()â€¦ è¿™äº› CUDA API æ¥å®ç°å¯¹è®¾å¤‡æ˜¾å­˜çš„æ“ä½œã€‚</p> 
<pre><code class="prism language-cpp"><span class="token comment">// nvcc simplekernel.cu -o simplekernel</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cuda_runtime.h&gt;</span></span>
__global__ <span class="token keyword">void</span> <span class="token function">simplekernel</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span> <span class="token comment">// __device__, __host__</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> index <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> m <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    simplekernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>m<span class="token punctuation">,</span> n<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// m = gridDim.x, n = blockDim.x</span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<pre><code class="prism language-bash">threadIdx.x          threadIdx.x         threadIdx.x         threadIdx.x
 - - - - - - - -     - - - - - - - -     - - - - - - - -     - - - - - - - - 
<span class="token operator">|</span><span class="token number">0</span><span class="token operator">|</span><span class="token number">1</span><span class="token operator">|</span><span class="token number">2</span><span class="token operator">|</span><span class="token number">3</span><span class="token operator">|</span><span class="token number">4</span><span class="token operator">|</span><span class="token number">5</span><span class="token operator">|</span><span class="token number">6</span><span class="token operator">|</span><span class="token number">7</span>    <span class="token operator">|</span><span class="token number">0</span><span class="token operator">|</span><span class="token number">1</span><span class="token operator">|</span><span class="token number">2</span><span class="token operator">|</span><span class="token number">3</span><span class="token operator">|</span><span class="token number">4</span><span class="token operator">|</span><span class="token number">5</span><span class="token operator">|</span><span class="token number">6</span><span class="token operator">|</span><span class="token number">7</span>    <span class="token operator">|</span><span class="token number">0</span><span class="token operator">|</span><span class="token number">1</span><span class="token operator">|</span><span class="token number">2</span><span class="token operator">|</span><span class="token number">3</span><span class="token operator">|</span><span class="token number">4</span><span class="token operator">|</span><span class="token number">5</span><span class="token operator">|</span><span class="token number">6</span><span class="token operator">|</span><span class="token number">7</span>    <span class="token operator">|</span><span class="token number">0</span><span class="token operator">|</span><span class="token number">1</span><span class="token operator">|</span><span class="token number">2</span><span class="token operator">|</span><span class="token number">3</span><span class="token operator">|</span><span class="token number">4</span><span class="token operator">|</span><span class="token number">5</span><span class="token operator">|</span><span class="token number">6</span><span class="token operator">|</span><span class="token number">7</span>
blockIdx.x <span class="token operator">=</span> <span class="token number">0</span>       blockIdx.x <span class="token operator">=</span> <span class="token number">1</span>      blockIdx.x <span class="token operator">=</span> <span class="token number">2</span>      blockIdx.x <span class="token operator">=</span> <span class="token number">3</span>

data:
<span class="token operator">|</span><span class="token number">0</span><span class="token operator">|</span><span class="token number">1</span><span class="token operator">|</span><span class="token number">2</span><span class="token operator">|</span><span class="token number">3</span><span class="token operator">|</span><span class="token number">4</span><span class="token operator">|</span><span class="token number">5</span><span class="token operator">|</span><span class="token number">6</span><span class="token operator">|</span><span class="token number">7</span><span class="token operator">|</span><span class="token number">8</span><span class="token operator">|</span><span class="token number">9</span><span class="token operator">|</span><span class="token number">10</span><span class="token operator">|</span><span class="token number">11</span><span class="token operator">|</span><span class="token number">12</span><span class="token operator">|</span><span class="token number">13</span><span class="token operator">|</span><span class="token number">14</span><span class="token operator">|</span><span class="token number">15</span><span class="token operator">|</span><span class="token number">16</span><span class="token operator">|</span><span class="token number">17</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">|</span><span class="token number">19</span><span class="token operator">|</span><span class="token number">20</span><span class="token operator">|</span><span class="token number">21</span><span class="token operator">|</span><span class="token number">22</span><span class="token operator">|</span><span class="token number">23</span><span class="token operator">|</span><span class="token number">24</span><span class="token operator">|</span><span class="token number">25</span><span class="token operator">|</span><span class="token number">26</span><span class="token operator">|</span><span class="token number">27</span><span class="token operator">|</span><span class="token number">28</span><span class="token operator">|</span><span class="token number">29</span><span class="token operator">|</span><span class="token number">30</span><span class="token operator">|</span><span class="token number">31</span>
<span class="token number">4</span> blocks <span class="token keyword">in</span> total, each of them contain <span class="token number">8</span> threads
data<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">(</span>blockIdx.x<span class="token punctuation">)</span> * <span class="token number">8</span><span class="token punctuation">(</span>blockDim.x<span class="token punctuation">)</span> + <span class="token number">4</span><span class="token punctuation">(</span>threadIdx.x<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-cpp"><span class="token comment">// nvcc add.cu -o add &amp;&amp; ./add</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"cuda_runtime.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;memory&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">N</span> <span class="token expression"><span class="token punctuation">(</span><span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">THREADS_PER_BLOCK</span> <span class="token expression"><span class="token number">512</span></span></span>

<span class="token keyword">class</span> <span class="token class-name">Obj</span><span class="token punctuation">{<!-- --></span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token function">Obj</span><span class="token punctuation">(</span><span class="token keyword">int</span> a<span class="token punctuation">)</span><span class="token operator">:</span><span class="token function">a_</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token function">Obj</span><span class="token punctuation">(</span><span class="token keyword">const</span> Obj <span class="token operator">&amp;</span>obj<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">puts</span><span class="token punctuation">(</span><span class="token string">"copy constructor called"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">this</span><span class="token operator">-&gt;</span>a_ <span class="token operator">=</span> obj<span class="token punctuation">.</span>a_<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token operator">~</span><span class="token function">Obj</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token keyword">int</span> a_<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token comment">// kernel å‡½æ•°é€šå¸¸æ²¡æœ‰è¿”å›å€¼ï¼Œå¯¹å®ƒçš„é”™è¯¯æ£€æŸ¥éœ€è¦ç”¨åˆ°å®å®šä¹‰</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">CHECK</span><span class="token expression"><span class="token punctuation">(</span>call<span class="token punctuation">)</span>                                 </span><span class="token punctuation">\</span>
<span class="token expression"><span class="token keyword">do</span>                                                  </span><span class="token punctuation">\</span>
<span class="token expression"><span class="token punctuation">{<!-- --></span>                                                   </span><span class="token punctuation">\</span>
   <span class="token expression"><span class="token keyword">const</span> cudaError_t error_code <span class="token operator">=</span> call<span class="token punctuation">;</span>             </span><span class="token punctuation">\</span>
   <span class="token expression"><span class="token keyword">if</span> <span class="token punctuation">(</span>error_code <span class="token operator">!=</span> cudaSuccess<span class="token punctuation">)</span>                   </span><span class="token punctuation">\</span>
   <span class="token expression"><span class="token punctuation">{<!-- --></span>                                                </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">"CUDA Error:\n"</span><span class="token expression"><span class="token punctuation">)</span><span class="token punctuation">;</span>                     </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">"    File:       %s\n"</span><span class="token expression"><span class="token punctuation">,</span> <span class="token constant">__FILE__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">"    Line:       %d\n"</span><span class="token expression"><span class="token punctuation">,</span> <span class="token constant">__LINE__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">"    Error code: %d\n"</span><span class="token expression"><span class="token punctuation">,</span> error_code<span class="token punctuation">)</span><span class="token punctuation">;</span>  </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">"    Error text: %s"</span><span class="token expression"><span class="token punctuation">,</span>                 </span><span class="token punctuation">\</span>
           <span class="token expression"><span class="token function">cudaGetErrorString</span><span class="token punctuation">(</span>error_code<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         </span><span class="token punctuation">\</span>
       <span class="token expression"><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                                     </span><span class="token punctuation">\</span>
   <span class="token expression"><span class="token punctuation">}</span>                                                </span><span class="token punctuation">\</span>
<span class="token expression"><span class="token punctuation">}</span> <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span></span>

__global__ <span class="token keyword">void</span> <span class="token function">addkernel</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> a<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> b<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> c<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> Obj obj<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>

    <span class="token keyword">const</span> <span class="token keyword">int</span> index <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token comment">// åªæ‰“å°ä¸€æ¬¡ï¼Œä¸ç„¶ç»ˆç«¯å¤ªå¤šä¿¡æ¯</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>index<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"obj.a_ : %d\n"</span><span class="token punctuation">,</span> obj<span class="token punctuation">.</span>a_<span class="token punctuation">)</span><span class="token punctuation">;</span>
        obj<span class="token punctuation">.</span>a_ <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">if</span><span class="token punctuation">(</span>index <span class="token operator">&lt;</span> n<span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        c<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">+</span> b<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> <span class="token operator">*</span>a<span class="token punctuation">,</span> <span class="token operator">*</span>b<span class="token punctuation">,</span> <span class="token operator">*</span>c<span class="token punctuation">;</span>
    <span class="token keyword">int</span> <span class="token operator">*</span>d_a<span class="token punctuation">,</span> <span class="token operator">*</span>d_b<span class="token punctuation">,</span> <span class="token operator">*</span>d_c<span class="token punctuation">;</span>
    <span class="token keyword">int</span> size <span class="token operator">=</span> N <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_a<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_b<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_c<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>

    a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> i<span class="token punctuation">;</span>
    b <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> b<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> i<span class="token punctuation">;</span>
    c <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_a<span class="token punctuation">,</span> a<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// printf("cudaMemcpy function: %s\n", cudaGetErrorString(cudaGetLastError()));</span>
    <span class="token comment">// å¦‚æœä½¿ç”¨ cudaMemcpyDefaultï¼Œäº¤æ¢ d_a å’Œ a ä¸ä¼šæŠ¥é”™ï¼ŒcudaMemcpyHostToDevice åˆ™ä¼šæŠ¥é”™</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_b<span class="token punctuation">,</span> b<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// å¦‚æœä½¿ç”¨ cudaMemcpyDefaultï¼Œäº¤æ¢ d_b å’Œ b ä¸ä¼šæŠ¥é”™ï¼ŒcudaMemcpyHostToDevice åˆ™ä¼šæŠ¥é”™</span>

    dim3 n<span class="token punctuation">{<!-- --></span>THREADS_PER_BLOCK<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    <span class="token comment">// blockDim.x å’Œ gridDim.x å¯ä»¥æ˜¯è¿è¡ŒæœŸå‚æ•°ï¼Œä¸ä¸€å®šåœ¨ç¼–è¯‘æ—¶å°±ç¡®å®š</span>
    dim3 m<span class="token punctuation">{<!-- --></span><span class="token punctuation">(</span>N <span class="token operator">+</span> n<span class="token punctuation">.</span>x <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> n<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">;</span>  <span class="token comment">// a/b ä¸Šå–æ•´ -&gt; (a+b-1)/b</span>

    <span class="token comment">// std::unique_ptr&lt;int&gt; d_ap(d_a);</span>
    <span class="token comment">// std::unique_ptr&lt;int&gt; d_bp(d_b);</span>
    <span class="token comment">// std::unique_ptr&lt;int&gt; d_cp(d_c);</span>
    <span class="token comment">// printf("d_ap.get(): %p, d_bp.get(): %p, d_cp.get(): %p\n", d_ap.get(), d_bp.get(), d_cp.get());</span>
    <span class="token comment">// addkernel&lt;&lt;&lt;m, n&gt;&gt;&gt;(d_ap.get(), d_bp.get(), d_cp.get(), N);</span>

    Obj <span class="token function">obj</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    addkernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>m<span class="token punctuation">,</span> n<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_a<span class="token punctuation">,</span> d_b<span class="token punctuation">,</span> d_c<span class="token punctuation">,</span> N<span class="token punctuation">,</span> obj<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaGetLastError</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span> d_c<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"gpu result %d, cpu result %d\n"</span><span class="token punctuation">,</span> c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// printf("after addkernel called, obj._a: %d\n", obj._a);</span>

    <span class="token function">free</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">free</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">free</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_a<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_b<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_c<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>å‡ ç‚¹æ³¨æ„äº‹é¡¹ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Â  
        
       
      
        \space 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em;"></span><span class="mspace">Â </span></span></span></span></span> kernel å‡½æ•°å¯ä»¥æ˜¯æ¨¡æ¿å‡½æ•°ï¼Œåœ¨å®ç°æ’ä»¶ä¸åŒç²¾åº¦è®¡ç®—æµç¨‹æ—¶æœ‰ç”¨ï¼Œä½†ç”±äºè®¡ç®—é€»è¾‘ä¸ä¸€è‡´ï¼Œéœ€è¦æ¨¡æ¿ç‰¹åŒ–</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Â  
        
       
      
        \space 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em;"></span><span class="mspace">Â </span></span></span></span></span> é™¤äº†æŒ‡é’ˆä¹‹å¤–ï¼Œä¼ é€’ç»™ kernel å‡½æ•°çš„å¯ä»¥æ˜¯ c++ çš„å¯¹è±¡ï¼Œæ­¤æ—¶åªèƒ½æ˜¯ pass by value semanticsï¼Œå¦åˆ™ä¼šæŠ¥ an illegal memory access was encountered çš„é”™è¯¯</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Â  
        
       
      
        \space 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em;"></span><span class="mspace">Â </span></span></span></span></span> .cu æ–‡ä»¶é‡Œé¢å¯ä»¥å¯ä»¥ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆï¼Œç¼–è¯‘æ²¡é—®é¢˜ã€‚ä½†æ˜¯ host å’Œ device ä¹‹é—´ä¼ é€’æ•°æ®çš„æŒ‡é’ˆéœ€è¦æ˜¯åŸå§‹æŒ‡é’ˆã€‚ç¬¦åˆ c++ è¯­è¨€æ ‡å‡†å¹¶ä¸æ„å‘³ç€æ”¯æŒ c++ çš„æ ‡å‡†åº“é‡Œæ‰€æœ‰ç‰¹å¾ï¼Œæ™ºèƒ½æŒ‡é’ˆæ˜¯æ ‡å‡†åº“é‡Œçš„ä¸œè¥¿ï¼ˆstd::shared_ptr&lt;T&gt;ï¼‰</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Â  
        
       
      
        \space 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em;"></span><span class="mspace">Â </span></span></span></span></span> c++ è¯­è¨€æ ‡å‡†å¹¶æ²¡æœ‰å¼ºåˆ¶è§„å®šç±»å‹çš„å¤§å°ã€‚sizeof(long) çš„å€¼ç”±ç¼–è¯‘å™¨å†³å®šï¼Œä¸åŒæ“ä½œç³»ç»Ÿå’Œä½“ç³»ç»“æ„ä½¿ç”¨ä¸åŒçš„æ•°æ®æ¨¡å‹ï¼ˆ<a href="https://nickdesaulniers.github.io/blog/2016/05/30/data-models-and-word-size/" rel="nofollow">Data Models and Word Size</a>ï¼Œ<a href="https://www.cnblogs.com/lsgxeva/p/7614856.html" rel="nofollow">æ•°æ®æ¨¡å‹(LP32 LP64 LLP64 ILP64)-Isgxeva-åšå®¢å›­</a>ï¼‰ã€‚åœ¨è¿™ç±»é—®é¢˜ä¸Šï¼Œnvcc è´Ÿè´£å’Œ host ç¼–è¯‘å™¨ï¼ˆæ¯”å¦‚ gcc å’Œ g++ï¼‰ä¿æŒä¸€è‡´</p> 
<p><font color="RoyalBlue"><strong>5.</strong></font> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Â  
        
       
      
        \space 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em;"></span><span class="mspace">Â </span></span></span></span></span> åŒä¸€ä¸ª block é‡Œé¢çš„ threads å¯ä»¥é€šä¿¡å’ŒåŒæ­¥ï¼Œç®€å•çš„ä¾‹å­æ¯”å¦‚å‘é‡ç›¸åŠ å¯èƒ½ç”¨ä¸åˆ°è¿™ç§æœºåˆ¶</p> 
<h3><a id="1_CUDA_165"></a>1. CUDAå…±äº«å†…å­˜</h3> 
<p>ä¸ŠèŠ‚è¯¾æåˆ° CUDA ç¼–ç¨‹æ¨¡å‹è®¾è®¡ grid å’Œ block ä¸¤ä¸ªå±‚çº§çš„æ¦‚å¿µæ˜¯å› ä¸ºä¸€ä¸ª block é‡Œçš„çº¿ç¨‹å¯ä»¥ä½¿ç”¨å…±äº«å†…å­˜é€šä¿¡ï¼ˆä¸€ä¸ªçº¿ç¨‹å†™ï¼Œå¦å¤–ä¸€ä¸ªçº¿ç¨‹è¯»ï¼‰ã€‚å…±äº«å†…å­˜ï¼ˆShared memoryï¼‰æ˜¯ä¸€ç§ç‰‡ä¸Šé«˜é€Ÿç¼“å­˜ã€‚å½“è¦è§£å†³çš„é—®é¢˜å¯ä»¥ data å¤ç”¨çš„æ—¶å€™ï¼Œæ¯æ¬¡éƒ½ä» globalï¼ˆåœ¨ DRAM ä¸Šï¼Œ*d_aï¼Œ*d_bï¼Œ*d_c è¿™äº›éƒ½æ˜¯ï¼‰è¯»å–çš„è¯æ¯”è¾ƒæŸå¤±æ€§èƒ½ï¼Œå¯ä»¥è€ƒè™‘ç”¨ shared memory ä½œä¸ºç¼“å­˜æ¥åŠ é€Ÿï¼ˆè¿™ä¸ªæ€æƒ³å¯¹äºæ‰€æœ‰æœ‰å†…å­˜å±‚çº§ç»“æ„çš„ç¡¬ä»¶éƒ½é€‚ç”¨ï¼Œä¸æ­¢ GPU/CUDAï¼‰</p> 
<p>Shared memory çš„ç‰¹æ€§ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> Shared memory æ˜¯åœ¨èŠ¯ç‰‡ä¸Šï¼ˆon-chipï¼‰çš„å†…å­˜ã€‚æ•°é‡å°‘ï¼Œé€Ÿåº¦å¿«ï¼ˆhigher bandwidthï¼Œlower latencyï¼‰</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> åªå¯¹ä¸€ä¸ª block é‡Œé¢çš„æ‰€æœ‰çº¿ç¨‹å¯è§ï¼Œå…¶ä»– block æœ‰å®ƒä»¬è‡ªå·±çš„ shared memory å‰¯æœ¬</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> ç›¸æ¯”äº L1 ç¼“å­˜ï¼ˆåŒæ · on-chipï¼‰ï¼Œå®ƒå¯ä»¥ç”±ç¨‹åºå‘˜ç®¡ç†ï¼Œç”¨ __shared__ æ¥åˆ†é…</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> æœ‰åŠ¨æ€å’Œé™æ€åˆ†é…æ–¹å¼ï¼Œä¸¤ç§åˆ†é…æ–¹å¼æ²¡æœ‰æ€§èƒ½å·®å¼‚ï¼š</p> 
<ul><li><font color="RoyalBlue"><strong>a.</strong></font> é™æ€ï¼š__shared__temp[size];</li><li><font color="RoyalBlue"><strong>b.</strong></font> åŠ¨æ€ï¼š__shared__temp[];kernel&lt;&lt;&lt;m,n,size_in_bytes&gt;&gt;&gt;();</li></ul> 
<p>1D stencil é—®é¢˜çš„å®šä¹‰ï¼šæ¯ä¸ªå…ƒç´ çš„ output æ˜¯å…¶å‘¨å›´ï¼ˆåŒ…æ‹¬å®ƒè‡ªå·±ï¼‰2r+1 ä¸ªå…ƒç´ çš„å’Œï¼ˆç±»ä¼¼ä¸€ç»´å·ç§¯ï¼‰ã€‚ä¾‹å­ï¼š</p> 
<blockquote> 
 <p>â€‹ |x|x|x| input |x|x|x|</p> 
 <p>â€‹ |x|x|x| output|x|x|x|</p> 
</blockquote> 
<p>å½“ r æ˜¯ 3 çš„æ—¶å€™ï¼Œæ¯ä¸ªå…ƒç´ è®¡ç®—å…¶å‘¨å›´ 7 ä¸ªå…ƒç´ çš„å’Œã€‚æ³¨æ„ï¼šè¾“å…¥è¾“å‡ºçš„æ•°é‡è§„æ¨¡æ˜¯ä¸€æ ·çš„ï¼ˆæœ‰åˆ«äºæ•°æ®è§„çº¦æ±‚å’Œï¼‰</p> 
<p>åœ¨ä¸€ä¸ªçº¿ç¨‹å— block é‡Œé¢çš„æ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸€ä¸ª outputï¼Œè¾“å…¥æ•°æ®å­˜åœ¨é‡å¤è¯»å–çš„æƒ…å†µï¼š</p> 
<blockquote> 
 <p>â€‹ input: |x|x|x|X|Y|x|x|output|x|x|x|x|x|x|x|â€¦ï¼ˆæ€»ä½“æ•°æ®é‡å¾ˆå¤§ï¼Œè¿™è¾¹åªè€ƒè™‘ä¸€ä¸ª block é‡Œçš„æƒ…å†µï¼‰</p> 
 <p>â€‹ ^ ^</p> 
</blockquote> 
<p>è®¡ç®— X æ—¶å€™ï¼Œéœ€è¯»å–å‘¨å›´ 7 ä¸ªå…ƒç´ ã€‚è®¡ç®— Y çš„æ—¶å€™ï¼Œä¹Ÿéœ€è¦è¯»å–å‘¨å›´ 7 ä¸ªå…ƒç´ ã€‚å¹³å‡ä¸‹æ¥ï¼Œå½“ r æ˜¯ 3 çš„æ—¶å€™ï¼Œæ¯ä¸ªè¾“å…¥æ•°æ®éœ€è¦è¢«è¯»å– 7 æ¬¡ï¼Œå®ƒåœ¨ 7 ä¸ªè¾“å‡ºæ•°æ®çš„è®¡ç®—è¿‡ç¨‹ä¸­è¢«ç”¨åˆ°</p> 
<p>æ€è·¯ï¼šæŠŠæ•°æ®ç¼“å­˜åœ¨ shared memory é‡Œï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> è®¾ç½®ä¸€ä¸ª block é‡Œè¦å¤„ç†çš„æ•°æ®é‡æ­£å¥½æ˜¯ blockDim.x ä¸ª</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> ä» global memory é‡Œé¢è¯»å– blockDim.x + 2 * rï¼ˆåŸå› è§ä¸‹ï¼‰è¿™ä¹ˆå¤šè¾“å…¥æ•°æ®åˆ° shared memory é‡Œ</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> è®¡ç®— blockDim.x ä¸ªè¾“å‡ºæ•°æ®ï¼Œæ¯ä¸ªçº¿ç¨‹ç”¨è‡ªå·±çš„å¯„å­˜å™¨ä¿å­˜æ±‚å’Œçš„ç»“æœï¼ˆresï¼‰</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> æŠŠ blockDim.x ä¸ªè¾“å‡ºæ•°æ®å†™å› global memory é‡Œ</p> 
<p><font color="RoyalBlue"><strong>5.</strong></font> æ¯ä¸ª block éœ€è¦åœ¨å·¦å³è¾¹ç•Œåˆ†åˆ«å¡«è¡¥ r ä¸ªå…ƒç´ ï¼Œr = 3 çš„ä¾‹å­</p> 
<blockquote> 
 <p>â€‹ |x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|</p> 
 <p>|x|x|x|^ ^|x|x|x|</p> 
</blockquote> 
<p>Exampleï¼š</p> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">r</span> <span class="token expression"><span class="token number">3</span></span></span>
__global__ <span class="token function">stencil_1d</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> in<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> out<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    __shared__ <span class="token keyword">int</span> temp<span class="token punctuation">[</span>BLOCK_SIZE <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> r<span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">// per-block, static allocation</span>
    <span class="token keyword">int</span> gindex <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>  <span class="token comment">// ç”¨æ¥ç´¢å¼• global memory</span>
    <span class="token keyword">int</span> lindex <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> r<span class="token punctuation">;</span>   <span class="token comment">// ç”¨æ¥ç´¢å¼• shared memory</span>
    
    <span class="token comment">// æŠŠæ•°æ®ä» global memory è¯»åˆ° shared memory é‡Œã€‚æ²¡æœ‰ for å¾ªç¯ï¼ŒSIMT æ¨¡å¼ï¼Œä¸€ä¸ª block é‡Œæ‰€æœ‰çº¿ç¨‹åˆä½œå®Œæˆ</span>
    temp<span class="token punctuation">[</span>lindex<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>gindex<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> r<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        temp<span class="token punctuation">[</span>lindex <span class="token operator">-</span> r<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>gindex <span class="token operator">-</span> r<span class="token punctuation">]</span><span class="token punctuation">;</span>
        temp<span class="token punctuation">[</span>lindex <span class="token operator">+</span> BLOCK_SIZE<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>gindex <span class="token operator">+</span> BLOCK_SIZE<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// ç¡®ä¿æ‰€æœ‰æ•°æ®å·²ç»è¯»åˆ° shared memory é‡Œï¼Œæ³¨æ„ä¸èƒ½å†™åœ¨ if æ¡ä»¶è¯­å¥é‡Œ</span>
    <span class="token keyword">int</span> res <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token comment">// æ­¤æ—¶éœ€è¦ for å¾ªç¯ï¼Œå› ä¸ºä¸€æ¬¡çº¿ç¨‹è¦è´Ÿè´£è®¡ç®— 2*r+1 ä¸ªå…ƒç´ çš„å’Œ</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> <span class="token operator">-</span>r<span class="token punctuation">;</span> offset <span class="token operator">&lt;=</span> r<span class="token punctuation">;</span> offset<span class="token operator">++</span><span class="token punctuation">)</span>
        res <span class="token operator">+=</span> temp<span class="token punctuation">[</span>lindex <span class="token operator">+</span> offset<span class="token punctuation">]</span><span class="token punctuation">;</span>
    out<span class="token punctuation">[</span>gindex<span class="token punctuation">]</span> <span class="token operator">=</span> res<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="2_GPU_239"></a>2. GPUæ¶æ„ç®€ä»‹</h3> 
<p>å‰é¢ä¸¤èŠ‚è¯¾è®²äº†å¦‚ä½•å†™è¯­æ³•æ­£ç¡®çš„ CUDAã€‚äººä»¬ä½¿ç”¨ CUDA çš„åŸå› æ˜¯æé«˜æ€§èƒ½ï¼Œè€Œè¿™éœ€è¦äº†è§£ GPU çš„ç¡¬ä»¶æ¶æ„çŸ¥è¯†æ•™ç¨‹é‡Œçš„æé«˜å¹¶è¡Œåº¦ï¼Œå¢åŠ  GPU ä½¿ç”¨ç‡ -&gt; ä½¿ç”¨è¶³å¤Ÿå¤šçš„çº¿ç¨‹ï¼Œä½†æ˜¯ä»€ä¹ˆæ˜¯â€œè¶³å¤Ÿå¤šâ€ï¼Ÿ</p> 
<p>GPU çš„ core å’Œ CPU çš„ ALU ç±»ä¼¼ï¼ŒCPU çš„ core å’Œ GPU çš„ sm ç±»ä¼¼</p> 
<p>Dual-issueï¼šwarp schedule èƒ½å¤Ÿåœ¨åŒä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…è°ƒåº¦ä¸¤æ¡åœ¨ä¸€ä¸ªæŒ‡ä»¤é˜Ÿåˆ—é‡Œçš„ç›¸é‚»çš„æŒ‡ä»¤</p> 
<p>ä¸€èˆ¬è€Œè¨€ï¼ŒSM æ•°é‡è¶Šå¤šï¼Œæ€§èƒ½è¶Šå¥½ã€‚ç¨‹åºå¯ä»¥åœ¨ä¸ç”¨é‡æ–°ç¼–è¯‘çš„æƒ…å†µä¸‹è‡ªåŠ¨é€‚é…æœ‰æ›´å¤šçš„ SM çš„æ¶æ„</p> 
<p>Warp scheduler: å†³å®šäº†ä»€ä¹ˆæ—¶å€™å“ªæ¡æŒ‡ä»¤å¾—åˆ°æ‰§è¡Œï¼Œwarp-by-warp çš„ï¼Œæ°¸è¿œæ˜¯ä¸€ä¸ª warpï¼ˆ32 ä¸ªçº¿ç¨‹ä¸€èµ·æ‰§è¡Œï¼‰</p> 
<p>åŒä¸€æ¶æ„é‡Œï¼ŒCompute compabilityï¼ˆCCï¼‰çš„ç¬¬ä¸€ä¸ªæ•°å­—æ˜¯ä¸€æ ·çš„ï¼ˆTuring é™¤å¤–ï¼Œå®ƒå’Œ Volta ä¸€æ ·ï¼Œä¹Ÿæ˜¯ 7.xï¼‰</p> 
<p>cc5.2 å’Œ cc6.1 ç¡¬ä»¶æ¶æ„ç±»ä¼¼ï¼Œcc6.0 å’Œ cc7.0 ç¡¬ä»¶æ¶æ„ç±»ä¼¼</p> 
<p>Tesla GPU çš„æ˜¾å­˜æœ‰ ecc å†…å­˜ï¼ˆ<a href="https://zhuanlan.zhihu.com/p/667459081" rel="nofollow">å†…å­˜ECC æœºåˆ¶</a>ï¼‰ï¼ŒGeforce ç³»åˆ—åˆ™æ²¡æœ‰</p> 
<p>ä¸€ä¸ªçº¿ç¨‹å—é‡Œçš„çº¿ç¨‹ä¸ä¼šè·¨è¶Š SM é©»ç•™ï¼Œä»å§‹è‡³ç»ˆï¼ˆfrom æŒ‡ä»¤ issue to retireï¼‰å®ƒä»¬æ€»æ˜¯é©»ç•™åœ¨ä¸€ä¸ª SM é‡Œ</p> 
<p><img src="https://images2.imgbox.com/d6/a1/lSCewq8y_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/29/82/C6nMvLHO_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/82/73/gOyvR3vz_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/05/f0/h7SyrOHy_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><a href="https://zhuanlan.zhihu.com/p/394352476" rel="nofollow">NVIDIA GPU æ¶æ„æ¢³ç†</a> <a href="https://zhuanlan.zhihu.com/p/146042266" rel="nofollow">NVIDIA Ampere æ¶æ„æ·±åº¦è§£æ</a></p> 
<p>ä¸€ä¸ªçº¿ç¨‹å— block å¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºå¤šä¸ª warpï¼Œä¸€ä¸ª warp ç”± 32 ä¸ªçº¿ç¨‹ç»„æˆã€‚æŒ‡ä»¤çš„æ‰§è¡Œæ€»æ˜¯ä»¥ warpï¼ˆ32 ä¸ªçº¿ç¨‹ï¼‰ä¸ºå•ä½ GPU æ²¡æœ‰ CPU é‚£æ ·é¢„å–å’Œåˆ†æ”¯é¢„æµ‹ä¹‹ç±»çš„æœºåˆ¶ï¼Œå®ƒèƒ½æé«˜æ€§èƒ½çš„æ–¹å¼åªæœ‰ä¸€ä¸ªï¼šå»¶è¿Ÿéšè—ï¼ˆlatency hidingï¼‰ã€‚è¿™ä¸€ç‚¹éœ€è¦æœ‰è¶³å¤Ÿçš„ warp æ¥å®ç°ï¼Œä¹Ÿå°±æ˜¯è¶³å¤Ÿå¤šçš„çº¿ç¨‹ã€‚å›ç­”â€è®¾ç½®å‡ ä¸ªçº¿ç¨‹ï¼ˆgridDim.x * blockDim.xï¼‰åˆé€‚â€œè¿™ä¸ªé—®é¢˜ï¼Ÿ</p> 
<p>Latencyï¼šä½ è¦ä¸€ä¸ªä¸œè¥¿å’Œä½ å¾—åˆ°ä¸€ä¸ªä¸œè¥¿ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼Œé€šå¸¸ç”¨ clock cycle æ¥è¡¡é‡</p> 
<p>å…¨å±€å†…å­˜è®¿é—®çš„ latencyï¼š&gt;100ï¼ˆor hundredsï¼‰è®¡ç®—çš„ latencyï¼š&lt;100ï¼ˆtypical 5ï¼‰cycles</p> 
<p>å‡è®¾ä½ æ˜¯ warp è°ƒåº¦å™¨ï¼Œä½ çš„ç›®æ ‡æ˜¯ä½¿å¾—æœºå™¨ä¸è¦æœ‰é—²ç½®çš„æ—¶åˆ»ï¼Œè¿™æ ·å°±èƒ½å–å¾—é«˜æ€§èƒ½</p> 
<p><img src="https://images2.imgbox.com/6b/dd/YeqFDFd1_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æ³¨æ„åœ¨çœŸå®çš„åœºæ™¯ä¸­ï¼Œè®¿é—®å…¨å±€å†…å­˜çš„ latency è¦è¿œå¤§äº 18 ä¸ª cycleã€‚å¦‚æœä½ çš„ warp æ•°é‡æ˜¯æ— é™å¤§ï¼Œé‚£ä¹ˆä½ çš„æœºå™¨æ°¸è¿œä¸ä¼šé—²ç½®ï¼Œä½†è¿™æ˜¯ä¸å¯èƒ½çš„ã€‚Voltaï¼š64 warps per SM æ˜¯ä¸Šé™å€¼ï¼Œ80ï¼ˆSMsï¼‰* 64 * 32ï¼ˆthreads/warpï¼‰= 163840ï¼ŒgridDim.x * blockDim.x çš„å€¼å¦‚æœå°äº 163840ï¼Œé‚£ä¹ˆå¯¹äº Volta æ¶æ„ï¼Œæ˜¯æ²¡æœ‰å®Œå…¨åˆ©ç”¨å¤„ç†å™¨æ€§èƒ½çš„ã€‚</p> 
<p>æ³¨æ„äº‹é¡¹ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> ä»¥ä¸Šè®¨è®ºæ²¡æœ‰è€ƒè™‘ cache çš„å­˜åœ¨ï¼Œåˆä»£ GPU æ˜¯æ²¡æœ‰ cache çš„ï¼Œè¯´æ˜ latency hiding ä»»ä½•æ—¶å€™éƒ½æœ‰ç”¨</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> å½“ç„¶ï¼Œå¦‚æœæŒ‡ä»¤ä¹‹é—´æ²¡æœ‰ä¾èµ–æ€§æ—¶ä¹Ÿå¯ä»¥åšåˆ° latency hiding</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> å¦‚æœä½ çš„ kernel æ˜¯å¸¦å®½ï¼ˆè®¡ç®— or è®¿å­˜ï¼‰å—é™ï¼Œé‚£ä¹ˆå¢åŠ ä¸€ä¸ª SM é‡Œçº¿ç¨‹æ•°é‡ä¹Ÿä¸ä¼šæé«˜æ€§èƒ½</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> åŒä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…ï¼Œ10 æŒ‡ä»¤å¯ä»¥æœ‰ä¸åŒçš„ warp ç”±ä¸åŒçš„ warp scheduler æ¥è°ƒåº¦ï¼Œåœ¨è®¡ç®—èµ„æºå……è¶³çš„æƒ…å†µä¸‹</p> 
<p><font color="RoyalBlue"><strong>5.</strong></font> ä¸Šå›¾é‡Œçš„ warp å¯ä»¥æ¥è‡ªä¸åŒçš„ blockï¼Œä¸€ä¸ª SM é‡Œå¯ä»¥åŒæ—¶é©»ç•™å¤šä¸ª blockï¼Œä½†æ˜¯æœ‰ä¸Šé™ã€‚è§ä¸‹é¢çš„ä»£ç ï¼š</p> 
<p><font color="RoyalBlue"><strong>6.</strong></font> åœ¨ç¬¬ 5 ç‚¹æ²¡è¾¾åˆ°ä¸Šé™çš„æƒ…å†µä¸‹ï¼ŒæŠŠä¸€ä¸ª block é‡Œçš„ warp æ•°å‡åŠåŒæ—¶å¢åŠ ä¸€å€çš„ blocks å’Œä¹‹å‰ç‰ˆæœ¬æ²¡æœ‰æ€§èƒ½å·®å¼‚</p> 
<pre><code class="prism language-cpp"><span class="token comment">// æ¼”ç¤º block schedule çš„ç¤ºä¾‹ä»£ç </span>
<span class="token comment">// ä¸€ä¸ª SM é‡Œèƒ½åŒæ—¶é©»ç•™çš„ block æ•°é‡æ˜¯æœ‰é™åˆ¶çš„ï¼Œ(Maxwell/Pascal/Volta:32)</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;sys/time.h&gt;</span></span>

<span class="token keyword">double</span> <span class="token function">cpuSecond</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">struct</span> <span class="token class-name">timeval</span> tp<span class="token punctuation">;</span>
    <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>tp<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span> tp<span class="token punctuation">.</span>tv_sec <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span>tp<span class="token punctuation">.</span>tv_usec<span class="token operator">*</span><span class="token number">1e-6</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">CLOCK_RATE</span> <span class="token expression"><span class="token number">1695000</span>  </span><span class="token comment">/* Modify from below */</span></span>
__device__ <span class="token keyword">void</span> <span class="token function">sleep</span><span class="token punctuation">(</span><span class="token keyword">float</span> t<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    clock_t t0 <span class="token operator">=</span> <span class="token function">clock64</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    clock_t t1 <span class="token operator">=</span> t0<span class="token punctuation">;</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>t1 <span class="token operator">-</span> t0<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>CLOCK_RATE<span class="token operator">*</span><span class="token number">1000.0f</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> t<span class="token punctuation">)</span>
        t1 <span class="token operator">=</span> <span class="token function">clock64</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

__global__ <span class="token keyword">void</span> <span class="token function">mykernel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> cha<span class="token operator">*</span> argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    cudaDeviceProp prop<span class="token punctuation">;</span>
    <span class="token function">cudaGetDeviceProperties</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>prop<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">int</span> mp <span class="token operator">=</span> prop<span class="token punctuation">.</span>multiProcessorCount<span class="token punctuation">;</span>  <span class="token comment">// 64</span>
    <span class="token comment">// int mbp = prop.maxBlocksPerMultiProcessor;  // 16</span>
    <span class="token comment">// printf("mbp     %10d\n",mbp);</span>
    <span class="token comment">// clock_t clock_rate = prop.clockRate;</span>
    <span class="token comment">// printf("clock_rate     %10d\n",clock_rate);</span>
    <span class="token comment">// 64 * 16 = 1024, 2048, 3072, 4096</span>
    <span class="token keyword">int</span> num_blocks <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    dim3 <span class="token function">block</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    dim3 <span class="token function">grid</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">/* N blocks */</span>
    
    <span class="token keyword">double</span> start <span class="token operator">=</span> <span class="token function">cpuSecond</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    mykernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span>block<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">double</span> etime <span class="token operator">=</span> <span class="token function">cpuSecond</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start<span class="token punctuation">;</span>
    
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"mp         %10d\n"</span><span class="token punctuation">,</span>mp<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"block/SM   %10.2f\n"</span><span class="token punctuation">,</span>num_blocks<span class="token operator">/</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span>mp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"time       %10.2f\n"</span><span class="token punctuation">,</span>etime<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">cudaDeviceReset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="3_CUDA_352"></a>3. CUDAå†…å­˜å­ç³»ç»Ÿ</h3> 
<p>ä¸ŠèŠ‚è¯¾æˆ‘ä»¬ç»“åˆ GPU çš„ç¡¬ä»¶æ¶æ„å­¦åˆ°äº† CUDA æ€§èƒ½ä¼˜åŒ–çš„ä¸€å¤§å‡†åˆ™ï¼šå¼€å¯è¶³å¤Ÿå¤šçš„çº¿ç¨‹ï¼Œè¿™èŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ å¦ä¸€å¤§å‡†åˆ™ï¼šé«˜æ•ˆåˆ©ç”¨å†…å­˜å­ç³»ç»Ÿï¼Œæˆ‘ä»¬ä¸»è¦è®¨è®ºå¯¹ global å’Œ shared memory çš„è®¿é—®ã€‚</p> 
<p>GPU å†…å­˜å±‚çº§ç»“æ„ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> æœ¬åœ°å­˜å‚¨ï¼ˆlocal storageï¼‰ï¼Œæ¯ä¸ªçº¿ç¨‹ç‹¬æœ‰ï¼Œé€šå¸¸æ˜¯æŒ‡å¯„å­˜å™¨ï¼Œstencil é—®é¢˜é‡Œä¿å­˜æ±‚å’Œç»“æœçš„å˜é‡ res</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> å…±äº«å†…å­˜/L1 ç¼“å­˜ï¼Œé€šå¸¸æ˜¯ 48ï¼ˆ6496ï¼‰KB è¿™ä¸ªçº§åˆ«ã€‚å¯ä»¥ç”±ç¨‹åºå‘˜ç®¡ç†ï¼Œå¯¹äºä¸€ä¸ª block é‡Œæ‰€ä»¥çš„çº¿ç¨‹å¯è§ï¼Œè®¿é—®é€Ÿåº¦å¾ˆå¿«ï¼Œå¸¦å®½å¾ˆé«˜ï¼Œé€šå¸¸å¤§äº 1TB/sï¼ŒL1 æ²¡æœ‰ cache ä¸€è‡´æ€§åè®®</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> L2 ç¼“å­˜ï¼Œdevice çº§åˆ«çš„èµ„æºï¼Œå¯¹äºæ‰€æœ‰çº¿ç¨‹å¯è§ï¼Œç”¨æ¥ç¼“å­˜å¯¹äº global å†…å­˜çš„è®¿é—®ã€‚L2 ç¼“å­˜æœ‰ cache ä¸€è‡´æ€§åè®®ã€‚</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> Global å†…å­˜ï¼Œå¯¹äºæ‰€æœ‰çº¿ç¨‹å¯è§ï¼ŒCPU ä¹Ÿå¯ä»¥ã€‚latency æ¯”è¾ƒé«˜ï¼ˆå‡ ç™¾ä¸ª cyclesï¼‰ï¼Œå¸¦å®½é€šå¸¸æ˜¯ 900GB/sï¼ˆVolta V100ï¼‰ï¼Œ768GB/sï¼ˆa5000ï¼‰è¿™ä¸ªçº§åˆ«ã€‚ç”¨ cudaMalloc å’Œ cudaFree æ¥ç®¡ç†ã€‚</p> 
<p><img src="https://images2.imgbox.com/87/71/4YtZrDjH_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/a7/86/jpjp3tfX_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>Global memory çš„è®¿é—®ç‰¹æ€§ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> è¯»å–ï¼šæœ‰ Cachingï¼Œæ˜¯é»˜è®¤çš„è¡Œä¸ºï¼Œå½“è¯»å–ä¸€ä¸ªæ•°æ®æ—¶ï¼Œå…ˆä» L1 ä¸­æ‰¾ï¼Œæ‰¾ä¸åˆ°çš„è¯ä» L2 ä¸­æ‰¾ï¼Œå†æ‰¾ä¸åˆ°çš„è¯æ‰ä» global memoryï¼Œä¸€æ¬¡è¯»å–çš„ç²’åº¦æ˜¯ 128 ä¸ª bytesï¼Œç§°ä¸ºä¸€ä¸ªç¼“å­˜è¡Œã€‚ä¹Ÿå¯ä»¥è¯´æ²¡æœ‰ç¼“å­˜çš„ï¼Œé€šè¿‡ç»™ nvcc ä¼ é€’ <code>-Xptxas -dlcm=cg</code> è¿™ä¸ªå‚æ•°ã€‚è¿™ä¸ªæ—¶å€™è¯»å–çš„ç²’åº¦æ˜¯ 32 ä¸ª bytesã€‚ä»€ä¹ˆæ—¶å€™æœ‰ç”¨ï¼Ÿç¨‹åºæ­£ç¡®æ€§è§’åº¦ï¼šæƒ³è¦ä¸¤ä¸ªåœ¨ä¸åŒ SM é‡Œçš„çº¿ç¨‹é€šä¿¡æ—¶æœ‰ç”¨ã€‚æ€§èƒ½è§’åº¦ï¼šç¼“è§£å…¨å±€å†…å­˜è®¿é—®ä¸åˆå¹¶æ—¶å€™æœ‰ç”¨ï¼ˆè§ä¸‹æ–‡ï¼‰ã€‚</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> å†™å…¥ï¼šä½¿ L1 ä¸­æŸä¸ªç¼“å­˜è¡Œå¤±æ•ˆï¼Œä¹Ÿå°±æ˜¯å¦‚æœå°†æ¥æœ‰å¯¹è¿™ä¸ªæ•°æ®çš„è¯»å–ï¼ŒL1 Cache ä¼š missï¼Œå¯¹äº L2 æ˜¯å›å†™å¼ï¼ˆwrite-backï¼‰ï¼Œä¹Ÿå°±æ˜¯å…ˆæ›´æ–° L2 é‡Œå†…å­˜ï¼Œåœ¨å°†æ¥æŸä¸ªæ—¶åˆ»å†å†™å›åˆ° global å†…å­˜é‡Œã€‚</p> 
<p><strong>æ³¨æ„</strong>ï¼šè®¿å­˜æ“ä½œä¹Ÿæ˜¯ä¸€ä¸ª warp é‡Œçš„ 32 ä¸ªçº¿ç¨‹ä¸€èµ·æ‰§è¡Œçš„ï¼Œä¸åŒçº¿ç¨‹å¯ä»¥è®¿é—®ä¸åŒå†…å®¹çš„æ•°æ®ï¼ˆé€šå¸¸æ˜¯ 32 ä¸ªä¸åŒçš„åœ°å€ï¼‰ã€‚å†…å­˜æ§åˆ¶å™¨ï¼ˆmemory controllerï¼‰å†³å®šäº†éœ€è¦è®¿é—®å“ªä¸€ä¸ªç¼“å­˜è¡Œï¼ˆä¸æ˜¯ä¸€ä¸ªå­—èŠ‚ï¼‰ã€‚</p> 
<p>ä¸‹å›¾ä¸­ï¼Œä¸€ä¸ª warp é‡Œè¦è®¿é—®çš„åœ°å€æ­£å¥½è½åœ¨ä¸€ä¸ª 32 ä½å¯¹é½çš„ç¼“å­˜è¡Œï¼ˆ128 bytesï¼‰é‡Œï¼Œå®ƒä»¬æ˜¯ç›¸é‚»ä¸”è¿ç»­çš„ã€‚128 bytes é€šè¿‡ bus ä¼ è¾“ä» global memory ä¼ è¾“åˆ°å¯„å­˜å™¨ä¸­ã€‚å®ƒä»¬ä¹Ÿæ˜¯è®¡ç®—æ—¶ç”¨åˆ°çš„ï¼Œbus å¸¦å®½çš„åˆ©ç”¨ç‡æ˜¯ 100%ã€‚<code>int c = a[idx];</code> è¿™æ ·çš„è®¿å­˜æ¨¡å¼ç§°ä¸ºåˆå¹¶è®¿å­˜ï¼ˆcoalescedï¼‰</p> 
<p><img src="https://images2.imgbox.com/04/b2/8wVZsSrw_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å›¾ä¸­ï¼Œè™½ç„¶æ¯ä¸ªçº¿ç¨‹è¦è®¿é—®çš„åœ°å€æ˜¯ä¸è¿ç»­çš„ï¼Œä½†å®ƒä»¬åŒæ ·è½åœ¨ä¸€ä¸ª 32 ä½å¯¹é½çš„ç¼“å­˜è¡Œé‡Œã€‚è¿™æ ·çš„è®¿å­˜æ¨¡å¼ä¹Ÿæ˜¯åˆå¹¶çš„ï¼Œå¸¦å®½çš„åˆ©ç”¨ç‡ä¹Ÿæ˜¯ 100%ã€‚<code>int c = a[rand()%warpSize];</code>ã€‚</p> 
<p><img src="https://images2.imgbox.com/ea/d8/80VZcPPB_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å›¾ä¸­ï¼Œä¸€ä¸ª warp é‡Œçš„çº¿ç¨‹è¦è®¿é—®çš„åœ°å€æ˜¯æ²¡æœ‰ 32 ä½å¯¹é½çš„è¿ç»­çš„ 128 bytesï¼Œæ­¤æ—¶è¿™äº›åœ°å€è½åœ¨äº† 2 ä¸ªç¼“å­˜è¡Œé‡Œã€‚è¿™å¯¼è‡´å®é™…åœ¨ bus ä¸Šä¼ è¾“çš„æ•°æ®é‡æ˜¯ 256 bytesï¼Œä½†æ˜¯è®¡ç®—æœ‰ç”¨çš„æ‰ 128 bytesã€‚bus åˆ©ç”¨ç‡æ˜¯ 50%ï¼Œä¼ è¾“çš„ 256 bytes é‡Œæœ‰ä¸€åŠæ²¡æœ‰ç”¨åˆ°ï¼Œæ­¤æ—¶çš„è®¿å­˜æ¨¡å¼ä¸æ˜¯åˆå¹¶çš„ã€‚<code>int c = a[idx-2];</code>ã€‚ä»è¿™ä¸ªè§’åº¦çœ‹ï¼Œå¦‚æœ kernel æ˜¯å¸¦å®½å—é™ï¼ˆmemory boundï¼‰ï¼Œé‚£ä¹ˆæ€§èƒ½ç›´æ¥ä¸‹é™ä¸€åŠã€‚ä½†æ˜¯å½“å…¶ä»– warp çš„çº¿ç¨‹è®¿å­˜çš„æ—¶å€™ï¼Œä¼šå‘ç°æ•°æ®å·²ç»åœ¨ç¼“å­˜ä¸­äº†ï¼Œæ‰€ä»¥å‡æ‘Šä¸‹æ¥ï¼Œå¹³å‡ä¸€ä¸ª warp éœ€è¦è®¿é—®ä¸€ä¸ªç¼“å­˜è¡Œï¼Œæ€§èƒ½å’Œåˆå¹¶è®¿å­˜å‡ ä¹æ²¡æœ‰å·®å¼‚ã€‚</p> 
<p><img src="https://images2.imgbox.com/d6/2d/rAJD8WX4_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å›¾ä¸­ï¼Œä¸€ä¸ª warp é‡Œ 32 ä¸ªçº¿ç¨‹è¦è®¿é—®çš„æ˜¯åŒä¸€ä¸ªåœ°å€ï¼Œæ­¤æ—¶è¿˜æ˜¯éœ€è¦ä¼ è¾“ä¸€ä¸ªç¼“å†²è¡Œçš„æ•°æ®é‡ï¼Œä¹Ÿå°±æ˜¯ 128 bytesã€‚ç”¨åˆ°çš„åªæ˜¯å…¶ä¸­çš„ 4 bytesï¼Œbus çš„åˆ©ç”¨ç‡æ˜¯ 4/128=3.125%ï¼Œ<code>int c = a[30]</code>ã€‚</p> 
<p><img src="https://images2.imgbox.com/06/5f/j63JdtyA_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å›¾ä¸­ï¼Œä¸€ä¸ª warp é‡Œ 32 ä¸ªçº¿ç¨‹è®¿é—®çš„åœ°å€æ˜¯éšæœºçš„ï¼Œæœ€å·®çš„æƒ…å†µæ˜¯æ¯ä¸ªåœ°å€éƒ½è½åœ¨äº†ä¸€ä¸ªç¼“å†²è¡Œé‡Œé¢ã€‚bus åˆ©ç”¨ç‡ï¼š128/(128*N)ï¼ŒN=32 æ—¶ï¼Œæœ€å·® 3.125%ã€‚<code>int c = a[rand()]</code>ã€‚é€šå¸¸é—´æ¥å¯»å€ä¼šå¯¼è‡´è¿™ç§è®¿å­˜æ¨¡å¼ï¼ˆindex æœ¬èº«æ˜¯éšæœºæ•°äº§ç”Ÿçš„ï¼‰ï¼ŒscatterND æ“ä½œä¸ºä»€ä¹ˆæ€§èƒ½ä½ï¼Ÿ</p> 
<p><img src="https://images2.imgbox.com/fe/05/W6kfsQIo_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å›¾ä¸­ï¼Œå¦‚æœé€šè¿‡ <code>Xptxas -dlcm=cg</code> æŠŠ L1 ç¼“å­˜å…³æ‰ï¼Œåˆ™æ²¡æœ‰ç¼“å­˜è¡Œçš„å­˜åœ¨ï¼Œæ¯æ¬¡å¯ä»¥åªè¯» 32 ä¸ª bytesã€‚æ­¤æ—¶æœ€å·®æƒ…å†µå½“ N=32 æ—¶çš„ bus åˆ©ç”¨ç‡æ˜¯ 128/(32*N)=12.5%ã€‚æœ‰åŠ©äºæ”¹å–„å…¨å±€å†…å­˜è®¿é—®ä¸åˆå¹¶çš„é—®é¢˜ã€‚</p> 
<p><img src="https://images2.imgbox.com/2d/78/HUx9zae7_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¼˜åŒ–ç­–ç•¥ï¼šæƒ³åŠæ³•åšåˆ°åˆå¹¶è®¿å­˜ï¼Œæœ‰æ—¶å€™å¯è€ƒè™‘ paddingã€‚ä¸€ä¸ª warp é‡Œçš„çº¿ç¨‹å°½å¯èƒ½è®¿é—®è¿ç»­çš„å†…å­˜åŒºåŸŸã€‚å¯¹äº memory bound çš„æ ¸å‡½æ•°ï¼ŒåŠªåŠ›æå‡ bus çš„åˆ©ç”¨ç‡ã€‚å¦‚ä½•åšåˆ°ï¼Ÿåœ¨ä¿è¯çº¿ç¨‹æ•°é‡è¶³å¤Ÿå¤šçš„æƒ…å†µä¸‹ï¼Œå¯ä»¥è€ƒè™‘è®©ä¸€ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªæ•°æ® -&gt; å‘é‡åŒ–è®¿å­˜ï¼ˆvector-loadï¼‰</p> 
<p>å…±äº«å†…å­˜ï¼ˆshared memoryï¼‰çš„ç»„ç»‡/æ€§èƒ½å’Œä½¿ç”¨åœºæ™¯ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> 32 ä¸ª bankï¼Œæ¯ä¸ª bank å®½åº¦ä¸º 4 ä¸ªå­—èŠ‚ã€‚ä¸¤ä¸ªç›¸å·®ä¸º 4 ä¸ª bytes çš„åœ°å€å±äºç›¸é‚»çš„ä¸åŒ bankï¼Œä¸¤ä¸ªç›¸å·® 128 bytes çš„åœ°å€å±äºç›¸åŒçš„ bankã€‚</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> ç”¨å…±äº«å†…å­˜æ¥å®ç°å—ï¼ˆblockï¼‰å†…çº¿ç¨‹é—´çš„é€šä¿¡ä»¥åŠç¼“å­˜é‡å¤çš„å¯¹å…¨å±€è®¿å­˜çš„è®¿é—®ï¼Œæ”¹å–„å…¨å±€å†…å­˜è®¿é—®æ¨¡å¼ï¼ˆçŸ©é˜µè½¬ç½®ï¼‰</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> Shared memory çš„å¸¦å®½å¾ˆé«˜ï¼Œé€šå¸¸å¤§äº 1TB/sï¼Œå®ƒæ²¡æœ‰åˆå¹¶è®¿é—®çš„é—®é¢˜ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„ bank å†²çªï¼Œä¸€ä¸ª SM å¯ä»¥åœ¨ 1 åˆ° 2 ä¸ªæ—¶é’Ÿå‘¨æœŸé‡Œæ¥å¤„ç†è®¿é—®æ¥è‡ªä¸åŒ bank é‡Œåœ°å€çš„è®¿å­˜è¯·æ±‚ã€‚ç›¸ååœ°ï¼Œå¦‚æœè¦è®¿é—®åœ°åœ°å€æ¥è‡ªç›¸åŒçš„ bankï¼Œåˆ™éœ€è¦æ›´å¤šçš„æ—¶é’Ÿå‘¨æœŸæ¥åºåˆ—åŒ–è®¿é—®ï¼ˆbank0ï¼Œbank1â€¦ï¼‰ï¼Œæ­¤æ—¶ç§°ä¸º bank å†²çªã€‚ä½†å¦‚æœè¦è®¿é—®çš„æ˜¯åŒä¸€ä¸ª bank é‡Œç›¸åŒçš„åœ°å€ï¼ˆmulticastï¼‰ï¼Œåˆ™æ­¤æ—¶ä¹Ÿä¸ä¼šæœ‰ bank å†²çªã€‚</p> 
<p><img src="https://images2.imgbox.com/0e/95/3DArV1fT_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/31/c3/rA3cuncP_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä»¥ä¸‹ä¸¤ç§æƒ…å†µæ²¡æœ‰ bank å†²çªã€‚æ³¨æ„ bank ä¸ä»£è¡¨æ˜¯åœ°å€ï¼Œçº¿ç¨‹ 0 è®¿é—® bank0 è¯´æ˜çº¿ç¨‹ 0 è®¿é—®çš„å†…å­˜åœ°å€åœ¨ç¬¬ä¸€åˆ—</p> 
<p><img src="https://images2.imgbox.com/87/7d/XsUbg9Bg_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä»¥ä¸‹åˆ†åˆ«æ˜¯ 2 è·¯å’Œ 16 è·¯ bank å†²çªçš„æƒ…å†µï¼š</p> 
<p><img src="https://images2.imgbox.com/7d/d0/dDzME3AM_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>å‡è®¾ shared memory æ˜¯ 32x32 å¤§å°ï¼Œä¸€ä¸ª warp çš„ 32 çº¿ç¨‹è®¿é—®åŒä¸€ä¸ª bankï¼ˆé¢œè‰²ç›¸åŒçš„ä¸€åˆ—ï¼‰ï¼Œæ­¤æ—¶å‘ç”Ÿäº† 32 è·¯ bank å†²çªï¼Œè¯¥æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼ŸæŠŠ shared memory æ·»åŠ ä¸€åˆ—å˜æˆ 32x33 å¤§å°ï¼Œåˆ™æ­¤æ—¶æ¯ä¸€åˆ—çš„åœ°å€å±äºä¸åŒçš„ bankï¼ˆé¢œè‰²ä¸ä¸€è‡´ï¼‰ï¼Œæ­¤æ—¶æ˜¯æ²¡æœ‰ bank å†²çªçš„ã€‚padding çš„å…ƒç´ æ°¸è¿œä¸ä¼šè¢«è®¿é—®ã€‚</p> 
<p><img src="https://images2.imgbox.com/b8/df/KqsKOJ6z_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/60/4d/STVhwBuW_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="4_warp_shuffle_445"></a>4. åŸå­/è§„çº¦æ“ä½œå’Œwarp shuffle</h3> 
<p>ä¹‹å‰çš„è¯¾ç¨‹æˆ‘ä»¬å­¦ä¹ äº† transform ç±»å‹çš„é—®é¢˜ï¼ˆæ•°ç›®è¾“å‡ºè§„æ¨¡å¤§ä½“ä¸€è‡´ï¼‰ï¼Œè¿™èŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ åŸå­/è§„çº¦æ“ä½œå’Œ warp shuffleã€‚ä»€ä¹ˆæ˜¯è§„çº¦æ“ä½œï¼Ÿæ±‚ä¸€ä¸ªæ•°ç»„çš„å’Œ/æœ€å¤§å€¼/æœ€å°å€¼ã€‚è¾“å…¥æ˜¯ N ä¸ªæ•°æ®ï¼Œè¾“å‡ºæ˜¯ 1 ä¸ªæ•°æ®ã€‚æˆ‘ä»¬éœ€è¦å›ç­”è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šæ¯ä¸ªçº¿ç¨‹è¯¥å¹²ä¸€ä»¶ä»€ä¹ˆäº‹æƒ…ï¼ˆthread strategyï¼‰ï¼Ÿtransform ç±»å‹çš„é—®é¢˜å¾ˆç›´è§‚ï¼Œæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹åšä¸€äº›è®¡ç®—ï¼ˆæ¯”å¦‚ï¼Œout = in * scaleï¼‰ã€‚è§„çº¦ç±»é—®é¢˜ï¼ˆreductionï¼‰åˆ™æ²¡æœ‰é‚£ä¹ˆçš„ç›´è§‚ã€‚</p> 
<p>å¼€å¯å’Œè¾“å…¥æ•°æ®è§„æ¨¡ä¸€æ ·å¤§è§„æ¨¡çš„çº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹åœ¨ä¸€ä¸ªå…¨å±€å˜é‡ä¸Šè¿›è¡Œç´¯åŠ ï¼Œä¼ªä»£ç å’Œæ±‡ç¼–å¦‚ä¸‹ï¼š</p> 
<pre><code class="prism language-cpp">c <span class="token operator">+=</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>


LD R2<span class="token punctuation">,</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
LD R1<span class="token punctuation">,</span>c
ADD R3<span class="token punctuation">,</span>R1<span class="token punctuation">,</span>R2
ST c<span class="token punctuation">,</span>R3
</code></pre> 
<p>æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹åœ°æ‰§è¡Œä¸Šé¢çš„æŒ‡ä»¤ï¼Œcuda ç¼–ç¨‹æ¨¡å‹å¹¶ä¸ä¿è¯çº¿ç¨‹æ‰§è¡Œçš„é¡ºåºï¼Œæœ€åçš„ç»“æœå¯èƒ½æ˜¯é”™è¯¯çš„ã€‚éœ€è¦ç”¨ <code>atomicAdd(&amp;c, a[i])</code> æ¥ç¡®ä¿æ­£ç¡®æ€§ï¼Œä¸Šé¢ 4~6 è¡Œçš„æŒ‡ä»¤ä¼šå˜æˆä¸€æ¡ä¸å¯åˆ†å‰²çš„æŒ‡ä»¤ï¼š</p> 
<pre><code class="prism language-cpp">RED<span class="token punctuation">.</span>E<span class="token punctuation">.</span>ADD<span class="token punctuation">.</span>F32<span class="token punctuation">.</span>FTZ<span class="token punctuation">.</span>RN<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>R2<span class="token punctuation">;</span>
</code></pre> 
<p>åŸå­æ“ä½œçš„å®ç°éœ€è¦ç”¨åˆ° L2 ç¼“å­˜ï¼Œå› ä¸ºæ­¤æ—¶çº¿ç¨‹ä¹‹é—´ä¸å†å¹¶å‘ï¼Œè€Œæ˜¯ç­‰ä¸€ä¸ªçº¿ç¨‹å…ˆæ‰§è¡Œä¸‰æ¡æŒ‡ä»¤å®Œäº†ä¹‹åå…¶ä»–çº¿ç¨‹æ‰ä¼šå¼€å§‹æ‰§è¡Œç›¸åŒçš„ä¸‰æ¡æŒ‡ä»¤ï¼Œæ‰€ä»¥ä¼šå¯¹æ€§èƒ½æœ‰å½±å“ã€‚åŸå­æ“ä½œæœ‰å¾ˆå¤šï¼Œæœ‰ <code>atomicMax/Min/Sub/Inc</code>â€¦ æ‰€æœ‰çš„åŸå­æ“ä½œéƒ½å¯ä»¥ç”¨ <code>atomicCAS</code> è¿™ä¸ªåŸå­æ“ä½œæ¥å®ç°ã€‚åœ¨ Pascal æ¶æ„ä»¥å‰ï¼Œ<code>atomicAdd</code> å‡½æ•°ä¸æ”¯æŒ double ç²¾åº¦çš„æµ®ç‚¹æ•°ï¼Œå¯ä»¥ç”¨ <code>atomicCAS</code> å‡½æ•°æ¥å®ç°æ”¯æŒ double ç²¾åº¦çš„ <code>atomicAdd</code> å‡½æ•°ã€‚ä½†æ˜¯è¿™ä¸ªç‰ˆæœ¬çš„å‡½æ•°è¦æ¯” Pascal ä»¥åŠæ›´é«˜æ¶æ„åŸç”Ÿæä¾›çš„ <code>atomicAdd</code> å‡½æ•°æ…¢å¾ˆå¤šï¼Œæœ‰å…´è¶£çš„è¯å¯ä»¥æ”¹ä¸‹è¿™ä»½ï¼ˆ<a href="https://github.com/HaohaoNJU/CenterPoint/blob/master/src/preprocess.cu#L94">https://github.com/HaohaoNJU/CenterPoint/blob/master/src/preprocess.cu#L94</a>ï¼‰ä»£ç çœ‹å¿«äº†å¤šå°‘ã€‚</p> 
<p><code>atomicAdd</code> å‡½æ•°çš„è¿”å›å€¼æ˜¯å…¶ç¬¬ä¸€å‚æ•°é‡Œçš„åŠ ä¹‹å‰çš„å€¼ï¼Œè¿™ä¸€ç‚¹å¯ä»¥ç”¨æ¥å¹¶è¡Œåœ°å†³å®šè¦å¤„ç†çš„æ•°æ®åœ¨é˜Ÿåˆ—çš„ä½ç½®ï¼š</p> 
<pre><code class="prism language-cpp"><span class="token keyword">int</span> index <span class="token operator">=</span> <span class="token function">atomicAdd</span><span class="token punctuation">(</span>order<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>åœ¨ä¸´æ—¶ buffer é‡Œé¢„ç•™ä¸€å®šçš„ç©ºé—´ï¼šæ¯ä¸ªçº¿ç¨‹ç‹¬è‡ªäº§ç”Ÿä¸€å®šé‡çš„æ•°æ®ï¼Œå¦‚ä½•å¹¶è¡Œåœ°å°†å®ƒä»¬æ”¶é›†åœ¨ä¸€ä¸ª buffer é‡Œï¼Ÿ</p> 
<pre><code class="prism language-cpp">buffer_ptr<span class="token operator">:</span> <span class="token operator">-&gt;</span><span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span>
buffer_idx<span class="token operator">:</span>       <span class="token operator">--</span><span class="token operator">-</span><span class="token operator">^</span>

<span class="token keyword">int</span> size <span class="token operator">=</span> var<span class="token punctuation">;</span>
<span class="token keyword">float</span> local_buffer<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span>   <span class="token comment">// äº§ç”Ÿä¸€æ‰¹å¤§å°æ˜¯ size æ•°æ®</span>
<span class="token keyword">int</span> offset <span class="token operator">=</span> <span class="token function">atomicAdd</span><span class="token punctuation">(</span>buffer_index<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// ä¹‹å‰æ•°æ®å­˜åœ¨ buffer_index è¿™ä¸ªä½ç½®å¤„</span>
<span class="token function">memcpy</span><span class="token punctuation">(</span>buffer_ptr <span class="token operator">+</span> offset<span class="token punctuation">,</span> local_buffer<span class="token punctuation">,</span> size <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>è¿™ä¸ªæ˜¯ç»å…¸çš„æµå‹ç¼©é—®é¢˜ï¼ˆstream compactionï¼‰ï¼š<a href="https://www.codenong.com/34059753/" rel="nofollow">CUDAæµå‹ç¼©ç®—æ³• | ç å†œå®¶å›­</a>ï¼Œ<code>atomicAdd</code> å¯èƒ½ä¸æ˜¯æœ€é«˜æ•ˆçš„å®ç°</p> 
<p>åŸå­æ“ä½œä¸èƒ½å®Œå…¨åˆ©ç”¨å†…å­˜å¸¦å®½ï¼Œæœ‰æŸæ€§èƒ½ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´é«˜æ•ˆçš„ç®—æ³•æ¥æ±‚è§£è§„çº¦é—®é¢˜ï¼Œå°½å¯èƒ½ç”¨åˆ°æ‰€æœ‰çš„çº¿ç¨‹ã€‚parallel reduction æ˜¯ä¸€ç§å¸¸è§çš„è§„çº¦çš„æ–¹å¼ï¼Œå®ƒé‡‡å–äº†ä¸€ç§æ ‘çŠ¶çš„æ–¹å¼ï¼š</p> 
<p><img src="https://images2.imgbox.com/1c/03/UinwFreH_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹å±‚çš„èŠ‚ç‚¹åœ¨è¿ç®—ä¹‹å‰éœ€è¦ä¿è¯ä¸Šå±‚çš„èŠ‚ç‚¹å·²ç»è®¡ç®—å®Œæ¯•ï¼Œéœ€è¦å…¨å±€çš„åŒæ­¥ã€‚å¯ä»¥é€šè¿‡å¼€å¯ä¸åŒçš„æ ¸å‡½æ•°æ¥å®ç°è¿™ç‚¹ï¼Œä¸€å±‚å¼€å¯ä¸€ä¸ªæ ¸å‡½æ•°ï¼Œä¸åŒçš„æ ¸å‡½æ•°å¤©ç„¶åœ°å¯ä»¥ä½œä¸ºä¸€ä¸ªå…¨å±€åœ°åŒæ­¥ç‚¹ï¼Œä½†æ˜¯å¼€å¯æ ¸å‡½æ•°ä¹Ÿæœ‰ overheadã€‚ä¹Ÿå¯ä»¥åœ¨æ¯ä¸ª block å±‚çº§ reduction è®¡ç®—çš„ç»“å°¾å¤„ä½¿ç”¨åŸå­æ“ä½œæ¥ç¡®ä¿åŒæ­¥ã€‚æˆ–è€…<a href="https://blog.csdn.net/yutianzuijin/article/details/8507355">å…³äºCUDAä¸­__threadfenceçš„ç†è§£-CSDNåšå®¢</a>å’Œåä½œç»„ï¼ˆcooperative groupsï¼ŒcudaLaunchCooperativeKernelï¼‰</p> 
<p>Sweep reductionï¼š</p> 
<pre><code class="prism language-cpp"><span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> s <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> s<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">;</span> s<span class="token operator">&gt;&gt;=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> s<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        sdata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> sdata<span class="token punctuation">[</span>tid<span class="token operator">+</span>s<span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">// å³åŠéƒ¨åˆ†åŠ åˆ°å·¦åŠéƒ¨åˆ†</span>
    <span class="token punctuation">}</span>
    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// åœ¨ if æ¡ä»¶è¯­å¥çš„å¤–é¢</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3e/fe/yNSWtHml_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æœ€ç»ˆå¾—åˆ°çš„æ˜¯ä¸€ä¸ª block é‡Œé¢æ‰€æœ‰å…ƒç´ çš„å±€éƒ¨å’Œã€‚ä¹Ÿå¯ä»¥ç›¸é‚»å…ƒç´ ç›¸åŠ æ±‚å’Œçš„æ–¹å¼ï¼Œä½†æ˜¯ sweep çš„è®¿é—®æ–¹å¼å¯ä»¥é¿å… bank å†²çªçš„é—®é¢˜ï¼Œä¹Ÿå¯ä»¥è§„é¿æµ®ç‚¹æ•°ç›¸åŠ æ²¡æœ‰äº¤æ¢å¾‹çš„é—®é¢˜ï¼ˆå¤§æ•°åƒå°æ•°ï¼‰ã€‚</p> 
<p>å¸Œæœ›è®¾è®¡çš„æ ¸å‡½æ•°å¯ä»¥å¤„ç†ä»»ä½•è§„æ¨¡çš„è¾“å…¥æ•°æ®ï¼Œä¸€ä¸ª block é‡Œå¼€å¯çš„çº¿ç¨‹æ•°ç›®ä¸å—è¾“å…¥æ•°æ®çš„å½±å“-&gt;grid-stride loop</p> 
<pre><code class="prism language-cpp"><span class="token comment">// gdata[0...N-1]   | | | | | | | | | | | | | | | | | | | | | | | | | | | |...</span>
<span class="token comment">//                  |grid-width stride|grid-width stride|grid-width stride|...</span>
<span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token keyword">while</span><span class="token punctuation">(</span>idx <span class="token operator">&lt;</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    sdata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> gdata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>   <span class="token comment">// ä¸€ä¸ª warp é‡Œæ‰€æœ‰çš„çº¿ç¨‹éƒ½åŠ ä¸Š</span>
    idx <span class="token operator">+=</span> gridDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>  <span class="token comment">// grid width, å¯ä»¥å°äºï¼Œç­‰äºæˆ–å¤§äºè¾“å…¥æ•°æ®çš„è§„æ¨¡ N</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>ä¸€ä¸ªå®Œæ•´çš„ kernel å‡½æ•°ï¼š</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> gdata<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> out<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    __shared__ <span class="token keyword">float</span> sdata<span class="token punctuation">[</span>BLOCK_SIZE<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    sdata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
    size_t idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>

    <span class="token keyword">while</span><span class="token punctuation">(</span>idx <span class="token operator">&lt;</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span> <span class="token comment">// grid stride loop to load data</span>
        sdata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> gdata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
        idx <span class="token operator">+=</span> gridDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> s <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> s<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">;</span> s<span class="token operator">&gt;=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> s<span class="token punctuation">)</span> sdata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> sdata<span class="token punctuation">[</span>tid<span class="token operator">+</span>s<span class="token punctuation">]</span><span class="token punctuation">;</span>   <span class="token comment">// parallel sweep reduction</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> out<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> sdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>   <span class="token comment">// è¿™é‡Œåªæ˜¯ä¸€ä¸ª block é‡Œé¢çš„å±€éƒ¨å’Œ</span>
    <span class="token comment">// if(tid == 0) atomicAdd(out, sdata[0]);  // è¿™æ ·å¯ä»¥é¿å…å†å¼€å¯ä¸€ä¸ª kernel</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>Warp shuffleï¼š</p> 
<p>åˆ©ç”¨å…±äº«å†…å­˜ shared memory å¯ä»¥å®ç° block å†…çš„çº¿ç¨‹ä¹‹é—´çš„é€šä¿¡ï¼ŒCUDA 9.0 ä¹‹åå¯ä»¥ä½¿ç”¨å¦å¤–ä¸€ç§ä¸ç”¨åˆ° shared memory æ›´é«˜æ•ˆçš„é€šä¿¡æœºåˆ¶ï¼šwarp shuffleã€‚æ˜¯ä¸€ä¸ª warp é‡Œçš„çº¿ç¨‹æŸä¹‹é—´çš„é€šä¿¡æœºåˆ¶ï¼Œæ¯”å¦‚ shared memory æ›´ç»†ç²’åº¦ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> __shfl_sync()ï¼šæ‹·è´æ¥è‡ªä»»æ„ lane id(0~31) çº¿ç¨‹é‡Œçš„å€¼</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> __shfl_xor_sync()ï¼šæ‹·è´æ¥è‡ªä¸€ä¸ªè®¡ç®—å‡ºæ¥çš„ lane id(0~31) çº¿ç¨‹é‡Œçš„å€¼</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> __shfl_up_sync()ï¼šæ‹·è´æ¥è‡ªæœ‰ä¸€å®šåç§»é‡ lane id æ›´å°çš„çº¿ç¨‹é‡Œçš„å€¼</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> __sync_down_sync()ï¼šæ‹·è´æ¥è‡ªæœ‰ä¸€å®šåç§»é‡ lane id æ›´å¤§çš„çº¿ç¨‹é‡Œçš„å€¼</p> 
<p>æºçº¿ç¨‹å’Œç›®æ ‡çº¿ç¨‹å¿…é¡»å‚ä¸è®¡ç®—ï¼ˆä¸èƒ½æœ‰ä¸€ä¸ªåœ¨ if æ¡ä»¶è¯­å¥é‡Œï¼‰ï¼Œå‚æ•° mask åŒæ¥ä»£è¡¨å“ªäº›çº¿ç¨‹éœ€è¦å‚ä¸è®¡ç®—ã€‚</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">reduce_ws</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> gdata<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> out<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    __shared__ <span class="token keyword">float</span> sdata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">float</span> val <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>   <span class="token comment">// ç”¨æ¥ä¿å­˜ç´¯åŠ ç»“æœçš„æ˜¯ä¸€ä¸ªä¸´æ—¶å˜é‡ï¼Œè€Œä¸æ˜¯ shared memory</span>
    <span class="token keyword">unsigned</span> mask <span class="token operator">=</span> <span class="token number">0xFFFFFFFFU</span><span class="token punctuation">;</span>   <span class="token comment">// 32 ä¸ª 1 ä»£è¡¨ä¸€ä¸ª warp é‡Œçš„ 32 ä¸ªçº¿ç¨‹å…¨éƒ½å‚ä¸è®¡ç®—</span>
    <span class="token keyword">int</span> lane   <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">%</span> warpSize<span class="token punctuation">;</span>  <span class="token comment">// å½“å‰çº¿ç¨‹æ˜¯ warp å†…éƒ¨çš„å“ªä¸ªçº¿ç¨‹</span>
    <span class="token keyword">int</span> warpId <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">/</span> warpSize<span class="token punctuation">;</span>  <span class="token comment">// å½“å‰çº¿ç¨‹æ˜¯å±äºå“ªä¸€ä¸ª warp</span>
    <span class="token keyword">while</span><span class="token punctuation">(</span>idx <span class="token operator">&lt;</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>    <span class="token comment">// grid stride loop to load gdata</span>
        val <span class="token operator">+=</span> gdata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
        idx <span class="token operator">+=</span> gridDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// 1st warp-shuffle reductionï¼Œæ¯ä¸ª warp å†…éƒ¨æ±‚å’Œ</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> warpSize<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> offset<span class="token operator">&gt;</span><span class="token number">2</span><span class="token punctuation">;</span> offset<span class="token operator">&gt;&gt;=</span><span class="token number">1</span><span class="token punctuation">)</span>
        val <span class="token operator">+=</span> <span class="token function">__shfl_down_sync</span><span class="token punctuation">(</span>mask<span class="token punctuation">,</span> val<span class="token punctuation">,</span> offset<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// ç¬¬ä¸€è½®è¿­ä»£</span>
    <span class="token comment">// æŠŠçº¿ç¨‹å·ä¸º 16 çš„ val å€¼åŠ åˆ°çº¿ç¨‹å·ä¸º 0 çš„ val å€¼ä¸Šï¼Œç»“æœè®°å½•åœ¨çº¿ç¨‹å·æ˜¯ 0 çš„ val å€¼é‡Œ</span>
    <span class="token comment">// æŠŠçº¿ç¨‹å·ä¸º 17 çš„ val å€¼åŠ åˆ°çº¿ç¨‹å·ä¸º 1 çš„ val å€¼ä¸Šï¼Œç»“æœè®°å½•åœ¨çº¿ç¨‹å·æ˜¯ 1 çš„ val å€¼é‡Œ</span>
    <span class="token comment">// ç¬¬äºŒè½®è¿­ä»£</span>
    <span class="token comment">// æŠŠçº¿ç¨‹å·ä¸º 8 çš„ val å€¼åŠ åˆ°çº¿ç¨‹å·ä¸º 0 çš„ val å€¼ä¸Šï¼Œç»“æœè®°å½•åœ¨çº¿ç¨‹å·æ˜¯ 0 çš„ val å€¼é‡Œ</span>
    <span class="token comment">// æŠŠçº¿ç¨‹å·ä¸º 9 çš„ val å€¼åŠ åˆ°çº¿ç¨‹å·ä¸º 1 çš„ val å€¼ä¸Šï¼Œç»“æœè®°å½•åœ¨çº¿ç¨‹å·æ˜¯ 1 çš„ val å€¼é‡Œ</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>lane <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> sdata<span class="token punctuation">[</span>warpId<span class="token punctuation">]</span> <span class="token operator">=</span> val<span class="token punctuation">;</span>  <span class="token comment">// æ¯ä¸ª warp æœ‰ä¸€ä¸ªæ±‚å’Œçš„ç»“æœï¼Œæœ€å¤š 32 ä¸ª warp</span>
    <span class="token comment">// å†…éƒ¨æ±‚å’Œçš„ç»“æœç´¯åŠ åˆ°çº¿ç¨‹å·æ˜¯ 0 çš„çº¿ç¨‹çš„ val å€¼é‡Œï¼Œè¿™æ­¥æ˜¯æŠŠæ”¾åˆ° shared memory é‡Œ</span>
    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// ä¹‹ååªåœ¨ç¬¬ä¸€ä¸ª warp é‡Œè¿›è¡Œæ±‚å’Œå³å¯</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>warpId <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token comment">// å¦‚æœ warp å­˜åœ¨ï¼Œåˆ™æŠŠæ•°æ®ä» shared memory é‡Œå†è¯»å–å‡ºæ¥</span>
        <span class="token comment">// æ¯”å¦‚ blockDim.x = 1024ï¼Œtid(0~1023)ï¼Œä¸€å…±æœ‰ 32 ä¸ª warp</span>
        val <span class="token operator">=</span> <span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">/</span> warpSize<span class="token punctuation">)</span> <span class="token operator">?</span> sdata<span class="token punctuation">[</span>lane<span class="token punctuation">]</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token comment">// æœ€åå† warp ä¹‹é—´å†åšä¸€æ¬¡æ±‚å’Œæ“ä½œ</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> warpSize <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span>
            val <span class="token operator">+=</span> <span class="token function">__shfl_down_sync</span><span class="token punctuation">(</span>mask<span class="token punctuation">,</span> val<span class="token punctuation">,</span> offset<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token function">atomicAdd</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>Warp shuffle çš„ä¼˜ç‚¹ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> å¯ä»¥å‡è½»æˆ–è€…æ¶ˆé™¤å¯¹ shared memory çš„ä½¿ç”¨ï¼Œè®©æ ¸å‡½æ•°çš„ occupancy ä¸å†å—åˆ° shared memory çš„é™åˆ¶</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> ä»æœºå™¨æ‰§è¡Œçš„æŒ‡ä»¤è§’åº¦çœ‹ï¼ŒæŠŠä¹‹å‰å¯¹ shared memory çš„è¯»å†™çš„ 2 æ¡æŒ‡ä»¤å˜æˆäº†ä¸€æ¡æŒ‡ä»¤</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> å‡å°‘äº†æ˜¾å¼åŒæ­¥çš„æ¬¡æ•°ï¼Œä¹Ÿå°±æ˜¯å¯¹ __syncthreads() è¯­å¥çš„è°ƒç”¨æ¬¡æ•°ï¼Œæå‡äº†æ€§èƒ½</p> 
<p>å…¶å®ƒä½¿ç”¨åœºæ™¯ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> Warp shuffle è¿˜å¯ä»¥ç”¨æ¥æ±‚ warp çº§åˆ«çš„å‰ç¼€å’Œï¼ˆprefix-sumï¼‰ä»¥åŠæ’åºï¼ˆsortï¼‰ï¼Œ<a href="https://zhuanlan.zhihu.com/p/423992093" rel="nofollow">CUDAé«˜æ€§èƒ½è®¡ç®—ç»å…¸é—®é¢˜ï¼ˆäºŒï¼‰â€”â€” å‰ç¼€å’Œï¼ˆPrefix Sumï¼‰</a></p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> å‡è½» <code>atomicAdd</code> ä¹‹ç±»çš„åŸå­æ“ä½œå¯¹ L2 ç¼“å­˜ç³»ç»Ÿçš„å‹åŠ›ã€‚ä¸€ä¸ª warp é‡Œçš„ 32 ä¸ªçº¿ç¨‹éƒ½è°ƒç”¨ä¸€æ¬¡ <code>atomicAdd</code> æ¥è¿›è¡Œæ±‚å’Œæ“ä½œã€‚warp shuffle å…ˆåœ¨ä¸€ä¸ª warp é‡Œé¢æ±‚å’Œï¼Œç„¶åè°ƒç”¨ä¸€æ¬¡ <code>atomicAdd</code>ï¼ˆatomic aggregationï¼‰</p> 
<p>å¯¹äº for å¾ªç¯ï¼Œgcc é‡Œçš„ #pragma unroll N è¯­å¥å¯¹äº nvcc ç¼–è¯‘å™¨åŒæ ·æœ‰ä¼˜åŒ–æ•ˆæœï¼Œæœ¬è´¨æ˜¯å¾ªç¯å±•å¼€ä¹‹åå¯ä»¥å¯¹æŒ‡ä»¤è¿›è¡Œé‡æ–°æ’åºï¼Œé™ä½å¯¹è®¿å­˜æŒ‡ä»¤çš„ä¾èµ–æ€§ã€‚å…·ä½“è®¨è®ºå¯è§<a href="https://blog.csdn.net/weixin_44444450/article/details/104469278">å¾ªç¯å±•å¼€</a>ã€‚ä¸ºäº†æ–¹ä¾¿ç¼–è¯‘å™¨åšè¿™ä»¶äº‹æƒ…ï¼Œå¾ªç¯çš„æ¬¡æ•°æœ€å¥½æ˜¯åœ¨ç¼–è¯‘æœŸé—´å°±ç¡®å®šä¸‹æ¥ã€‚</p> 
<p>Mask å‚æ•°å’Œ if æ¡ä»¶è¯­å¥çš„åŒºåˆ«ï¼šPascal ä»¥åŠä¹‹å‰çš„æ¶æ„ä¸­ï¼Œif æ¡ä»¶è¯­å¥ä¹‹åï¼Œdivergent çš„ warp éœ€è¦é‡æ–° reconvergeï¼Œä½†è¿™æœ‰ç‚¹æœ‰æŸæ€§èƒ½ã€‚ä» Volta æ¶æ„å¼€å§‹ï¼Œå¦‚æœæœ‰æ€§èƒ½çš„åŸå› ä¸”ä¸å½±å“ç¨‹åºçš„æ­£ç¡®æ€§ï¼Œé‚£ä¹ˆå³ä½¿ if æ¡ä»¶è¯­å¥ç»“æŸï¼Œ warp ä»ç„¶å¯ä»¥ä¿æŒ divergent çš„çŠ¶æ€ï¼Œè™½ç„¶çœ‹èµ·æ¥åº”è¯¥æ˜¯ reconverge äº†ã€‚ä½†æ˜¯ç¼–è¯‘å™¨æ²¡æœ‰ä¹‰åŠ¡ä¿è¯è¿™ä¸€ç‚¹ã€‚æ³¨æ„æ˜¯å¯ä»¥ï¼Œå…·ä½“æ˜¯ä¸æ˜¯ divergent çš„çŠ¶æ€æ˜¯ä¸ªç°è‰²åœ°å¸¦ã€‚ä½†æœ‰æ—¶å€™éœ€è¦ convergence æ¥ç¡®ä¿ç¨‹åºçš„æ­£ç¡®æ€§ï¼Œæ¯”å¦‚ warp shuffle æ“ä½œã€‚æ–°çš„ CUDA(cuda 9.0+) ç¼–ç¨‹æ¨¡å‹æœ‰äº† mask å‚æ•°ã€‚å®ƒå‘Šè¯‰ç¼–è¯‘å™¨ï¼Œä¸ç®¡ warp çš„çŠ¶æ€æ˜¯ä¸æ˜¯ convergent çš„ï¼Œå¦‚æœ warp æ˜¯ divergent çš„ï¼Œå¹¶ä¸”ä»£ç ä¸åœ¨ä»»ä½•é˜»æ­¢ convergent çš„ if æ¡ä»¶è¯­å¥é‡Œé¢ï¼Œé‚£ä¹ˆå¿…é¡»å›åˆ° convergent çš„çŠ¶æ€æ¥ç¡®ä¿å°†è¦æ‰§è¡Œçš„æŒ‡ä»¤æ˜¯æœ‰æ•ˆä¸”èƒ½äº§ç”Ÿæ­£ç¡®çš„ç»“æœã€‚æ³¨æ„åªæ˜¯ mask å‚æ•°æŒ‡å®šçš„çº¿ç¨‹ï¼ˆæ¯”å¦‚ 16ï¼‰éœ€è¦ reconvergentï¼Œå…¶ä»–æœªæŒ‡å®šçš„çº¿ç¨‹æ˜¯ä»€ä¹ˆçŠ¶ï¼ˆconvergent è¿˜æ˜¯ divergentï¼‰è¿˜æ˜¯æœªçŸ¥çš„ã€‚</p> 
<p><a href="https://forums.developer.nvidia.com/t/what-does-mask-mean-in-warp-shuffle-functions-shfl-sync/67697" rel="nofollow">What does mask mean in warp shuffle functions(__shfl_sync)</a></p> 
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="nofollow">CUDA C++ Programming Guide</a></p> 
<pre><code class="prism language-shell">supported by devices of compute capability <span class="token number">5.0</span> or higher.
Deprecation Notice: __shfl, __shfl_up, __shfl_down, and __shfl_xor have been deprecated <span class="token keyword">in</span> CUDA <span class="token number">9.0</span> <span class="token keyword">for</span> all devices.
Removal Notice: When targeting devices with compute capability <span class="token number">7</span>.x or higher, __shfl, __shfl_up, __shfl_down, and __shfl_xor are no longer available and their <span class="token function">sync</span> variants should be used instead.
</code></pre> 
<h3><a id="5_CUDAManaged_Memory_628"></a>5. CUDAç»Ÿä¸€å†…å­˜(Managed Memory)</h3> 
<p>è¿™èŠ‚è¯¾æˆ‘ä»¬å­¦ä¹  cuda çš„ç»Ÿä¸€å†…å­˜ï¼ˆmanaged memoryï¼‰ï¼šç›®çš„æ˜¯ä¸ºäº†ç®€åŒ–ç¼–ç¨‹ï¼Œä¸ä¸€å®šèƒ½æé«˜æ€§èƒ½ã€‚</p> 
<p>cuda ç¼–ç¨‹æ¨¡å‹éœ€è¦ä¸‰æ­¥èµ°ç­–ç•¥ï¼š1. ä» cpu æ‹·æ•°æ®åˆ° gpu 2. åœ¨ gpu ä¸Šæ‰§è¡Œè®¡ç®— 3. æŠŠç»“æœä» gpu æ‹·å› cpuã€‚åˆ©ç”¨ managed memoryï¼Œç¨‹åºå‘˜å¯ä»¥ä¸ç”¨æ˜¾å¼åœ°åš 1 å’Œ 3ï¼Œcudaruntime è‡ªåŠ¨å®Œæˆè¿™ä»¶äº‹ã€‚Managed Memory ä¸æ˜¯ä¸€å¼€å§‹å°±æœ‰çš„ç‰¹æ€§ï¼Œæ˜¯ä» 2012-2013/cuda 6.0/kepler æ¶æ„å¼€å§‹æ‰æœ‰çš„ç‰¹æ€§ã€‚</p> 
<p>åªæœ‰ä¸€ä¸ªæŒ‡é’ˆï¼Œæ•°æ®åªæœ‰ä¸€ä»½ï¼Œé€šè¿‡ data migration æœºåˆ¶æ¥å®ç°ç»Ÿä¸€å†…å­˜ã€‚å“ªä¸ªå¤„ç†å™¨éœ€è¦æ•°æ®ï¼Œå°±æŠŠæ•°æ®æ¬åˆ°å“ªè¾¹ï¼Œå¤©ç„¶åœ°ä¿è¯äº†æ•°æ®ä¸€è‡´æ€§ã€‚æ²¡æœ‰ data race çš„æƒ…å†µï¼ŒåŒä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…æ•°æ®åªèƒ½è¢«ä¸€ä¸ªå¤„ç†å™¨è®¿é—®ã€‚</p> 
<p>ä» pascal æ¶æ„/cuda 8 å¼€å§‹ï¼Œç»Ÿä¸€å†…å­˜æœ‰äº† oversubscription/demand paging çš„æœºåˆ¶ï¼Œå¯ä»¥ç”¨ cudaMallocManaged åˆ†é…è¶…è¿‡ GPU æ˜¾å­˜å¤§å°çš„æ•°æ®é‡ï¼ˆæ¯”å¦‚å¦‚æœæ˜¾å­˜æ˜¯ 16Gï¼Œé‚£ cudaMalloc æœ€å¤šåªèƒ½åˆ†é… 16 G çš„æ•°æ®é‡ï¼‰ï¼Œä½†æ˜¯ä¹Ÿä¸èƒ½è¶…è¿‡ system memory çš„å¤§å°ã€‚ä¹‹å‰å­¦ä¹ çš„åŸå­æ“ä½œå¯¹äºç»Ÿä¸€å†…å­˜ä¹Ÿé€‚ç”¨ï¼Œæä¾›äº†è·¨å¤„ç†å™¨çš„èƒ½åŠ›ï¼ˆatomicAdd_systemï¼‰ã€‚</p> 
<pre><code class="prism language-cpp"><span class="token comment">// cpu ä»£ç </span>
<span class="token keyword">void</span> <span class="token function">sortfile</span><span class="token punctuation">(</span>FILE<span class="token operator">*</span> fp<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
    data <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">fread</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> N<span class="token punctuation">,</span> fp<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">qsort</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> compare<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">use_data</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">free</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">// ä¸ä½¿ç”¨ç»Ÿä¸€å†…å­˜çš„ cuda ä»£ç </span>
<span class="token keyword">void</span> <span class="token function">sortfile</span><span class="token punctuation">(</span>FILE<span class="token operator">*</span> fp<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">,</span> <span class="token operator">*</span>d_data<span class="token punctuation">;</span>
    data <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_data<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">fread</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> N<span class="token punctuation">,</span> fp<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_data<span class="token punctuation">,</span> data<span class="token punctuation">,</span> N<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 1</span>
    qsort<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_data<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 2</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> d_data<span class="token punctuation">,</span> N<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 3, åŒæ­¥æ“ä½œ</span>

    <span class="token function">use_data</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">free</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">// ä½¿ç”¨ç»Ÿä¸€å†…å­˜çš„ cuda ä»£ç </span>
<span class="token keyword">void</span> <span class="token function">sortfile</span><span class="token punctuation">(</span>FILE<span class="token operator">*</span> fp<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
    <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">fread</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> N<span class="token punctuation">,</span> fp<span class="token punctuation">)</span><span class="token punctuation">;</span>
    qsort<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">// æ¯”èµ· cpu ä»£ç å°±å¤šäº†è¿™ä¹ˆä¸€è¡Œï¼Œå› ä¸º gpu å’Œ gpu æ˜¯å¼‚æ­¥æ‰§è¡Œçš„</span>

    <span class="token function">use_data</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>å’Œ malloc ä¸€æ ·ï¼ŒcudaMallocï¼ŒcudaMallocManaged åªè´Ÿè´£ç”³è¯·ï¼Œä¸è´Ÿè´£åˆå§‹åŒ–ï¼š</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">setValue</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> ptr<span class="token punctuation">,</span> <span class="token keyword">int</span> index<span class="token punctuation">,</span> <span class="token keyword">int</span> val<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    ptr<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> val<span class="token punctuation">;</span>
<span class="token punctuation">}</span>


<span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
    <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// ç”³è¯·ç»Ÿä¸€å†…å­˜</span>

    <span class="token function">memset</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// åœ¨ CPU ç«¯è®¿é—®æ‰€æœ‰çš„æ•°æ®</span>

    setValue<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> size<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// åœ¨ GPU ç«¯è®¿é—®æŸä¸€ä¸ªæ•°æ®</span>
    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">useData</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">cudaFree</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>ä¸‹å›¾å±•ç¤ºç»Ÿä¸€å†…å­˜çš„å·¥ä½œæœºåˆ¶ï¼Œé€šè¿‡ç¼ºé¡µä¸­æ–­ï¼ˆpage faultï¼‰æ¥å®ç°ï¼Œpage fault åœ¨ cpu å’Œ gpu ä¸Šéƒ½å¯ä»¥è§¦å‘</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> cudaMallocManaged() é¢„ç•™äº†ä¸€äº›å†…å­˜ï¼Œä½†æ­¤æ—¶è¿˜æ²¡æœ‰é¡µåˆ†é…çš„æ“ä½œï¼ˆbring allocation into existenceï¼‰</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> è°ƒç”¨ memset çš„æ—¶å€™ä¼šå‘ç”Ÿç¼ºé¡µä¸­æ–­ï¼ˆ[page fault]ï¼‰ï¼Œæ­¤æ—¶æ•°æ®éƒ½åœ¨ CPU çš„ system memory é‡Œï¼Œå·²ç»åˆå§‹åŒ–</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> setValue ä¼šåŒæ ·å‡ºå‘ page faultï¼Œè¿™ä¸ªä¸­æ–­ä¼šæŠŠç”¨åˆ°çš„æ•°æ®æ‰€åœ¨çš„ page é€šè¿‡ bus æ¬åˆ° GPU é‡Œï¼ˆdata migrationï¼‰</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> ä¹Ÿå¯ä»¥å…ˆåœ¨ GPU ä¸Šåˆ†é…å¥½æ‰€æœ‰çš„é¡µï¼Œç„¶ååœ¨ CPU ç«¯ç”¨åˆ°çš„æ—¶å€™è§¦å‘ page fault</p> 
<p><img src="https://images2.imgbox.com/b3/0f/HOD14rbH_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æ³¨æ„å’Œ pinned memory çš„åŒºåˆ«ï¼špinned memory ä¸€ç›´æ˜¯ host memoryï¼Œåªä¸è¿‡æœ‰æ—¶å€™å¯ä»¥è¢« gpu è®¿é—®åˆ°ã€‚</p> 
<p>cudaMallocManaged åˆ†é…çš„å†…å­˜ï¼Œå¦‚æœä¸€ä¼šå„¿åœ¨ gpu ç«¯è®¿é—®ï¼Œä¸€ä¼šå„¿åœ¨ cpu ç«¯è®¿é—®ï¼Œæ€§èƒ½ä¼šå¾ˆå·®ï¼ˆé¢‘ç¹è§¦å‘ page faultï¼‰</p> 
<p>å¦‚æœç”¨ cudaMallocManaged åˆ†é…ä¸€æ®µå†…å­˜ï¼Œä½†æ˜¯ä»æ¥ä¸åœ¨ gpu ç«¯å»è®¿é—®å®ƒã€‚è¿™æ®µå†…å­˜ç¬¬ä¸€æ¬¡åœ¨ cpu ä¸Šè®¿é—®çš„æ—¶å€™ï¼Œå’Œç›´æ¥ç”¨ malloc åˆ†é…çš„å†…å­˜ç›¸æ¯”ï¼Œè¿˜æ˜¯ä¼šæœ‰ç•¥å¾®æ€§èƒ½ä¸Šçš„å·®è·ï¼Œè¿™ç‚¹å’Œ cpu çš„ç¼“å­˜æœºåˆ¶æœ‰å…³ã€‚</p> 
<p>å’Œ GPUDirect RDMA çš„åŒºåˆ«ï¼šGPUDirect RDMA å’Œç»Ÿä¸€å†…å­˜æ²¡æœ‰å…³ç³»ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯åœ¨ cpu é‡Œåˆ†é…ä¸€æ®µ bufferï¼Œè¿™æ®µ buffer å¯ä»¥è¢«ä¸€äº›ç¬¬ä¸‰æ–¹è®¾å¤‡ï¼ˆæ¯”å¦‚ç½‘å¡ï¼‰ç›´æ¥è®¿é—®ï¼Œè€Œä¸éœ€è¦ç»è¿‡ system memoryã€‚è¿™æ®µ buffer ä¸æ˜¯ç”±ç¨‹åºå‘˜æ‰‹åŠ¨åˆ†é…çš„ã€‚</p> 
<p>åœ¨ Pascal æ¶æ„ä»¥å‰ï¼Œæˆ–è€…åœ¨ windows æ“ä½œç³»ç»Ÿä¸Šï¼Œæ²¡æœ‰æŒ‰éœ€æ¬ç§»ï¼ˆon-demand migrationï¼‰ï¼Œè®¤è´­è¶…é¢ï¼ˆoversubscriptionï¼‰ï¼Œå¹¶å‘è®¿é—®ï¼ˆconcurrent accessï¼‰è¿™äº›æœºåˆ¶ã€‚cudaMallocManaged åˆ†é…çš„å†…å­˜ä¼šåœ¨ kernel å¯åŠ¨çš„æ—¶å€™å…¨éƒ¨æ¬åˆ° GPU ä¸Šï¼ˆå³ä½¿ kernel ç”¨ä¸åˆ°ï¼‰ã€‚ç„¶ååœ¨ kernel å‡½æ•°ç»“æŸçš„æ—¶å€™ï¼Œå†é€šè¿‡è°ƒç”¨ cudaDeviceSynchronize() æ¥ä½¿å¾—æ•°æ®åˆå¯ä»¥åœ¨ CPU ç«¯è®¿é—®ï¼Œå¦‚æœæ²¡æœ‰ä¼šæŠ¥ segmentation faultã€‚åœ¨ Pascal æ¶æ„ä¹‹åä¸å†è°ƒç”¨ cudaDeviceSynchronize() çš„è¯ä¸ä¼š segmentation faultï¼Œè™½ç„¶ç¨‹åºç»“æœä¸ä¸€å®šæ­£ç¡®ã€‚</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">mykernel</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token char">'g'</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
    <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    mykernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// æ³¨æ„è¿™é‡Œæ²¡æœ‰è°ƒç”¨ cudaDeviceSynchronize()</span>
    data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token char">'c'</span><span class="token punctuation">;</span>   <span class="token comment">// pascal æ¶æ„ä¹‹å‰ä¼šæŠ¥ segmentation faultï¼Œpascal æ¶æ„ä¹‹åä¸ä¼šï¼Œä½†ä¸ç¡®ä¿è®¿é—®é¡ºåº</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// data[0] å’Œ data[1] çš„è®¿é—®é¡ºåºä¸ç¡®å®š</span>
<span class="token punctuation">}</span>
</code></pre> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">mykernel</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> addr<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token function">atomicAdd_system</span><span class="token punctuation">(</span>addr<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// å®ç°å¤šä¸ª gpu ä¹‹é—´çš„åŸå­æ“ä½œï¼Œpascal æ¶æ„å¼€å§‹æ‰æ”¯æŒ</span>
<span class="token punctuation">}</span>

<span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span><span class="token operator">*</span> addr<span class="token punctuation">;</span>
    <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span>addr<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token operator">*</span>addr <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    
    mykernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>addr<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// cpu atomic</span>
    <span class="token function">__sync_fetch_and_add</span><span class="token punctuation">(</span>addr<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>ä»¥ä¸‹ä»£ç éªŒè¯äº† Pascal æ¶æ„ä¹‹åçš„ oversubscription çš„ç‰¹æ€§ï¼š</p> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token comment">// å‡è®¾ GPU æ˜¾å­˜ä¸€å…± 16G</span>
    <span class="token comment">// åˆ©ç”¨ cudaMallocManaged å¯ä»¥åˆ†é… 64G çš„å†…å­˜</span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
    size_t size <span class="token operator">=</span> <span class="token number">64ULL</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">;</span>  <span class="token comment">// æ³¨æ„ size çš„ç±»å‹æ˜¯ size_t</span>
    <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>æ³¨æ„ä»¥ä¸Šè®¨è®ºä¸é€‚ç”¨äº jetson ç³»ç»Ÿçš„ SoC ä¸Šï¼Œåœ¨ jetson ç³»ç»Ÿä¸Šï¼Œhost å’Œ device memory åœ¨ç‰©ç†ä¸Šæ˜¯ä¸€ä¸ªä¸œè¥¿ã€‚æ‰€æœ‰å¦‚æœç¨‹åºå‘˜æ˜¯ä½¿ç”¨ cudaMallocManaged åˆ†é…çš„å†…å­˜ï¼Œè®¿é—®çš„æ—¶å€™æ˜¯ä¸ä¼šè§¦å‘ç¼ºé¡µä¸­æ–­ï¼ˆæ•°æ®æ¬ç§»ï¼‰çš„ï¼Œæ‰€ä»¥ä¹Ÿä¸ä¼šæœ‰ä»»ä½•çš„æ€§èƒ½æŸå¤±ï¼Œä¸ç®¡åœ¨ CPU ç«¯è¿˜æ˜¯ GPU ç«¯ã€‚å¦‚æœåœ¨ jetson ä¸Šä½¿ç”¨æ™®é€šçš„ malloc å’Œ cudaMalloc/cudaMemcpy æ¥æ“ä½œçš„è¯ï¼Œé‚£ä¹ˆåœ¨æ•´ä¸ª dram é‡Œæœ‰ä¸¤å—åŒºåŸŸä¿æŒç€ç›¸åŒçš„æ•°æ®ï¼Œå®ƒä»¬åˆ†åˆ«ç”±å„è‡ªçš„æŒ‡é’ˆï¼ˆdevice pointer/host pointerï¼‰æ‰èƒ½è®¿é—®åˆ°ï¼Œè¿™æ—¶å€™å°±æ²¡æœ‰é«˜æ•ˆåˆ©ç”¨å†…å­˜ã€‚</p> 
<p>ç»Ÿä¸€å†…å­˜ä½¿ç”¨çš„åœºæ™¯</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> æ·±æ‹·è´ï¼ˆdeep copyï¼‰</p> 
<pre><code class="prism language-cpp"><span class="token keyword">struct</span> <span class="token class-name">dataElem</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> key<span class="token punctuation">;</span>
    <span class="token keyword">int</span> len<span class="token punctuation">;</span>
    <span class="token keyword">char</span><span class="token operator">*</span> name<span class="token punctuation">;</span> <span class="token comment">// æŒ‡å‘ä¸€ä¸ª bufferï¼Œchar buffer[len]</span>
<span class="token punctuation">}</span>
<span class="token comment">// ä¸ç”¨ç»Ÿä¸€å†…å­˜çš„ä»£ç </span>
<span class="token keyword">void</span> <span class="token function">launch</span><span class="token punctuation">(</span>dataElem<span class="token operator">*</span> elem<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>  <span class="token comment">// ä¸€ä¸ªæ•°ç»„ï¼Œæ•°æ®é‡Œé¢çš„å…ƒç´ ç±»å‹æ˜¯ dataElem</span>
    dataElem<span class="token operator">*</span> d_elem<span class="token punctuation">;</span>

    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_elem<span class="token punctuation">,</span> N <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>dataElem<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_elem<span class="token punctuation">,</span> elem<span class="token punctuation">,</span> N <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>dataElem<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token keyword">char</span><span class="token operator">*</span> d_name<span class="token punctuation">;</span>
        <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_name<span class="token punctuation">,</span> elem<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>len<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_name<span class="token punctuation">,</span> elem<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">,</span> elem<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>len<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>d_elem<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>d_name<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_elem<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// ä¼ é€’ç»™æ ¸å‡½æ•°çš„å¯ä»¥æ˜¯ç»“æ„ä½“æˆ–è€…å¯¹è±¡</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><font color="RoyalBlue"><strong>2.</strong></font> å¦‚æœç®—æ³•æ“ä½œçš„æ•°æ®ç»“æ„æ˜¯é“¾è¡¨ï¼Œå’Œæ·±æ‹·è´çš„æƒ…å†µç±»ä¼¼ï¼Œä½¿ç”¨ cudaMallocManaged æ—¶å¯ä»¥è§„é¿å¤åˆ¶ï¼Œç®€åŒ–ç¼–ç¨‹</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> C++ å¯¹è±¡ï¼Œå¯ä»¥é‡è½½ new å’Œ delete è¿ç®—ç¬¦ï¼Œåœ¨é‡è½½çš„å®ç°é‡Œä½¿ç”¨ç»Ÿä¸€å†…å­˜ï¼Œå…¶ä»–ç±»ç»§æ‰¿å®ƒï¼Œç”¨æˆ·æ— æ„Ÿ</p> 
<pre><code class="prism language-cpp"><span class="token keyword">class</span> <span class="token class-name">Managed</span><span class="token punctuation">{<!-- --></span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token keyword">void</span><span class="token operator">*</span> <span class="token keyword">operator</span> <span class="token keyword">new</span><span class="token punctuation">(</span>size_t len<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token keyword">void</span><span class="token operator">*</span> ptr<span class="token punctuation">;</span>
        <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>ptr<span class="token punctuation">,</span> len<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> ptr<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">void</span> <span class="token keyword">operator</span> <span class="token keyword">delete</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span> ptr<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">cudaDevicesynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cudaFree</span><span class="token punctuation">(</span>ptr<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token keyword">class</span> <span class="token class-name">umString</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Managed</span></span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> length<span class="token punctuation">;</span>
    <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token comment">// ç”¨æ‹·è´æ„é€ å™¨æ¥å®ç°æŒ‰å€¼ä¼ é€’</span>
    <span class="token function">umString</span><span class="token punctuation">(</span><span class="token keyword">const</span> umString<span class="token operator">&amp;</span> s<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        length <span class="token operator">=</span> s<span class="token punctuation">.</span>length<span class="token punctuation">;</span>
        <span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> length<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">memcpy</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> s<span class="token punctuation">.</span>data<span class="token punctuation">,</span> length<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token keyword">class</span> <span class="token class-name">dataElem</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Managed</span></span><span class="token punctuation">{<!-- --></span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token keyword">int</span> key<span class="token punctuation">;</span>
    umString name<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

dataElem<span class="token operator">*</span> data <span class="token operator">=</span> <span class="token keyword">new</span> dataElem<span class="token punctuation">[</span>N<span class="token punctuation">]</span><span class="token punctuation">;</span>   <span class="token comment">// new çš„æ“ä½œæ˜¯é‡è½½çš„å®ç°ï¼Œä½†æ˜¯å¯¹äºç”¨æˆ·æ˜¯æ— æ„Ÿçš„</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><font color="RoyalBlue"><strong>4.</strong></font> å‡è®¾æ•°æ®ç»“æ„å¾ˆå¤§ä¸”è®¿é—®æ¨¡å¼äº‹å…ˆä¸èƒ½çŸ¥é“ï¼ˆæ¯”å¦‚ä¸€å¼ å¾ˆå¤§çš„ graphï¼Œå›¾éå†çš„æ—¶å€™ä¸‹ä¸€ä¸ªè¦è®¿é—®çš„èŠ‚ç‚¹ä¸èƒ½åƒæ•°ç»„é‚£æ ·é¢„å…ˆçŸ¥é“ï¼‰ï¼Œè¶…è¿‡äº† gpu çš„æ˜¾å­˜ã€‚è¿™æ—¶å€™ç”¨ç»Ÿä¸€å†…å­˜å¯ä»¥åˆ©ç”¨ oversubscription çš„ç‰¹æ€§ï¼Œè™½ç„¶æ€§èƒ½æœ‰æ‰€ä¸‹é™ã€‚</p> 
<p>ç»Ÿä¸€å†…å­˜å¯¹æ€§èƒ½æœ‰å½±å“ï¼Œæœ‰æ—¶å€™è¿˜å¾ˆä¸¥é‡ï¼Œéœ€è¦æ‰‹åŠ¨è°ƒä¼˜ï¼Œè§ä¸‹é¢ä»£ç ï¼š</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> data<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> index <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    data<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> va<span class="token punctuation">;</span>   <span class="token comment">// è¿™æ ·çš„è®¿é—®æ¨¡å¼å¯¼è‡´æ•°æ®æ˜¯ç”¨åˆ°äº†æ‰ä¼šæ¬ç§»</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token number">256</span> <span class="token operator">*</span> <span class="token number">256</span><span class="token punctuation">;</span>
<span class="token keyword">float</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
<span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>è¿™æ®µä»£ç è¦æ¯”ä¸ä½¿ç”¨ç»Ÿä¸€å†…å­˜ï¼ˆæˆ–è€…ä½¿ç”¨ pascal æ¶æ„ä¹‹å‰çš„ç»Ÿä¸€å†…å­˜ï¼‰çš„ç‰ˆæœ¬æ…¢å¾ˆå¤šã€‚ç©¶å…¶åŸå› ï¼Œä¾èµ–äºç¼ºé¡µä¸­æ–­æ¥æ¬ç§»æ•°æ®çš„æœºåˆ¶ï¼Œå½“è¦æ¬ç§»çš„æ•°æ®é‡å¾ˆå¤§çš„æ—¶å€™ï¼Œæ¯é¡µéƒ½æœ‰ä¸€å®šçš„ overheadã€‚æ˜¯ä¸é«˜æ•ˆçš„ã€‚å¯¹äºå¤§æ•°æ®é‡çš„æ¬ç§»ï¼Œé«˜æ•ˆçš„åšæ³•æ˜¯åƒ <code>memcpy</code> é‚£æ ·ä¸€æ•´å—çš„æ¬ç§»ã€‚</p> 
<p>åˆ©ç”¨ <code>cudaMemPrefetchAsync(ptr, length, destDevice, stream)</code> å¯ä»¥æ¢å¤æ€§èƒ½ï¼š</p> 
<pre><code class="prism language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> data<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> index <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    data<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> va<span class="token punctuation">;</span>   <span class="token comment">// è¿™æ ·çš„è®¿é—®æ¨¡å¼å¯¼è‡´æ•°æ®æ˜¯ç”¨åˆ°äº†æ‰ä¼šæ¬ç§»</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token number">256</span> <span class="token operator">*</span> <span class="token number">256</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> ds <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">float</span><span class="token operator">*</span> data<span class="token punctuation">;</span>
<span class="token function">cudaMallocManaged</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>data<span class="token punctuation">,</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemPrefetchAsync</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> ds<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// æŠŠæ•°æ®æ‹·åˆ°è®¾å¤‡å·æ˜¯ 0 å·çš„è®¾å¤‡ä¸Š</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemPrefetchAsync</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> ds<span class="token punctuation">,</span> cudaCpuDeviceId<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">// æŠŠæ•°æ®æ‹·å›å»</span>
</code></pre> 
<p>è¿™ä¸ª API å’Œ cudaMemcpy(Async) éå¸¸ç›¸ä¼¼ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªæŒ‡é’ˆï¼Œé•¿åº¦ï¼Œå’Œè®¾å¤‡å·è¿™äº›å‚æ•°ã€‚æ³¨æ„è®¾å¤‡å·å¯ä»¥æ˜¯ cpuã€‚</p> 
<p>å¦‚æœå·²çŸ¥å¯¹æ•°æ®çš„ä½¿ç”¨æ–¹å¼ï¼Œè¿˜å¯ä»¥ç”¨ <code>cudaMemAdvise(ptr, count, hint, device)</code> è¿™ä¸ª API æ¥ç»™ cudaruntime ä¸€äº›æç¤ºï¼Œè¿™è¾¹çš„ hint å‚æ•°å¯ä»¥æ˜¯ä»¥ä¸‹å‡ ä¸ªï¼š</p> 
<ul><li><font color="RoyalBlue"><strong>a.</strong></font> cudaMemAdviseSetReadMostlyï¼šå»ºè®®çš„å¤§éƒ¨åˆ†æ“ä½œæ˜¯åªè¯»ã€‚cudaruntime ä¼šç»™æ¯ä¸€ä¸ªè¦è®¿é—®å®ƒçš„å¤„ç†å™¨åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å‰¯æœ¬ï¼Œè¿™æ ·æ•°æ® overhead åªåœ¨æ¯ä¸€ä¸ªå¤„ç†å™¨ç¬¬ä¸€æ¬¡è®¿é—®çš„æ—¶å€™æ‰æœ‰ï¼Œä¹‹åæ²¡æœ‰ã€‚å½“ç„¶è¿™è¾¹åªæ˜¯å»ºè®®ï¼Œå†™æ“ä½œè¿˜æ˜¯æœ‰æ•ˆçš„ã€‚å½“æœ‰å¤„ç†å™¨å¯¹è¿™å—æ•°æ®è¿›è¡Œå†™æ“ä½œçš„æ—¶å€™ï¼Œæ‰€æœ‰å¤„ç†å™¨çš„å‰¯æœ¬éƒ½å¤±æ•ˆï¼Œé™¤äº†æ‰§è¡Œå†™æ“ä½œçš„è¿™ä¸ªå¤„ç†å™¨è‡ªå·±çš„å‰¯æœ¬ï¼Œæ‰€ä»¥è¦æƒ³è·å–é«˜æ€§èƒ½ï¼Œè¿˜æ˜¯å¾—éµå®ˆå®ƒå¾—å»ºè®®ï¼Œdevice è¿™ä¸ªç»™å‚æ•°è¢«å¿½ç•¥ã€‚</li><li><font color="RoyalBlue"><strong>b.</strong></font> cudaMemAdviseSetPreferredLocationï¼šå»ºè®®è¿™å—æ•°æ®æœ€å¤šè¢«å“ªä¸ªå¤„ç†å™¨è®¿é—®ã€‚ä¸ä¼šè‡ªåŠ¨è§¦å‘æ•°æ®æ¬ç§»ï¼Œå½“å»ºè®®å¾—å¤„ç†å™¨çœŸçš„è®¿é—®ï¼ˆæˆ–è€… prefetchï¼‰çš„æ—¶å€™æ‰ä¼šæœ‰æ•°æ®æ¬ç§»ã€‚å½“æœ‰å…¶ä»–å¤„ç†å™¨ä¹Ÿè¦è®¿é—®è¿™å—æ•°æ®çš„æ—¶å€™ï¼Œå¦‚æœæ¡ä»¶å…è®¸ï¼Œä¼šå»ºç«‹æ˜ å°„ã€‚ä¸æ»¡è¶³æ¡ä»¶ï¼Œåˆ™ä¼šå¼•èµ·æ•°æ®æ¬ç§»ã€‚ä» Volta æ¶æ„å¼€å§‹ï¼Œcudaruntime å¯ä»¥è‡ªåŠ¨ç»Ÿè®¡æ¯ä¸ªå¤„ç†å™¨è®¿é—®è¿™å—æ•°æ®çš„æ¬¡æ•°ï¼Œä¸éœ€è¦ç¨‹åºå‘˜å»å»ºè®®ã€‚</li><li><font color="RoyalBlue"><strong>c.</strong></font> cudaMemAdviseSetAccessedByï¼šå»ºè®®è¦è®¿é—®çš„å¤„ç†å™¨åœ¨è®¿é—®çš„æ—¶å€™é€šè¿‡æ˜ å°„è€Œä¸æ˜¯æ•°æ®æ¬ç§»çš„æ–¹å¼å»è®¿é—®ã€‚å¦‚æœæ•°æ®è¢«æ¬ç§»äº†ï¼Œæ˜ å°„ä¹Ÿä¼šè¢«æ›´æ–°ã€‚ç›®çš„æ˜¯ä¸ºäº†åœ¨ä¸å¼•èµ·ç¼ºé¡µä¸­æ–­çš„æƒ…å†µä¸‹è®¿é—®æ•°æ®ã€‚</li></ul> 
<p>æ³¨æ„ï¼Œ<code>cudaMemeAdvise</code> åšçš„äº‹æƒ…åªæ˜¯å¯¹ cudaruntime çš„å»ºè®®ï¼Œè¿™ä¸ª API è‡ªå·±æœ¬èº«ä¸ä¼šæ¬è¿æ•°æ®ã€‚</p> 
<p><strong>æ€»ç»“</strong>ï¼šç»Ÿä¸€å†…å­˜åªæ˜¯ç®€åŒ–ç¼–ç¨‹ï¼Œä¸ä¼šæå‡æ€§èƒ½ï¼Œå®ƒçš„æ€§èƒ½ä¸Šé™æ˜¯æ™®é€šçš„ä¸ä½¿ç”¨ç»Ÿä¸€å†…å­˜çš„æ€§èƒ½ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå®ƒæ¯”å†™å¾—å¥½çš„æ‰‹åŠ¨æ¬è¿æ•°æ®çš„ä»£ç æ€§èƒ½æ›´ä½ã€‚æ»¥ç”¨ç»Ÿä¸€å†…å­˜ä¼šä½¿å¾—ä»£ç æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚ç»Ÿä¸€å†…å­˜æœ‰åŠ©äºå®ç°åœ¨å¤æ‚æ•°æ®ç»“æ„ä¸Šçš„ç®—æ³•ï¼Œä»¥åŠç‰¹å®šçš„è®¾è®¡æ¨¡å¼ã€‚å¯¹äºä½¿ç”¨å¾ˆå¤šç¬¬ä¸‰æ–¹åº“çš„ä»£ç ï¼Œæ¯ä¸ªç¬¬ä¸‰æ–¹åº“è‡ªå·±ä¼šä½¿ç”¨ä¸€å®šé‡çš„ GPU æ˜¾å­˜ï¼Œä½†æ˜¯å¯¹äºå…¶å®ƒç¬¬ä¸‰æ–¹åº“ä½¿ç”¨çš„ GPU æ˜¾å­˜é‡æ— æ„Ÿçš„æƒ…å†µä¸‹ï¼Œç»Ÿä¸€å†…å­˜çš„ oversubscription æœºåˆ¶æœ‰åŠ©äºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè€Œä¸éœ€è¦é‡æ„ä»£ç ï¼Œå‡è½»ç§»æ¤ä»£ç æ—¶å€™çš„å·¥ä½œé‡ã€‚</p> 
<h3><a id="6_CUDA_888"></a>6. CUDAæµå’Œå¹¶å‘</h3> 
<p>ä¹‹å‰æˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•å†™å¥½ä¸€ä¸ªé«˜æ€§èƒ½çš„æ ¸å‡½æ•°ï¼Œè¿™èŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ æ ¸å‡½æ•°ä¹‹é—´çš„å¹¶å‘ï¼Œæ›´å¥½åœ°åˆ©ç”¨å¤„ç†å™¨èµ„æºï¼Œæå‡æ•´ä¸ªç³»ç»Ÿçš„æ€§èƒ½ã€‚å›é¡¾ä¸‹ä¸‰æ­¥èµ°ç­–ç•¥ï¼š1. æŠŠæ•°æ®ä» cpu ä¸Šæ‹·åˆ° gpu ä¸Š; 2. åœ¨ gpu ä¸Šè¿›è¡Œè®¡ç®—; 3. æŠŠç»“æœä» gpu ä¸Šæ‹·å›åˆ° cpu é‡Œã€‚æˆ‘ä»¬è¿˜å­¦åˆ°å³ä½¿åˆ©ç”¨äº†ç»Ÿä¸€å†…å­˜çš„æŠ€æœ¯ï¼Œè¿˜æ˜¯å¾—éµå®ˆè¿™æ ·çš„ä¸‰æ­¥èµ°ç­–ç•¥ï¼Œåªä¸è¿‡ cudaruntime å¸®ç¨‹åºå‘˜åšäº†æ•°æ®æ‹·è´çš„æ“ä½œã€‚cuda å¹¶å‘æŠ€æœ¯çš„åˆè¡·æ˜¯æƒ³åŠæ³•æŠŠæ•°æ®æ¬è¿å’Œè®¡ç®—çš„æ­¥éª¤åœ¨æ—¶é—´çº¿ä¸Šé‡å ï¼ˆoverlapï¼‰èµ·æ¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p> 
<p><img src="https://images2.imgbox.com/24/11/zAoNsgzD_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>è¿™æ ·å°±èƒ½å‡å°‘æ€»ä½“è€—æ—¶ï¼Œç¬¦åˆäººä»¬ä½¿ç”¨ GPU çš„æœ€åˆç›®çš„ï¼Œå¯ä»¥æˆä¸º CUDA ä¼˜åŒ–çš„ç¬¬ä¸‰å¤§å‡†åˆ™ã€‚</p> 
<p>è¦æƒ³å®ç° CUDA å¹¶å‘ï¼Œå°±éœ€è¦ä½¿ç”¨ pinned memoryï¼Œpinned memory ä¹Ÿæ˜¯å±äº system dram çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒå¯ä»¥å®ç°å¼‚æ­¥çš„æ‹·è´æ•°æ®ï¼Œä»è€Œå®ç°åœ¨æ—¶é—´ä¸Šçš„é‡å ã€‚cudaHostAlloc/cudaFreeHost/cudaHostRegister/cudaHostUnregister è¿™äº› API å¯ä»¥å¯¹ pinned memory çš„æ“ä½œã€‚pinned memory å®è´¨ä¸Šæ˜¯åœ¨ç‰©ç†å†…å­˜é‡Œåˆ†é…çš„ï¼Œæ²¡æœ‰è™šæ‹Ÿå†…å­˜çš„å‚ä¸ï¼Œä¸ä¼šè¢«æ“ä½œç³»ç»Ÿäº¤æ¢åˆ°ç£ç›˜ä¸Šã€‚é€»è¾‘ä¸Šä¹Ÿè¯´å¾—é€šï¼Œå› ä¸º gpu ç«¯è¦æƒ³è®¿é—®æŸä¸ªåœ°å€æ—¶å®ƒæ²¡åŠæ³•çŸ¥é“è¿™ä¸ªåœ°å€æ‰€åœ¨çš„é¡µæ˜¯åœ¨è™šæ‹Ÿå†…å­˜é‡Œï¼Œè¿˜æ˜¯è¢«æ“ä½œç³»ç»Ÿäº¤æ¢åˆ°ç£ç›˜ä¸Šï¼Œæ‰€ä»¥å¹²è„†ä¸è¦è™šæ‹Ÿå†…å­˜é‚£å¥—æœºåˆ¶ã€‚ä¹Ÿå› æ­¤ï¼Œä¸èƒ½åˆ†é…å¤§äºç³»ç»Ÿç‰©ç†å†…å­˜çš„ pinned memoryï¼ˆout of memory æŠ¥é”™ï¼‰ã€‚æ»¥ç”¨ pinned memory ä¼šé™ä½ç³»ç»Ÿæ•´ä½“çš„æ€§èƒ½ï¼Œå› ä¸ºæ“ä½œç³»ç»Ÿä¹Ÿéœ€è¦ä¸€å®šçš„ç‰©ç†å†…å­˜æ¥å¹²å®ƒåº”è¯¥å¹²çš„äº‹æƒ…ã€‚</p> 
<p>å®ç° cuda å¹¶å‘çš„å¦ä¸€æœºåˆ¶æ˜¯ streamã€‚cuda ç¼–ç¨‹æ¨¡å‹çš„é»˜è®¤è¡Œä¸ºæ˜¯ï¼šæ ¸å‡½æ•°è°ƒç”¨æ˜¯å¼‚æ­¥çš„ï¼ŒcudaMemcpy æ˜¯åŒæ­¥çš„ã€‚å¦‚æœä½¿ç”¨é»˜è®¤æµï¼ˆlegacy default streamï¼‰çš„è¯ï¼Œæ‰€æœ‰å¯¹ CUDA API çš„è°ƒç”¨éƒ½æ˜¯ç”± cuda é©±åŠ¨åºåˆ—åŒ–çš„ï¼ˆç­‰å‰ä¸€ä¸ªè°ƒç”¨è¿”å›ä¹‹åå†è°ƒç”¨åä¸€ä¸ª CUDA APIï¼‰ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–°çš„ APIï¼šcudaMemcpyAsync()ï¼Œè¿™ä¸ª API éœ€è¦æ¥å—ä¸€ä¸ªé¢å¤–çš„ stream å‚æ•°ï¼Œè€Œä¸”å®ƒå‚æ•°é‡Œçš„åœ°å€éœ€è¦æ˜¯å±äº pinned memory çš„ã€‚ä¸¤ä¸ªæ–¹å‘çš„å¹¶å‘åœ°æ•°æ®æ‹·è´ï¼ˆHostToDeviceï¼ŒDeviceToHostï¼‰ä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸ª API æ¥å®ç°ã€‚ä»€ä¹ˆæ˜¯ streamï¼Ÿä¸€ç³»åˆ—æŒ‰ç…§ä»£ç ç¼–å†™é¡ºåºæ‰§è¡Œçš„æ“ä½œã€‚æ¥è‡ªä¸åŒ stream çš„æ“ä½œå¯ä»¥åœ¨æ—¶é—´ä¸Šé‡å ï¼Œæ¯”å¦‚æ¥è‡ªä¸åŒ stream çš„æ ¸å‡½æ•°è°ƒç”¨å’Œæ•°æ®æ‹·è´æ“ä½œã€‚åŒä¸€ä¸ª stream é‡Œæ“ä½œæ— æ³•åœ¨æ—¶é—´ä¸Šé‡å ã€‚</p> 
<p>stream çš„è¯­ä¹‰ï¼šä¸¤ä¸ªåœ¨åŒä¸€ä¸ª stream é‡Œçš„æ“ä½œæ°¸è¿œä»¥ä»£ç ç¼–å†™çš„é¡ºåºæ‰§è¡Œã€‚ä»£ç ä¸Šåé¢çš„æ“ä½œæ°¸è¿œæ— æ³•åœ¨å‰é¢çš„æ“ä½œæ‰§è¡Œå®Œæ¯•ä¹‹å‰å°±å¼€å§‹æ‰§è¡Œï¼Œæ— è®ºå®ƒä»¬æ˜¯å¦é åœ¨ä¸€èµ·æˆ–è€…ç”±å…¶ä»–çš„æ“ä½œå¤¹æ‚åœ¨å…¶ä¸­ã€‚åœ¨ä¸åŒ stream é‡Œçš„ä¸¤ä¸ªæ“ä½œæ²¡æœ‰æ‰§è¡Œé¡ºåºä¸Šçš„çº¦å®šï¼Œä¸€ä¸ªåœ¨ stream1 é‡Œçš„æ“ä½œå¯ä»¥åœ¨å¦ä¸€ä¸ª stream2 é‡Œçš„æ“ä½œçš„æ‰§è¡Œä¹‹å‰ï¼Œæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œæˆ–è€…æ‰§è¡Œä¹‹åæ‰§è¡Œã€‚CUDA ç¼–ç¨‹æ¨¡å‹å¯¹äºè¿™ä¸€ç‚¹æ²¡æœ‰ä»»ä½•è§„å®šã€‚é€šå¸¸æ ¸å‡½æ•°ï¼Œcuda api è°ƒç”¨ï¼ˆcudaMemcpyAsyncï¼‰ï¼ŒåŒ…æ‹¬ stream callbackï¼ˆè§ä¸‹æ–‡ï¼‰ï¼Œéƒ½ä¼šæ¥å—ä¸€ä¸ª stream å‚æ•°ã€‚</p> 
<pre><code class="prism language-cpp">cudaStream_t stream1<span class="token punctuation">,</span> stream2<span class="token punctuation">;</span>
<span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream1<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream2<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>dst<span class="token punctuation">,</span> src<span class="token punctuation">,</span> size<span class="token punctuation">,</span> direction<span class="token punctuation">,</span> stream1<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// è¿™ä¸¤ä¸ªæ“ä½œå¯ä»¥åœ¨æ—¶é—´ä¸Šé‡å ï¼Œpinned memory</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> block<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> stream2<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// æ³¨æ„ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯åŠ¨æ€å…±äº«å†…å­˜çš„å¤§å°ï¼Œè¿™é‡Œç»™ 0</span>
<span class="token comment">// ä»ä»£ç å±‚é¢çœ‹ï¼Œè™½ç„¶æ ¸å‡½æ•°åœ¨æ•°æ®æ‹·è´çš„åé¢ï¼Œä½†ç”±äºåœ¨ä¸¤ä¸ª stream é‡Œï¼Œæ‰§è¡Œé¡ºåºæœªçŸ¥</span>
<span class="token function">cudaStreamQuery</span><span class="token punctuation">(</span>stream1<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// æµ‹è¯• stream1 æ˜¯å¦ç©ºé—²</span>
<span class="token function">cudaStreamSynchronize</span><span class="token punctuation">(</span>stream2<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// å¼ºåˆ¶ cpu çº¿ç¨‹ç­‰å¾…æ‰€æœ‰åœ¨ stream2 é‡Œçš„ cuda æ“ä½œæ‰§è¡Œå®Œæ¯•ï¼Œå’Œ cudaDeviceSynchronize() åŒºåˆ†</span>
<span class="token function">cudaStreamDestroy</span><span class="token punctuation">(</span>stream2<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>ç¬¬ä¸€å¼ å›¾å·¦è¾¹é»‘è‰²çš„æ˜¯ä»£ç å±‚é¢çš„é¡ºåºï¼Œä¸­é—´æ©˜é»„è‰²çš„æ˜¯æ—¶é—´çº¿ä¸Šçš„æ‰§è¡Œé¡ºåºï¼š</p> 
<p>ç¬¬äºŒå¼ å›¾æ˜¯ä¸€ä¸ªæ›´åŠ å…·ä½“çš„ä¾‹å­ï¼Œå±•ç¤ºäº†æœ‰æ—  stream æƒ…å†µä¸‹æ—¶é—´çº¿ä¸Šçš„æ‰§è¡Œé¡ºåºï¼ˆæŠŠæ•´ä¸ªè¦å¤„ç†çš„è¾“å…¥æ•°æ®æ‹†åˆ†æˆå’Œ stream æ•°é‡å¤§å°ä¸€è‡´çš„åˆ†ç»„ï¼Œæ¯ä¸ªåˆ†ç»„åœ¨ä¸€ä¸ª stream é‡Œæ‰§è¡Œï¼Œå¯ä»¥å®ç°æ—¶é—´ä¸Šé‡å ï¼Œéœ€è¦ç®—æ³•å¯ä»¥æ‹†åˆ†ã€‚æ ¸å‡½æ•°å¼€å¯çš„å¼€é”€ä¹Ÿå¯ä»¥è¢«è¦†ç›–æ‰ï¼Œè¿™æ¯”åºåˆ—åŒ–çš„æ“ä½œå¥½å¾ˆå¤šï¼‰ï¼š</p> 
<p><img src="https://images2.imgbox.com/66/40/Okok6lc3_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><img src="https://images2.imgbox.com/26/a6/2HcGXJkf_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>è¿™ä¸ªæ˜¯ä¸€ç§â€æ·±åº¦ä¼˜å…ˆâ€œçš„ä»£ç ç¼–å†™é¡ºåºï¼šåœ¨ä¸€ä¸ª for å¾ªç¯é‡Œåšæ•°æ®æ‹·è´ï¼Œkernel è®¡ç®—ï¼Œæ•°æ®æ‹·å›ä¸‰ä¸ªæ“ä½œã€‚å…¶å®ä¹Ÿå¯ä»¥ç”¨ä¸€ä¸ªâ€å®½åº¦ä¼˜å…ˆâ€œçš„æ–¹å¼ï¼šä¸€ä¸ª for å¾ªç¯é‡Œåªåšæ•°æ®æ‹·è´ï¼Œä¸€ä¸ª for å¾ªç¯é‡Œåªåš kernel è®¡ç®—ï¼Œä¸€ä¸ª for å¾ªç¯é‡Œåªåšæ•°æ®æ‹·å›ã€‚ä¸¤ç§æ¨¡å¼åœ¨æ€§èƒ½ä¸Šï¼ˆå¹¶å‘åº¦ï¼‰æ²¡æœ‰å·®å¼‚ï¼Œä½†æ˜¯â€æ·±åº¦ä¼˜å…ˆâ€œçš„æ–¹å¼ä¼šæœ‰ä¸€ä¸ªé—®é¢˜ï¼šstream çš„æœ¬è´¨æ˜¯ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå½“è¾“å…¥æ•°æ®éå¸¸å¤§çš„æ—¶å€™ï¼Œæ‹·è´æ“ä½œçš„æ•°é‡ä¼šè¶…è¿‡é˜Ÿåˆ—é•¿åº¦çš„ä¸Šé™å€¼ã€‚</p> 
<p>æ³¨æ„ï¼š</p> 
<p><font color="RoyalBlue"><strong>1.</strong></font> stream çš„åˆ›å»ºå’Œé”€æ¯ä¹Ÿæ˜¯æœ‰æˆæœ¬çš„ï¼Œä½†æ˜¯å®ƒä»¬é€šå¸¸ä¸ä¼šè¢«åœ¨æµ‹é‡æ€§èƒ½æ—¶ç»Ÿè®¡è¿›å»ã€‚æ¯”å¦‚ cudaMallocï¼Œå®ƒå½“ç„¶ä¹Ÿæ²¡æœ‰ stream å‚æ•°ã€‚</p> 
<p><font color="RoyalBlue"><strong>2.</strong></font> åœ¨ä¸€ä¸ª stream é‡Œæ‰§è¡Œçš„æ ¸å‡½æ•°å¯ä»¥è®¿é—®åŒä¸€è®¾å¤‡é‡Œçš„ä»»ä½•åœ°å€ï¼ŒåŒ…æ‹¬åœ¨å…¶ä»– stream é‡Œæ‰§è¡Œçš„æ‹·è´æ“ä½œçš„æ•°æ®/è¢«å…¶ä»–æ ¸å‡½æ•°ä¿®æ”¹çš„æ•°æ®ï¼Œè¿™æ—¶å€™å°±æœ‰ data race çš„é—®é¢˜ï¼Œç¨‹åºå‘˜éœ€è¦æ‰‹åŠ¨åšå¥½åŒæ­¥ã€‚</p> 
<p><font color="RoyalBlue"><strong>3.</strong></font> å¯ä»¥åˆ›å»ºçš„ stream çš„æ•°é‡ä¸Šæ˜¯æœ‰ä¸Šé™å€¼çš„ï¼Œé€šå¸¸æ¥è¯´ 2~3 ä¸ª stream å·²ç»æ»¡è¶³å®é™…éœ€æ±‚ã€‚&gt;10 ä¸ª stream è¯´æ˜ä»£ç æ²¡å†™å¥½</p> 
<p><font color="RoyalBlue"><strong>4.</strong></font> æ ¸å‡½æ•°è®¿é—®ä¸€ä¸ªè¿˜æ²¡æœ‰ä» host ç«¯æ‹·åˆ° GPU é‡Œçš„æ•°æ®çš„åœ°å€æ˜¯æœªå®šä¹‰è¡Œä¸ºã€‚cudaruntime çš„ API æ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚</p> 
<p><font color="RoyalBlue"><strong>5.</strong></font> ç”±äºæ ¸å‡½æ•°æ‰§è¡Œæ—¶é—´é€šå¸¸è¾ƒæ•°æ®æ‹·è´è¦å°å¾ˆå¤šï¼Œæ€§èƒ½æå‡ä¸»è¦åœ¨äºä¸¤ä¸ªæ–¹å‘çš„æ•°æ®æ‹·è´æ“ä½œåœ¨æ—¶é—´ä¸Šçš„é‡å ã€‚</p> 
<p><font color="RoyalBlue"><strong>6.</strong></font> å¦‚æœä¸€ä¸ªæ ¸å‡½æ•°ç”¨å®Œäº†æŸç§ç¡¬ä»¶è®¡ç®—å•å…ƒï¼Œå…¶ä»– stream é‡Œç”¨åˆ°åŒæ ·è®¡ç®—å•å…ƒçš„æ ¸å‡½æ•°åˆ™ä¸ä¼šå¹¶å‘æ‰§è¡Œã€‚</p> 
<p>è¿˜æœ‰ä¸€ä¸ªé»˜è®¤æµï¼ˆlegacy default steamï¼‰çš„æ¦‚å¿µï¼Œå¦‚æœå¼€å¯æ ¸å‡½æ•°æ—¶ä¸ä¼  stream å‚æ•°ï¼Œä»¥åŠ cudaMemcpy è¿™ä¸ª APIï¼Œå®ƒä»¬ç”¨åˆ°çš„æ˜¯é»˜è®¤æµã€‚é»˜è®¤æµæ˜¯ä¸€ä¸ªå…¨å±€çš„åŒæ­¥ç‚¹ï¼šå¦‚æœæŠŠè‡ªå·±åˆ›å»ºçš„ stream å’Œé»˜è®¤æµä¸€èµ·ä½¿ç”¨ï¼Œé‚£ä¹ˆåœ¨é»˜è®¤æµé‡Œçš„æ“ä½œå¿…é¡»ç­‰å¾…å…¶ä»– stream é‡Œåœ¨å®ƒå‰é¢çš„æ“ä½œæ‰§è¡Œå®Œæ¯•æ‰å¼€å§‹æ‰§è¡Œï¼Œå…¶ä»– stream é‡Œåé¢çš„æ“ä½œä¹Ÿå¿…é¡»ç­‰å¾…é»˜è®¤æµé‡Œæ“ä½œæ‰§è¡Œå®Œæ¯•æ‰å¼€å§‹æ‰§è¡Œï¼Œç®€è€Œè¨€ä¹‹ä¼šç ´åå¹¶å‘æ€§ã€‚ä¸»æœºç«¯çš„çº¿ç¨‹å…±äº«ä¸€ä¸ªé»˜è®¤æµï¼ˆä¹Ÿå¯ä»¥æ”¹å˜è¿™ä¸ªè¡Œä¸ºï¼Œç»™ nvcc ä¼ é€’ --default-stream per-thread è¿™ä¸ªå‚æ•°ï¼‰ã€‚è¿™ä¸ªç‰¹æ€§åªåœ¨å’Œåˆ«äººåˆä½œæ—¶æœ‰ç”¨ï¼Œè‡ªå·±ä»å¤´å†™ä»£ç çš„è¯ï¼Œåœ¨è¿½æ±‚é«˜åº¦å¹¶å‘çš„åœºæ™¯ä¸‹ï¼Œåº”è¯¥é¿å…ä½¿ç”¨é»˜è®¤æµã€‚</p> 
<p>ç”¨ cudaLaunchHostFunc() è¿™ä¸ªå‡½æ•°å¯ä»¥å®ç° â€œstream callbackâ€ã€‚ä¸»æœºç«¯çš„å‡½æ•°ä¹Ÿå¯ä»¥åœ¨ stream é‡Œå®Œæˆï¼Œå®ƒçš„è¡Œä¸ºç¬¦åˆä¹‹å‰çš„ stream è¯­ä¹‰ã€‚éœ€è¦åœ¨ CPU ç«¯å¼€å¯æ–°çš„çº¿ç¨‹ï¼Œæ–°çš„çº¿ç¨‹é‡Œä¸èƒ½è°ƒç”¨ cuda è¿è¡Œæ—¶ api/æ ¸å‡½æ•°è°ƒç”¨ï¼Œåªèƒ½åšä¸€äº›å¸¸è§„çš„åœ¨ CPU ä¸Šçš„æ“ä½œã€‚éœ€è¦ CPU ç«¯ç­‰å¾… GPU çš„ç»“æœå‡ºæ¥æ‰èƒ½ç»§ç»­æ‰§è¡Œçš„åœºæ™¯ä¸‹æœ‰ç”¨ï¼ˆæ¯”å¦‚ç”¨åˆ°äº† cuda ç»Ÿä¸€å†…å­˜ï¼Œä»¥å‰åªèƒ½é€šè¿‡è°ƒç”¨ cudaDeviceSynchronize æ¥ç¡®ä¿ gpu çš„æ”¹åŠ¨å¯¹ cpu å¯è§ï¼Œé«˜å¹¶å‘çš„åœºæ™¯ä¸‹å¯ä»¥ç”¨ stream callback æ¥æ›¿æ¢ï¼‰ã€‚cudaStreamAddCallback æ˜¯æ—§çš„ API</p> 
<p>å¯¹äºç»Ÿä¸€å†…å­˜ï¼Œè°ƒç”¨ cudaMemPrefetchAsync è€Œä¸æ˜¯ cudaMemcpy æ¥å®ç°æ•°æ®çš„æ‹·è´ã€‚æµè¯­ä¹‰ä¼šä¿è¯ä¹‹å‰æåˆ°çš„æ•°æ®æ¬ç§»ï¼ˆdata migrationï¼‰çš„æ“ä½œä¼šä»¥æ­£ç¡®çš„é¡ºåºæ‰§è¡Œã€‚ä½†æ˜¯ï¼ŒcudaMemPrefetchAsync åšçš„å·¥ä½œè¦æ¯” cudaMemcpy å¤šï¼Œå› ä¸ºéœ€è¦æ›´æ–° GPU å’Œ CPU ä¸Šçš„é¡µè¡¨ï¼Œç›¸åº”åœ°ï¼Œè€—æ—¶æ¯”å¹³å¸¸åœ°å¼‚æ­¥è°ƒç”¨ä¼šæ›´å¤šï¼Œå¯èƒ½ä¼šåœ¨æ—¶é—´çº¿ä¸Šé€ æˆç©ºéš™ã€‚ä¸ºäº†ç¡®ä¿é«˜ååé‡ï¼ŒDeviceToHost éœ€è¦åœ¨ä¸€ä¸ª busy çš„ stream é‡Œè€Œ HostToDevice éœ€è¦åœ¨ä¸€ä¸ª idle çš„ stream é‡Œå®Œæˆã€‚è¯¦ç»†è®¨è®ºå¯ä»¥å‚è€ƒï¼ˆ<a href="https://developer.nvidia.com/blog/maximizing-unified-memory-performance-cuda/" rel="nofollow">Maximizing Unified Memory Performance in CUDA | NVIDIA Technical Blog</a>ï¼‰</p> 
<p>cudaEvent æ˜¯ä¸€ä¸ªæ”¾åœ¨ stream é‡Œçš„æ ‡è®°ã€‚å½“ä»£ç é‡Œå†™ä¸‹ cudaEvent æ—¶ç§°ä¸ºè¢«è®°å½•ä¸‹ï¼Œå½“ stream çš„æ‰§è¡Œåˆ°è¾¾ä¹‹å‰è®°å½•çš„ç‚¹çš„æ—¶å€™ç§°ä¸ºå®Œæˆã€‚å¸¸ç”¨åœºæ™¯æ˜¯ç”¨æ¥æµ‹è¯•ä¸€æ®µæ ¸å‡½æ•°çš„è€—æ—¶ï¼š</p> 
<pre><code class="prism language-cpp">cudaEvent_t start<span class="token punctuation">,</span> stop<span class="token punctuation">;</span>
<span class="token function">cudaEventCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>start<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// è®°å½•ä¸€ä¸ªå¼€å§‹çš„æœªçŸ¥</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// å¯ä»¥æ˜¯å…¶ä»–ä»»ä½•è®¾å¤‡ä¸Šçš„ cuda æ“ä½œ</span>
<span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// è®°å½•ä¸€ä¸ªç»“æŸçš„ä½ç½®</span>
<span class="token function">cudaEventSynchronize</span><span class="token punctuation">(</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// ç­‰å¾… stream æ‰§è¡Œåˆ° stop è¿™ä¸ªæ ‡è®°çš„ä½ç½®</span>
<span class="token function">cudaEventElapsedTime</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>float_val<span class="token punctuation">,</span> start<span class="token punctuation">,</span> stop<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>cudaEvent å’Œ NVTX marker çš„åŒºåˆ«ï¼šcudaEvent ä¸»è¦æ˜¯å¯¹ cudaruntime api å¯è§ï¼Œè€Œ NVTX marker ä¸»è¦å¯¹ profile å¯è§ã€‚</p> 
<p>ä¹Ÿå¯ä»¥ç”¨ cudaStreamWaitEvent è¿™ä¸ªå‡½æ•°æ¥å®ç°é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œå¯ä»¥ä½¿ä¸€ä¸ª stream ç­‰å¾…å¦ä¸€ä¸ª stream é‡Œçš„ eventï¼Œä¸€å®šç¨‹åº¦ä¸Šæ‰“ç ´äº†ä¹‹å‰æåˆ°çš„ stream è¯­ä¹‰ã€‚stream ä¹Ÿå¯ä»¥åœ¨å¤šè®¾å¤‡çš„åœºæ™¯ä¸‹ä½¿ç”¨ï¼Œè§ä»£ç ï¼š</p> 
<pre><code class="prism language-cpp"><span class="token function">cudaSetDevice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream0<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaSetDevice</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream1<span class="token punctuation">)</span><span class="token punctuation">;</span>
kernel1<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>b<span class="token punctuation">,</span>t<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>stream1<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// kernel1 å’Œ kernel2 å¯ä»¥å¹¶å‘æ‰§è¡Œ</span>
<span class="token function">cudaSetDevice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
kernel2<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>b<span class="token punctuation">,</span> t<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> stream0<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>æ ¸å¿ƒå‡½æ•°å’Œ CPU ç«¯çš„å‡½æ•°çš„å¼‚æ­¥è¡Œä¸ºå¯ä»¥è½»æ˜“è¢«è§è¯ï¼Œä½†æ˜¯æ ¸å‡½æ•°ä¹‹é—´çš„å¹¶å‘æ€§å¾ˆéš¾è¢«è§è¯ã€‚éœ€è¦å‚ä¸å¹¶å‘çš„æ ¸å‡½æ•°ä½¿ç”¨ç›¸å¯¹å°‘çš„èµ„æºçš„åŒæ—¶åˆæœ‰ç›¸å¯¹è¾ƒé•¿çš„æ‰§è¡Œæ—¶é—´ã€‚ä¸å¦‚åœ¨ä¸€ä¸ªæ ¸å‡½æ•°é‡Œå°½å¯èƒ½å……åˆ†åˆ©ç”¨è®¾å¤‡çš„èµ„æºã€‚å¯ä»¥æ”¯æŒçš„å¹¶å‘æ ¸å‡½æ•°çš„æ•°é‡æ˜¯ç”±ç¡¬ä»¶é™åˆ¶çš„ï¼Œå½“ä¸€ä¸ª kernel ä½¿ç”¨äº†æ‰€æœ‰çš„ SM é‡Œçš„æ‰€æœ‰ block æ—¶ï¼Œè¿™æ—¶å€™ CWDï¼ˆcuda work distributorï¼‰ä¸èƒ½åŒæ—¶è°ƒåº¦å…¶ä»–æ ¸å‡½æ•°çš„ block è¿›è¡Œæ‰§è¡Œã€‚å³ä½¿å…¶ä»–å¹¶å‘çš„æ¡ä»¶éƒ½æ»¡è¶³ï¼Œä¹Ÿå°±æ˜¯ä¸¤ä¸ªæ ¸å‡½æ•°åœ¨ä¸åŒ stream é‡Œã€‚æ³¨æ„è¿™ä¸æ˜¯ç¡¬æ€§è§„å®šï¼Œä½† cuda é€šå¸¸æ¥è¯´éƒ½æ˜¯è¿™ä¹ˆåšçš„ï¼Œå› ä¸ºæ²¡é“ç†åœ¨ä¸€ä¸ªæ ¸å‡½æ•°è¿˜æ²¡å¹²å®Œçš„æ—¶å€™è®©å®ƒåœä¸‹æ¥å»è°ƒåº¦å…¶ä»–çš„æ ¸å‡½æ•°ã€‚</p> 
<p>stream ä¹‹é—´è¿˜å¯ä»¥è®¾ç½®ä¸åŒçš„ä¼˜å…ˆçº§ï¼Œå¦‚æœä¸¤ä¸ªåœ¨ä¸åŒä¼˜å…ˆçº§ stream é‡Œçš„æ ¸å‡½æ•°éƒ½æœ‰æœºä¼šè¢« CWD è°ƒåº¦ï¼Œé‚£ä¹ˆ CWD ä¼šä¼˜å…ˆè°ƒåº¦åœ¨ä¼˜å…ˆçº§æ¯”è¾ƒé«˜çš„é‚£ä¸ª stream é‡Œçš„æ ¸å‡½æ•°ã€‚æ³¨æ„è¿™æ˜¯è°ƒåº¦æ—¶å€™å°±æœ‰çš„è¡Œä¸ºï¼Œè€Œä¸æ˜¯é«˜ä¼˜å…ˆçº§ kernel æŠ¢å äº†ä½ä¼˜å…ˆçº§ kernel çš„æ‰§è¡Œã€‚ä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="prism language-cpp"><span class="token keyword">int</span> priority_high<span class="token punctuation">,</span> priority_low<span class="token punctuation">;</span>
<span class="token function">cudaDeviceGetStreamPriorityRange</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>priority_low<span class="token punctuation">,</span> $priority_high<span class="token punctuation">)</span><span class="token punctuation">;</span>
cudaStream_t st_high<span class="token punctuation">,</span> st_low<span class="token punctuation">;</span>
<span class="token function">cudaStreamCreateWithPriority</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>st_high<span class="token punctuation">,</span> cudaStreamNonBlocking<span class="token punctuation">,</span> priority_high<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaStreamCreateWithPriority</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>st_low<span class="token punctuation">,</span> cudaStreamNonBlocking<span class="token punctuation">,</span> priority_low<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>å’Œ stream æœ‰å…³çš„è¯é¢˜æ˜¯ cuda graphï¼Œè¿™ä¸ªæ˜¯åœ¨ cuda 10 å¼€å§‹çš„ç‰¹æ€§ã€‚å…è®¸ä¸€ä¸ª stream é‡Œæ‰€æœ‰æ“ä½œï¼ˆæ ¸å‡½æ•°ï¼Œå†…å­˜æ‹·è´ï¼Œstream å›è°ƒï¼Œç”šè‡³æ˜¯å…¶ä»– cuda graphï¼‰ç»„ç»‡æˆå›¾çš„å½¢å¼ã€‚æ¯é¡¹æ“ä½œéƒ½æ˜¯å›¾é‡Œçš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿™æ ·å°±å¯ä»¥è‡ªå®šä¹‰æ“ä½œï¼ˆèŠ‚ç‚¹ï¼‰ä¹‹é—´çš„ä¾èµ–æ€§ã€‚ä¸€æ—¦åˆ›å»ºæˆå›¾ï¼Œåé¢å¯ä»¥å¤šæ¬¡è°ƒç”¨ï¼Œä¸éœ€è¦ cpu çš„å‚ä¸ã€‚ä¸»è¦æ˜¯ç”¨æ¥å‡å°‘ cpu ç«¯å¼€å¯è¿™äº›å·¥ä½œé¡¹çš„å¼€é”€ã€‚cuda graph å¯ä»¥æ‰‹åŠ¨å»ºå›¾ï¼Œä¹Ÿå¯ä»¥æ•è·ä¸€ä¸ªå›¾ã€‚æ³¨æ„æ•è·çš„æ—¶å€™åªæ˜¯æ•è·ï¼Œå¹¶æ²¡æœ‰å®é™…åœ°å»è°ƒç”¨è¿™äº›å‡½æ•°ã€‚</p> 
<h3><a id="7_Profiler_989"></a>7. Profileré©±åŠ¨çš„ä¼˜åŒ–</h3> 
<blockquote> 
 <p>è¿™èŠ‚è¯¾ç¨‹æ›´åå‘å®æˆ˜ï¼Œå»ºè®®å¤§å®¶è§‚çœ‹è§†é¢‘</p> 
</blockquote> 
<p>NVIDIA å®˜æ–¹å…³äº Nsight Compute å·¥å…·è¿›è¡Œæ ¸å‡½æ•°æ€§èƒ½ä¼˜åŒ–çš„ä¸‰ç¯‡ç³»åˆ—åšå®¢ï¼š</p> 
<ul><li> <p><a href="https://developer.nvidia.com/blog/analysis-driven-optimization-preparing-for-analysis-with-nvidia-nsight-compute-part-1/" rel="nofollow">Analysis-Driven Optimization: Preparing for Analysis with NVIDIA Nsight Compute, Part 1</a></p> </li><li> <p><a href="https://developer.nvidia.com/blog/analysis-driven-optimization-analyzing-and-improving-performance-with-nvidia-nsight-compute-part-2/" rel="nofollow">Analysis-Driven Optimization: Analyzing and Improving Performance with NVIDIA Nsight Compute, Part 2</a></p> </li><li> <p><a href="https://developer.nvidia.com/blog/analysis-driven-optimization-finishing-the-analysis-with-nvidia-nsight-compute-part-3/" rel="nofollow">Analysis-Driven Optimization: Finishing the Analysis with NVIDIA Nsight Compute, Part 3</a></p> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2627e54bd604b405a455ed1f0537446/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">å¤§æ¨¡å‹é•œåƒæ‰“åŒ…å®æˆ˜:CodeGeeX2ä¸ºä¾‹</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/237d49f9e80ebcf54ddd876809e63192/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">YOLOv8-OBBæ¨ç†è¯¦è§£åŠéƒ¨ç½²å®ç°</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>