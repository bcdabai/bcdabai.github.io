<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>入门推荐系统——Wide&amp;Deep - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="入门推荐系统——Wide&amp;Deep" />
<meta property="og:description" content="1.点击率预估简介 点击率预估用来解决什么问题？
点击率预估是对每次广告点击情况作出预测，输出点击或者不点击，也可以输出该次点击的概率，有时后者称为pClick。
点击率预估模型需要做什么？
通过点击率预估的基本概念，发现其实点击率预估问题是一个二分类问题，在机器学习中，使用逻辑回归作为模型的输出，其输出的是一个概率值，将机器学习输出的概率认为是某个用户点击某个广告的概率。
点击率和推荐算法有什么不同？
广告点击率预估是需要得到某个用户对某个广告的点击率，然后结合广告的出价排序。
推荐算法大多数只需要得到一个最优的推荐次序，即TopN推荐。
也可利用广告的点击率来排序，作为广告的推荐。
2.为什么不用FM，要用Wide&amp;Deep？ FM缺点：当query-item矩阵是稀疏并且是high-rank的时候（比如user有特殊的爱好，或item比较小众），很难非常效率的学习出低维度的表示。这种情况下，大部分的query-item都没有什么关系。但是dense embedding会导致几乎所有的query-item预测值都是非0的，这就导致了推荐过度泛化，会推荐一些不那么相关的物品。
相反，简单的linear model却可以通过cross-product transformation来记住这些exception rules，cross-product transformation。
3.Wide &amp; Deep模型的“记忆能力”与“泛化能力” Memorization 和 Generalization是推荐系统很常见的两个概念，其中Memorization指的是通过用户与商品的交互信息矩阵学习规则，而Generalization则是泛化规则。
FM算法就是很好的Generalization的例子，它可以根据交互信息学习到一个比较短的矩阵 V V V，其中 v i v_{i} vi​储存着每个用户特征的压缩表示（embedding），而协同过滤与SVD都是靠记住用户之前与哪些物品发生了交互从而推断出的推荐结果，这两者推荐结果当然存在一些差异，我们的Wide&amp;Deep模型就能够融合这两种推荐结果做出最终的推荐，得到一个比之前的推荐结果都好的模型。
Memorization趋向于更加保守，推荐用户之前有过行为的items。相比之下，generalization更加趋向于提高推荐系统的多样性（diversity）。Memorization只需要使用一个线性模型即可实现，而Generalization需要使用DNN实现。
下面是wide&amp;deep模型的结构图，由左边的wide部分(一个简单的线性模型)，右边的deep部分(一个典型的DNN模型)。
其实wide&amp;deep模型本身的结构是非常简单的，对于有点机器学习基础和深度学习基础的人来说都非常的容易看懂，但是如何根据自己的场景去选择那些特征放在Wide部分，哪些特征放在Deep部分就需要理解这篇论文提出者当时对于设计该模型不同结构时的意图了，所以这也是用好这个模型的一个前提。
如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？
wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交互特征(cross-product transformation)，对于交互特征可以定义为： ϕ k ( x ) = ∏ i = 1 d x i c k i , c k i ∈ 0 , 1 \phi_{k}(x)=\prod_{i=1}^d x_i^{c_{ki}}, c_{ki}\in {0,1} ϕk​(x)=i=1∏d​xicki​​,cki​∈0,1
式子自行查找原论文理解
大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：
AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9cc11172e7993e2e75d6c19ba9e76a53/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-10-27T22:02:50+08:00" />
<meta property="article:modified_time" content="2020-10-27T22:02:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">入门推荐系统——Wide&amp;Deep</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1_0"></a>1.点击率预估简介</h2> 
<p><strong>点击率预估用来解决什么问题？</strong><br> 点击率预估是对每次广告点击情况作出预测，输出点击或者不点击，也可以输出该次点击的概率，有时后者称为pClick。</p> 
<p><strong>点击率预估模型需要做什么？</strong><br> 通过点击率预估的基本概念，发现其实点击率预估问题是一个<strong>二分类问题</strong>，在机器学习中，使用逻辑回归作为模型的输出，其输出的是一个概率值，将机器学习输出的概率认为是某个用户点击某个广告的概率。</p> 
<p><strong>点击率和推荐算法有什么不同？</strong><br> 广告点击率预估是需要得到某个用户对某个广告的点击率，然后结合广告的出价排序。<br> 推荐算法大多数只需要得到一个最优的推荐次序，即TopN推荐。<br> 也可利用广告的点击率来排序，作为广告的推荐。</p> 
<h2><a id="2FMWideDeep_12"></a>2.为什么不用FM，要用Wide&amp;Deep？</h2> 
<p>FM缺点：当query-item矩阵是稀疏并且是high-rank的时候（比如user有特殊的爱好，或item比较小众），很难非常效率的学习出低维度的表示。这种情况下，大部分的query-item都没有什么关系。但是dense embedding会导致几乎所有的query-item预测值都是非0的，这就导致了推荐过度泛化，会推荐一些不那么相关的物品。<br> 相反，简单的linear model却可以通过cross-product transformation来记住这些exception rules，cross-product transformation。</p> 
<h2><a id="3Wide__Deep_16"></a>3.Wide &amp; Deep模型的“记忆能力”与“泛化能力”</h2> 
<p>Memorization 和 Generalization是推荐系统很常见的两个概念，其中Memorization指的是通过用户与商品的交互信息矩阵学习规则，而Generalization则是泛化规则。<br> FM算法就是很好的Generalization的例子，它可以根据交互信息学习到一个比较短的矩阵<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         V 
        
       
      
        V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">V</span></span></span></span></span>，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          v 
         
        
          i 
         
        
       
      
        v_{i} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>储存着每个用户特征的压缩表示（embedding），而协同过滤与SVD都是靠记住用户之前与哪些物品发生了交互从而推断出的推荐结果，这两者推荐结果当然存在一些差异，我们的Wide&amp;Deep模型就能够融合这两种推荐结果做出最终的推荐，得到一个比之前的推荐结果都好的模型。</p> 
<p>Memorization趋向于更加保守，推荐用户之前有过行为的items。相比之下，generalization更加趋向于提高推荐系统的多样性（diversity）。Memorization只需要使用一个线性模型即可实现，而Generalization需要使用DNN实现。</p> 
<p>下面是wide&amp;deep模型的结构图，由左边的wide部分(一个简单的线性模型)，右边的deep部分(一个典型的DNN模型)。<br> <img src="https://images2.imgbox.com/cc/61/aCIPj2St_o.png" alt="W&amp;D"><br> 其实wide&amp;deep模型本身的结构是非常简单的，对于有点机器学习基础和深度学习基础的人来说都非常的容易看懂，但是如何<strong>根据自己的场景去选择那些特征放在Wide部分，哪些特征放在Deep部分</strong>就需要理解这篇论文提出者当时对于设计该模型不同结构时的意图了，所以这也是用好这个模型的一个前提。</p> 
<p><strong>如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？</strong></p> 
<ul><li> <p>wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交互特征(cross-product transformation)，对于交互特征可以定义为： <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             ϕ 
            
           
             k 
            
           
          
            ( 
           
          
            x 
           
          
            ) 
           
          
            = 
           
           
           
             ∏ 
            
            
            
              i 
             
            
              = 
             
            
              1 
             
            
           
             d 
            
           
           
           
             x 
            
           
             i 
            
            
            
              c 
             
             
             
               k 
              
             
               i 
              
             
            
           
          
            , 
           
           
           
             c 
            
            
            
              k 
             
            
              i 
             
            
           
          
            ∈ 
           
           
           
             0 
            
           
             , 
            
           
             1 
            
           
          
         
           \phi_{k}(x)=\prod_{i=1}^d x_i^{c_{ki}}, c_{ki}\in {0,1} 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathdefault">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 3.11378em; vertical-align: -1.27767em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.83611em;"><span class="" style="top: -1.87233em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05001em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∏</span></span></span><span class="" style="top: -4.30001em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.752052em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.15066em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.34877em; margin-left: 0em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.151229em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.83888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">1</span></span></span></span></span></span></span></p> 
  <blockquote> 
   <p>式子自行查找原论文理解</p> 
  </blockquote> <p>大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：</p> </li></ul> 
<blockquote> 
 <p>AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。</p> 
</blockquote> 
<p>wide部分训练时候使用的优化器是带<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          1 
         
        
       
      
        L_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTLR是非常注重模型稀疏性质的，也就是说W&amp;D模型采用L1 FTRL是想让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。<strong>Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力</strong></p> 
<blockquote> 
 <p>例如Google W&amp;D期望wide部分发现这样的规则：用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。</p> 
</blockquote> 
<ul><li>Deep部分是一个DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，Deep部分的数学形式如下： <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
       
        
         
          
          
            a 
           
           
           
             ( 
            
           
             l 
            
           
             + 
            
           
             1 
            
           
             ) 
            
           
          
         
           = 
          
         
           f 
          
         
           ( 
          
          
          
            W 
           
          
            l 
           
          
          
          
            a 
           
           
           
             ( 
            
           
             l 
            
           
             ) 
            
           
          
         
           + 
          
          
          
            b 
           
          
            l 
           
          
         
           ) 
          
         
        
          a^{(l+1)} = f(W^{l}a^{(l)} + b^{l}) 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.938em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.14911em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span> **我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。**对于Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。</li></ul> 
<blockquote> 
 <p>AdaGrad</p> 
</blockquote> 
<p>Wide部分与Deep部分的结合<br> W&amp;D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。<br> 联合训练的数学形式如下： <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
        
          Y 
         
        
          = 
         
        
          1 
         
        
          ∣ 
         
        
          x 
         
        
          ) 
         
        
          = 
         
        
          δ 
         
        
          ( 
         
         
         
           w 
          
          
          
            w 
           
          
            i 
           
          
            d 
           
          
            e 
           
          
         
           T 
          
         
        
          [ 
         
        
          x 
         
        
          , 
         
        
          ϕ 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          ] 
         
        
          + 
         
         
         
           w 
          
          
          
            d 
           
          
            e 
           
          
            e 
           
          
            p 
           
          
         
           T 
          
         
         
         
           a 
          
          
          
            ( 
           
          
            l 
           
          
            f 
           
          
            ) 
           
          
         
        
          + 
         
        
          b 
         
        
          ) 
         
        
       
         P(Y=1|x)=\delta(w_{wide}^T[x,\phi(x)] + w_{deep}^T a^{(lf)} + b) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.14133em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.03785em;">δ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.891331em;"><span class="" style="top: -2.453em; margin-left: -0.02691em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.02691em;">w</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">ϕ</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.32111em; vertical-align: -0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.891331em;"><span class="" style="top: -2.453em; margin-left: -0.02691em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault mtight" style="margin-right: 0.10764em;">f</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span></span></span></p> 
<h2><a id="4_48"></a>4.操作流程</h2> 
<ul><li><strong>Retrieval</strong>：利用机器学习模型和一些人为定义的规则，来返回最匹配当前Query的一个小的items集合，这个集合就是最终的推荐列表的候选集。</li><li>Ranking： 
  <ul><li>收集更细致的用户特征，如： 
    <ul><li>User features（年龄、性别、语言、民族等）</li><li>Contextual features(上下文特征：设备，时间等)</li><li>Impression features（展示特征：app age、app的历史统计信息等）</li></ul> </li><li>将特征分别传入Wide和Deep一起做训练。<br> 在训练的时候，根据最终的loss计算出gradient，反向传播到Wide和Deep两部分中，分别训练自己的参数（wide组件只需要填补deep组件的不足就行了，所以需要比较少的cross-product feature transformations，而不是full-size wide Model） 
    <ul><li>训练方法是用mini-batch stochastic optimization。</li><li>Wide组件是用FTRL（Follow-the-regularized-leader） + L1正则化学习。</li><li>Deep组件是用AdaGrad来学习。</li></ul> </li><li>训练完之后推荐TopN</li></ul> </li></ul> 
<p>wide&amp;deep模型尽管在模型结构上非常的简单，但是如果想要很好的使用wide&amp;deep模型的话，还是要<strong>深入理解业务，确定wide部分使用哪部分特征，deep部分使用哪些特征，以及wide部分的交叉特征应该如何去选择</strong>。</p> 
<h2><a id="5_64"></a>5.代码实现</h2> 
<p>主要分为两大部分，第一部分是使用tensorflow中已经封装好的wide&amp;deep模型，这一部分主要是熟悉模型训练的整体结构。第二部分是使用tensorflow中的keras实现wide&amp;deep，这一部分主要是尽可能的看到模型内部的细节并将其实现。</p> 
<blockquote> 
 <p>wide部分用哪些特征，deep部分使用哪些特征，以及wide部分的交叉特征应该如何去选择，需要深入学习<br> <strong>未跑</strong></p> 
</blockquote> 
<h3><a id="TensorflowWideDeepModel_70"></a>Tensorflow内置的WideDeepModel</h3> 
<p>在Tensorflow的库中是已经内置了Wide-Deep model的，想要查看源代码了解具体实现过程可以看<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/premade/wide_deep.py#L34-L219">这里</a>。下面参考<a href="https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel" rel="nofollow">Tensorflow官网的示例代码</a>进行讲解。我们用到的数据集下载链接<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/" rel="nofollow">戳这里</a>。</p> 
<p>全局实现：</p> 
<pre><code class="prism language-python">tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>WideDeepModel<span class="token punctuation">(</span>
    linear_model<span class="token punctuation">,</span> dnn_model<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs
<span class="token punctuation">)</span>
</code></pre> 
<p>上面这一步是将linear_model与dnn_model拼接在了一起，对应于Wide-Deep FM中的最后一步。</p> 
<p>我们可以将linear_model与dnn_model做一个最简单的实现：</p> 
<pre><code class="prism language-python">linear_model <span class="token operator">=</span> LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
dnn_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                             keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
combined_model <span class="token operator">=</span> WideDeepModel<span class="token punctuation">(</span>linear_model<span class="token punctuation">,</span> dnn_model<span class="token punctuation">)</span>
combined_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sgd'</span><span class="token punctuation">,</span> <span class="token string">'adam'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'mse'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'mse'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># define dnn_inputs and linear_inputs as separate numpy arrays or</span>
<span class="token comment"># a single numpy array if dnn_inputs is same as linear_inputs.</span>
combined_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>linear_inputs<span class="token punctuation">,</span> dnn_inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
<span class="token comment"># or define a single `tf.data.Dataset` that contains a single tensor or</span>
<span class="token comment"># separate tensors for dnn_inputs and linear_inputs.</span>
dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensors<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">[</span>linear_inputs<span class="token punctuation">,</span> dnn_inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
combined_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
</code></pre> 
<p>上面代码中，第一步直接调用一个keras.experimental中的linear_model，第二步简单实现了一个全连接神经网络，第三步使用WideDeepModel将前两步产生的两个model拼接在一起，形成最终的combined_model，接着就是常规的compile和fit了。</p> 
<p>除此之外线性模型与DNN模型在<strong>联合训练之前</strong>均可进行分别训练：</p> 
<pre><code class="prism language-python">linear_model <span class="token operator">=</span> LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
linear_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'adagrad'</span><span class="token punctuation">,</span> <span class="token string">'mse'</span><span class="token punctuation">)</span>
linear_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>linear_inputs<span class="token punctuation">,</span> y<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
dnn_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dnn_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'rmsprop'</span><span class="token punctuation">,</span> <span class="token string">'mse'</span><span class="token punctuation">)</span>
dnn_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>dnn_inputs<span class="token punctuation">,</span> y<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
combined_model <span class="token operator">=</span> WideDeepModel<span class="token punctuation">(</span>linear_model<span class="token punctuation">,</span> dnn_model<span class="token punctuation">)</span>
combined_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sgd'</span><span class="token punctuation">,</span> <span class="token string">'adam'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'mse'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'mse'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
combined_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>linear_inputs<span class="token punctuation">,</span> dnn_inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
</code></pre> 
<p>上面的前三行代码训练了一个线性模型，中间三行代码训练了一个DNN模型，最后三行代码则将两个模型联合训练，以上就完成了对Tensorflow的WideDeepModel的调用，其中每个函数有一些其他参数我们这里不详细说明，读者若有需要可自行在tensorflow官网查询，另外该部分的源代码在Tensorflow的Github上有展示，<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/premade/wide_deep.py#L34-L219">链接在这</a></p> 
<h3><a id="Tensorflowwidedeep_115"></a>Tensorflow实现wide&amp;deep模型</h3> 
<p>这一部分对原始特征进行转换，以及deep特征和wide特征的选择，特征的交叉等一系列特征操作，模型也分成了wide部分和deep部分，相比于上述直接使用tensorflow内置的模型,更加的详细，可以对模型理解的更加的深刻。</p> 
<p>在这里wide和deep部分的优化，为了简单实现，使用了同一个优化器优化两部分,详细内容参考代码中的注释。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> warnings
<span class="token keyword">import</span> random<span class="token punctuation">,</span> math<span class="token punctuation">,</span> os
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>regularizers <span class="token keyword">import</span> l2<span class="token punctuation">,</span> l1_l2

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoder<span class="token punctuation">,</span> MinMaxScaler<span class="token punctuation">,</span> StandardScaler<span class="token punctuation">,</span> LabelEncoder

<span class="token comment"># 读取数据，并将标签做简单的转换</span>
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    COLUMNS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"age"</span><span class="token punctuation">,</span> <span class="token string">"workclass"</span><span class="token punctuation">,</span> <span class="token string">"fnlwgt"</span><span class="token punctuation">,</span> <span class="token string">"education"</span><span class="token punctuation">,</span> <span class="token string">"education_num"</span><span class="token punctuation">,</span>
               <span class="token string">"marital_status"</span><span class="token punctuation">,</span> <span class="token string">"occupation"</span><span class="token punctuation">,</span> <span class="token string">"relationship"</span><span class="token punctuation">,</span> <span class="token string">"race"</span><span class="token punctuation">,</span> <span class="token string">"gender"</span><span class="token punctuation">,</span>
               <span class="token string">"capital_gain"</span><span class="token punctuation">,</span> <span class="token string">"capital_loss"</span><span class="token punctuation">,</span> <span class="token string">"hours_per_week"</span><span class="token punctuation">,</span> <span class="token string">"native_country"</span><span class="token punctuation">,</span>
               <span class="token string">"income_bracket"</span><span class="token punctuation">]</span>

    df_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/adult_train.csv"</span><span class="token punctuation">,</span> names<span class="token operator">=</span>COLUMNS<span class="token punctuation">)</span>
    df_test <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/adult_test.csv"</span><span class="token punctuation">,</span> names<span class="token operator">=</span>COLUMNS<span class="token punctuation">)</span>

    df_train<span class="token punctuation">[</span><span class="token string">'income_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"income_bracket"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">"&gt;50K"</span> <span class="token keyword">in</span> x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
    df_test<span class="token punctuation">[</span><span class="token string">'income_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">"income_bracket"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">"&gt;50K"</span> <span class="token keyword">in</span> x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> df_train<span class="token punctuation">,</span> df_test


<span class="token comment"># 特征处理分为wide部分的特征处理和deep部分的特征处理</span>
<span class="token keyword">def</span> <span class="token function">data_process</span><span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 年龄特征离散化</span>
    age_groups <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">]</span>
    age_labels <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>age_groups<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>
    df_train<span class="token punctuation">[</span><span class="token string">'age_group'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> age_groups<span class="token punctuation">,</span> labels<span class="token operator">=</span>age_labels<span class="token punctuation">)</span>
    df_test<span class="token punctuation">[</span><span class="token string">'age_group'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> age_groups<span class="token punctuation">,</span> labels<span class="token operator">=</span>age_labels<span class="token punctuation">)</span>

    <span class="token comment"># wide部分的原始特征及交叉特征</span>
    wide_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'workclass'</span><span class="token punctuation">,</span> <span class="token string">'education'</span><span class="token punctuation">,</span> <span class="token string">'marital_status'</span><span class="token punctuation">,</span> <span class="token string">'occupation'</span><span class="token punctuation">,</span> \
                 <span class="token string">'relationship'</span><span class="token punctuation">,</span> <span class="token string">'race'</span><span class="token punctuation">,</span> <span class="token string">'gender'</span><span class="token punctuation">,</span> <span class="token string">'native_country'</span><span class="token punctuation">,</span> <span class="token string">'age_group'</span><span class="token punctuation">]</span>
    x_cols <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'education'</span><span class="token punctuation">,</span> <span class="token string">'occupation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'native_country'</span><span class="token punctuation">,</span> <span class="token string">'occupation'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># deep部分的特征分为两大类，一类是数值特征(可以直接输入到网络中进行训练)，</span>
    <span class="token comment"># 一类是类别特征(只能在embedding之后才能输入到模型中进行训练）</span>
    embedding_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'workclass'</span><span class="token punctuation">,</span> <span class="token string">'education'</span><span class="token punctuation">,</span> <span class="token string">'marital_status'</span><span class="token punctuation">,</span> <span class="token string">'occupation'</span><span class="token punctuation">,</span> \
                      <span class="token string">'relationship'</span><span class="token punctuation">,</span> <span class="token string">'race'</span><span class="token punctuation">,</span> <span class="token string">'gender'</span><span class="token punctuation">,</span> <span class="token string">'native_country'</span><span class="token punctuation">]</span>
    cont_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'capital_gain'</span><span class="token punctuation">,</span> <span class="token string">'capital_loss'</span><span class="token punctuation">,</span> <span class="token string">'hours_per_week'</span><span class="token punctuation">]</span>

    <span class="token comment"># 类别标签</span>
    target <span class="token operator">=</span> <span class="token string">'income_label'</span>

    <span class="token keyword">return</span> df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span> cont_cols<span class="token punctuation">,</span> target


<span class="token keyword">def</span> <span class="token function">process_wide_feats</span><span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 合并训练和测试数据，后续一起编码</span>
    df_train<span class="token punctuation">[</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    df_test<span class="token punctuation">[</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    df_wide <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 选出wide部分特征中的类别特征, 类别特征在DataFrame中是object类型</span>
    categorical_columns <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>df_wide<span class="token punctuation">.</span>select_dtypes<span class="token punctuation">(</span>include<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>columns<span class="token punctuation">)</span> 

    <span class="token comment"># 构造交叉特征</span>
    crossed_columns_d <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> f1<span class="token punctuation">,</span> f2 <span class="token keyword">in</span> x_cols<span class="token punctuation">:</span>
        col_name <span class="token operator">=</span> f1 <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> f2
        crossed_columns_d<span class="token punctuation">.</span>append<span class="token punctuation">(</span>col_name<span class="token punctuation">)</span>
        df_wide<span class="token punctuation">[</span>col_name<span class="token punctuation">]</span> <span class="token operator">=</span> df_wide<span class="token punctuation">[</span><span class="token punctuation">[</span>f1<span class="token punctuation">,</span> f2<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">'-'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># wide部分的所有特征</span>
    wide_cols <span class="token operator">+=</span> crossed_columns_d
    df_wide <span class="token operator">=</span> df_wide<span class="token punctuation">[</span>wide_cols <span class="token operator">+</span> <span class="token punctuation">[</span>target<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    <span class="token comment"># 将wide部分类别特征进行onehot编码</span>
    dummy_cols <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> wide_cols <span class="token keyword">if</span> c <span class="token keyword">in</span> categorical_columns <span class="token operator">+</span> crossed_columns_d<span class="token punctuation">]</span>
    df_wide <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>df_wide<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> dummy_cols<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 将训练数据和测试数据分离</span>
    train <span class="token operator">=</span> df_wide<span class="token punctuation">[</span>df_wide<span class="token punctuation">.</span>IS_TRAIN <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test <span class="token operator">=</span> df_wide<span class="token punctuation">[</span>df_wide<span class="token punctuation">.</span>IS_TRAIN <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    cols <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> train<span class="token punctuation">.</span>columns <span class="token keyword">if</span> c <span class="token operator">!=</span> target<span class="token punctuation">]</span>
    X_train <span class="token operator">=</span> train<span class="token punctuation">[</span>cols<span class="token punctuation">]</span><span class="token punctuation">.</span>values
    y_train <span class="token operator">=</span> train<span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    X_test <span class="token operator">=</span> test<span class="token punctuation">[</span>cols<span class="token punctuation">]</span><span class="token punctuation">.</span>values
    y_test <span class="token operator">=</span> test<span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_test


<span class="token keyword">def</span> <span class="token function">process_deep_feats</span><span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span> cont_cols<span class="token punctuation">,</span> target<span class="token punctuation">,</span> emb_dim<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> emb_reg<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 标记训练和测试集，方便特征处理完之后进行训练和测试集的分离</span>
    df_train<span class="token punctuation">[</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    df_test<span class="token punctuation">[</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    df_deep <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 拼接数值特征和embedding特征</span>
    deep_cols <span class="token operator">=</span> embedding_cols <span class="token operator">+</span> cont_cols
    df_deep <span class="token operator">=</span> df_deep<span class="token punctuation">[</span>deep_cols <span class="token operator">+</span> <span class="token punctuation">[</span>target<span class="token punctuation">,</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    <span class="token comment"># 数值类特征进行标准化</span>
    scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    df_deep<span class="token punctuation">[</span>cont_cols<span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span>cont_cols<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns<span class="token operator">=</span>cont_cols<span class="token punctuation">)</span>

    <span class="token comment"># 类边特征编码</span>
    unique_vals <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    lbe <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> feats <span class="token keyword">in</span> embedding_cols<span class="token punctuation">:</span>
        df_deep<span class="token punctuation">[</span>feats<span class="token punctuation">]</span> <span class="token operator">=</span> lbe<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_deep<span class="token punctuation">[</span>feats<span class="token punctuation">]</span><span class="token punctuation">)</span>
        unique_vals<span class="token punctuation">[</span>feats<span class="token punctuation">]</span> <span class="token operator">=</span> df_deep<span class="token punctuation">[</span>feats<span class="token punctuation">]</span><span class="token punctuation">.</span>nunique<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 构造模型的输入层，和embedding层，虽然对于连续的特征没有embedding层，但是为了统一，将Reshape层</span>
    <span class="token comment"># 当成是连续特征的embedding层</span>
    inp_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    emb_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ec <span class="token keyword">in</span> embedding_cols<span class="token punctuation">:</span>
        layer_name <span class="token operator">=</span> ec <span class="token operator">+</span> <span class="token string">'_inp'</span>
        inp <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">,</span> name<span class="token operator">=</span>layer_name<span class="token punctuation">)</span>
        emb <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>unique_vals<span class="token punctuation">[</span>ec<span class="token punctuation">]</span><span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> embeddings_regularizer<span class="token operator">=</span>l2<span class="token punctuation">(</span>emb_reg<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inp<span class="token punctuation">)</span>
        inp_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>inp<span class="token punctuation">)</span>
        emb_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>inp<span class="token punctuation">)</span>

    <span class="token keyword">for</span> cc <span class="token keyword">in</span> cont_cols<span class="token punctuation">:</span>
        layer_name <span class="token operator">=</span> cc <span class="token operator">+</span> <span class="token string">'_inp'</span>
        inp <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">,</span> name<span class="token operator">=</span>layer_name<span class="token punctuation">)</span>
        emb <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inp<span class="token punctuation">)</span>
        inp_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>inp<span class="token punctuation">)</span>
        emb_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>inp<span class="token punctuation">)</span>

    <span class="token comment"># 训练和测试集分离</span>
    train <span class="token operator">=</span> df_deep<span class="token punctuation">[</span>df_deep<span class="token punctuation">.</span>IS_TRAIN <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    test <span class="token operator">=</span> df_deep<span class="token punctuation">[</span>df_deep<span class="token punctuation">.</span>IS_TRAIN <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'IS_TRAIN'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># 提取训练和测试集中的特征</span>
    X_train <span class="token operator">=</span> <span class="token punctuation">[</span>train<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> deep_cols<span class="token punctuation">]</span>
    y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    X_test <span class="token operator">=</span> <span class="token punctuation">[</span>test<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> deep_cols<span class="token punctuation">]</span>
    y_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test<span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> emb_layer<span class="token punctuation">,</span> inp_layer


<span class="token keyword">def</span> <span class="token function">wide_deep</span><span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span> cont_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># wide部分特征处理</span>
    X_train_wide<span class="token punctuation">,</span> y_train_wide<span class="token punctuation">,</span> X_test_wide<span class="token punctuation">,</span> y_test_wide <span class="token operator">=</span> \
        process_wide_feats<span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

    <span class="token comment"># deep部分特征处理</span>
    X_train_deep<span class="token punctuation">,</span> y_train_deep<span class="token punctuation">,</span> X_test_deep<span class="token punctuation">,</span> y_test_deep<span class="token punctuation">,</span> deep_inp_embed<span class="token punctuation">,</span> deep_inp_layer <span class="token operator">=</span> \
        process_deep_feats<span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span>cont_cols<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

    <span class="token comment"># wide特征与deep特征拼接</span>
    X_tr_wd <span class="token operator">=</span> <span class="token punctuation">[</span>X_train_wide<span class="token punctuation">]</span> <span class="token operator">+</span> X_train_deep
    Y_tr_wd <span class="token operator">=</span> y_train_deep  <span class="token comment"># wide部分和deep部分的label是一样的</span>
    X_te_wd <span class="token operator">=</span> <span class="token punctuation">[</span>X_test_wide<span class="token punctuation">]</span> <span class="token operator">+</span> X_test_deep
    Y_te_wd <span class="token operator">=</span> y_test_deep  <span class="token comment"># wide部分和deep部分的label是一样的</span>

    <span class="token comment"># wide部分的输入</span>
    w <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>X_train_wide<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'wide'</span><span class="token punctuation">)</span>

    <span class="token comment"># deep部分的NN结构</span>
    d <span class="token operator">=</span> concatenate<span class="token punctuation">(</span>deep_inp_embed<span class="token punctuation">)</span>
    d <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    d <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>l1_l2<span class="token punctuation">(</span>l1<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> l2<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    d <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    d <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'deep'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    d <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>

    <span class="token comment"># 将wide部分与deep部分的输入进行拼接, 然后输入一个线性层</span>
    wd_inp <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> d<span class="token punctuation">]</span><span class="token punctuation">)</span>
    wd_out <span class="token operator">=</span> Dense<span class="token punctuation">(</span>Y_tr_wd<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'wide_deep'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>wd_inp<span class="token punctuation">)</span> 
    
    <span class="token comment"># 构建模型，这里需要注意模型的输入部分是由wide和deep部分组成的</span>
    wide_deep <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">+</span> deep_inp_layer<span class="token punctuation">,</span> outputs<span class="token operator">=</span>wd_out<span class="token punctuation">)</span>
    wide_deep<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'AUC'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 设置模型学习率，不设置学习率keras默认的学习率是0.01</span>
    wide_deep<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>lr <span class="token operator">=</span> <span class="token number">0.001</span>

    <span class="token comment"># 模型训练</span>
    wide_deep<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_tr_wd<span class="token punctuation">,</span> Y_tr_wd<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

    <span class="token comment"># 模型预测及验证</span>
    results <span class="token operator">=</span> wide_deep<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>X_te_wd<span class="token punctuation">,</span> Y_te_wd<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> results<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取数据</span>
    df_train<span class="token punctuation">,</span> df_test <span class="token operator">=</span> get_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 特征处理</span>
    df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span> cont_cols<span class="token punctuation">,</span> target <span class="token operator">=</span> data_process<span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">)</span>

    <span class="token comment"># 模型训练</span>
    wide_deep<span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> wide_cols<span class="token punctuation">,</span> x_cols<span class="token punctuation">,</span> embedding_cols<span class="token punctuation">,</span> cont_cols<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="6_324"></a>6.深度学习推荐系统的发展</h2> 
<p>Wide&amp;Deep模型在深度学习发展中起到了非常重要的作用，从下图中我们就可以看到它对后续模型发展的一个影响。<br> <img src="https://images2.imgbox.com/fc/e3/AVny24Wz_o.png" alt="模型发展"></p> 
<h2><a id="7_328"></a>7.思考</h2> 
<p>Wide&amp;Deep模型仍然存在哪些不足，阵对这些不足工程师们有哪些改进？</p> 
<h2><a id="8_331"></a>8.参考</h2> 
<ul><li><a href="https://blog.csdn.net/u010352603/article/details/80590129">翻译很到位的博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/142958834" rel="nofollow">见微知著，你真的搞懂Google的Wide&amp;Deep模型了吗？</a></li><li><a href="https://fuhailin.github.io/Wide-Deep/" rel="nofollow">推荐系统CTR实战——Wide&amp;Deep</a></li><li><a href="https://zhuanlan.zhihu.com/p/47293765" rel="nofollow">看Google如何实现Wide&amp;Deep模型（1）</a></li><li><a href="https://zhuanlan.zhihu.com/p/53110408" rel="nofollow">用NumPy手工打造Wide&amp;Deep</a></li><li><a href="https://arxiv.org/pdf/1606.07792.pdf" rel="nofollow">论文原文</a></li><li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel" rel="nofollow">Tensorflow官网的WideDeeoModel</a></li><li><a href="https://github.com/shenweichen/DeepCTR">deepctr项目</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b33ea42dbe328d08d8895f3dc76909b1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">win10麦克风说话没声音_电脑版微信，语音通话无声音的解决</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/92a05d2394f1b745574a718cf50f1140/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">一套开源免费的 SpringBoot &#43;Layui通用后台管理系统 ！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>