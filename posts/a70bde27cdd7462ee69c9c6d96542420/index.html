<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>64个热门图像分类数据集免费、高速资源分享，涵盖通用视觉、食物、艺术、医疗等多种场景 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="64个热门图像分类数据集免费、高速资源分享，涵盖通用视觉、食物、艺术、医疗等多种场景" />
<meta property="og:description" content="小伙伴们期待已久的数据集资源盘点系列又来啦~
本期将分享64个图像分类任务相关的热门公开数据集资源，粗略分了10类：
● 通用视觉类；● 手写体&amp;单通道类；● 细粒度图像识别类；● 自然界图像和场景类；● 遥感类；● 医疗健康类；● 科学教育类；● 艺术类；● 食物类；● 生活场景类。
快来看看有没有你想要的吧。
如果觉得不错的话，记得收藏。更多资源，欢迎访问OpenDataLab官网：https://opendatalab.org.cn/
目录
一、通用视觉类
No.1 CIFAR-10
No.2 CIFAR-100
No.3 STL-10
No.4 PASCAL VOC2007
No.5 PASCAL VOC2012
No.6 ImageNet-P
No.7 ImageNet-Sketch
No.8 ObjectNet
No.9 Open Images V4
No.10 ImageNet-21k
No.11 ImageNet-O
No.12 DEIC Benchmark (Data-Efficient Image Classification Benchmark)
No.13 OmniBenchmark
No.14 Caltech-256
No.15 CIFAR-10N (Real-World Human Annotations)
No.16 CIFAR-100N (Real-World Human Annotations)
二、手写体&amp;单通道类
No.17 MNIST
No.18 Fashion-MNIST" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/a70bde27cdd7462ee69c9c6d96542420/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-02T11:10:50+08:00" />
<meta property="article:modified_time" content="2022-12-02T11:10:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">64个热门图像分类数据集免费、高速资源分享，涵盖通用视觉、食物、艺术、医疗等多种场景</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>小伙伴们期待已久的数据集资源盘点系列又来啦~</p> 
<p></p> 
<p>本期将分享64个图像分类任务相关的热门公开数据集资源，粗略分了10类：</p> 
<p><strong>● 通用视觉类；● 手写体&amp;单通道类；● 细粒度图像识别类；● 自然界图像和场景类；● 遥感类；● 医疗健康类；● 科学教育类；● 艺术类；● 食物类；● 生活场景类</strong>。</p> 
<p>快来看看有没有你想要的吧。</p> 
<p></p> 
<p>如果觉得不错的话，记得收藏。更多资源，欢迎访问OpenDataLab官网：<a class="link-info" href="https://opendatalab.org.cn/?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/">https://opendatalab.org.cn/</a></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E9%80%9A%E7%94%A8%E8%A7%86%E8%A7%89%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E9%80%9A%E7%94%A8%E8%A7%86%E8%A7%89%E7%B1%BB" rel="nofollow">一、通用视觉类</a></p> 
<p id="No.1%20%C2%A0CIFAR-10-toc" style="margin-left:40px;"><a href="#No.1%20%C2%A0CIFAR-10" rel="nofollow">No.1  CIFAR-10</a></p> 
<p id="No.2%20%C2%A0CIFAR-100-toc" style="margin-left:40px;"><a href="#No.2%20%C2%A0CIFAR-100" rel="nofollow">No.2  CIFAR-100</a></p> 
<p id="No.3%20%C2%A0STL-10-toc" style="margin-left:40px;"><a href="#No.3%20%C2%A0STL-10" rel="nofollow">No.3  STL-10</a></p> 
<p id="No.4%20%C2%A0PASCAL%20VOC2007-toc" style="margin-left:40px;"><a href="#No.4%20%C2%A0PASCAL%20VOC2007" rel="nofollow">No.4  PASCAL VOC2007</a></p> 
<p id="No.5%20%C2%A0PASCAL%20VOC2012-toc" style="margin-left:40px;"><a href="#No.5%20%C2%A0PASCAL%20VOC2012" rel="nofollow">No.5  PASCAL VOC2012</a></p> 
<p id="No.6%20%C2%A0ImageNet-P-toc" style="margin-left:40px;"><a href="#No.6%20%C2%A0ImageNet-P" rel="nofollow">No.6  ImageNet-P</a></p> 
<p id="No.7%20%C2%A0ImageNet-Sketch-toc" style="margin-left:40px;"><a href="#No.7%20%C2%A0ImageNet-Sketch" rel="nofollow">No.7  ImageNet-Sketch</a></p> 
<p id="No.8%20%C2%A0ObjectNet-toc" style="margin-left:40px;"><a href="#No.8%20%C2%A0ObjectNet" rel="nofollow">No.8  ObjectNet</a></p> 
<p id="No.9%20%C2%A0Open%20Images%20V4-toc" style="margin-left:40px;"><a href="#No.9%20%C2%A0Open%20Images%20V4" rel="nofollow">No.9  Open Images V4</a></p> 
<p id="No.10%20%C2%A0ImageNet-21k-toc" style="margin-left:40px;"><a href="#No.10%20%C2%A0ImageNet-21k" rel="nofollow">No.10  ImageNet-21k</a></p> 
<p id="No.11%20%C2%A0ImageNet-O-toc" style="margin-left:40px;"><a href="#No.11%20%C2%A0ImageNet-O" rel="nofollow">No.11  ImageNet-O</a></p> 
<p id="No.12%20%C2%A0DEIC%20Benchmark%20(Data-Efficient%20Image%20Classification%20Benchmark)-toc" style="margin-left:40px;"><a href="#No.12%20%C2%A0DEIC%20Benchmark%20%28Data-Efficient%20Image%20Classification%20Benchmark%29" rel="nofollow">No.12  DEIC Benchmark (Data-Efficient Image Classification Benchmark)</a></p> 
<p id="No.13%20%C2%A0OmniBenchmark-toc" style="margin-left:40px;"><a href="#No.13%20%C2%A0OmniBenchmark" rel="nofollow">No.13  OmniBenchmark</a></p> 
<p id="No.14%C2%A0%C2%A0Caltech-256-toc" style="margin-left:40px;"><a href="#No.14%C2%A0%C2%A0Caltech-256" rel="nofollow">No.14  Caltech-256</a></p> 
<p id="No.15%20%C2%A0CIFAR-10N%20(Real-World%20Human%20Annotations)-toc" style="margin-left:40px;"><a href="#No.15%20%C2%A0CIFAR-10N%20%28Real-World%20Human%20Annotations%29" rel="nofollow">No.15  CIFAR-10N (Real-World Human Annotations)</a></p> 
<p id="No.16%20%C2%A0CIFAR-100N%20(Real-World%20Human%20Annotations)-toc" style="margin-left:40px;"><a href="#No.16%20%C2%A0CIFAR-100N%20%28Real-World%20Human%20Annotations%29" rel="nofollow">No.16  CIFAR-100N (Real-World Human Annotations)</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%89%8B%E5%86%99%E4%BD%93%26%E5%8D%95%E9%80%9A%E9%81%93%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%89%8B%E5%86%99%E4%BD%93%26%E5%8D%95%E9%80%9A%E9%81%93%E7%B1%BB" rel="nofollow">二、手写体&amp;单通道类</a></p> 
<p id="No.17%20%C2%A0MNIST-toc" style="margin-left:40px;"><a href="#No.17%20%C2%A0MNIST" rel="nofollow">No.17  MNIST</a></p> 
<p id="No.18%20%C2%A0Fashion-MNIST-toc" style="margin-left:40px;"><a href="#No.18%20%C2%A0Fashion-MNIST" rel="nofollow">No.18  Fashion-MNIST</a></p> 
<p id="No.19%20%C2%A0MultiMNIST-toc" style="margin-left:40px;"><a href="#No.19%20%C2%A0MultiMNIST" rel="nofollow">No.19  MultiMNIST</a></p> 
<p id="No.20%20%C2%A0EMNIST%20(Extended%20MNIST)-toc" style="margin-left:40px;"><a href="#No.20%20%C2%A0EMNIST%20%28Extended%20MNIST%29" rel="nofollow">No.20  EMNIST (Extended MNIST)</a></p> 
<p id="No.21%20%C2%A0Kuzushiji-49-toc" style="margin-left:40px;"><a href="#No.21%20%C2%A0Kuzushiji-49" rel="nofollow">No.21  Kuzushiji-49</a></p> 
<p id="No.22%20%C2%A0Kuzushiji-Kanji-toc" style="margin-left:40px;"><a href="#No.22%20%C2%A0Kuzushiji-Kanji" rel="nofollow">No.22  Kuzushiji-Kanji</a></p> 
<p id="%E4%B8%89%E3%80%81%E7%BB%86%E7%B2%92%E5%BA%A6%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E7%BB%86%E7%B2%92%E5%BA%A6%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%B1%BB" rel="nofollow">三、细粒度图像识别类</a></p> 
<p id="No.23%20%C2%A0SUN%20Attribute-toc" style="margin-left:40px;"><a href="#No.23%20%C2%A0SUN%20Attribute" rel="nofollow">No.23  SUN Attribute</a></p> 
<p id="No.24%20%C2%A0Oxford-IIIT%20Pet-toc" style="margin-left:40px;"><a href="#No.24%20%C2%A0Oxford-IIIT%20Pet" rel="nofollow">No.24  Oxford-IIIT Pet</a></p> 
<p id="No.25%20%C2%A0FGVC%20Aircraft-toc" style="margin-left:40px;"><a href="#No.25%20%C2%A0FGVC%20Aircraft" rel="nofollow">No.25  FGVC Aircraft</a></p> 
<p id="No.26%20%C2%A0DTD%20(Describable%20Textures%20Dataset)-toc" style="margin-left:40px;"><a href="#No.26%20%C2%A0DTD%20%28Describable%20Textures%20Dataset%29" rel="nofollow">No.26  DTD (Describable Textures Dataset)</a></p> 
<p id="No.27%20%C2%A0CUB-200-2011-toc" style="margin-left:40px;"><a href="#No.27%20%C2%A0CUB-200-2011" rel="nofollow">No.27  CUB-200-2011</a></p> 
<p id="%E5%9B%9B%E3%80%81%E8%87%AA%E7%84%B6%E7%95%8C%E5%9B%BE%E5%83%8F%E5%92%8C%E5%9C%BA%E6%99%AF%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E8%87%AA%E7%84%B6%E7%95%8C%E5%9B%BE%E5%83%8F%E5%92%8C%E5%9C%BA%E6%99%AF%E7%B1%BB" rel="nofollow">四、自然界图像和场景类</a></p> 
<p id="No.28%20%C2%A0IP102-toc" style="margin-left:40px;"><a href="#No.28%20%C2%A0IP102" rel="nofollow">No.28  IP102</a></p> 
<p id="No.29%20%C2%A0Places365-toc" style="margin-left:40px;"><a href="#No.29%20%C2%A0Places365" rel="nofollow">No.29  Places365</a></p> 
<p id="No.30%20%C2%A0Imagenette-toc" style="margin-left:40px;"><a href="#No.30%20%C2%A0Imagenette" rel="nofollow">No.30  Imagenette</a></p> 
<p id="No.31%20%C2%A0AIDER-toc" style="margin-left:40px;"><a href="#No.31%20%C2%A0AIDER" rel="nofollow">No.31  AIDER</a></p> 
<p id="No.32%20%C2%A0DeepFish-toc" style="margin-left:40px;"><a href="#No.32%20%C2%A0DeepFish" rel="nofollow">No.32  DeepFish</a></p> 
<p id="No.33%20%C2%A0iNaturalist2021-toc" style="margin-left:40px;"><a href="#No.33%20%C2%A0iNaturalist2021" rel="nofollow">No.33  iNaturalist2021</a></p> 
<p id="%E4%BA%94%E3%80%81%E9%81%A5%E6%84%9F%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E9%81%A5%E6%84%9F%E7%B1%BB" rel="nofollow">五、遥感类</a></p> 
<p id="No.34%20%C2%A0EuroSAT-toc" style="margin-left:40px;"><a href="#No.34%20%C2%A0EuroSAT" rel="nofollow">No.34  EuroSAT</a></p> 
<p id="No.35%20%C2%A0BigEarthNet-toc" style="margin-left:40px;"><a href="#No.35%20%C2%A0BigEarthNet" rel="nofollow">No.35  BigEarthNet</a></p> 
<p id="No.36%20%C2%A0So2Sat%20LCZ42-toc" style="margin-left:40px;"><a href="#No.36%20%C2%A0So2Sat%20LCZ42" rel="nofollow">No.36  So2Sat LCZ42</a></p> 
<p id="No.37%20%C2%A0MLRSNet-toc" style="margin-left:40px;"><a href="#No.37%20%C2%A0MLRSNet" rel="nofollow">No.37  MLRSNet</a></p> 
<p id="No.38%20df2k_ost-toc" style="margin-left:40px;"><a href="#No.38%20df2k_ost" rel="nofollow">No.38 df2k_ost</a></p> 
<p id="No.39%20%C2%A0Million-AID-toc" style="margin-left:40px;"><a href="#No.39%20%C2%A0Million-AID" rel="nofollow">No.39  Million-AID</a></p> 
<p id="%E5%85%AD%E3%80%81%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7%E7%B1%BB" rel="nofollow">六、医疗健康类</a></p> 
<p id="No.40%20%C2%A0HErlev%20(HErlev%20Pap%20Smear%20Dataset)-toc" style="margin-left:40px;"><a href="#No.40%20%C2%A0HErlev%20%28HErlev%20Pap%20Smear%20Dataset%29" rel="nofollow">No.40  HErlev (HErlev Pap Smear Dataset)</a></p> 
<p id="No.41%C2%A0%C2%A0BBBC041%20(P.%20vivax%20(malaria)%20infected%20human%20blood%20smears)-toc" style="margin-left:40px;"><a href="#No.41%C2%A0%C2%A0BBBC041%20%28P.%20vivax%20%28malaria%29%20infected%20human%20blood%20smears%29" rel="nofollow">No.41  BBBC041 (P. vivax (malaria) infected human blood smears)</a></p> 
<p id="No.42%C2%A0%C2%A0Chest-Xray8%20(COVID-19)-toc" style="margin-left:40px;"><a href="#No.42%C2%A0%C2%A0Chest-Xray8%20%28COVID-19%29" rel="nofollow">No.42  Chest-Xray8 (COVID-19)</a></p> 
<p id="%E4%B8%83%E3%80%81%E7%A7%91%E5%AD%A6%E6%95%99%E8%82%B2%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%B8%83%E3%80%81%E7%A7%91%E5%AD%A6%E6%95%99%E8%82%B2%E7%B1%BB" rel="nofollow">七、科学教育类</a></p> 
<p id="No.43%C2%A0%C2%A0PlantVillage-toc" style="margin-left:40px;"><a href="#No.43%C2%A0%C2%A0PlantVillage" rel="nofollow">No.43  PlantVillage</a></p> 
<p id="No.44%C2%A0%C2%A0PlantDoc-toc" style="margin-left:40px;"><a href="#No.44%C2%A0%C2%A0PlantDoc" rel="nofollow">No.44  PlantDoc</a></p> 
<p id="No.45%C2%A0%C2%A0AI2D%20(AI2%20Diagrams)-toc" style="margin-left:40px;"><a href="#No.45%C2%A0%C2%A0AI2D%20%28AI2%20Diagrams%29" rel="nofollow">No.45  AI2D (AI2 Diagrams)</a></p> 
<p id="No.46%C2%A0%C2%A0ANIMAL%20(ANIMAL-10N)-toc" style="margin-left:40px;"><a href="#No.46%C2%A0%C2%A0ANIMAL%20%28ANIMAL-10N%29" rel="nofollow">No.46  ANIMAL (ANIMAL-10N)</a></p> 
<p id="No.47%C2%A0%C2%A0FruitsAndVegetables-toc" style="margin-left:40px;"><a href="#No.47%C2%A0%C2%A0FruitsAndVegetables" rel="nofollow">No.47  FruitsAndVegetables</a></p> 
<p id="%E5%85%AB%E3%80%81%E8%89%BA%E6%9C%AF%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E5%85%AB%E3%80%81%E8%89%BA%E6%9C%AF%E7%B1%BB" rel="nofollow">八、艺术类</a></p> 
<p id="No.48%C2%A0%C2%A0iCartoonFace-toc" style="margin-left:40px;"><a href="#No.48%C2%A0%C2%A0iCartoonFace" rel="nofollow">No.48  iCartoonFace</a></p> 
<p id="No.49%C2%A0%C2%A0KaoKore-toc" style="margin-left:40px;"><a href="#No.49%C2%A0%C2%A0KaoKore" rel="nofollow">No.49  KaoKore</a></p> 
<p id="No.50%C2%A0%C2%A0MAMe%20(Museum%20Art%20Medium%20dataset)-toc" style="margin-left:40px;"><a href="#No.50%C2%A0%C2%A0MAMe%20%28Museum%20Art%20Medium%20dataset%29" rel="nofollow">No.50  MAMe (Museum Art Medium dataset)</a></p> 
<p id="No.51%C2%A0%C2%A0ArtDL-toc" style="margin-left:40px;"><a href="#No.51%C2%A0%C2%A0ArtDL" rel="nofollow">No.51  ArtDL</a></p> 
<p id="%E4%B9%9D%E3%80%81%E9%A3%9F%E7%89%A9%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%B9%9D%E3%80%81%E9%A3%9F%E7%89%A9%E7%B1%BB" rel="nofollow">九、食物类</a></p> 
<p id="No.52%C2%A0%C2%A0Food-101-toc" style="margin-left:40px;"><a href="#No.52%C2%A0%C2%A0Food-101" rel="nofollow">No.52  Food-101</a></p> 
<p id="No.53%C2%A0%C2%A0ECUSTFD%20(ECUST%20Food%20Dataset)-toc" style="margin-left:40px;"><a href="#No.53%C2%A0%C2%A0ECUSTFD%20%28ECUST%20Food%20Dataset%29" rel="nofollow">No.53  ECUSTFD (ECUST Food Dataset)</a></p> 
<p id="No.54%C2%A0%C2%A0ChineseFoodNet-toc" style="margin-left:40px;"><a href="#No.54%C2%A0%C2%A0ChineseFoodNet" rel="nofollow">No.54  ChineseFoodNet</a></p> 
<p id="No.55%C2%A0%C2%A0THFOOD-50%20(Thai%20Food%2050%20Image%20Classification)-toc" style="margin-left:40px;"><a href="#No.55%C2%A0%C2%A0THFOOD-50%20%28Thai%20Food%2050%20Image%20Classification%29" rel="nofollow">No.55  THFOOD-50 (Thai Food 50 Image Classification)</a></p> 
<p id="No.56%C2%A0%C2%A0KenyanFood13-toc" style="margin-left:40px;"><a href="#No.56%C2%A0%C2%A0KenyanFood13" rel="nofollow">No.56  KenyanFood13</a></p> 
<p id="No.57%C2%A0%C2%A0MyFood%20Dataset-toc" style="margin-left:40px;"><a href="#No.57%C2%A0%C2%A0MyFood%20Dataset" rel="nofollow">No.57  MyFood Dataset</a></p> 
<p id="%E5%8D%81%E3%80%81%E7%94%9F%E6%B4%BB%E5%9C%BA%E6%99%AF%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E5%8D%81%E3%80%81%E7%94%9F%E6%B4%BB%E5%9C%BA%E6%99%AF%E7%B1%BB" rel="nofollow">十、生活场景类</a></p> 
<p id="No.58%C2%A0%C2%A0SVHN-toc" style="margin-left:40px;"><a href="#No.58%C2%A0%C2%A0SVHN" rel="nofollow">No.58  SVHN</a></p> 
<p id="No.59%C2%A0%C2%A0Clothing1M-toc" style="margin-left:40px;"><a href="#No.59%C2%A0%C2%A0Clothing1M" rel="nofollow">No.59  Clothing1M</a></p> 
<p id="No.60%C2%A0%C2%A0Stanford%20Online%20Products-toc" style="margin-left:40px;"><a href="#No.60%C2%A0%C2%A0Stanford%20Online%20Products" rel="nofollow">No.60  Stanford Online Products</a></p> 
<p id="No.61%C2%A0%C2%A0Grocery%20Store-toc" style="margin-left:40px;"><a href="#No.61%C2%A0%C2%A0Grocery%20Store" rel="nofollow">No.61  Grocery Store</a></p> 
<p id="No.62%C2%A0%C2%A0ARC-100-toc" style="margin-left:40px;"><a href="#No.62%C2%A0%C2%A0ARC-100" rel="nofollow">No.62  ARC-100</a></p> 
<p id="No.63%C2%A0%C2%A0FoodLogoDet-1500-toc" style="margin-left:40px;"><a href="#No.63%C2%A0%C2%A0FoodLogoDet-1500" rel="nofollow">No.63  FoodLogoDet-1500</a></p> 
<p id="No.64%C2%A0%20Icon645-toc" style="margin-left:40px;"><a href="#No.64%C2%A0%20Icon645" rel="nofollow">No.64  Icon645</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E9%80%9A%E7%94%A8%E8%A7%86%E8%A7%89%E7%B1%BB"><strong><strong><strong><strong>一、通用视觉类</strong></strong></strong></strong></h2> 
<h3 id="No.1%20%C2%A0CIFAR-10"><em><strong><strong>No.1 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/CIFAR-10?source=Y3Nkbg%3D%3D" rel="nofollow" title="CIFAR-10">CIFAR-10</a></strong></h3> 
<p>● <strong>发布方</strong>：麻省理工学院 · 纽约大学</p> 
<p>● <strong>发布时间</strong>：2009</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/CIFAR-10?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/CIFAR-10">https://opendatalab.org.cn/CIFAR-10</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别、十个类别</p> 
<p></p> 
<h3 id="No.2%20%C2%A0CIFAR-100"><em><strong><strong>No.2 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/CIFAR-100?source=Y3Nkbg%3D%3D" rel="nofollow" title="CIFAR-100">CIFAR-100</a></strong></h3> 
<p>● <strong>发布方</strong>：麻省理工学院 · 纽约大学</p> 
<p>● <strong>发布时间</strong>：2009</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/CIFAR-100?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/CIFAR-100">https://opendatalab.org.cn/CIFAR-100</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别、一百个类别</p> 
<p></p> 
<h3 id="No.3%20%C2%A0STL-10"><em><strong><strong>No.3 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/STL-10?source=Y3Nkbg%3D%3D" rel="nofollow" title="STL-10">STL-10</a></strong></h3> 
<p>● <strong>发布方</strong>：斯坦福大学 · 密歇根大学</p> 
<p>● <strong>发布时间</strong>：2011</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/STL-10?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/STL-10">https://opendatalab.org.cn/STL-10</a></p> 
<p>● <strong>关键词</strong>：广泛用于无监督特征学习算法评估</p> 
<p></p> 
<h3 id="No.4%20%C2%A0PASCAL%20VOC2007"><em><strong><strong>No.4 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/PASCAL_VOC2007?source=Y3Nkbg%3D%3D" rel="nofollow" title="PASCAL VOC2007">PASCAL VOC2007</a></strong></h3> 
<p>● <strong>发布方</strong>：牛津大学 · 微软剑桥研究院 · 利兹大学</p> 
<p>● <strong>发布时间</strong>：2007</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/PASCAL_VOC2007?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/PASCAL_VOC2007">https://opendatalab.org.cn/PASCAL_VOC2007</a></p> 
<p>● <strong>关键词</strong>：目标检测</p> 
<p></p> 
<h3 id="No.5%20%C2%A0PASCAL%20VOC2012"><em><strong><strong>No.5 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/PASCAL_VOC2012?source=Y3Nkbg%3D%3D" rel="nofollow" title="PASCAL VOC2012">PASCAL VOC2012</a></strong></h3> 
<p>● <strong>发布方</strong>：牛津大学 · 利兹大学 · 微软剑桥研究院</p> 
<p>● <strong>发布时间</strong>：2012</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/PASCAL_VOC2012?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/PASCAL_VOC2012">https://opendatalab.org.cn/PASCAL_VOC2012</a></p> 
<p>● <strong>关键词</strong>：目标检测</p> 
<p></p> 
<h3 id="No.6%20%C2%A0ImageNet-P"><em><strong><strong>No.6 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ImageNet-P?source=Y3Nkbg%3D%3D" rel="nofollow" title="ImageNet-P">ImageNet-P</a></strong></h3> 
<p>● <strong>发布方</strong>：加州大学 · 俄勒冈州立大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ImageNet-P?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ImageNet-P">https://opendatalab.org.cn/ImageNet-P</a></p> 
<p>● <strong>关键词</strong>：由噪声、模糊、天气和数字失真组成</p> 
<p></p> 
<h3 id="No.7%20%C2%A0ImageNet-Sketch"><em><strong><strong>No.7 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ImageNet-Sketch?source=Y3Nkbg%3D%3D" rel="nofollow" title="ImageNet-Sketch">ImageNet-Sketch</a></strong></h3> 
<p>● <strong>发布方</strong>：卡内基梅隆大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ImageNet-Sketch?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ImageNet-Sketch">https://opendatalab.org.cn/ImageNet-Sketch</a></p> 
<p>● <strong>关键词</strong>：黑白线稿草图</p> 
<p></p> 
<h3 id="No.8%20%C2%A0ObjectNet"><em><strong><strong>No.8 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ObjectNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="ObjectNet">ObjectNet</a></strong></h3> 
<p>● <strong>发布方</strong>：麻省理工学院</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ObjectNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ObjectNet">https://opendatalab.org.cn/ObjectNet</a></p> 
<p>● <strong>关键词</strong>：无监督图像分类</p> 
<p></p> 
<h3 id="No.9%20%C2%A0Open%20Images%20V4"><em><strong><strong>No.9 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Open_Images_V4?source=Y3Nkbg%3D%3D" rel="nofollow" title="Open Images V4">Open Images V4</a></strong></h3> 
<p>● <strong>发布方</strong>：Google Research</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Open_Images_V4?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Open_Images_V4">https://opendatalab.org.cn/Open_Images_V4</a></p> 
<p>● <strong>关键词</strong>：大规模图像分类数据集、单图多标签标注</p> 
<p></p> 
<h3 id="No.10%20%C2%A0ImageNet-21k"><em><strong><strong>No.10 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ImageNet-21k?source=Y3Nkbg%3D%3D" rel="nofollow" title="ImageNet-21k">ImageNet-21k</a></strong></h3> 
<p>● <strong>发布方</strong>：斯坦福大学 · 普林斯顿大学 · 北卡罗来纳大学教堂山分校 · Facebook · Shopagon</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ImageNet-21k?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ImageNet-21k">https://opendatalab.org.cn/ImageNet-21k</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别</p> 
<p></p> 
<h3 id="No.11%20%C2%A0ImageNet-O"><em><strong><strong>No.11 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ImageNet-O?source=Y3Nkbg%3D%3D" rel="nofollow" title="ImageNet-O">ImageNet-O</a></strong></h3> 
<p>● <strong>发布方</strong>：加州大学伯克利分校 · 华盛顿大学 · 芝加哥大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ImageNet-O?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ImageNet-O">https://opendatalab.org.cn/ImageNet-O</a></p> 
<p>● <strong>关键词</strong>：包含来自 ImageNet-1k 数据集中没有的类的图像，用于测试视觉模型对分布外样本的鲁棒性</p> 
<p></p> 
<h3 id="No.12%20%C2%A0DEIC%20Benchmark%20(Data-Efficient%20Image%20Classification%20Benchmark)"><em><strong><strong>No.12 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/DEIC_Benchmark?source=Y3Nkbg%3D%3D" rel="nofollow" title="DEIC Benchmark (Data-Efficient Image Classification Benchmark)">DEIC Benchmark (Data-Efficient Image Classification Benchmark)</a></strong></h3> 
<p>● <strong>发布方</strong>：罗马大学 · 耶拿大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/DEIC_Benchmark?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/DEIC_Benchmark">https://opendatalab.org.cn/DEIC_Benchmark</a></p> 
<p>● <strong>关键词</strong>：由6个数据集组成、涵盖多个图像领域和数据类型</p> 
<p></p> 
<h3 id="No.13%20%C2%A0OmniBenchmark"><em><strong><strong>No.13 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/OmniBenchmark?source=Y3Nkbg%3D%3D" rel="nofollow" title="OmniBenchmark">OmniBenchmark</a></strong></h3> 
<p>● <strong>发布方</strong>：商汤科技研究所 · 南洋理工大学实验室</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/OmniBenchmark?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/OmniBenchmark">https://opendatalab.org.cn/OmniBenchmark</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别、覆盖大多数视觉领域</p> 
<p></p> 
<h3 id="No.14%C2%A0%C2%A0Caltech-256"><em><strong><strong>No.14<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Caltech-256?source=Y3Nkbg%3D%3D" rel="nofollow" title="Caltech-256">Caltech-256</a></strong></h3> 
<p>● <strong>发布方</strong>：加州理工学院</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Caltech-256?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Caltech-256">https://opendatalab.org.cn/Caltech-256</a></p> 
<p>● <strong>关键词</strong>：图像物体识别</p> 
<p></p> 
<h3 id="No.15%20%C2%A0CIFAR-10N%20(Real-World%20Human%20Annotations)"><em><strong><strong>No.15 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/CIFAR-10N?source=Y3Nkbg%3D%3D" rel="nofollow" title="CIFAR-10N (Real-World Human Annotations)">CIFAR-10N (Real-World Human Annotations)</a></strong></h3> 
<p>● <strong>发布方</strong>：加州大学 · 悉尼大学 · 日本理化学研究所先进智能研究中心</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/CIFAR-10N?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/CIFAR-10N">https://opendatalab.org.cn/CIFAR-10N</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别、加入真实世界噪声标签</p> 
<p></p> 
<h3 id="No.16%20%C2%A0CIFAR-100N%20(Real-World%20Human%20Annotations)"><em><strong><strong>No.16 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/CIFAR-100N?source=Y3Nkbg%3D%3D" rel="nofollow" title="CIFAR-100N (Real-World Human Annotations)">CIFAR-100N (Real-World Human Annotations)</a></strong></h3> 
<p>● <strong>发布方</strong>：加州大学 · 悉尼大学</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/CIFAR-100N?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/CIFAR-100N">https://opendatalab.org.cn/CIFAR-100N</a></p> 
<p>● <strong>关键词</strong>：通用视觉对象识别、加入真实世界噪声标签</p> 
<p></p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%89%8B%E5%86%99%E4%BD%93%26%E5%8D%95%E9%80%9A%E9%81%93%E7%B1%BB"><strong>二、手写体&amp;单通道类</strong></h2> 
<h3 id="No.17%20%C2%A0MNIST"><em><strong><strong>No.17 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/MNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="MNIST">MNIST</a></strong></h3> 
<p>● <strong>发布方</strong>：纽约大学 · Google · 微软</p> 
<p>● <strong>发布时间</strong>：1998</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/MNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/MNIST">https://opendatalab.org.cn/MNIST</a></p> 
<p>● <strong>关键词</strong>：手写数字识别</p> 
<p></p> 
<h3 id="No.18%20%C2%A0Fashion-MNIST"><em><strong><strong>No.18 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Fashion-MNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="Fashion-MNIST">Fashion-MNIST</a></strong></h3> 
<p>● <strong>发布方</strong>：Zalando Research</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Fashion-MNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Fashion-MNIST">https://opendatalab.org.cn/Fashion-MNIST</a></p> 
<p>● <strong>关键词</strong>：服装分类、十个类别</p> 
<p></p> 
<h3 id="No.19%20%C2%A0MultiMNIST"><em><strong><strong>No.19 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/MultiMNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="MultiMNIST">MultiMNIST</a></strong></h3> 
<p>● <strong>发布方</strong>：Google</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/MultiMNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/MultiMNIST">https://opendatalab.org.cn/MultiMNIST</a></p> 
<p>● <strong>关键词</strong>：手写字母识别、数字叠加、重叠</p> 
<p></p> 
<h3 id="No.20%20%C2%A0EMNIST%20(Extended%20MNIST)"><em><strong><strong>No.20 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/EMNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="EMNIST (Extended MNIST)">EMNIST (Extended MNIST)</a></strong></h3> 
<p>● <strong>发布方</strong>：西悉尼大学</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/EMNIST?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/EMNIST">https://opendatalab.org.cn/EMNIST</a></p> 
<p>● <strong>关键词</strong>：手写字母识别、细粒度图像分类</p> 
<p></p> 
<h3 id="No.21%20%C2%A0Kuzushiji-49"><em><strong><strong>No.21 </strong> </strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Kuzushiji-49?source=Y3Nkbg%3D%3D" rel="nofollow" title="Kuzushiji-49">Kuzushiji-49</a></strong></h3> 
<p>● <strong>发布方</strong>：ROIS-DS Center for Open Data in the Humanities · 吉尔福德皇家文法学校 · 国立日本文学研究所 · Mila – Quebec Artifcial Intelligence Institute · Google AI Research</p> 
<p>● <strong>发布时间</strong>：2018</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Kuzushiji-49?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Kuzushiji-49">https://opendatalab.org.cn/Kuzushiji-49</a></p> 
<p>● <strong>关键词</strong>：手写字符识别、日语假名</p> 
<p></p> 
<h3 id="No.22%20%C2%A0Kuzushiji-Kanji"><em><strong><strong>No.22<em><strong><strong> </strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Kuzushiji-Kanji?source=Y3Nkbg%3D%3D" rel="nofollow" title="Kuzushiji-Kanji">Kuzushiji-Kanji</a></strong></h3> 
<p>● <strong>发布方</strong>：ROIS-DS Center for Open Data in the Humanities · 吉尔福德皇家文法学校 · 国立日本文学研究所 · Mila – Quebec Artifcial Intelligence Institute · Google AI Research</p> 
<p>● <strong>发布时间</strong>：2018</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Kuzushiji-Kanji?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Kuzushiji-Kanji">https://opendatalab.org.cn/Kuzushiji-Kanji</a></p> 
<p>● <strong>关键词</strong>：手写字符识别、日本汉字草书风格</p> 
<p></p> 
<h2 id="%E4%B8%89%E3%80%81%E7%BB%86%E7%B2%92%E5%BA%A6%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%B1%BB"><strong>三、细粒度图像识别类</strong></h2> 
<h3 id="No.23%20%C2%A0SUN%20Attribute"><em><strong><strong>No.23 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/SUN_Attribute?source=Y3Nkbg%3D%3D" rel="nofollow" title="SUN Attribute">SUN Attribute</a></strong></h3> 
<p>● <strong>发布方</strong>：海斯实验室</p> 
<p>● <strong>发布时间</strong>：2011</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/SUN_Attribute?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/SUN_Attribute">https://opendatalab.org.cn/SUN_Attribute</a></p> 
<p>● <strong>关键词</strong>：细粒度场景识别、高级场景理解</p> 
<p></p> 
<h3 id="No.24%20%C2%A0Oxford-IIIT%20Pet"><em><strong><strong>No.24 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Oxford-IIIT_Pets?source=Y3Nkbg%3D%3D" rel="nofollow" title="Oxford-IIIT Pet">Oxford-IIIT Pet</a></strong></h3> 
<p>● <strong>发布方</strong>：牛津大学</p> 
<p>● <strong>发布时间</strong>：2012</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Oxford-IIIT_Pets?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Oxford-IIIT_Pets">https://opendatalab.org.cn/Oxford-IIIT_Pets</a></p> 
<p>● <strong>关键词</strong>：细粒度图像分类、图像压缩</p> 
<p></p> 
<h3 id="No.25%20%C2%A0FGVC%20Aircraft"><em><strong><strong>No.25 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/FGVC_Aircraft?source=Y3Nkbg%3D%3D" rel="nofollow" title="FGVC Aircraft">FGVC Aircraft</a></strong></h3> 
<p>● <strong>发布方</strong>：奥卢大学 · TTI, Inc. · 巴黎中央学校 · 牛津大学</p> 
<p>● <strong>发布时间</strong>：2013</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/FGVC_Aircraft?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/FGVC_Aircraft">https://opendatalab.org.cn/FGVC_Aircraft</a></p> 
<p>● <strong>关键词</strong>：细粒度视觉分类、飞机图像</p> 
<p></p> 
<h3 id="No.26%20%C2%A0DTD%20(Describable%20Textures%20Dataset)"><em><strong><strong>No.26 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/DTD?source=Y3Nkbg%3D%3D" rel="nofollow" title="DTD (Describable Textures Dataset)">DTD (Describable Textures Dataset)</a></strong></h3> 
<p>● <strong>发布方</strong>：牛津大学 · Toyota Technological Institute · 巴黎中央学校 · 石溪大学</p> 
<p>● <strong>发布时间</strong>：2014</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/DTD?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/DTD">https://opendatalab.org.cn/DTD</a></p> 
<p>● <strong>关键词</strong>：纹理分类</p> 
<p></p> 
<h3 id="No.27%20%C2%A0CUB-200-2011"><em><strong><strong>No.27 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/CUB-200-2011?source=Y3Nkbg%3D%3D" rel="nofollow" title="CUB-200-2011">CUB-200-2011</a></strong></h3> 
<p>● <strong>发布方</strong>：Allan Lab</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/CUB-200-2011?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/CUB-200-2011">https://opendatalab.org.cn/CUB-200-2011</a></p> 
<p>● <strong>关键词</strong>：细粒度图像分类、局部区域定位、鸟类</p> 
<p></p> 
<h2 id="%E5%9B%9B%E3%80%81%E8%87%AA%E7%84%B6%E7%95%8C%E5%9B%BE%E5%83%8F%E5%92%8C%E5%9C%BA%E6%99%AF%E7%B1%BB"><strong>四、自然界图像和场景类</strong></h2> 
<h3 id="No.28%20%C2%A0IP102"><em><strong><strong>No.28 <em><strong> </strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/IP102?source=Y3Nkbg%3D%3D" rel="nofollow" title="IP102">IP102</a></strong></h3> 
<p>● <strong>发布方</strong>：南开大学计算机学院 · 卡迪夫大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/IP102?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/IP102">https://opendatalab.org.cn/IP102</a></p> 
<p>● <strong>关键词</strong>：自然界图像、呈现自然的长尾发布</p> 
<p></p> 
<h3 id="No.29%20%C2%A0Places365"><em><strong><strong>No.29<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Places365?source=Y3Nkbg%3D%3D" rel="nofollow" title="Places365">Places365</a></strong></h3> 
<p>● <strong>发布方</strong>：马德里自治大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Places365?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Places365">https://opendatalab.org.cn/Places365</a></p> 
<p>● <strong>关键词</strong>：图像分类、场景识别</p> 
<p></p> 
<h3 id="No.30%20%C2%A0Imagenette"><em><strong><strong>No.30<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Imagenette?source=Y3Nkbg%3D%3D" rel="nofollow" title="Imagenette">Imagenette</a></strong></h3> 
<p>● <strong>发布方</strong>：旧金山大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Imagenette?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Imagenette">https://opendatalab.org.cn/Imagenette</a></p> 
<p>● <strong>关键词</strong>： Imagenet 中 10 个易于分类的类别的子集（板凳、英语弹跳器、磁带播放器、链锯、教堂、圆号、垃圾车、加油站、高尔夫球、降落伞）</p> 
<p></p> 
<h3 id="No.31%20%C2%A0AIDER"><em><strong><strong>No.31<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/AIDER?source=Y3Nkbg%3D%3D" rel="nofollow" title="AIDER">AIDER</a></strong></h3> 
<p>● <strong>发布方</strong>：塞浦路斯大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/AIDER?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/AIDER">https://opendatalab.org.cn/AIDER</a></p> 
<p>● <strong>关键词</strong>：无人机视角、灾难事件、空中场景分类</p> 
<p></p> 
<h3 id="No.32%20%C2%A0DeepFish"><em><strong><strong>No.32<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/DeepFish?source=Y3Nkbg%3D%3D" rel="nofollow" title="DeepFish">DeepFish</a></strong></h3> 
<p>● <strong>发布方</strong>：詹姆斯库克大学 · 不列颠哥伦比亚大学 · Element AI</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/DeepFish?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/DeepFish">https://opendatalab.org.cn/DeepFish</a></p> 
<p>● <strong>关键词</strong>：热带海洋环境、水下鱼监控</p> 
<p></p> 
<h3 id="No.33%20%C2%A0iNaturalist2021"><em><strong><strong>No.33<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/iNaturalist2021?source=Y3Nkbg%3D%3D" rel="nofollow" title="iNaturalist2021">iNaturalist2021</a></strong></h3> 
<p>● <strong>发布方</strong>：康奈尔大学 · 加州理工学院 · Google · 爱丁堡大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/iNaturalist2021?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/iNaturalist2021">https://opendatalab.org.cn/iNaturalist2021</a></p> 
<p>● <strong>关键词</strong>：1万个种类</p> 
<p></p> 
<h2 id="%E4%BA%94%E3%80%81%E9%81%A5%E6%84%9F%E7%B1%BB"><strong>五、遥感类</strong></h2> 
<h3 id="No.34%20%C2%A0EuroSAT"><em><strong><strong>No.34<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/EuroSAT?source=Y3Nkbg%3D%3D" rel="nofollow" title="EuroSAT">EuroSAT</a></strong></h3> 
<p>● <strong>发布方</strong>：德国人工智能研究中心 · 凯泽斯劳滕工业大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/EuroSAT?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/EuroSAT">https://opendatalab.org.cn/EuroSAT</a></p> 
<p>● <strong>关键词</strong>：土地利用和覆盖分类</p> 
<p></p> 
<h3 id="No.35%20%C2%A0BigEarthNet"><em><strong><strong>No.35<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/BigEarthNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="BigEarthNet">BigEarthNet</a></strong></h3> 
<p>● <strong>发布方</strong>：柏林工业大学 · 德国人工智能研究中心</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/BigEarthNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/BigEarthNet">https://opendatalab.org.cn/BigEarthNet</a></p> 
<p>● <strong>关键词</strong>：遥感场景分类</p> 
<p></p> 
<h3 id="No.36%20%C2%A0So2Sat%20LCZ42"><em><strong><strong>No.36<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/So2Sat_LCZ42?source=Y3Nkbg%3D%3D" rel="nofollow" title="So2Sat LCZ42">So2Sat LCZ42</a></strong></h3> 
<p>● <strong>发布方</strong>：慕尼黑工业大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/So2Sat_LCZ42?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/So2Sat_LCZ42">https://opendatalab.org.cn/So2Sat_LCZ42</a></p> 
<p>● <strong>关键词</strong>：由多光谱光学图像数据及相应的局部气候标签组成</p> 
<p></p> 
<h3 id="No.37%20%C2%A0MLRSNet"><em><strong><strong>No.37<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/MLRSNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="MLRSNet">MLRSNet</a></strong></h3> 
<p>● <strong>发布方</strong>：中国地质大学 · 重庆邮电大学 · 北京师范大学 · 雅典大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/MLRSNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/MLRSNet">https://opendatalab.org.cn/MLRSNet</a></p> 
<p>● <strong>关键词</strong>：多标签高空间分辨率遥感图像</p> 
<p></p> 
<h3 id="No.38%20df2k_ost"><em><strong><strong>No.38 </strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/df2k_ost?source=Y3Nkbg%3D%3D" rel="nofollow" title="df2k_ost">df2k_ost</a></strong></h3> 
<p>● <strong>发布方</strong>：腾讯 · 中国科学院深圳先进技术研究院 · 中国科学院 · 中国科学院大学 · 上海人工智能实验室</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/df2k_ost?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/df2k_ost">https://opendatalab.org.cn/df2k_ost</a></p> 
<p>● <strong>关键词</strong>：高质量图像超分辨率和恢复数据集</p> 
<p></p> 
<h3 id="No.39%20%C2%A0Million-AID"><em><strong><strong>No.39<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Million-AID?source=Y3Nkbg%3D%3D" rel="nofollow" title="Million-AID">Million-AID</a></strong></h3> 
<p>● <strong>发布方</strong>：武汉大学 · 中国科学院 · 特温特大学 · 德国航空航天中心 · 慕尼黑工业大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Million-AID?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Million-AID">https://opendatalab.org.cn/Million-AID</a></p> 
<p>● <strong>关键词</strong>：遥感场景分类、大型基准数据集</p> 
<p></p> 
<h2 id="%E5%85%AD%E3%80%81%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7%E7%B1%BB"><strong>六、医疗健康类</strong></h2> 
<h3 id="No.40%20%C2%A0HErlev%20(HErlev%20Pap%20Smear%20Dataset)"><em><strong><strong>No.40<em><strong><strong> <em><strong> </strong></em></strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/HErlev?source=Y3Nkbg%3D%3D" rel="nofollow" title="HErlev (HErlev Pap Smear Dataset)">HErlev (HErlev Pap Smear Dataset)</a></strong></h3> 
<p>● <strong>发布方</strong>：爱琴海大学</p> 
<p>● <strong>发布时间</strong>：2008</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/HErlev?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/HErlev">https://opendatalab.org.cn/HErlev</a></p> 
<p>● <strong>关键词</strong>：健康和癌性细胞涂片</p> 
<p></p> 
<h3 id="No.41%C2%A0%C2%A0BBBC041%20(P.%20vivax%20(malaria)%20infected%20human%20blood%20smears)"><em><strong><strong>No.41<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/BBBC041?source=Y3Nkbg%3D%3D" rel="nofollow" title="BBBC041 (P. vivax (malaria) infected human blood smears)">BBBC041 (P. vivax (malaria) infected human blood smears)</a></strong></h3> 
<p>● <strong>发布方</strong>：麻省理工学院</p> 
<p>● <strong>发布时间</strong>：2012</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/BBBC041?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/BBBC041">https://opendatalab.org.cn/BBBC041</a></p> 
<p>● <strong>关键词</strong>：疟原虫感染、人体血液涂片</p> 
<p></p> 
<h3 id="No.42%C2%A0%C2%A0Chest-Xray8%20(COVID-19)"><em><strong><strong>No.42  </strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Chest-Xray8?source=Y3Nkbg%3D%3D" rel="nofollow" title="Chest-Xray8 (COVID-19)">Chest-Xray8 (COVID-19)</a></strong></h3> 
<p>● <strong>发布方</strong>：医疗公园医院 · 菲拉特大学 · 布里斯托尔大学 · 芒祖尔大学 · 义安理工学院 · 亚洲大学 · 熊本大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Chest-Xray8?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Chest-Xray8">https://opendatalab.org.cn/Chest-Xray8</a></p> 
<p>● <strong>关键词</strong>：胸部X射线、 COVID-19、肺炎</p> 
<p></p> 
<h2 id="%E4%B8%83%E3%80%81%E7%A7%91%E5%AD%A6%E6%95%99%E8%82%B2%E7%B1%BB"><strong>七、科学教育类</strong></h2> 
<h3 id="No.43%C2%A0%C2%A0PlantVillage"><em><strong><strong>No.43  </strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/PlantVillage?source=Y3Nkbg%3D%3D" rel="nofollow" title="PlantVillage">PlantVillage</a></strong></h3> 
<p>● <strong>发布方</strong>：安那大学</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/PlantVillage?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/PlantVillage">https://opendatalab.org.cn/PlantVillage</a></p> 
<p>● <strong>关键词</strong>：植物叶片</p> 
<p></p> 
<h3 id="No.44%C2%A0%C2%A0PlantDoc"><em><strong><strong>No.44<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/PlantDoc?source=Y3Nkbg%3D%3D" rel="nofollow" title="PlantDoc">PlantDoc</a></strong></h3> 
<p>● <strong>发布方</strong>：印度理工学院甘地纳加尔分校</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/PlantDoc?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/PlantDoc">https://opendatalab.org.cn/PlantDoc</a></p> 
<p>● <strong>关键词</strong>：植物病害检测</p> 
<p></p> 
<h3 id="No.45%C2%A0%C2%A0AI2D%20(AI2%20Diagrams)"><em><strong><strong>No.45<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/AI2D?source=Y3Nkbg%3D%3D" rel="nofollow" title="AI2D (AI2 Diagrams)">AI2D (AI2 Diagrams)</a></strong></h3> 
<p>● <strong>发布方</strong>：艾伦人工智能研究所</p> 
<p>● <strong>发布时间</strong>：2016</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/AI2D?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/AI2D">https://opendatalab.org.cn/AI2D</a></p> 
<p>● <strong>关键词</strong>：小学科学图表、图文问答</p> 
<p></p> 
<h3 id="No.46%C2%A0%C2%A0ANIMAL%20(ANIMAL-10N)"><em><strong><strong>No.46<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ANIMAL?source=Y3Nkbg%3D%3D" rel="nofollow" title="ANIMAL (ANIMAL-10N)">ANIMAL (ANIMAL-10N)</a></strong></h3> 
<p>● <strong>发布方</strong>：韩国科学技术院</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ANIMAL?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ANIMAL">https://opendatalab.org.cn/ANIMAL</a></p> 
<p>● <strong>关键词</strong>：5 对相似动物</p> 
<p></p> 
<h3 id="No.47%C2%A0%C2%A0FruitsAndVegetables"><em><strong><strong>No.47<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/FruitsAndVegetables?source=Y3Nkbg%3D%3D" rel="nofollow" title="FruitsAndVegetables">FruitsAndVegetables</a></strong></h3> 
<p>● <strong>发布方</strong>：未知</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/FruitsAndVegetables?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/FruitsAndVegetables">https://opendatalab.org.cn/FruitsAndVegetables</a></p> 
<p>● <strong>关键词</strong>：常见水果、蔬菜识别</p> 
<p></p> 
<h2 id="%E5%85%AB%E3%80%81%E8%89%BA%E6%9C%AF%E7%B1%BB"><strong>八、艺术类</strong></h2> 
<h3 id="No.48%C2%A0%C2%A0iCartoonFace"><em><strong><strong>No.48<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/iCartoonFace?source=Y3Nkbg%3D%3D" rel="nofollow" title="iCartoonFace">iCartoonFace</a></strong></h3> 
<p>● <strong>发布方</strong>：爱奇艺 · 北京航空航天大学虚拟现实技术与系统国家重点实验室</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/iCartoonFace?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/iCartoonFace">https://opendatalab.org.cn/iCartoonFace</a></p> 
<p>● <strong>关键词</strong>：包含多种风格的卡通人脸检测大规模数据集</p> 
<p></p> 
<h3 id="No.49%C2%A0%C2%A0KaoKore"><em><strong><strong>No.49<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/KaoKore?source=Y3Nkbg%3D%3D" rel="nofollow" title="KaoKore">KaoKore</a></strong></h3> 
<p>● <strong>发布方</strong>：Google AI Research · 剑桥大学 · 国立情报学研究所</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/KaoKore?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/KaoKore">https://opendatalab.org.cn/KaoKore</a></p> 
<p>● <strong>关键词</strong>：近代日本艺术品中提取的面孔</p> 
<p></p> 
<h3 id="No.50%C2%A0%C2%A0MAMe%20(Museum%20Art%20Medium%20dataset)"><em><strong><strong>No.50<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/MAMe?source=Y3Nkbg%3D%3D" rel="nofollow" title="MAMe (Museum Art Medium dataset)">MAMe (Museum Art Medium dataset)</a></strong></h3> 
<p>● <strong>发布方</strong>：巴塞罗那超级计算中心 · 巴塞罗那大学 · 加泰罗尼亚理工大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/MAMe?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/MAMe">https://opendatalab.org.cn/MAMe</a></p> 
<p>● <strong>关键词</strong>：显著高分辨率和可变形状属性、博物馆艺术品材料和工艺</p> 
<p></p> 
<h3 id="No.51%C2%A0%C2%A0ArtDL"><em><strong><strong>No.51<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ArtDL?source=Y3Nkbg%3D%3D" rel="nofollow" title="ArtDL">ArtDL</a></strong></h3> 
<p>● <strong>发布方</strong>：米兰理工大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ArtDL?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ArtDL">https://opendatalab.org.cn/ArtDL</a></p> 
<p>● <strong>关键词</strong>：绘画图像、大多数来自文艺复兴时期</p> 
<p></p> 
<h2 id="%E4%B9%9D%E3%80%81%E9%A3%9F%E7%89%A9%E7%B1%BB"><strong>九、食物类</strong></h2> 
<h3 id="No.52%C2%A0%C2%A0Food-101"><em><strong><strong>No.52<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Food-101?source=Y3Nkbg%3D%3D" rel="nofollow" title="Food-101">Food-101</a></strong></h3> 
<p>● <strong>发布方</strong>：苏黎世联邦理工学院 · 鲁汶天主教大学</p> 
<p>● <strong>发布时间</strong>：2014</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Food-101?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Food-101">https://opendatalab.org.cn/Food-101</a></p> 
<p>● <strong>关键词</strong>：101类食物</p> 
<p></p> 
<h3 id="No.53%C2%A0%C2%A0ECUSTFD%20(ECUST%20Food%20Dataset)"><em><strong><strong>No.53<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ECUSTFD?source=Y3Nkbg%3D%3D" rel="nofollow" title="ECUSTFD (ECUST Food Dataset)">ECUSTFD (ECUST Food Dataset)</a></strong></h3> 
<p>● <strong>发布方</strong>：华东理工大学</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ECUSTFD?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ECUSTFD">https://opendatalab.org.cn/ECUSTFD</a></p> 
<p>● <strong>关键词</strong>：硬币和餐盘标定的食物图像、食物卡路里计算</p> 
<p></p> 
<h3 id="No.54%C2%A0%C2%A0ChineseFoodNet"><em><strong><strong>No.54<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ChineseFoodNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="ChineseFoodNet">ChineseFoodNet</a></strong></h3> 
<p>● <strong>发布方</strong>：美的新兴技术中心 · 美的人工智能研究院</p> 
<p>● <strong>发布时间</strong>：2017</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ChineseFoodNet?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ChineseFoodNet">https://opendatalab.org.cn/ChineseFoodNet</a></p> 
<p>● <strong>关键词</strong>：食物识别、中餐菜谱/食物图片、跨模态信息检索</p> 
<p></p> 
<h3 id="No.55%C2%A0%C2%A0THFOOD-50%20(Thai%20Food%2050%20Image%20Classification)"><em><strong><strong>No.55<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/THFOOD-50?source=Y3Nkbg%3D%3D" rel="nofollow" title="THFOOD-50 (Thai Food 50 Image Classification)">THFOOD-50 (Thai Food 50 Image Classification)</a></strong></h3> 
<p>● <strong>发布方</strong>：纳瑞宣大学</p> 
<p>● <strong>发布时间</strong>：2018</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/THFOOD-50?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/THFOOD-50‍">https://opendatalab.org.cn/THFOOD-50‍</a></p> 
<p>● <strong>关键词</strong>：50种泰国食物图像、手机识别</p> 
<p></p> 
<h3 id="No.56%C2%A0%C2%A0KenyanFood13"><em><strong><strong>No.56<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/KenyanFood13?source=Y3Nkbg%3D%3D" rel="nofollow" title="KenyanFood13">KenyanFood13</a></strong></h3> 
<p>● <strong>发布方</strong>：纳瑞宣大学</p> 
<p>● <strong>发布时间</strong>：2018</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/KenyanFood13?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/KenyanFood13">https://opendatalab.org.cn/KenyanFood13</a></p> 
<p>● <strong>关键词</strong>：肯尼亚食物图像</p> 
<p></p> 
<h3 id="No.57%C2%A0%C2%A0MyFood%20Dataset"><em><strong><strong>No.57<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/MyFood_Dataset?source=Y3Nkbg%3D%3D" rel="nofollow" title="MyFood Dataset">MyFood Dataset</a></strong></h3> 
<p>● <strong>发布方</strong>：伯南布哥农村联邦大学</p> 
<p>● <strong>发布时间</strong>：2020</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/MyFood_Dataset?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/MyFood_Dataset">https://opendatalab.org.cn/MyFood_Dataset</a></p> 
<p>● <strong>关键词</strong>：巴西食物图像</p> 
<p></p> 
<h2 id="%E5%8D%81%E3%80%81%E7%94%9F%E6%B4%BB%E5%9C%BA%E6%99%AF%E7%B1%BB"><strong>十、生活场景类</strong></h2> 
<h3 id="No.58%C2%A0%C2%A0SVHN"><em><strong><strong>No.58<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/SVHN?source=Y3Nkbg%3D%3D" rel="nofollow" title="SVHN">SVHN</a></strong></h3> 
<p>● <strong>发布方</strong>：斯坦福大学</p> 
<p>● <strong>发布时间</strong>：2011</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/SVHN?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/SVHN">https://opendatalab.org.cn/SVHN</a></p> 
<p>● <strong>关键词</strong>：光学字符识别、街景门牌号</p> 
<p></p> 
<h3 id="No.59%C2%A0%C2%A0Clothing1M"><em><strong><strong>No.59<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Clothing1M?source=Y3Nkbg%3D%3D" rel="nofollow" title="Clothing1M">Clothing1M</a></strong></h3> 
<p>● <strong>发布方</strong>：香港中文大学 · 百度</p> 
<p>● <strong>发布时间</strong>：2015</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Clothing1M?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Clothing1M">https://opendatalab.org.cn/Clothing1M</a></p> 
<p>● <strong>关键词</strong>：在线购物网站收集的14类服装图像</p> 
<p></p> 
<h3 id="No.60%C2%A0%C2%A0Stanford%20Online%20Products"><em><strong><strong>No.60<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Stanford_online_Products?source=Y3Nkbg%3D%3D" rel="nofollow" title="Stanford Online Products">Stanford Online Products</a></strong></h3> 
<p>● <strong>发布方</strong>：斯坦福大学 · 麻省理工学院</p> 
<p>● <strong>发布时间</strong>：2016</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Stanford_online_Products?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Stanford_online_Products">https://opendatalab.org.cn/Stanford_online_Products</a></p> 
<p>● <strong>关键词</strong>：22634 类、120053 张网上销售的产品图片</p> 
<p></p> 
<h3 id="No.61%C2%A0%C2%A0Grocery%20Store"><em><strong><strong>No.61<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Grocery_Store?source=Y3Nkbg%3D%3D" rel="nofollow" title="Grocery Store">Grocery Store</a></strong></h3> 
<p>● <strong>发布方</strong>：瑞典皇家理工学院 · 微软研究院</p> 
<p>● <strong>发布时间</strong>：2019</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Grocery_Store?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Grocery_Store">https://opendatalab.org.cn/Grocery_Store</a></p> 
<p>● <strong>关键词</strong>：杂货店杂货自然图像、手机拍摄</p> 
<p></p> 
<h3 id="No.62%C2%A0%C2%A0ARC-100"><em><strong><strong>No.62<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/ARC-100?source=Y3Nkbg%3D%3D" rel="nofollow" title="ARC-100">ARC-100</a></strong></h3> 
<p>● <strong>发布方</strong>：拉合尔工程技术大学</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/ARC-100?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/ARC-100">https://opendatalab.org.cn/ARC-100</a></p> 
<p>● <strong>关键词</strong>：巴基斯坦100种常见零售商品、自动零售结账</p> 
<p></p> 
<h3 id="No.63%C2%A0%C2%A0FoodLogoDet-1500"><em><strong><strong>No.63<em><strong><strong>  </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/FoodLogoDet-1500?source=Y3Nkbg%3D%3D" rel="nofollow" title="FoodLogoDet-1500">FoodLogoDet-1500</a></strong></h3> 
<p>● <strong>发布方</strong>：山东师范大学 · 中国科学院</p> 
<p>● <strong>发布时间</strong>：2021</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/FoodLogoDet-1500?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/FoodLogoDet-1500">https://opendatalab.org.cn/FoodLogoDet-1500</a></p> 
<p>● <strong>关键词</strong>：大型食品商标数据集</p> 
<p></p> 
<h3 id="No.64%C2%A0%20Icon645"><em><strong><strong>No.64 <em><strong><strong> </strong></strong></em></strong></strong></em><strong><a class="link-info" href="https://opendatalab.org.cn/Icon645?source=Y3Nkbg%3D%3D" rel="nofollow" title="Icon645">Icon645</a></strong></h3> 
<p>● <strong>发布方</strong>：加州大学洛杉矶分校 · 中山大学 · 华东师范大学 · 哥伦比亚大学</p> 
<p>● <strong>发布时间</strong>：2022</p> 
<p>● <strong>下载链接</strong>：<a class="link-info" href="https://opendatalab.org.cn/Icon645?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/Icon645">https://opendatalab.org.cn/Icon645</a></p> 
<p>● <strong>关键词</strong>：大规模图标图像数据集</p> 
<p></p> 
<p>以上就是本次分享，更多精彩的数据集干货，欢迎访问OpenDataLab官网：<a class="link-info" href="https://opendatalab.org.cn/?source=Y3Nkbg%3D%3D" rel="nofollow" title="https://opendatalab.org.cn/">https://opendatalab.org.cn/</a>。还有哪些想看的内容，快来告诉小助手吧。</p> 
<p></p> 
<p>- End -</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ccc15f3fe8f8c7345abf257ff3e2752e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">银河麒麟高级服务器操作系统V10 SP2安装tomcat 8.5.31</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/15183063ca990469e2643345f813c277/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">计算机通信与网络（原书第7版）自顶向下答案</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>