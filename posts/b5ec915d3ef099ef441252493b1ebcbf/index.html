<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>三维点云处理（三）——Kenerl PCA - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="三维点云处理（三）——Kenerl PCA" />
<meta property="og:description" content="文章目录 前言1.1 关于Kernel PCA1.2 用法总结1.3 Kernel PCA实例总结 前言 上一章节说明的基础PCA主成分分析的基本原理，这种PCA主要适用于线性关系的数据点，在原理里包含的矩阵乘法实际上也是线性操作。数据中矩阵乘一个向量就是对矩阵的列的线性组合。如果我们遇到数据不是线性的情况下怎么办呢？
1.1 关于Kernel PCA 如上图所示的 一批点，如果给他做线性PCA时无法区分开红色和绿色的点，也就达不到聚类的效果，所以在解决非线性相关的数据时，我们应该用升维的方法 。比方说将上图里的数据点，我们将其放置于一个平面上，再从三维空间的角度将平面折叠起来成一个圆锥的话，就可以很好的将红点和绿点区分开来。这时候做一个普通的PCA就可以进行聚类了。
于是我们引出了kernel PCA的概念，他的步骤就是将原来n₀维度的数据给提升成n₁，得到一个函数ɸ，将中心值变为0，计算其矩阵H的相关矩阵，加上波浪线之后和原来的矩阵区分开，下一步解他们的特征值和特征向量，下面就引申出来两个问题：
如何去选择升维函数ɸ？如果避免升维过高而产生的过高算力，以节省运算资源。 由此我们得到了kernel PCA的方法。证明如下：
将Hz=λz代入，得到结论：
得到如下的式子，通过Kα = λα替换进去，代表αr应该有一个1/λr的长度，得到一个仍然含有ɸ的式子，我们最终目标是要去掉ɸ，在后续的变换中，将所有的ɸ都变换为核函数k，只需要定义一个核函数k即可。之前我们假设了高维空间的中心点为0，需要进行一个Normalization。
最后将所有的变换回到核函数上去：
这里有很多核函数形式，还包括高斯和拉普拉斯分布等，通常会通过数据实验来评估使用效果。
1.2 用法总结 将所有的数据点投影到主向量上去，由此得到投影后的系数yr。
1.3 Kernel PCA实例 图一为三个不同数据点组成的圆，我们选取一个简单的二次多项式的核函数，就可以计算出不同的主成分，将原来的数据投影到主向量上面，x轴为第一个主向量，y轴为第一个主向量。就已经可以将数据明显区分开来。
再使用高斯核函数来验证一下：
横轴为第一个主成分，竖轴为第二个主成分，此时已经可以区分开不同数据点这就是高维空间以及核PCA的用法。
总结 从PCA引入到kernel PCA，主要是通过使用核函数来对数据进行升维来达成聚类效果。而核PCA的中心思想就是将高维空间的运算转换成低维空间的核函数。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b5ec915d3ef099ef441252493b1ebcbf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-13T14:04:04+08:00" />
<meta property="article:modified_time" content="2023-06-13T14:04:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">三维点云处理（三）——Kenerl PCA</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">前言</a></li><li><a href="#11_Kernel_PCA_8" rel="nofollow">1.1 关于Kernel PCA</a></li><li><a href="#12__30" rel="nofollow">1.2 用法总结</a></li><li><a href="#13_Kernel_PCA_34" rel="nofollow">1.3 Kernel PCA实例</a></li><li><a href="#_44" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_4"></a>前言</h2> 
<p><code>上一章节说明的基础PCA主成分分析的基本原理，这种PCA主要适用于线性关系的数据点，在原理里包含的矩阵乘法实际上也是线性操作。数据中矩阵乘一个向量就是对矩阵的列的线性组合。如果我们遇到数据不是线性的情况下怎么办呢？</code></p> 
<h2><a id="11_Kernel_PCA_8"></a>1.1 关于Kernel PCA</h2> 
<p><img src="https://images2.imgbox.com/5e/0d/7hbqXytX_o.png" alt="在这里插入图片描述"><br> 如上图所示的 一批点，如果给他做线性PCA时无法区分开红色和绿色的点，也就达不到聚类的效果，所以在解决非线性相关的数据时，我们应该用升维的方法 。比方说将上图里的数据点，我们将其放置于一个平面上，再从三维空间的角度将平面折叠起来成一个圆锥的话，就可以很好的将红点和绿点区分开来。这时候做一个普通的PCA就可以进行聚类了。<br> <img src="https://images2.imgbox.com/96/7f/oPjZabde_o.png" alt="在这里插入图片描述"><br> 于是我们引出了kernel PCA的概念，他的步骤就是将原来n₀维度的数据给提升成n₁，得到一个函数ɸ，将中心值变为0，计算其矩阵H的相关矩阵，加上波浪线之后和原来的矩阵区分开，下一步解他们的特征值和特征向量，下面就引申出来两个问题：</p> 
<ol><li>如何去选择升维函数ɸ？</li><li>如果避免升维过高而产生的过高算力，以节省运算资源。</li></ol> 
<p>由此我们得到了kernel PCA的方法。证明如下：<br> <img src="https://images2.imgbox.com/44/9d/Z5mp8Xnj_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/76/94/F6vTBqtI_o.png" alt="在这里插入图片描述"><br> 将Hz=λz代入，得到结论：<br> <img src="https://images2.imgbox.com/01/76/QtGZ9ckg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a3/68/ukAqLv08_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a5/e0/HGrR7LjE_o.png" alt="在这里插入图片描述"><br> 得到如下的式子，通过Kα = λα替换进去，代表αr应该有一个1/λr的长度，得到一个仍然含有ɸ的式子，我们最终目标是要去掉ɸ，在后续的变换中，将所有的ɸ都变换为核函数k，只需要定义一个核函数k即可。之前我们假设了高维空间的中心点为0，需要进行一个Normalization。<br> <img src="https://images2.imgbox.com/85/06/7HUL7yMZ_o.png" alt="在这里插入图片描述"><br> 最后将所有的变换回到核函数上去：<br> <img src="https://images2.imgbox.com/ba/f6/ku0GD3G8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e3/0c/92qE3plR_o.png" alt="在这里插入图片描述"><br> 这里有很多核函数形式，还包括高斯和拉普拉斯分布等，通常会通过数据实验来评估使用效果。</p> 
<h2><a id="12__30"></a>1.2 用法总结</h2> 
<p><img src="https://images2.imgbox.com/1f/f0/upKM9TpR_o.png" alt="在这里插入图片描述"><br> 将所有的数据点投影到主向量上去，由此得到投影后的系数yr。</p> 
<h2><a id="13_Kernel_PCA_34"></a>1.3 Kernel PCA实例</h2> 
<p><img src="https://images2.imgbox.com/c1/14/BtjFow3u_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7f/38/k7l1wVBG_o.png" alt="在这里插入图片描述"><br> 图一为三个不同数据点组成的圆，我们选取一个简单的二次多项式的核函数，就可以计算出不同的主成分，将原来的数据投影到主向量上面，x轴为第一个主向量，y轴为第一个主向量。就已经可以将数据明显区分开来。<br> 再使用高斯核函数来验证一下：<br> <img src="https://images2.imgbox.com/04/7d/Lm09fTwC_o.png" alt="在这里插入图片描述"><br> 横轴为第一个主成分，竖轴为第二个主成分，此时已经可以区分开不同数据点这就是高维空间以及核PCA的用法。</p> 
<hr> 
<h2><a id="_44"></a>总结</h2> 
<p>从PCA引入到kernel PCA，主要是通过使用核函数来对数据进行升维来达成聚类效果。而核PCA的中心思想就是将高维空间的运算转换成低维空间的核函数。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ffccddc0a9ff688118ec7324bcfc4415/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">redis集群选举机制简介高可用性与主备切换原理(经典)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/75cfd4d76348b0e7937054285f1388dc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">iptables filter表</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>