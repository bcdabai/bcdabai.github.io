<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>逻辑回归实现分类计算（二） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="逻辑回归实现分类计算（二）" />
<meta property="og:description" content="在上一篇逻辑回归分类计算中，模型的准确率为0.1，准确率较差且在分类1的模型预测结果显示中效果极差。在网上查找了各种逻辑回归分类的代码分析。发现错误还是在梯度下降算法计算回归系数的上，导致模型预测的精确度不高。
所以本次更改梯度下降算法来进行新的预测。
损失函数为：
对θ求导得到梯度：
更新回归系数：
同时也对因变量进行修改，不再对因变量处理成[-6,6]的线性数据。将因变量处理成分类变量，每一类形成一列新数据，数据列全为0和1,分别表示有无该类别。在数据中，增加一列为全为1的偏移变量。
数据处理结果为：
引申逻辑判别多分类函数softmax。
为了使每个样本数据都能参加到训练中，采用交叉检验。本次实验用到了K折交叉检验
K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。
代码就不再直接写在博客上了，有需要的可以在百度云下载：链接，提取码：1yx5
结果显示如下：
准确率能达到0.675.在梯度下降算法中，移动步长是固定的，更新移动步长为随机，查看模型准确率提升效果。
代码如下：
def RandomGradientDescent(dataMartrix, labelMat, numIter=500): m,n = np.shape(dataMartrix) weights = np.ones((n,1)) for j in range(numIter): for k in range(m): alpha = 10/(1.0&#43;j&#43;k)&#43;0.01 #改进移动步长 h = sigmoid(dataMartrix[k] * weights) error = h - labelMat[k] #计算样本误差 weights = weights - alpha * dataMartrix[k].T * error #更新回归系数 return weights.getA() 当然随机梯度下降算法的计算量也是比较大的，准确率会较固定梯度下降算法提高。由于该样本数据的分布不均（0的样本数量为273条，1的样本数量为127条）导致类别为1的判别效果较差。所以尝试增加类别为1的样本数据，观察样本判别结果。
将下面的代码放在数据读取之后和处理之前。
#增加样本数量 a = dataSet[dataSet.admit == 1] dataSet = dataSet." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/40b12a955152a5bfe2e9548caeca3e29/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-10-18T17:30:52+08:00" />
<meta property="article:modified_time" content="2018-10-18T17:30:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">逻辑回归实现分类计算（二）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-indent:50px;">在上一篇<a href="https://blog.csdn.net/qq_33361618/article/details/83023735">逻辑回归分类</a>计算中，模型的准确率为0.1，准确率较差且在分类1的模型预测结果显示中效果极差。在网上查找了各种逻辑回归分类的代码分析。发现错误还是在梯度下降算法计算回归系数的上，导致模型预测的精确度不高。</p> 
<p style="text-indent:50px;">所以本次更改梯度下降算法来进行新的预测。</p> 
<p style="text-indent:50px;">损失函数为：</p> 
<p style="text-indent:50px;"><img alt="J(\Theta )=\frac{1}{2}\sum_{i=1}^{m}(x_{i}\Theta-y_{i})^{2}" class="mathcode" src="https://images2.imgbox.com/4a/60/h45CTX5L_o.gif"></p> 
<p style="text-indent:50px;">对θ求导得到梯度：</p> 
<p style="text-indent:50px;"><img alt="J(\Theta)=2X^T(Xw-y)" class="mathcode" src="https://images2.imgbox.com/21/f2/mPpk2H6P_o.gif"></p> 
<p style="text-indent:50px;">更新回归系数：</p> 
<p style="text-indent:50px;"><img alt="\Theta_{k+1}=\Theta_k-\partial X^T(X\Theta_k-y)" class="mathcode" src="https://images2.imgbox.com/10/f7/jI1uxU29_o.gif"></p> 
<p style="text-indent:50px;">同时也对因变量进行修改，不再对因变量处理成[-6,6]的线性数据。将因变量处理成分类变量，每一类形成一列新数据，数据列全为0和1,分别表示有无该类别。在数据中，增加一列为全为1的偏移变量。</p> 
<p style="text-indent:50px;">数据处理结果为：</p> 
<p style="text-indent:50px;"><img alt="" class="has" height="93" src="https://images2.imgbox.com/f3/55/4BdFceBV_o.png" width="494"></p> 
<p style="text-indent:50px;">引申逻辑判别多分类函数softmax。</p> 
<p style="text-indent:50px;"><img alt="softmax=\frac{e^{z_{i}}}{\sum_i e^{z_{i}}}" class="mathcode" src="https://images2.imgbox.com/b0/52/D7q1Esw5_o.gif"></p> 
<p style="text-indent:50px;">为了使每个样本数据都能参加到训练中，采用交叉检验。本次实验用到了K折交叉检验</p> 
<p style="text-indent:50px;">K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。</p> 
<p style="text-indent:50px;">代码就不再直接写在博客上了，有需要的可以在百度云下载：<a href="https://pan.baidu.com/s/1oYJFdh1cFqbIFhsg0XFEFw" rel="nofollow">链接</a>，提取码：1yx5</p> 
<p style="text-indent:50px;">结果显示如下：</p> 
<p style="text-indent:50px;"><img alt="" class="has" height="131" src="https://images2.imgbox.com/53/86/cCXj1vwD_o.png" width="206"></p> 
<p style="text-indent:50px;"> 准确率能达到0.675.在梯度下降算法中，移动步长是固定的，更新移动步长为随机，查看模型准确率提升效果。</p> 
<p style="text-indent:50px;">代码如下：</p> 
<pre class="has"><code class="language-python">def RandomGradientDescent(dataMartrix, labelMat, numIter=500):
    
    m,n = np.shape(dataMartrix)
    weights = np.ones((n,1))
    
    for j in range(numIter):
        
        for k in range(m):
            
            alpha = 10/(1.0+j+k)+0.01 #改进移动步长
            h = sigmoid(dataMartrix[k] * weights)
            error = h - labelMat[k]    #计算样本误差
            weights = weights - alpha * dataMartrix[k].T * error  #更新回归系数
            
    return weights.getA()</code></pre> 
<p style="text-indent:50px;">当然随机梯度下降算法的计算量也是比较大的，准确率会较固定梯度下降算法提高。由于该样本数据的分布不均（0的样本数量为273条，1的样本数量为127条）导致类别为1的判别效果较差。所以尝试增加类别为1的样本数据，观察样本判别结果。</p> 
<p style="text-indent:50px;">将下面的代码放在数据读取之后和处理之前。</p> 
<pre class="has"><code class="language-python">#增加样本数量
a = dataSet[dataSet.admit == 1]
dataSet = dataSet.append(a)
dataSet.index = range(len(dataSet))</code></pre> 
<p style="text-indent:50px;">运行结果如下：</p> 
<p style="text-indent:50px;"><img alt="" class="has" height="144" src="https://images2.imgbox.com/41/6e/WFUUfv2Z_o.png" width="208"></p> 
<p style="text-indent:50px;">增加一份全为1的样本数据后，准确率、召回率、F1调和平均值明显的提高。解决判别类型为1的效果较差问题。所以当增加样本数据效果不好时，考虑增加样本数据进行建模。</p> 
<p style="text-indent:50px;">但该模型指标也不是特别高，所以模型效果并不是特别好，如上一篇文章结论所说，认为仅仅凭借成绩、GPA和排名，不能确定是否通过考研。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dfa08aa288d3a42110cd41fa1d9723a4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【portia前端组织结构拆解】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4443a4a232b25fbd0938f382fd619dec/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">cookie 有效域名如何设置？？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>