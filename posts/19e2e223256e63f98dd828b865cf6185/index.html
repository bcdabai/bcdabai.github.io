<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>七种 WebSocket 框架的性能比较 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="七种 WebSocket 框架的性能比较" />
<meta property="og:description" content="1、 原文地址 colobu.com
前一篇文章使用四种框架分别实现百万 websocket 常连接的服务器介绍了四种 websocket 框架的测试方法和基本数据。
前一篇文章使用四种框架分别实现百万 websocket 常连接的服务器介绍了四种 websocket 框架的测试方法和基本数据。 最近我又使用几个框架实现了 websocket push 服务器的原型，并专门对这七种实现做了测试。 本文记录了测试结果和一些对结果的分析。
这七种框架是：
NettyUndertowJettyVert.xGrizzlyspray-websocketnodejs-websocket/Node.js 最近用 Golang 实现了第八种，Go 表现还不错。
Go 一、测试环境 使用三台 C3.4xlarge AWS 服务器做测试。 一台作为服务器，两台作为客户端机器， 每台客户端机器启动 10 个 client, 一共 20 个 client
C3.4xlarge 的配置如下：
型号vCPU内存 (GiB)SSD 存储 (GB)c3.large23.752 x 16c3.xlarge47.52 x 40c3.2xlarge8152 x 80c3.4xlarge16302 x 160c3.8xlarge32602 x 320 服务器和客户端机器按照上一篇文章做了基本的优化。
以下是测试的配置数据：
20 clientssetup rate 设为 500 * 20 requests/second = 10000 request /second每个 client 负责建立 50000 个 websocket 连接等 1,000,000 个 websocket 建好好，发送一个消息 (时间戳) 给所有的客户端，客户端根据时间戳计算 latency如果服务器 setup rate 建立很慢，主动停止测试监控三个阶段的性能指标： setup 时， setup 完成后应用发呆 (idle) 时，发送消息时 二、测试结果 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/19e2e223256e63f98dd828b865cf6185/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-14T14:17:30+08:00" />
<meta property="article:modified_time" content="2023-10-14T14:17:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">七种 WebSocket 框架的性能比较</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>1、 原文地址 <a href="https://colobu.com/2015/07/14/performance-comparison-of-7-websocket-frameworks/" rel="nofollow">colobu.com</a></p> 
<blockquote> 
 <p>前一篇文章使用四种框架分别实现百万 websocket 常连接的服务器介绍了四种 websocket 框架的测试方法和基本数据。</p> 
</blockquote> 
<p>前一篇文章<a href="https://colobu.com/2015/05/22/implement-C1000K-servers-by-spray-netty-undertow-and-node-js" rel="nofollow">使用四种框架分别实现百万 websocket 常连接的服务器</a>介绍了四种 websocket 框架的测试方法和基本数据。 最近我又使用几个框架实现了 websocket push 服务器的原型，并专门对这七种实现做了测试。 本文记录了测试结果和一些对结果的分析。<br> 这七种框架是：</p> 
<ul><li><a href="http://netty.io/" rel="nofollow">Netty</a></li><li><a href="http://undertow.io/" rel="nofollow">Undertow</a></li><li><a href="http://www.eclipse.org/jetty/" rel="nofollow">Jetty</a></li><li><a href="http://http//vertx.io" rel="nofollow">Vert.x</a></li><li><a href="https://grizzly.java.net/" rel="nofollow">Grizzly</a></li><li><a href="https://github.com/wandoulabs/spray-websocket">spray-websocket</a></li><li><a href="https://github.com/sitegui/nodejs-websocket">nodejs-websocket/Node.js</a></li></ul> 
<p>最近用 Golang 实现了第八种，Go 表现还不错。</p> 
<ul><li><a href="https://golang.org/" rel="nofollow">Go</a></li></ul> 
<h2><a id="_19"></a>一、测试环境</h2> 
<hr> 
<p>使用三台 C3.4xlarge AWS 服务器做测试。 一台作为服务器，两台作为客户端机器， 每台客户端机器启动 10 个 client, 一共 20 个 client<br> C3.4xlarge 的配置如下：</p> 
<table><tbody><tr><td>型号</td><td>vCPU</td><td>内存 (GiB)</td><td>SSD 存储 (GB)</td></tr><tr><td>c3.large</td><td>2</td><td>3.75</td><td>2 x 16</td></tr><tr><td>c3.xlarge</td><td>4</td><td>7.5</td><td>2 x 40</td></tr><tr><td>c3.2xlarge</td><td>8</td><td>15</td><td>2 x 80</td></tr><tr><td>c3.4xlarge</td><td>16</td><td>30</td><td>2 x 160</td></tr><tr><td>c3.8xlarge</td><td>32</td><td>60</td><td>2 x 320</td></tr></tbody></table> 
<p>服务器和客户端机器按照上一篇文章做了基本的优化。</p> 
<p>以下是测试的配置数据：</p> 
<ul><li>20 clients</li><li>setup rate 设为 500 * 20 requests/second = 10000 request /second</li><li>每个 client 负责建立 50000 个 websocket 连接</li><li>等 1,000,000 个 websocket 建好好，发送一个消息 (时间戳) 给所有的客户端，客户端根据时间戳计算 latency</li><li>如果服务器 setup rate 建立很慢，主动停止测试</li><li>监控三个阶段的性能指标： setup 时， setup 完成后应用发呆 (idle) 时，发送消息时</li></ul> 
<h2><a id="_38"></a>二、测试结果</h2> 
<hr> 
<h3><a id="21Netty_41"></a>2.1、Netty</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 90%</li><li>minor gc: Few</li><li>full gc: No</li></ul> 
<p><strong>Setup 完成， 应用 Idle 时</strong></p> 
<ul><li>cpu idle: 100%</li><li>memory usage: 1.68G</li><li>server free memory: 16.3G</li></ul> 
<p><strong>发送消息时</strong></p> 
<ul><li> <p>cpu idle: 75%</p> </li><li> <p>minor gc: few</p> </li><li> <p>full gc: No</p> </li><li> <p>Message latency (one client)</p> <pre><code class="prism language-shell">count <span class="token operator">=</span> <span class="token number">50000</span>
         min <span class="token operator">=</span> <span class="token number">0</span>
         max <span class="token operator">=</span> <span class="token number">18301</span>
        mean <span class="token operator">=</span> <span class="token number">2446.09</span>
      stddev <span class="token operator">=</span> <span class="token number">3082.11</span>
      median <span class="token operator">=</span> <span class="token number">1214.00</span>
        <span class="token number">75</span>% <span class="token operator">&lt;=</span> <span class="token number">3625.00</span>
        <span class="token number">95</span>% <span class="token operator">&lt;=</span> <span class="token number">8855.00</span>
        <span class="token number">98</span>% <span class="token operator">&lt;=</span> <span class="token number">12069.00</span>
        <span class="token number">99</span>% <span class="token operator">&lt;=</span> <span class="token number">13274.00</span>
      <span class="token number">99.9</span>% <span class="token operator">&lt;=</span> <span class="token number">18301.00</span>
</code></pre> </li></ul> 
<h3><a id="22Vertx_77"></a>2.2、Vert.x</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 95%</li><li>minor gc: Few</li><li>full gc: No</li></ul> 
<p><strong>Setup 完成， 应用 Idle 时</strong></p> 
<ul><li>cpu idle: 100%</li><li>memory usage: 6.37G</li><li>server free memory: 16.3G</li></ul> 
<p><strong>发送消息时</strong></p> 
<ul><li> <p>cpu idle: 47% ~ 76%</p> </li><li> <p>minor gc: few</p> </li><li> <p>full gc: few</p> </li><li> <p>Message latency (one client)</p> <pre><code class="prism language-shell">count <span class="token operator">=</span> <span class="token number">50000</span>
         min <span class="token operator">=</span> <span class="token number">49</span>
         max <span class="token operator">=</span> <span class="token number">18949</span>
        mean <span class="token operator">=</span> <span class="token number">10427.00</span>
      stddev <span class="token operator">=</span> <span class="token number">5182.72</span>
      median <span class="token operator">=</span> <span class="token number">10856.00</span>
        <span class="token number">75</span>% <span class="token operator">&lt;=</span> <span class="token number">14934.00</span>
        <span class="token number">95</span>% <span class="token operator">&lt;=</span> <span class="token number">17949.00</span>
        <span class="token number">98</span>% <span class="token operator">&lt;=</span> <span class="token number">18458.00</span>
        <span class="token number">99</span>% <span class="token operator">&lt;=</span> <span class="token number">18658.00</span>
      <span class="token number">99.9</span>% <span class="token operator">&lt;=</span> <span class="token number">18949.00</span>
</code></pre> </li></ul> 
<h3><a id="23Undertow_113"></a>2.3、Undertow</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 90%</li><li>minor gc: Few</li><li>full gc: No</li></ul> 
<p><strong>Setup 完成， 应用 Idle 时</strong></p> 
<ul><li>cpu idle: 100%</li><li>memory usage: 4.02G</li><li>server free memory: 14.2G</li></ul> 
<p><strong>发送消息时</strong></p> 
<ul><li> <p>cpu idle: 65%</p> </li><li> <p>minor gc: few</p> </li><li> <p>full gc: No</p> </li><li> <p>Message latency</p> <pre><code class="prism language-shell">count <span class="token operator">=</span> <span class="token number">50000</span>
         min <span class="token operator">=</span> <span class="token number">1</span>
         max <span class="token operator">=</span> <span class="token number">11948</span>
        mean <span class="token operator">=</span> <span class="token number">1366.86</span>
      stddev <span class="token operator">=</span> <span class="token number">2007.77</span>
      median <span class="token operator">=</span> <span class="token number">412.00</span>
        <span class="token number">75</span>% <span class="token operator">&lt;=</span> <span class="token number">2021.00</span>
        <span class="token number">95</span>% <span class="token operator">&lt;=</span> <span class="token number">5838.00</span>
        <span class="token number">98</span>% <span class="token operator">&lt;=</span> <span class="token number">7222.00</span>
        <span class="token number">99</span>% <span class="token operator">&lt;=</span> <span class="token number">8051.00</span>
      <span class="token number">99.9</span>% <span class="token operator">&lt;=</span> <span class="token number">11948.00</span>
</code></pre> </li></ul> 
<h3><a id="24Jetty_149"></a>2.4、Jetty</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 2%</li><li>minor gc: Many</li><li>full gc: No</li><li>memory usage: 5G</li><li>server free memory: 17.2G</li></ul> 
<p><em>当建立 360,000 左右的 websocket 时， setup 非常的慢， gc 频繁，无法继续正常建立 websocket， 主动终止测试。</em></p> 
<h3><a id="25Grizzly_161"></a>2.5、Grizzly</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 20%</li><li>minor gc: Some</li><li>full gc: Some</li><li>memory usage: 11.5G</li><li>server free memory: 12.3G</li></ul> 
<p><em>当建立 500,000 左右的 websocket 时， setup 非常的慢， gc 频繁，无法继续正常建立 websocket， 主动终止测试。</em></p> 
<h3><a id="26Spray_173"></a>2.6、Spray</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 80%</li><li>minor gc: Many</li><li>full gc: No</li></ul> 
<p><em>当建立 500,000 左右的 websocket 时， setup 非常的慢， gc 频繁，无法继续正常建立 websocket， 主动终止测试。</em></p> 
<h3><a id="27Nodejs_183"></a>2.7、Node.js</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 94%</li></ul> 
<p><strong>Setup 完成， 应用 Idle 时</strong></p> 
<ul><li>cpu idle: 100%</li><li>memory usage: 5.0G</li><li>server free memory: 16.3G</li></ul> 
<p><strong>发送消息时</strong></p> 
<ul><li> <p>cpu idle: 94%</p> </li><li> <p>Message latency (one client)</p> </li><li> <p>Message latency</p> <pre><code class="prism language-shell">count <span class="token operator">=</span> <span class="token number">50000</span>
         min <span class="token operator">=</span> <span class="token number">0</span>
         max <span class="token operator">=</span> <span class="token number">18</span>
        mean <span class="token operator">=</span> <span class="token number">1.27</span>
      stddev <span class="token operator">=</span> <span class="token number">3.08</span>
      median <span class="token operator">=</span> <span class="token number">1.00</span>
        <span class="token number">75</span>% <span class="token operator">&lt;=</span> <span class="token number">1.00</span>
        <span class="token number">95</span>% <span class="token operator">&lt;=</span> <span class="token number">1.00</span>
        <span class="token number">98</span>% <span class="token operator">&lt;=</span> <span class="token number">1.00</span>
        <span class="token number">99</span>% <span class="token operator">&lt;=</span> <span class="token number">1.00</span>
      <span class="token number">99.9</span>% <span class="token operator">&lt;=</span> <span class="token number">15.00</span>
</code></pre> </li></ul> 
<h3><a id="28Go_216"></a>2.8、Go</h3> 
<p><strong>Setup 时</strong></p> 
<ul><li>cpu idle: 94%</li></ul> 
<p><strong>Setup 完成， 应用 Idle 时</strong></p> 
<ul><li>cpu idle: 100%</li><li>memory usage: 15G</li><li>server free memory: 6G</li></ul> 
<p><strong>发送消息时</strong></p> 
<ul><li> <p>cpu idle: 94%</p> </li><li> <p>Message latency (one client)</p> </li><li> <p>Message latency</p> <pre><code class="prism language-shell">count <span class="token operator">=</span> <span class="token number">50000</span>
         min <span class="token operator">=</span> <span class="token number">0</span>
         max <span class="token operator">=</span> <span class="token number">35</span>
        mean <span class="token operator">=</span> <span class="token number">1.89</span>
      stddev <span class="token operator">=</span> <span class="token number">1.83</span>
      median <span class="token operator">=</span> <span class="token number">1.00</span>
        <span class="token number">75</span>% <span class="token operator">&lt;=</span> <span class="token number">1.00</span>
        <span class="token number">95</span>% <span class="token operator">&lt;=</span> <span class="token number">2.00</span>
        <span class="token number">98</span>% <span class="token operator">&lt;=</span> <span class="token number">2.00</span>
        <span class="token number">99</span>% <span class="token operator">&lt;=</span> <span class="token number">4.00</span>
      <span class="token number">99.9</span>% <span class="token operator">&lt;=</span> <span class="token number">34.00</span>
</code></pre> </li></ul> 
<h2><a id="_249"></a>三、测试结果分析</h2> 
<hr> 
<ul><li>Netty, Go, Node.js, Undertow, Vert.x 都能正常建立百万连接。 Jetty, Grizzly 和 Spray 未能完成百万连接</li><li>Netty 表现最好。内存占用非常的少， CPU 使用率也不高。 尤其内存占用，远远小于其它框架</li><li>Jetty, Grizzly 和 Spray 会产生大量的中间对象，导致垃圾回收频繁。Jetty 表现最差</li><li>Node.js 表现非常好。 尤其是测试中使用单实例单线程，建立速度非常快，消息的 latency 也很好。 内存占用也不错</li><li>Undertow 表现也不错，内存占用比 Netty 高一些，其它差不多</li><li>这里还未测到 Spray 另一个不好的地方。 在大量连接的情况小，即使没有消息发送，Spray 也会占用 40% CPU 时间</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a1091566aa2bc6af7c934ed338e543d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">彩票系统java</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/149b33eccc89ce061d4e6958de1523b8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LeetCode——动态规划（五）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>