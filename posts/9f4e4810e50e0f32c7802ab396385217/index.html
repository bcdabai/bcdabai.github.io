<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>H264编码简介 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="H264编码简介" />
<meta property="og:description" content="H264编码简介 H.264，同时也是MPEG-4第十部分，是由ITU-T视频编码专家组（VCEG）和ISO/IEC动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的高度压缩数字视频编解码器标准。H.264 不仅具有优异的压缩性能，而且具有良好的网络亲和性。和MPEG-4 中的重点是灵活性不同，H.264 着重在压缩的高效率和传输的高可靠性，因而其应用面十分广泛。
1. H.264的特点
H264标准的主要特点如下：
更高的编码效率：同H.263等标准的特率效率相比，能够平均节省大于50%的码率。高质量的视频画面：H.264能够在低码率情况下提供高质量的视频图像，在较低带宽上提供高质量的图像传输是H.264的应用亮点。提高网络适应能力：H.264可以工作在实时通信应用（如视频会议）低延时模式下，也可以工作在没有延时的视频存储或视频流服务器中。采用混合编码结构：同H.263相同，H.264也使用采用DCT变换编码加DPCM的差分编码的混合编码结构，还增加了如多模式运动估计、帧内预测、多帧预测、基于内容的变长编码、4x4二维整数变换等新的编码方式，提高了编码效率。H.264的编码选项较少：在H.263中编码时往往需要设置相当多选项，增加了编码的难度，而H.264做到了力求简洁的“回归基本”，降低了编码时复杂度。H.264可以应用在不同场合：H.264可以根据不同的环境使用不同的传输和播放速率，并且提供了丰富的错误处理工具，可以很好的控制或消除丢包和误码。错误恢复功能：H.264提供了解决网络传输包丢失的问题的工具，适用于在高误码率传输的无线网络中传输视频数据。较高的复杂度：264性能的改进是以增加复杂性为代价而获得的。据估计，H.264编码的计算复杂度大约相当于H.263的3倍，解码复杂度大约相当于H.263的2倍。 2. H.264编解码器
H.264 并不明确地规定一个编解码器如何实现，而是规定了一个编了码的视频比特流的句法，和该比特流的解码方法，各个厂商的编码器和解码器在此框架下应能够互通，在实现上具有较大灵活性，而且有利于相互竞争。H.264 编码器和解码器的功能组成分别见图2.1，图2.2。
图2.1 H.264 编码器
图2.2 H.264解码器
从上述二图可见，H.264 和基于以前的标准（如H.261、H.263、MPEG-1、MPEG-4）中的编解码器功能块的组成并没有什么区别，主要的不同在于各功能块的细节。由于视频内容时刻在变化，这种内容的多变性就必须采用相应的自适应的技术措施；由于信道在环境恶劣下也是多变的，这就要求采取相应的自适应方法来对抗这种信道畸变带来的不良影响。这两方面的多变带来了自适应压缩技术的复杂性。H.264 就是利用实现的复杂性获得压缩性能的明显改善。
编码器采用的仍是变换和预测的混合编码法。由图2.1，输入的帧或场Fn以宏块为单位被编码器处理。首先，按帧内或帧间预测编码的方法进行处理。如果采用帧内预测编码，其预测值PRED（图中用P 表示）是由当前片中前面已编码的参考图像经运动补偿（MC）后得出，其中参考图像用F’n-1 表示。为了提高预测精度，从而提高压缩比，实际的参考图像可在过去或未来（指显示次序上）已编码解码重建和滤波的帧中进行选择。预测值PRED 和当前块相减后，产生一个残差块Dn，经块变换、量化后产生一组量化后的变换系数X，再经熵编码，与解码所需的一些边信息（如预测模式量化参数、运动矢量等）一起组成一个压缩后的码流，经NAL（网络自适应层）供传输和存储用。正如上述，为了提供进一步预测用的参考图像，编码器必须有重建图像的功能。因此必须使残差图像经反量化、反变换后得到的Dn’与预测值P 相加，得到uFn’（未经滤波的帧）。为了去除编码解码环路中产生的噪声，为了提高参考帧的图像质量，从而提高压缩图像性能，设置了一个环路滤波器，滤波后的输出Fn’即重建图像可用作参考图像。
由图 2.1可知，由编码器的NAL输出一个压缩后的H.264压缩比特流。由图2.2，经熵解码得到量化后的一组变换系数X，再经反量化、反变换，得到残差Dn’。利用从该比特流中解码出的头信息，解码器就产生一个预测块PRED，它和编码器中的原始PRED是相同的。当该解码器产生的PRED与残差Dn’相加后，就产生uFu’，再经滤波后，最后就得到滤波后的Fn’，这个Fn’就是最后的解码输出图像。
3. Profile和Level
H264主要包括Baseline，Ext，Main, High这几种常用profile，各种profile是根据不同的应用场景设计的，具体如下：
Baseline主要是用于可视电话，会议电视，无线通讯等实时通信。要实时，就要减少视频decode和display的时延，所以没有B frame；为了提高针对网络丢包的容错能力，特意添加了FMO，ASO和冗余slice。
Main用于数字广播电视和数字视频存储，侧重点在于提高压缩率，所以有了CABAC，MBAFF，Interlace，B frame等。 Extend用于改进误码性能和码流切换（SP和SI slice），侧重于码流切换（SI，SP slice）和error resilience（数据分割）。 High主要用于高压缩效率和质量， 引入8x8 DCT，选择量化矩阵等。
H.264 Baseline profile、Extended profile和Main profile都是针对8位样本数据、4:2:0格式的视频序列，FRExt将其扩展到8～12位样本数据，视频格式可以为4:2:0、4:2:2、4:4:4，设立了High profile（HP）、High 10profile（Hi10P）、High 4:2:2 profile（Hi422P）、High 4:4:4 profile（Hi444P）4个profile，这4个profile都以Main profile为基础。
每个profile 都规定了一个算法特征和限制的子集，任何遵守某个profile 的解码器都应该支持与其相应的子集。 每个level都规定了一组对标准中语法成员（syntax element）所采用的各种参数值的限制。
在给定的profile下，level通常与解码器的处理能力和内存容量相对应。每一个档次设置不同的参数（如取样速率、图像尺寸、编码比特率等），得到对应的编解码器性能的不同level。
4. 编码数据格式
4.1 H.264 的编码格式" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9f4e4810e50e0f32c7802ab396385217/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-11T08:38:38+08:00" />
<meta property="article:modified_time" content="2019-05-11T08:38:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">H264编码简介</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="margin-left:0cm;"><strong>H264编码简介</strong></h2> 
<p style="margin-left:0cm;">H.264，同时也是MPEG-4第十部分，是由ITU-T视频编码专家组（VCEG）和ISO/IEC动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的高度压缩数字视频编解码器标准。H.264 不仅具有优异的压缩性能，而且具有良好的网络亲和性。和MPEG-4 中的重点是灵活性不同，H.264 着重在压缩的高效率和传输的高可靠性，因而其应用面十分广泛。</p> 
<p><strong>1.  H.264</strong><strong>的特点</strong></p> 
<p style="margin-left:0cm;"><span style="color:#333333;">H2</span>64标准的主要特点如下：</p> 
<ul><li>更高的编码效率：同H.263等标准的特率效率相比，能够平均节省大于50%的码率。</li><li>高质量的视频画面：H.264能够在低码率情况下提供高质量的视频图像，在较低带宽上提供高质量的图像传输是H.264的应用亮点。</li><li>提高网络适应能力：H.264可以工作在实时通信应用（如视频会议）低延时模式下，也可以工作在没有延时的视频存储或视频流服务器中。</li><li>采用混合编码结构：同H.263相同，H.264也使用采用DCT<a href="https://baike.baidu.com/item/%E5%8F%98%E6%8D%A2%E7%BC%96%E7%A0%81" rel="nofollow">变换编码</a>加DPCM的差分编码的混合编码结构，还增加了如多模式<a href="https://baike.baidu.com/item/%E8%BF%90%E5%8A%A8%E4%BC%B0%E8%AE%A1" rel="nofollow">运动估计</a>、帧内预测、多帧预测、基于内容的<a href="https://baike.baidu.com/item/%E5%8F%98%E9%95%BF%E7%BC%96%E7%A0%81" rel="nofollow">变长编码</a>、4x4二维整数变换等新的编码方式，提高了编码效率。</li><li>H.264的编码选项较少：在H.263中编码时往往需要设置相当多选项，增加了编码的难度，而H.264做到了力求简洁的“回归基本”，降低了编码时复杂度。</li><li>H.264可以应用在不同场合：H.264可以根据不同的环境使用不同的传输和播放速率，并且提供了丰富的错误处理工具，可以很好的控制或消除丢包和误码。</li><li>错误恢复功能：H.264提供了解决<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93" rel="nofollow">网络传输</a>包丢失的问题的工具，适用于在高<a href="https://baike.baidu.com/item/%E8%AF%AF%E7%A0%81%E7%8E%87" rel="nofollow">误码率</a>传输的无线网络中传输视频数据。</li><li>较高的复杂度：264性能的改进是以增加复杂性为代价而获得的。据估计，H.264编码的计算复杂度大约相当于H.263的3倍，解码复杂度大约相当于H.263的2倍<span style="color:#333333;">。</span></li></ul> 
<p><strong><span style="color:#000000;">2.  H.264编解码器</span></strong></p> 
<p style="margin-left:0cm;">H.264 并不明确地规定一个编解码器如何实现，而是规定了一个编了码的视频比特流的句法，和该比特流的解码方法，各个厂商的编码器和解码器在此框架下应能够互通，在实现上具有较大灵活性，而且有利于相互竞争。H.264 编码器和解码器的功能组成分别见图2.1，图2.2。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="248" src="https://images2.imgbox.com/1d/5b/rXWSDaQQ_o.png" width="642"></p> 
<p style="text-indent:50px;">                                                         图2.1 H.264 编码器</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="174" src="https://images2.imgbox.com/3a/b8/TXVSifGd_o.png" width="639"></p> 
<p style="margin-left:0cm;">                                                                  图2.2 H.264解码器</p> 
<p style="margin-left:0cm;">从上述二图可见，H.264 和基于以前的标准（如H.261、H.263、MPEG-1、MPEG-4）中的编解码器功能块的组成并没有什么区别，主要的不同在于各功能块的细节。由于视频内容时刻在变化，这种内容的多变性就必须采用相应的自适应的技术措施；由于信道在环境恶劣下也是多变的，这就要求采取相应的自适应方法来对抗这种信道畸变带来的不良影响。这两方面的多变带来了自适应压缩技术的复杂性。H.264 就是利用实现的复杂性获得压缩性能的明显改善。</p> 
<p style="margin-left:0cm;">编码器采用的仍是变换和预测的混合编码法。由图2.1，输入的帧或场Fn以宏块为单位被编码器处理。首先，按帧内或帧间预测编码的方法进行处理。如果采用帧内预测编码，其预测值PRED（图中用P 表示）是由当前片中前面已编码的参考图像经运动补偿（MC）后得出，其中参考图像用F’n-1 表示。为了提高预测精度，从而提高压缩比，实际的参考图像可在过去或未来（指显示次序上）已编码解码重建和滤波的帧中进行选择。预测值PRED 和当前块相减后，产生一个残差块Dn，经块变换、量化后产生一组量化后的变换系数X，再经熵编码，与解码所需的一些边信息（如预测模式量化参数、运动矢量等）一起组成一个压缩后的码流，经NAL（网络自适应层）供传输和存储用。正如上述，为了提供进一步预测用的参考图像，编码器必须有重建图像的功能。因此必须使残差图像经反量化、反变换后得到的Dn’与预测值P 相加，得到uFn’（未经滤波的帧）。为了去除编码解码环路中产生的噪声，为了提高参考帧的图像质量，从而提高压缩图像性能，设置了一个环路滤波器，滤波后的输出Fn’即重建图像可用作参考图像。</p> 
<p style="margin-left:0cm;">由图 2.1可知，由编码器的NAL输出一个压缩后的H.264压缩比特流。由图2.2，经熵解码得到量化后的一组变换系数X，再经反量化、反变换，得到残差Dn’。利用从该比特流中解码出的头信息，解码器就产生一个预测块PRED，它和编码器中的原始PRED是相同的。当该解码器产生的PRED与残差Dn’相加后，就产生uFu’，再经滤波后，最后就得到滤波后的Fn’，这个Fn’就是最后的解码输出图像。</p> 
<p><strong>3. Profile</strong><strong>和</strong><strong>Level</strong></p> 
<p style="margin-left:0cm;">H264主要包括Baseline，Ext，Main, High这几种常用profile，各种profile是根据不同的应用场景设计的，具体如下：</p> 
<p style="margin-left:0cm;">Baseline主要是用于可视电话，会议电视，无线通讯等实时通信。要实时，就要减少视频decode和display的时延，所以没有B frame；为了提高针对网络丢包的容错能力，特意添加了FMO，ASO和冗余slice。</p> 
<p style="margin-left:0cm;">Main用于数字广播电视和数字视频存储，侧重点在于提高压缩率，所以有了CABAC，MBAFF，Interlace，B frame等。        </p> 
<p style="margin-left:0cm;">Extend用于改进误码性能和码流切换（SP和SI slice），侧重于码流切换（SI，SP slice）和error resilience（数据分割）。       </p> 
<p style="margin-left:0cm;">High主要用于高压缩效率和质量， 引入8x8 DCT，选择量化矩阵等。</p> 
<p style="margin-left:0cm;">H.264 Baseline profile、Extended profile和Main profile都是针对8位样本数据、4:2:0格式的视频序列，FRExt将其扩展到8～12位样本数据，视频格式可以为4:2:0、4:2:2、4:4:4，设立了High profile（HP）、High 10profile（Hi10P）、High 4:2:2 profile（Hi422P）、High 4:4:4 profile（Hi444P）4个profile，这4个profile都以Main profile为基础。</p> 
<p style="margin-left:0cm;">每个profile 都规定了一个算法特征和限制的子集，任何遵守某个profile 的解码器都应该支持与其相应的子集。   每个level都规定了一组对标准中语法成员（syntax element）所采用的各种参数值的限制。</p> 
<p style="margin-left:0cm;">在给定的profile下，level通常与解码器的处理能力和内存容量相对应。每一个档次设置不同的参数（如取样速率、图像尺寸、编码比特率等），得到对应的编解码器性能的不同level。</p> 
<p><strong>4. 编码数据</strong><span style="color:#000000;">格式</span></p> 
<p><strong><span style="color:#000000;">4.1 H.264 </span></strong><strong><span style="color:#000000;">的编码格式</span></strong></p> 
<p style="margin-left:0cm;">H.264 的功能分为两层，即视频编码层（VCL）和网络提取层（NAL，Network AbstractionLayer）。VCL数据即编码处理的输出，它表示被压缩编码后的视频数据序列。在VCL 数据传输或存储之前，这些编码的VCL数据，先被映射或封装进NAL单元中。</p> 
<p style="margin-left:0cm;">每个NAL单元包括一个原始字节序列负荷（RBSP）、一组对应于视频编码数据的NAL头信息。<span style="color:#000000;">NAL</span><span style="color:#000000;">单元序列的结构见图</span><span style="color:#000000;">4.1</span></p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="77" src="https://images2.imgbox.com/90/36/RplPhuTP_o.png" width="721"></p> 
<p style="margin-left:0cm;">                                                                              图4.1 NAL单元序列</p> 
<p><strong>4.2 <span style="color:#000000;">参考图像</span></strong></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">为了提</span>高预测精度，H.264 编码器可从一组前面或后面已编码图像中选出一个或两个与当前最匹配的图像作为帧间编码间的参考图像，这样一来，复杂度大为增加，但多次比较的结果，使匹配后的预测精度显著改进。H.264 中最多可从15 个参考图像中进行选择，选出最佳的匹配图像。对于P片中帧间编码宏块和宏块分割的预测可从表“0”中选择参考图像；对于B片中的帧间编码宏块和宏块分<span style="color:#000000;">割的预测，可从表</span><span style="color:#000000;">“0”</span><span style="color:#000000;">和</span><span style="color:#000000;">“1”</span><span style="color:#000000;">中选择参考图像。</span></p> 
<p><strong>4.3 <span style="color:#000000;">片和片组</span></strong></p> 
<p style="margin-left:0cm;">一个视频图像可编码成一个或更多个片，每片包含整数个宏块（MB），即每片至少一个MB，最多时每片包含整个图像的宏块。总之，一幅图像中每片的宏块数不一定固定。设片的目的是为了限制误码的扩散和传输，应使编码片相互间是独立的。某片的预测不能以其它片中的宏块为参考图像，这样某一片中的预测误差才不会传播到其它片中去<span style="color:#000000;">。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">编码片共有</span><span style="color:#000000;">5 </span><span style="color:#000000;">种不同类型，除已讲过的</span><span style="color:#000000;">I</span><span style="color:#000000;">片、</span><span style="color:#000000;">P</span><span style="color:#000000;">片、</span><span style="color:#000000;">B</span><span style="color:#000000;">片外，还有</span><span style="color:#000000;">SP</span><span style="color:#000000;">片和</span><span style="color:#000000;">SI</span><span style="color:#000000;">片。片的句法结构见图4.2，其中片头规定了片的类型，该片属于哪个图像，有关的参考图像等，片的数据包含一系列的编码MB，和/或跳编码（不编码）数据。每个MB包含头单元（见表6.1）和残差数据。</span></p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="295" src="https://images2.imgbox.com/26/b0/QafCMczw_o.png" width="580"></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">                                                            图4.2 片的句法结构</span></p> 
<p style="margin-left:0cm;">片组是一个<span style="color:#000000;">编码图象</span>中若干MB的一个子集，它可包含一个或若干个片。MB的分配用MB到片组之间的映射来确定，它表示每一个MB属于哪个片组。</p> 
<p><strong>4.4 帧内预测</strong></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">在帧内</span>预测<span style="color:#000000;">模式中，预测块</span><span style="color:#000000;">P</span><span style="color:#000000;">是基于已编码重建块和当前块形成的。对亮度像素而言，</span><span style="color:#000000;">P</span><span style="color:#000000;">块用于</span><span style="color:#000000;">4×4</span><span style="color:#000000;">子块或者</span><span style="color:#000000;">16×16</span><span style="color:#000000;">宏块的相关操作。</span><span style="color:#000000;">4×4</span><span style="color:#000000;">亮度子块有</span><span style="color:#000000;">9</span><span style="color:#000000;">种可选预测模式，独立预测每一个</span><span style="color:#000000;">4×4</span><span style="color:#000000;">亮度子块，适用于带有大量细节的图像编码；</span><span style="color:#000000;">16×16</span><span style="color:#000000;">亮度块有</span><span style="color:#000000;">4</span><span style="color:#000000;">种预测模式，预测整个</span><span style="color:#000000;">16×16</span><span style="color:#000000;">亮度块，适用于平坦区域图像编码；色度块也有</span><span style="color:#000000;">4</span><span style="color:#000000;">种预测模式，类似于</span><span style="color:#000000;">16×16</span><span style="color:#000000;">亮度块预测模式。编码器通常选择使</span><span style="color:#000000;">P</span><span style="color:#000000;">块和编码块之间差异最小的预测模式。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">此外，还有一种帧内编码模式称为I_PCM 编码模式。该模式下，编码器直接传输图像像素值，而不经过预测和变换。在一些特殊的情况下，特别是图像内容不规则或者量化参数非常低时该模式比起</span><span style="color:#000000;">“</span><span style="color:#000000;">常规操作</span><span style="color:#000000;">”</span><span style="color:#000000;">（帧内预测</span><span style="color:#000000;">—</span><span style="color:#000000;">变换</span><span style="color:#000000;">—</span><span style="color:#000000;">量化</span><span style="color:#000000;">—</span><span style="color:#000000;">熵编码）效率更高。I_PCM 模式用于以下目的：</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">1</span><span style="color:#000000;">） 允许编码器精确的表示像素值。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">2</span><span style="color:#000000;">） 提供表示不规则图像内容的准确值，而不引起重大的数据量增加。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">3</span><span style="color:#000000;">） 严格限制宏块解码比特数，但不损害编码效率。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">在以往H.263+、MPEG-4 等视频压缩编码标准中，帧内编码被引入变换域。H.264帧内编码则参考预测块左方或者上方的已编码块的邻近像素点，被引入空间域。但是，如果参考预测块是帧间编码宏块，该预测会因参考块的运动补偿引起误码扩散。所以，参考块通常选取帧内编码的邻近块。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">包括帧内预测的所有预测都不能跨片边界预测，每片必须独立编解码。</span></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">帧内预测以绝对误差和（SAE）为标准选取最佳预测模式，使预测帧更加接近原始帧，减少了相互间的差异，去除时间上的数据冗余，提高了编码的压缩效率。帧内预测中，块或宏块利用已编码并重建的块作为参考，进行预测。具体编程时，编码器通过计算并比较各种模式下的SAE，选取SAE 值最小的模式作为最佳预测模式，并将该模式信息化，同时传送至解码端，以供正确解码。</span></p> 
<p><strong>4.5 帧间预测</strong></p> 
<p style="margin-left:0cm;">H.264<span style="color:#000000;">帧间预测是利用已编码视频帧/场和基于块的运动补偿的预测模式。与以往标准帧间预测的区别在于块尺寸范围更广（从16</span><span style="color:#000000;">×</span><span style="color:#000000;">16 </span><span style="color:#000000;">到4</span><span style="color:#000000;">×</span><span style="color:#000000;">4</span><span style="color:#000000;">）、亚像素运动矢量的使用（亮度采用1/4 像素精度MV</span>）及多参考帧的运用等等。</p> 
<p><strong>4.5.1 树状结构运动补偿</strong></p> 
<p style="margin-left:0cm;">每个宏块（16×16 像素）可以4种方式分割：一个16×16，两个16×8，两个8×16，四个8×8。其运动补偿也相应有四种。而8×8 模式的每个子宏块还可以四种方式分割：一个8×8，两个4×8 或两个8×4 及4 个4×4。这些分割和子宏块大大提高了各宏块之间的关联性。这种分割下的运动补偿则称为树状结构运动补偿。</p> 
<p style="margin-left:0cm;">每个分割或子宏块都有一个独立的运动补偿。每个MV必须被编码、传输，分割的选择也需编码到压缩比特流中。对大的分割尺寸而言，MV选择和分割类型只需少量的比特，但运动补偿残差在多细节区域能量将非常高。小尺寸分割运动补偿残差能量低，但需要较多的比特表征MV和分割选择。分割尺寸的选择影响了压缩性能。整体而言，大的分割尺寸适合平坦区域，而小尺寸适合多细节区域。</p> 
<p style="margin-left:0cm;">举例：图4.3 显示了一个残差帧（没有进行运动补偿）。H.264 编码器为帧的每个部分选择了最佳分割尺寸，使传输信息量最小，并将选择的分割加到残差帧上。在帧变化小的区域（残差显示灰色），选择16×16分割；多运动区域（残差显示黑色或白色），选择更有效的小的尺寸。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="293" src="https://images2.imgbox.com/13/2c/uDZNNCCH_o.png" width="396"></p> 
<p><strong>4.5.2 运动矢量</strong></p> 
<p style="margin-left:0cm;">帧间编码宏块的每个分割或者子宏块都是从参考图像某一相同尺寸区域预测而得。两者之间的差异（MV）对亮度成分采用1/4 像素精度，色度1/8 像素精度。亚像素位置的亮度和色度像素并不存在于参考图像中，需利用邻近已编码点进行内插而得。</p> 
<p><strong>4.5.3 MV</strong><strong>预测</strong></p> 
<p style="margin-left:0cm;">每个分割MV的编码需要相当数目的比特，特别是使用小分割尺寸时。为减少传输比特数，可利用邻近分割的MV较强的相关性，MV可由邻近已编码分割的MV预测而得。预测矢量MVp基于已计算MV和MVD（预测与当前的差异）并被编码和传送。MVp则取决于运动补偿尺寸和邻近MV的有无。</p> 
<p> </p> 
<p><strong><span style="color:#000000;">4.5.4 整数变换与量化</span></strong></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">为了进</span>一步节省图像传输码率，需要对图像信号进行压缩，一般方法为去除图像信号中的相关性及减小图像编码的动态范围，通常采用变换编码及量化。变换编码将图像时域信号变换成频域信号，在频域中图像信号能量大部分集中在低频区域，相对时域信号，码率有较大的下降。H.264 对图像或预测残差采用了4×4 整数离散余弦变换技术，避免了以往标准中使用的通用8×8 离散余弦变换逆变换经常出现的失配问题。量化过程根据图像的动态范围大小确定量化参数，既保留图像必要的细节，又减少码流。</p> 
<p style="margin-left:0cm;">在图像编码中，变换编码和量化从原理上讲是两个独立的过程。但在H.264 中，将两个过程中的乘法合二为一，并进一步采用整数运算，减少编解码的运算量，提高图像压缩的实时性，这些措施对峰值信噪比（PSNR）的影响很小，一般低于0.02dB，可不计。</p> 
<p style="margin-left:0cm;">量化过程在不降低视觉效果的前提下减少图像编码长度，减少视觉恢复中不必要的信息。H.264采用标量量化技术，它将每个图像样点编码映射成较小的数值。</p> 
<p style="margin-left:0cm;"><span style="color:#000000;">在量化和反量</span>化过程中，量化步长QP决定量化器的编码压缩率及图像精度。如果QP比较大，则量化值FQ动态范围较小，其相应的编码长度较小，但反量化时损失较多的图像细节信息；如果QP比较小，则FQ动态范围较大，相应的编码长度也较大，但图像细节信息损失较少。编码器根据图像值实际动态范围自动改变QP 值，在编码长度和图像精度之间折衷，达到整体最佳效果。</p> 
<p style="margin-left:0cm;">在H.264 中，量化步长共有52 个值。当QP取最小值0 时代表最精细的量化，当QP取最大值51时代表最粗糙的量化。对于色度编码，一般使用与亮度编码同样的量化步长。为了避免在较高量化步长时的出现颜色量化人工效应，色度的QP最大值大约限制在亮度QP 最大值的80％范围内，亮度QP的最大值是51，而色度QP的最大值是39。</p> 
<p><strong>4.5.5 <span style="color:#000000;">CAVLC(基于上下文自适应的可变长编码)</span></strong></p> 
<p style="margin-left:0cm;">熵编码是无损压缩编码方法，它生成的码流可以经解码无失真地恢复出原数据。熵编码是建立在随机过程的统计特性基础上的。</p> 
<p style="margin-left:0cm;">熵的大小与信源的概率模型有着密切的关系，各个符号出现的概率不同，信源的熵也不同。当信源中各事件是等概率分布时，熵具有极大值。信源的熵与其可能达到的最大值之间的差值反映了该信源所含有的冗余度。信源的冗余度越小，即每个符号所独立携带的信息量越大，那么传送相同的信息量所需要的序列长度越短，符号位越少。因此，数据压缩的一个基本的途径是去除信源的符号之间的相关性，尽可能地使序列成为无记忆的，即前一符号的出现不影响以后任何一个符号出现的概率。</p> 
<p style="margin-left:0cm;">在H.264的CAVLC(基于上下文自适应的可变长编码)中，通过根据已编码句法元素的情况动态调整编码中使用的码表，取得了极高的压缩比。</p> 
<p style="margin-left:0cm;">CAVLC用于亮度和色度残差数据的编码。残差经过变换量化后的数据表现出如下特性：4*4 块数据经过预测、变换、量化后，非零系数主要集中在低频部分，而高频系数大部分是零；量化后的数据经过zig-zag 扫描，DC系数附近的非零系数值较大，而高频位置上的非零系数值大部分是+1 和-1；相邻的4*4 块的非零系数的数目是相关的。CAVLC 充分利用残差经过整数变换、量化后数据的特性进行压缩，进一步减少数据中的冗余信息，为H.264 卓越的编码效率奠定了基础。</p> 
<p style="margin-left:0cm;">利用相邻已编码符号所提供的相关性，为所要编码的符号选择合适的上下文模型。利用合适的上下文模型，就可以大大降低符号间的冗余度。在CAVLC 中上下文模型的选择主要体现在两个方面, 非零系数编码所需表格的选择以及拖尾系数后缀长度的更新。</p> 
<p><strong>4.5.6 <span style="color:#000000;">CABAC(基于上下文的自适应二进制算术熵编码)</span></strong></p> 
<p style="margin-left:0cm;">算术编码的思想是用0到1的区间上的一个数来表示一个字符输入流，它的本质是为整个输入流分配一个码字，而不是给输入流中的每个字符分别指定码字。算术编码是用区间递进的方法来为输入流寻找这个码字的，它从于第一个符号确定的初始区间（0 到1）开始，逐个字符地读入输入流，在每一个新的字符出现后递归地划分当前区间，划分的根据是各个字符的概率，将当前区间按照各个字符的概率划分成若干子区间，将当前字符对应的子2 区间取出，作为处理下一个字符时的当前区间。到处理完最后一个字符后，得到了最终区间，在最终区间中任意挑选一个数作为输出。解码器按照和编码相同的方法和步骤工作，不同的是作为逆过程，解码器每划分一个子区间就得到输入流中的一个字符。</p> 
<p style="margin-left:0cm;">CABAC 中内建了由大量实验统计而得到的概率模型。在编码过程中，CABAC 根据当前所要编码的内容以及先前已编码好内容，动态地选择概率模型来进行编码，并实时更新相对应的概率模型。并且，CABAC 在计算量和编码速度上进行了优化，用了量化查表、移位、逻辑运算等方法代替复杂的概率估计和乘法运算。在实际应用中，CABAC与其它主流的熵编码方式相比有更高的编码效率,用一组质量在28~40dB 的视频图像做测试，应用CABAC可使比特率进一步提高9%~14%。</p> 
<p><strong>4.5.7 <span style="color:#000000;">去方块滤波</span></strong></p> 
<p style="margin-left:0cm;">H.264/MPEG-4 AVC 视频编码标准中，在编解码器反变换量化后图像会出现方块效应。其产生的原因有两个。最重要的一个原因是基于块的帧内和帧间预测残差的DCT变换。变换系数的量化过程相对粗糙，因而反量化过程恢复的变换系数带有误差，会造成在图像块边界上的视觉不连续。第二个原因来自于运动补偿预测。运动补偿块可能是从不是同一帧的不同位置上的内插样点数据复制而来。因为运动补偿块的匹配不可能是绝对准确的，所以就会在复制块的边界上产生数据不连续。当然，参考帧中存在的边界不连续也被复制到需要补偿的图像块内。尽管H.264/MPEG-4 AVC采用较小的4×4变换尺寸可以降低这种不连续现象，但仍需要一个去方块滤波器以最大程度提高编码性能。</p> 
<p style="margin-left:0cm;">在视频编解码器中加入去方块滤波器的方法有两种：后置滤波器和环路滤波器。后置滤波器只处理编码环路外的显示缓冲器中的数据，所以它不是标准化过程中的规范内容，在标准中只是可选项。相反，环路滤波器处理编码环路中的数据。在编码器中，被滤波的图像帧作为后续编码帧运动补偿的参考帧；在解码器中，滤波后的图像输出显示。这要求所有与本标准一致的解码器采用同一个滤波器以与编码器同步。当然如果有必要，解码器也还可以在使用环路滤波器的同时使用后置滤波器。</p> 
<p style="margin-left:0cm;">自适应去方块滤波器利用简单的算法可靠地提高图像的主客观质量。其较好的性能是因为可靠地区分了真实的和人为的图像边界，并有效地滤除后者。在相同的PSNR 下可以节省码流超过9%，并同时明显地提高图像视觉质量。</p> 
<p><strong>4.5.8 <span style="color:#000000;">参考图像管理</span></strong></p> 
<p style="margin-left:0cm;">H.264 中，已编码图像存储在编码器和解码器的参考缓冲区（DPB，解码图像缓冲区），并有相应的参考图像列表list0，以供帧间宏块的运动补偿预测使用。对B片预测而言，list0包含当前图像的前面和后面两个方向的图像，并以显示次序排列；也可同时包含短期和长期参考图像。这里，已编码图像由编码器重建的标为短期图像或刚刚编码图像，并由其帧号标定。长期参考图像是较早的图像，由LongTermPicNum 标定，保存在DPB 中，直到被代替或删除。</p> 
<p style="margin-left:0cm;">由编码器发送的自适应内存控制命令用来管理短期和长期参考图像索引。参考图像缓冲区通常由编码器发送的IDR（瞬时解码器刷新）编码图像刷新，IDR 图像一般为I片或SI 片。当接受到IDR 图像时，解码器立即将缓冲区中的图像标为“非参考”。后继的片进行无图像参考编码。通常，编码视频序列的第一幅图像都是IDR 图形</p> 
<p style="margin-left:0cm;"><strong>4.5.9 ​​​​​​​<span style="color:#000000;">隔行视频</span></strong></p> 
<p style="margin-left:0cm;">效率高的隔行视频编码工具应该能优化场宏块的压缩。如果场编码被支持，图像的类型（场或帧）在片头中表示。H.264 采用宏块自适应帧场编码（MB-AFF）模式中，帧场编码的选择在宏块级中指定。且当前片通常是16亮度像素宽和32亮度像素高的单元组成，并以宏块对的形式编码。编码器可按两个帧宏块或者两个场宏块来编码每个宏块对，也可根据图像每个区域选择最佳编码模式。</p> 
<p><strong>5 H.264 </strong><strong>传输</strong></p> 
<p style="margin-left:0cm;">H.264 的编码视频序列包括一系列的NAL 单元，每个NAL 单元包含一个RBSP。如表5.1 所示。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="236" src="https://images2.imgbox.com/98/d1/iyIcPdEH_o.png" width="589"></p> 
<p style="margin-left:0cm;">表5.1 RBSP描述</p> 
<p style="margin-left:0cm;">编码片（包括数据分割片和IDR片）和序列RBSP结束符被定义为VCL NAL单元，其余的为NAL 单元。典型的RBSP 单元序列如图5.2所示。每个单元都按独立的NAL单元传送。NAL单元的头信息（一个字节）定义了RBSP 单元的类型，NAL 单元的其余部分则为RBSP 数据。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="56" src="https://images2.imgbox.com/62/ed/75PvLhBQ_o.png" width="461"></p> 
<p style="margin-left:0cm;">图5.2 RBSP序列</p> 
<p><strong>5.1 <span style="color:#000000;">参数集</span></strong></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">H.264</span><span style="color:#000000;">引入了参数集</span>的概念，每个参数集包含了相应的编码图像的信息。序列参数集SPS包含的是针对一连续编码视频序列的参数，如标识符seq_parameter_set_id、帧数及POC 的约束、参考帧数目、解码图像尺寸和帧场编码模式选择标识等等。图像参数集PPS 对应的是一个序列中某一幅图像或者某几幅图像 ，其参数如标识符pic_parameter_set_id、可选的seq_parameter_set_id、熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系数调整标识等等。</p> 
<p style="margin-left:0cm;">通常，SPS和PPS在片的头信息和数据解码前传送至解码器。每个片的头信息对应一个pic_parameter_set_id，PPS被其激活后一直有效到下一个PPS被激活；类似的，每个PPS 对应一个seq_parameter_set_id，SPS被其激活以后将一直有效到下一个SPS被激活。参数集机制将一些重要的、改变少的序列参数和图像参数与编码片分离，并在编码片之前传送至解码端，或者通过其他机制传输。</p> 
<p><strong>5.2 <span style="color:#000000;">NAL</span><span style="color:#000000;">单元传输和存储</span></strong></p> 
<p style="margin-left:0cm;"><span style="color:#000000;">H.2</span>64标准并未定义NAL单元的传输方式，但实际中根据不同的传输环境其传输方式还是存在一定的差异。如在包传输网络中，每个NAL单元以独立的包传输，在解码之前进行重新排序。在电路交换传输环境中，传输之前须在每个NAL单元之前加上起始前缀码，使解码器能够找出NAL单元的起始位置。在一些应用中，编码视频需要和音频及相关信息一起传输存储，这就需要一些机制来实现，目前通常用的是RTP/UDP协议协同实现。MPEG-2 System 部分的一个改进版本规定了H.264视频传输机制，ITU-T H.241定义了用H.264连接H.32*多媒体终端。对要求视频、音频及其他信息一起存储流媒体回放、DVD回放等应用，将推出的MPEG-4 System改进版本定义了H.264 编码数据和相关媒体流是如何以ISO的媒体<span style="color:#000000;">文件格式存储的。</span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/71907cfa4b57608a3a1b22b6b567b912/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ImportError: dynamic module does not define module export function (PyInit_cv2)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0a79c432f61f7f7547638e636aed4f93/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">各种友(e)善(xin)数论总集，从入门到绝望1---基础数论知识以及矩阵树（未完待续）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>