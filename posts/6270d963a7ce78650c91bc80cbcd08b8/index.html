<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习入门（五）：卷积神经网络 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习入门（五）：卷积神经网络" />
<meta property="og:description" content="卷积神经网络 本章的主题是卷积神经网。CNN被用于图像识别、语言识别等各种场合。
整体结构 之前介绍的神经网络中，相邻层的所有神经元之间都有连接。这称为全连接。CNN中新增了Convolution层和Pooling层。CNN层的连接顺序是“Convolution-ReLU-(Pooling)”（Pooling层有时会被省略）。这可以理解为之前的“affine-ReLU”连接被替换成了“Convolution-ReLU-(Pooling)”连接。
卷积层 CNN中出现了一些特有的术语。比如填充，步幅等。此外，各层中传递的数据都是有形状的数据。
全连接层存在的问题 全连接层存在什么问题呢？那就是数据的形状被”忽视“了。比如，输入数据是图像时，图像通常时高，长、通道方向上的3维形状。但是，向全连接层输入时，需要将3维数据拉平维1维数据。
图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值，RGB的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3维形状中可能隐藏有值得提取的本质模式。
而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维数据的形式接受输入数据，并同样以 3维数据的形式输出至下一层。因此，在CNN中，可以（有可能）正确理解图像等具有形状的数据。
另外，CNN中，有时将卷积层的输入输出数据称为特征图。其中，卷积层的输入数据称为输入特征图，输出数据称为输出特征图。
卷积运算 卷积层进行的处理就是卷积运算。
对于输入数据，卷积运算 以一定间隔滑动滤波器的窗口并应用。将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积累加运算）。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出。
CNN中，滤波器的参数就对应之间的权重。
包含偏置的卷积运算的处理流
填充 在卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为填充，是卷积运算中经常会用到的处理。在下图中对大小为（4，4）的输入数据应用了幅度为1的填充。”幅度为1的填充“是指用幅度为1像素的0填充周围。
通过填充，大小为（4，4）的输入数据变成了（6，6）的形状。然后，应用大小为（3，3）的滤波器，生成了大小为（4，4）的输出数据。
使用填充主要是为了调整输出的大小。比如，对大小为（4，4）的输入数据应用（3，3）的滤波器时，输出大小变为（2，2），相当于输出大小比输入大小缩小了2个元素。在反复进行多次卷积运算的深度网络中会成为问题。为什么呢？因为如果每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为1，导致无法再应用卷积运算。
步幅 应用滤波器的位置间隔称为步幅。
如果将步幅设为2，应用滤波器的窗口间隔变为2个元素。
综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。如何计算输出大小。
假设输入大小为（H,W）,滤波器大小为（FH,FW），输出大小为（OH,OW）,填充为P，步幅为S。此时，输出大小 O H = H &#43; 2 P − F H S &#43; 1 OH=\frac{H&#43;2P-FH}{S}&#43;1 OH=SH&#43;2P−FH​&#43;1 O W = W &#43; 2 P − F W S &#43; 1 OW=\frac{W&#43;2P-FW}{S}&#43;1 OW=SW&#43;2P−FW​&#43;1
上述公式只适用于可以除尽的情况。
3维数据的卷积运算 通道方向上有多个特征图时，会按通道进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。
在3维数据的卷积运算中， 输入数据和滤波器的通道数要设为相同的值。滤波器的大小可以设定为任意值（不过，每个通道的滤波器大小要全部相同）。
在这个例子中，数据输出是1张特征图。所谓1张特征图，就是通道数为1的特征图。那么，如果要在通道方向上也拥有多个卷积运算的输出，该怎么做？为此，就需要多个滤波器。
如果追加偏置的加法运算处理，结果如下：
不同形状的方块相加时，可以基于NumPy的广播功能轻松实现。
批处理 神经网络的处理中进行了将输入数据打包的批处理。通过批处理，能够实现处理的高效化和学习时对mini-batch的对应。
我们希望卷积运算也同样对应批处理。为此，需要将在各层间传递的数据保存为4维数据。（batch_num,channel,height,width）的顺序保存数据。
也就是说，批处理将N次的处理汇总成了1次进行。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6270d963a7ce78650c91bc80cbcd08b8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-01T22:01:58+08:00" />
<meta property="article:modified_time" content="2021-01-01T22:01:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习入门（五）：卷积神经网络</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>卷积神经网络</h2> 
<p>本章的主题是卷积神经网。CNN被用于图像识别、语言识别等各种场合。</p> 
<h3><a id="_2"></a>整体结构</h3> 
<p>之前介绍的神经网络中，相邻层的所有神经元之间都有连接。这称为<strong>全连接</strong>。CNN中新增了Convolution层和Pooling层。CNN层的连接顺序是“Convolution-ReLU-(Pooling)”（Pooling层有时会被省略）。这可以理解为之前的“affine-ReLU”连接被替换成了“Convolution-ReLU-(Pooling)”连接。</p> 
<h3><a id="_4"></a>卷积层</h3> 
<p>CNN中出现了一些特有的术语。比如填充，步幅等。此外，各层中传递的数据都是有形状的数据。</p> 
<h4><a id="_6"></a>全连接层存在的问题</h4> 
<p>全连接层存在什么问题呢？那就是数据的形状被”忽视“了。比如，输入数据是图像时，图像通常时高，长、通道方向上的3维形状。但是，向全连接层输入时，需要将3维数据拉平维1维数据。<br> 图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值，RGB的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3维形状中可能隐藏有值得提取的本质模式。<br> 而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维数据的形式接受输入数据，并同样以 3维数据的形式输出至下一层。因此，在CNN中，可以（有可能）正确理解图像等具有形状的数据。<br> 另外，CNN中，有时将卷积层的输入输出数据称为<strong>特征图</strong>。其中，卷积层的输入数据称为<strong>输入特征图</strong>，输出数据称为<strong>输出特征图</strong>。</p> 
<h4><a id="_11"></a>卷积运算</h4> 
<p>卷积层进行的处理就是卷积运算。<br> 对于输入数据，卷积运算 以一定间隔滑动滤波器的窗口并应用。将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为<strong>乘积累加运算</strong>）。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出。<br> CNN中，滤波器的参数就对应之间的权重。<img src="https://images2.imgbox.com/d2/35/MYDD0Yvm_o.png" alt="在这里插入图片描述"></p> 
<p>包含偏置的卷积运算的处理流<br> <img src="https://images2.imgbox.com/ae/8d/HZROQsq6_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="_18"></a>填充</h4> 
<p>在卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为填充，是卷积运算中经常会用到的处理。在下图中对大小为（4，4）的输入数据应用了幅度为1的填充。”幅度为1的填充“是指用幅度为1像素的0填充周围。<br> <img src="https://images2.imgbox.com/47/c7/vKvsKNjp_o.png" alt="在这里插入图片描述"><br> 通过填充，大小为（4，4）的输入数据变成了（6，6）的形状。然后，应用大小为（3，3）的滤波器，生成了大小为（4，4）的输出数据。<br> 使用填充主要是为了调整输出的大小。比如，对大小为（4，4）的输入数据应用（3，3）的滤波器时，输出大小变为（2，2），相当于输出大小比输入大小缩小了2个元素。在反复进行多次卷积运算的深度网络中会成为问题。为什么呢？因为如果每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为1，导致无法再应用卷积运算。</p> 
<h4><a id="_23"></a>步幅</h4> 
<p>应用滤波器的位置间隔称为<strong>步幅</strong>。<br> <img src="https://images2.imgbox.com/02/28/8FrsuOt9_o.png" alt="在这里插入图片描述"><br> 如果将步幅设为2，应用滤波器的窗口间隔变为2个元素。<br> 综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。如何计算输出大小。<br> 假设输入大小为（H,W）,滤波器大小为（FH,FW），输出大小为（OH,OW）,填充为P，步幅为S。此时，输出大小<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          O 
         
        
          H 
         
        
          = 
         
         
          
          
            H 
           
          
            + 
           
          
            2 
           
          
            P 
           
          
            − 
           
          
            F 
           
          
            H 
           
          
         
           S 
          
         
        
          + 
         
        
          1 
         
        
       
         OH=\frac{H+2P-FH}{S}+1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.04633em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          O 
         
        
          W 
         
        
          = 
         
         
          
          
            W 
           
          
            + 
           
          
            2 
           
          
            P 
           
          
            − 
           
          
            F 
           
          
            W 
           
          
         
           S 
          
         
        
          + 
         
        
          1 
         
        
       
         OW=\frac{W+2P-FW}{S}+1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.04633em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span><br> 上述公式只适用于可以除尽的情况。</p> 
<h4><a id="3_30"></a>3维数据的卷积运算</h4> 
<p><img src="https://images2.imgbox.com/23/5e/dXdVvT0f_o.png" alt="在这里插入图片描述"><br> 通道方向上有多个特征图时，会按通道进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。<br> 在3维数据的卷积运算中， 输入数据和滤波器的通道数要设为相同的值。滤波器的大小可以设定为任意值（不过，每个通道的滤波器大小要全部相同）。<img src="https://images2.imgbox.com/74/0e/o2aGG9WI_o.png" alt="在这里插入图片描述"><br> 在这个例子中，数据输出是1张特征图。所谓1张特征图，就是通道数为1的特征图。那么，如果要在通道方向上也拥有多个卷积运算的输出，该怎么做？为此，就需要多个滤波器。<img src="https://images2.imgbox.com/71/29/bB4aSMZm_o.png" alt="在这里插入图片描述"><br> 如果追加偏置的加法运算处理，结果如下：<br> <img src="https://images2.imgbox.com/1f/eb/PGFQL6v3_o.png" alt="在这里插入图片描述"><br> 不同形状的方块相加时，可以基于NumPy的广播功能轻松实现。</p> 
<h4><a id="_38"></a>批处理</h4> 
<p>神经网络的处理中进行了将输入数据打包的批处理。通过批处理，能够实现处理的高效化和学习时对mini-batch的对应。<br> 我们希望卷积运算也同样对应批处理。为此，需要将在各层间传递的数据保存为4维数据。（batch_num,channel,height,width）的顺序保存数据。<br> 也就是说，批处理将N次的处理汇总成了1次进行。<br> <img src="https://images2.imgbox.com/99/a2/RenFpqfI_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_43"></a>池化层</h3> 
<p>池化是缩小高，长方向上的空间的运算。<br> <img src="https://images2.imgbox.com/a5/4e/Z9tVI2H8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/65/25/SsrEIZHM_o.png" alt="在这里插入图片描述"><br> 这个例子是按步幅进行2×2的Max池化时的处理顺序。“Max池化”是获取最大值的运算。“2×2”表示目标区域的大小。从2×2区域中取出最大的元素。此外，这个例子将步幅设为了2，所以2×2的窗口的移动间隔为2个元素，另外，一般来说，<strong>池化窗口的大小会和步幅设定成相同的值</strong>。<br> 除了Max池化之外，还有Average池化等。相对于Max池化是从目标区域中取出最大值，Average池化则是计算目标区域的平均值。</p> 
<h4><a id="_49"></a>池化层的特征</h4> 
<ul><li>没有要学习的参数</li><li>通道数不发生变化</li><li>对微小的位置变化具有鲁棒性（健壮）</li></ul> 
<h3><a id="_53"></a>卷积层和池化层的实现</h3> 
<h4><a id="im2col_54"></a>基于im2col的展开</h4> 
<p>im2col是一个函数，将输入数据展开以适合滤波器（权重）对三维的输入数据应用im2col后，数据转换为2维矩阵。<br> im2col会把输入数据展开以适合滤波器。对于输入数据，将应用滤波器的区域（3维方块）横向展开为1列。im2col会在所有应用滤波器的地方进行这个展开处理。<br> 使用im2col的实现存在比普通的实现比普通的实现消耗更多内存的缺点，由于滤波器的应用区域几乎都是重叠的。但是，汇总成一个大的矩阵进行计算，对计算机的实现颇有益处，比如，在矩阵计算的库（线性代数库）等中，矩阵计算的实现已被高度最优化。可以高效地进行大矩阵的乘法运算。<br> <img src="https://images2.imgbox.com/a5/73/AF5tjy9R_o.jpg" alt="在这里插入图片描述"><br> 使用im2col展开输入数据后，之后就只需将卷积层的滤波器纵向展开为1列，并计算2个矩阵的乘积即可。然后将2维输出数据转换维合适的形状。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">im2col</span><span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> filter_h<span class="token punctuation">,</span> filter_w<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""

    Parameters
    ----------
    input_data : 由(数据量, 通道, 高, 长)的4维数组构成的输入数据
    filter_h : 滤波器的高
    filter_w : 滤波器的长
    stride : 步幅
    pad : 填充

    Returns
    -------
    col : 2维数组
    """</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> input_data<span class="token punctuation">.</span>shape
    out_h <span class="token operator">=</span> <span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>pad <span class="token operator">-</span> filter_h<span class="token punctuation">)</span><span class="token operator">//</span>stride <span class="token operator">+</span> <span class="token number">1</span>
    out_w <span class="token operator">=</span> <span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>pad <span class="token operator">-</span> filter_w<span class="token punctuation">)</span><span class="token operator">//</span>stride <span class="token operator">+</span> <span class="token number">1</span>

    img <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>pad<span class="token punctuation">,</span> pad<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>pad<span class="token punctuation">,</span> pad<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'constant'</span><span class="token punctuation">)</span>
    col <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> filter_h<span class="token punctuation">,</span> filter_w<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> y <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>filter_h<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_max <span class="token operator">=</span> y <span class="token operator">+</span> stride<span class="token operator">*</span>out_h
        <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>filter_w<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x_max <span class="token operator">=</span> x <span class="token operator">+</span> stride<span class="token operator">*</span>out_w
            col<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> y<span class="token punctuation">:</span>y_max<span class="token punctuation">:</span>stride<span class="token punctuation">,</span> x<span class="token punctuation">:</span>x_max<span class="token punctuation">:</span>stride<span class="token punctuation">]</span>

    col <span class="token operator">=</span> col<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token operator">*</span>out_h<span class="token operator">*</span>out_w<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> col

</code></pre> 
<h4><a id="_95"></a>卷积层的实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Convolution</span><span class="token punctuation">:</span>
	<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		self<span class="token punctuation">.</span>W <span class="token operator">=</span> W
		self<span class="token punctuation">.</span>b <span class="token operator">=</span> b
		self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
		self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad
	
	<span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		FN<span class="token punctuation">,</span> C<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>shape
		N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
		out_h <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>self<span class="token punctuation">.</span>pad<span class="token operator">-</span>FH<span class="token punctuation">)</span><span class="token operator">/</span>self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>
		out_w <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>self<span class="token punctuation">.</span>pad<span class="token operator">-</span>FW<span class="token punctuation">)</span><span class="token operator">/</span>self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>
		
		col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
		col_W <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>FN<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T   <span class="token comment"># 滤波器的展开</span>
		out <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>col<span class="token punctuation">,</span> col_W<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b

		out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

		<span class="token keyword">return</span> out
</code></pre> 
<p>transpose会更改多维数组的轴的顺序。</p> 
<h4><a id="_120"></a>池化层的实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Pooling</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pool_h<span class="token punctuation">,</span> pool_w<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pool_h <span class="token operator">=</span> pool_h
        self<span class="token punctuation">.</span>pool_w <span class="token operator">=</span> pool_w
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        out_h <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>
        out_w <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>

        <span class="token comment"># 展开</span>
        col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
        col <span class="token operator">=</span> col<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h <span class="token operator">*</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span>
        
        <span class="token comment"># 最大值</span>
        out <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>col<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 转换</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> out
</code></pre> 
<h3><a id="CNN_148"></a>CNN的实现</h3> 
<p>网络的构成是“Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax”,我们将它命名为SimpleConvNet的类</p> 
<h4><a id="_150"></a>参数</h4> 
<ul><li>input_dim ——输入数据的维度：（通道，高，长）</li><li>conv_param —— 卷积层的超参数（字典）。字典的关键字如下：<br> - filiter_num——滤波器的数量<br> - filter_size —— 滤波器的大小<br> - stride——步幅<br> - pad——填充</li><li>hidden_size——隐藏层（全连接）的神经元数量</li><li>output_size——输出层（全连接）的神经元数量</li><li>weight_int_std——初始化时权重的标准差</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">SimpleConvNet</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""简单的ConvNet

    conv - relu - pool - affine - relu - affine - softmax
    
    Parameters
    ----------
    input_size : 输入大小（MNIST的情况下为784）
    hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]）
    output_size : 输出大小（MNIST的情况下为10）
    activation : 'relu' or 'sigmoid'
    weight_init_std : 指定权重的标准差（e.g. 0.01）
        指定'relu'或'he'的情况下设定“He的初始值”
        指定'sigmoid'或'xavier'的情况下设定“Xavier的初始值”
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                 conv_param<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'filter_num'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'filter_size'</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'pad'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'stride'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                 hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        filter_num <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'filter_num'</span><span class="token punctuation">]</span>
        filter_size <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'filter_size'</span><span class="token punctuation">]</span>
        filter_pad <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span>
        filter_stride <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
        input_size <span class="token operator">=</span> input_dim<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        conv_output_size <span class="token operator">=</span> <span class="token punctuation">(</span>input_size <span class="token operator">-</span> filter_size <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>filter_pad<span class="token punctuation">)</span> <span class="token operator">/</span> filter_stride <span class="token operator">+</span> <span class="token number">1</span>
        pool_output_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>filter_num <span class="token operator">*</span> <span class="token punctuation">(</span>conv_output_size<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>conv_output_size<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 初始化权重</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>filter_num<span class="token punctuation">,</span> input_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> filter_size<span class="token punctuation">,</span> filter_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>filter_num<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>pool_output_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>

        <span class="token comment"># 生成层</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Convolution<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                           conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Pool1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Pooling<span class="token punctuation">(</span>pool_h<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> pool_w<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>last_layer <span class="token operator">=</span> SoftmaxWithLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""求损失函数
        参数x是输入数据、t是教师标签
        """</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>last_layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> t<span class="token punctuation">.</span>ndim <span class="token operator">!=</span> <span class="token number">1</span> <span class="token punctuation">:</span> t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        acc <span class="token operator">=</span> <span class="token number">0.0</span>
        
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            tx <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>batch_size<span class="token punctuation">]</span>
            tt <span class="token operator">=</span> t<span class="token punctuation">[</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>batch_size<span class="token punctuation">]</span>
            y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tx<span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y <span class="token operator">==</span> tt<span class="token punctuation">)</span> 
        
        <span class="token keyword">return</span> acc <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""求梯度（数值微分）

        Parameters
        ----------
        x : 输入数据
        t : 教师标签

        Returns
        -------
        具有各层的梯度的字典变量
            grads['W1']、grads['W2']、...是各层的权重
            grads['b1']、grads['b2']、...是各层的偏置
        """</span>
        loss_w <span class="token operator">=</span> <span class="token keyword">lambda</span> w<span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        grads <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            grads<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            grads<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> grads

    <span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""求梯度（误差反向传播法）

        Parameters
        ----------
        x : 输入数据
        t : 教师标签

        Returns
        -------
        具有各层的梯度的字典变量
            grads['W1']、grads['W2']、...是各层的权重
            grads['b1']、grads['b2']、...是各层的偏置
        """</span>
        <span class="token comment"># forward</span>
        self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        <span class="token comment"># backward</span>
        dout <span class="token operator">=</span> <span class="token number">1</span>
        dout <span class="token operator">=</span> self<span class="token punctuation">.</span>last_layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>

        layers <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layers<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            dout <span class="token operator">=</span> layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>

        <span class="token comment"># 设定</span>
        grads <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
        grads<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db

        <span class="token keyword">return</span> grads
        
    <span class="token keyword">def</span> <span class="token function">save_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token operator">=</span><span class="token string">"params.pkl"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> val
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>params<span class="token punctuation">,</span> f<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">load_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token operator">=</span><span class="token string">"params.pkl"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            params <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> val

        <span class="token keyword">for</span> i<span class="token punctuation">,</span> key <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">,</span> <span class="token string">'Affine1'</span><span class="token punctuation">,</span> <span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>W <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>b <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<h3><a id="CNN_313"></a>具有代表性的CNN</h3> 
<h4><a id="LeNet_314"></a>LeNet</h4> 
<p>LeNet有连续的卷积层和池化层，最后经全连接层输出结果。<br> 和“现在的CNN”相比，LeNet有几个不同点。</p> 
<ul><li>LeNet中使用sigmoid函数，而现在的CNN中主要使用ReLU函数。</li><li>原始的LeNet中使用子采样缩小中间数据的大小，而现在的CNN中Max池化是主流。</li></ul> 
<h4><a id="AlexNet_320"></a>AlexNet</h4> 
<p>AlexNet与LeNet的不同：</p> 
<ul><li>激活函数使用ReLU</li><li>使用进行局部正规化的LRN层。</li><li>使用Dropout</li></ul> 
<h3><a id="_325"></a>说明</h3> 
<p>此为本人学习《深度学习入门》的学习笔记，详情请阅读原书.</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/906d9ce7f3b3a4c596e21166c64b411b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在linux下调试并测试串口驱动</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ae0ad992008b061c2d61b4b32e319dd9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">转换pb_Keras模型转换成Tensorflow模型方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>