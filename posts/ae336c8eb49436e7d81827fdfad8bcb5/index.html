<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SRM滤波器与双线性池化 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="SRM滤波器与双线性池化" />
<meta property="og:description" content="【时间】2020.01.14
【题目】SRM滤波器与双线性池化
在【CVPR 2018】Learning Rich Features for Image Manipulation Detection(图像篡改检测)中，提到了通过SRM滤波获得噪声图片，以及最后通过双线性池化（Bilinear pool）融合两条支路。
1、SRM滤波器
SRM指是《 Rich models for steganalysis of digital images》中提出来的，所以应该是Steganalysis Rich Model的缩写，富隐写分析模型的意思。论文中使用下面3个滤波器获得噪声图片：
输入RGB图片，通过上面的 3个滤波器获得通道数依旧为3的特征。在keras中通过Conv层实现如下：
def SRMLayer(x): q = [4.0, 12.0, 2.0] filter1 = [[0, 0, 0, 0, 0], [0, -1, 2, -1, 0], [0, 2, -4, 2, 0], [0, -1, 2, -1, 0], [0, 0, 0, 0, 0]] filter2 = [[-1, 2, -2, 2, -1], [2, -6, 8, -6, 2], [-2, 8, -12, 8, -2], [2, -6, 8, -6, 2], [-1, 2, -2, 2, -1]] filter3 = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 1, -2, 1, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] filter1 = np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ae336c8eb49436e7d81827fdfad8bcb5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-14T22:49:40+08:00" />
<meta property="article:modified_time" content="2020-01-14T22:49:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SRM滤波器与双线性池化</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>【时间】2020.01.14</p> 
<p>【题目】SRM滤波器与双线性池化</p> 
<p>在<a href="https://blog.csdn.net/luolan9611/article/details/82804248">【CVPR 2018】Learning Rich Features for Image Manipulation Detection(图像篡改检测)</a>中，提到了通过SRM滤波获得噪声图片，以及最后通过双线性池化（Bilinear pool）融合两条支路。</p> 
<p><img alt="" class="has" height="437" src="https://images2.imgbox.com/c3/2f/3AlGLg15_o.png" width="945"></p> 
<p> </p> 
<p><strong>1、SRM滤波器</strong></p> 
<p>SRM指是《 Rich models for steganalysis of digital images》中提出来的，所以应该是Steganalysis Rich Model的缩写，富隐写分析模型的意思。论文中使用下面3个滤波器获得噪声图片：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/5a/25/vKVAT9qr_o.png"></p> 
<p>输入RGB图片，通过上面的 3个滤波器获得通道数依旧为3的特征。在keras中通过Conv层实现如下：</p> 
<pre class="has"><code class="language-python">def SRMLayer(x):
    q = [4.0, 12.0, 2.0]
    filter1 = [[0, 0, 0, 0, 0],
            [0, -1, 2, -1, 0],
            [0, 2, -4, 2, 0],
            [0, -1, 2, -1, 0],
            [0, 0, 0, 0, 0]]
    filter2 = [[-1, 2, -2, 2, -1],
            [2, -6, 8, -6, 2],
            [-2, 8, -12, 8, -2],
            [2, -6, 8, -6, 2],
            [-1, 2, -2, 2, -1]]
    filter3 = [[0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0],
            [0, 1, -2, 1, 0],
            [0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0]]
    filter1 = np.asarray(filter1, dtype=float) / q[0]
    filter2 = np.asarray(filter2, dtype=float) / q[1]
    filter3 = np.asarray(filter3, dtype=float) / q[2]
    filters = np.asarray([[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]) #shape=(3,3,5,5)
    filters = np.transpose(filters, (2,3,1,0)) #shape=(5,5,3,3)

    initializer_srm = keras.initializers.Constant(filters)
    output = Conv2D(3, (5, 5), padding='same', kernel_initializer=initializer_srm, use_bias=False, trainable=False)(x)
 
    return output</code></pre> 
<p>2、双线性池化（Bilinear pool） </p> 
<p>双线性池化将两个CNN特征进行<strong>outer product（外积），</strong>把RGB流和噪声流结合到一起的同时保留了空间信息。</p> 
<p>是在论文《Bilinear CNN Models for Fine-Grained Visual Recognition》中提出来的，用于细粒度图片分类，即同一子类的类别分类，比如X种类海鸥与Y种类海鸥。</p> 
<p>具体见：<a href="https://www.jianshu.com/p/61fd694b4af4" rel="nofollow">简书：Bilinear CNNs for Fine-grained Visual Recognition</a></p> 
<p><a href="https://blog.csdn.net/zsx1713366249/article/details/85090616">细粒度论文笔记：双线性模型 《Bilinear CNN Models for Fine-Grained Visual Recognition》</a></p> 
<p>计算方法为：</p> 
<p>它们的bilinear combination为：</p> 
<p>f表示特征，每个位置的特征值可以表示为f（channel，x，y）</p> 
<p>单个位置f（x,y）的双线性值：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/e4/69/gZInHlYG_o.png"></p> 
<p>对所有位置的双线性值求和：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/f1/b8/QYFf7CNN_o.png"></p> 
<p>注意：fA和fB的size（即S=H*W）必须相同，通道数（M和N）可以不同。最后相当于将fA和fB两个特征分别按通道交叉元素级别点乘再求和，最后获得一个MxN的向量作为特征向量。具体实现是将fA 和 fB resize成（S,M）和（S,N），前者再转置成（M,S）,两者矩阵相乘，获得（M，N）的矩阵，在将其展平为MxN的向量。</p> 
<p>其pytorch实现代码如下：<a href="https://github.com/Ylexx/Bilinear_CNN/blob/master/train_last.py">github</a></p> 
<pre class="has"><code class="language-python">import torch
import torchvision
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F

# vgg16 = torchvision.models.vgg16(pretrained=True)
# import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "2"



class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            # nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),


            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            # nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),



            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            # nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),


            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            # nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),

            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),


            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),

            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0),

        )

        self.classifiers = nn.Sequential(
            nn.Linear(512 ** 2, 200),
        )

    def forward(self, x):
        x = self.features(x)
        batch_size = x.size(0)
        x = x.view(batch_size, 512, 28 ** 2)

        x = (torch.bmm(x, torch.transpose(x, 1, 2)) / 28 ** 2).view(batch_size, -1)

        x = torch.nn.functional.normalize(torch.sign(x) * torch.sqrt(torch.abs(x) + 1e-10))

        # feature = feature.view(feature.size(0), -1)
        x = self.classifiers(x)
        return x
</code></pre> 
<p> </p> 
<p>代码在对所有位置的双线性值求和后还做了平均，之后还进行了归一化。</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8fe44435e05547be1e21af26cb5becf0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">polkitd进程解释</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b803c4f58f916936bd84349849019a7c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[每日一题] 95. 旋转数组(数组、rotate函数、循环移位)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>