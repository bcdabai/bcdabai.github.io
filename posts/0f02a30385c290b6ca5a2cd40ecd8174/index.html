<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用python做一个全球疫情数据采集&#43;采用Excel存储&#43;采用词云图展示 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用python做一个全球疫情数据采集&#43;采用Excel存储&#43;采用词云图展示" />
<meta property="og:description" content="前期准备工作
需要了解基本的python语法知识，可以参考我的另一篇文章，对python基础知识的总结，或者参考缪雪峰老师的python课程，是免费的。
我们先来了解一下爬虫
网络爬虫与浏览器的区别
浏览器是展示数据的，而网络爬虫是采集数据的
什么是网络爬虫
模拟客户端发送网络请求，获取响应数据，一种按照一定的规则，自动地抓取万维网信息的程序和脚本
网络爬虫的作用
从互联网上采集我们所需要的数据
本程序需要使用到的几个库：
1.Requests请求库
作用：Python HTTP请求库，发送请求，获取响应数据
导入模块发送get请求，获取响应从响应中获取数据 text 获取响应的字符串
encoding 二进制转换成字符时使用的方式
content 响应体bytes类型数据
安装：pip install requests
简单示例
#导入模块 import requests #1.爬取百度的疫情数据网页 #目标url url = &#34;https://voice.baidu.com/act/newpneumonia/newpneumonia&#34; #发出get请求 response = requests.get(url) #打印响应内容 print(response.content.decode()) 2.模块lxml
作用：实现解析HTML、XML文档
数据提取：在发送请求获取响应后，可能存在多种不同类型的响应内容，我们只需要有用的部分
lxml是一款高性能的python HTML、XML解析器
XPath是一门在HTML、XML文档中查找信息的语言，可用在HTML、XML对元素和属性进行遍历
常用的几种使用方式
/从根节点选取
//从匹配选择的当前节点选择文档中的节点，而不考虑他们的位置
.选取当前节点
@选取属性
text()选择文本
*匹配任何元素节点
安装：pip install lxml
例如
//script[@lang=”eng”] 选取所有tltle元素，且这些元素拥有值为eng的lang属性
简单示例
#导入lxml的etree库（使用XPath） from lxml import etree #利用etree.HTML将字符串转化为Element对象，其具有xpath方法，返回的结果列表能够接收bytes类型的数据和str类型的数据 html = etree.HTML(text) result = html." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/0f02a30385c290b6ca5a2cd40ecd8174/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-20T17:28:07+08:00" />
<meta property="article:modified_time" content="2021-12-20T17:28:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用python做一个全球疫情数据采集&#43;采用Excel存储&#43;采用词云图展示</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>前期准备工作</strong></p> 
<p>需要了解基本的python语法知识，可以参考我的另一篇文章，对python基础知识的总结，或者参考缪雪峰老师的python课程，是免费的。</p> 
<p><strong>我们先来了解一下爬虫</strong></p> 
<p>网络爬虫与浏览器的区别</p> 
<p><u>浏览器是展示数据的，而网络爬虫是采集数据的</u></p> 
<p>什么是网络爬虫</p> 
<p><u>模拟客户端发送网络请求，获取响应数据，一种按照一定的规则，自动地抓取万维网信息的程序和脚本</u></p> 
<p>网络爬虫的作用</p> 
<p><u>从互联网上采集我们所需要的数据</u></p> 
<p><strong>本程序需要使用到的几个库：</strong></p> 
<p><strong>1.Requests请求库</strong></p> 
<p>作用：<u>Python HTTP请求库，发送请求，获取响应数据</u></p> 
<ol><li>导入模块</li><li>发送get请求，获取响应</li><li>从响应中获取数据</li></ol> 
<p>text 获取响应的字符串</p> 
<p>encoding 二进制转换成字符时使用的方式</p> 
<p>content  响应体bytes类型数据</p> 
<p>安装：pip install requests</p> 
<p>简单示例</p> 
<pre><code>#导入模块
import requests
#1.爬取百度的疫情数据网页
#目标url
url = "https://voice.baidu.com/act/newpneumonia/newpneumonia"
#发出get请求
response = requests.get(url)
#打印响应内容
print(response.content.decode())</code></pre> 
<p></p> 
<p><strong>2.模块lxml</strong></p> 
<p><strong>作用：</strong>实现解析HTML、XML文档</p> 
<p>数据提取：在发送请求获取响应后，可能存在多种不同类型的响应内容，我们只需要有用的部分</p> 
<p>lxml是一款高性能的python HTML、XML<strong>解析器</strong></p> 
<p><u>XPath是一门在HTML、XML</u><u>文档中查找信息的语言</u>，可用在HTML、XML对元素和属性进行遍历</p> 
<p>常用的几种使用方式</p> 
<p>/从根节点选取</p> 
<p><strong>//从匹配选择的当前节点选择文档中的节点，而不考虑他们的位置</strong></p> 
<p><strong>.选取当前节点</strong></p> 
<p><strong>@选取属性</strong></p> 
<p><strong>text()选择文本</strong></p> 
<p><strong>*匹配任何元素节点</strong></p> 
<p>安装：pip install lxml</p> 
<p><strong>例如</strong></p> 
<p><u>//script[@lang=”eng”] 选取所有tltle元素，且这些元素拥有值为eng的lang属性</u></p> 
<p>简单示例</p> 
<pre><code>#导入lxml的etree库（使用XPath）

from lxml import etree

#利用etree.HTML将字符串转化为Element对象，其具有xpath方法，返回的结果列表能够接收bytes类型的数据和str类型的数据

html = etree.HTML(text)

result = html.xpath('//*[@id="captain-config"]/text()')

ret_list = html.xpath(“xpath字符串“)</code></pre> 
<p><strong>3.openpyxl库</strong>：实现Excel文件操作</p> 
<p>安装：pip install openpyxl</p> 
<p>创建表的简单示例</p> 
<pre><code>#导入模块
from openpyxl import workbook
#新建文件，同时新建一张工作表（worksheet）
wb = workbook()
#获取正在运行的工作表
ws = wb.active
#在创建工作表时自动重命名。按照顺序依次命名为（sheet,sheet1,sheet2)
#可以通过调用下面属性修改工作表名称
ws.title = "new title"
#通过索引增加数据
ws["A1"] = "姓名"
ws["B1"] = "年龄"
ws["A2"] = "职业"
ws["B2"] = "生日"
#使用append()方法插入数据行
#ws.append(["黎明","18","学生","2000-5-25"])
#使用save()保存工作薄文件
wb.save("信息资料.xlsx")
</code></pre> 
<p>读取表的简单示例</p> 
<pre><code>#读取一个已存在的文件
workbook2 = load_workbook("信息资料.xlsx")
#获取所有sheet表名
print(workbook2.sheetnames)
#指定sheet表
ws = workbook2["new title"]
#获取指定单元格对象，取出的不是真实数据
cell=ws["A3"]
#通过此方法取出真实数据
print(cell.value)
#通过遍历获取所有数据，他会把每一行当作一个数据,ws.values存了所有元组
for x in ws.values:
    print(x)</code></pre> 
<p><strong>4.wordcloud： 实现词云图生成</strong></p> 
<p>安装：pip install wordcloud</p> 
<p><strong>简单示例</strong></p> 
<pre><code>#wordcloud的使用实例
#导入模块
from wordcloud import WordCloud
#从给定的text中按空格读取单词，出现次数越多的单纯，在生成的图像越大
text = "dag cat fish bird cat cat dog dog dog"
#创建词云图像，需要进行配置默认黑色背景，200*400
wc = WordCloud()
#根据词频生成词云图
wc.generate(text)
#保存
wc.to_file("1.png")
</code></pre> 
<p><strong>下面进入正题</strong></p> 
<p><strong>程序实现的思路</strong></p> 
<p><strong>第一步：</strong>导入需要使用的模块</p> 
<pre><code>#导入模块
import requests
import json
from lxml import etree
from openpyxl import Workbook
from tqdm import tqdm</code></pre> 
<p><strong>第二步：</strong>使用requests库发送请求，获取数据</p> 
<pre><code>#1.获取百度的疫情数据网页
#目标url
url = "https://voice.baidu.com/act/newpneumonia/newpneumonia"
#发出get请求
response  = requests.get(url)
#打印响应内容
#print(response.content.decode())</code></pre> 
<p><strong>第三步：</strong>获取数据内容，这里需要使用lxml模块，调用etree.HTML创建一个html对象，再使用xpath语法获取我们需要的数据。</p> 
<pre><code>

#2.解析获取到的内容，获得疫情数据
#根据获取的内容，创建一个html对象
html = etree.HTML(response.content.decode())
#使用xpath语法获取各国疫情数据
result1 = html.xpath('//*[@id="captain-config"]/text()')
#使用xpath语法获取各洲疫情数据
result2 = html.xpath('//*[@id="captain-config"]/text()')</code></pre> 
<p></p> 
<p>通过浏览器自带的网站开发工具我们得知，所需要的数据都放在id=captain-config的script标签下，因为利用etree.HTML将字符串转化为Element对象，其具有xpath方法，返回的结果列表能够接收bytes类型的数据和str类型的数据。由此我们可以使用  <strong>html.xpath('//*[@id="captain-config"]/text()')</strong>来获取id=captain-config标签下的text形式的数据。</p> 
<p><strong>第四步：</strong>由于第三步获取的数据并不是真正的“字典数据”，而是json类型的字符串数据，所以在此我们需要用到python自带的json模块，调用json.loads，把数据转化为python类型数据</p> 
<pre><code>#result[0]不是真正的字典类型
#通过json.loads将json字符串转为字典
result1 = json.loads(result1[0])
result2 = json.loads(result2[0])</code></pre> 
<p>这里需要说明：在我们使用 json.loads(result[0])获取的数据才转化为python的字典类型，之前是json类型的字符串，是使用的双引号，现在是单引号。使用[0]是因为，result是一个大的字典，我们需要的数据在第一个字典的元素里。</p> 
<p><strong>第五步：</strong>通过以获取到的数据，进一步通过网站的标签，获取到全球各国的疫情数据</p> 
<p><img alt="" height="302" src="https://images2.imgbox.com/5f/c9/MAiOzHEh_o.png" width="1138"></p> 
<p>经过研究和测试，能够推断出我们需要的全球疫情数据在键为component中，由上图知道component对应的值又是一个字典，取完component后，又是一个列表，我们需要再取第0个元素，由已知条件，我们能够推断出，键为caseOutsideList是全球各国疫情数据，键：globalList为各大洲的疫情数据</p> 
<p><u>通过for循环，即可获取到各国数据，和各大洲疫情数据</u></p> 
<p><strong>第六步：</strong>调用openpyxl库，创建Excel表格，通过对第五步以获取到的全球疫情数据，以及各大洲疫情数据，进行遍历写进两个Excel表格</p> 
<pre><code>#3.将数据保存到excel
#创建工作表
wb = Workbook()
ws = wb.active
ws.title = "国际疫情数据"

#填写表的列名
ws.append(["国家","累计确诊","死亡","治愈","现有确诊",
           "累计确诊增量","死亡增量","治愈的增量","现有确诊增量"])

#循环遍历数据，按照顺序，将数据加入到excel中
for each in tqdm(result1,"采集各国疫情数据到Excel进度"):
    temp_list = [each['area'],each['confirmed'],each['died'],
                 each['crued'],each['curConfirm'],
                 each['confirmedRelative'],each['diedRelative'],
                 each['curedRelative'],each['curConfirmRelative']]
    for i in range(len(temp_list)):
        if temp_list[i] == '':
            temp_list[i] = '0'
    ws.append(temp_list)

#保存文件

#3.将数据保存到excel
#创建工作表
wb = Workbook()
ws = wb.active
ws.title = "各大洲疫情数据"

#填写表的列名
ws.append(["洲名","现有确诊","累计确诊","累计治愈","累计死亡","累计确诊增量"])
#循环遍历数据，按照顺序，将数据加入到excel中
for each in tqdm(result2,"采集各洲疫情数据到Excel进度"):
    temp_list = [each['area'],each['curConfirm'],each['confirmed'],
                 each['crued'],each['died'],each['confirmedRelative']]
    for i in range(len(temp_list)):
        if temp_list[i] == '':
            temp_list[i] = '0'
    ws.append(temp_list)
#保存文件
</code></pre> 
<p>这里需要提醒的是，我们不是所有的数据都需要，而是截取了"国家","累计确诊","死亡","治愈","现有确诊","累计确诊增量","死亡增量","治愈的增量","现有确诊增量" 即对应的</p> 
<p>'area'、'confirmed'、'died'、'crued'、'curConfirm'、'confirmedRelative'、'diedRelative'、'curedRelative'、'curConfirmRelative'</p> 
<p>"洲名","现有确诊","累计确诊","累计治愈","累计死亡","累计确诊增量"即对应的</p> 
<p>'area'、'confirmed'、'died'、'crued'、'curConfirm'、'confirmedRelative'、'diedRelative'、'curedRelative'、'curConfirmRelative'</p> 
<p>通过遍历以获取的数据，组成一个新的列表。还通过for循环来判断数据是否为空，为空就补0</p> 
<p><u>调用tqdm是为了添加进度条，使得程序运行过程更加直观，记得在最前面添加tqdm库</u></p> 
<p><u><strong>第七步：</strong>保存文件</u></p> 
<pre><code>#保存文件全球疫情数据
wb.save("C:/Users/80817/Desktop/疫情数据统计/Excel/global_covid_data.xlsx")
#保存文件各大洲疫情数据
wb.save("C:/Users/80817/Desktop/疫情数据统计/Excel/zhou_covid_data.xlsx")</code></pre> 
<p><strong>第八步：</strong>通过调用openpyxl库读取，第七步保存的文件，获取疫情数据。同时，调用wordcloud库，在此，我们需要先创建一个空的字典，我们需要用wc.generate_from_frequencies()此方法（只需要传入一个字典{词：词频}）它将会根据词频来自动生成图片，我们需要通过循环遍历文件，只需要获取{国家名称：累计确诊人数}，{国家名称：累计死亡人数}，{国家名称：现有确诊人数}，{国家名称：累计治愈人数}传入到字典，再通过上述方法，完成创建出需要的词云图。</p> 
<pre><code>#导入模块
from openpyxl import load_workbook
from wordcloud import WordCloud
from tqdm import tqdm

#1.读取已保存的excel文件
wb = load_workbook("C:/Users/80817/Desktop/疫情数据统计/Excel/global_covid_data.xlsx")
ws = wb["国际疫情数据"]

#生成词云图需要一个字典格式，生成一个字典{词：频率} ,{省份：累计确诊数}，词频是数字类型用int强转
#1.遍历国家累计确诊量
frequencie = {}
for row in tqdm(ws.values,"遍历各国累计确诊量"):
    if row[0] != "国家":
        #row[0]是key,row[1]是值
        frequencie[row[0]] = int(row[1])

#2.遍历国家累计死亡量
frequencie1 = {}
for row in tqdm(ws.values,"遍历各国累计死亡量"):
    if row[0] != "国家":
        #row[0]是key,row[1]是值
        frequencie1[row[0]] = int(row[2])

#3.遍历国家累计死亡量
frequencie2= {}
for row in tqdm(ws.values,"遍历各国现有确诊量"):
    if row[0] != "国家":
        #row[0]是key,row[1]是值
        frequencie2[row[0]] = int(row[4])

#3.遍历国家累计治愈量
frequencie3= {}
for row in tqdm(ws.values,"遍历各国现有确诊量"):
    if row[0] != "国家":
        #row[0]是key,row[1]是值
        frequencie3[row[0]] = int(row[3])
#print(frequencie1)

#2.生成词云图
#自定义字体，宽高，颜色
wc = WordCloud(font_path="msyh.ttc",width=800,height=480,background_color="snow")
wc.generate_from_frequencies(frequencie)
wc.to_file("C:/Users/80817/Desktop/疫情数据统计/wordcloud/各国累计确诊量统计.png")
wc.generate_from_frequencies(frequencie1)
wc.to_file("C:/Users/80817/Desktop/疫情数据统计/wordcloud/各国累计死亡量统计.png")
wc.generate_from_frequencies(frequencie2)
wc.to_file("C:/Users/80817/Desktop/疫情数据统计/wordcloud/各国现有确诊统计.png")
wc.generate_from_frequencies(frequencie3)
wc.to_file("C:/Users/80817/Desktop/疫情数据统计/wordcloud/各国累计治愈量.png")
</code></pre> 
<p>到此，通过python爬取疫情数据（全球疫情）的全过程就是这么多啦，爬取国内疫情数据，原理差不多。</p> 
<p><strong>项目效果</strong></p> 
<p><strong>获取疫情数据</strong></p> 
<p><img alt="" height="290" src="https://images2.imgbox.com/ed/a4/ytAZvyNT_o.png" width="879"></p> 
<p> </p> 
<p></p> 
<p>以下是获取到的疫情数据Excel表格</p> 
<p></p> 
<p><img alt="" height="530" src="https://images2.imgbox.com/d3/79/4w4vmTwd_o.png" width="714"></p> 
<p><img alt="" height="263" src="https://images2.imgbox.com/60/12/4Pje2sSA_o.png" width="604"></p> 
<p> </p> 
<p>通过Excel生成词云图</p> 
<p></p> 
<p><strong> 生成词云图</strong></p> 
<p><img alt="" height="233" src="https://images2.imgbox.com/26/51/6ll36EUh_o.png" width="836"></p> 
<p> </p> 
<p>显示云词图效果</p> 
<p><img alt="" height="183" src="https://images2.imgbox.com/e7/c1/Q975oJ8t_o.png" width="553"></p> 
<p> </p> 
<p>才疏学浅，有写错的地方忘大佬多多指教</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/38929afbac0f7d9673046f2533f8880d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Element-UI的this.$message在js里面使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e9f63094ef6733543110e3ddcfdcc7c8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HttpClient连接池管理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>