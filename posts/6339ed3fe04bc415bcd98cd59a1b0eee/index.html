<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>心脏病数据集Spark-Scala分析 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="心脏病数据集Spark-Scala分析" />
<meta property="og:description" content="目录
前言
一、Sprak是什么？
二、Scala介绍与安装
1.Scala介绍
2.Windows安装Scala
1.将scala-2.11.12.zip解压到某个路径
2.配置SCALA_HOME和path环境变量
三.IDEA创建普通的scala项目
1.安装scala插件
四.准备数据集
1.数据来源
2.数据指标
五.编写统计分析代码
1.建一个包便于观察
2.导入需要的包
3.编写统计代码，分析数据相关性
1.Age_agg
2.AgeMax_thalach
3. Agg_chol
4.Max_chol
5.cp_chance
6.Max_trestbps
总结
前言 随着心脏病患者的逐年增加，我们运用有效的知识来分析统计心脏病与各数据指标的关系，来减少患有心脏病的风险
提示：以下是本篇文章正文内容，下面案例可供参考
一、Sprak是什么？ spark官网Apache Spark™ - Unified Engine for large-scale data analytics
Spark是一种快速、通用、可扩展的大数据分析引擎，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、SparkStreaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。
————————————
二、Scala介绍与安装 1.Scala介绍 Scala是一门多范式的、纯粹的面向对象、函数式编程语言。由于Scala文件（.scala）可被编译成Java字节码，所以scala程序可以由JVM加载并运行。
由于Scala编译后得到Java字节码，所以Scala和Java本质上是一个东西，Scala和Java类可以相互调用。
import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import warnings warnings.filterwarnings(&#39;ignore&#39;) import ssl ssl._create_default_https_context = ssl._create_unverified_context 2.Windows安装Scala 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6339ed3fe04bc415bcd98cd59a1b0eee/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-21T18:10:46+08:00" />
<meta property="article:modified_time" content="2023-11-21T18:10:46+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">心脏病数据集Spark-Scala分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p style="text-align:center;"></p> 
</blockquote> 
<p></p> 
<div> 
 <p id="main-toc"><strong>目录</strong></p> 
 <p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
 <p id="%E4%B8%80%E3%80%81Sprak%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81Sprak%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F" rel="nofollow">一、Sprak是什么？</a></p> 
 <p id="%E4%BA%8C%E3%80%81Scala%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81Scala%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85" rel="nofollow">二、Scala介绍与安装</a></p> 
 <p id="1.Scala%E4%BB%8B%E7%BB%8D-toc" style="margin-left:40px;"><a href="#1.Scala%E4%BB%8B%E7%BB%8D" rel="nofollow">1.Scala介绍</a></p> 
 <p id="2.Windows%E5%AE%89%E8%A3%85Scala-toc" style="margin-left:40px;"><a href="#2.Windows%E5%AE%89%E8%A3%85Scala" rel="nofollow">2.Windows安装Scala</a></p> 
 <p id="1.%E5%B0%86scala-2.11.12.zip%E8%A7%A3%E5%8E%8B%E5%88%B0%E6%9F%90%E4%B8%AA%E8%B7%AF%E5%BE%84-toc" style="margin-left:80px;"><a href="#1.%E5%B0%86scala-2.11.12.zip%E8%A7%A3%E5%8E%8B%E5%88%B0%E6%9F%90%E4%B8%AA%E8%B7%AF%E5%BE%84" rel="nofollow">1.将scala-2.11.12.zip解压到某个路径</a></p> 
 <p id="2.%E9%85%8D%E7%BD%AESCALA_HOME%E5%92%8Cpath%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-toc" style="margin-left:80px;"><a href="#2.%E9%85%8D%E7%BD%AESCALA_HOME%E5%92%8Cpath%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" rel="nofollow">2.配置SCALA_HOME和path环境变量</a></p> 
 <p id="%E4%B8%89.IDEA%E5%88%9B%E5%BB%BA%E6%99%AE%E9%80%9A%E7%9A%84scala%E9%A1%B9%E7%9B%AE-toc" style="margin-left:40px;"><a href="#%E4%B8%89.IDEA%E5%88%9B%E5%BB%BA%E6%99%AE%E9%80%9A%E7%9A%84scala%E9%A1%B9%E7%9B%AE" rel="nofollow">三.IDEA创建普通的scala项目</a></p> 
 <p id="1.%E5%AE%89%E8%A3%85scala%E6%8F%92%E4%BB%B6-toc" style="margin-left:80px;"><a href="#1.%E5%AE%89%E8%A3%85scala%E6%8F%92%E4%BB%B6" rel="nofollow">1.安装scala插件</a></p> 
 <p id="%C2%A0%E5%9B%9B.%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#%C2%A0%E5%9B%9B.%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow"> 四.准备数据集</a></p> 
 <p id="1.%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90-toc" style="margin-left:80px;"><a href="#1.%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90" rel="nofollow">1.数据来源</a></p> 
 <p id="2.%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87-toc" style="margin-left:80px;"><a href="#2.%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87" rel="nofollow">2.数据指标</a></p> 
 <p id="%E4%BA%94.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#%E4%BA%94.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81" rel="nofollow">五.编写统计分析代码</a></p> 
 <p id="1.%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8C%85%E4%BE%BF%E4%BA%8E%E8%A7%82%E5%AF%9F-toc" style="margin-left:80px;"><a href="#1.%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8C%85%E4%BE%BF%E4%BA%8E%E8%A7%82%E5%AF%9F" rel="nofollow">1.建一个包便于观察</a></p> 
 <p id="2.%E5%AF%BC%E5%85%A5%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85-toc" style="margin-left:80px;"><a href="#2.%E5%AF%BC%E5%85%A5%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85" rel="nofollow">2.导入需要的包</a></p> 
 <p id="3.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%80%A7-toc" style="margin-left:80px;"><a href="#3.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%80%A7" rel="nofollow">3.编写统计代码，分析数据相关性</a></p> 
 <p id="1.Age_agg-toc" style="margin-left:120px;"><a href="#1.Age_agg" rel="nofollow">1.Age_agg</a></p> 
 <p id="2.AgeMax_thalach-toc" style="margin-left:120px;"><a href="#2.AgeMax_thalach" rel="nofollow">2.AgeMax_thalach</a></p> 
 <p id="3.%C2%A0Agg_chol-toc" style="margin-left:120px;"><a href="#3.%C2%A0Agg_chol" rel="nofollow">3. Agg_chol</a></p> 
 <p id="4.Max_chol-toc" style="margin-left:120px;"><a href="#4.Max_chol" rel="nofollow">4.Max_chol</a></p> 
 <p id="5.cp_chance-toc" style="margin-left:120px;"><a href="#5.cp_chance" rel="nofollow">5.cp_chance</a></p> 
 <p id="6.Max_trestbps-toc" style="margin-left:120px;"><a href="#6.Max_trestbps" rel="nofollow">6.Max_trestbps</a></p> 
 <p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></p> 
</div> 
<hr> 
<h2 id="%E5%89%8D%E8%A8%80"><a id="_7"></a>前言</h2> 
<p>  随着心脏病患者的逐年增加，我们运用有效的知识来分析统计心脏病与各数据指标的关系，来减少患有心脏病的风险</p> 
<hr> 
<p><code>提示：以下是本篇文章正文内容，下面案例可供参考</code></p> 
<h2 id="%E4%B8%80%E3%80%81Sprak%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><a id="pandas_16"></a>一、Sprak是什么？</h2> 
<p><img alt="" height="174" src="https://images2.imgbox.com/53/c9/hHkLGERH_o.png" width="554"></p> 
<p>spark官网<a href="https://spark.apache.org/" rel="nofollow" title="Apache Spark™ - Unified Engine for large-scale data analytics">Apache Spark™ - Unified Engine for large-scale data analytics</a></p> 
<p>Spark是一种快速、通用、可扩展的大数据分析引擎，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、SparkStreaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。<br> ————————————</p> 
<h2 id="%E4%BA%8C%E3%80%81Scala%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85"><a id="_19"></a>二、Scala介绍与安装</h2> 
<h3 id="1.Scala%E4%BB%8B%E7%BB%8D"><a id="1_20"></a>1.Scala介绍</h3> 
<p style="margin-left:.0001pt;text-align:justify;">Scala是一门<strong><strong>多范式</strong></strong>的、<strong><strong>纯粹的面向对象</strong></strong>、<strong><strong>函数式</strong></strong>编程语言。由于Scala文件（.scala）可被编译成Java字节码，所以scala程序可以由JVM加载并运行。</p> 
<p style="margin-left:.0001pt;text-align:justify;">由于Scala编译后得到Java字节码，所以Scala和Java本质上是一个东西，Scala和Java类可以<strong><strong>相互调用</strong></strong>。</p> 
<pre><code class="language-c">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import  ssl
ssl._create_default_https_context = ssl._create_unverified_context
</code></pre> 
<h3 id="2.Windows%E5%AE%89%E8%A3%85Scala"><a id="2_34"></a>2.Windows安装Scala</h3> 
<h4 id="1.%E5%B0%86scala-2.11.12.zip%E8%A7%A3%E5%8E%8B%E5%88%B0%E6%9F%90%E4%B8%AA%E8%B7%AF%E5%BE%84" style="text-align:justify;">1.将scala-2.11.12.zip解压到某个路径</h4> 
<h4 id="2.%E9%85%8D%E7%BD%AESCALA_HOME%E5%92%8Cpath%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" style="text-align:justify;">2.配置SCALA_HOME和path环境变量</h4> 
<p style="margin-left:.0001pt;text-align:justify;">验证是否部署成功：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="202" src="https://images2.imgbox.com/3e/23/0r1guSny_o.png" width="796"></p> 
<p style="margin-left:.0001pt;text-align:justify;">出现下面一串说明安装成功</p> 
<h3 id="%E4%B8%89.IDEA%E5%88%9B%E5%BB%BA%E6%99%AE%E9%80%9A%E7%9A%84scala%E9%A1%B9%E7%9B%AE" style="margin-left:.0001pt;text-align:justify;">三.IDEA创建普通的scala项目</h3> 
<h4 id="1.%E5%AE%89%E8%A3%85scala%E6%8F%92%E4%BB%B6">1.安装scala插件</h4> 
<p style="margin-left:.0001pt;text-align:justify;">运行idea，选择file -&gt; settings...</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="532" src="https://images2.imgbox.com/0e/f1/bt1sgghy_o.png" width="771"></p> 
<hr> 
<h3 id="%C2%A0%E5%9B%9B.%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"> 四.准备数据集</h3> 
<h4 id="1.%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90">1.数据来源</h4> 
<p>数据来源与网址：<a href="https://www.kaggle.com/datasets" rel="nofollow" title="Find Open Datasets and Machine Learning Projects | Kaggle">Find Open Datasets and Machine Learning Projects | Kaggle</a></p> 
<h4 id="2.%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87">2.数据指标</h4> 
<p>数据指标特征</p> 
<p><img alt="" height="388" src="https://images2.imgbox.com/fb/83/RkLnW66o_o.png" width="583"></p> 
<h3 id="%E4%BA%94.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81">五.编写统计分析代码</h3> 
<h4 id="1.%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8C%85%E4%BE%BF%E4%BA%8E%E8%A7%82%E5%AF%9F">1.建一个包便于观察</h4> 
<p><img alt="" height="184" src="https://images2.imgbox.com/51/dc/MnYaFkz1_o.png" width="189"></p> 
<h4 id="2.%E5%AF%BC%E5%85%A5%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85">2.导入需要的包</h4> 
<p>代码中导入需要用到的包</p> 
<p><img alt="" height="68" src="https://images2.imgbox.com/58/5a/vPU3DBLD_o.png" width="401"></p> 
<h4 id="3.%E7%BC%96%E5%86%99%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%80%A7">3.编写统计代码，分析数据相关性</h4> 
<h5 id="1.Age_agg">1.Age_agg</h5> 
<pre><code class="language-Scala">package lzzy.com.heart
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object Age_agg {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("Spark").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")
    // 统计年龄大于50的所有数据
    val countAgeOver50 = df.filter(col("age") &gt; 50).count()

    // 统计年龄大于50且target为1的数据
    val countAgeOver50AndTarget1 = df.filter(col("age") &gt; 50 &amp;&amp; col("target") === 1).count()

    // 计算年龄大于50且target为1的概率
    val ageOver50AndTarget1Prob = countAgeOver50AndTarget1.toDouble / countAgeOver50 * 100

    // 选择需要显示的列，并过滤数据
    val filteredDf = df.select("age","trestbps", "chol", "thalach", "target")
      .filter(col("age") &gt; 50 &amp;&amp; col("target") === 1)

    // 打印结果
    println(s"年龄大于50的数据有 $countAgeOver50 条。")
    println(s"年龄大于50且target为1（即患有心脏病）的数据有 $countAgeOver50AndTarget1 条，概率约为 $ageOver50AndTarget1Prob%。")
    println("显示其中五个指标观察为：age,trestbps, chol, thalach, target")
    filteredDf.show()
  }

}
</code></pre> 
<p>运行结果1 </p> 
<p><img alt="" height="162" src="https://images2.imgbox.com/c7/0a/4iZH1ZIT_o.png" width="868"> </p> 
<p>运行结果2</p> 
<p><img alt="" height="599" src="https://images2.imgbox.com/39/f2/180MRKiL_o.png" width="400"> </p> 
<h5 id="2.AgeMax_thalach">2.AgeMax_thalach</h5> 
<pre><code class="language-Scala">package lzzy.com.heart

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object AgeMax_thalach {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("Spa").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")

    // 过滤出 age 大于 50 且 target 为 1 的行，并选择属性为 thalach(心率） 的所有列
    val filteredDF = df.filter(col("age") &gt; 50 &amp;&amp; col("target") === 1).orderBy(col("thalach").desc)

    // 打印患有心脏病年龄大于50的患者的较高心率的前20行结果
    filteredDF.show()
  }

}
</code></pre> 
<p>运行结果</p> 
<p><img alt="" height="636" src="https://images2.imgbox.com/47/16/QGuwWdJg_o.png" width="914"> </p> 
<h5 id="3.%C2%A0Agg_chol">3. Agg_chol</h5> 
<pre><code class="language-Scala">package lzzy.com.heart

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object Agg_chol {
  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder.appName("S").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")
    // 过滤出 target 值为 1 的行，统计 chol 列的平均值
    val avgChol = df.filter(col("target") === 1).agg(avg(col("chol")))
    // 打印所有患者胆固醇平均值
    println("所有患病者的胆固醇指标平均值是： " + avgChol.first().getDouble(0))

  }

}
</code></pre> 
<p>运行结果</p> 
<p><img alt="" height="204" src="https://images2.imgbox.com/f8/f8/Ezr7jeLy_o.png" width="860"></p> 
<h5 id="4.Max_chol">4.Max_chol</h5> 
<pre><code class="language-Scala">package lzzy.com.heart

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object Max_chol {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("YourApp").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")
    //     df.show()
    // 过滤出 target 值为 1 的行（患有心脏病的患者）
    val filteredDF = df.filter(col("target") === 1)
    // 按照 chol 列降序排序，并获取第一行数据
    val highestCholRow = filteredDF.orderBy(col("chol").desc).first()
    println(highestCholRow)
    //打印出胆固醇最高的患者的所有信息
  }


}
</code></pre> 
<p>运行结果</p> 
<p><img alt="" height="146" src="https://images2.imgbox.com/4f/37/qlYVXkM5_o.png" width="790"></p> 
<h5 id="5.cp_chance">5.cp_chance</h5> 
<pre><code class="language-Scala">package lzzy.com.heart
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object cp_chance {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("Spar").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")
    val countHeartDisease = df.filter(col("target") === 1).count()
    val countCpAndHeartDisease = df.filter(col("target") === 1 &amp;&amp; col("cp") =!= 0).count()

    // 计算患有心脏病的人群中患有胸痛的比例
    val cpChance = countCpAndHeartDisease.toDouble / countHeartDisease * 100

    // 打印结果
    println(s"在数据集中患有心脏病的人有 $countHeartDisease 人。")
    println(s"在患有心脏病的人群中，患有胸痛的人占比约为 $cpChance%。")
  }
}
</code></pre> 
<p>运行结果</p> 
<p><img alt="" height="183" src="https://images2.imgbox.com/2c/5f/A4A6cA4m_o.png" width="593"></p> 
<h5 id="6.Max_trestbps">6.Max_trestbps</h5> 
<pre><code class="language-Scala">package lzzy.com.heart

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object Max_trestbps {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("Sp").master("local[*]").getOrCreate()
    val df = spark.read.format("csv")
      .option("header", "true")
      .load("数据集/heart.csv")

    // 过滤出 target 值为 1 且 trestbps 列不为空的行，并按照 trestbps（静息血压） 列进行降序排序
    val filteredDF = df.filter(col("target") === 1 &amp;&amp; col("trestbps").isNotNull).orderBy(col("trestbps").desc)

    // 打印患有心脏病患者中静息血压降序排序显示20行
    filteredDF.show()


  }

}
</code></pre> 
<p>运行结果</p> 
<p><img alt="" height="635" src="https://images2.imgbox.com/9e/86/uLO8wBo9_o.png" width="765"></p> 
<h2 id="%E6%80%BB%E7%BB%93"><a id="_45"></a>总结</h2> 
<p>经过对心脏病数据集的分析统计，我们得出以下总结：</p> 
<p>1. 年龄大于50的数据：根据数据集中的年龄字段，我们发现共有 705 条数据的年龄大于50。</p> 
<p>2. 年龄大于50且目标为1的数据：在年龄大于50的数据中，我们筛选出符合目标为1的数据，发现共有 311 条数据满足这个条件。</p> 
<p>3. 年龄大于50且目标为1的概率：根据统计结果，年龄大于50且目标为1的数据占年龄大于50的数据的比例约为 44%。这意味着年龄大于50的人群中，有一定比例的人患有心脏病。</p> 
<p>4. 选择的列名和数据：根据需求，我们选择了 trestbps（静息血压）、chol（胆固醇水平）、thalach（最大心率）和 target（心脏病情况）这四列进行分析，并且筛选出符合年龄大于50且目标为1的数据进行显示。</p> 
<p>通过以上分析，我们可以更好地了解了年龄大于50的人群中患有心脏病的情况，并对相关指标进行了统计和展示。这些分析结果可以为进一步的研究和决策提供有价值的信息。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/721883ea185b5644a60350a42d990c83/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ORA-00821_ Specified value of sga_target 1280M is too small, needs to be at least 1744M</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/792ac0e35c7fea862ea34e76854d7369/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">shell脚本字典创建遍历打印</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>