<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka——入门 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Kafka——入门" />
<meta property="og:description" content="文章目录 Kafka1.Kafka是什么？2.Kafka的使用场景3.Kafka的基本概念4.Kafka的基本操作5.Kafka配置文件server.properties核心配置详解：6.单播消息与多播消息,消费多个主题6.1 单播消息6.2 多播消息6.3 消费多个主题 7.Topic 和消息日志Log8.总结 Kafka 1.Kafka是什么？ Kafka 是一个分布式、支持分区（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统。最大的特点就是可以实时处理大量的数据以满足各种需求场景。
2.Kafka的使用场景 消息系统：生产者和消费者解耦，缓存消息。日志收集：公司可以用Kafka收集各种服务的log，通过Kafka以统一接口服务的方式开发给各种consumer，例如hadoop，Hbase，Solr等。用户活动跟踪：：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这
些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到
hadoop、数据仓库中做离线分析和挖掘。运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反
馈，比如报警和报告。 3.Kafka的基本概念 名称解释Broker消息中间件处理节点，一个kafka节点就是一个broker，一个或者多个broker 可以组成一个kafka集群，需要注意的是kafka集群并不是以broder来做单位，就是说多个broder可能会在同时的工作，不分主备TopicKafka 根据topic 对消息进行归类，发布到Kafka 集群的每条消息都需要制定一个topic，是一个抽象的概念。Producer消息生产者，向Broder 发送消息的客户端Consumer消息消费者，从Broder 读取消息的客户端ConsumerGroup每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的ConsumerGroup消费，但是一个ConsumerGroup中只能有一个Consumer能够消费该消息Partition物理上的概念，一个topic可以分为多个partition，默认是一个，每个partition内部消息是有序的 因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费。
服务端（Brokers）和客户端（producer，consumer）之间通信通过TCP协议来完成。
4.Kafka的基本操作 此处下载步骤省略了。
启动服务
首先第一步启动zookeeper，然后在启动kafka。
bin/zookeeper-server-start.sh config/zookeeper.properties // 此处启动zookeeper，因为kafka是基于zookeeper的 bin/kafka-server-start.sh config/server.properties // 在启动kafka，后面的参数是配置文件 创建一个topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test // --zookeeper localhost:2181 是用于连接zookeeper用到的。 // --replication-factor 1 是副本，后续会讲 // --partitions 1 是分区。一个topic可以对应多个分区。 // --topic test 是我们主题的名称。 生产消息（Producer）
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test This is a message This is another message // --broker-list 是用于连接kafka的服务。 // --topic 是表示往哪个topic发送消息 消费消息（Consumer）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/4a42a55d1385a9fe1ea9284b0c4b74d2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-07-21T03:48:35+08:00" />
<meta property="article:modified_time" content="2021-07-21T03:48:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka——入门</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Kafka_2" rel="nofollow">Kafka</a></li><li><ul><li><a href="#1Kafka_3" rel="nofollow">1.Kafka是什么？</a></li><li><a href="#2Kafka_6" rel="nofollow">2.Kafka的使用场景</a></li><li><a href="#3Kafka_15" rel="nofollow">3.Kafka的基本概念</a></li><li><a href="#4Kafka_28" rel="nofollow">4.Kafka的基本操作</a></li><li><a href="#5Kafkaserverproperties_80" rel="nofollow">5.Kafka配置文件server.properties核心配置详解：</a></li><li><a href="#6_91" rel="nofollow">6.单播消息与多播消息,消费多个主题</a></li><li><ul><li><a href="#61__92" rel="nofollow">6.1 单播消息</a></li><li><a href="#62__99" rel="nofollow">6.2 多播消息</a></li><li><a href="#63__107" rel="nofollow">6.3 消费多个主题</a></li></ul> 
   </li><li><a href="#7Topic_Log_112" rel="nofollow">7.Topic 和消息日志Log</a></li><li><a href="#8_143" rel="nofollow">8.总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Kafka_2"></a>Kafka</h2> 
<h3><a id="1Kafka_3"></a>1.Kafka是什么？</h3> 
<p>Kafka 是一个分布式、支持分区（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统。最大的特点就是可以实时处理大量的数据以满足各种需求场景。</p> 
<h3><a id="2Kafka_6"></a>2.Kafka的使用场景</h3> 
<ul><li>消息系统：生产者和消费者解耦，缓存消息。</li><li>日志收集：公司可以用Kafka收集各种服务的log，通过Kafka以统一接口服务的方式开发给各种consumer，例如hadoop，Hbase，Solr等。</li><li>用户活动跟踪：：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这<br> 些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到<br> hadoop、数据仓库中做离线分析和挖掘。</li><li>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反<br> 馈，比如报警和报告。</li></ul> 
<h3><a id="3Kafka_15"></a>3.Kafka的基本概念</h3> 
<table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>Broker</td><td>消息中间件处理节点，一个kafka节点就是一个broker，一个或者多个broker 可以组成一个kafka集群，需要注意的是kafka集群并不是以broder来做单位，就是说多个broder可能会在同时的工作，不分主备</td></tr><tr><td>Topic</td><td>Kafka 根据topic 对消息进行归类，发布到Kafka 集群的每条消息都需要制定一个topic，是一个抽象的概念。</td></tr><tr><td>Producer</td><td>消息生产者，向Broder 发送消息的客户端</td></tr><tr><td>Consumer</td><td>消息消费者，从Broder 读取消息的客户端</td></tr><tr><td>ConsumerGroup</td><td>每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的ConsumerGroup消费，但是一个ConsumerGroup中只能有一个Consumer能够消费该消息</td></tr><tr><td>Partition</td><td>物理上的概念，一个topic可以分为多个partition，默认是一个，每个partition内部消息是有序的</td></tr></tbody></table> 
<p>因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费。<br> 服务端（Brokers）和客户端（producer，consumer）之间通信通过TCP协议来完成。</p> 
<h3><a id="4Kafka_28"></a>4.Kafka的基本操作</h3> 
<p>此处下载步骤省略了。<br> <strong>启动服务</strong><br> 首先第一步启动zookeeper，然后在启动kafka。</p> 
<pre><code class="prism language-shell">bin/zookeeper-server-start.sh config/zookeeper.properties  // 此处启动zookeeper，因为kafka是基于zookeeper的
bin/kafka-server-start.sh config/server.properties  // 在启动kafka，后面的参数是配置文件
</code></pre> 
<p><strong>创建一个topic</strong></p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="token function">test</span>
// --zookeeper localhost:2181 是用于连接zookeeper用到的。
// --replication-factor 1 是副本，后续会讲
// --partitions 1  是分区。一个topic可以对应多个分区。
// --topic <span class="token function">test</span> 是我们主题的名称。
</code></pre> 
<p><strong>生产消息（Producer）</strong></p> 
<pre><code class="prism language-shell">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="token function">test</span>
This is a message
This is another message

// --broker-list 是用于连接kafka的服务。
// --topic 是表示往哪个topic发送消息
</code></pre> 
<p><strong>消费消息（Consumer）</strong></p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="token function">test</span> --from-beginning

// --bootstrap-server localhost:9092 是用于连接kafka服务
// --topic <span class="token function">test</span> 表示从哪个topic接受消息
// --from-beginning 表示从头开始接受消息。
// 此处未使用到消费者组。会有一个默认的组
</code></pre> 
<p><strong>额外的一些操作</strong></p> 
<pre><code class="prism language-shell">// 消费多主题
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist <span class="token string">"test|test-2"</span>
// 查看某个主题的情况
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test1
// 查看消费组名
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list 
// 查看消费组的消费偏移量
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup
<span class="token comment">## current-offset：当前消费组的已消费偏移量</span>
<span class="token comment">## log-end-offset：主题对应分区消息的结束偏移量(HW)</span>
<span class="token comment">## lag：当前消费组未消费的消息数</span>
// 查看已经存在的topic
bin/kafka-topics.sh --list --zookeeper localhost:2181
// 删除主题，开启删除的配置就可以删除主题
bin/kafka-topics.sh --delete --topic <span class="token function">test</span> --zookeeper localhost:2181
</code></pre> 
<h3><a id="5Kafkaserverproperties_80"></a>5.Kafka配置文件server.properties核心配置详解：</h3> 
<table><thead><tr><th>属性</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>broker.id</td><td>0</td><td>每个broker.id都可以用一个唯一的非负整数id进行标识;这个id可以作为broker的名称，你可以选择任意你喜欢的数字作为id，只要id是唯一，且不能为负数</td></tr><tr><td>log.dirs</td><td>/tmp/kafka-logs</td><td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新的partition时，都会选择在包含最少partition的路径下进行。</td></tr><tr><td>listeners</td><td>是关闭的，可以自行开启PLAINTEXT://:9092</td><td>server 接受客户端连接端口，IP配置kafka本机IP即可</td></tr><tr><td>zookeeper.connect</td><td>localhost:2181</td><td>zookeeper连接字符串的格式为：hostname:port,此处hostname和port分别是Zookeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为hostname1:port1, hostname2:port2,hostname3:port3</td></tr><tr><td>num.partitions</td><td>1</td><td>创建topic的默认分区数</td></tr><tr><td>default.replication.factor</td><td>默认是没有配置的</td><td>自动创建topic的默认副本数量，建议设置为大于等于2</td></tr><tr><td>min.insync.replicas</td><td>默认是没有配置的</td><td>当producer设置ack为-1时，min.insync.replicas 指定replicas的最小数目（必须确认每一个replica的写数据都是成功的）如果这个数目么有达到，producer发送消息会产生异常</td></tr><tr><td>delete.topic.enable</td><td>默认是没有的</td><td>是否允许删除主题</td></tr></tbody></table> 
<h3><a id="6_91"></a>6.单播消息与多播消息,消费多个主题</h3> 
<h4><a id="61__92"></a>6.1 单播消息</h4> 
<p>一个消息只能被某一个消费者消费的模式，只需要让所有的消费者在同一个消费组里即可<br> 分别在两个客户端执行如下消费命令，然后往主题中发布消息，结果只有一个客户端能收到消息。</p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id<span class="token operator">=</span>danboGroup  --topic danbo 
// --consumer-property group.id<span class="token operator">=</span>danboGroup 可以去设置消费者组
</code></pre> 
<h4><a id="62__99"></a>6.2 多播消息</h4> 
<p>一条消息能够被多个消费者消费的模式，类似于publish-subscribe模式，针对kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只能保证这些消费者属于不同的消费组即可。</p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id<span class="token operator">=</span>duoboGroup1  --topic duobo 
// --consumer-property group.id<span class="token operator">=</span>danboGroup 可以去设置消费者组
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id<span class="token operator">=</span>duoboGroup2  --topic duobo 
</code></pre> 
<h4><a id="63__107"></a>6.3 消费多个主题</h4> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist <span class="token string">"test|test-2"</span>
</code></pre> 
<h3><a id="7Topic_Log_112"></a>7.Topic 和消息日志Log</h3> 
<p>可以理解Topic 是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区（Partition）日志文件：<br> <img src="https://images2.imgbox.com/31/f0/u2EJcA4z_o.png" alt="在这里插入图片描述"></p> 
<ol><li>Partition 是一个有序的message序列，这些message按顺序添加到一个叫做commit log的文件中。每个partition 中的消息都有一个唯一的编号，成为offset，用来唯一标示某个分区中的message。</li><li>每个partition，都对应一个commit log 文件。一个partition中的message的offset都是唯一的，但是不同的partition的message的offset可能是相同的。</li><li>kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间（log.retention.hours）确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保留大量的数据消息日志不会有什么影响。</li><li>每个consumer是基于自己在commit log 中的消费进度（offset）来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit log 中的消息，当然我可以通过制定offset来重复消息某些信息，或者跳过某些信息。</li><li>这意味kafka中的consumer 对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。<br> <strong>实战一把</strong><br> <strong>创建多个分区的主题</strong></li></ol> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic duofenqu
</code></pre> 
<p><strong>查看topic的情况</strong></p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic duofenqu
</code></pre> 
<p><img src="https://images2.imgbox.com/b0/09/getyfbFq_o.png" alt="在这里插入图片描述"></p> 
<ul><li>leader节点负责给定partition的所有读写请求</li><li>replicas 表示某个partition 在哪几个broker上存在备份。不管这个节点是不是“leader”，设置这个节点挂了，也会列出。</li><li>isr 是replicas的一个子集，它只会列出当前还存活着的，并且已同步备份了该partition的节点。 必须是当前存活的。</li></ul> 
<p>** 进入kafka的数据文件存储目录查看消息日志文件：(具体路径就在配置文件中指定的)**<br> <img src="https://images2.imgbox.com/f5/38/HGKRWwzU_o.png" alt="在这里插入图片描述"><br> 我们可以看到有 duofenqu-0，doufenqu-1。消息日志文件主要存放在分区文件夹里的以log结尾日志文件里。可以通过以下命令进行增加topic的分区数量（目前kafka不支持减少分区）</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh -alter --partitions 3 --zookeeper 192.168.65.60:2181 --topic duofenqu
</code></pre> 
<h3><a id="8_143"></a>8.总结</h3> 
<p>可以这么来理解Topic，Partition，Broker</p> 
<p>一个topic，代表逻辑上的一个业务数据集，比如按数据库操作消息区分放入不同topic，订单相关的操作放入订单topic，用户相关的操作放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。</p> 
<p>为什么要对topic下数据进行分区存储？</p> 
<ol><li>commit log 文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据。</li><li>为了提高并行度。</li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fca8be676bff0d010802251acc6ab6a0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Vue-grid-layout实现web拖拽布局功能</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9f8146a150ec801255bc586201929699/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">软考计算机qzzn,PMP和软考同时考怎么样?</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>