<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于Python的51job(前程无忧)招聘网站数据采集，通过selenium绕过网站反爬，可以采集全国各地数十万条招聘信息 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于Python的51job(前程无忧)招聘网站数据采集，通过selenium绕过网站反爬，可以采集全国各地数十万条招聘信息" />
<meta property="og:description" content="使用Python编程语言和Selenium库来实现自动化的网页操作，从而实现登录、搜索和爬取职位信息的功能。
首先，导入了所需的库，包括time用于处理时间，selenium用于模拟浏览器操作，csv用于写入CSV文件，BeautifulSoup用于解析网页数据。然后，定义了一个名为login的函数，该函数接受一个WebDriver对象和一个关键词作为参数。
在login函数中，使用WebDriver对象打开51job网站，并通过模拟用户的行为进行登录操作。登录过程中需要输入关键词并点击搜索按钮。然后，使用BeautifulSoup库解析页面源代码，找到包含职位信息的HTML元素，并逐个提取出岗位名、公司、薪资、城市、区县、行业、标签、性质、企业人数和回复等信息。将提取的信息存储在一个列表中，并通过csv库将列表中的数据写入到CSV文件中。
在主函数main中，配置了Chrome浏览器的启动选项，并创建了一个WebDriver对象。接下来，代码循环遍历不同的城市列表，在每个城市中调用login函数进行登录和职位信息的爬取。
代码的运行过程是自动化的，通过模拟浏览器操作来实现登录和搜索功能，然后从搜索结果中提取所需的职位信息，并将其保存到CSV文件中。使用Selenium库可以实现与浏览器相同的操作，包括点击按钮、输入文本、滚动页面等。
主要代码如下：
def main(): # while True: &#34;&#34;&#34; chromeOptions 是一个配置 chrome 启动是属性的类,就是初始化 &#34;&#34;&#34; option = webdriver.ChromeOptions() &#34;&#34;&#34; add_experimental_option 添加实验性质的设置参数 &#34;&#34;&#34; option.add_experimental_option(&#39;excludeSwitches&#39;, [&#39;enable-automation&#39;]) # webdriver防检测 &#39;&#39;&#39; add_argument 添加启动参数 &#39;&#39;&#39; # option.add_argument(&#34;--disable-blink-features=AutomationControlled&#34;) # option.add_argument(&#34;--no-sandbox&#34;) # option.add_argument(&#34;--disable-dev-usage&#34;) # option.add_experimental_option(&#34;prefs&#34;, {&#34;profile.managed_default_content_settings.images&#34;: 2})#不加载图片 &#34;&#34;&#34; Chrome 配置驱动 &#34;&#34;&#34; driver = webdriver.Chrome(executable_path=&#39;chromedriver.exe&#39;,options=option) driver.set_page_load_timeout(15) list0=[[&#39;guangzhou&#39;, &#39;广州&#39;], [&#39;shanghai&#39;, &#39;上海&#39;], [&#39;shenzhen&#39;, &#39;深圳&#39;], [&#39;changsha&#39;, &#39;长沙&#39;],[&#39;chongqing&#39;,&#39;重庆&#39;]] for k in list0: login(driver,k) time.sleep(15) # driver.set_page_load_timeout(15) # jugesd(driver) if __name__ == &#39;__main__&#39;: headers = { &#39;User-Agent&#39;:&#39;你的user-agent&#39;, &#39;Cookie&#39;:&#39;你的cookie（一定要登录，不然久不久就会反爬验证）&#39;} main() 完整代码可联系我，白嫖勿扰" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7fb96801b261f7fbea9f6cd2e741b332/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-15T10:21:48+08:00" />
<meta property="article:modified_time" content="2024-01-15T10:21:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于Python的51job(前程无忧)招聘网站数据采集，通过selenium绕过网站反爬，可以采集全国各地数十万条招聘信息</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>使用Python编程语言和Selenium库来实现自动化的网页操作，从而实现登录、搜索和爬取职位信息的功能。</p> 
<p>首先，导入了所需的库，包括time用于处理时间，selenium用于模拟浏览器操作，csv用于写入CSV文件，BeautifulSoup用于解析网页数据。然后，定义了一个名为login的函数，该函数接受一个WebDriver对象和一个关键词作为参数。</p> 
<p>在login函数中，使用WebDriver对象打开51job网站，并通过模拟用户的行为进行登录操作。登录过程中需要输入关键词并点击搜索按钮。然后，使用BeautifulSoup库解析页面源代码，找到包含职位信息的HTML元素，并逐个提取出岗位名、公司、薪资、城市、区县、行业、标签、性质、企业人数和回复等信息。将提取的信息存储在一个列表中，并通过csv库将列表中的数据写入到CSV文件中。</p> 
<p>在主函数main中，配置了Chrome浏览器的启动选项，并创建了一个WebDriver对象。接下来，代码循环遍历不同的城市列表，在每个城市中调用login函数进行登录和职位信息的爬取。</p> 
<p>代码的运行过程是自动化的，通过模拟浏览器操作来实现登录和搜索功能，然后从搜索结果中提取所需的职位信息，并将其保存到CSV文件中。使用Selenium库可以实现与浏览器相同的操作，包括点击按钮、输入文本、滚动页面等。</p> 
<p>主要代码如下：</p> 
<pre>def main():
    # while True:
        """
        chromeOptions 是一个配置 chrome 启动是属性的类,就是初始化
        """
        option = webdriver.ChromeOptions()
        """
        add_experimental_option 添加实验性质的设置参数
        """
        option.add_experimental_option('excludeSwitches', ['enable-automation'])  # webdriver防检测
        '''
        add_argument 添加启动参数
        '''
        # option.add_argument("--disable-blink-features=AutomationControlled")
        # option.add_argument("--no-sandbox")
        # option.add_argument("--disable-dev-usage")
        # option.add_experimental_option("prefs", {"profile.managed_default_content_settings.images": 2})#不加载图片
        """
        Chrome 配置驱动
        """
        driver = webdriver.Chrome(executable_path='chromedriver.exe',options=option)
        driver.set_page_load_timeout(15)
        list0=[['guangzhou', '广州'], ['shanghai', '上海'], ['shenzhen', '深圳'], ['changsha', '长沙'],['chongqing','重庆']]
        for k in list0:
            login(driver,k)
            time.sleep(15)
        # driver.set_page_load_timeout(15)

        # jugesd(driver)
if __name__ == '__main__':
    headers = {
        'User-Agent':'你的user-agent',
    'Cookie':'你的cookie（一定要登录，不然久不久就会反爬验证）'}
    main()</pre> 
<p>完整代码可联系我，白嫖勿扰</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3f5e09cfba7468e0ef27d02c64036b56/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MySQL 查看表结构简单命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d5c6fcbae540d0f2e65d567021286944/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【SWAT水文模型】SWAT-CUP参数率定过程问题总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>