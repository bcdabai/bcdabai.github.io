<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ç¬¬P8å‘¨ï¼šYOLOv5-C3æ¨¡å—å®ç° - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ç¬¬P8å‘¨ï¼šYOLOv5-C3æ¨¡å—å®ç°" />
<meta property="og:description" content="&gt;- **ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/rbOOmire8OocQ90QM78DRA) ä¸­çš„å­¦ä¹ è®°å½•åšå®¢** &gt;- **ğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶](https://mtyjkh.blog.csdn.net/)** ä¸€ã€ å‰æœŸå‡†å¤‡ 1. è®¾ç½®GPU å¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPU
import torch import torch.nn as nn import torchvision.transforms as transforms import torchvision from torchvision import transforms, datasets import os,PIL,pathlib,warnings warnings.filterwarnings(&#34;ignore&#34;) #å¿½ç•¥è­¦å‘Šä¿¡æ¯ device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;) device 2. å¯¼å…¥æ•°æ® import os,PIL,random,pathlib data_dir = &#39;./8-data/&#39; data_dir = pathlib.Path(data_dir) data_paths = list(data_dir.glob(&#39;*&#39;)) classeNames = [str(path).split(&#34;\\&#34;)[1] for path in data_paths] classeNames # å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863 train_transforms = transforms.Compose([ transforms." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/58975388e0c20aab62e989c688272cd2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T22:22:08+08:00" />
<meta property="article:modified_time" content="2023-12-29T22:22:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ç¬¬P8å‘¨ï¼šYOLOv5-C3æ¨¡å—å®ç°</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <pre><code class="hljs">&gt;- **ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/rbOOmire8OocQ90QM78DRA) ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**
&gt;- **ğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶](https://mtyjkh.blog.csdn.net/)**</code></pre> 
<h2 id="3e9ff6f7">ä¸€ã€ å‰æœŸå‡†å¤‡</h2> 
<h3 id="1327236c">1. è®¾ç½®GPU</h3> 
<p id="u0f76d29c"></p> 
<p id="u92173f8c">å¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPU</p> 
<p></p> 
<pre><code class="language-python">import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision
from torchvision import transforms, datasets
import os,PIL,pathlib,warnings

warnings.filterwarnings("ignore")             #å¿½ç•¥è­¦å‘Šä¿¡æ¯

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device</code></pre> 
<h3 id="c2c5b3ce">2. å¯¼å…¥æ•°æ®</h3> 
<pre><code class="language-python">import os,PIL,random,pathlib

data_dir = './8-data/'
data_dir = pathlib.Path(data_dir)

data_paths  = list(data_dir.glob('*'))
classeNames = [str(path).split("\\")[1] for path in data_paths]
classeNames</code></pre> 
<pre><code class="language-python"># å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863
train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    # transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

test_transform = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

total_data = datasets.ImageFolder("./8-data/",transform=train_transforms)
total_data</code></pre> 
<pre><code class="language-python">Dataset ImageFolder
    Number of datapoints: 1125
    Root location: ./8-data/
    StandardTransform
Transform: Compose(
               Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=None)
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           )</code></pre> 
<pre><code class="language-python">total_data.class_to_idx</code></pre> 
<pre><code class="language-python">{'cloudy': 0, 'rain': 1, 'shine': 2, 'sunrise': 3}</code></pre> 
<h3 id="c6ea104f">3. åˆ’åˆ†æ•°æ®é›†</h3> 
<pre><code class="language-python">train_size = int(0.8 * len(total_data))
test_size  = len(total_data) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(total_data, [train_size, test_size])
train_dataset, test_dataset</code></pre> 
<pre><code class="language-python">(&lt;torch.utils.data.dataset.Subset at 0x19600429450&gt;,
 &lt;torch.utils.data.dataset.Subset at 0x196004297e0&gt;)</code></pre> 
<pre><code class="language-python">batch_size = 4

train_dl = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True,
                                           num_workers=1)
test_dl = torch.utils.data.DataLoader(test_dataset,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          num_workers=1)</code></pre> 
<pre><code class="language-python">for X, y in test_dl:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break</code></pre> 
<pre><code class="language-python">Shape of X [N, C, H, W]: Â torch.Size([4, 3, 224, 224])
Shape of y: Â torch.Size([4]) torch.int64</code></pre> 
<h2 id="75c34346">äºŒã€æ­å»ºåŒ…å«C3æ¨¡å—çš„æ¨¡å‹</h2> 
<p id="u7f499bb1"><strong>ğŸ“Œ</strong><strong>KåŒå­¦å•Šæç¤ºï¼šæ˜¯å¦å¯ä»¥å°è¯•é€šè¿‡å¢åŠ /è°ƒæ•´C3æ¨¡å—ä¸Convæ¨¡å—æ¥æé«˜å‡†ç¡®ç‡ï¼Ÿ</strong></p> 
<p id="ub4336a13"></p> 
<p class="img-center"><img alt="" height="534" id="u3e3e65fe" src="https://images2.imgbox.com/4d/41/oxZ5g665_o.png" width="1200"></p> 
<h3 id="tH5WN">1. æ­å»ºæ¨¡å‹</h3> 
<p id="u4665e905"></p> 
<pre id="ca43bdbf"><code>import torch.nn.functional as F

def autopad(k, p=None):  # kernel, padding
    # Pad to 'same'
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p

class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))

class model_K(nn.Module):
    def __init__(self):
        super(model_K, self).__init__()
        
        # å·ç§¯æ¨¡å—
        self.Conv = Conv(3, 32, 3, 2) 
        
        # C3æ¨¡å—1
        self.C3_1 = C3(32, 64, 3, 2)
        
        # å…¨è¿æ¥ç½‘ç»œå±‚ï¼Œç”¨äºåˆ†ç±»
        self.classifier = nn.Sequential(
            nn.Linear(in_features=802816, out_features=100),
            nn.ReLU(),
            nn.Linear(in_features=100, out_features=4)
        )
        
    def forward(self, x):
        x = self.Conv(x)
        x = self.C3_1(x)
        x = torch.flatten(x, start_dim=1)
        x = self.classifier(x)

        return x

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using {} device".format(device))
    
model = model_K().to(device)
model</code></pre> 
<p id="uce4facdb"></p> 
<pre id="87df0d06"><code>Using cuda device

model_K(
  (Conv): Conv(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): SiLU()
  )
  (C3_1): C3(
    (cv1): Conv(
      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): SiLU()
    )
    (cv2): Conv(
      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): SiLU()
    )
    (cv3): Conv(
      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): SiLU()
    )
    (m): Sequential(
      (0): Bottleneck(
        (cv1): Conv(
          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
      )
      (1): Bottleneck(
        (cv1): Conv(
          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
      )
      (2): Bottleneck(
        (cv1): Conv(
          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
      )
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=802816, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=4, bias=True)
  )
)</code></pre> 
<p id="ua8c73fcd"></p> 
<h3 id="OMg9Y">2. æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…</h3> 
<p id="u68c66340"></p> 
<pre id="5c31575f"><code># ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡ä»¥åŠå…¶ä»–æŒ‡æ ‡
import torchsummary as summary
summary.summary(model, (3, 224, 224))</code></pre> 
<p id="u883b6c61"></p> 
<pre id="5ab747c9"><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
              SiLU-3         [-1, 32, 112, 112]               0
              Conv-4         [-1, 32, 112, 112]               0
            Conv2d-5         [-1, 32, 112, 112]           1,024
       BatchNorm2d-6         [-1, 32, 112, 112]              64
              SiLU-7         [-1, 32, 112, 112]               0
              Conv-8         [-1, 32, 112, 112]               0
            Conv2d-9         [-1, 32, 112, 112]           1,024
      BatchNorm2d-10         [-1, 32, 112, 112]              64
             SiLU-11         [-1, 32, 112, 112]               0
             Conv-12         [-1, 32, 112, 112]               0
           Conv2d-13         [-1, 32, 112, 112]           9,216
      BatchNorm2d-14         [-1, 32, 112, 112]              64
             SiLU-15         [-1, 32, 112, 112]               0
             Conv-16         [-1, 32, 112, 112]               0
       Bottleneck-17         [-1, 32, 112, 112]               0
           Conv2d-18         [-1, 32, 112, 112]           1,024
      BatchNorm2d-19         [-1, 32, 112, 112]              64
             SiLU-20         [-1, 32, 112, 112]               0
             Conv-21         [-1, 32, 112, 112]               0
           Conv2d-22         [-1, 32, 112, 112]           9,216
      BatchNorm2d-23         [-1, 32, 112, 112]              64
             SiLU-24         [-1, 32, 112, 112]               0
             Conv-25         [-1, 32, 112, 112]               0
       Bottleneck-26         [-1, 32, 112, 112]               0
           Conv2d-27         [-1, 32, 112, 112]           1,024
      BatchNorm2d-28         [-1, 32, 112, 112]              64
             SiLU-29         [-1, 32, 112, 112]               0
             Conv-30         [-1, 32, 112, 112]               0
           Conv2d-31         [-1, 32, 112, 112]           9,216
      BatchNorm2d-32         [-1, 32, 112, 112]              64
             SiLU-33         [-1, 32, 112, 112]               0
             Conv-34         [-1, 32, 112, 112]               0
       Bottleneck-35         [-1, 32, 112, 112]               0
           Conv2d-36         [-1, 32, 112, 112]           1,024
      BatchNorm2d-37         [-1, 32, 112, 112]              64
             SiLU-38         [-1, 32, 112, 112]               0
             Conv-39         [-1, 32, 112, 112]               0
           Conv2d-40         [-1, 64, 112, 112]           4,096
      BatchNorm2d-41         [-1, 64, 112, 112]             128
             SiLU-42         [-1, 64, 112, 112]               0
             Conv-43         [-1, 64, 112, 112]               0
               C3-44         [-1, 64, 112, 112]               0
           Linear-45                  [-1, 100]      80,281,700
             ReLU-46                  [-1, 100]               0
           Linear-47                    [-1, 4]             404
================================================================
Total params: 80,320,536
Trainable params: 80,320,536
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 150.06
Params size (MB): 306.40
Estimated Total Size (MB): 457.04
----------------------------------------------------------------</code></pre> 
<p id="u475fecf5"></p> 
<h2 id="d6d117cc">ä¸‰ã€ è®­ç»ƒæ¨¡å‹</h2> 
<p id="ubcd04cbb"></p> 
<h3 id="74c3b3c6">1. ç¼–å†™è®­ç»ƒå‡½æ•°</h3> 
<p id="uec41d7bb"></p> 
<pre id="0eb0bcb5"><code># è®­ç»ƒå¾ªç¯
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°
    num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)

    train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
    
    for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾
        X, y = X.to(device), y.to(device)
        
        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)          # ç½‘ç»œè¾“å‡º
        loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()  # gradå±æ€§å½’é›¶
        loss.backward()        # åå‘ä¼ æ’­
        optimizer.step()       # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
        
        # è®°å½•accä¸loss
        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
            
    train_acc  /= size
    train_loss /= num_batches

    return train_acc, train_loss</code></pre> 
<p id="u4c21855a"></p> 
<h3 id="92baad45">2. ç¼–å†™æµ‹è¯•å‡½æ•°</h3> 
<p id="u60d16095"></p> 
<p id="ucc3402ad">æµ‹è¯•å‡½æ•°å’Œè®­ç»ƒå‡½æ•°å¤§è‡´ç›¸åŒï¼Œä½†æ˜¯ç”±äºä¸è¿›è¡Œæ¢¯åº¦ä¸‹é™å¯¹ç½‘ç»œæƒé‡è¿›è¡Œæ›´æ–°ï¼Œæ‰€ä»¥ä¸éœ€è¦ä¼ å…¥ä¼˜åŒ–å™¨</p> 
<p id="uc6c87371"></p> 
<pre id="5cb33529"><code>def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°
    num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)
    test_loss, test_acc = 0, 0
    
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:
            imgs, target = imgs.to(device), target.to(device)
            
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()

    test_acc  /= size
    test_loss /= num_batches

    return test_acc, test_loss</code></pre> 
<p id="u936a7483"></p> 
<h3 id="199aab1d">3. æ­£å¼è®­ç»ƒ</h3> 
<p id="uc6ae1ecc"></p> 
<p id="udf642601"><code>model.train()</code>ã€<code>model.eval()</code>è®­ç»ƒè¥å¾€æœŸæ–‡ç« ä¸­æœ‰è¯¦ç»†çš„ä»‹ç»ã€‚</p> 
<p id="u6b3fc326"></p> 
<p id="uf36ef98c">ğŸ“Œå¦‚æœå°†ä¼˜åŒ–å™¨æ¢æˆ SGD ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿè¯·è‡ªè¡Œæ¢ç´¢æ¥ä¸‹æ¥å‘ç”Ÿçš„è¯¡å¼‚äº‹ä»¶çš„åŸå› ã€‚</p> 
<p id="u121122aa"></p> 
<pre id="47f0c376"><code>import copy

optimizer  = torch.optim.Adam(model.parameters(), lr= 1e-4)
loss_fn    = nn.CrossEntropyLoss() # åˆ›å»ºæŸå¤±å‡½æ•°

epochs     = 20

train_loss = []
train_acc  = []
test_loss  = []
test_acc   = []

best_acc = 0    # è®¾ç½®ä¸€ä¸ªæœ€ä½³å‡†ç¡®ç‡ï¼Œä½œä¸ºæœ€ä½³æ¨¡å‹çš„åˆ¤åˆ«æŒ‡æ ‡

for epoch in range(epochs):
    
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° best_model
    if epoch_test_acc &gt; best_acc:
        best_acc   = epoch_test_acc
        best_model = copy.deepcopy(model)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)
    
    # è·å–å½“å‰çš„å­¦ä¹ ç‡
    lr = optimizer.state_dict()['param_groups'][0]['lr']
    
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}, Lr:{:.2E}')
    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, 
                          epoch_test_acc*100, epoch_test_loss, lr))
    
# ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°æ–‡ä»¶ä¸­
PATH = './best_model.pth'  # ä¿å­˜çš„å‚æ•°æ–‡ä»¶å
torch.save(model.state_dict(), PATH)

print('Done')</code></pre> 
<p id="u1de5bb05"></p> 
<pre id="dfa9d7f0"><code>Epoch: 1, Train_acc:70.6%, Train_loss:1.395, Test_acc:90.7%, Test_loss:0.458, Lr:1.00E-04
Epoch: 2, Train_acc:86.7%, Train_loss:0.407, Test_acc:88.4%, Test_loss:0.792, Lr:1.00E-04
Epoch: 3, Train_acc:94.3%, Train_loss:0.202, Test_acc:89.8%, Test_loss:0.692, Lr:1.00E-04
Epoch: 4, Train_acc:96.0%, Train_loss:0.153, Test_acc:88.0%, Test_loss:0.726, Lr:1.00E-04
Epoch: 5, Train_acc:96.7%, Train_loss:0.137, Test_acc:89.8%, Test_loss:0.475, Lr:1.00E-04
Epoch: 6, Train_acc:98.1%, Train_loss:0.063, Test_acc:88.9%, Test_loss:0.745, Lr:1.00E-04
Epoch: 7, Train_acc:98.3%, Train_loss:0.044, Test_acc:89.8%, Test_loss:0.608, Lr:1.00E-04
Epoch: 8, Train_acc:98.7%, Train_loss:0.051, Test_acc:93.3%, Test_loss:0.743, Lr:1.00E-04
Epoch: 9, Train_acc:97.9%, Train_loss:0.087, Test_acc:89.8%, Test_loss:1.218, Lr:1.00E-04
Epoch:10, Train_acc:97.1%, Train_loss:0.130, Test_acc:89.3%, Test_loss:0.801, Lr:1.00E-04
Epoch:11, Train_acc:99.1%, Train_loss:0.037, Test_acc:92.0%, Test_loss:0.747, Lr:1.00E-04
Epoch:12, Train_acc:99.3%, Train_loss:0.014, Test_acc:92.0%, Test_loss:0.642, Lr:1.00E-04
Epoch:13, Train_acc:98.2%, Train_loss:0.065, Test_acc:88.4%, Test_loss:0.881, Lr:1.00E-04
Epoch:14, Train_acc:98.2%, Train_loss:0.053, Test_acc:92.4%, Test_loss:0.857, Lr:1.00E-04
Epoch:15, Train_acc:99.2%, Train_loss:0.044, Test_acc:88.4%, Test_loss:0.646, Lr:1.00E-04
Epoch:16, Train_acc:99.2%, Train_loss:0.017, Test_acc:88.4%, Test_loss:0.811, Lr:1.00E-04
Epoch:17, Train_acc:100.0%, Train_loss:0.003, Test_acc:91.1%, Test_loss:0.743, Lr:1.00E-04
Epoch:18, Train_acc:99.8%, Train_loss:0.004, Test_acc:93.3%, Test_loss:0.544, Lr:1.00E-04
Epoch:19, Train_acc:96.2%, Train_loss:0.230, Test_acc:88.4%, Test_loss:1.133, Lr:1.00E-04
Epoch:20, Train_acc:97.8%, Train_loss:0.078, Test_acc:93.3%, Test_loss:0.918, Lr:1.00E-04
Done</code></pre> 
<p id="u598536d6"></p> 
<h2 id="03880b4e">å››ã€ ç»“æœå¯è§†åŒ–</h2> 
<p id="ub23d2006"></p> 
<h3 id="7f04c97e">1. Lossä¸Accuracyå›¾</h3> 
<p id="u2c945822"></p> 
<pre id="1da5eaaa"><code>import matplotlib.pyplot as plt
#éšè—è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯
plt.rcParams['font.sans-serif']    = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False      # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['figure.dpi']         = 100        #åˆ†è¾¨ç‡

epochs_range = range(epochs)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()</code></pre> 
<p id="ucf44ccc6"></p> 
<p id="u7e447bed"></p> 
<p class="img-center"><img alt="" height="293" id="ufdad540b" src="https://images2.imgbox.com/07/f2/TBj1d1wU_o.png" width="987"></p> 
<h3 id="dfceb3e6">2. æ¨¡å‹è¯„ä¼°</h3> 
<p id="u82f92c9b"></p> 
<pre id="052b6b1d"><code>best_model.eval()
epoch_test_acc, epoch_test_loss = test(test_dl, best_model, loss_fn)</code></pre> 
<p id="ud9fca249"></p> 
<pre id="a7da494b"><code>epoch_test_acc, epoch_test_loss</code></pre> 
<p id="ud99dff2e"></p> 
<pre id="d29f7348"><code>(0.9333333333333333, 0.7428147030978105)</code></pre> 
<p id="u243188ab"></p> 
<pre id="8bac59fd"><code># æŸ¥çœ‹æ˜¯å¦ä¸æˆ‘ä»¬è®°å½•çš„æœ€é«˜å‡†ç¡®ç‡ä¸€è‡´
epoch_test_acc</code></pre> 
<p id="u52079b39"></p> 
<pre id="undefined0.9333333333333333"><code>0.9333333333333333</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/388b5f3d54450df559252fdea6cf1af1/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">ä¼ ç»Ÿé¡¹ç›®åŸºäºtomcat cookieå•ä½“ä¼šè¯å‡çº§åˆ†å¸ƒå¼ä¼šè¯è§£å†³æ–¹æ¡ˆ</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e7b4d317e8f79712211667071c3ec378/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">pythonåšæ•°æ®åˆ†ææ—¶ç¼ºå¤±å€¼å¡«è¡¥ã€ç¼ºå¤±å€¼å¡«å……æ–¹æ³•æ±‡æ€»</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>