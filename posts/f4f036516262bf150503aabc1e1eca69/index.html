<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>分享57个Python源码，总有一款适合您 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="分享57个Python源码，总有一款适合您" />
<meta property="og:description" content="Python源码
分享57个Python源码，总有一款适合您
57个Python源码下载链接：https://pan.baidu.com/s/1YZcrJAYFFy3OrdEN5IxnQQ?pwd=6666
提取码：6666
下面是文件的名字，我放了一些图片，文章里不是所有的图主要是放不下...，大家下载后可以看到。
参数代码 base_url = &#34;https://down.chinaz.com&#34; # 采集的网址 save_path = &#34;D:\\Freedom\\Sprider\\ChinaZ\\&#34; sprider_count = 88 # 采集数量 sprider_start_count=0# 从第几个序号开始 直接改数量即可 会做除法操作正 正在采集第32页的第16个资源 debug word_content_list = [] folder_name = &#34;&#34; page_end_number=0 max_pager=15 #每页的数量 haved_sprider_count =0 # 已经采集的数量 page_count = 1 # 每个栏目开始业务content=&#34;text/html; charset=gb2312&#34; 核心代码 def sprider(self,title_name=&#34;NET&#34;): &#34;&#34;&#34; 采集 PHP https://down.chinaz.com/class/572_5_1.htm NET https://down.chinaz.com/class/572_4_1.htm ASP https://down.chinaz.com/class/572_3_1.htm Pytyhon https://down.chinaz.com/class/604_572_1.htm :return: &#34;&#34;&#34; if title_name == &#34;PHP&#34;: self.folder_name = &#34;PHP源码&#34; self.second_column_name = &#34;572_5&#34; elif title_name == &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/f4f036516262bf150503aabc1e1eca69/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-11T08:19:02+08:00" />
<meta property="article:modified_time" content="2023-04-11T08:19:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">分享57个Python源码，总有一款适合您</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Python源码<br> 分享57个Python源码，总有一款适合您</p> 
<p>57个Python源码下载链接：<a class="link-info" href="https://pan.baidu.com/s/1YZcrJAYFFy3OrdEN5IxnQQ?pwd=6666" rel="nofollow" title="https://pan.baidu.com/s/1YZcrJAYFFy3OrdEN5IxnQQ?pwd=6666">https://pan.baidu.com/s/1YZcrJAYFFy3OrdEN5IxnQQ?pwd=6666</a><br> 提取码：6666</p> 
<p><br> 下面是文件的名字，我放了一些图片，文章里不是所有的图主要是放不下...，大家下载后可以看到。</p> 
<p style="text-align:center;"><br>  <img alt="" src="https://images2.imgbox.com/09/c0/559R6Ibb_o.png"></p> 
<p> </p> 
<pre><code class="hljs">参数代码

    base_url =  "https://down.chinaz.com" # 采集的网址
    save_path = "D:\\Freedom\\Sprider\\ChinaZ\\"
    sprider_count = 88  # 采集数量
    sprider_start_count=0# 从第几个序号开始 直接改数量即可 会做除法操作正 正在采集第32页的第16个资源 debug
 
 
 
    word_content_list = []
    folder_name = ""
    page_end_number=0
    max_pager=15 #每页的数量
    haved_sprider_count =0  # 已经采集的数量
    page_count = 1  # 每个栏目开始业务content="text/html; charset=gb2312"
核心代码

 
    def sprider(self,title_name="NET"):
 
        """
       采集
       PHP https://down.chinaz.com/class/572_5_1.htm
       NET https://down.chinaz.com/class/572_4_1.htm
       ASP https://down.chinaz.com/class/572_3_1.htm
       Pytyhon https://down.chinaz.com/class/604_572_1.htm
       :return:
       """
        if title_name == "PHP":
            self.folder_name = "PHP源码"
            self.second_column_name = "572_5"
        elif title_name == "Go":
            self.folder_name = "Go源码"
            self.second_column_name = "606_572"
        elif title_name == "NET":
            self.folder_name = "NET源码"
            self.second_column_name = "572_4"
        elif title_name == "ASP":
            self.folder_name = "ASP源码"
            self.second_column_name = "572_3"
        elif title_name == "Python":
            self.folder_name = "Python源码"
            self.second_column_name = "604_572"
        #
 
        first_column_name = title_name # 一级目录
        second_folder_name = str(self.sprider_count) + "个" + self.folder_name #二级目录
 
        merchant=int(self.sprider_start_count) //int(self.max_pager)+1 #起始页码用于效率采集
        self.file_path = self.save_path + os.sep + "Code" + os.sep + first_column_name + os.sep + second_folder_name
        self.save_path = self.save_path+ os.sep + "Code" + os.sep+first_column_name+os.sep + second_folder_name+ os.sep + self.folder_name
        BaseFrame().debug("开始采集ChinaZCode"+self.folder_name+"...")
        sprider_url = (self.base_url + "/class/{0}_1.htm".format(self.second_column_name))
        down_path="D:\\Freedom\\Sprider\\ChinaZ\\Code\\"+first_column_name+"\\"+second_folder_name+"\\Temp\\"
        if os.path.exists(down_path) is True:
            shutil.rmtree(down_path)
        if os.path.exists(down_path) is False:
            os.makedirs(down_path)
 
        if os.path.exists(self.save_path ) is True:
            shutil.rmtree(self.save_path )
        if os.path.exists(self.save_path ) is False:
            os.makedirs(self.save_path )
        chrome_options = webdriver.ChromeOptions()
        diy_prefs ={'profile.default_content_settings.popups': 0,
                    'download.default_directory':'{0}'.format(down_path)}
        # 添加路径到selenium配置中
        chrome_options.add_experimental_option('prefs', diy_prefs)
        chrome_options.add_argument('--headless') #隐藏浏览器
 
        # 实例化chrome浏览器时，关联忽略证书错误
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_window_size(1280, 800)  # 分辨率 1280*800
 
        # driver.get方法将定位在给定的URL的网页，get接受url可以是任何网址，此处以百度为例
        driver.get(sprider_url)
        # content = driver.page_source
        # print(content)
        div_elem = driver.find_element(By.CLASS_NAME, "main")  # 列表页面 核心内容
        element_list = div_elem.find_elements(By.CLASS_NAME, 'item')
 
        laster_pager_ul = driver.find_element(By.CLASS_NAME, "el-pager")
        laster_pager_li =laster_pager_ul.find_elements(By.CLASS_NAME, 'number')
        laster_pager_url = laster_pager_li[len(laster_pager_li) - 1]
        page_end_number = int(laster_pager_url.text)
        self.page_count=merchant
        while self.page_count &lt;= int(page_end_number):  # 翻完停止
            try:
                if self.page_count == 1:
                    self.sprider_detail(driver,element_list,self.page_count,page_end_number,down_path)
                    pass
                else:
                    if self.haved_sprider_count == self.sprider_count:
                        BaseFrame().debug("采集到达数量采集停止...")
                        BaseFrame().debug("开始写文章...")
                        self.builder_word(self.folder_name, self.save_path, self.word_content_list)
                        BaseFrame().debug("文件编写完毕，请到对应的磁盘查看word文件和下载文件！")
                        break
                    #(self.base_url + "/sort/{0}/{1}/".format(url_index, self.page_count))
                    #http://soft.onlinedown.net/sort/177/2/
 
                    next_url = self.base_url + "/class/{0}_{1}.htm".format(self.second_column_name, self.page_count)
                    driver.get(next_url)
 
                    div_elem = driver.find_element(By.CLASS_NAME, "main")  # 列表页面 核心内容
                    element_list = div_elem.find_elements(By.CLASS_NAME, 'item')
                    self.sprider_detail( driver, element_list, self.page_count, page_end_number, down_path)
                    pass
                #print(self.page_count)
                self.page_count = self.page_count + 1  # 页码增加1
            except Exception as e:
                print("sprider()执行过程出现错误:" + str(e))
                sleep(10)
 
 
 
    def sprider_detail(self, driver,element_list,page_count,max_page,down_path):
        """
        采集明细页面
        :param driver:
        :param element_list:
        :param page_count:
        :param max_page:
        :param down_path:
        :return:
        """
        index = 0
        element_array=[]
        element_length=len(element_list)
        for element in element_list:
            url_A_obj = element.find_element(By.CLASS_NAME,  'name-text')
            next_url = url_A_obj.get_attribute("href")
            coder_title = url_A_obj.get_attribute("title")
            e=coder_title+"$"+ next_url
            element_array.append(e)
            pass
 
        self.sprider_start_index = int(self.sprider_start_count) % int(self.max_pager)
        index=self.sprider_start_index
        while index &lt; element_length:
 
 
            if os.path.exists(down_path) is False:
                os.makedirs(down_path)
 
            if self.haved_sprider_count == self.sprider_count:
                BaseFrame().debug("采集到达数量采集停止...")
                break
 
            #element = element_list[index]
            element=element_array[index]
            time.sleep(1)
 
            index = index + 1
            sprider_info="正在采集第"+str(page_count)+"页的第"+str(index)+"个资源，共"+str(max_page)+"页资源"
            BaseFrame().debug(sprider_info)
            next_url=element.split("$")[1]
            coder_title=element.split("$")[0]
            # next_url = element.find_element(By.TAG_NAME, 'a').get_attribute("href")
            # coder_title =element.find_element(By.TAG_NAME, 'img').get_attribute("title")
            driver.get(next_url) # 请求明细页面
            try:
                # codeEntity = SpriderEntity()  # 下载过的资源不再下载
                # codeEntity.sprider_base_url = self.base_url
                # codeEntity.create_datetime = SpriderTools.get_current_datetime()
                # codeEntity.sprider_url = next_url
                # codeEntity.sprider_pic_title = coder_title
                # codeEntity.sprider_pic_index = str(index)
                # codeEntity.sprider_pager_index = page_count
                # codeEntity.sprider_type = "code"
                # if SpriderAccess().query_sprider_entity_by_urlandindex(next_url, str(index)) is None:
                #     SpriderAccess().save_sprider(codeEntity)
                # else:
                #     BaseFrame().debug(coder_title+next_url + "数据采集过因此跳过")
                #     continue
 
                if SeleniumTools.judeg_element_isexist(driver, "CLASS_NAME", "download-item") == 3:
                    driver.back()
                    BaseFrame().debug(coder_title+"不存在源码是soft因此跳过哦....")
                    continue
                print("准备点击下载按钮...")
                driver.find_element(By.CLASS_NAME, "download-item").click() #下载源码
 
                result,message=SpriderTools.judge_file_exist(True,240,1,down_path,"zip|rar|gz|tgz")#判断源码
                if result is True:
 
                    sprider_content = [coder_title, self.save_path + os.sep +"image"+ os.sep + coder_title + ".jpg"]  # 采集成功的记录
                    self.word_content_list.append(sprider_content)  # 增加到最终的数组
                    self.haved_sprider_count = self.haved_sprider_count + 1
                    BaseFrame().debug("已经采集完成第" + str(self.haved_sprider_count) + "个")
                    time.sleep(1)
                    driver.back()
 
                    coder_title = str(coder_title).replace("/", "") #去掉windows不识别的字符
                    files = os.listdir(down_path)
                    srcFile = down_path + os.sep + files[0]
                    file_ext = os.path.splitext(srcFile)[-1]
 
                    dstFile = down_path + os.sep + coder_title + file_ext
                    os.rename(srcFile, dstFile)
                    srcFile = dstFile
                    dstFile = self.save_path + os.sep + coder_title + file_ext
 
                    shutil.move(srcFile, dstFile)  # 移动文件
 
                else:
                    BaseFrame().error("检测下载文件出错可能原因是等待时间不够已经超时，再等待70秒...")
                    time.sleep(70)
                    #shutil.rmtree(down_path) #如果没下载完是无法删除的
                    #使用数组append记录文件名字 移动的时候过滤
 
                    pass
            except Exception as e:
                #shutil.rmtree(down_path)
                BaseFrame().error("sprider_detail()执行过程出现错误：" + str(e))
                #driver.get(sprider_url)
                #driver.quit()
 
        if(int(page_count)==int(max_page)):
            self.builder_word(self.folder_name,self.save_path,self.word_content_list)
            BaseFrame().debug("文件编写完毕，请到对应的磁盘查看word文件和下载文件！")</code></pre> 
<p>Locust负载测试工具 v2.14.2<br> ArkID企业级IDaaS/IAM平台系统 v2.6.10<br> Apache Superset数据探查与可视化平台 v2.0.1<br> Jumpserver开源堡垒机 v2.28.6<br> bk-PaaS蓝鲸智云PaaS平台 v2.14.40<br> PaddleNLP v2.4.8<br> CODO云管理平台 v1.0<br> MindArmour v1.9.0<br> PaddleHub v2.3.1<br> PaddlePaddle深度学习平台 v2.4.1<br> Macast投屏软件 v0.7 源码包<br> MrDoc在线文档系统 v0.8.5<br> DrissionPage  Web自动化操作集成工具 v2.7.3<br> Quick Cut 视频处理软件 v1.6.10<br> MindInsight可视化仪表板 v1.9.0<br> GreaterWMS仓库管理系统 v2.1.25<br> W5 SOAR安全编排与自动化响应平台 v0.6.2<br> wukongrobot智能音箱项目 v2.5.4<br> Spyder集成开发环境 v5.4.0<br> Hyperledger Fabric区块链分布式账本 v2.4.7<br> simpleui v2021.8.1<br> Spug自动化运维平台 v3.2.5<br> Archery SQL审核查询平台 v1.9.1<br> smartchart数据可视化平台 v5.7<br> PaddleDetection v2.5.0<br> PaddleOCR工具库 v2.6.0<br> Lepus数据库企业监控系统 v5.1<br> ChiaTools (Chia官方钱包P图功能的替代品) v1.5.6<br> Graphite网站实时信息采集和统计 v1.1.10<br> Redash开源的数据图表工具 v10.1.0<br> PaddleX v2.0.0 rc0<br> Spyder集成开发环境 v4.2.5<br> Jumpserver v2.7.3<br> PyMiner数学工具 v2.1.0 beta<br> Hyperledger Fabric区块链分布式账本 v1.4.11<br> vtags编辑器插件 v1.0<br> Taisite-Platform v1.0<br> PyMiner数学工具 v1.0.2<br> ECommerceCrawlers Web爬虫 v11<br> yiwa伊瓦 v1.0<br> Senta情感分析系统 v1.0<br> DFace人脸识别系统 v0.5<br> inna映射技术 v1.0<br> PySipder爬虫程序 v0.3.10<br> PPMessage在线客服平台 v1.0<br> MySQLMTOP数据库监控系统 v2.1<br> plainCms异步协程内容管理系统 v1.0<br> ZeroNet去中心化网站系统 v0.7.1<br> API Star工具箱 v0.7.2<br> 鸿鹄智能云CMS站群系统 v1.2.2<br> 双鱼林Python基于Django图书管理系统 v1.0<br> 在线网络小说阅读网站 v1.2<br> Django博客系统 v3.2 正式版<br> ijd8 Octopress主题 v0.1<br> 求打赏 v1.0<br> GAEPhotos v1.0.3<br> Mediacore 多媒体建站系统  v0.9.0<br>  </p> 
<p>清理垃圾文件</p> 
<pre><code class="hljs">import os
 
 
# 查找指定文件夹下所有相同名称的文件
def search_file(dirPath, fileName):
    dirs = os.listdir(dirPath)  # 查找该层文件夹下所有的文件及文件夹，返回列表
    for currentFile in dirs:  # 遍历列表
        absPath = dirPath + '/' + currentFile
        if os.path.isdir(absPath):  # 如果是目录则递归，继续查找该目录下的文件
            search_file(absPath, fileName)
        elif currentFile == fileName:
            print(absPath)  # 文件存在，则打印该文件的绝对路径
            os.remove(absPath)
 
 
if __name__ == "__main__":
    dirPath = 'D:\Freedom\Sprider\ChinaZ\Code\Python\\57个Python源码\Python源码'
    #dirPath = 'D:\\Freedom\\Sprider\\ChinaZ\\Code\\NET\\99个NET源码\\NET源码' D:\Freedom\Sprider\ChinaZ\Code\PHP\126个PHP源码\PHP源码
    fileName4 = '服务器软件.url'
    fileName3 = '脚本之家.url'
    fileName2 = 'Readme-说明.htm'
    fileName5 = 'jb51.net.txt'
    fileName1 = '说明.htm'
    search_file(dirPath, fileName1)
    search_file(dirPath, fileName2)
    search_file(dirPath, fileName3)
    search_file(dirPath, fileName4)
    search_file(dirPath, fileName5)
 
    search_file(dirPath, "源码之家说明.txt")
    search_file(dirPath, "服务器常用软件.html")
    search_file(dirPath, "访问脚本之家.html")</code></pre> 
<p>最后送大家一首诗:</p> 
<p>山高路远坑深,<br> 大军纵横驰奔,<br> 谁敢横刀立马？<br> 惟有点赞加关注大军。<br>  </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/59ef146e6ac25c5b2da71a99c6890c20/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于解决Vue.config.productionTip=false控制台的提示没消失问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f69f9b218f1a56b2ebeb0306338bc0f1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Idea中的NexChatGPT如何使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>