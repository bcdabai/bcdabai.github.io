<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>子域名挖掘，子域名爆破,Python脚本编写（Python安全攻防）。 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="子域名挖掘，子域名爆破,Python脚本编写（Python安全攻防）。" />
<meta property="og:description" content="1.什么是域名。 域名（Domain Name），又称网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识（有时也指地理位置）。 由于IP地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP地址相互映射，使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP地址数串。
域名有级别之分，可以分为顶级域名（一级域名）、二级域名、三级域名、多级域名
二级三级和多级则是此网站的子域名。例如：顶级域名：miduoqi.com，二级域名：www.miduoqi.com； 三级域名：.............
2.子域名挖掘的收集原理 常用的收集方式有字典爆破，DNS信息收集，证书查询，爬虫提取子域名等，咱们这次脚本是通过搜索引擎进行子域名搜集。
1.字典爆破
字典爆破就是通过收集来的字典，拼接到顶级域名前面，然后通过自动化工具进行访问，判断返回结果，从而跑出子域名是否存在。
爆破处理接货主要是依赖于字典的精准度，一本好的字典可以让你事半功倍。
2.DNS信息收集
DNS原理就是搜集DNS的解析历史，通过查询dns记录来获取到对方的解析记录，从而获取到子域名，正常来说你的域名经DNS解析过一般就会搜到。
3.证书查询
通过HTTPS 证书，ssl证书等搜集子域名记录。
4.爬虫提取子域名
可以利用爬虫从页面源代码中提取子域名。
原理介绍参考：
(11条消息) 信息搜集-子域名挖掘_小刚的博客-CSDN博客_子域名挖掘https://blog.csdn.net/weixin_43221560/article/details/109118270
3.脚本编写 （1）创建名为子域名挖掘的py文件，导入一些需要用的python模块
#requests库内置了不同的方法来发送不同类型的http请求 import requests #BS主要功能是从网页抓取数据，提供一些简单的、python 式的函数用来处理导航、搜索、修改分析树等功能 from bs4 import BeautifulSoup #模块主要用于解析url中的参数，对url按照一定格式进行 拆分或拼接，将url分为6个部分，返回一个包含6个字符串项目的元组：协议、位置、路径、参数、查询、片段 from urllib.parse import urlparse import sys （2）通过bing搜索引擎来进行子域名搜集s
def bing_search(site,pages): Subdomain = [] headers = { #HTTP Headers是HTTP请求和相应的核心，它承载了关于客户端浏览器，请求页面，服务器等相关的信息 &#39;User-Agent&#39;: &#39;Mozilla/5.0 (x11; Linux x86_64;rv:68.0)Gecko/20100101 Firefox/68.0&#39;, #是Http协议中的一部分，属于头域的组成部分，是一种向访问网站提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识 &#39;Accept&#39;: &#39;text/html,application/xhtml&#43;xml,application/xml;q=0.9,*/*;q=0.8&#39;,#属于请求报头，代表发送端（客户端）希望接受的数据类型 &#39;Referer&#39;: &#34;https://cn.bing.com&#34;, #表示一个来源 &#39;Cookie&#39;: &#34;MUID=3B46E5B***********78X&amp;T=6&#34; #类型为“小型文本文件”，是某些网站为了辨别用户身份，进行Session跟踪而储存在用户本地终端上的数据（通常经过加密），由用户客户端计算机暂时或永久保存的信息 } for i in range(1,int(pages)&#43;1): url = &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7b16d59591f87ad54f6ab904bf048005/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-17T21:27:37+08:00" />
<meta property="article:modified_time" content="2021-11-17T21:27:37+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">子域名挖掘，子域名爆破,Python脚本编写（Python安全攻防）。</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1.什么是域名。</h2> 
<p><span style="color:#0d0016;"><strong>域名</strong>（<strong>Domain Name</strong>），又称<strong>网域</strong>，是由一串用点分隔的名字组成的<a href="https://baike.baidu.com/item/Internet" rel="nofollow" title="Internet">Internet</a>上某一台<a href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA/140338" rel="nofollow" title="计算机">计算机</a>或计算机组的名称，用于在数据传输时对计算机的定位标识（有时也指地理位置）。 由于<a href="https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80/150859" rel="nofollow" title="IP地址">IP地址</a>具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（<a href="https://baike.baidu.com/item/DNS" rel="nofollow" title="DNS">DNS</a>，Domain Name System）来将域名和<a href="https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80" rel="nofollow" title="IP地址">IP地址</a>相互<a href="https://baike.baidu.com/item/%E6%98%A0%E5%B0%84/20402621" rel="nofollow" title="映射">映射</a>，使人更方便地访问<a href="https://baike.baidu.com/item/%E4%BA%92%E8%81%94%E7%BD%91/199186" rel="nofollow" title="互联网">互联网</a>，而不用去记住能够被机器直接读取的<a href="https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80" rel="nofollow" title="IP地址">IP地址</a>数串。</span></p> 
<p><span style="color:#0d0016;"><strong>域名有级别之分</strong>，可以分为顶级域名（一级域名）、二级域名、三级域名、多级域名<br> 二级三级和多级则是此网站的子域名。例如：顶级域名：miduoqi.com，二级域名：www.miduoqi.com； 三级域名：.............</span><br>  </p> 
<h2>2.子域名挖掘的收集原理</h2> 
<p><span style="color:#0d0016;">常用的收集方式有字典爆破，DNS信息收集，证书查询，爬虫提取子域名等，咱们这次脚本是通过搜索引擎进行子域名搜集</span>。</p> 
<p>1.字典爆破<br> 字典爆破就是通过收集来的字典，拼接到顶级域名前面，然后通过自动化工具进行访问，判断返回结果，从而跑出子域名是否存在。<br> 爆破处理接货主要是依赖于字典的精准度，一本好的字典可以让你事半功倍。</p> 
<p>2.DNS信息收集<br> DNS原理就是搜集DNS的解析历史，通过查询dns记录来获取到对方的解析记录，从而获取到子域名，正常来说你的域名经DNS解析过一般就会搜到。</p> 
<p>3.证书查询<br> 通过HTTPS 证书，ssl证书等搜集子域名记录。</p> 
<p>4.爬虫提取子域名<br> 可以利用爬虫从页面源代码中提取子域名。<br> 原理介绍参考：</p> 
<p><a class="has-card" href="https://blog.csdn.net/weixin_43221560/article/details/109118270" title="(11条消息) 信息搜集-子域名挖掘_小刚的博客-CSDN博客_子域名挖掘"><span class="link-card-box"><span class="link-title">(11条消息) 信息搜集-子域名挖掘_小刚的博客-CSDN博客_子域名挖掘</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/51/50/yJycAPJN_o.png">https://blog.csdn.net/weixin_43221560/article/details/109118270</span></span></a></p> 
<h2>3.脚本编写</h2> 
<p>（1）创建名为子域名挖掘的py文件，导入一些需要用的python模块</p> 
<pre><code class="language-python">#requests库内置了不同的方法来发送不同类型的http请求
import requests                      
 #BS主要功能是从网页抓取数据，提供一些简单的、python 式的函数用来处理导航、搜索、修改分析树等功能
from bs4 import BeautifulSoup  
#模块主要用于解析url中的参数，对url按照一定格式进行 拆分或拼接，将url分为6个部分，返回一个包含6个字符串项目的元组：协议、位置、路径、参数、查询、片段     
from urllib.parse import urlparse   
import sys 
</code></pre> 
<p>（2）通过bing搜索引擎来进行子域名搜集s</p> 
<pre><code class="language-python">def bing_search(site,pages):
    Subdomain = []
    headers = {         #HTTP Headers是HTTP请求和相应的核心，它承载了关于客户端浏览器，请求页面，服务器等相关的信息
        'User-Agent': 'Mozilla/5.0 (x11; Linux x86_64;rv:68.0)Gecko/20100101 Firefox/68.0',   #是Http协议中的一部分，属于头域的组成部分，是一种向访问网站提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',#属于请求报头，代表发送端（客户端）希望接受的数据类型
        'Referer': "https://cn.bing.com",  #表示一个来源
        'Cookie': "MUID=3B46E5B***********78X&amp;T=6"   #类型为“小型文本文件”，是某些网站为了辨别用户身份，进行Session跟踪而储存在用户本地终端上的数据（通常经过加密），由用户客户端计算机暂时或永久保存的信息
    }
    for i in range(1,int(pages)+1):
        url = "https://cn.bing.com/search?q=site%3a"+site+"&amp;go=Search&amp;qs=ds&amp;first="+ str((int(i)-1)*10) +"&amp;FORM=PERE"
        html = requests.get(url,headers=headers)     #获取HTML网页，对应HTTP的GET
        soup = BeautifulSoup(html.content,'html.parser')
        job_bt = soup.findAll('h2')     #返回一个包含HTML文档标题标签h2的列表
        for i in job_bt:
            link = i.a.get('href')
            domain = str(urlparse(link).scheme + "://" +urlparse(link).netloc)  #储存子域名
            if domain in Subdomain:
                pass
            else:
                Subdomain.append(domain)
                print(domain)
if __name__ == '__main__':
    if len(sys.argv) == 3:
        site = sys.argv[1]
        page = sys.argv[2]
    else:
        print("usage: %s baidu.com 10" % sys.argv[0])         #输出帮助信息
        sys.exit(-1)
    Subdomain = bing_search(site,page)</code></pre> 
<p></p> 
<p>  (3) 结果：输入python 子域名挖掘.py baidu.com 5</p> 
<p><img alt="" height="388" src="https://images2.imgbox.com/cf/ac/FMIuLVvM_o.png" width="703"></p> 
<p><strong>以上总结或许能帮助到你，或许帮助不到你，但还是希望能帮助到你，如有疑问、歧义，直接私信留言会及时修正发布；非常期待你的点赞和分享哟，谢谢！</strong></p> 
<p><img alt="" height="258" src="https://images2.imgbox.com/31/fc/fRiJQn9N_o.png" width="653"></p> 
<p> </p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6d3fab404d753e282965ae4dddc74ef4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Mybatis-Plus学习笔记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a1066d6fee10cb128cce043e23411b58/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">oracle闪回查询恢复数据操作示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>