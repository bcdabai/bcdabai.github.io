<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习思考题目——10神经网络基础 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习思考题目——10神经网络基础" />
<meta property="og:description" content="本文直译自《hands on ML》课后题。（有改动的以【】表示）
1.用原始人工神经元（为组件）画出一个ANN的示意图，来实现操作 A ⊕ B ：⊕表示异或操作XOR。提示：A ⊕ B = (A∧ ¬ B) ∨ (¬ A ∧ B). 下图是用原始人工神经元为基础的神经网络，实现异或操作，基于公式A ⊕ B = (A ∧ ¬ B)
∨ (¬ A ∧ B)。图形还有其他若干解法，例如基于公式 A ⊕ B =(A ∨ B) ∧ ¬(A ∧ B)或者 A ⊕ B = (A ∨ B) ∧ (¬ A ∨ ∧ B)等等。
【补充——画图方法——不同情况示意图】
2.一般而言，为什么Logistics Regression分类器比经典感知机（i.e.，classical Perceptron，a single layer of linear threshold units trained using the Perceptron training algorithm）更好？怎样调整（tweak）感知机，使其等价于Logistics Regression分类器？ （1）经典感知机只有在数据集线性可分的情况下才收敛，而且它不能估计类的概率。数据集线性不可分的时候，LR分类器也可以收敛到一个好的解，同时LR会输出类的概率。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/a84b5449efb55cdbcba0fe846d54f8c9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-11T19:07:25+08:00" />
<meta property="article:modified_time" content="2019-03-11T19:07:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习思考题目——10神经网络基础</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>本文直译自《hands on ML》课后题。（有改动的以【】表示）</p> 
<h3><a id="1ANN_A__B_XORA__B__A__B___A__B_2"></a>1.用原始人工神经元（为组件）画出一个ANN的示意图，来实现操作 A ⊕ B ：⊕表示异或操作XOR。提示：A ⊕ B = (A∧ ¬ B) ∨ (¬ A ∧ B).</h3> 
<p>下图是用原始人工神经元为基础的神经网络，实现异或操作，基于公式A ⊕ B = (A ∧ ¬ B)<br> ∨ (¬ A ∧ B)。图形还有其他若干解法，例如基于公式 A ⊕ B =(A ∨ B) ∧ ¬(A ∧ B)或者 A ⊕ B = (A ∨ B) ∧ (¬ A ∨ ∧ B)等等。<br> <img src="https://images2.imgbox.com/aa/ff/aiw362J1_o.png" alt="在这里插入图片描述">【补充——画图方法——不同情况示意图】<br> <img src="https://images2.imgbox.com/3f/f1/H3arYect_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2Logistics_Regressionieclassical_Perceptrona_single_layer_of_linear_threshold_units_trained_using_the_Perceptron_training_algorithmtweakLogistics_Regression_8"></a>2.一般而言，为什么Logistics Regression分类器比经典感知机（i.e.，classical Perceptron，a single layer of linear threshold units trained using the Perceptron training algorithm）更好？怎样调整（tweak）感知机，使其等价于Logistics Regression分类器？</h3> 
<p>（1）经典感知机只有在数据集线性可分的情况下才收敛，而且它不能估计类的概率。数据集线性不可分的时候，LR分类器也可以收敛到一个好的解，同时LR会输出类的概率。<br> （2）如果把感知机的激活函数改为logistics函数（如果有多个输出神经元，则改为softmax函数），用梯度下降来训练（或者其他能最小化损失函数（例如交叉熵）的优化算法），这样感知机就等价于LR分类器。</p> 
<h3><a id="3logisticsMLPkey_ingredient_13"></a>3.为什么logistics激活函数是训练MLP的关键成分（key ingredient）？</h3> 
<p>logistics激活函数是训练MLP中的关键成分，是因为它的导数总是非零的，因此梯度下降总可以从斜坡（slope）向下滑动（roll down the slope）。当激活函数是阶梯函数的时候，梯度下降不能移动，因为根本就没有斜坡（slope）。<br> 【说明：原题干是训练 ‘first MLPs’，没理解，所以作了修改】</p> 
<h3><a id="4_18"></a>4.列举三种常用的激活函数，你能画出图形么？</h3> 
<p>（a）阶梯函数（step function）<br> （b）logistics函数：公式为 σ(z) =1 / (1 + exp(–z))<br> （c）双曲正切函数（hyperbolic tangent）：<br> tanh (z) = 2σ(2z) – 1=2 / (1+exp(-2z))-1=(1-exp(-2z)) / (1+exp(-2z))<br> （d）整流线性单元（ReLU函数）：ReLU (z) = max (0, z)（简化版公式）<br> （e）ELU函数<br> （f ）LeakyReLU<br> 部分激活函数及其导数图形如下（只包含阶梯函数、logistics、Tanh、ReLU）：<br> <img src="https://images2.imgbox.com/23/95/UFATDGsL_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5MLP10passthrough_neurons503ReLU_30"></a>5.假设一个MLP组成如下：输入层有10个输入神经元（passthrough neurons），后面有50个神经元的隐层，最后是3个神经元的输出层。所有的神经元（不包括输入层的）都是用ReLU激活函数：</h3> 
<p><strong>（a）输入矩阵（input matrix）X的形状是什么？<br> （b）隐层weight向量Wh的形状是什么？隐层bias向量bh的形状是什么？<br> （c）输出层weight向量Wo的形状是什么？输出层bias向量bo形状是什么？<br> （d）这个网络的输出矩阵Y的形状是什么？<br> （e）计算Y的关于 X、Wh、bh、Wo、bo的计算公式是什么？</strong></p> 
<p><em><strong>ANSWER:</strong></em><br> （a）输入矩阵X的形状是 m × 10，m表示训练batch中样本数量；<br> （b）Wh形状是 10 × 50；bh的长度是50；<br> （c）Wo的形状是 50 × 3，bo长度是3；<br> （d）输出矩阵Y的形状是 m × 3；<br> （e）Y=ReLU(ReLU(X*Wh+bh)<em>Wo+bo)【原答案是Y=(X</em>Wh+bh)*Wo+bo,貌似有点问题】</p> 
<h3><a id="6MNIST_44"></a>6.如果想把邮件分为垃圾邮件和正常邮件，输出层中需要几个神经元，输出层中应该用什么激活函数？如果是处理MNIST数据集，输出层中应该用几个神经元，什么激活函数？对于房价预测问题，输出层中该用几个神经元，什么激活函数？</h3> 
<p>（1）邮件分为为二分类：输出层需要1个神经元，可以用logistics激活函数；<br> （2）MNIST是多（10）分类：输出层需要10个神经元，用softmax激活函数；<br> （3）房价预测是回归问题：输出层需要1个神经元，输出层中不需要激活函数。说明：如果目标值之间数量级跨度很大，可以对目标值取对数之后的值作为目标值，对于模型的输出，可以再取指数得到原值，即利用exp ( log ( v ) )=v 。</p> 
<h3><a id="7backpropagationreversemode_49"></a>7.什么是反向传播（backpropagation），它是怎么工作的？反向传播和reverse-mode自动微分的区别是什么？</h3> 
<p>【反向传播】反向传播是用来训练人工神经网络（ANN）的技术。它首先计算损失函数关于每个模型参数（所有的weight和bias）的梯度，然后用这些梯度进行梯度下降。（模型训练）一般需要用很多训练batch进行上千次甚至百万次反向传播，直到模型参数收敛到损失函数的最小点（理想上的）。<br> 【Reverse-mode自动微分】为了计算梯度，反向传播运用了reverse-mode自动微分（尽管当反向传播发明的时候，它的称呼并不是这个，而且目前它已经被改造过若干次）。Reverse-mode自动微分向前穿过计算图，计算每个节点的在当前训练batch下的数值，然后它反向穿过计算图，一次计算出所有的梯度。<br> 【二者的区别】那他们的区别是什么呢？反向传播是指应用多次[反向传播步骤]训练神经网络的全过程，每一次[反向传播步骤]中计算梯度然后用它们来进行梯度下降。reverse-mode自动微分只是高效计算梯度的一种技术，它恰巧被反向传播所用。</p> 
<h3><a id="8_MLP_53"></a>8. 能否列出MLP中所有可以调节的超参数？怎样调节超参数来解决过拟合问题？</h3> 
<p>（1）可以调节的超参数：<br> （a）隐层的数目；<br> （b）每个隐层的神经元的数目；<br> （c）所有隐层和输出层的激活函数（一般而言：RELU是隐层激活函数好的默认选项；二分类用logistics激活函数；多分类用softmax；回归问题不需要激活函数）；<br> （2）过拟合的时候可以尝试减少隐层的数目和每个隐层的神经元的数目。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6bdf3c7a35ac1a801747993d4a8096b1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">thymeleaf模板对没有结束符的HTML5标签解析出错的解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/759dde8d3008579ebc7744f409dbe0fd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用python创建数组的方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>