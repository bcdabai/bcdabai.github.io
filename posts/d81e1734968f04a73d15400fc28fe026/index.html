<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文阅读笔记（8）: 图卷积半监督分类 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文阅读笔记（8）: 图卷积半监督分类" />
<meta property="og:description" content="代码：
参考：链接
pytorch git hub: 链接
# -*- coding: utf-8 -*- # time : 2021/4/19 19:52 # task: gcn 代码解读 import torch import numpy as np import scipy.sparse as sp import sys from sklearn.preprocessing import OneHotEncoder import sklearn import pandas as pd &#39;&#39;&#39; 先将所有由字符串表示的标签数组用set保存，set的重要特征就是元素没有重复， 因此表示成set后可以直接得到所有标签的总数，随后为每个标签分配一个编号，创建一个单位矩阵， 单位矩阵的每一行对应一个one-hot向量，也就是np.identity(len(classes))[i, :]， 再将每个数据对应的标签表示成的one-hot向量，类型为numpy数组 &#39;&#39;&#39; def encode_onehot(labels): classes = set(labels) # set() 函数创建一个无序不重复元素集 classes_dict = {c: np.identity(len(classes))[i, :] for i, c in # identity创建方矩阵 enumerate(classes)} # 字典 key为label的值，value为矩阵的每一行 # enumerate函数用于将一个可遍历的数据对象组合为一个索引序列 labels_onehot = np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/d81e1734968f04a73d15400fc28fe026/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-20T19:48:30+08:00" />
<meta property="article:modified_time" content="2021-04-20T19:48:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文阅读笔记（8）: 图卷积半监督分类</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/39/16/2lEpRgqI_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/5d/3e/fct94YMm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6f/91/SpfhIdwj_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9e/83/qnvFJXMt_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ca/de/Vp7acnKn_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a1/5b/dj2uLq83_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1d/b2/2r4SsCUF_o.png" alt="在这里插入图片描述"><br> 代码：<br> 参考：<a href="https://blog.csdn.net/weixin_43476533/article/details/105750702">链接</a><br> pytorch git hub: <a href="https://github.com/smiledinisa/GNN_code/tree/main/semi_Gcn_torch_version">链接</a></p> 
<pre><code class="prism language-cpp"># <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> coding<span class="token operator">:</span> utf<span class="token operator">-</span><span class="token number">8</span> <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> 

<span class="token macro property"># time : 2021/4/19 19:52</span>
<span class="token macro property"># task:  gcn 代码解读</span>
import torch
import numpy as np
import scipy<span class="token punctuation">.</span>sparse as sp
import sys
from sklearn<span class="token punctuation">.</span>preprocessing import OneHotEncoder
import sklearn
import pandas as pd
<span class="token string">''</span>'
先将所有由字符串表示的标签数组用set保存，set的重要特征就是元素没有重复，
因此表示成set后可以直接得到所有标签的总数，随后为每个标签分配一个编号，创建一个单位矩阵，
单位矩阵的每一行对应一个one<span class="token operator">-</span>hot向量，也就是np<span class="token punctuation">.</span><span class="token function">identity</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token operator">:</span><span class="token punctuation">]</span>，
再将每个数据对应的标签表示成的one<span class="token operator">-</span>hot向量，类型为numpy数组
<span class="token string">''</span>'
def <span class="token function">encode_onehot</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token operator">:</span>
    classes <span class="token operator">=</span> <span class="token function">set</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>  # <span class="token function">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 函数创建一个无序不重复元素集
    classes_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>c<span class="token operator">:</span> np<span class="token punctuation">.</span><span class="token function">identity</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token operator">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> c in  # identity创建方矩阵
                    <span class="token function">enumerate</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">}</span>     # 字典 key为label的值，value为矩阵的每一行
    <span class="token macro property"># enumerate函数用于将一个可遍历的数据对象组合为一个索引序列</span>
    labels_onehot <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span><span class="token function">list</span><span class="token punctuation">(</span><span class="token function">map</span><span class="token punctuation">(</span>classes_dict<span class="token punctuation">.</span>get<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  # get函数得到字典key对应的value
                             dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
    <span class="token keyword">return</span> labels_onehot
    <span class="token macro property"># map() 会根据提供的函数对指定序列做映射</span>
    # 第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表
    <span class="token macro property">#  map(lambda x: x ** 2, [1, 2, 3, 4, 5])</span>
    <span class="token macro property">#  output:[1, 4, 9, 16, 25]</span>

<span class="token macro property"># use skleran onehot encoder.</span>
def <span class="token function">onehot_label</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token operator">:</span>
    # 同样的现将非数值的label转换成数值型。
    classes <span class="token operator">=</span> <span class="token function">set</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    class_dir <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span>label in <span class="token function">enumerate</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token operator">:</span>
        class_dir<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token operator">=</span> index
    # 将标签转换成数字。
    new_labels <span class="token operator">=</span> <span class="token punctuation">[</span>class_dir<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token keyword">for</span> label in labels<span class="token punctuation">]</span>
    new_labels <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>new_labels<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> # 需要转换成二维，才可以使用onehot
    # 使用skleran的onehot方法。
    enc <span class="token operator">=</span> <span class="token function">OneHotEncoder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    enc<span class="token punctuation">.</span><span class="token function">fit</span><span class="token punctuation">(</span>new_labels<span class="token punctuation">)</span>
    onehot_labels <span class="token operator">=</span> enc<span class="token punctuation">.</span><span class="token function">transform</span><span class="token punctuation">(</span>new_labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toarray</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


    <span class="token keyword">return</span> onehot_labels

def <span class="token function">onehot_label2</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">''</span><span class="token string">' 其实也可以直接使用onehot应用'</span><span class="token string">''</span>
    <span class="token function">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span> # labels 的形状必须是一维的。
    labels <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    enc <span class="token operator">=</span> <span class="token function">OneHotEncoder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    enc<span class="token punctuation">.</span><span class="token function">fit</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    onehot_labels <span class="token operator">=</span> enc<span class="token punctuation">.</span><span class="token function">transform</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toarray</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> onehot_labels

def <span class="token function">onehotlabel3</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">" 使用 sklearn 的 label binarize 方法"</span><span class="token string">""</span>
    label_set <span class="token operator">=</span> <span class="token function">set</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    onehot_labels <span class="token operator">=</span> sklearn<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span><span class="token function">label_binarize</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> classes<span class="token operator">=</span><span class="token function">list</span><span class="token punctuation">(</span>label_set<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> onehot_labels




# 载入数据的函数
def <span class="token function">load_data</span><span class="token punctuation">(</span>path<span class="token operator">=</span><span class="token string">"../GNN_dataset/cora/"</span><span class="token punctuation">,</span> dataset<span class="token operator">=</span><span class="token string">"cora"</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"Load citation network dataset (cora only for now)"</span><span class="token string">""</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'Loading {} dataset...'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    idx_features_labels <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">genfromtxt</span><span class="token punctuation">(</span><span class="token string">"{}{}.content"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        dtype<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token function">dtype</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">)</span> # 数据文件：cora<span class="token punctuation">.</span>content
    <span class="token macro property"># array([['31336', '0', '0', ..., '0', '0', 'Neural_Networks'],</span>
    #        <span class="token punctuation">[</span><span class="token string">'1061127'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'Rule_Learning'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #        <span class="token punctuation">[</span><span class="token string">'1106406'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'Reinforcement_Learning'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
    #        <span class="token punctuation">[</span><span class="token string">'1128978'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'Genetic_Algorithms'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #        <span class="token punctuation">[</span><span class="token string">'117328'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'Case_Based'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #        <span class="token punctuation">[</span><span class="token string">'24043'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'Neural_Networks'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token macro property">#       dtype='&lt;U22')</span>
    # 可以看出，最后一列是标签，第一列是id，中间的是特征。
    features <span class="token operator">=</span> sp<span class="token punctuation">.</span><span class="token function">csr_matrix</span><span class="token punctuation">(</span>idx_features_labels<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  # 储存为csr型稀疏矩阵
    labels <span class="token operator">=</span> <span class="token function">encode_onehot</span><span class="token punctuation">(</span>idx_features_labels<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    #这里的label为onthot格式，如第一类代表<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token macro property"># content file的每一行的格式为 ： &lt;paper_id&gt; &lt;word_attributes&gt;+ &lt;class_label&gt;</span>
    #    分别对应 <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>
    <span class="token macro property"># feature为第二列到倒数第二列，labels为最后一列</span>

    <span class="token macro property"># build graph</span>
    <span class="token macro property"># cites file的每一行格式为：  &lt;cited paper ID&gt;  &lt;citing paper ID&gt;  cora.cites 文件。</span>
    # 根据前面的contents与这里的cites创建图，算出edges矩阵与adj 矩阵
    idx <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>idx_features_labels<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
    idx_map <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>j<span class="token operator">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> j in <span class="token function">enumerate</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">}</span>  # idx_to_sortindx
    edges_unordered <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">genfromtxt</span><span class="token punctuation">(</span><span class="token string">"{}{}.cites"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> # 第一列是被引，后边是引用，都是文章原始id
    # #<span class="token function">array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>     <span class="token number">35</span><span class="token punctuation">,</span>    <span class="token number">1033</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">[</span>     <span class="token number">35</span><span class="token punctuation">,</span>  <span class="token number">103482</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">[</span>     <span class="token number">35</span><span class="token punctuation">,</span>  <span class="token number">103515</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">[</span> <span class="token number">853118</span><span class="token punctuation">,</span> <span class="token number">1140289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">[</span> <span class="token number">853155</span><span class="token punctuation">,</span>  <span class="token number">853118</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    #    <span class="token punctuation">[</span> <span class="token number">954315</span><span class="token punctuation">,</span> <span class="token number">1155073</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token string">''</span>'# content 文件的特征是节点特征，个数就是整个图的结点数。标签为结点标签。
    <span class="token macro property"># cites 文件的引用和被引用关系，构成了图的邻接矩阵。'''</span>

    <span class="token macro property"># edges_unordered为直接从边表文件中直接读取的结果，是一个(edge_num, 2)的数组，每一行表示一条边两个端点的idx</span>
    edges <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span><span class="token function">list</span><span class="token punctuation">(</span><span class="token function">map</span><span class="token punctuation">(</span>idx_map<span class="token punctuation">.</span>get<span class="token punctuation">,</span> edges_unordered<span class="token punctuation">.</span><span class="token function">flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  # flatten：降维，返回一维数组
                     dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>edges_unordered<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    # 边的edges_unordered中存储的是端点id，要将每一项的id换成编号。
    # 在idx_map中以idx作为键查找得到对应节点的编号，reshape成与edges_unordered形状一样的数组
    adj <span class="token operator">=</span> sp<span class="token punctuation">.</span><span class="token function">coo_matrix</span><span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">ones</span><span class="token punctuation">(</span>edges<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edges<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  # coo型稀疏矩阵
                        shape<span class="token operator">=</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                        dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token string">''</span>'# coo_matrix <span class="token operator">:</span>  <span class="token function">coo_matrix</span><span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token punctuation">(</span>row<span class="token punctuation">,</span>cow<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token punctuation">,</span> dtype<span class="token punctuation">)</span>
    <span class="token macro property"># data,row,cow 数量相等。 ad  '''</span>
    # 根据coo矩阵性质，这一段的作用就是，网络有多少条边，邻接矩阵就有多少个<span class="token number">1</span>，
    # 所以先创建一个长度为edge_num的全<span class="token number">1</span>数组，每个<span class="token number">1</span>的填充位置就是一条边中两个端点的编号，
    # 即edges<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edges<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>，矩阵的形状为<span class="token punctuation">(</span>node_size<span class="token punctuation">,</span> node_size<span class="token punctuation">)</span>。


    <span class="token macro property"># build symmetric adjacency matrix   论文里A^=(D~)^0.5 A~ (D~)^0.5这个公式</span>
    adj <span class="token operator">=</span> adj <span class="token operator">+</span> adj<span class="token punctuation">.</span>T<span class="token punctuation">.</span><span class="token function">multiply</span><span class="token punctuation">(</span>adj<span class="token punctuation">.</span>T <span class="token operator">&gt;</span> adj<span class="token punctuation">)</span> <span class="token operator">-</span> adj<span class="token punctuation">.</span><span class="token function">multiply</span><span class="token punctuation">(</span>adj<span class="token punctuation">.</span>T <span class="token operator">&gt;</span> adj<span class="token punctuation">)</span>  # 这里可以看出为什么之后的lmax <span class="token operator">=</span><span class="token number">2</span> 了。


    # 对于无向图，邻接矩阵是对称的。上一步得到的adj是按有向图构建的，转换成无向图的邻接矩阵需要扩充成对称矩阵
    features <span class="token operator">=</span> <span class="token function">normalize</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span>
    adj <span class="token operator">=</span> <span class="token function">normalize</span><span class="token punctuation">(</span>adj <span class="token operator">+</span> sp<span class="token punctuation">.</span><span class="token function">eye</span><span class="token punctuation">(</span>adj<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   # eye创建单位矩阵，第一个参数为行数，第二个为列数
    # 对应公式A<span class="token operator">~</span><span class="token operator">=</span>A<span class="token operator">+</span>IN
    <span class="token string">''</span><span class="token string">' 至此，图和节点的特征就创建完成'</span><span class="token string">''</span>

    # 分别构建训练集、验证集、测试集，并创建特征矩阵、标签向量和邻接矩阵的tensor，用来做模型的输入
    idx_train <span class="token operator">=</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">140</span><span class="token punctuation">)</span>
    idx_val <span class="token operator">=</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span>
    idx_test <span class="token operator">=</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">1500</span><span class="token punctuation">)</span>

    features <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">FloatTensor</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>features<span class="token punctuation">.</span><span class="token function">todense</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  # tensor为pytorch常用的数据结构
    labels <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">LongTensor</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">where</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    #这里将onthot label转回index
    adj <span class="token operator">=</span> <span class="token function">sparse_mx_to_torch_sparse_tensor</span><span class="token punctuation">(</span>adj<span class="token punctuation">)</span>   # 邻接矩阵转为tensor处理

    idx_train <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">LongTensor</span><span class="token punctuation">(</span>idx_train<span class="token punctuation">)</span>
    idx_val <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">LongTensor</span><span class="token punctuation">(</span>idx_val<span class="token punctuation">)</span>
    idx_test <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">LongTensor</span><span class="token punctuation">(</span>idx_test<span class="token punctuation">)</span>

    <span class="token keyword">return</span> adj<span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> idx_train<span class="token punctuation">,</span> idx_val<span class="token punctuation">,</span> idx_test

def <span class="token function">normalize</span><span class="token punctuation">(</span>mx<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"Row-normalize sparse matrix"</span><span class="token string">""</span>
    rowsum <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>mx<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  # 对每一行求和
    r_inv <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">power</span><span class="token punctuation">(</span>rowsum<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 求倒数
    r_inv<span class="token punctuation">[</span>np<span class="token punctuation">.</span><span class="token function">isinf</span><span class="token punctuation">(</span>r_inv<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.</span>  # 如果某一行全为<span class="token number">0</span>，则r_inv算出来会等于无穷大，将这些行的r_inv置为<span class="token number">0</span>
    r_mat_inv <span class="token operator">=</span> sp<span class="token punctuation">.</span><span class="token function">diags</span><span class="token punctuation">(</span>r_inv<span class="token punctuation">)</span>  # 构建对角元素为r_inv的对角矩阵
    mx <span class="token operator">=</span> r_mat_inv<span class="token punctuation">.</span><span class="token function">dot</span><span class="token punctuation">(</span>mx<span class="token punctuation">)</span>
    # 用对角矩阵与原始矩阵的点积起到标准化的作用，原始矩阵中每一行元素都会与对应的r_inv相乘，最终相当于除以了sum
    <span class="token keyword">return</span> mx

def <span class="token function">accuracy</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token operator">:</span>
    preds <span class="token operator">=</span> output<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">type_as</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span> # 使用<span class="token function">type_as</span><span class="token punctuation">(</span>tesnor<span class="token punctuation">)</span>将张量转换为给定类型的张量。
    correct <span class="token operator">=</span> preds<span class="token punctuation">.</span><span class="token function">eq</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token keyword">double</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 记录等于preds的label eq<span class="token operator">:</span>equal
    correct <span class="token operator">=</span> correct<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> correct <span class="token operator">/</span> <span class="token function">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>


def <span class="token function">sparse_mx_to_torch_sparse_tensor</span><span class="token punctuation">(</span>sparse_mx<span class="token punctuation">)</span><span class="token operator">:</span>    # 把一个sparse matrix转为torch稀疏张量
    <span class="token string">""</span>"
    numpy中的ndarray转化成pytorch中的tensor <span class="token operator">:</span> torch<span class="token punctuation">.</span><span class="token function">from_numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    pytorch中的tensor转化成numpy中的ndarray <span class="token operator">:</span> <span class="token function">numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token string">""</span>"
    sparse_mx <span class="token operator">=</span> sparse_mx<span class="token punctuation">.</span><span class="token function">tocoo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">from_numpy</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">vstack</span><span class="token punctuation">(</span><span class="token punctuation">(</span>sparse_mx<span class="token punctuation">.</span>row<span class="token punctuation">,</span> sparse_mx<span class="token punctuation">.</span>col<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">)</span>
    # 不懂的可以去看看COO性稀疏矩阵的结构
    values <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">from_numpy</span><span class="token punctuation">(</span>sparse_mx<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    shape <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">Size</span><span class="token punctuation">(</span>sparse_mx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">FloatTensor</span><span class="token punctuation">(</span>indices<span class="token punctuation">,</span> values<span class="token punctuation">,</span> shape<span class="token punctuation">)</span>


</code></pre> 
<p>GCN layer :</p> 
<pre><code class="prism language-cpp"># <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> coding<span class="token operator">:</span> utf<span class="token operator">-</span><span class="token number">8</span> <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> 

<span class="token macro property"># time : 2021/4/20 17:00</span>
<span class="token macro property"># task: </span>
import math

import torch

from torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parameter import Parameter
from torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>module import Module


<span class="token keyword">class</span> <span class="token class-name">GraphConvolution</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>

    # 初始化层：输入feature，输出feature，权重，偏移
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token function">super</span><span class="token punctuation">(</span>GraphConvolution<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_features <span class="token operator">=</span> in_features
        self<span class="token punctuation">.</span>out_features <span class="token operator">=</span> out_features
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> <span class="token function">Parameter</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token function">FloatTensor</span><span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">)</span><span class="token punctuation">)</span>  # FloatTensor建立tensor
        # 常见用法self<span class="token punctuation">.</span>v <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">Parameter</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token function">FloatTensor</span><span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>：
        # 首先可以把这个函数理解为类型转换函数，将一个不可训练的类型Tensor转换成可以训练的类型parameter并将这个parameter
        # 绑定到这个module里面，所以经过类型转换这个self<span class="token punctuation">.</span>v变成了模型的一部分，成为了模型中根据训练可以改动的参数了。
        # 使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。
        <span class="token keyword">if</span> bias<span class="token operator">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> <span class="token function">Parameter</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token function">FloatTensor</span><span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token operator">:</span>
            self<span class="token punctuation">.</span><span class="token function">register_parameter</span><span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>
            <span class="token macro property"># Parameters与register_parameter都会向parameters写入参数，但是后者可以支持字符串命名</span>
        self<span class="token punctuation">.</span><span class="token function">reset_parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span> # 定义权重后还需要初始化权重。

    # 初始化权重
    def <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">:</span>
        stdv <span class="token operator">=</span> <span class="token number">1.</span> <span class="token operator">/</span> math<span class="token punctuation">.</span><span class="token function">sqrt</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token macro property"># size()函数主要是用来统计矩阵元素个数，或矩阵某一维上的元素个数的函数  size（1）为行</span>
        self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span><span class="token function">uniform_</span><span class="token punctuation">(</span><span class="token operator">-</span>stdv<span class="token punctuation">,</span> stdv<span class="token punctuation">)</span>  # <span class="token function">uniform</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 方法将随机生成下一个实数，它在 <span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span> 范围内
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>bias is <span class="token operator">not</span> None<span class="token operator">:</span>
            self<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span><span class="token function">uniform_</span><span class="token punctuation">(</span><span class="token operator">-</span>stdv<span class="token punctuation">,</span> stdv<span class="token punctuation">)</span>  # 类似凯明初始化。

    <span class="token string">''</span>'
    前馈运算 即计算A<span class="token operator">~</span> X <span class="token function">W</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    input X与权重W相乘，然后adj矩阵与他们的积稀疏乘
    直接输入与权重之间进行torch<span class="token punctuation">.</span>mm操作，得到support，即XW
    support与adj进行torch<span class="token punctuation">.</span>spmm操作，得到output，即AXW选择是否加bias
    <span class="token string">''</span>'
    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> adj<span class="token punctuation">)</span><span class="token operator">:</span>
        support <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">mm</span><span class="token punctuation">(</span>input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token macro property"># torch.mm(a, b)是矩阵a和b矩阵相乘，torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">spmm</span><span class="token punctuation">(</span>adj<span class="token punctuation">,</span> support<span class="token punctuation">)</span>
        <span class="token macro property"># output = torch.smm(adj,support)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>bias is <span class="token operator">not</span> None<span class="token operator">:</span>
            <span class="token keyword">return</span> output <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
        <span class="token keyword">else</span><span class="token operator">:</span>
            <span class="token keyword">return</span> output
#通过设置断点，可以看出output的形式是<span class="token number">0.01</span>，<span class="token number">0.01</span>，<span class="token number">0.01</span>，<span class="token number">0.01</span>，<span class="token number">0.01</span>，#<span class="token number">0.01</span>，<span class="token number">0.94</span><span class="token punctuation">]</span>，里面的值代表该x对应标签不同的概率，故此值可转换为#<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>，对应我们之前把标签onthot后的第七种标签

    def <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__ <span class="token operator">+</span> <span class="token string">' ('</span> \
               <span class="token operator">+</span> <span class="token function">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_features<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' -&gt; '</span> \
               <span class="token operator">+</span> <span class="token function">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_features<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">')'</span>


</code></pre> 
<p>models:</p> 
<pre><code class="prism language-cpp"># <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> coding<span class="token operator">:</span> utf<span class="token operator">-</span><span class="token number">8</span> <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> 

<span class="token macro property"># time : 2021/4/20 17:01</span>
<span class="token macro property"># task: </span>
import torch<span class="token punctuation">.</span>nn as nn
import torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional as F
from layer import GraphConvolution


<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nfeat<span class="token punctuation">,</span> nhid<span class="token punctuation">,</span> nclass<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token operator">:</span>  # 底层节点的参数，feature的个数；隐层节点个数；最终的分类数
        <span class="token function">super</span><span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  #  <span class="token function">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">_init_</span><span class="token punctuation">(</span><span class="token punctuation">)</span>在利用父类里的对象构造函数

        self<span class="token punctuation">.</span>gc1 <span class="token operator">=</span> <span class="token function">GraphConvolution</span><span class="token punctuation">(</span>nfeat<span class="token punctuation">,</span> nhid<span class="token punctuation">)</span>   # gc1输入尺寸nfeat，输出尺寸nhid
        self<span class="token punctuation">.</span>gc2 <span class="token operator">=</span> <span class="token function">GraphConvolution</span><span class="token punctuation">(</span>nhid<span class="token punctuation">,</span> nclass<span class="token punctuation">)</span>  # gc2输入尺寸nhid，输出尺寸ncalss
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout

    # 输入分别是特征和邻接矩阵。最后输出为输出层做log_softmax变换的结果
    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> adj<span class="token punctuation">)</span><span class="token operator">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token function">relu</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token function">gc1</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> adj<span class="token punctuation">)</span><span class="token punctuation">)</span>    # adj即公式Z<span class="token operator">=</span><span class="token function">softmax</span><span class="token punctuation">(</span>A<span class="token operator">~</span><span class="token function">Relu</span><span class="token punctuation">(</span>A<span class="token operator">~</span><span class="token function">XW</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token function">W</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>中的A<span class="token operator">~</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token function">dropout</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>  # x要dropout
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">gc2</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> adj<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span><span class="token function">log_softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> # 打分。batchsize<span class="token punctuation">,</span>inchannels<span class="token punctuation">,</span>outchannels 。


</code></pre> 
<p>train :</p> 
<pre><code class="prism language-cpp"># <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> coding<span class="token operator">:</span> utf<span class="token operator">-</span><span class="token number">8</span> <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> 

<span class="token macro property"># time : 2021/4/20 16:59</span>
<span class="token macro property"># task: </span>
from __future__ import division
from __future__ import print_function

import time
import argparse  # argparse 是python自带的命令行参数解析包，可以用来方便地读取命令行参数
import numpy as np

import torch
import torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional as F
import torch<span class="token punctuation">.</span>optim as optim

from utils import load_data<span class="token punctuation">,</span> accuracy
from models import GCN

<span class="token macro property"># Training settings</span>
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span><span class="token function">ArgumentParser</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--no-cuda'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span>True<span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Disables CUDA training.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--fastmode'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span>False<span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Validate during training pass.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--seed'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'Random seed.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Number of epochs to train.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">float</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Initial learning rate.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--weight_decay'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">float</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">5e-4</span><span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Weight decay (L2 loss on parameters).'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--hidden'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Number of hidden units.'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span><span class="token function">add_argument</span><span class="token punctuation">(</span><span class="token string">'--dropout'</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token keyword">float</span><span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>
                    help<span class="token operator">=</span><span class="token string">'Dropout rate (1 - keep probability).'</span><span class="token punctuation">)</span>

# 如果程序不禁止使用gpu且当前主机的gpu可用，arg<span class="token punctuation">.</span>cuda就为True
args <span class="token operator">=</span> parser<span class="token punctuation">.</span><span class="token function">parse_args</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
args<span class="token punctuation">.</span>cuda <span class="token operator">=</span> <span class="token operator">not</span> args<span class="token punctuation">.</span>no_cuda <span class="token operator">and</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span><span class="token function">is_available</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">seed</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>seed<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span><span class="token function">manual_seed</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>seed<span class="token punctuation">)</span>   # 为CPU设置种子用于生成随机数，以使得结果是确定的
<span class="token keyword">if</span> args<span class="token punctuation">.</span>cuda<span class="token operator">:</span>
    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span><span class="token function">manual_seed</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>seed<span class="token punctuation">)</span>

<span class="token macro property"># Load data</span>
adj<span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> idx_train<span class="token punctuation">,</span> idx_val<span class="token punctuation">,</span> idx_test <span class="token operator">=</span> <span class="token function">load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token macro property"># Model and optimizer</span>
model <span class="token operator">=</span> <span class="token function">GCN</span><span class="token punctuation">(</span>nfeat<span class="token operator">=</span>features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            nhid<span class="token operator">=</span>args<span class="token punctuation">.</span>hidden<span class="token punctuation">,</span>
            nclass<span class="token operator">=</span>labels<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
            dropout<span class="token operator">=</span>args<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span><span class="token function">Adam</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span><span class="token function">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>args<span class="token punctuation">.</span>weight_decay<span class="token punctuation">)</span>

# 数据写入cuda，便于后续加速
<span class="token keyword">if</span> args<span class="token punctuation">.</span>cuda<span class="token operator">:</span>
    model<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   # <span class="token punctuation">.</span> <span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>会分配到显存里（如果gpu可用）
    features <span class="token operator">=</span> features<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    adj <span class="token operator">=</span> adj<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> labels<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    idx_train <span class="token operator">=</span> idx_train<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    idx_val <span class="token operator">=</span> idx_val<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    idx_test <span class="token operator">=</span> idx_test<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

def <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token operator">:</span>
    t <span class="token operator">=</span> time<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 返回当前时间
    model<span class="token punctuation">.</span><span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span><span class="token function">zero_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token macro property"># optimizer.zero_grad()意思是把梯度置零，也就是把loss关于weight的导数变成0.</span>
    <span class="token macro property"># pytorch中每一轮batch需要设置optimizer.zero_gra</span>
    output <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> adj<span class="token punctuation">)</span>
    loss_train <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token function">nll_loss</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_train<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_train<span class="token punctuation">]</span><span class="token punctuation">)</span>
    # 由于在算output时已经使用了log_softmax，这里使用的损失函数就是NLLloss，如果前面没有加log运算，
    # 这里就要使用CrossEntropyLoss了
    # 损失函数<span class="token function">NLLLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 的输入是一个对数概率向量和一个目标标签<span class="token punctuation">.</span> 它不会为我们计算对数概率，
    # 适合最后一层是<span class="token function">log_softmax</span><span class="token punctuation">(</span><span class="token punctuation">)</span>的网络<span class="token punctuation">.</span> 损失函数 <span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 与 <span class="token function">NLLLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 类似<span class="token punctuation">,</span>
    # 唯一的不同是它为我们去做 softmax<span class="token punctuation">.</span>可以理解为：<span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">=</span><span class="token function">log_softmax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">NLLLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token macro property"># https://blog.csdn.net/hao5335156/article/details/80607732</span>
    acc_train <span class="token operator">=</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_train<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_train<span class="token punctuation">]</span><span class="token punctuation">)</span>  #计算准确率
    loss_train<span class="token punctuation">.</span><span class="token function">backward</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 反向求导  Back Propagation
    optimizer<span class="token punctuation">.</span><span class="token function">step</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 更新所有的参数  Gradient Descent

    <span class="token keyword">if</span> <span class="token operator">not</span> args<span class="token punctuation">.</span>fastmode<span class="token operator">:</span>
        <span class="token macro property"># Evaluate validation set performance separately,</span>
        <span class="token macro property"># deactivates dropout during validation run.</span>
        model<span class="token punctuation">.</span><span class="token function">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # <span class="token function">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 函数用来执行一个字符串表达式，并返回表达式的值
        output <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> adj<span class="token punctuation">)</span>

    loss_val <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token function">nll_loss</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_val<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_val<span class="token punctuation">]</span><span class="token punctuation">)</span>    # 验证集的损失函数
    acc_val <span class="token operator">=</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_val<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_val<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: {:04d}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'loss_train: {:.4f}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>loss_train<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'acc_train: {:.4f}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>acc_train<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'loss_val: {:.4f}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>loss_val<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'acc_val: {:.4f}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>acc_val<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'time: {:.4f}s'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t<span class="token punctuation">)</span><span class="token punctuation">)</span>

# 定义测试函数，相当于对已有的模型在测试集上运行对应的loss与accuracy
def <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    model<span class="token punctuation">.</span><span class="token function">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> adj<span class="token punctuation">)</span>
    loss_test <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token function">nll_loss</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_test<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_test<span class="token punctuation">]</span><span class="token punctuation">)</span>
    acc_test <span class="token operator">=</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span>idx_test<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>idx_test<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"Test set results:"</span><span class="token punctuation">,</span>
          <span class="token string">"loss= {:.4f}"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>loss_test<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">"accuracy= {:.4f}"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>acc_test<span class="token punctuation">.</span><span class="token function">item</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token macro property"># Train model  逐个epoch进行train，最后test</span>
t_total <span class="token operator">=</span> time<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch in <span class="token function">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"Optimization Finished!"</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"Total time elapsed: {:.4f}s"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t_total<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/676fed4bfeaca4a63c71df8be82ad3f3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">笔记-微信订阅号开发</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/07e33a16d72e5e823a2e62aac6dd1310/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring--aop--02--纯注解实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>