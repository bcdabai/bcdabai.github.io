<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于keras_bert使用CNN、LSTM、BiLSTM进行文本分类 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于keras_bert使用CNN、LSTM、BiLSTM进行文本分类" />
<meta property="og:description" content="数据集：数据集
选择了其中的10个类别
##train.py &#39;&#39;&#39; 导入所需要的库 &#39;&#39;&#39; from keras_bert import load_trained_model_from_checkpoint, Tokenizer from keras.layers import Input, Dense, LSTM, Conv1D, Concatenate,MaxPool1D,Flatten,Dropout,GlobalMaxPooling1D,Bidirectional,Lambda from keras.models import Model from keras.optimizers import Adam,RMSprop from keras.utils.np_utils import to_categorical import codecs import numpy as np from random import shuffle from sklearn.preprocessing import LabelEncoder from keras.preprocessing import sequence from keras.engine import Layer from keras.callbacks import * &#39;&#39;&#39; bert相关文件路径 &#39;&#39;&#39; maxlen = 128 # config_path = &#34;chinese_L-12_H-768_A-12\\bert_config.json&#34; checkpoint_path = &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/39087f076cd165950aadff75aac89bc1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-10T18:16:48+08:00" />
<meta property="article:modified_time" content="2021-03-10T18:16:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于keras_bert使用CNN、LSTM、BiLSTM进行文本分类</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>数据集：<a href="http://thuctc.thunlp.org/#%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86THUCNews" rel="nofollow">数据集</a><br> 选择了其中的10个类别</p> 
<pre><code class="prism language-python"><span class="token comment">##train.py</span>
<span class="token triple-quoted-string string">'''
导入所需要的库
'''</span>
<span class="token keyword">from</span> keras_bert <span class="token keyword">import</span> load_trained_model_from_checkpoint<span class="token punctuation">,</span> Tokenizer
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> LSTM<span class="token punctuation">,</span> Conv1D<span class="token punctuation">,</span> Concatenate<span class="token punctuation">,</span>MaxPool1D<span class="token punctuation">,</span>Flatten<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>GlobalMaxPooling1D<span class="token punctuation">,</span>Bidirectional<span class="token punctuation">,</span>Lambda
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token punctuation">,</span>RMSprop
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>np_utils <span class="token keyword">import</span> to_categorical
<span class="token keyword">import</span> codecs
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> random <span class="token keyword">import</span> shuffle
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>engine <span class="token keyword">import</span> Layer
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> <span class="token operator">*</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''
bert相关文件路径
'''</span>
maxlen <span class="token operator">=</span> <span class="token number">128</span> <span class="token comment">#</span>
config_path <span class="token operator">=</span> <span class="token string">"chinese_L-12_H-768_A-12\\bert_config.json"</span>
checkpoint_path <span class="token operator">=</span> <span class="token string">"chinese_L-12_H-768_A-12\\bert_model.ckpt"</span>
dict_path <span class="token operator">=</span> <span class="token string">"chinese_L-12_H-768_A-12\\vocab.txt"</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># Tokenizer分词后句子首位会分别加上 [CLS] 和 [SEP] 标记，</span>
<span class="token comment"># 其中 [CLS] 位置对应的输出向量是能代表整句的句向量，</span>
<span class="token comment"># 而 [SEP] 则是句间的分隔符，其余部分则是单字输出（对于中文来说）</span>
<span class="token comment"># 重写Tokenizer的 _tokenize 方法是要保证 tokenize 之后的结果，</span>
<span class="token comment"># 跟原来的字符串长度等长（如果算上两个标记，那么就是等长再加 2）。 </span>
<span class="token comment"># Tokenizer 自带的 _tokenize 会自动去掉空格，然后有些字符会粘在一块输出，</span>
<span class="token comment"># 导致 tokenize 之后的列表不等于原来字符串的长度了，这样如果做序列标注的任务会很麻烦。</span>
<span class="token comment"># [unused*] 这些标记是未经训练的（随即初始化），</span>
<span class="token comment"># 是 Bert 预留出来用来增量添加词汇的标记，所以我们可以用它们来指代任何新字符。</span>
<span class="token keyword">class</span> <span class="token class-name">OurTokenizer</span><span class="token punctuation">(</span>Tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">def</span> <span class="token function">_tokenize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>
		R <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
		<span class="token keyword">for</span> c <span class="token keyword">in</span> text<span class="token punctuation">:</span>
			<span class="token keyword">if</span> c <span class="token keyword">in</span> self<span class="token punctuation">.</span>_token_dict<span class="token punctuation">:</span>
				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
			<span class="token keyword">elif</span> self<span class="token punctuation">.</span>_is_space<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">:</span>
				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'[unused1]'</span><span class="token punctuation">)</span> <span class="token comment"># 用[unused1]来表示空格类字符</span>
			<span class="token keyword">else</span><span class="token punctuation">:</span>
				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'[UNK]'</span><span class="token punctuation">)</span> <span class="token comment"># 剩余的字符是[UNK]</span>
		<span class="token keyword">return</span> R
<span class="token triple-quoted-string string">'''
:param: dict_path: 是bert模型的vocab.txt文件
:return:将文件中字进行编码
'''</span>
<span class="token keyword">def</span> <span class="token function">get_token_dict</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"获取编码字典"</span><span class="token punctuation">)</span>
    token_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> codecs<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> reader<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> reader<span class="token punctuation">:</span>
            token <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            token_dict<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_dict<span class="token punctuation">)</span>
    <span class="token keyword">return</span> token_dict
</code></pre> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''
# 读取数据的函数
# :return: list  类型的 数据
'''</span>        
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span>datatype<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"读取"</span><span class="token operator">+</span>datatype<span class="token operator">+</span><span class="token string">"数据"</span><span class="token punctuation">)</span>
    path <span class="token operator">=</span> <span class="token string">'data\\cnews.'</span> <span class="token operator">+</span>datatype <span class="token operator">+</span> <span class="token string">'.txt'</span>
    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    
    <span class="token keyword">with</span> codecs<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> reader<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> reader<span class="token punctuation">:</span>
            all_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    
    <span class="token keyword">return</span> all_data
<span class="token comment"># 获取标签</span>
<span class="token keyword">def</span> <span class="token function">readLable</span><span class="token punctuation">(</span>datatype<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"读取"</span><span class="token operator">+</span>datatype<span class="token operator">+</span><span class="token string">"标签"</span><span class="token punctuation">)</span>
    path <span class="token operator">=</span> <span class="token string">'data\\cnews.'</span> <span class="token operator">+</span>datatype <span class="token operator">+</span> <span class="token string">'.txt'</span>
    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    
    <span class="token keyword">with</span> codecs<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> reader<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> reader<span class="token punctuation">:</span>
            all_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    
    <span class="token keyword">return</span> all_data
<span class="token comment">#将标签编码 ##此时还不是one—hot形式</span>
<span class="token keyword">def</span> <span class="token function">encodeLable</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>   
    le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    resultLable <span class="token operator">=</span> le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>    
    <span class="token keyword">return</span> resultLable
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 让每条文本的长度相同，用0填充</span>
<span class="token keyword">def</span> <span class="token function">seq_padding</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	L <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> X<span class="token punctuation">]</span>
	ML <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
	<span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
		np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>padding<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>ML <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">&lt;</span> ML <span class="token keyword">else</span> x <span class="token keyword">for</span> x <span class="token keyword">in</span> X
	<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">##数据生成器</span>
<span class="token keyword">class</span> <span class="token class-name">data_generator</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer        <span class="token comment"># print(self.tokenizer)</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size        
        self<span class="token punctuation">.</span>steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>batch_size
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>batch_size <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>steps <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>steps
    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            idxs <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
            X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> idxs<span class="token punctuation">:</span>
                d <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                text <span class="token operator">=</span> d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>maxlen<span class="token punctuation">]</span>
                x1<span class="token punctuation">,</span> x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>first<span class="token operator">=</span>text<span class="token punctuation">)</span>
                y <span class="token operator">=</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                X1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
                X2<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
                Y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                
                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X1<span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>batch_size <span class="token operator">or</span> i <span class="token operator">==</span> idxs<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                	X1 <span class="token operator">=</span> seq_padding<span class="token punctuation">(</span>X1<span class="token punctuation">)</span>
                	X2 <span class="token operator">=</span> seq_padding<span class="token punctuation">(</span>X2<span class="token punctuation">)</span>
                	Y <span class="token operator">=</span> seq_padding<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
                	<span class="token keyword">yield</span> <span class="token punctuation">[</span>X1<span class="token punctuation">,</span> X2<span class="token punctuation">]</span><span class="token punctuation">,</span> Y    
                	X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                    <span class="token comment">#### yield构造一个生成器，相当于return </span>
                    <span class="token comment">#### 执行到 yield语句时发生了程序中断，</span>
                    <span class="token comment">### 下一次调用从上一次中断的地方继续执行下去</span>
</code></pre> 
<p>单BERT模型</p> 
<pre><code class="prism language-python"><span class="token comment"># x[:,n]表示在全部数组（维）中取第n个数据，直观来说，x[:,n]就是取所有集合的第n个数据, </span>
<span class="token keyword">def</span> <span class="token function">build_model_BERT_Only</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    bert_model <span class="token operator">=</span> load_trained_model_from_checkpoint<span class="token punctuation">(</span>config_path<span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">,</span> seq_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> l <span class="token keyword">in</span> bert_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        l<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
    x1_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x2_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> bert_model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">)</span> 
    cls_layer <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment">## 取出[CLS]对应的向量用来做分类,[cls]能代表整句话在经过token后</span>
    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>cls_layer<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
        loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>
        optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
<p>BERT接LSTM</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_model_LSTM</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    bert_model <span class="token operator">=</span> load_trained_model_from_checkpoint<span class="token punctuation">(</span>config_path<span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">,</span> seq_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> l <span class="token keyword">in</span> bert_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        l<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
    x1_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x2_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"加载bert模型"</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> bert_model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token comment"># cls_layer = Lambda(lambda x: x[:, 0])(x) ## 取出[CLS]对应的向量用来做分类</span>
    T <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
    T <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span>
    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
        loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>
        optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
<p>BERT接BiLSTM</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_model_BiLSTM</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    bert_model <span class="token operator">=</span> load_trained_model_from_checkpoint<span class="token punctuation">(</span>config_path<span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">,</span> seq_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> l <span class="token keyword">in</span> bert_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        l<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
    x1_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x2_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> bert_model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">)</span>
    T <span class="token operator">=</span> Bidirectional<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
    T <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span>
    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
        loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>
        optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
<p>BERT接CNN</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_model_CNN</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    bert_model <span class="token operator">=</span> load_trained_model_from_checkpoint<span class="token punctuation">(</span>config_path<span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">,</span> seq_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> l <span class="token keyword">in</span> bert_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        l<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
    x1_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x2_in <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> bert_model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">)</span>
    c <span class="token operator">=</span> Conv1D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
    c <span class="token operator">=</span> GlobalMaxPooling1D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    c <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>  
    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">[</span>x1_in<span class="token punctuation">,</span> x2_in<span class="token punctuation">]</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
        loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>
        optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
<p>训练</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>allTrainData<span class="token punctuation">,</span> allValData<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span>modelName<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> modelName <span class="token operator">==</span> <span class="token string">'LSTM'</span><span class="token punctuation">:</span>
        model <span class="token operator">=</span> build_model_LSTM<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> modelName <span class="token operator">==</span> <span class="token string">'CNN'</span><span class="token punctuation">:</span>
        model <span class="token operator">=</span> build_model_CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> modelName <span class="token operator">==</span> <span class="token string">'BiLSTM'</span><span class="token punctuation">:</span>
        model <span class="token operator">=</span> build_model_BiLSTM<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    <span class="token keyword">else</span><span class="token punctuation">:</span> 
        model <span class="token operator">=</span> build_model_BERT_Only<span class="token punctuation">(</span><span class="token punctuation">)</span>   
    filepath<span class="token operator">=</span><span class="token string">'1\\'</span><span class="token operator">+</span><span class="token string">'BertNoTrain_'</span><span class="token operator">+</span> modelName<span class="token operator">+</span><span class="token string">'_{epoch:02d}-{accuracy:.4f}-{val_accuracy:.4f}.h5'</span>
    early_stopping <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 早停法，防止过拟合</span>
    plateau <span class="token operator">=</span> ReduceLROnPlateau<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> factor<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>
                                patience<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 当评价指标不在提升时，减少学习率</span>
    checkpoint <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                     save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span> save_weights_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 保存最好的模型</span>
    train_D <span class="token operator">=</span> data_generator<span class="token punctuation">(</span> allTrainData<span class="token punctuation">,</span>tokenizer<span class="token punctuation">)</span>
    valid_D <span class="token operator">=</span> data_generator<span class="token punctuation">(</span>allValData<span class="token punctuation">,</span>tokenizer<span class="token punctuation">)</span>
    history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>
        train_D<span class="token punctuation">.</span>__iter__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        steps_per_epoch<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_D<span class="token punctuation">)</span><span class="token punctuation">,</span>
        epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        validation_data<span class="token operator">=</span>valid_D<span class="token punctuation">.</span>__iter__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        validation_steps<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_D<span class="token punctuation">)</span><span class="token punctuation">,</span>
        callbacks<span class="token operator">=</span><span class="token punctuation">[</span>early_stopping<span class="token punctuation">,</span> plateau<span class="token punctuation">,</span> checkpoint<span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>save_weights<span class="token punctuation">(</span><span class="token string">'\keras_bert_'</span><span class="token operator">+</span> modelName<span class="token operator">+</span><span class="token string">'.h5'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> history
</code></pre> 
<p>主函数</p> 
<pre><code class="prism language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span> 
    token_dict <span class="token operator">=</span> get_token_dict<span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span>  
    tokenizer <span class="token operator">=</span> OurTokenizer<span class="token punctuation">(</span>token_dict<span class="token punctuation">)</span>
    trainlable <span class="token operator">=</span> encodeLable<span class="token punctuation">(</span>readLable<span class="token punctuation">(</span><span class="token string">"trains"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">##获取标签编码</span>
    <span class="token comment">##将标签进行one—hot编码</span>
    trainCate <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>trainlable<span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
    traindata <span class="token operator">=</span> get_data<span class="token punctuation">(</span><span class="token string">"trains"</span><span class="token punctuation">)</span>   
    allTrainData <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>traindata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        allTrainData<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>i<span class="token punctuation">,</span><span class="token punctuation">(</span>traindata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>trainCate<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 获取验证数据     </span>
    vallable <span class="token operator">=</span> encodeLable<span class="token punctuation">(</span>readLable<span class="token punctuation">(</span><span class="token string">"vals"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">##获取标签编码</span>
    valCate <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>vallable<span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> 
    valdata <span class="token operator">=</span> get_data<span class="token punctuation">(</span><span class="token string">"vals"</span><span class="token punctuation">)</span>
    allValData <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>valdata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        allValData<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>i<span class="token punctuation">,</span><span class="token punctuation">(</span>valdata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>valCate<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      
   
    train_model<span class="token punctuation">(</span>allTrainData<span class="token punctuation">,</span> allValData<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span><span class="token string">"LSTM"</span><span class="token punctuation">)</span>
    train_model<span class="token punctuation">(</span>allTrainData<span class="token punctuation">,</span> allValData<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span><span class="token string">"CNN"</span><span class="token punctuation">)</span>
    train_model<span class="token punctuation">(</span>allTrainData<span class="token punctuation">,</span> allValData<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span><span class="token string">"BiLSTM"</span><span class="token punctuation">)</span>
    train_model<span class="token punctuation">(</span>allTrainData<span class="token punctuation">,</span> allValData<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span><span class="token string">"BERT"</span><span class="token punctuation">)</span>
</code></pre> 
<p>预测predict.py</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> load_model
<span class="token keyword">from</span> keras_bert <span class="token keyword">import</span> get_custom_objects
<span class="token keyword">from</span> keras_bert <span class="token keyword">import</span> load_trained_model_from_checkpoint<span class="token punctuation">,</span> Tokenizer
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>np_utils <span class="token keyword">import</span> to_categorical
<span class="token keyword">import</span> codecs
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
<span class="token keyword">import</span> train <span class="token keyword">as</span> BL <span class="token comment">##导入train.py</span>

<span class="token keyword">def</span> <span class="token function">BertModelPridect</span><span class="token punctuation">(</span>modelName<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dict_path <span class="token operator">=</span> <span class="token string">"chinese_L-12_H-768_A-12\\vocab.txt"</span>
    <span class="token keyword">def</span> <span class="token function">get_token_dict</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"获取编码字典"</span><span class="token punctuation">)</span>
        token_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> reader<span class="token punctuation">:</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> reader<span class="token punctuation">:</span>
                token <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                token_dict<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_dict<span class="token punctuation">)</span>
        <span class="token keyword">return</span> token_dict
    <span class="token keyword">class</span> <span class="token class-name">OurTokenizer</span><span class="token punctuation">(</span>Tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    	<span class="token keyword">def</span> <span class="token function">_tokenize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    		R <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    		<span class="token keyword">for</span> c <span class="token keyword">in</span> text<span class="token punctuation">:</span>
    			<span class="token keyword">if</span> c <span class="token keyword">in</span> self<span class="token punctuation">.</span>_token_dict<span class="token punctuation">:</span>
    				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    			<span class="token keyword">elif</span> self<span class="token punctuation">.</span>_is_space<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">:</span>
    				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'[unused1]'</span><span class="token punctuation">)</span> <span class="token comment"># 用[unused1]来表示空格类字符</span>
    			<span class="token keyword">else</span><span class="token punctuation">:</span>
    				R<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'[UNK]'</span><span class="token punctuation">)</span> <span class="token comment"># 剩余的字符是[UNK]</span>
    		<span class="token keyword">return</span> R
    token_dict <span class="token operator">=</span> get_token_dict<span class="token punctuation">(</span>dict_path<span class="token punctuation">)</span>
    tokenizer <span class="token operator">=</span> OurTokenizer<span class="token punctuation">(</span>token_dict<span class="token punctuation">)</span>  
    <span class="token comment"># # 获取预测数据 1000</span>
    testlable <span class="token operator">=</span> BL<span class="token punctuation">.</span>encodeLable<span class="token punctuation">(</span>BL<span class="token punctuation">.</span>readLable<span class="token punctuation">(</span><span class="token string">"tests"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">##获取标签编码</span>
    valCate <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> 
    testdata <span class="token operator">=</span> BL<span class="token punctuation">.</span>get_data<span class="token punctuation">(</span><span class="token string">"tests"</span><span class="token punctuation">)</span>
    <span class="token comment">#构造预测数据输入到模型中的格式</span>
    allTestData <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>testdata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        allTestData<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>i<span class="token punctuation">,</span><span class="token punctuation">(</span>testdata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>valCate<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># print(len(allTestData))</span>
    test_D <span class="token operator">=</span> BL<span class="token punctuation">.</span>data_generator<span class="token punctuation">(</span> allTestData<span class="token punctuation">,</span>tokenizer<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"加载训练"</span><span class="token operator">+</span>modelName<span class="token operator">+</span><span class="token string">"好的模型"</span><span class="token punctuation">)</span> 
    basePath <span class="token operator">=</span> <span class="token string">'1\\'</span>    
    modelpath <span class="token operator">=</span> basePath <span class="token operator">+</span> modelName
    <span class="token comment"># # 保存的model中包含了自定义的层（Custom Layer）</span>
    model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>modelpath<span class="token punctuation">,</span> custom_objects<span class="token operator">=</span>get_custom_objects<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> model<span class="token punctuation">.</span>predict_generator<span class="token punctuation">(</span>test_D<span class="token punctuation">.</span>__iter__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>steps<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_D<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   
    <span class="token keyword">return</span> testlable<span class="token punctuation">,</span> result
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
	modelName <span class="token operator">=</span> <span class="token string">'BERT_06-1.0000-0.9360.h5'</span> 
	<span class="token comment"># modelName = 'LSTM_10-1.0000-0.9840.h5'  #</span>
	<span class="token comment"># modelName = 'BiLSTM_06-1.0000-0.9680.h5' </span>
	<span class="token comment"># modelName = 'CNN_07-0.9990-0.9520.h5' </span>
	testlable<span class="token punctuation">,</span> result <span class="token operator">=</span> BertModelPridect<span class="token punctuation">(</span>modelName<span class="token punctuation">)</span>
	resultlable <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	<span class="token keyword">for</span> each <span class="token keyword">in</span> result<span class="token punctuation">:</span>
		resultlable<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>each<span class="token punctuation">)</span><span class="token punctuation">)</span>

	report <span class="token operator">=</span> metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">)</span>
	confusion_matrix <span class="token operator">=</span> metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">)</span>
	accuracy_score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">)</span>
	precision_score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">,</span>average <span class="token operator">=</span> <span class="token string">"weighted"</span><span class="token punctuation">)</span>
	f1_score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">,</span>average <span class="token operator">=</span><span class="token string">"weighted"</span><span class="token punctuation">)</span>
	recall_score<span class="token operator">=</span> metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>testlable<span class="token punctuation">,</span> resultlable<span class="token punctuation">,</span>average <span class="token operator">=</span><span class="token string">"weighted"</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6707a4d6cee9104dfb7f92f7fc45af93/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">UDP实现消息发送</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/96f157b010e04fa34e8fb2ef449d7780/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Aandroid studio复制工程并对包进行重命名</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>