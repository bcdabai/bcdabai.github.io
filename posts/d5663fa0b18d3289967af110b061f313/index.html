<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop框架---MapReduce框架原理(下) - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop框架---MapReduce框架原理(下)" />
<meta property="og:description" content="标题 一.MapReduce框架原理(下)1.1 OutputFormat数据输出1.1.1 OutputFormat接口实现类1.1.2 自定义OutputFormat案例实操 1.2 MapReduce内核源码解析1.2.1 MapTask工作机制1.2.2 ReduceTask工作机制1.2.3 ReduceTask并行度决定机制1.2.4 MapTask &amp; ReduceTask源码解析 一.MapReduce框架原理(下) 1.1 OutputFormat数据输出 1.1.1 OutputFormat接口实现类 OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了 OutputFormat接口。下面我们介绍几种常见的OutputFormat实现类：
1.OutputFormat实现类(默认输出格式为TextOutputFormat 按行读取)
2.自定义OutputFormat
应用场景：如，输出数据到MYSQL/HBase/Elasticsearch等存储框架中
步骤：自定义一个类继承FileOutputFormat --&gt; 改写RecordWriter，具体改写输出数据的write()方法
1.1.2 自定义OutputFormat案例实操 1）需求
过滤输入的 log 日志，包含 atguigu 的网站输出到 D:\java_learning\output\outputformat1，不包含 atguigu 的网站输出到 D:\java_learning\output\outputformat2。
(1)输入data
(2）期望输出数据
两个txt文件：
2）需求分析
3）案例实操
（1）编写 LogMapper 类
package com.root.mapreduce.OutPutFormat; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.LongWritable; import org.apache.hadoop.io.NullWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Mapper; import java.io.IOException; public class LogMapper extends Mapper&lt;LongWritable, Text,Text, NullWritable&gt; { @Override protected void map(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/d5663fa0b18d3289967af110b061f313/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-11T16:46:45+08:00" />
<meta property="article:modified_time" content="2023-05-11T16:46:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop框架---MapReduce框架原理(下)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>标题</h4> 
 <ul><li><a href="#MapReduce_1" rel="nofollow">一.MapReduce框架原理(下)</a></li><li><ul><li><a href="#11_OutputFormat_3" rel="nofollow">1.1 OutputFormat数据输出</a></li><li><ul><li><a href="#111_OutputFormat_4" rel="nofollow">1.1.1 OutputFormat接口实现类</a></li><li><a href="#112_OutputFormat_18" rel="nofollow">1.1.2 自定义OutputFormat案例实操</a></li></ul> 
   </li><li><a href="#12_MapReduce_242" rel="nofollow">1.2 MapReduce内核源码解析</a></li><li><ul><li><a href="#121_MapTask_244" rel="nofollow">1.2.1 MapTask工作机制</a></li><li><a href="#122_ReduceTask_266" rel="nofollow">1.2.2 ReduceTask工作机制</a></li><li><a href="#123_ReduceTask_275" rel="nofollow">1.2.3 ReduceTask并行度决定机制</a></li><li><a href="#124_MapTask__ReduceTask_322" rel="nofollow">1.2.4 MapTask &amp; ReduceTask源码解析</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="MapReduce_1"></a>一.MapReduce框架原理(下)</h2> 
<h3><a id="11_OutputFormat_3"></a>1.1 OutputFormat数据输出</h3> 
<h4><a id="111_OutputFormat_4"></a>1.1.1 OutputFormat接口实现类</h4> 
<p><code>OutputFormat</code>是<code>MapReduce</code>输出的<code>基类</code>，所有实现MapReduce输出都实现了 OutputFormat接口。下面我们介绍几种常见的OutputFormat实现类：</p> 
<p><mark>1.OutputFormat实现类(<code>默认</code>输出格式为<code>TextOutputFormat 按行读取</code>)</mark></p> 
<p><img src="https://images2.imgbox.com/e1/16/QR4ZSNbz_o.png" alt="请添加图片描述"></p> 
<p><mark>2.自定义OutputFormat</mark></p> 
<p><strong>应用场景</strong>：如，<code>输出数据</code>到<code>MYSQL/HBase/Elasticsearch</code>等存储框架中</p> 
<p><strong>步骤</strong>：<code>自定义一个类继承FileOutputFormat</code> --&gt; <code>改写RecordWriter</code>，具体改写输出数据的<code>write()方法</code></p> 
<h4><a id="112_OutputFormat_18"></a>1.1.2 自定义OutputFormat案例实操</h4> 
<p><strong>1）需求</strong></p> 
<p>过滤输入的 log 日志，<code>包含 atguigu </code>的网站输出到<code> D:\java_learning\output\outputformat1</code>，<code>不包含 atguigu </code>的网站输出到 <code>D:\java_learning\output\outputformat2</code>。</p> 
<p><mark>(1)输入data</mark></p> 
<p><img src="https://images2.imgbox.com/fc/db/xehRhVcr_o.png" alt="请添加图片描述"></p> 
<p><mark>(2）期望输出数据</mark></p> 
<p>两个txt文件：<br> <img src="https://images2.imgbox.com/8f/45/XkrlrO6N_o.png" alt="请添加图片描述"></p> 
<p><strong>2）需求分析</strong></p> 
<p><img src="https://images2.imgbox.com/3f/3d/7CsBZmMA_o.png" alt="请添加图片描述"></p> 
<p><strong>3）案例实操</strong><br> （1）编写 LogMapper 类</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">OutPutFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IntWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Mapper</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>
   
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span> key<span class="token punctuation">,</span> <span class="token class-name">Text</span> value<span class="token punctuation">,</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">.</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//map不需要分割 也不需要其他操作 直接输出</span>
        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span><span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（2）编写 LogReducer 类</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">OutPutFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>
    
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">.</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//http://www.baidu.com</span>
        <span class="token comment">//http://www.baidu.com</span>
        <span class="token comment">//有可能出现两条相同的数据，为了以防丢失数据,如下操作</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">NullWritable</span> value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（3）自定义一个 LogOutputFormat 类</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">OutPutFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">RecordWriter</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">TaskAttemptContext</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span></span><span class="token class-name">FileOutputFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogOutputFormat</span> <span class="token keyword">extends</span> <span class="token class-name">FileOutputFormat</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">RecordWriter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token function">getRecordWriter</span><span class="token punctuation">(</span><span class="token class-name">TaskAttemptContext</span> job<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//创建一个自定义的 RecordWriter 返回</span>
        <span class="token class-name">LogRecordWriter</span> lrw<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">LogRecordWriter</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> lrw<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（4）编写 LogRecordWriter 类</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">OutPutFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">FSDataOutputStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">FileSystem</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">Path</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOUtils</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">RecordWriter</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">TaskAttemptContext</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>webapp<span class="token punctuation">.</span>hamlet2<span class="token punctuation">.</span></span><span class="token class-name">Hamlet</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogRecordWriter</span> <span class="token keyword">extends</span> <span class="token class-name">RecordWriter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">private</span>  <span class="token class-name">FSDataOutputStream</span> atguiguOut<span class="token punctuation">;</span>
    <span class="token keyword">private</span>  <span class="token class-name">FSDataOutputStream</span> otherOut<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token class-name">LogRecordWriter</span><span class="token punctuation">(</span><span class="token class-name">TaskAttemptContext</span> job<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//创建两条流</span>
        <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
        	<span class="token comment">//获取文件系统对象</span>
            <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>job<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">//用文件系统对象创建两个输出流对应不同的目录</span>
             atguiguOut <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\java_learning\\output\\outputformat1\\atguigu.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
             otherOut <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\java_learning\\output\\outputformat2\\other.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span><span class="token class-name">Text</span> text<span class="token punctuation">,</span> <span class="token class-name">NullWritable</span> nullWritable<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//具体写</span>
        <span class="token class-name">String</span> s <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//根据一行的 log 数据是否包含 atguigu,判断两条输出流输出的内容</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>s<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
            atguiguOut<span class="token punctuation">.</span><span class="token function">writeBytes</span><span class="token punctuation">(</span>s<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>
            otherOut<span class="token punctuation">.</span><span class="token function">writeBytes</span><span class="token punctuation">(</span>s<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token class-name">TaskAttemptContext</span> taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
    	<span class="token comment">//关流</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>atguiguOut<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>otherOut<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>（5）编写 LogDriver 类</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">OutPutFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span></span><span class="token class-name">WordCountDriver</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span></span><span class="token class-name">WordCountMapper</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>root<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span></span><span class="token class-name">WordCountReducer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">Path</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IntWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Job</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span></span><span class="token class-name">FileInputFormat</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span></span><span class="token class-name">FileOutputFormat</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">Driver</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogDriver</span> <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span><span class="token punctuation">,</span> <span class="token class-name">ClassNotFoundException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">//1.获取job</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Job</span> ins <span class="token operator">=</span> <span class="token class-name">Job</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//2.设置jar包路径</span>
        ins<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span><span class="token class-name">LogDriver</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//3.关联mapper和reducer</span>
        ins<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span><span class="token class-name">LogMapper</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        ins<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span><span class="token class-name">LogReducer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//4.设置map输出的kv类型</span>
        ins<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span><span class="token class-name">Text</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        ins<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span><span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//5.设置最终输出的kv类型</span>
        ins<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span><span class="token class-name">Text</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        ins<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span><span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//5+:设置自定义的outputformat</span>
        ins<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span><span class="token class-name">LogOutputFormat</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//6.设置输入路径和输出路径</span>
        <span class="token class-name">FileInputFormat</span><span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>ins<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\java_learning\\input\\inputOutputfomat"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</span>
        <span class="token comment">//而fileoutputformat还要输出一个_SUCCESS文件，所以还要再指定一个目录(产生的_SUCCESS文件及其校验文件都在此产生)</span>
        <span class="token class-name">FileOutputFormat</span><span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>ins<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\java_learning\\output\\output111"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//7.提交job</span>
        <span class="token keyword">boolean</span> result <span class="token operator">=</span> ins<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>4）结果展示</p> 
<p><img src="https://images2.imgbox.com/fb/df/EAzQ0YLL_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/d9/62/F7RG7ga6_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/aa/86/jZK61FgZ_o.png" alt="请添加图片描述"></p> 
<h3><a id="12_MapReduce_242"></a>1.2 MapReduce内核源码解析</h3> 
<h4><a id="121_MapTask_244"></a>1.2.1 MapTask工作机制</h4> 
<p><img src="https://images2.imgbox.com/97/d9/37RCf6dK_o.png" alt="请添加图片描述"></p> 
<p>（1）<mark>Read 阶段</mark>：<code>MapTask</code> 通过 <code>InputFormat</code> 获得的 <code>RecordReade</code>r，从<code>输入 InputSplit</code> 中<code>解析</code>出一个个 <code>key/value</code>。</p> 
<p>（2）<mark>Map 阶段</mark><code>：该节点主要是</code>将解析出的 key/value 交给用户编写 map()函数<code>处理，并</code>产生<code>一系列</code>新的 key/value`。</p> 
<p>（3）<mark>Collect 收集阶段</mark><code>：在用户编写</code> map()函数<code>中，当</code>数据处理完成<code>后，一般会</code>调用OutputCollector.collect()输出<code>结果。在该函数内部，它会将</code>生成的 key/value 分区<code>（调用Partitioner），并</code>写入一个环形内存缓冲区`中。</p> 
<p>（4）<mark>Spill 阶段</mark>：即“<code>溢写”</code>，当<code>环形缓冲区满</code>后，MapReduce 会将<code>数据</code>写到<code>本地磁盘</code>上，生成一个<code>临时文件</code>。需要注意的是，将数据<code>写入本地磁盘之前</code>，先要对数据进行一次<code>本地排序</code>，并在<code>必要时对数据进行合并、压缩等</code>操作。</p> 
<blockquote> 
 <p><code>溢写阶段</code>详情：<br> <mark>步骤 1</mark>：利用<code>快速排序</code>算法对缓存区内的数据进行排序，排序方式是，<code>先按照分区编号Partition</code> 进行排序，然<code>后按照 key </code>进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照 key 有序。<br> <mark>步骤 2</mark>：<code>按照分区编号由小到大</code>依次<code>将每个分区中的数据写入</code>任务工作目录下的<code>临时文件 output/spillN.out</code>（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。<br> <mark>步骤 3</mark>：<code>将分区数据的元信息写到内存索引数据结构 SpillRecord</code> 中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过 1MB，则将内存索引写到文件 output/spillN.out.index 中。</p> 
</blockquote> 
<p>（5）<mark>Merge 阶段</mark>：当所有<code>数据处理完成</code>后，<code>MapTask 对所有临时文件</code>进行一次<code>合并</code>，以确保<code>最终只会生成一个数据文件</code>。当所有数据处理完后，MapTask 会<code>将所有临时文件合并成一个大文件</code>，并保存<code>到文件output/file.out 中</code>，同时生成<code>相应的索引文件 output/file.out.index</code>。在进行文件合并过程中，<code>MapTask 以分区为单位进行合并</code>。对于某个分区，它将采用多轮递归合并的方式。每轮合并 mapreduce.task.io.sort.factor（默认 10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p> 
<h4><a id="122_ReduceTask_266"></a>1.2.2 ReduceTask工作机制</h4> 
<p><img src="https://images2.imgbox.com/59/7e/0irnB2ce_o.png" alt="请添加图片描述"></p> 
<p>（1）<mark>Copy 阶段</mark>：<code>ReduceTask</code> 从各个<code> MapTask</code> 上<code>远程拷贝一片数据</code>，并<code>针对某一片数据</code>，如果<code>其大小超过一定阈值</code>，则<code>写到磁盘上</code>，<code>否则直接放到内存中</code>。</p> 
<p>（2）<mark>Sort 阶段</mark>：在<code>远程拷贝数据的同时</code>，<code>ReduceTask</code> 启动了<code>两个后台线程</code>对<code>内存和磁盘上</code>的<code>文件进行合并</code>，以防止内存使用过多或磁盘上文件过多。按照 MapReduce 语义，<code>用户编写 reduce()函数输入数据</code>是<code>按 key </code>进行<code>聚集</code>的一组数据。为了将 key 相同的数据聚在一起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此，ReduceTask 只需对所有数据进行一次归并排序即可。</p> 
<p>（3）<mark>Reduce 阶段</mark>：<code>reduce()函数</code>将计算结果<code>写到 HDFS 上</code>。</p> 
<h4><a id="123_ReduceTask_275"></a>1.2.3 ReduceTask并行度决定机制</h4> 
<p>回顾：<mark>MapTask 并行度由切片个数决定，切片个数由输入文件和切片规则决定(控制minSize，maxSize)。</mark>(参考<a href="https://blog.csdn.net/f986153489/article/details/130529341?spm=1001.2014.3001.5501">Hadoop框架—MapReduce框架原理(上)</a>)</p> 
<p>思考：ReduceTask 并行度由谁决定？</p> 
<p><strong>1）设置 ReduceTask 并行度（个数）</strong></p> 
<p>ReduceTask 的并行度同样影响整个 Job 的执行并发度和执行效率，但与 MapTask 的并发数由切片数决定不同，ReduceTask 数量的决定是可以直接手动设置：</p> 
<p>// 默认值是 1，手动设置为 4<br> <code>job.setNumReduceTasks(4);</code></p> 
<p><strong>2）实验：测试 ReduceTask 多少合适</strong></p> 
<p>（1）实验环境：1 个 Master 节点，16 个 Slave 节点：CPU:8GHZ，内存: 2G</p> 
<p>（2）实验结论<br> <img src="https://images2.imgbox.com/bc/0f/kg4ALomx_o.png" alt="请添加图片描述"></p> 
<p><strong>3）注意事项</strong></p> 
<p>（1）<code>ReduceTask=0</code>，表示<code>没有Reduce阶段</code>，<code>输出文件个数</code>和<code>Map个数一致</code>。</p> 
<p>（2）<code>ReduceTask默认值</code>就是<code>1</code>，所以<code>输出文件</code>个数为<code>一个</code>。</p> 
<p>（3）如果<code>数据分布不均匀</code>，就有<code>可能在Reduce阶段</code>产生<code>数据倾斜</code></p> 
<p>（4）<code>ReduceTask数量</code>并<code>不是任意设置</code>，还要考虑<code>业务逻辑需求</code>，有些情况下，需要计算全<br> 局汇总结果，就只能有1个ReduceTask。</p> 
<p>（5）<code>具体</code>多少个ReduceTask，需要<code>根据集群性能</code>而定。</p> 
<p>（6）如果<code>分区数不是1</code>，但是<code>ReduceTask</code>为<code>1</code>，是否执行分区过程。答案是：<mark>不执行分区过程</mark>。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1肯定不执行:(参考<a href="https://blog.csdn.net/f986153489/article/details/130559671?spm=1001.2014.3001.5501">Hadoop框架—MapReduce框架原理(中)</a>Partition分区案例实操.)</p> 
<p><img src="https://images2.imgbox.com/02/af/dyB3c3Bz_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/26/9d/ysBxPD45_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/be/f3/8nWIz692_o.png" alt="请添加图片描述"></p> 
<p>再看输出结果：</p> 
<p><img src="https://images2.imgbox.com/43/f3/SnIkckD3_o.png" alt="请添加图片描述"></p> 
<h4><a id="124_MapTask__ReduceTask_322"></a>1.2.4 MapTask &amp; ReduceTask源码解析</h4> 
<p>1）MapTask 源码解析流程</p> 
<pre><code class="prism language-markup">context.write(k, NullWritable.get()); //自定义的 map 方法的写出，进入
	output.write(key, value); 
		//MapTask727 行，收集方法，进入两次
		collector.collect(key, value,partitioner.getPartition(key, value, partitions));
			HashPartitioner(); //默认分区器
		collect() //MapTask1082 行 map 端所有的 kv 全部写出后会走下面的 close 方法
			close() //MapTask732 行
				collector.flush() // 溢出刷写方法，MapTask735 行，提前打个断点，进入
					sortAndSpill() //溢写排序，MapTask1505 行，进入
						sorter.sort() QuickSort //溢写排序方法，MapTask1625 行，进入
					mergeParts(); //合并文件，MapTask1527 行
				collector.close(); //MapTask739 行,收集器关闭,即将进入 ReduceTask				

</code></pre> 
<p>2）ReduceTask 源码解析流程</p> 
<pre><code class="prism language-markup">if (isMapOrReduce()) //reduceTask324 行，提前打断点
initialize() // reduceTask333 行,进入
init(shuffleContext); // reduceTask375 行,走到这需要先给下面的打断点
 totalMaps = job.getNumMapTasks(); // ShuffleSchedulerImpl 第 120 行，提前打断点
 merger = createMergeManager(context); //合并方法，Shuffle 第 80 行
	// MergeManagerImpl 第 232 235 行，提前打断点
	this.inMemoryMerger = createInMemoryMerger(); //内存合并
	this.onDiskMerger = new OnDiskMerger(this); //磁盘合并
rIter = shuffleConsumerPlugin.run();
	eventFetcher.start(); //开始抓取数据，Shuffle 第 107 行，提前打断点
	eventFetcher.shutDown(); //抓取结束，Shuffle 第 141 行，提前打断点
	copyPhase.complete(); //copy 阶段完成，Shuffle 第 151 行
	taskStatus.setPhase(TaskStatus.Phase.SORT); //开始排序阶段，Shuffle 第 152 行
sortPhase.complete(); //排序阶段完成，即将进入 reduce 阶段 reduceTask382 行
reduce(); //reduce 阶段调用的就是我们自定义的 reduce 方法，会被调用多次
cleanup(context); //reduce 完成之前，会最后调用一次 Reducer 里面的 cleanup 方法
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3304d87ace44037795f2a29d9831fcc2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">6.常见报错-已解决：v-on event ‘@showSizeChange‘ must be hyphenated</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/633577e070759a4f990215df65b6c513/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">响应码及分类</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>