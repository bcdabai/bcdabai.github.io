<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>2021-Swin Transformer Attention机制的详细推导 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="2021-Swin Transformer Attention机制的详细推导" />
<meta property="og:description" content="文章目录 1. Title2. Summary3. Problem Statement4. Method(s)4.1 Overall Architecture（1）Patch Partition（2）StagesPatch MergingSwin Transformer Block 4.2 Shifted Window based Self-Attention（1）Self-Attention in Non-Overlapped Windows（2）Shifted Window Partitioning in Successive Blocks（3）Efficient Batch Computation for Shifted ConfigurationNaive SolutionBatch Computation ApproachMask计算结果手工推导Mask作用的手工推导 （4）Relative Position Bias 4.3 Architecture Variants 5. Evaluation（1）对比实验（2）消融实验 6. Conclusion 1. Title paper
github
2. Summary SwinTransformer与PVT一样，也是想设计一个可以作为密集预测任务的Transformer Backbone，其采用与PVT类似的PatchMerging的策略，构建了层次化的特征，使得其可以作为密集预测任务的Backbone。
同时考虑到密集预测任务中，tokens数目太多导致计算量过大的问题，其采用一种在local window内部计算Self-Attention的机制去降低计算复杂度，使得整体计算复杂度由 O ( N 2 ) O(N^2) O(N2)降低至 O ( N ) O(N) O(N)水平。
为了弥补Local Self-Attention带来了远程依赖关系缺失的问题，其创新性地采用了Shift Window操作，引入了不同window之间的关系，并且在精度以及速度上都超越了简单的Sliding Window的方法。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ec247809301a7d5f6e93b5b2b55c4644/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-26T20:15:34+08:00" />
<meta property="article:modified_time" content="2021-04-26T20:15:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2021-Swin Transformer Attention机制的详细推导</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1_Title_1" rel="nofollow">1. Title</a></li><li><a href="#2_Summary_4" rel="nofollow">2. Summary</a></li><li><a href="#3_Problem_Statement_9" rel="nofollow">3. Problem Statement</a></li><li><a href="#4_Methods_19" rel="nofollow">4. Method(s)</a></li><li><ul><li><a href="#41_Overall_Architecture_25" rel="nofollow">4.1 Overall Architecture</a></li><li><ul><li><a href="#1Patch_Partition_27" rel="nofollow">（1）Patch Partition</a></li><li><a href="#2Stages_77" rel="nofollow">（2）Stages</a></li><li><ul><li><a href="#Patch_Merging_78" rel="nofollow">Patch Merging</a></li><li><a href="#Swin_Transformer_Block_129" rel="nofollow">Swin Transformer Block</a></li></ul> 
   </li></ul> 
   </li><li><a href="#42_Shifted_Window_based_SelfAttention_132" rel="nofollow">4.2 Shifted Window based Self-Attention</a></li><li><ul><li><a href="#1SelfAttention_in_NonOverlapped_Windows_134" rel="nofollow">（1）Self-Attention in Non-Overlapped Windows</a></li><li><a href="#2Shifted_Window_Partitioning_in__Successive_Blocks_146" rel="nofollow">（2）Shifted Window Partitioning in Successive Blocks</a></li><li><a href="#3Efficient_Batch_Computation_for_Shifted_Configuration_182" rel="nofollow">（3）Efficient Batch Computation for Shifted Configuration</a></li><li><ul><li><a href="#Naive_Solution_184" rel="nofollow">Naive Solution</a></li><li><a href="#Batch_Computation_Approach_188" rel="nofollow">Batch Computation Approach</a></li><li><ul><li><a href="#Mask_193" rel="nofollow">Mask计算结果手工推导</a></li><li><a href="#Mask_240" rel="nofollow">Mask作用的手工推导</a></li></ul> 
    </li></ul> 
    </li><li><a href="#4Relative_Position_Bias_246" rel="nofollow">（4）Relative Position Bias</a></li></ul> 
   </li><li><a href="#43_Architecture_Variants_251" rel="nofollow">4.3 Architecture Variants</a></li></ul> 
  </li><li><a href="#5_Evaluation_254" rel="nofollow">5. Evaluation</a></li><li><ul><li><a href="#1_255" rel="nofollow">（1）对比实验</a></li><li><a href="#2_260" rel="nofollow">（2）消融实验</a></li></ul> 
  </li><li><a href="#6_Conclusion_263" rel="nofollow">6. Conclusion</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1_Title_1"></a>1. Title</h2> 
<p><a href="https://arxiv.org/pdf/2103.14030.pdf" rel="nofollow">paper</a><br> <a href="https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation">github</a></p> 
<h2><a id="2_Summary_4"></a>2. Summary</h2> 
<p>SwinTransformer与PVT一样，也是想设计一个可以作为密集预测任务的Transformer Backbone，其采用与PVT类似的PatchMerging的策略，构建了层次化的特征，使得其可以作为密集预测任务的Backbone。<br> 同时考虑到密集预测任务中，tokens数目太多导致计算量过大的问题，其采用一种在local window内部计算Self-Attention的机制去降低计算复杂度，使得整体计算复杂度由<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         O 
        
       
         ( 
        
        
        
          N 
         
        
          2 
         
        
       
         ) 
        
       
      
        O(N^2) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06411em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>降低至<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         O 
        
       
         ( 
        
       
         N 
        
       
         ) 
        
       
      
        O(N) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mclose">)</span></span></span></span></span>水平。<br> 为了弥补Local Self-Attention带来了远程依赖关系缺失的问题，其创新性地采用了Shift Window操作，引入了不同window之间的关系，并且在精度以及速度上都超越了简单的Sliding Window的方法。<br> 是Transformer在Local Attention策略上的一次不错的尝试。</p> 
<h2><a id="3_Problem_Statement_9"></a>3. Problem Statement</h2> 
<p>卷积操作由于其权值共享、Locality、滑窗等特性，天然比较适合对图像的各种特征进行建模，因此，也成为了计算机视觉领域的主流架构。但是随着近些年的研究，CNN结构的性能逐渐达到了一个瓶颈，CNN结构的locality特性使得其对于远距离依赖的建模成本较高，只能通过堆叠多个CNN层或是使用Dilated Conv等操作提升感受野。而在NLP领域成为主流架构的Transformer结构由于其对远程依赖超高效的建模能力，开始逐渐被改造并应用于计算机视觉领域。那么是否能够将Transformer作为CV领域的一个通用的backbone呢？就像Transformer之于NLP，CNN之于CV一样。</p> 
<p>直接将Transformer作为CV领域的一个通用的backbone存在着两大挑战：</p> 
<ul><li>视觉领域实例一般尺度变化较大<br> 在NLP领域，word tokens作为基本的处理元素，一般通过padding或裁减的方式保持其长度固定，并且这种操作对结果的生成不会产生太大影响。<br> 但是在CV领域，如何挖掘多尺度信息是一个重要命题，固定长度的token不太利于多尺度信息的挖掘。</li><li>image的像素分辨率较高<br> 相较于NLP领域的words的数目，image中的像素数目更多，一些密集预测任务例如语义分割需要完成像素级的密集预测，这个计算量对于Transformer中Self-Attention的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          O 
         
        
          ( 
         
         
         
           N 
          
         
           2 
          
         
        
          ) 
         
        
       
         O(N^2) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06411em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>计算复杂度是难以解决的。</li></ul> 
<h2><a id="4_Methods_19"></a>4. Method(s)</h2> 
<p>为了解决上述问题，本文提出了一个通用视觉Backbone——SwinTransformer结构，该结构可以形成分层次的特征图，并且对图像大小具有线性的计算复杂度。</p> 
<ul><li>SwinTransformer首先从小尺寸的patches开始，并且在更深的Transformer Layer中逐步合并相邻的patches，最终形成一系列层次化的特征。这种层次化的特征很容易与一些密集预测结构结合以完成相应任务。</li><li>SwinTransformer仅在一个局部窗口内计算Self-Attention（窗口互相不重叠，用于分割整张图片），由于每个窗口中的patches的数目是固定的，因此，这种local的self-Attention计算复杂度对于image size来说即成为线性复杂度。</li><li>但是倘若仅在Local Window内计算Self-Attention，便无法发挥Transformer在全局依赖建模上的能力，因此，SwinTransformer采用了一种Shift-Windows的方法，来引入不同Windows之间的关系，并且<strong>由于在一个Windows内，所有的query patches都共享一个key，内存的占用也较少</strong>，Shift-Windows的方法相较于Sliding-Windows的方法具有更低的时延，同时建模能力也较为相似。</li></ul> 
<h3><a id="41_Overall_Architecture_25"></a>4.1 Overall Architecture</h3> 
<p><img src="https://images2.imgbox.com/75/93/ZJGotL02_o.png" alt="Tiny SwinTransformer整体结构"></p> 
<h4><a id="1Patch_Partition_27"></a>（1）Patch Partition</h4> 
<p>和大部分Transformer结构类似，SwinTransformer首先会将RGB图片分割为一系列不重叠的patches 。在SwinTransformer设定中，每个patch的大小为4*4，由于每个像素有RGB三个通道值，因此，每个patch的维度为4*4*3，并最终通过一个线性Embedding层转化为Embedding Dimension C。代码如下所示：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">PatchEmbed</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Image to Patch Embedding

    Args:
        patch_size (int): Patch token size. Default: 4.
        in_chans (int): Number of input image channels. Default: 3.
        embed_dim (int): Number of linear projection output channels. Default: 96.
        norm_layer (nn.Module, optional): Normalization layer. Default: None
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> patch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> in_chans<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span><span class="token number">96</span><span class="token punctuation">,</span> norm_layer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        patch_size <span class="token operator">=</span> to_2tuple<span class="token punctuation">(</span>patch_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>patch_size <span class="token operator">=</span> patch_size

        self<span class="token punctuation">.</span>in_chans <span class="token operator">=</span> in_chans
        self<span class="token punctuation">.</span>embed_dim <span class="token operator">=</span> embed_dim

        <span class="token comment"># 带步长卷积实现分块的同时进行Embedding</span>
        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_chans<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>patch_size<span class="token punctuation">,</span> stride<span class="token operator">=</span>patch_size<span class="token punctuation">)</span>

        <span class="token comment"># LayerNorm</span>
        <span class="token keyword">if</span> norm_layer <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>norm <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>embed_dim<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>norm <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Forward function."""</span>
        <span class="token comment"># 在下方或者是右侧进行padding以确保图片可以被patchsize整除</span>
        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> W <span class="token operator">%</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> W <span class="token operator">%</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> H <span class="token operator">%</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> H <span class="token operator">%</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		
		<span class="token comment"># 一共得到 wh * Ww 个tokens</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># B C Wh Ww</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Wh<span class="token punctuation">,</span> Ww <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>embed_dim<span class="token punctuation">,</span> Wh<span class="token punctuation">,</span> Ww<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x
</code></pre> 
<h4><a id="2Stages_77"></a>（2）Stages</h4> 
<h5><a id="Patch_Merging_78"></a>Patch Merging</h5> 
<p>Patch Tokens会送入SwinTransformer blocks中，得到的tokens数目不变，仍然为Wh*Ww。<br> Linear Embedding也就是代码中的proj以及后续的Transformer Blocks合在一起组成<strong>Stage 1</strong>。经过Stage 1，特征图大小变为原图的1/4（H / 4，W / 4）。<br> 为了形成一个层次化的结构，随着网络的进行，tokens的数目会通过Patch Merging操作逐步合并而减少。<br> 具体而言，Patch Merging操作首先会将临近2*2范围内的patch拼接起来，得到一个4C维度的feature，然后通过一个线性层将其维度降低为2C（对于每个patch而言，维度由C上升至2C），然后该特征送入几个Transformer Block中，得到<strong>Stage 2</strong>。经过Stage 2，特征图变为原图的1/8（H / 8，W / 8）。<br> 以此类推，得到Stage 3 （H / 16, W / 16）和 Stage 4（H / 32，W / 32）。<br> Patch Merging的代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">PatchMerging</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Patch Merging Layer

    Args:
        dim (int): Number of input channels.
        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim
        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> dim<span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" Forward function.

        Args:
            x: Input feature, tensor size (B, H*W, C).
            H, W: Spatial resolution of the input feature.
        """</span>
        B<span class="token punctuation">,</span> L<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        <span class="token keyword">assert</span> L <span class="token operator">==</span> H <span class="token operator">*</span> W<span class="token punctuation">,</span> <span class="token string">"input feature has wrong size"</span>

        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>

        <span class="token comment"># padding</span>
        pad_input <span class="token operator">=</span> <span class="token punctuation">(</span>H <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span>W <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> pad_input<span class="token punctuation">:</span>
            x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> W <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> H <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        x0 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C 左上</span>
        x1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C 左下 </span>
        x2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C 右上</span>
        x3 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C 右下</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x0<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> x3<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># B H/2 W/2 4*C</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> C<span class="token punctuation">)</span>  <span class="token comment"># B H/2*W/2 4*C</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>reduction<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># B H/2*W/2 2*C </span>

        <span class="token keyword">return</span> x
</code></pre> 
<h5><a id="Swin_Transformer_Block_129"></a>Swin Transformer Block</h5> 
<p>Swin Transformer Block与普通Transformer Block的区别主要在于使用了一个基于Shift Windows的模块去替换了标准的Multi-head Self-Attention（MSA）模块；除此之外，其LayerNorm加在了MSA和MLP的<strong>前面</strong>。</p> 
<h3><a id="42_Shifted_Window_based_SelfAttention_132"></a>4.2 Shifted Window based Self-Attention</h3> 
<p>标准的Transformer结构或其变体都采用的是Global Self Attention，其会计算一个token和其他所有token的关系，其计算复杂度太高，不适合与密集预测等需要大量token的任务。</p> 
<h4><a id="1SelfAttention_in_NonOverlapped_Windows_134"></a>（1）Self-Attention in Non-Overlapped Windows</h4> 
<p>为了降低计算复杂度，SwinTransformer在局部Windows内部计算Self-Attention。<br> 每个image都会被平均划分为若干个windows，并且这些Windows之间是没有重叠的。<br> 假设image的大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         h 
        
       
         ∗ 
        
       
         w 
        
       
      
        h*w 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span></span></span></span></span>，每个Window包含<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         M 
        
       
         ∗ 
        
       
         M 
        
       
      
        M*M 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span></span></span></span></span>个patches，则标准MSA和基于window的局部SelfAttention的计算量分别为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
           
            
           
          
          
           
            
             
            
              Ω 
             
            
              ( 
             
             
             
               M 
              
             
               S 
              
             
               A 
              
             
            
              ) 
             
            
              = 
             
            
              4 
             
            
              h 
             
            
              w 
             
             
             
               C 
              
             
               2 
              
             
            
              + 
             
            
              2 
             
            
              ( 
             
            
              h 
             
            
              w 
             
             
             
               ) 
              
             
               2 
              
             
            
              C 
             
            
           
          
         
         
          
           
            
           
          
          
           
            
             
            
              Ω 
             
            
              ( 
             
            
              W 
             
            
              − 
             
             
             
               M 
              
             
               S 
              
             
               A 
              
             
            
              ) 
             
            
              = 
             
            
              4 
             
            
              h 
             
            
              w 
             
             
             
               C 
              
             
               2 
              
             
            
              + 
             
            
              2 
             
             
             
               M 
              
             
               2 
              
             
            
              h 
             
            
              w 
             
            
              C 
             
            
           
          
         
        
       
         \begin{aligned} &amp;\Omega(\mathrm{MSA})=4 h w C^{2}+2(h w)^{2} C\\ &amp;\Omega(\mathrm{W}-\mathrm{MSA})=4 h w C^{2}+2 M^{2} h w C \end{aligned} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 3.04822em; vertical-align: -1.27411em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.77411em;"><span class="" style="top: -3.77411em;"><span class="pstrut" style="height: 2.86411em;"></span><span class="mord"></span></span><span class="" style="top: -2.25em;"><span class="pstrut" style="height: 2.86411em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27411em;"><span class=""></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.77411em;"><span class="" style="top: -3.91em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"></span><span class="mord">Ω</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">S</span><span class="mord mathrm">A</span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord">4</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span></span></span><span class="" style="top: -2.38589em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"></span><span class="mord">Ω</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm" style="margin-right: 0.01389em;">W</span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">S</span><span class="mord mathrm">A</span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord">4</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27411em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></p> 
<p>两个公式的推导可参见下图：<br> <img src="https://images2.imgbox.com/2d/f8/j6V8i83x_o.png" alt="MSA计算量推导"><img src="https://images2.imgbox.com/5b/16/WI3W4rXM_o.png" alt="W-MSA计算量推导"><br> 由于Window的大小是固定的（论文中设定为7），W-MSA的计算量将远远小于MSA。</p> 
<h4><a id="2Shifted_Window_Partitioning_in__Successive_Blocks_146"></a>（2）Shifted Window Partitioning in Successive Blocks</h4> 
<p>在局部window内计算Self-Attention确实可以极大地降低计算复杂度，但是其也缺失了窗口之间的信息交互，降低了模型的表示能力。为了引入Cross-Window Connection，SwinTransformer采用了一种移位窗口划分的方法来实现这一目标，窗口会在<strong>连续两个SwinTransformer Blocks交替移动</strong>，使得不同Windows之间有机会进行交互。<br> <img src="https://images2.imgbox.com/e4/81/AE0bGDig_o.png" alt="Shifted Window Approach"><br> Shifted Window方法是在连续的两个Transformer Block之间实现的。</p> 
<ul><li>第一个模块使用一个标准的window partition策略，从feature map的左上角出发，例如一个8*8的feature map会被平分为2*2个window，每个window的大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
          = 
         
        
          4 
         
        
       
         M=4 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">4</span></span></span></span></span>。</li><li>紧接着的第二个模块则使用了移动窗口的策略，window会从feature map的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
         
         
           ⌊ 
          
          
          
            M 
           
          
            2 
           
          
         
           ⌋ 
          
         
        
          , 
         
         
         
           ⌊ 
          
          
          
            M 
           
          
            2 
           
          
         
           ⌋ 
          
         
        
          ) 
         
        
       
         \left(\left\lfloor\frac{M}{2}\right\rfloor,\left\lfloor\frac{M}{2}\right\rfloor\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.22234em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.872331em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌋</span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.872331em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌋</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span>位置处开始，然后再进行window partition操作。</li></ul> 
<p>这样一来，不同window之间在两个连续的模块之间便有机会进行交互。<br> 基于移动窗口策略，两个连续的SwinTransformer Block的计算过程如下：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
           
            
             
              
              
                z 
               
              
                ^ 
               
              
             
               l 
              
             
            
              = 
             
            
              W 
             
            
              − 
             
             
             
               M 
              
             
               S 
              
             
               A 
              
             
             
             
               ( 
              
              
              
                L 
               
              
                N 
               
              
              
              
                ( 
               
               
               
                 z 
                
                
                
                  l 
                 
                
                  − 
                 
                
                  1 
                 
                
               
              
                ) 
               
              
             
               ) 
              
             
            
              + 
             
             
             
               z 
              
              
              
                l 
               
              
                − 
               
              
                1 
               
              
             
            
           
          
         
         
          
           
            
             
             
               z 
              
             
               l 
              
             
            
              = 
             
            
              MLP 
             
            
              ⁡ 
             
             
             
               ( 
              
              
              
                L 
               
              
                N 
               
              
              
              
                ( 
               
               
                
                
                  z 
                 
                
                  ^ 
                 
                
               
                 l 
                
               
              
                ) 
               
              
             
               ) 
              
             
            
              + 
             
             
              
              
                z 
               
              
                ^ 
               
              
             
               l 
              
             
            
              , 
             
            
           
          
         
         
          
           
            
             
              
              
                z 
               
              
                ^ 
               
              
              
              
                l 
               
              
                + 
               
              
                1 
               
              
             
            
              = 
             
             
             
               S 
              
             
               W 
              
             
            
              − 
             
             
             
               M 
              
             
               S 
              
             
               A 
              
             
             
             
               ( 
              
              
              
                L 
               
              
                N 
               
              
              
              
                ( 
               
               
               
                 z 
                
               
                 l 
                
               
              
                ) 
               
              
             
               ) 
              
             
            
              + 
             
             
             
               z 
              
             
               l 
              
             
            
           
          
         
         
          
           
            
             
             
               z 
              
              
              
                l 
               
              
                + 
               
              
                1 
               
              
             
            
              = 
             
            
              MLP 
             
            
              ⁡ 
             
             
             
               ( 
              
             
               LN 
              
             
               ⁡ 
              
              
              
                ( 
               
               
                
                
                  z 
                 
                
                  ^ 
                 
                
                
                
                  l 
                 
                
                  + 
                 
                
                  1 
                 
                
               
              
                ) 
               
              
             
               ) 
              
             
            
              + 
             
             
              
              
                z 
               
              
                ^ 
               
              
              
              
                l 
               
              
                + 
               
              
                1 
               
              
             
            
           
          
         
        
       
         \begin{array}{l} \hat{\mathbf{z}}^{l}=\mathrm{W}-\mathrm{MSA}\left(\mathrm{LN}\left(\mathbf{z}^{l-1}\right)\right)+\mathbf{z}^{l-1} \\ \mathbf{z}^{l}=\operatorname{MLP}\left(\mathrm{LN}\left(\hat{\mathbf{z}}^{l}\right)\right)+\hat{\mathbf{z}}^{l}, \\ \hat{\mathbf{z}}^{l+1}=\mathrm{SW}-\mathrm{MSA}\left(\mathrm{LN}\left(\mathbf{z}^{l}\right)\right)+\mathbf{z}^{l} \\ \mathbf{z}^{l+1}=\operatorname{MLP}\left(\operatorname{LN}\left(\hat{\mathbf{z}}^{l+1}\right)\right)+\hat{\mathbf{z}}^{l+1} \end{array} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 4.84em; vertical-align: -2.17em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width: 0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 2.67em;"><span class="" style="top: -4.82em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord"><span class="mord mathrm" style="margin-right: 0.01389em;">W</span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">S</span><span class="mord mathrm">A</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">N</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.61em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mop"><span class="mord mathrm">M</span><span class="mord mathrm">L</span><span class="mord mathrm">P</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">N</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span class="" style="top: -2.4em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord"><span class="mord mathrm">S</span><span class="mord mathrm" style="margin-right: 0.01389em;">W</span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">S</span><span class="mord mathrm">A</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">N</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -1.19em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mop"><span class="mord mathrm">M</span><span class="mord mathrm">L</span><span class="mord mathrm">P</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mop"><span class="mord mathrm">L</span><span class="mord mathrm">N</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 2.17em;"><span class=""></span></span></span></span></span><span class="arraycolsep" style="width: 0.5em;"></span></span></span></span></span></span></span></span><br> Shift Windows策略在官方代码中的体现为：</p> 
<pre><code class="prism language-python"><span class="token comment"># build blocks</span>
        self<span class="token punctuation">.</span>blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            SwinTransformerBlock<span class="token punctuation">(</span>
                dim<span class="token operator">=</span>dim<span class="token punctuation">,</span>
                num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>
                window_size<span class="token operator">=</span>window_size<span class="token punctuation">,</span>
                shift_size<span class="token operator">=</span><span class="token number">0</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">else</span> window_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token comment"># 交替移动</span>
                mlp_ratio<span class="token operator">=</span>mlp_ratio<span class="token punctuation">,</span>
                qkv_bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span>
                qk_scale<span class="token operator">=</span>qk_scale<span class="token punctuation">,</span>
                drop<span class="token operator">=</span>drop<span class="token punctuation">,</span>
                attn_drop<span class="token operator">=</span>attn_drop<span class="token punctuation">,</span>
                drop_path<span class="token operator">=</span>drop_path<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>drop_path<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">else</span> drop_path<span class="token punctuation">,</span>
                norm_layer<span class="token operator">=</span>norm_layer<span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3Efficient_Batch_Computation_for_Shifted_Configuration_182"></a>（3）Efficient Batch Computation for Shifted Configuration</h4> 
<p>Shifted Window Partition存在一个问题，由于没有与边界对齐，其会产生更多的Windows，从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ⌈ 
         
         
         
           h 
          
         
           M 
          
         
        
          ⌉ 
         
        
       
         × 
        
        
        
          ⌈ 
         
         
         
           w 
          
         
           M 
          
         
        
          ⌉ 
         
        
       
      
        \left\lceil\frac{h}{M}\right\rceil \times\left\lceil\frac{w}{M}\right\rceil 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.23012em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌈</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.880108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌉</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.20001em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌈</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.695392em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌉</span></span></span></span></span></span></span>个Windows上升至<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ⌈ 
         
         
         
           h 
          
         
           M 
          
         
        
          + 
         
        
          1 
         
        
          ⌉ 
         
        
       
         × 
        
        
        
          ⌈ 
         
         
         
           w 
          
         
           M 
          
         
        
          + 
         
        
          1 
         
        
          ⌉ 
         
        
       
      
        \left\lceil\frac{h}{M}+1\right\rceil \times\left\lceil\frac{w}{M}+1\right\rceil 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.23012em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌈</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.880108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌉</span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.20001em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌈</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.695392em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌉</span></span></span></span></span></span></span>，并且其中很多windows的大小也不足<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         M 
        
       
         ∗ 
        
       
         M 
        
       
      
        M*M 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span></span></span></span></span>，具体可以参见原论文中的Figure 2。</p> 
<h5><a id="Naive_Solution_184"></a>Naive Solution</h5> 
<p>比较Naive的一种解决方法如下图所示：<br> <img src="https://images2.imgbox.com/27/6d/QQo4alQP_o.png" alt="Naive Solution"><br> 可以看出这种解决方法的缺点在于额外计算了很多padding的部分，浪费了大量计算。</p> 
<h5><a id="Batch_Computation_Approach_188"></a>Batch Computation Approach</h5> 
<p>为此，SwinTransformer采用了一个更为高效的Batch Computation Approach。<br> <img src="https://images2.imgbox.com/4d/ba/DTI8U81A_o.png" alt="Efficient Batch Computation Approach"><br> 这一部分在论文中并没有详细说明，仅仅通过上图进行了展示，其实整体思想就是：通过设定特殊的mask，在Attention时，仅对一个window内的有效部分进行Attention，其余部分被mask掉，即可实现在原来计算Attention方法不变的情况下，对非规则的Window计算Attention。<br> 具体方法，我将结合官方提供的代码一步步推导展示出来。</p> 
<h6><a id="Mask_193"></a>Mask计算结果手工推导</h6> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">window_partition</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> window_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Args:
        x: (B, H, W, C)
        window_size (int): window size

    Returns:
        windows: (num_windows*B, window_size, window_size, C)
    """</span>
    B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> W <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
    windows <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
    <span class="token keyword">return</span> windows

<span class="token comment"># calculate attention mask for SW-MSA</span>
Hp <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>H <span class="token operator">/</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size
Wp <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>W <span class="token operator">/</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size
img_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> Hp<span class="token punctuation">,</span> Wp<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>  <span class="token comment"># 1 Hp Wp 1</span>
h_slices <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w_slices <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
cnt <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> h <span class="token keyword">in</span> h_slices<span class="token punctuation">:</span>
    <span class="token keyword">for</span> w <span class="token keyword">in</span> w_slices<span class="token punctuation">:</span>
        img_mask<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> cnt
        cnt <span class="token operator">+=</span> <span class="token number">1</span>

mask_windows <span class="token operator">=</span> window_partition<span class="token punctuation">(</span>img_mask<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>  <span class="token comment"># nW, window_size, window_size, 1</span>
mask_windows <span class="token operator">=</span> mask_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>
attn_mask <span class="token operator">=</span> mask_windows<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span> mask_windows<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
attn_mask <span class="token operator">=</span> attn_mask<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>attn_mask <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>attn_mask <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>以上几行即为Mask的计算代码，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         H 
        
       
      
        H 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         W 
        
       
      
        W 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span></span></span></span></span>即为输入feature map的高和宽。window_size即为window的大小，也就是论文中的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         M 
        
       
      
        M 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span></span></span></span></span>，shift_size为窗口移动的大小，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         s 
        
       
         h 
        
       
         i 
        
       
         f 
        
       
         t 
        
       
         _ 
        
       
         s 
        
       
         i 
        
       
         z 
        
       
         e 
        
       
         = 
        
        
        
          ⌊ 
         
         
         
           M 
          
         
           2 
          
         
        
          ⌋ 
         
        
       
      
        shift\_size=\left\lfloor\frac{M}{2}\right\rfloor 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.00444em; vertical-align: -0.31em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">h</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right: 0.02778em;">_</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.22234em; vertical-align: -0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.872331em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">⌋</span></span></span></span></span></span></span>，self是对象，可以忽略。<br> 详细说明见下图：<br> <img src="https://images2.imgbox.com/d9/09/k0wSqT75_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9f/37/uWuzwxxI_o.png" alt="Attn Mask推导"><br> <img src="https://images2.imgbox.com/d9/d9/yLmUdIpb_o.png" alt="Attention Mask推导"><br> 其他的window对应的Attention Mask可以采用上述类似的逻辑推导出其具体值。<br> 下图依次为window (1)，window (2)，window (3)，window (4)对应的attn mask的示意图：<br> <img src="https://images2.imgbox.com/48/05/TrFz2Dxf_o.png" alt="在这里插入图片描述"> <img src="https://images2.imgbox.com/e6/47/YyEnL9tf_o.png" alt="请添加图片描述"> <img src="https://images2.imgbox.com/85/c2/9WKEDaBo_o.png" alt="请添加图片描述"> <img src="https://images2.imgbox.com/91/65/Am60yHoL_o.png" alt="请添加图片描述"><br> 其中黑色表示fill为-100的值，灰色表示fill为0的值。<br> 可以看出对于window(2)来说，确实如同我们推导的结果一样，是一个棋盘状的结构。</p> 
<h6><a id="Mask_240"></a>Mask作用的手工推导</h6> 
<p>那么，这种Attention的结果到底意味着什么呢？<br> 下面我将推导window(2)对应的这种棋盘状的mask的作用。<br> <img src="https://images2.imgbox.com/ac/d2/ESPE8oU0_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/f7/3e/dprxC4Z3_o.png" alt="在这里插入图片描述"><br> 同理可以完成其他Attention Mask作用的推导。<br> 至此，我们完成了SwinTransformer Mask计算结果的推导及其实现的作用的推导。</p> 
<h4><a id="4Relative_Position_Bias_246"></a>（4）Relative Position Bias</h4> 
<p>在计算Self-Attention的过程中，SwinTransformer也加入了相对位置编码的部分。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Attention 
         
        
          ⁡ 
         
        
          ( 
         
        
          Q 
         
        
          , 
         
        
          K 
         
        
          , 
         
        
          V 
         
        
          ) 
         
        
          = 
         
        
          SoftMax 
         
        
          ⁡ 
         
         
         
           ( 
          
         
           Q 
          
          
          
            K 
           
          
            T 
           
          
         
           / 
          
          
          
            d 
           
          
         
           + 
          
         
           B 
          
         
           ) 
          
         
        
          V 
         
        
       
         \operatorname{Attention}(Q, K, V)=\operatorname{SoftMax}\left(Q K^{T} / \sqrt{d}+B\right) V 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">A</span><span class="mord mathrm">t</span><span class="mord mathrm">t</span><span class="mord mathrm">e</span><span class="mord mathrm">n</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">o</span><span class="mord mathrm">n</span></span><span class="mopen">(</span><span class="mord mathdefault">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.80002em; vertical-align: -0.65002em;"></span><span class="mop"><span class="mord mathrm">S</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right: 0.07778em;">f</span><span class="mord mathrm">t</span><span class="mord mathrm">M</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord mathdefault">Q</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.891331em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.981095em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord" style="padding-left: 0.833em;"><span class="mord mathdefault">d</span></span></span><span class="" style="top: -2.94109em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
             <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
              <path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"></path> 
             </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.058905em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault" style="margin-right: 0.05017em;">B</span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">V</span></span></span></span></span></span><br> 相对位置编码主要是为了解决Self-Attention中的排列不变性的问题，即不同顺序输入的tokens会得到一样的结果。<br> 相对位置编码也是值得一说的问题，就不在这篇博客里面细说了，后续再在其提出论文中详细进行讨论。</p> 
<h3><a id="43_Architecture_Variants_251"></a>4.3 Architecture Variants</h3> 
<p>SwinTransformer具有四个具体实例，Swin-B具有和Vit-B/DeiT-B相近的模型大小以及计算复杂度，除此之外还有Swin-T, Swin-S 和 Swin-L，其模型大小依次为Base模型的0.25×, 0.5× 和 2×倍。<br> <img src="https://images2.imgbox.com/c4/9a/wnO29Sm5_o.png" alt="SwinTransformer实例"></p> 
<h2><a id="5_Evaluation_254"></a>5. Evaluation</h2> 
<h3><a id="1_255"></a>（1）对比实验</h3> 
<p>SwinTransformer主要进行了分类、检测以及分割任务的实验。<br> <img src="https://images2.imgbox.com/fd/37/bEKs8shD_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/84/e1/pazoDzQ1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c2/93/PAk7wmi0_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_260"></a>（2）消融实验</h3> 
<p><img src="https://images2.imgbox.com/ab/16/CgClMDMF_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/92/c6/70b4nt7K_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="6_Conclusion_263"></a>6. Conclusion</h2> 
<p>SwinTransformer通过计算LocalAttention，极大地降低了密集预测任务中Transformer的计算量，同时采用了一种Shift Window的策略，引入Local Windows间的联系，增强了其建模能力，并且在分类、检测以及分割等多个任务上都取得了很好的结果。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c3ef237b56ed0eb5ce95623967376ad2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">简单的创建一个小型服务器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/64e6af016b6a7b16bba5d78dfbf0fbb9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LVGL7.11中使用freetype库加载显示字体</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>