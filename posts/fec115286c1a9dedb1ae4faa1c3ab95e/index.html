<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【动手学深度学习PyTorch版】14 卷积层里的多输入多输出通道 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【动手学深度学习PyTorch版】14 卷积层里的多输入多输出通道" />
<meta property="og:description" content="目录
一、卷积层里的多输入多输出通道
1.1 多输入多输出通道
◼ 多个输入通道
◼ 多输出通道
◼ 1*1卷积核
◼ 二维卷积层
◼ 总结
二、代码实现
2.1 输入与输出（使用自定义）
◼ 多输入多输出通道互相关运算
2.2 1X1卷积（使用自定义）
2.3 1X1卷积（使用框架）
一、卷积层里的多输入多输出通道 1.1 多输入多输出通道 ◼ 多个输入通道 通常来说，我们会用到彩色图片，彩色图像一般是由RGB三个通道组成的。彩色图片一般会有更加丰富的信息。
但是转换为灰度会丢失信息，所以在图片的表示中通道数应该是3。我们之前都是只用了一个通道，简单图片对于单通道来说还是ok的，但是对于复杂图像就不行了。
假设图片的大小为200x200，那么图像的张量表示应该是200x200x3，不仅仅是一个简单的矩阵了。
当输入有了多个通道之后，假设有2个通道，Input中，前面的是通道0，后面是通道1。那么每个通道就会需要一个卷积核，比如针对通道0的卷积核对通道0做卷积，针对通道1的卷积核对通道1做卷积。再按元素相加，得到我们最终的结果。
① 核的通道数与输入的通道数一样。如果有多个通道，每一个通道都有一个卷积核，结果是所有通道卷积结果的和。
我们假设：
卷积核也会对应的变成三维的矩阵，但是输出是一个单通道，因为不管输入是多少通道，输出是把结果相加之后产生的。也就是说对每一个通道，把它对应的输入和对应的核做卷积，再按元素相加起来，得到输出。
◼ 多输出通道 无论有多少通道的输入，到目前为止不论有多少输入通道，我们只会得到单输出通道。
如果我们希望输出是多维的，得到多输出通道该怎么办呢？
做法是对每一个输出都有一个自己的三维的卷积核，总共设置多个三维的卷积核，每一个卷积核计算出来的结果作为一个通道，把每一个通道一一做运算，再把它们concat起来得到我们的输出。
相比于之前单输出通道多了一个参数Co。输出通道数，即卷积核的个数是卷积层的另一个超参数。
输出里面的第i个通道，其实就是完整的输入X与对应第i个核，做多输入的卷积，然后对所有的i做遍历。
这样就得到了多输出通道的结果。
那为什么要这么做呢？
我们可以认为每一个通道识别出来的都是一些特殊的模式，这是输出通道干的事情。
多输入通道干什么呢？假设我把这6个通道丢给下一层，下一层要把这每个模式识别出来并组合起来，得到一个组合的模式序列。
当然， 每一层有多个输出通道时至关重要的。
在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分别率以获得更大的通道深度。
比如说，我们可以先识别猫的胡须，耳朵，再往上走的话，把这些纹理组合起来，在上层的一些卷积层可能就是识别的猫头。
直观地说，我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。
因此，多输出通道并不仅是学习多个单通道的检测器。
◼ 1*1卷积核 (1,1)的卷积核是一个常用的卷积核，它并不能识别空间信息，它的作用是融合通道。
因为1x1卷积层每次只识别一个像素，而不查看该像素与周围像素的关系，所以它并不识别空间信息。
等价于把整个NhxNw的输入拉成一个长为NhNw的向量，也就是说空间信息没有了，然后通道数拉成特征数Ci。将卷积核重新写成CoxCi，等价于输入为NhxNwxCi，权重为CoxCi的全连接层。
◼ 二维卷积层 模型存储挺小的，但是计算量不一定小。
◼ 总结 二、代码实现 2.1 输入与输出（使用自定义） ◼ 多输入多输出通道互相关运算 （1）实现一下多输入通道互相关运算：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/fec115286c1a9dedb1ae4faa1c3ab95e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-27T09:14:49+08:00" />
<meta property="article:modified_time" content="2022-10-27T09:14:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【动手学深度学习PyTorch版】14 卷积层里的多输入多输出通道</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%8D%B7%E7%A7%AF%E5%B1%82%E9%87%8C%E7%9A%84%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%8D%B7%E7%A7%AF%E5%B1%82%E9%87%8C%E7%9A%84%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93" rel="nofollow">一、卷积层里的多输入多输出通道</a></p> 
<p id="1.1-toc" style="margin-left:40px;"><a href="#1.1" rel="nofollow">1.1 多输入多输出通道</a></p> 
<p id="%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87" rel="nofollow">◼ 多个输入通道</a></p> 
<p id="%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87" rel="nofollow">◼ 多输出通道</a></p> 
<p id="%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87" rel="nofollow">◼ 1*1卷积核</a></p> 
<p id="%E2%97%BC%20%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82" rel="nofollow">◼ 二维卷积层</a></p> 
<p id="%E2%97%BC%20%E6%80%BB%E7%BB%93-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E6%80%BB%E7%BB%93" rel="nofollow">◼ 总结</a></p> 
<p id="%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87-toc" style="margin-left:0px;"><a href="#%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87" rel="nofollow">二、代码实现</a></p> 
<p id="2.1%20%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89-toc" style="margin-left:40px;"><a href="#2.1%20%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89" rel="nofollow">2.1 输入与输出（使用自定义）</a></p> 
<p id="%E2%97%BC%20%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97-toc" style="margin-left:80px;"><a href="#%E2%97%BC%20%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97" rel="nofollow">◼ 多输入多输出通道互相关运算</a></p> 
<p id="2.2%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89-toc" style="margin-left:40px;"><a href="#2.2%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89" rel="nofollow">2.2 1X1卷积（使用自定义）</a></p> 
<p id="2.3%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%EF%BC%89-toc" style="margin-left:40px;"><a href="#2.3%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%EF%BC%89" rel="nofollow">2.3 1X1卷积（使用框架）</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%8D%B7%E7%A7%AF%E5%B1%82%E9%87%8C%E7%9A%84%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93">一、卷积层里的多输入多输出通道</h2> 
<h3 id="1.1">1.1 多输入多输出通道</h3> 
<h4 id="%E2%97%BC%20%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87">◼ 多个输入通道</h4> 
<p>通常来说，我们会用到彩色图片，彩色图像一般是由RGB三个通道组成的。彩色图片一般会有更加丰富的信息。</p> 
<p>但是转换为灰度会丢失信息，所以在图片的表示中通道数应该是3。我们之前都是只用了一个通道，简单图片对于单通道来说还是ok的，但是对于复杂图像就不行了。</p> 
<p><img alt="" height="376" src="https://images2.imgbox.com/bc/94/ZWWBhWdH_o.png" width="1200"></p> 
<p><img alt="" height="394" src="https://images2.imgbox.com/66/16/gelPkmsE_o.png" width="1200"> 假设图片的大小为200x200，那么图像的张量表示应该是200x200x3，不仅仅是一个简单的矩阵了。</p> 
<p>当输入有了多个通道之后，假设有2个通道，Input中，前面的是通道0，后面是通道1。那么每个通道就会需要一个卷积核，比如针对通道0的卷积核对通道0做卷积，针对通道1的卷积核对通道1做卷积。再按元素相加，得到我们最终的结果。</p> 
<blockquote> 
 <p>① 核的通道数与输入的通道数一样。如果有多个通道，每一个通道都有一个卷积核，结果是所有通道卷积结果的和。</p> 
</blockquote> 
<p><img alt="" height="492" src="https://images2.imgbox.com/b0/40/24wQql5C_o.png" width="1200"></p> 
<p>我们假设：</p> 
<p><img alt="" height="422" src="https://images2.imgbox.com/c8/03/dSTNGRU3_o.png" width="1200"></p> 
<p>卷积核也会对应的变成三维的矩阵，但是输出是一个单通道，因为不管输入是多少通道，输出是把结果相加之后产生的。也就是说对每一个通道，把它对应的输入和对应的核做卷积，再按元素相加起来，得到输出。</p> 
<h4>◼ 多输出通道</h4> 
<p>无论有多少通道的输入，到目前为止不论有多少输入通道，我们只会得到单输出通道。</p> 
<p>如果我们希望输出是多维的，得到多输出通道该怎么办呢？</p> 
<p><strong>做法</strong>是对每一个输出都有一个自己的三维的卷积核，总共设置多个三维的卷积核，每一个卷积核计算出来的结果作为一个通道，把每一个通道一一做运算，再把它们concat起来得到我们的输出。</p> 
<p>相比于之前单输出通道多了一个参数Co。输出通道数，即卷积核的个数是卷积层的另一个超参数。</p> 
<p><img alt="" height="220" src="https://images2.imgbox.com/73/03/WOCVlZ86_o.png" width="1200"></p> 
<p>输出里面的第i个通道，其实就是完整的输入X与对应第i个核，做多输入的卷积，然后对所有的i做遍历。</p> 
<p><img alt="" height="89" src="https://images2.imgbox.com/e6/8a/bjadQxdM_o.png" width="1200"></p> 
<p>这样就得到了多输出通道的结果。</p> 
<p>那为什么要这么做呢？</p> 
<p>我们可以认为每一个通道识别出来的都是一些特殊的模式，这是输出通道干的事情。</p> 
<p><img alt="" height="166" src="https://images2.imgbox.com/2c/26/PSLCpYBm_o.png" width="1200"></p> 
<p>多输入通道干什么呢？假设我把这6个通道丢给下一层，下一层要把这每个模式识别出来并组合起来，得到一个组合的模式序列。</p> 
<p>当然， 每一层有多个输出通道时至关重要的。</p> 
<p>在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分别率以获得更大的通道深度。</p> 
<p>比如说，我们可以先识别猫的胡须，耳朵，再往上走的话，把这些纹理组合起来，在上层的一些卷积层可能就是识别的猫头。</p> 
<p>直观地说，我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。</p> 
<p>因此，多输出通道并不仅是学习多个单通道的检测器。</p> 
<h4>◼ 1*1卷积核</h4> 
<p>(1,1)的卷积核是一个常用的卷积核，它并不能识别空间信息，它的作用是融合通道。</p> 
<p>因为1x1卷积层每次只识别一个像素，而不查看该像素与周围像素的关系，所以它并不识别空间信息。</p> 
<p><img alt="" height="331" src="https://images2.imgbox.com/bc/88/0XPyoGQ6_o.png" width="1200"></p> 
<p>等价于把整个NhxNw的输入拉成一个长为NhNw的向量，也就是说空间信息没有了，然后通道数拉成特征数Ci。将卷积核重新写成CoxCi，等价于输入为NhxNwxCi，权重为CoxCi的全连接层。</p> 
<h4 id="%E2%97%BC%20%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82">◼ 二维卷积层</h4> 
<p><img alt="" height="487" src="https://images2.imgbox.com/b3/9f/Xk8mmFbp_o.png" width="1200"></p> 
<p> 模型存储挺小的，但是计算量不一定小。</p> 
<h4 id="%E2%97%BC%20%E6%80%BB%E7%BB%93">◼ 总结</h4> 
<p><img alt="" height="277" src="https://images2.imgbox.com/4d/b4/n2mMS6mo_o.png" width="1200"></p> 
<p></p> 
<h2>二、代码实现</h2> 
<h3 id="2.1%20%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89">2.1 输入与输出（使用自定义）</h3> 
<h4 id="%E2%97%BC%20%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97">◼ 多输入多输出通道互相关运算</h4> 
<p>（1）实现一下多输入通道互相关运算：</p> 
<p>假设X和K是3D的，将X和K zip起来，每次zip就会对输入通道的维数进行遍历，即每次for拿出对应的输入通道里的那个小矩阵，然后把它做互运算，对所有通道求和。</p> 
<pre><code class="language-python">import torch 
from d2l import torch as d2l

def corr2d_multi_in(X, K):
    return sum(d2l.corr2d(x, k) for x,k in zip(X,K))</code></pre> 
<p>（2）验证互相关运算的输出：</p> 
<pre><code class="language-python"># 这是多通道输入（2，3，3），单通道输出（2，2），两个核（2，2）
# 一个核对应一个通道
X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])

corr2d_multi_in(X, K)
</code></pre> 
<p>（3）计算多个通道的输出的互相关函数：</p> 
<p>假设X是3D的，K是4D的，最外层是输出通道数。</p> 
<p>对每一个输出通道的K拿出它对应的3D核K。</p> 
<p>现在一个核有多个通道，每一个核的形状是（2, 2, 2），共有三个核（3，2，2，2）。</p> 
<p>一个卷积核经过一次操作后会得到单通道的输出（2，2），下面这个操作就是让每一个卷积核得到的一个通道的输出，堆叠起来----------（3，2，2）。</p> 
<pre><code class="language-python"># 计算多个通道的输入输出
def corr2d_multi_in_out(X,K):
    # 现在一个核有多个通道，每一个核的形状是（2, 2, 2），共有三个核（3，2，2，2）
    # 一个卷积核经过一次操作后会得到单通道的输出（2，2）
    # 下面这个操作就是让每一个卷积核得到的一个通道的输出，堆叠起来。（3，2，2）
    return torch.stack([corr2d_multi_in(X,k) for k in K])

# 创建三个卷积核
K = torch.stack((K, K + 1, K + 2), 0)
print(type(K))
# print(K.shape)

corr2d_multi_in_out(X,K)
</code></pre> 
<p><img alt="" height="687" src="https://images2.imgbox.com/69/7d/F1LZ5eJn_o.png" width="1200"></p> 
<pre><code class="language-python">help(torch.stack)</code></pre> 
<p><img alt="" height="540" src="https://images2.imgbox.com/d5/00/ZESJKkP8_o.png" width="1200"></p> 
<p></p> 
<h3 id="2.2%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%EF%BC%89">2.2 1X1卷积（使用自定义）</h3> 
<p>验证1X1卷积等价于一个全连接？</p> 
<ul><li>创建3x3的数入X；</li><li>K：输出通道为2，输入通道为3，核为1x1；</li></ul> 
<pre><code class="language-python"># 1*1的卷积核
def corr2d_multi_in_out_1x1(X, K):
    c_i,h,w = X.shape
    c_o = K.shape[0]    # K的第一个shape
    # 这里就是将一张图片的高和宽展平成一条直线(3, 3, 3) =&gt; (3,9)
    # 剩下（channel_num，input）
    X = X.reshape((c_i,h*w))    # c_i是通道数
    # 把卷积核的高和宽展平成一条直线(2, 3, 1, 1) =&gt; (2,3)，剩下（kernel_num, kernnel），就变成了一个矩阵
    K = K.reshape((c_o,c_i))    # 这样，X和K都是一个矩阵了
    Y = torch.matmul(K,X)    # 那么直接调用矩阵乘法，将K*X
    print(X.shape,K.shape,Y.shape)
    return Y.reshape((c_o, h, w))    # 最后的Y

X = torch.normal(0, 1, (3, 3, 3))
K = torch.normal(0, 1, (2, 3, 1, 1))    # 输出通道为2，输入通道为3，核为1x1

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
assert float(torch.abs(Y1 - Y2).sum()) &lt; 1e-6  # 如果小于1e-6，可以认为几乎完全一样 
</code></pre> 
<p><img alt="" height="652" src="https://images2.imgbox.com/15/b2/xyOyiy6w_o.png" width="1200"></p> 
<p></p> 
<h3 id="2.3%201X1%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%EF%BC%89">2.3 1X1卷积（使用框架）</h3> 
<pre><code class="language-python">def comp_conv2d(conv2d, X): # conv2d 作为传参传进去，在内部使用
    X = X.reshape((1,1)+X.shape) # 在维度前面加入一个通道数和批量大小数
    Y = conv2d(X)  # 卷积处理是一个四维的矩阵
    return Y.reshape(Y.shape[2:]) # 将前面两个维度拿掉

X = torch.rand(size=(8,8))
conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2) # Pytorch里面卷积函数的第一个参数为输出通道，第二个参数为输入通道   
print(comp_conv2d(conv2d,X).shape) 

conv2d = nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4)) # 一个稍微复杂的例子
print(comp_conv2d(conv2d,X).shape)</code></pre> 
<p><img alt="" height="500" src="https://images2.imgbox.com/22/81/80mYGDGo_o.png" width="1200"></p> 
<p>输入的高宽都减半的情况下，通常会把输出的通道数加一倍。（空间信息压缩了，把提取出来的信息保存在更多的通道里）。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/905d4857ff38ba7d2e208ad71ccc7af7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Redis基本使用！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/592330ddad0d4285b2b0294c486e7f3e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Typescript中的工具类型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>