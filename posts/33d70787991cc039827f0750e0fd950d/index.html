<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>计算机图形学七渲染管线和着色器Rendering Pipeline And Shader - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="计算机图形学七渲染管线和着色器Rendering Pipeline And Shader" />
<meta property="og:description" content="图形渲染管线和着色器Rendering Pipeline And Shader 前言：什么是管线？
管线我们可以理解为流水线，流水线大家都懂，就是工厂里面生产东西的一整套流程。例如饮料厂要生产饮料，需要洗瓶子，倒饮料，加盖，包装等等，这一整套过程就是流水线。
那我们要把一个三维场景渲染成二维图像，同样需要一个先干嘛再干嘛最后干嘛的一个过程，这个过程就成为管线。
图形渲染管线（Graphics Rendering Pipeline） 我们知道了要把一个三维场景渲染成一个二维的图像大致分为以下几个步骤：
1.MVP变换和齐次裁剪，透视除法，视口变换，把三维场景变得屏幕空间大小一样（但此时还是一个3D的）2.光栅化，把物体离散成一个个像素，在屏幕上显示出来。3.深度缓存，根据每个像素做深度缓存。4.着色，根据着色频率的不同，不同的着色会在不同的时间点进行。 对于这一套流程，我们就可以称之为实时渲染管线，大致整理一下可以得到下面的流程图：
Vertex Stream 我们的MVP变换，视口变换实则是对物体表面也就是Mesh中的每个三角形的顶点进行变换，这部操作我们可以称之为Vertex Processing，操作的内容都是顶点，即vertex stream。
同时我们之前所说的高洛德着色就是在这里进行操作的，因为高洛德着色处理的就是顶点。
Triangle Stream 顶点变换好之后，我们自然就可以听过这些顶点组成三角形，指定三个顶点即可连成一个三角形，即可得到所有三角形面，即Triangle Stream，这步操作称之为Triangle Processing；
Fragment Stream 然后我们就要把这些三角形进行光栅化，离散成一个个像素。在OpenGL当中引入了Fragment的概念，我们可以理解为一个采样点所覆盖的区域即为一个Fragment，若我们对一个像素进行一次采样，那么Fragment就是一个像素，但是如果我们做MSAA操作，例如在一个像素选取四个点进行采样，那么这个像素就有四个Fragment。
每个Fragment 都会记录颜色，深度，透明度等信息，所以说MSAA的显存和带宽开销会加倍，但是渲染计算时还是只运行一次fragment shader，这就是MSAA与SSAA的区别，详情可见之前的文章。
本文我们就简单的吧一个Fragment 当做是一个像素。因此在光栅化操作（Rasterization）中，我们得到的即是Fragment的集合（Fragment Stream）
然后我们的深度缓存，以及冯氏着色都是针对每个Fragment进行处理的，这些相关操作我们称之为Fragment Processing。在这里通过重心坐标我们就可以知道每个Fragment对应的颜色，从而得到每个像素对应的颜色。
(PS:在片元处理阶段，除了使用Blinn-Phong之外，我们还可以去做texture mapping，利用texture的信息来代替blinn-phong模型漫反射系数来当做颜色）
这样，我们的一个管线就走完了，即可得到我们最终的结果，也就是一副二维的图像。
当然了，上面的介绍仅仅是一个大致的说明，实际上的渲染管线要复杂的更多，并且在不同的图形API里，整个过程也是有所不同的，甚至在相同的图形API里，随着版本的迭代，渲染管线也在不断的更新。
Shader 上面所说的管线，都是在我们GPU里制定好的，但是在现代的GPU里，允许Vertex Processing和Fragment Processing这两部分是可编程的。也就是说我们可以通过自己写代码来控制它们是怎么着色的，而这部分代码就是Shader。
Shader本身是一个能在GPU上执行的模块，作用在Vertex Processing的我们称之为Vertex Shader，作用在Fragment Processing的我们称之为Fragment Shader。
从基本意义上来说，Shader只是一种把输入转化为输出的程序，也是一种非常独立的程序，因为它们之间不能相互通信；它们之间唯一的沟通只有通过输入和输出。
Vertex Shader的输入即是顶点的属性，而它的输出往往会作为Fragment Shader的输入，Fragment Shader输出则是一个颜色值，代表每个像素的最终颜色。
我们可以使用我们常说的那些图形API（例如OpenGL和DirectX）来编写Shader，目前主要有3种语言：
1.基于OpenGL的OpenGL Shading Language，简称GLSL。
2.基于DirectX的High Level Shading Language，简称HLSL。
3.NVIDIA公司的C for Graphic，简称Cg语言。
OpenGL和DirectX属于敌对的关系，我们可以把GLSL转换为HLSL。而Cg语言（C for Graphic）是为GPU编程设计的高级着色语言，可以被OpenGL和Direct3D广泛支持的图形处理器编程语言。因此Cg语言和GLSL、HLSL并不是同一层次的语言，而是它们的上层，即Cg程序是运行在OpenGL和DirectX标准顶点和像素着色的基础上的。Cg由NVIDIA公司和微软公司相互协作在标准硬件光照语言的语法和语义上达成了一致开发，所以HLSL和Cg其实是同一种语言。虽然它目前还在被使用，但是已停止了更新（https://developer.nvidia.com/cg-toolkit）。
接下来我们来简单的介绍下OpenGL和DirectX它们的渲染管线以及shader。
OpenGL OpenGL（Open Graphics Library）是一个定义了跨编程语言、跨平台的编程接口规格的专业图形程序接口。它用于二维/三维图像，是一个功能强大，调用方便的底层图形库，是行业领域中最为广泛接纳的2D/3D图形API。OpenGL是一个与硬件无关的软件接口，可以在不同的平台如Windows、Linux、MacOS之间进行移植。因此，支持OpenGL的软件具有很好的移植性，可以获得非常广泛的应用。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/33d70787991cc039827f0750e0fd950d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-08T01:22:01+08:00" />
<meta property="article:modified_time" content="2023-08-08T01:22:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">计算机图形学七渲染管线和着色器Rendering Pipeline And Shader</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Rendering_Pipeline_And_Shader_0"></a>图形渲染管线和着色器Rendering Pipeline And Shader</h3> 
<p>前言：什么是管线？</p> 
<p>管线我们可以理解为流水线，流水线大家都懂，就是工厂里面生产东西的一整套流程。例如饮料厂要生产饮料，需要洗瓶子，倒饮料，加盖，包装等等，这一整套过程就是流水线。<br> 那我们要把一个三维场景渲染成二维图像，同样需要一个先干嘛再干嘛最后干嘛的一个过程，这个过程就成为管线。</p> 
<h3><a id="Graphics_Rendering_Pipeline_5"></a>图形渲染管线（Graphics Rendering Pipeline）</h3> 
<p>我们知道了要把一个三维场景渲染成一个二维的图像大致分为以下几个步骤：</p> 
<blockquote> 
 <ul><li>1.MVP变换和齐次裁剪，透视除法，视口变换，把三维场景变得屏幕空间大小一样（但此时还是一个3D的）</li><li>2.光栅化，把物体离散成一个个像素，在屏幕上显示出来。</li><li>3.深度缓存，根据每个像素做深度缓存。</li><li>4.着色，根据着色频率的不同，不同的着色会在不同的时间点进行。</li></ul> 
</blockquote> 
<p>对于这一套流程，我们就可以称之为实时渲染管线，大致整理一下可以得到下面的流程图：<br> <img src="https://images2.imgbox.com/62/cf/HIZsrx4c_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Vertex_Stream_15"></a>Vertex Stream</h4> 
<p>我们的MVP变换，视口变换实则是对物体表面也就是Mesh中的每个三角形的顶点进行变换，这部操作我们可以称之为Vertex Processing，操作的内容都是顶点，即vertex stream。<br> 同时我们之前所说的高洛德着色就是在这里进行操作的，因为高洛德着色处理的就是顶点。</p> 
<h4><a id="Triangle_Stream_19"></a>Triangle Stream</h4> 
<p>顶点变换好之后，我们自然就可以听过这些顶点组成三角形，指定三个顶点即可连成一个三角形，即可得到所有三角形面，即Triangle Stream，这步操作称之为Triangle Processing；</p> 
<h4><a id="Fragment_Stream_22"></a>Fragment Stream</h4> 
<p>然后我们就要把这些三角形进行光栅化，离散成一个个像素。在OpenGL当中引入了Fragment的概念，我们可以理解为<strong>一个采样点所覆盖的区域即为一个Fragment</strong>，若我们对一个像素进行一次采样，那么Fragment就是一个像素，但是如果我们做MSAA操作，例如在一个像素选取四个点进行采样，那么这个像素就有四个Fragment。<br> 每个Fragment 都会记录颜色，深度，透明度等信息，所以说MSAA的显存和带宽开销会加倍，但是渲染计算时还是只运行一次fragment shader，这就是MSAA与SSAA的区别，详情可见之前的文章。<br> 本文我们就简单的吧一个Fragment 当做是一个像素。因此在光栅化操作（Rasterization）中，我们得到的即是Fragment的集合（Fragment Stream）<br> 然后我们的深度缓存，以及冯氏着色都是针对每个Fragment进行处理的，这些相关操作我们称之为Fragment Processing。<strong>在这里通过重心坐标我们就可以知道每个Fragment对应的颜色，从而得到每个像素对应的颜色。</strong><br> <strong>(PS:在片元处理阶段，除了使用Blinn-Phong之外，我们还可以去做texture mapping，利用texture的信息来代替blinn-phong模型漫反射系数来当做颜色）</strong></p> 
<p>这样，我们的一个管线就走完了，即可得到我们最终的结果，也就是一副二维的图像。<br> 当然了，上面的介绍仅仅是一个大致的说明，实际上的渲染管线要复杂的更多，并且在不同的图形API里，整个过程也是有所不同的，甚至在相同的图形API里，随着版本的迭代，渲染管线也在不断的更新。</p> 
<h3><a id="Shader_32"></a>Shader</h3> 
<p>上面所说的管线，都是在我们GPU里制定好的，但是在现代的GPU里，允许Vertex Processing和Fragment Processing这两部分是可编程的。也就是说我们可以通过自己写代码来控制它们是怎么着色的，而这部分代码就是Shader。</p> 
<p>Shader本身是一个能在GPU上执行的模块，作用在Vertex Processing的我们称之为<strong>Vertex Shader</strong>，作用在Fragment Processing的我们称之为<strong>Fragment Shader</strong>。</p> 
<p>从基本意义上来说，Shader只是一种把输入转化为输出的程序，也是一种非常独立的程序，<strong>因为它们之间不能相互通信；它们之间唯一的沟通只有通过输入和输出</strong>。<br> Vertex Shader的输入即是顶点的属性，而它的输出往往会作为Fragment Shader的输入，Fragment Shader输出则是一个颜色值，代表每个像素的最终颜色。</p> 
<p>我们可以使用我们常说的那些图形API（例如OpenGL和DirectX）来编写Shader，目前主要有3种语言：</p> 
<p>1.基于OpenGL的OpenGL Shading Language，简称GLSL。<br> 2.基于DirectX的High Level Shading Language，简称HLSL。<br> 3.NVIDIA公司的C for Graphic，简称Cg语言。</p> 
<p>OpenGL和DirectX属于敌对的关系，我们可以把GLSL转换为HLSL。而Cg语言（C for Graphic）是为GPU编程设计的高级着色语言，可以被OpenGL和Direct3D广泛支持的图形处理器编程语言。因此Cg语言和GLSL、HLSL并不是同一层次的语言，而是它们的上层，即Cg程序是运行在OpenGL和DirectX标准顶点和像素着色的基础上的。Cg由NVIDIA公司和微软公司相互协作在标准硬件光照语言的语法和语义上达成了一致开发，所以HLSL和Cg其实是同一种语言。虽然它目前还在被使用，但是已停止了更新（https://developer.nvidia.com/cg-toolkit）。</p> 
<p>接下来我们来简单的介绍下OpenGL和DirectX它们的渲染管线以及shader。</p> 
<h4><a id="OpenGL_50"></a>OpenGL</h4> 
<p>OpenGL（Open Graphics Library）是一个定义了跨编程语言、跨平台的编程接口规格的专业图形程序接口。它用于二维/三维图像，是一个功能强大，调用方便的底层图形库，是行业领域中最为广泛接纳的2D/3D图形API。OpenGL是一个与硬件无关的软件接口，可以在不同的平台如Windows、Linux、MacOS之间进行移植。因此，支持OpenGL的软件具有很好的移植性，可以获得非常广泛的应用。</p> 
<p>官方文档：<br> https://www.khronos.org/opengl/wiki/Main_Page<br> opengl下的渲染管线<img src="https://images2.imgbox.com/b9/0c/Uwl6w0yK_o.png" alt="在这里插入图片描述"><br> ​有关使用GLSL写Shader的学习，在官方文档里也有介绍，同时也可参考中文教程里的着色器部分。</p> 
<p>我们来看一个GLSL写的Fragment Shader的例子：</p> 
<pre><code class="prism language-cpp">uniform sampler2D myTexture<span class="token punctuation">;</span>
uniform vec3 lightDir<span class="token punctuation">;</span>
in vec2 uv<span class="token punctuation">;</span>
in vec3 norm<span class="token punctuation">;</span>
out vec4 FragColor<span class="token punctuation">;</span>

<span class="token keyword">void</span> <span class="token function">diffuseShader</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    vec3 kd<span class="token punctuation">;</span>
    kd <span class="token operator">=</span> <span class="token function">texture2d</span><span class="token punctuation">(</span>myTexture<span class="token punctuation">,</span> uv<span class="token punctuation">)</span><span class="token punctuation">;</span>
    kd <span class="token operator">*=</span> <span class="token function">clamp</span><span class="token punctuation">(</span><span class="token function">dot</span><span class="token punctuation">(</span><span class="token operator">-</span>lightDir<span class="token punctuation">,</span> norm<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    FragColor<span class="token operator">=</span> <span class="token function">vec4</span><span class="token punctuation">(</span>kd<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>首先是关键字<strong>uniform</strong>，uniform定义的是全局的变量，其值是外部application程序传递过来的。在例子中，我们用它定义了一个纹理和一个光照方向。</p> 
<p>然后是<strong>in</strong>，<strong>out</strong>，每个着色器使用这两个关键字设定输入和输出，只要一个输出变量与下一个着色器阶段的输入匹配，它就会传递下去。在例子中，我们用 in 定义了顶点对应的uv和法线，这些值在vertex shader里会 out 出来。然后用 out 定义了该片段最终的输出颜色。</p> 
<p>接下来就是函数体了，我们用该函数实现了一个简单的漫反射。函数里我们用texture2d函数根据uv坐标对纹理进行采样，得到的颜色存在kd变量里，这kd即我们漫反射公式里的系数。至于texture2d内部怎么实现的，这个我们不用管，OpenGL为我们做好了。但是通过纹理映射的学习，我们能够懂这块的原理就好了。然后我们把光的方向和法线方向点乘，即Lambert 余弦定率，得到的值和采样得到的颜色相乘，得到的结果就是我们光照影响后的漫反射结果，将其输出。（注：这里省略了光能量的传播，即少了 I/(r*r) 这一项）</p> 
<p>在我们的Shader中，我们并没有用循环来遍历所有的像素来一一着色，<strong>这是因为我们Shader里的操作是针对每个顶点和每个像素的</strong>，也就是说每个顶点都会执行一遍Vertex Shader，每个像素都会执行一遍Fragment Shader，我们只需要为它们写一个统一的逻辑即可，这样可以最大限度的发挥我们GPU的性能，即可以<strong>并行操作多个顶点或像素</strong>。</p> 
<p>可以发现在这个Fragment Shader里，涉及到的纹理映射，uv，漫反射，还有例如一些上面没提到的转换矩阵，都是图形学中所学习的，因此只要我们学好图形学，再来理解这些图形API，是很容易的。</p> 
<p>在OpenGL里，我们不仅可以自定义Vertex Shader和Fragment Shader，我们还可以自定义<strong>Tessellation Shader</strong>和<strong>Geometry Shader</strong>。</p> 
<p>Tessellation Shader为<strong>曲面细分着色器</strong>，发生在顶点处理阶段，我们可以用它生成新的顶点和面，即把一个三角形拆分为多个三角形。</p> 
<p>Geometry Shader为<strong>几何着色器</strong>，它的输入是一个图元（如点或三角形）的一组顶点。几何着色器可以在顶点发送到下一着色器阶段之前对它们随意变换。能够将（这一组）顶点变换为完全不同的图元，并且还能生成比原来更多的顶点。也就是说我们可以在这里改变几何的形状。<br> 可参考：https://learnopenglcn.github.io/04%20Advanced%20OpenGL/09%20Geometry%20Shader/</p> 
<h4><a id="Vulkan_93"></a>Vulkan</h4> 
<p>​Vulkan的Shader与之前的提到的都不同，Vulkan中的Shader代码必须以二进制字节码的格式使用，而不是像GLSL和HLSL这样具有比较好的可读性的语法。此字节格式成为SPIR-V。这样可使得GPU厂商编写将Shader转换为本地代码的编译器复杂度减少了很多。当然了，我们不需要手写这样的二进制文件，我们可以把GLSL文件编译成SPIR-V格式的。</p> 
<h4><a id="Compute_Shader_96"></a>Compute Shader(计算着色器）</h4> 
<p>如今还有更牛逼的Compute Shader，可用于高频的大量计算用于辅助渲染，例如一帧内要做成千上万次矩阵乘法。在它的帮助下，可直接将GPU作为并行处理器加以利用，GPU将不仅具有3D渲染能力，也具有其他的运算能力。</p> 
<p>在之前不管是OpenGL还是DirectX的渲染管线图里面，我们并看不见Compute Shader的身影，<strong>这是因为Compute Shader是独立于渲染管线之外。也就是说，Compute Shader是个完全独立的东西，你任何时候，不做渲染的时候，你都可以通过它来实现大量的计算，它有自己的管线，即Compute Rendering.</strong><br> <img src="https://images2.imgbox.com/7f/4e/0X9s3uLY_o.png" alt="在这里插入图片描述"><br> 在每个Render pipelines里面我们可以选择不同的Rendering path，一个Rendering path指的是一系列有关光照和阴影的操作，因此不同的Rendering path也会有不同的表现效果。选择哪个Rendering path主要看我们的项目需求以及硬件设备，常见的Rendering path有如下两种：</p> 
<p><strong>Forward Rendering：</strong><br> 正向渲染，它是我们渲染物体的一种非常直接的方式，在场景中我们根据所有光源照亮一个物体，之后再渲染下一个物体，以此类推。<br> 它非常容易理解，也很容易实现，但是同时它对程序性能的影响也很大，因为对于每一个需要渲染的物体，程序都要对每一个光源每一个需要渲染的片段进行迭代，这是非常多的！因为大部分片段着色器的输出都会被之后的输出覆盖，正向渲染还会在场景中因为高深的复杂度(多个物体重合在一个像素上)浪费大量的片段着色器运行时间。</p> 
<p><strong>Deferred Shading：</strong><br> 延迟渲染，为了解决Forward Rendering的问题而诞生了，它大幅度地改变了我们渲染物体的方式。这给我们优化拥有大量光源的场景提供了很多的选择，因为它能够在渲染上百甚至上千光源的同时还能够保持能让人接受的帧率。它需要硬件的支持。<br> 之后会开一篇着重讨论延迟渲染及其相关问题，还有forward+等问题。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/18a41b72bcd7858fe8a54db98aba649f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">42.利用 牛顿迭代法解非线性高维方程组（matlab程序）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6dc804a99113590da3b8b6f1f4f9cee8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">微信小程序：Mobx的使用指南</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>