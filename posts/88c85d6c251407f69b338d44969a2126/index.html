<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FlinkAPI开发之FlinkSQL - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FlinkAPI开发之FlinkSQL" />
<meta property="og:description" content="一.代码中使用FlinkSQL 需要引入的依赖 &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-api-java-bridge&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; 这里的依赖是一个Java的“桥接器”（bridge），主要就是负责Table API和下层DataStream API的连接支持，按照不同的语言分为Java版和Scala版。
如果我们希望在本地的集成开发环境（IDE）里运行Table API和SQL，还需要引入以下依赖：
&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-planner-loader&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-runtime&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-files&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; 二. 创建表环境 对于Flink这样的流处理框架来说，数据流和表在结构上还是有所区别的。所以使用Table API和SQL需要一个特别的运行时环境，这就是所谓的“表环境”（TableEnvironment）。它主要负责：
（1）注册Catalog和表； （2）执行 SQL 查询； （3）注册用户自定义函数（UDF）； （4）DataStream 和表之间的转换。 每个表和SQL的执行，都必须绑定在一个表环境（TableEnvironment）中。TableEnvironment是Table API中提供的基本接口类，可以通过调用静态的create()方法来创建一个表环境实例。方法需要传入一个环境的配置参数EnvironmentSettings，它可以指定当前表环境的执行模式和计划器（planner）。执行模式有批处理和流处理两种选择，默认是流处理模式；计划器默认使用blink planner。
批处理表环境 import org.apache.flink.table.api.EnvironmentSettings; import org.apache.flink.table.api.TableEnvironment; EnvironmentSettings settings = EnvironmentSettings .newInstance() .inStreamingMode() // 使用流处理模式 .build(); TableEnvironment tableEnv = TableEnvironment.create(setting); 流处理表环境 对于流处理场景，其实默认配置就完全够用了。所以我们也可以用另一种更加简单的方式来创建表环境：
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.table.api.EnvironmentSettings; import org.apache.flink.table.api.bridge.java.StreamTableEnvironment; // TODO: 2024/1/23 创建流式表环境 StreamExecutionEnvironment environment = StreamExecutionEnvironment." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/88c85d6c251407f69b338d44969a2126/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-24T13:17:14+08:00" />
<meta property="article:modified_time" content="2024-01-24T13:17:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FlinkAPI开发之FlinkSQL</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="FlinkSQL_0"></a>一.代码中使用FlinkSQL</h2> 
<h3><a id="_2"></a>需要引入的依赖</h3> 
<pre><code class="prism language-bash"><span class="token operator">&lt;</span>dependency<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>groupId<span class="token operator">&gt;</span>org.apache.flink<span class="token operator">&lt;</span>/groupId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>artifactId<span class="token operator">&gt;</span>flink-table-api-java-bridge<span class="token operator">&lt;</span>/artifactId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>version<span class="token operator">&gt;</span><span class="token variable">${flink.version}</span><span class="token operator">&lt;</span>/version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/dependency<span class="token operator">&gt;</span>
</code></pre> 
<p>这里的依赖是一个Java的“桥接器”（bridge），主要就是负责Table API和下层DataStream API的连接支持，按照不同的语言分为Java版和Scala版。<br> 如果我们希望在本地的集成开发环境（IDE）里运行Table API和SQL，还需要引入以下依赖：</p> 
<pre><code class="prism language-bash"><span class="token operator">&lt;</span>dependency<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>groupId<span class="token operator">&gt;</span>org.apache.flink<span class="token operator">&lt;</span>/groupId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>artifactId<span class="token operator">&gt;</span>flink-table-planner-loader<span class="token operator">&lt;</span>/artifactId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>version<span class="token operator">&gt;</span><span class="token variable">${flink.version}</span><span class="token operator">&lt;</span>/version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/dependency<span class="token operator">&gt;</span>

<span class="token operator">&lt;</span>dependency<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>groupId<span class="token operator">&gt;</span>org.apache.flink<span class="token operator">&lt;</span>/groupId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>artifactId<span class="token operator">&gt;</span>flink-table-runtime<span class="token operator">&lt;</span>/artifactId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>version<span class="token operator">&gt;</span><span class="token variable">${flink.version}</span><span class="token operator">&lt;</span>/version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/dependency<span class="token operator">&gt;</span>

<span class="token operator">&lt;</span>dependency<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>groupId<span class="token operator">&gt;</span>org.apache.flink<span class="token operator">&lt;</span>/groupId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>artifactId<span class="token operator">&gt;</span>flink-connector-files<span class="token operator">&lt;</span>/artifactId<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>version<span class="token operator">&gt;</span><span class="token variable">${flink.version}</span><span class="token operator">&lt;</span>/version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/dependency<span class="token operator">&gt;</span>
</code></pre> 
<h2><a id="__34"></a>二. 创建表环境</h2> 
<p>对于Flink这样的流处理框架来说，数据流和表在结构上还是有所区别的。所以使用Table API和SQL需要一个特别的运行时环境，这就是所谓的“表环境”（TableEnvironment）。它主要负责：</p> 
<pre><code class="prism language-bash">（1）注册Catalog和表；
（2）执行 SQL 查询；
（3）注册用户自定义函数（UDF）；
（4）DataStream 和表之间的转换。
</code></pre> 
<p>每个表和SQL的执行，都必须绑定在一个表环境（TableEnvironment）中。TableEnvironment是Table API中提供的基本接口类，可以通过调用静态的create()方法来创建一个表环境实例。方法需要传入一个环境的配置参数EnvironmentSettings，它可以指定当前表环境的执行模式和计划器（planner）。执行模式有批处理和流处理两种选择，默认是流处理模式；计划器默认使用blink planner。</p> 
<h3><a id="_47"></a>批处理表环境</h3> 
<pre><code class="prism language-bash"><span class="token function">import</span> org.apache.flink.table.api.EnvironmentSettings<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.TableEnvironment<span class="token punctuation">;</span>

EnvironmentSettings settings <span class="token operator">=</span> EnvironmentSettings
    .newInstance<span class="token punctuation">(</span><span class="token punctuation">)</span>
    .inStreamingMode<span class="token punctuation">(</span><span class="token punctuation">)</span>    // 使用流处理模式
    .build<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
TableEnvironment tableEnv <span class="token operator">=</span> TableEnvironment.create<span class="token punctuation">(</span>setting<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="_60"></a>流处理表环境</h3> 
<p>对于流处理场景，其实默认配置就完全够用了。所以我们也可以用另一种更加简单的方式来创建表环境：</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.EnvironmentSettings<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>

// TODO: <span class="token number">2024</span>/1/23 创建流式表环境
        StreamExecutionEnvironment environment <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        StreamTableEnvironment tableEnvironment <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>environment<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里我们引入了一个“流式表环境”（StreamTableEnvironment），它是继承自TableEnvironment的子接口。调用它的create()方法，只需要直接将当前的流执行环境（StreamExecutionEnvironment）传入，就可以创建出对应的流式表环境了。</p> 
<h2><a id="_76"></a>三.创建表</h2> 
<p>表（Table）是我们非常熟悉的一个概念，它是关系型数据库中数据存储的基本形式，也是SQL执行的基本对象。<br> 具体创建表的方式，有通过连接器（connector）和虚拟表（virtual tables）两种。</p> 
<h3><a id="Connector_Tables_81"></a>连接器表（Connector Tables）</h3> 
<p>最直观的创建表的方式，就是通过连接器（connector）连接到一个外部系统，然后定义出对应的表结构。<br> 在代码中，我们可以调用表环境的executeSql()方法，可以传入一个DDL作为参数执行SQL操作。这里我们传入一个CREATE语句进行表的创建，并通过WITH关键字指定连接到外部系统的连接器：</p> 
<pre><code class="prism language-bash">tableEnvironment.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE [TEMPORARY] TABLE MyTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里的TEMPORARY关键字可以省略。</p> 
<h3><a id="Virtual_Tables_91"></a>虚拟表（Virtual Tables）</h3> 
<p>在环境中注册之后，我们就可以在SQL中直接使用这张表进行查询转换了。</p> 
<pre><code class="prism language-bash">Table newTable <span class="token operator">=</span> tableEnvironment.sqlQuery<span class="token punctuation">(</span><span class="token string">"SELECT ... FROM MyTable... "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里调用了表环境的sqlQuery()方法，直接传入一条SQL语句作为参数执行查询，得到的结果是一个Table对象。Table是Table API中提供的核心接口类，就代表了一个Java中定义的表实例。<br> 由于newTable是一个Table对象，并没有在表环境中注册；所以如果希望直接在SQL中使用，我们还需要将这个中间结果表注册到环境中：</p> 
<pre><code class="prism language-bash">tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"NewTable"</span>, newTable<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>我们发现，这里的注册其实是创建了一个“虚拟表”（Virtual Table）。这个概念与SQL语法中的视图（View）非常类似，所以调用的方法也叫作创建“虚拟视图”（createTemporaryView）。</p> 
<h2><a id="_107"></a>四.表的查询</h2> 
<p>创建好了表，接下来自然就是对表进行查询转换了。对一个表的查询（Query）操作，就对应着流数据的转换（Transform）处理。<br> Flink为我们提供了两种查询方式：SQL，和Table API。</p> 
<h3><a id="SQL_111"></a>执行SQL进行查询</h3> 
<p>基于表执行SQL语句，是我们最为熟悉的查询方式。<br> 在代码中，我们只要调用表环境的sqlQuery()方法，传入一个字符串形式的SQL查询语句就可以了。执行得到的结果，是一个Table对象。</p> 
<pre><code class="prism language-bash">// 查询用户Alice的点击事件，并提取表中前两个字段
Table aliceVisitTable <span class="token operator">=</span> tableEnv.sqlQuery<span class="token punctuation">(</span>
    <span class="token string">"SELECT user, url "</span> +
    <span class="token string">"FROM EventTable "</span> +
    <span class="token string">"WHERE user = 'Alice' "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>目前Flink支持标准SQL中的绝大部分用法，并提供了丰富的计算函数。这样我们就可以把已有的技术迁移过来，像在MySQL、Hive中那样直接通过编写SQL实现自己的处理需求，从而大大降低了Flink上手的难度。<br> 例如，我们也可以通过GROUP BY关键字定义分组聚合，调用COUNT()、SUM()这样的函数来进行统计计算：</p> 
<pre><code class="prism language-bash">Table urlCountTable <span class="token operator">=</span> tableEnv.sqlQuery<span class="token punctuation">(</span>
    <span class="token string">"SELECT user, COUNT(url) "</span> +
    <span class="token string">"FROM EventTable "</span> +
    <span class="token string">"GROUP BY user "</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上面的例子得到的是一个新的Table对象，我们可以再次将它注册为虚拟表继续在SQL中调用。另外，我们也可以直接将查询的结果写入到已经注册的表中，这需要调用表环境的executeSql()方法来执行DDL，传入的是一个INSERT语句：</p> 
<pre><code class="prism language-bash">// 注册表
tableEnv.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE EventTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
tableEnv.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE OutputTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<pre><code class="prism language-bash">// 将查询结果输出到OutputTable中
tableEnv.executeSql <span class="token punctuation">(</span>
<span class="token string">"INSERT INTO OutputTable "</span> +
    <span class="token string">"SELECT user, url "</span> +
    <span class="token string">"FROM EventTable "</span> +
    <span class="token string">"WHERE user = 'Alice' "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="Table_API_152"></a>调用Table API进行查询</h3> 
<p>另外一种查询方式就是调用Table API。这是嵌入在Java和Scala语言内的查询API，核心就是Table接口类，通过一步步链式调用Table的方法，就可以定义出所有的查询转换操作。<br> 由于Table API是基于Table的Java实例进行调用的，因此我们首先要得到表的Java对象。基于环境中已注册的表，可以通过表环境的from()方法非常容易地得到一个Table对象：</p> 
<pre><code class="prism language-bash">Table eventTable <span class="token operator">=</span> tableEnv.from<span class="token punctuation">(</span><span class="token string">"EventTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>传入的参数就是注册好的表名。注意这里eventTable是一个Table对象，而EventTable是在环境中注册的表名。得到Table对象之后，就可以调用API进行各种转换操作了，得到的是一个新的Table对象：</p> 
<pre><code class="prism language-bash">Table maryClickTable <span class="token operator">=</span> eventTable
        .where<span class="token punctuation">(</span><span class="token variable"><span class="token variable">$(</span>"user"<span class="token variable">)</span></span>.isEqual<span class="token punctuation">(</span><span class="token string">"Alice"</span><span class="token punctuation">))</span>
        .select<span class="token punctuation">(</span><span class="token variable"><span class="token variable">$(</span>"url"<span class="token variable">)</span></span>, <span class="token variable"><span class="token variable">$(</span>"user"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里每个方法的参数都是一个“表达式”（Expression），用方法调用的形式直观地说明了想要表达的内容；“$”符号用来指定表中的一个字段。上面的代码和直接执行SQL是等效的。<br> Table API是嵌入编程语言中的DSL，SQL中的很多特性和功能必须要有对应的实现才可以使用，因此跟直接写SQL比起来肯定就要麻烦一些。目前Table API支持的功能相对更少，可以预见未来Flink社区也会以扩展SQL为主，为大家提供更加通用的接口方式；所以我们接下来也会以介绍SQL为主，简略地提及Table API。</p> 
<h3><a id="API_172"></a>两种API的结合使用</h3> 
<p>可以发现，无论是调用Table API还是执行SQL，得到的结果都是一个Table对象；所以这两种API的查询可以很方便地结合在一起。<br> （1）无论是那种方式得到的Table对象，都可以继续调用Table API进行查询转换；<br> （2）如果想要对一个表执行SQL操作（用FROM关键字引用），必须先在环境中对它进行注册。所以我们可以通过创建虚拟表的方式实现两者的转换：</p> 
<pre><code class="prism language-bash">tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"MyTable"</span>, myTable<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>两种API殊途同归，实际应用中可以按照自己的习惯任意选择。不过由于结合使用容易引起混淆，而Table API功能相对较少、通用性较差，所以企业项目中往往会直接选择SQL的方式来实现需求。</p> 
<h2><a id="_183"></a>五.输出表</h2> 
<p>表的创建和查询，就对应着流处理中的读取数据源（Source）和转换（Transform）；而最后一个步骤Sink，也就是将结果数据输出到外部系统，就对应着表的输出操作。<br> 在代码上，输出一张表最直接的方法，就是调用Table的方法executeInsert()方法将一个 Table写入到注册过的表中，方法传入的参数就是注册的表名。</p> 
<pre><code class="prism language-bash">// 注册表，用于输出数据到外部系统
tableEnv.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE OutputTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
// 经过查询转换，得到结果表
Table result <span class="token operator">=</span> <span class="token punctuation">..</span>.
// 将结果表写入已注册的输出表中
result.executeInsert<span class="token punctuation">(</span><span class="token string">"OutputTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>在底层，表的输出是通过将数据写入到TableSink来实现的。TableSink是Table API中提供的一个向外部系统写入数据的通用接口，可以支持不同的文件格式（比如CSV、Parquet）、存储数据库（比如JDBC、Elasticsearch）和消息队列（比如Kafka）。</p> 
<pre><code class="prism language-bash">package com.zxl.SQL<span class="token punctuation">;</span>

<span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.Table<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>

public class FlinkSQLDemo <span class="token punctuation">{<!-- --></span>
    public static void main<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{<!-- --></span>
        // TODO: <span class="token number">2024</span>/1/23 <span class="token number">1</span>.创建流式表环境
        StreamExecutionEnvironment environment <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        StreamTableEnvironment tableEnvironment <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>environment<span class="token punctuation">)</span><span class="token punctuation">;</span>
        // TODO: <span class="token number">2024</span>/1/23 <span class="token number">2</span>.创建数据源表
        tableEnvironment.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE source ( <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    id INT, <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    ts BIGINT, <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    vc INT<span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">") WITH ( <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'connector' = 'datagen', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'rows-per-second'='1', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.id.kind'='random', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.id.min'='1', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.id.max'='10', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.ts.kind'='sequence', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.ts.start'='1', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.ts.end'='1000000', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.vc.kind'='random', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.vc.min'='1', <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    'fields.vc.max'='100'<span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">");<span class="token entity" title="\n">\n</span>"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        // TODO: <span class="token number">2024</span>/1/23 <span class="token number">3</span>.创建数据结果表
        tableEnvironment.executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE sink (<span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    id INT, <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"    sumVC INT <span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">") WITH (<span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">"'connector' = 'print'<span class="token entity" title="\n">\n</span>"</span> +
                <span class="token string">");<span class="token entity" title="\n">\n</span>"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        // TODO: <span class="token number">2024</span>/1/23   <span class="token number">4</span>.执行查询
        Table table <span class="token operator">=</span> tableEnvironment.sqlQuery<span class="token punctuation">(</span><span class="token string">"select id,sum(vc) as sumVC from source where id&gt;5 group by id ;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        // TODO: <span class="token number">2024</span>/1/23   <span class="token number">5</span>.把table对象，注册成表名
        tableEnvironment.createTemporaryView<span class="token punctuation">(</span><span class="token string">"tmp"</span>, table<span class="token punctuation">)</span><span class="token punctuation">;</span>
        // TODO: <span class="token number">2024</span>/1/23   <span class="token number">6</span>.输出表
        tableEnvironment.executeSql<span class="token punctuation">(</span><span class="token string">"insert into sink select * from tmp"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ac/72/EjYJNhOX_o.png" alt="在这里插入图片描述"><br> 使用tableAPI查询</p> 
<pre><code class="prism language-bash">// TODO: <span class="token number">2024</span>/1/23   <span class="token number">4</span>.执行查询
        Table <span class="token builtin class-name">source</span> <span class="token operator">=</span> tableEnvironment.from<span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        Table table <span class="token operator">=</span> source.where<span class="token punctuation">(</span><span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span>.isGreater<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">))</span>
                .select<span class="token punctuation">(</span><span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span>, <span class="token variable"><span class="token variable">$(</span>"vc"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h2><a id="_254"></a>六.表和流的转换</h2> 
<h3><a id="DataStreamTable_256"></a>将流（DataStream）转换成表（Table）</h3> 
<h3><a id="1fromDataStream_258"></a>（1）调用fromDataStream()方法</h3> 
<p>想要将一个DataStream转换成表很简单，可以通过调用表环境的fromDataStream()方法来实现，返回的就是一个Table对象。</p> 
<pre><code class="prism language-bash">StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
// 获取表环境
StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>
// 读取数据源
SingleOutputStreamOperator<span class="token operator">&lt;</span>WaterSensor<span class="token operator">&gt;</span> sensorDS <span class="token operator">=</span> env.fromSource<span class="token punctuation">(</span><span class="token punctuation">..</span>.<span class="token punctuation">)</span>
// 将数据流转换成表
Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>由于流中的数据本身就是定义好的POJO类型WaterSensor，所以我们将流转换成表之后，每一行数据就对应着一个WaterSensor，而表中的列名就对应着WaterSensor中的属性。<br> 另外，我们还可以在fromDataStream()方法中增加参数，用来指定提取哪些属性作为表中的字段名，并可以任意指定位置：</p> 
<pre><code class="prism language-bash">// 提取Event中的timestamp和url作为表中的列
Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>sensorDS, <span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span>, <span class="token variable"><span class="token variable">$(</span>"vc"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>也可以通过表达式的as()方法对字段进行重命名：</p> 
<pre><code class="prism language-bash">// 将timestamp字段重命名为ts
Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>sensorDS, <span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"sid"</span><span class="token punctuation">)</span>, <span class="token variable"><span class="token variable">$(</span>"vc"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="2createTemporaryView_286"></a>（2）调用createTemporaryView()方法</h3> 
<p>调用fromDataStream()方法简单直观，可以直接实现DataStream到Table的转换；不过如果我们希望直接在SQL中引用这张表，就还需要调用表环境的createTemporaryView()方法来创建虚拟视图了。<br> 对于这种场景，也有一种更简洁的调用方式。我们可以直接调用createTemporaryView()方法创建虚拟表，传入的两个参数，第一个依然是注册的表名，而第二个可以直接就是DataStream。之后仍旧可以传入多个参数，用来指定表中的字段</p> 
<pre><code class="prism language-bash">tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"sensorTable"</span>,sensorDS, <span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span>,<span class="token variable"><span class="token variable">$(</span>"ts"<span class="token variable">)</span></span>,<span class="token variable"><span class="token variable">$(</span>"vc"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这样，我们接下来就可以直接在SQL中引用表sensorTable了。</p> 
<h3><a id="TableDataStream_298"></a>将表（Table）转换成流（DataStream）</h3> 
<h3><a id="1toDataStream_300"></a>（1）调用toDataStream()方法</h3> 
<p>将一个Table对象转换成DataStream非常简单，只要直接调用表环境的方法toDataStream()就可以了。例如，我们可以将2.4小节经查询转换得到的表aliceClickTable转换成流打印输出：</p> 
<pre><code class="prism language-bash">tableEnv.toDataStream<span class="token punctuation">(</span>table<span class="token punctuation">)</span>.print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="2toChangelogStream_308"></a>（2）调用toChangelogStream()方法</h3> 
<p>urlCountTable这个表中进行了分组聚合统计，所以表中的每一行是会“更新”的。对于这样有更新操作的表，我们不应该直接把它转换成DataStream打印输出，而是记录一下它的“更新日志”（change log）。这样一来，对于表的所有更新操作，就变成了一条更新日志的流，我们就可以转换成流打印输出了。<br> 代码中需要调用的是表环境的toChangelogStream()方法：</p> 
<pre><code class="prism language-bash">Table table <span class="token operator">=</span> tableEnv.sqlQuery<span class="token punctuation">(</span>
    <span class="token string">"SELECT id, sum(vc) "</span> +
    <span class="token string">"FROM source "</span> +
    <span class="token string">"GROUP BY id "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>// 将表转换成更新日志流</p> 
<pre><code class="prism language-bash">tableEnv.toChangelogStream<span class="token punctuation">(</span>table<span class="token punctuation">)</span>.print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="_327"></a>综合应用示例</h3> 
<pre><code class="prism language-bash">package com.zxl.bean<span class="token punctuation">;</span>

public class WaterSensor <span class="token punctuation">{<!-- --></span>
    private String <span class="token function">id</span><span class="token punctuation">;</span>
    private Long ts<span class="token punctuation">;</span>
    private Integer vc<span class="token punctuation">;</span>

    public String <span class="token function-name function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token builtin class-name">return</span> <span class="token function">id</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public void setId<span class="token punctuation">(</span>String <span class="token function">id</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        this.id <span class="token operator">=</span> <span class="token function">id</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public Long <span class="token function-name function">getTs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token builtin class-name">return</span> ts<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public void setTs<span class="token punctuation">(</span>Long ts<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        this.ts <span class="token operator">=</span> ts<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public Integer <span class="token function-name function">getVc</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token builtin class-name">return</span> vc<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public void setVc<span class="token punctuation">(</span>Integer vc<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        this.vc <span class="token operator">=</span> vc<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public WaterSensor<span class="token punctuation">(</span>String id, Long ts, Integer vc<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        this.id <span class="token operator">=</span> <span class="token function">id</span><span class="token punctuation">;</span>
        this.ts <span class="token operator">=</span> ts<span class="token punctuation">;</span>
        this.vc <span class="token operator">=</span> vc<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    public <span class="token function-name function">WaterSensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">}</span>

    @Override
    public String <span class="token function-name function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token builtin class-name">return</span> <span class="token string">"WaterSensor{"</span> +
                <span class="token string">"id='"</span> + <span class="token function">id</span> + <span class="token string">'\''</span> +
                <span class="token string">", ts="</span> + ts +
                <span class="token string">", vc="</span> + vc +
                <span class="token string">'}'</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<pre><code class="prism language-bash">StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        DataStreamSource<span class="token operator">&lt;</span>WaterSensor<span class="token operator">&gt;</span> sensorDS <span class="token operator">=</span> env.fromElements<span class="token punctuation">(</span>
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s1"</span>, 1L, <span class="token number">1</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s1"</span>, 2L, <span class="token number">2</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s2"</span>, 2L, <span class="token number">2</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s3"</span>, 3L, <span class="token number">3</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s3"</span>, 4L, <span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">1</span>. 流转表
        Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"sensor"</span>, sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>
        Table filterTable <span class="token operator">=</span> tableEnv.sqlQuery<span class="token punctuation">(</span><span class="token string">"select id,ts,vc from sensor where ts&gt;2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        Table sumTable <span class="token operator">=</span> tableEnv.sqlQuery<span class="token punctuation">(</span><span class="token string">"select id,sum(vc) from sensor group by id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        // TODO <span class="token number">2</span>. 表转流
        // <span class="token number">2.1</span> 追加流
        tableEnv.toDataStream<span class="token punctuation">(</span>filterTable, WaterSensor.class<span class="token punctuation">)</span>.print<span class="token punctuation">(</span><span class="token string">"filter"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        // <span class="token number">2.2</span> changelog流<span class="token punctuation">(</span>结果需要更新<span class="token punctuation">)</span>
        tableEnv.toChangelogStream<span class="token punctuation">(</span>sumTable <span class="token punctuation">)</span>.print<span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        // 只要代码中调用了 DataStreamAPI，就需要 execute，否则不需要
        env.execute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e8/2f/Q9ikyj2q_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_411"></a>七.支持的数据类型</h2> 
<p>整体来看，DataStream中支持的数据类型，Table中也是都支持的，只不过在进行转换时需要注意一些细节。</p> 
<h3><a id="1_415"></a>（1）原子类型</h3> 
<p>在Flink中，基础数据类型（Integer、Double、String）和通用数据类型（也就是不可再拆分的数据类型）统一称作“原子类型”。原子类型的DataStream，转换之后就成了只有一列的Table，列字段（field）的数据类型可以由原子类型推断出。另外，还可以在fromDataStream()方法里增加参数，用来重新命名列字段。</p> 
<pre><code class="prism language-bash">StreamTableEnvironment tableEnv <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
DataStream<span class="token operator">&lt;</span>Long<span class="token operator">&gt;</span> stream <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
</code></pre> 
<p>// 将数据流转换成动态表，动态表只有一个字段，重命名为myLong</p> 
<pre><code class="prism language-bash">Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"myLong"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="2Tuple_430"></a>（2）Tuple类型</h3> 
<p>当原子类型不做重命名时，默认的字段名就是“f0”，容易想到，这其实就是将原子类型看作了一元组Tuple1的处理结果。<br> Table支持Flink中定义的元组类型Tuple，对应在表中字段名默认就是元组中元素的属性名f0、f1、f2…。所有字段都可以被重新排序，也可以提取其中的一部分字段。字段还可以通过调用表达式的as()方法来进行重命名。</p> 
<pre><code class="prism language-bash">StreamTableEnvironment tableEnv <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
DataStream<span class="token operator">&lt;</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Long, Integer<span class="token operator">&gt;&gt;</span> stream <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
</code></pre> 
<pre><code class="prism language-bash">// 将数据流转换成只包含f1字段的表
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"f1"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
// 将数据流转换成包含f0和f1字段的表，在表中f0和f1位置交换
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"f1"<span class="token variable">)</span></span>, <span class="token variable"><span class="token variable">$(</span>"f0"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
// 将f1字段命名为myInt，f0命名为myLong
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"f1"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"myInt"</span><span class="token punctuation">)</span>, <span class="token variable"><span class="token variable">$(</span>"f0"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"myLong"</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="3POJO__449"></a>（3）POJO 类型</h3> 
<p>Flink也支持多种数据类型组合成的“复合类型”，最典型的就是简单Java对象（POJO 类型）。由于POJO中已经定义好了可读性强的字段名，这种类型的数据流转换成Table就显得无比顺畅了。<br> 将POJO类型的DataStream转换成Table，如果不指定字段名称，就会直接使用原始 POJO 类型中的字段名称。POJO中的字段同样可以被重新排序、提却和重命名。</p> 
<pre><code class="prism language-bash">StreamTableEnvironment tableEnv <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
DataStream<span class="token operator">&lt;</span>Event<span class="token operator">&gt;</span> stream <span class="token operator">=</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span>
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"user"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
Table table <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>stream, <span class="token variable"><span class="token variable">$(</span>"user"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"myUser"</span><span class="token punctuation">)</span>, <span class="token variable"><span class="token variable">$(</span>"url"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"myUrl"</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
</code></pre> 
<p>（4）Row类型<br> Flink中还定义了一个在关系型表中更加通用的数据类型——行（Row），它是Table中数据的基本组织形式。<br> Row类型也是一种复合类型，它的长度固定，而且无法直接推断出每个字段的类型，所以在使用时必须指明具体的类型信息；我们在创建Table时调用的CREATE语句就会将所有的字段名称和类型指定，这在Flink中被称为表的“模式结构”（Schema）。</p> 
<h2><a id="UDF_466"></a>八.自定义函数（UDF）</h2> 
<p>系统函数尽管庞大，也不可能涵盖所有的功能；如果有系统函数不支持的需求，我们就需要用自定义函数（User Defined Functions，UDF）来实现了。<br> Flink的Table API和SQL提供了多种自定义函数的接口，以抽象类的形式定义。当前UDF主要有以下几类：</p> 
<pre><code class="prism language-bash">标量函数（Scalar Functions）：将输入的标量值转换成一个新的标量值；
表函数（Table Functions）：将标量值转换成一个或多个新的行数据，也就是扩展成一个表；
聚合函数（Aggregate Functions）：将多行数据里的标量值转换成一个新的标量值；
表聚合函数（Table Aggregate Functions）：将多行数据里的标量值转换成一个或多个新的行数据。
</code></pre> 
<h3><a id="_478"></a>整体调用流程</h3> 
<p>要想在代码中使用自定义的函数，我们需要首先自定义对应UDF抽象类的实现，并在表环境中注册这个函数，然后就可以在Table API和SQL中调用了。</p> 
<h3><a id="1_482"></a>（1）注册函数</h3> 
<p>注册函数时需要调用表环境的createTemporarySystemFunction()方法，传入注册的函数名以及UDF类的Class对象：</p> 
<pre><code class="prism language-bash">// 注册函数
tableEnv.createTemporarySystemFunction<span class="token punctuation">(</span><span class="token string">"MyFunction"</span>, MyFunction.class<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>我们自定义的UDF类叫作MyFunction，它应该是上面四种UDF抽象类中某一个的具体实现；在环境中将它注册为名叫MyFunction的函数。</p> 
<h3><a id="2Table_API_493"></a>（2）使用Table API调用函数</h3> 
<p>在Table API中，需要使用call()方法来调用自定义函数：</p> 
<pre><code class="prism language-bash">tableEnv.from<span class="token punctuation">(</span><span class="token string">"MyTable"</span><span class="token punctuation">)</span>.select<span class="token punctuation">(</span>call<span class="token punctuation">(</span><span class="token string">"MyFunction"</span>, <span class="token variable"><span class="token variable">$(</span>"myField"<span class="token variable">)</span></span><span class="token punctuation">))</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里call()方法有两个参数，一个是注册好的函数名MyFunction，另一个则是函数调用时本身的参数。这里我们定义MyFunction在调用时，需要传入的参数是myField字段。</p> 
<h3><a id="3SQL_503"></a>（3）在SQL中调用函数</h3> 
<p>当我们将函数注册为系统函数之后，在SQL中的调用就与内置系统函数完全一样了：</p> 
<pre><code class="prism language-bash">tableEnv.sqlQuery<span class="token punctuation">(</span><span class="token string">"SELECT MyFunction(myField) FROM MyTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>可见，SQL的调用方式更加方便，我们后续依然会以SQL为例介绍UDF的用法。</p> 
<h3><a id="Flink_514"></a>Flink自定义函数类型查询官网：</h3> 
<p><a href="https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/table/types" rel="nofollow">https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/table/types</a><br> <img src="https://images2.imgbox.com/57/25/P9QNiDaF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="FlinkCall__518"></a>Flink的Call 语句查询官网：</h3> 
<p><a href="https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/table/sql/call/" rel="nofollow">https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/table/sql/call/</a><br> <img src="https://images2.imgbox.com/c4/58/Br4dGp3p_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Scalar_Functions_522"></a>标量函数（Scalar Functions）</h3> 
<p>自定义标量函数可以把0个、 1个或多个标量值转换成一个标量值，它对应的输入是一行数据中的字段，输出则是唯一的值。所以从输入和输出表中行数据的对应关系看，标量函数是“一对一”的转换。<br> 想要实现自定义的标量函数，我们需要自定义一个类来继承抽象类ScalarFunction，并实现叫作eval() 的求值方法。标量函数的行为就取决于求值方法的定义，它必须是公有的（public），而且名字必须是eval。求值方法eval可以重载多次，任何数据类型都可作为求值方法的参数和返回值类型。<br> 这里需要特别说明的是，ScalarFunction抽象类中并没有定义eval()方法，所以我们不能直接在代码中重写（override）；但Table API的框架底层又要求了求值方法必须名字为eval()。这是Table API和SQL目前还显得不够完善的地方，未来的版本应该会有所改进。<br> 下面我们来看一个具体的例子。我们实现一个自定义的哈希（hash）函数HashFunction，用来求传入对象的哈希值。</p> 
<pre><code class="prism language-bash">package com.zxl.SQL<span class="token punctuation">;</span>

<span class="token function">import</span> com.zxl.bean.WaterSensor<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.annotation.DataTypeHint<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.annotation.InputGroup<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.Table<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.functions.ScalarFunction<span class="token punctuation">;</span>
<span class="token function">import</span> static org.apache.flink.table.api.Expressions.$<span class="token punctuation">;</span>
<span class="token function">import</span> static org.apache.flink.table.api.Expressions.call<span class="token punctuation">;</span>


public class MyScalarFunctionDemo <span class="token punctuation">{<!-- --></span>
    public static void main<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{<!-- --></span>
        StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        DataStreamSource<span class="token operator">&lt;</span>WaterSensor<span class="token operator">&gt;</span> sensorDS <span class="token operator">=</span> env.fromElements<span class="token punctuation">(</span>
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s1"</span>, 1L, <span class="token number">1</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s1"</span>, 2L, <span class="token number">2</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s2"</span>, 2L, <span class="token number">2</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s3"</span>, 3L, <span class="token number">3</span><span class="token punctuation">)</span>,
                new WaterSensor<span class="token punctuation">(</span><span class="token string">"s3"</span>, 4L, <span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"sensor"</span>, sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">2</span>.注册函数
        tableEnv.createTemporaryFunction<span class="token punctuation">(</span><span class="token string">"HashFunction"</span>, HashFunction.class<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">3</span>.调用 自定义函数
        // <span class="token number">3.1</span> sql用法
//        tableEnv.sqlQuery<span class="token punctuation">(</span><span class="token string">"select HashFunction(id) from sensor"</span><span class="token punctuation">)</span>
//                .execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  // 调用了 sql的execute，就不需要 env.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
//                .print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO: <span class="token number">2024</span>/1/24   <span class="token number">3.2</span> table api用法
        sensorTable
                .select<span class="token punctuation">(</span>call<span class="token punctuation">(</span><span class="token string">"HashFunction"</span>,<span class="token variable"><span class="token variable">$(</span>"id"<span class="token variable">)</span></span><span class="token punctuation">))</span>
                .execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
                .print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>



    <span class="token punctuation">}</span>


    // TODO <span class="token number">1</span>.定义 自定义函数的实现类
    public static  class HashFunction extends ScalarFunction <span class="token punctuation">{<!-- --></span>

        // 接受任意类型的输入，返回 INT型输出
        public int eval<span class="token punctuation">(</span>@DataTypeHint<span class="token punctuation">(</span>inputGroup <span class="token operator">=</span> InputGroup.ANY<span class="token punctuation">)</span> Object o<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token builtin class-name">return</span> o.hashCode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/35/88/V1JkQkHk_o.png" alt="在这里插入图片描述"></p> 
<p>这里我们自定义了一个ScalarFunction，实现了eval()求值方法，将任意类型的对象传入，得到一个Int类型的哈希值返回。当然，具体的求哈希操作就省略了，直接调用对象的hashCode()方法即可。<br> 另外注意，由于Table API在对函数进行解析时需要提取求值方法参数的类型引用，所以我们用DataTypeHint(inputGroup = InputGroup.ANY)对输入参数的类型做了标注，表示eval的参数可以是任意类型。</p> 
<h3><a id="Table_Functions_598"></a>表函数（Table Functions）</h3> 
<p>跟标量函数一样，表函数的输入参数也可以是 0个、1个或多个标量值；不同的是，它可以返回任意多行数据。“多行数据”事实上就构成了一个表，所以“表函数”可以认为就是返回一个表的函数，这是一个“一对多”的转换关系。之前我们介绍过的窗口TVF，本质上就是表函数。<br> 类似地，要实现自定义的表函数，需要自定义类来继承抽象类TableFunction，内部必须要实现的也是一个名为 eval 的求值方法。与标量函数不同的是，TableFunction类本身是有一个泛型参数T的，这就是表函数返回数据的类型；而eval()方法没有返回类型，内部也没有return语句，是通过调用collect()方法来发送想要输出的行数据的。<br> 在SQL中调用表函数，需要使用LATERAL TABLE()来生成扩展的“侧向表”，然后与原始表进行联结（Join）。这里的Join操作可以是直接做交叉联结（cross join），在FROM后用逗号分隔两个表就可以；也可以是以ON TRUE为条件的左联结（LEFT JOIN）。<br> 下面是表函数的一个具体示例。我们实现了一个分隔字符串的函数SplitFunction，可以将一个字符串转换成（字符串，长度）的二元组。</p> 
<pre><code class="prism language-bash">package com.zxl.SQL<span class="token punctuation">;</span>

<span class="token function">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.annotation.DataTypeHint<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.annotation.FunctionHint<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.Table<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.functions.TableFunction<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.types.Row<span class="token punctuation">;</span>

<span class="token function">import</span> static org.apache.flink.table.api.Expressions.$<span class="token punctuation">;</span>

public class MyTableFunctionDemo <span class="token punctuation">{<!-- --></span>
    public static void main<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{<!-- --></span>
        StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        DataStreamSource<span class="token operator">&lt;</span>String<span class="token operator">&gt;</span> strDS <span class="token operator">=</span> env.fromElements<span class="token punctuation">(</span>
                <span class="token string">"hello flink"</span>,
                <span class="token string">"hello world hi"</span>,
                <span class="token string">"hello java"</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        Table sensorTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>strDS, <span class="token variable"><span class="token variable">$(</span>"words"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"str"</span>, sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">2</span>.注册函数
        tableEnv.createTemporaryFunction<span class="token punctuation">(</span><span class="token string">"SplitFunction"</span>, SplitFunction.class<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">3</span>.调用 自定义函数
        // <span class="token number">3.1</span> 交叉联结
        tableEnv
                // <span class="token number">3.1</span> 交叉联结
//                .sqlQuery<span class="token punctuation">(</span><span class="token string">"select words,word,length from str,lateral table(SplitFunction(words))"</span><span class="token punctuation">)</span>
                // <span class="token number">3.2</span> 带 on  <span class="token boolean">true</span> 条件的 左联结
//                .sqlQuery<span class="token punctuation">(</span><span class="token string">"select words,word,length from str left join lateral table(SplitFunction(words)) on true"</span><span class="token punctuation">)</span>
                // 重命名侧向表中的字段
                .sqlQuery<span class="token punctuation">(</span><span class="token string">"select words,newWord,newLength from str left join lateral table(SplitFunction(words))  as T(newWord,newLength) on true"</span><span class="token punctuation">)</span>
                .execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
                .print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>



    <span class="token punctuation">}</span>


    // TODO <span class="token number">1</span>.继承 TableFunction<span class="token operator">&lt;</span>返回的类型<span class="token operator">&gt;</span>
    // 类型标注： Row包含两个字段：word和length
    @FunctionHint<span class="token punctuation">(</span>output <span class="token operator">=</span> @DataTypeHint<span class="token punctuation">(</span><span class="token string">"ROW&lt;word STRING,length INT&gt;"</span><span class="token punctuation">))</span>
    public static class SplitFunction extends TableFunction<span class="token operator">&lt;</span>Row<span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>

        // 返回是 void，用 collect方法输出
        public void eval<span class="token punctuation">(</span>String str<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token builtin class-name">:</span> str.split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">))</span> <span class="token punctuation">{<!-- --></span>
                collect<span class="token punctuation">(</span>Row.of<span class="token punctuation">(</span>word, word.length<span class="token punctuation">(</span><span class="token punctuation">))</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f9/ec/ngq612Gl_o.png" alt="在这里插入图片描述"></p> 
<p>这里我们直接将表函数的输出类型定义成了ROW，这就是得到的侧向表中的数据类型；每行数据转换后也只有一行。我们分别用交叉联结和左联结两种方式在SQL中进行了调用，还可以对侧向表的中字段进行重命名。</p> 
<h3><a id="Aggregate_Functions_677"></a>聚合函数（Aggregate Functions）</h3> 
<p>用户自定义聚合函数（User Defined AGGregate function，UDAGG）会把一行或多行数据（也就是一个表）聚合成一个标量值。这是一个标准的“多对一”的转换。<br> 聚合函数的概念我们之前已经接触过多次，如SUM()、MAX()、MIN()、AVG()、COUNT()都是常见的系统内置聚合函数。而如果有些需求无法直接调用系统函数解决，我们就必须自定义聚合函数来实现功能了。<br> 自定义聚合函数需要继承抽象类AggregateFunction。AggregateFunction有两个泛型参数&lt;T, ACC&gt;，T表示聚合输出的结果类型，ACC则表示聚合的中间状态类型。<br> Flink SQL中的聚合函数的工作原理如下：</p> 
<pre><code class="prism language-bash">（1）首先，它需要创建一个累加器（accumulator），用来存储聚合的中间结果。这与DataStream API中的AggregateFunction非常类似，累加器就可以看作是一个聚合状态。调用createAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>方法可以创建一个空的累加器。
（2）对于输入的每一行数据，都会调用accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>方法来更新累加器，这是聚合的核心过程。
（3）当所有的数据都处理完之后，通过调用getValue<span class="token punctuation">(</span><span class="token punctuation">)</span>方法来计算并返回最终的结果。
</code></pre> 
<p>所以，每个 AggregateFunction 都必须实现以下几个方法：</p> 
<pre><code class="prism language-bash">createAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>
这是创建累加器的方法。没有输入参数，返回类型为累加器类型ACC。
accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>
这是进行聚合计算的核心方法，每来一行数据都会调用。它的第一个参数是确定的，就是当前的累加器，类型为ACC，表示当前聚合的中间状态；后面的参数则是聚合函数调用时传入的参数，可以有多个，类型也可以不同。这个方法主要是更新聚合状态，所以没有返回类型。需要注意的是，accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>与之前的求值方法eval<span class="token punctuation">(</span><span class="token punctuation">)</span>类似，也是底层架构要求的，必须为public，方法名必须为accumulate，且无法直接override、只能手动实现。
getValue<span class="token punctuation">(</span><span class="token punctuation">)</span>
这是得到最终返回结果的方法。输入参数是ACC类型的累加器，输出类型为T。
</code></pre> 
<p>在遇到复杂类型时，Flink 的类型推导可能会无法得到正确的结果。所以AggregateFunction也可以专门对累加器和返回结果的类型进行声明，这是通过 getAccumulatorType()和getResultType()两个方法来指定的。<br> AggregateFunction 的所有方法都必须是 公有的（public），不能是静态的（static），而且名字必须跟上面写的完全一样。createAccumulator、getValue、getResultType 以及 getAccumulatorType 这几个方法是在抽象类 AggregateFunction 中定义的，可以override；而其他则都是底层架构约定的方法。<br> 下面举一个具体的示例，我们从学生的分数表ScoreTable中计算每个学生的加权平均分。</p> 
<pre><code class="prism language-bash">package com.zxl.SQL<span class="token punctuation">;</span>

<span class="token function">import</span> org.apache.flink.api.java.tuple.Tuple2<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.api.java.tuple.Tuple3<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.Table<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.functions.AggregateFunction<span class="token punctuation">;</span>

<span class="token function">import</span> static org.apache.flink.table.api.Expressions.$<span class="token punctuation">;</span>

public class MyAggregateFunctionDemo <span class="token punctuation">{<!-- --></span>
    public static void main<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{<!-- --></span>
        StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        //  姓名，分数，权重
        DataStreamSource<span class="token operator">&lt;</span>Tuple<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>String,Integer, Integer<span class="token operator">&gt;&gt;</span> scoreWeightDS <span class="token operator">=</span> env.fromElements<span class="token punctuation">(</span>
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"zs"</span>,80, <span class="token number">3</span><span class="token punctuation">)</span>,
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"zs"</span>,90, <span class="token number">4</span><span class="token punctuation">)</span>,
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"zs"</span>,95, <span class="token number">4</span><span class="token punctuation">)</span>,
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"ls"</span>,75, <span class="token number">4</span><span class="token punctuation">)</span>,
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"ls"</span>,65, <span class="token number">4</span><span class="token punctuation">)</span>,
                Tuple3.of<span class="token punctuation">(</span><span class="token string">"ls"</span>,85, <span class="token number">4</span><span class="token punctuation">)</span>

        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        Table scoreWeightTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>scoreWeightDS, <span class="token variable"><span class="token variable">$(</span>"f0"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span>,<span class="token variable"><span class="token variable">$(</span>"f1"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"score"</span><span class="token punctuation">)</span>, <span class="token variable"><span class="token variable">$(</span>"f2"<span class="token variable">)</span></span>.as<span class="token punctuation">(</span><span class="token string">"weight"</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
        tableEnv.createTemporaryView<span class="token punctuation">(</span><span class="token string">"scores"</span>, scoreWeightTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">2</span>.注册函数
        tableEnv.createTemporaryFunction<span class="token punctuation">(</span><span class="token string">"WeightedAvg"</span>, WeightedAvg.class<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">3</span>.调用 自定义函数
        tableEnv
                .sqlQuery<span class="token punctuation">(</span><span class="token string">"select name,WeightedAvg(score,weight)  from scores group by name"</span><span class="token punctuation">)</span>
                .execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
                .print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


    <span class="token punctuation">}</span>


    // TODO <span class="token number">1</span>.继承 AggregateFunction<span class="token operator">&lt;</span> 返回类型，累加器类型<span class="token operator">&lt;</span>加权总和，权重总和<span class="token operator">&gt;</span> <span class="token operator">&gt;</span>
    public static class WeightedAvg extends AggregateFunction<span class="token operator">&lt;</span>Double, Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;&gt;</span> <span class="token punctuation">{<!-- --></span>

        @Override
        public Double getValue<span class="token punctuation">(</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> integerIntegerTuple2<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token builtin class-name">return</span> integerIntegerTuple2.f0 * 1D / integerIntegerTuple2.f1<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        @Override
        public Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> <span class="token function-name function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token builtin class-name">return</span> Tuple2.of<span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        /**
         * 累加计算的方法，每来一行数据都会调用一次
         * @param acc 累加器类型
         * @param score 第一个参数：分数
         * @param weight 第二个参数：权重
         */
        public void accumulate<span class="token punctuation">(</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> acc,Integer score,Integer weight<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
            acc.f0 <span class="token operator">+=</span> score * weight<span class="token punctuation">;</span>  // 加权总和 <span class="token operator">=</span>  分数1 * 权重1 + 分数2 * 权重2 +<span class="token punctuation">..</span><span class="token punctuation">..</span>
            acc.f1 <span class="token operator">+=</span> weight<span class="token punctuation">;</span>         // 权重和 <span class="token operator">=</span> 权重1 + 权重2 +<span class="token punctuation">..</span><span class="token punctuation">..</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/21/3a/SiADSLS7_o.png" alt="在这里插入图片描述"></p> 
<p>聚合函数的accumulate()方法有三个输入参数。第一个是WeightedAvgAccum类型的累加器；另外两个则是函数调用时输入的字段：要计算的值 ivalue 和 对应的权重 iweight。这里我们并不考虑其它方法的实现，只要有必须的三个方法就可以了。</p> 
<h3><a id="Table_Aggregate_Functions_784"></a>表聚合函数（Table Aggregate Functions）</h3> 
<p>用户自定义表聚合函数（UDTAGG）可以把一行或多行数据（也就是一个表）聚合成另一张表，结果表中可以有多行多列。很明显，这就像表函数和聚合函数的结合体，是一个“多对多”的转换。<br> 自定义表聚合函数需要继承抽象类TableAggregateFunction。TableAggregateFunction的结构和原理与AggregateFunction非常类似，同样有两个泛型参数&lt;T, ACC&gt;，用一个ACC类型的累加器（accumulator）来存储聚合的中间结果。聚合函数中必须实现的三个方法，在TableAggregateFunction中也必须对应实现：</p> 
<pre><code class="prism language-bash">createAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>
创建累加器的方法，与AggregateFunction中用法相同。
accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>
聚合计算的核心方法，与AggregateFunction中用法相同。
emitValue<span class="token punctuation">(</span><span class="token punctuation">)</span>
所有输入行处理完成后，输出最终计算结果的方法。这个方法对应着AggregateFunction中的getValue<span class="token punctuation">(</span><span class="token punctuation">)</span>方法；区别在于emitValue没有输出类型，而输入参数有两个：第一个是ACC类型的累加器，第二个则是用于输出数据的“收集器”out，它的类型为Collect<span class="token operator">&lt;</span>T<span class="token operator">&gt;</span>。另外，emitValue<span class="token punctuation">(</span><span class="token punctuation">)</span>在抽象类中也没有定义，无法override，必须手动实现。
</code></pre> 
<p>表聚合函数相对比较复杂，它的一个典型应用场景就是TOP-N查询。比如我们希望选出一组数据排序后的前两名，这就是最简单的TOP-2查询。没有现成的系统函数，那么我们就可以自定义一个表聚合函数来实现这个功能。在累加器中应该能够保存当前最大的两个值，每当来一条新数据就在accumulate()方法中进行比较更新，最终在emitValue()中调用两次out.collect()将前两名数据输出。</p> 
<pre><code class="prism language-bash">package com.zxl.SQL<span class="token punctuation">;</span>

<span class="token function">import</span> org.apache.flink.api.java.tuple.Tuple2<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.Table<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.table.functions.TableAggregateFunction<span class="token punctuation">;</span>
<span class="token function">import</span> org.apache.flink.util.Collector<span class="token punctuation">;</span>

<span class="token function">import</span> static org.apache.flink.table.api.Expressions.call<span class="token punctuation">;</span>
<span class="token function">import</span> static org.apache.flink.table.api.Expressions.$<span class="token punctuation">;</span>


public class MyTableAggregateFunctionDemo <span class="token punctuation">{<!-- --></span>
    public static void main<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{<!-- --></span>
        StreamExecutionEnvironment <span class="token function">env</span> <span class="token operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        //  姓名，分数，权重
        DataStreamSource<span class="token operator">&lt;</span>Integer<span class="token operator">&gt;</span> numDS <span class="token operator">=</span> env.fromElements<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token number">6</span>, <span class="token number">12</span>, <span class="token number">5</span>, <span class="token number">8</span>, <span class="token number">9</span>, <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        StreamTableEnvironment tableEnv <span class="token operator">=</span> StreamTableEnvironment.create<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        Table numTable <span class="token operator">=</span> tableEnv.fromDataStream<span class="token punctuation">(</span>numDS, <span class="token variable"><span class="token variable">$(</span>"num"<span class="token variable">)</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">2</span>.注册函数
        tableEnv.createTemporaryFunction<span class="token punctuation">(</span><span class="token string">"Top2"</span>, Top2.class<span class="token punctuation">)</span><span class="token punctuation">;</span>

        // TODO <span class="token number">3</span>.调用 自定义函数: 只能用 Table API Call 语句用来调用存储过程。存储过程通常是用来执行一些数据操作和管理任务的,调用自定义函数。
        numTable
                .flatAggregate<span class="token punctuation">(</span>call<span class="token punctuation">(</span><span class="token string">"Top2"</span>, <span class="token variable"><span class="token variable">$(</span>"num"<span class="token variable">)</span></span><span class="token punctuation">)</span>.as<span class="token punctuation">(</span><span class="token string">"value"</span>, <span class="token string">"rank"</span><span class="token punctuation">))</span>
                .select<span class="token punctuation">(</span> <span class="token variable"><span class="token variable">$(</span>"value"<span class="token variable">)</span></span>, <span class="token variable"><span class="token variable">$(</span>"rank"<span class="token variable">)</span></span><span class="token punctuation">)</span>
                .execute<span class="token punctuation">(</span><span class="token punctuation">)</span>.print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


    <span class="token punctuation">}</span>


    // TODO <span class="token number">1</span>.继承 TableAggregateFunction<span class="token operator">&lt;</span> 返回类型，累加器类型<span class="token operator">&lt;</span>加权总和，权重总和<span class="token operator">&gt;</span> <span class="token operator">&gt;</span>
    // 返回类型 <span class="token punctuation">(</span>数值，排名<span class="token punctuation">)</span> <span class="token operator">=</span>》 <span class="token punctuation">(</span><span class="token number">12,1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">9,2</span><span class="token punctuation">)</span>
    // 累加器类型 <span class="token punctuation">(</span>第一大的数，第二大的数<span class="token punctuation">)</span> <span class="token operator">==</span><span class="token operator">=</span>》 （12,9）
    public static class Top2 extends TableAggregateFunction<span class="token operator">&lt;</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span>, Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;&gt;</span> <span class="token punctuation">{<!-- --></span>

        @Override
        public Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> <span class="token function-name function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token builtin class-name">return</span> Tuple2.of<span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>


        /**
         * 每来一个数据调用一次，比较大小，更新 最大的前两个数到 acc中
         *
         * @param acc 累加器
         * @param num 过来的数据
         */
        public void accumulate<span class="token punctuation">(</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> acc, Integer num<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>num <span class="token operator">&gt;</span> acc.f0<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                // 新来的变第一，原来的第一变第二
                acc.f1 <span class="token operator">=</span> acc.f0<span class="token punctuation">;</span>
                acc.f0 <span class="token operator">=</span> num<span class="token punctuation">;</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>num <span class="token operator">&gt;</span> acc.f1<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                // 新来的变第二，原来的第二不要了
                acc.f1 <span class="token operator">=</span> num<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>


        /**
         * 输出结果： （数值，排名）两条最大的
         *
         * @param acc 累加器
         * @param out 采集器<span class="token operator">&lt;</span>返回类型<span class="token operator">&gt;</span>
         */
        public void emitValue<span class="token punctuation">(</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;</span> acc, Collector<span class="token operator">&lt;</span>Tuple<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>Integer, Integer<span class="token operator">&gt;&gt;</span> out<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>acc.f0 <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                out.collect<span class="token punctuation">(</span>Tuple2.of<span class="token punctuation">(</span>acc.f0, <span class="token number">1</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>acc.f1 <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                out.collect<span class="token punctuation">(</span>Tuple2.of<span class="token punctuation">(</span>acc.f1, <span class="token number">2</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>


<span class="token punctuation">}</span>
</code></pre> 
<p>目前SQL中没有直接使用表聚合函数的方式，所以需要使用Table API的方式来调用。<br> 这里使用了flatAggregate()方法，它就是专门用来调用表聚合函数的接口。统计num值最大的两个；并将聚合结果的两个字段重命名为value和rank，之后就可以使用select()将它们提取出来了。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/720f646d6cab9d96f446cdf565abc9fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Linux工具篇】编辑器vim</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e6b3b3143ee7599021f48de1f09fff29/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java中的HTTPS通信</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>