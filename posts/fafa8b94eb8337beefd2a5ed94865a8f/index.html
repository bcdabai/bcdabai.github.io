<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>自动驾驶预测-决策-规划-控制学习（5）：图像分割与语义分割入门 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="自动驾驶预测-决策-规划-控制学习（5）：图像分割与语义分割入门" />
<meta property="og:description" content="提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档
文章目录 论文题目：Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey前言：图像分割与语义分割一、图像分割是什么？1.语义分割只区分像素类别，而不区分类别中的具体单位2.实例分割更进一步，把像素区域中每一个个体也能区别出来 二、语义分割模型演变过程1.FCN 基于全卷积网络2.DeepLab3.基于自上而下/自下而上方法①Deconvnet②U-Net 4.基于全局上下文①ParseNet②GCN 5.Based on receptive field enlargement and multi-scale contextincorporation 基于感受野扩大和多尺度上下文合并①PSPNet②Gated-SCNN 三、总结讨论1.研究内容：对基于CNN的不同语义分割模型进行调查。描述了不同的最新语义分割模型的架构细节2.论文的工作3.概括性的神经网络模型分类4.不同模型的性能对比 论文题目：Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey 前言：图像分割与语义分割 对于图像的分析，传统的检测任务，比如这幅图的人，用标注框来表示。
而图像分割，则是针对每一个像素都可以被认定为不同的语义信息，比如这里红色区域的像素点属于人，蓝色属于天空，浅绿色属于草地，深绿色属于树木。
一、图像分割是什么？ 图像分割于把图像分成若干个特定的、具有独特性质的区域并提取出感兴趣的目标。
如上图所示分割可以分为三类
1） 语义分割：像素级分类，将图像分割成具有语义信息的区域，为每个像素分配一个语义标签。
2）实例分割：检测每个object instance，实例分割不仅关注像素级别的语义信息，还区分不同物体实例之间的边界。
3）全景分割：上面二者的结合。既需要分割出全部像素，同类像素不同物体间不能有重合。图片内的每个像素都必须分配 semantic label 和 instance id. 如 Figure 1d. 相同 label 和相同 id 的像素属于相同 object。
1.语义分割只区分像素类别，而不区分类别中的具体单位 他分割出来属于人的一大块像素区域，但是无法具体把每个人都抠出来。
2.实例分割更进一步，把像素区域中每一个个体也能区别出来 二、语义分割模型演变过程 图像语义分割的发展主要经历了三个时期．
传统方法时期: 采用阈值法、边缘检测法、区域法等对图像进行分割，这些方法只能利用图片中边缘、颜色、纹理等低级特征，分割结果并不精确．传统分割方法和 CNN 相结合的时期: 先利用传统算法处理图像，再利用 CNN 模型训练分类器，虽然带来了分割精度的提升，但依旧受到传统方法的限制．基于 CNN 时期: 全卷积神经网络( FCN) 的出现开启了图像语义分割领域的新篇章．FCN 将 CNN 中的全连接层转换为卷积层，首次实现了端到端的、像素级的分类．FCN的提出为研究人员提供了全新的研究思路，在 CNN 和 FCN的基础上，U-Net、SegNet、DeconvNet、ＲefineNet、EncNet等模型相继出现，为语义分割领域的发展做出了杰出贡献。 论文主要从第三个时期的一些网络来讲述的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/fafa8b94eb8337beefd2a5ed94865a8f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-17T17:43:28+08:00" />
<meta property="article:modified_time" content="2024-01-17T17:43:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">自动驾驶预测-决策-规划-控制学习（5）：图像分割与语义分割入门</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Evolution_of_Image_Segmentation_using_Deep_Convolutional_Neural_Network_A_Survey_7" rel="nofollow">论文题目：Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey</a></li><li><a href="#_8" rel="nofollow">前言：图像分割与语义分割</a></li><li><a href="#_15" rel="nofollow">一、图像分割是什么？</a></li><li><ul><li><a href="#1_28" rel="nofollow">1.语义分割只区分像素类别，而不区分类别中的具体单位</a></li><li><a href="#2_32" rel="nofollow">2.实例分割更进一步，把像素区域中每一个个体也能区别出来</a></li></ul> 
  </li><li><a href="#_35" rel="nofollow">二、语义分割模型演变过程</a></li><li><ul><li><a href="#1FCN__42" rel="nofollow">1.FCN 基于全卷积网络</a></li><li><a href="#2DeepLab_51" rel="nofollow">2.DeepLab</a></li><li><a href="#3_61" rel="nofollow">3.基于自上而下/自下而上方法</a></li><li><ul><li><a href="#Deconvnet_62" rel="nofollow">①Deconvnet</a></li><li><a href="#UNet_69" rel="nofollow">②U-Net</a></li></ul> 
   </li><li><a href="#4_83" rel="nofollow">4.基于全局上下文</a></li><li><ul><li><a href="#ParseNet_84" rel="nofollow">①ParseNet</a></li><li><a href="#GCN_89" rel="nofollow">②GCN</a></li></ul> 
   </li><li><a href="#5Based_on_receptive_field_enlargement_and_multiscale_contextincorporation___93" rel="nofollow">5.Based on receptive field enlargement and multi-scale contextincorporation 基于感受野扩大和多尺度上下文合并</a></li><li><ul><li><a href="#PSPNet_94" rel="nofollow">①PSPNet</a></li><li><a href="#GatedSCNN_98" rel="nofollow">②Gated-SCNN</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_103" rel="nofollow">三、总结讨论</a></li><li><ul><li><a href="#1CNN_104" rel="nofollow">1.研究内容：对基于CNN的不同语义分割模型进行调查。描述了不同的最新语义分割模型的架构细节</a></li><li><a href="#2_106" rel="nofollow">2.论文的工作</a></li><li><a href="#3_113" rel="nofollow">3.概括性的神经网络模型分类</a></li><li><a href="#4_125" rel="nofollow">4.不同模型的性能对比</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="Evolution_of_Image_Segmentation_using_Deep_Convolutional_Neural_Network_A_Survey_7"></a>论文题目：Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey</h2> 
<h2><a id="_8"></a>前言：图像分割与语义分割</h2> 
<p>对于图像的分析，传统的检测任务，比如这幅图的人，用标注框来表示。<br> <img src="https://images2.imgbox.com/e3/43/aD3mdDw1_o.png" alt="在这里插入图片描述"><br> 而图像分割，则是针对每一个像素都可以被认定为不同的语义信息，比如这里红色区域的像素点属于人，蓝色属于天空，浅绿色属于草地，深绿色属于树木。<br> <img src="https://images2.imgbox.com/27/ee/mjzBT5by_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_15"></a>一、图像分割是什么？</h2> 
<p><img src="https://images2.imgbox.com/ba/9a/i7VUljHl_o.png" alt="在这里插入图片描述"><br> 图像分割于把图像分成若干个特定的、具有独特性质的区域并提取出感兴趣的目标。<br> <img src="https://images2.imgbox.com/36/70/oKmFoDa8_o.png" alt="在这里插入图片描述"><br> 如上图所示分割可以分为三类</p> 
<p>1） 语义分割：像素级分类，将图像分割成具有语义信息的区域，为每个像素分配一个语义标签。</p> 
<p>2）实例分割：检测每个object instance，实例分割不仅关注像素级别的语义信息，还区分不同物体实例之间的边界。</p> 
<p>3）全景分割：上面二者的结合。既需要分割出全部像素，同类像素不同物体间不能有重合。图片内的每个像素都必须分配 semantic label 和 instance id. 如 Figure 1d. 相同 label 和相同 id 的像素属于相同 object。</p> 
<h3><a id="1_28"></a>1.语义分割只区分像素类别，而不区分类别中的具体单位</h3> 
<p><img src="https://images2.imgbox.com/a1/0d/mKXAITdm_o.png" alt="在这里插入图片描述"><br> 他分割出来属于人的一大块像素区域，但是无法具体把每个人都抠出来。</p> 
<h3><a id="2_32"></a>2.实例分割更进一步，把像素区域中每一个个体也能区别出来</h3> 
<p><img src="https://images2.imgbox.com/be/e7/Tr9IieKx_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_35"></a>二、语义分割模型演变过程</h2> 
<p>图像语义分割的发展主要经历了三个时期．</p> 
<ol><li>传统方法时期: 采用阈值法、边缘检测法、区域法等对图像进行分割，这些方法只能利用图片中边缘、颜色、纹理等低级特征，分割结果并不精确．</li><li>传统分割方法和 CNN 相结合的时期: 先利用传统算法处理图像，再利用 CNN 模型训练分类器，虽然带来了分割精度的提升，但依旧受到传统方法的限制．</li><li>基于 CNN 时期: 全卷积神经网络( FCN) 的出现开启了图像语义分割领域的新篇章．FCN 将 CNN 中的全连接层转换为卷积层，首次实现了端到端的、像素级的分类．FCN的提出为研究人员提供了全新的研究思路，在 CNN 和 FCN的基础上，U-Net、SegNet、DeconvNet、ＲefineNet、EncNet等模型相继出现，为语义分割领域的发展做出了杰出贡献。</li></ol> 
<p>论文主要从第三个时期的一些网络来讲述的。</p> 
<h3><a id="1FCN__42"></a>1.FCN 基于全卷积网络</h3> 
<p><img src="https://images2.imgbox.com/65/e8/Y4rZ6SEZ_o.png" alt="在这里插入图片描述"><br> 方法：<br> （1）将全连接层替换为卷积层：从而可以接收不同大小图片的输入；<br> （2）其次可以进行像素级分类。在恢复高分辨率图像时，结合前面卷积层的信息，进行融合，相加。<br> 优点：以前只能输入固定大小的图片，改进后可以不限制图片大小。<br> 不足：FCN只使用局部信息进行语义分割，但只有局部信息会导致语义分割相当模糊，因为它没有全局信息，在结合前面卷积层时都是局部信息。</p> 
<p>数据集：PASCAL VOC 2011</p> 
<h3><a id="2DeepLab_51"></a>2.DeepLab</h3> 
<p>方法：<br> （1）基于全卷积网络（FCN）的架构，并结合了扩张卷积（dilated/atrous convolution）和空洞空间金字塔池化（ASPP）等技术。<br> （2）通过多尺度信息的融合来提高图像分割的性能。它使用了扩张卷积来增加感受野，以便更好地捕捉上下文信息。<br> （3）ASPP用于在不同尺度上对特征进行池化操作，通过并行的多个卷积核以不同的扩张率进行卷积操作，从而捕捉到不同尺度的上下文信息。这样可以在不增加网络参数和计算量的情况下，有效地提高模型对不同尺度目标的分割能力。</p> 
<p>优点：有助于保持图像的空间分辨率，产生密集预测<br> 缺点：将图像像素与其全局上下文隔离开来，这使得它容易发生错误分类。<br> <img src="https://images2.imgbox.com/96/d7/zqhLVQ2R_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3_61"></a>3.基于自上而下/自下而上方法</h3> 
<h4><a id="Deconvnet_62"></a>①Deconvnet</h4> 
<p>方法：<br> （1）一种卷积和反卷积网络。该网络在VGG16的基础上进行修改，去掉了最后的分类层，增加了池化和正则化层。反卷积网络与卷积网络在结构上相反，也包含多个反卷积、去聚合和正则化层。除了反卷积网络的最后一层生成像素级别的类别概率图外，网络中的所有层都提取特征图。<br> （2）应用了反池化来重建激活的原始大小，并通过使用多个学习到的滤波器进行类似卷积的操作来增加稀疏但放大的特征图的密度。</p> 
<p>优点：该方法对多尺度物体具有精细细节，并减少了训练复杂性和内存消耗。<br> <img src="https://images2.imgbox.com/5d/d0/7aCkDKsc_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="UNet_69"></a>②U-Net</h4> 
<p>方法：<br> （1）U-Net 是一种U形语义分割，具有收缩路径和扩展路径。</p> 
<p>（2）在收缩路径中，通过多次使用卷积和池化操作，网络逐渐减小图像的尺寸，并提取出更高级别的特征信息。这些操作使得网络能够理解图像中的重要特征。</p> 
<p>（3）在扩展路径中，通过上采样和卷积操作，网络将特征图的尺寸恢复到原始图像的尺寸，并与收缩路径中相应的特征图进行拼接。这样可以将高级别的特征信息与空间信息相结合，以获得更准确的分割结果。</p> 
<p>（4）最后，通过一系列卷积和非线性激活函数，网络进一步提取特征并增强分割的准确性。</p> 
<p>优点：强大的特征表示能力、上采样和拼接操作、适用于小样本数据和可扩展性。<br> 缺点：容易出现过拟合、对大尺寸图像处理较慢和对目标形状变化较大的图像分割效果较差。<br> <img src="https://images2.imgbox.com/ab/81/tcN8nACz_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4_83"></a>4.基于全局上下文</h3> 
<h4><a id="ParseNet_84"></a>①ParseNet</h4> 
<p>（1）对全卷积神经网络的改进。添加了全局特征或全局上下文信息，以实现更好的细分。作者使用了全局平均池来提取全局上下文信息进而执行反池化，以得到与输入特征图相同的大小。将原始特征图和反池化后的特征图进行组合以预测最终的分类得分。</p> 
<p>优点：能够捕捉到图像的全局上下文信息，从而提供更全面的语义理解能力。<br> 缺点：计算量较大：引入全局特征和反池化操作会增加计算量，特别是在处理大尺寸图像时，可能会导致较高的计算成本和较慢的推理速度。</p> 
<h4><a id="GCN_89"></a>②GCN</h4> 
<p>GCN：与ParseNet一样，全局卷积网络也使用了全局特征和局部特征，使像素级预测更加准确。语义分割的任务是分类和定位任务的结合。这两个任务在本质上是相互矛盾的。分类应该是变换不变的，定位应该是变换敏感的。以前的最先进的模型更注重本地化，而不是分类。在GCN中，作者没有使用任何完全连接的层或全局池化层来保留空间信息。另一方面，他们使用了一个大的核大小（全局卷积）来使他们的网络变换在像素级分类的情况下不变。为了进一步细化边界，作者使用了边界细化（BR）块。如图12所示，使用ResNet作为骨干。GCN模块被插入到网络中，然后插入BR模块。然后用反褶积层对较低分辨率的分数图进行上采样，然后与较高的分数图相加，生成新的分数图进行最终分割。</p> 
<h3><a id="5Based_on_receptive_field_enlargement_and_multiscale_contextincorporation___93"></a>5.Based on receptive field enlargement and multi-scale contextincorporation 基于感受野扩大和多尺度上下文合并</h3> 
<h4><a id="PSPNet_94"></a>①PSPNet</h4> 
<p>Zhao等人提出的金字塔场景解析网络（PSPNet）也使用全局上下文信息进行更好的分割。在此模型中，作者在使用扩张FCN提取的最后一个特征图的顶部使用了金字塔池化模块。在“金字塔池化”模块中，使用4个不同金字塔级别（分别具有1×1、2×2、3×3和6×6）的全局池化操作得到4个全局特征图，随后应用1×1卷积层对下采样的特征图进行特征提取，然后并上采样到原始大小。最终这4个特征图外加输入特征图被合并在一起以包含局部和全局上下文信息。然后，它们再次由卷积层处理以生成逐像素预测。在图13中，显示了PSPNet的体系结构。</p> 
<h4><a id="GatedSCNN_98"></a>②Gated-SCNN</h4> 
<p>Takikawa等人提出了门控形状CNN（GSCNN）[94]用于语义分割。 如图15所示，GSCNN由两个网络流组成：常规流和形状流。 常规流是用于处理语义区域信息的经典CNN。 形状流由多个门控卷积层（GCL）组成，该层使用来自常规流的低级特征图来处理区域的边界信息。 两种流的输出都馈入融合模块。 在融合模块中，两个输出都使用Atrous Special Pyramid Pooling [83]模块进行组合。 ASPP的使用有助于他们的模型保留多尺度的上下文信息。 最终，Fusion模块生成了具有精确边界的对象的语义区域。</p> 
<h2><a id="_103"></a>三、总结讨论</h2> 
<h3><a id="1CNN_104"></a>1.研究内容：对基于CNN的不同语义分割模型进行调查。描述了不同的最新语义分割模型的架构细节</h3> 
<h3><a id="2_106"></a>2.论文的工作</h3> 
<p>①给出了基于CNN的图像分类和演化概况。<br> ②详细探讨了一些基于CNN的流行的最先进的分割模型。<br> ③比较这些模型的训练细节，以便清楚地了解超参数调优。<br> ④比较这些最先进的模型在不同数据集上的性能指标。</p> 
<h3><a id="3_113"></a>3.概括性的神经网络模型分类</h3> 
<p>（1）基于全卷积网络（FCN）。 FCN的主要变化是基本模型VGG16，双线性插值技术（用于对最终特征图进行上采样）和跳层连接（用于在最终层中组合低层和高层特征以进行细粒度语义分割），从而帮助该模型获得了最先进的结果。然而，FCN分割结果非常模糊。 为了减少歧义，从整个图像中获得上下文信息非常有帮助。 在[79]和[80]中，作者使用了上下文特征并获得了最先进的性能。 最近，在[81]中，作者使用完全卷积的双流融合网络进行交互式图像分割。</p> 
<p>（2）Chen等人在语义分割中融合了扩张卷积和条件随机场（CRF），并在3.2.2节中讨论了DeepLab [82]。 后来，作者在DeepLabv2中引入了ASPP [83]。 DeepLabv3 [84]走得更远，并使用了改进的ASPP模块来合并多个上下文。 DeepLab的所有三个版本均取得了良好的效果。</p> 
<p>（3）Deconvnet [85]使用卷积网络，然后使用层次结构相反的反卷积网络进行语义分割，如3.2.3节所述。 Ronneberger等人使用了一种称为U-Net的U形网络[86]，该网络具有收缩和扩展的路径来进行语义分割。收缩路径提取特征图并减少空间信息，这是传统的卷积网络。扩展路径将收缩的特征图作为输入并应用反卷积。在扩展路径的每个步骤中，网络将缩小的反卷积特征图与来自收缩路径的相应裁剪特征图连接起来。通过这种方式，U-Net将高级特征和低级空间信息结合在一起，以实现更精确的分段。第3.2.4节更详细地讨论了该模型。最近，在[87]中，作者将带有multiRes块的U-Net用于多模态生物医学图像分割，并且比使用经典U-Net获得了更好的结果。 SegNet [88]是用于语义分段的编码器-解码器网络。编码器是基本的VGG16网络，不包括FC层。解码器与编码器相同，但是层在层次上相反。解码器使用卷积和反池化操作获得大小与输入图像相似的特征图，以精确定位已分割的对象。 SegNet在3.2.7节中讨论。除了一些单独的修改外，U-Net，Deconvnet和SegNet的基本体系结觉相似。这些体系结构的后半部分是前半部分的镜像。</p> 
<p>（4）Liu等人在FCN [78]体系结构中混合了全局平均池和L2归一化层，并提出了ParseNet [89]在各种数据集中获得最新的结果。 赵等提出了金字塔场景解析网络（PSPNet）[90]。 他们在最后提取的特征图的顶部使用了金字塔聚合模块，以整合全局上下文信息以进行更好的分割。 Peng等人使用了大内核的全局卷积的思想来利用局部和全局特征的优势[91]。 金字塔注意力网络（PAN）[92]，ParseNet [89]，PSPNet [90]和GCN [91]使用全局上下文信息和局部特征进行更好的分割。 第3.2.6、3.2.9和3.2.8节将详细讨论这些模型。</p> 
<p>（5）全卷积DenseNet [10]在[93，94]中用于解决语义分割问题。 DeepU-Net [95]，基于ResNet的FCN，用于分割海域。 同时，ENet [96]，ICNet [97]被用作自动驾驶汽车的实时语义分割模型。 最近的一些著作[98，99，100]结合使用了编码器-解码器体系结构和扩张卷积来进行更好的分割。 Kirillov等人[101] 在DeepLabV3 [84]和语义FPN [102]中使用了基于点的渲染，并产生了最新的语义分割模型。</p> 
<h3><a id="4_125"></a>4.不同模型的性能对比</h3> 
<p><img src="https://images2.imgbox.com/05/be/IXz4joch_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/92470fdb3f1fbbea16ff1e850314cfdb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JS数组已经有42个方法了</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b71266929d9c1d8e0ee07f1464756a63/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue3&#43;ts&#43;vite&#43;elementPlus后台管理系统学习总结01</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>