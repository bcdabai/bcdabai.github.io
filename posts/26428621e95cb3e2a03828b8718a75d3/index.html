<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>视觉 注意力机制——通道注意力、空间注意力、自注意力 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="视觉 注意力机制——通道注意力、空间注意力、自注意力" />
<meta property="og:description" content="前言 本文介绍注意力机制的概念和基本原理，并站在计算机视觉CV角度，进一步介绍通道注意力、空间注意力、混合注意力、自注意力等。
目录
前言
一、注意力机制
二、通道注意力机制
三、空间注意力机制
四、混合注意力机制 五、自注意力机制
六、注意力基础
6.1 注意力机制原理
6.2 注意力机制计算过程
一、注意力机制 我们可以通过眼睛看到各种各样的事物，感知世界上的大量信息；可以让自己免受海量信息的干扰，是因为人的选择能力，可以选择重要的信息，而忽视不重要信息。
举个例子，下面有一张图片，当我们看到这张图片的时候会下意识把注意力集中到熊猫的身上，而忽略背景。
即：在观看这幅图像的时候，并非能够对图片的所有信息给予相同的关注度，而是将注意力着重放在某个局部区域。
同样，希望网络也具有这种能力，从而在网络中引入了注意力机制。注意力机制，是对输入进行加权再输出，希望网络关注到的地方给较大的权重，不希望网络注意的地方给较小的权重。
再举个例子，在自然语言处理领域，在分析一句话的时候，并不是所有的词的信息都需要被关注，可以选择重要的词分析，即可理解句子所传达的语义。
二、通道注意力机制 通道注意力机制的代表模型是：压缩和激励网络（Squeeze-and-Excitation Networks，SENet）。SENet 分为压缩和激励两个部分，其中压缩部分的目的是对全局空间信息进行压缩，然后在通道维度进行特征学习，形成各个通对道的重要性，最后通过激励部分对各个通道进行分配不同权重的。
上图是SE模块的结构， 在压缩部分，输入的元素特征图的维度是 H×W×C，H、W 和 C 分别代表高度、宽度和通道数。压缩部分的功能是将维数从 H×W×C 压缩至1×1×C，即把 H×W 压缩为 1×1 维，这个过程由全局平均池化实现。
在激励部分，需要将压缩部分得到的 1×1×C 的维度融入全连接层，预测各个通道的重要程度，然后再激励到前面特征图对应通道上进行操作。采用简单的门控机制与Sigmoid 激活函数。
小结：在通道注意力机制，学习各个通道的重要性时，是先对特征图的空间进行压缩，然后在通道维度进行学习，得到各个通道的重要性。
三、空间注意力机制 空间注意力机制的代表模型是：空间变换神经网络（Spatial Transformer Networks，STN），STN 能够对各种形变数据在空间中进行转换并自动捕获重要区域特征。它能够保证图像在经过裁剪、平移或者旋转等操作后，依然可以获得和操作前的原始图像相同的结果。
举个例子，在MNIST 数字分类的中应用STN，该分类过程一共包含 4 个步骤：
MNIST中的数字，是经过随机平移、缩放和旋转处理；把它们输入到STN网络中；通过STN网络，预测前面输入数字的变换（是平移了？还是缩放了？或是旋转了？）STN网络预测出“变换前的数字”，即没经过变换的数字是怎样的最终进行分类预测 STN 网络包括局部网络、参数化网络采样（网络生成器）和差分图像采样。
局部网络：预测输入数字的变换（是平移了？还是缩放了？或是旋转了？）
网络生成器：获得输出特征图坐标点在输入特征图中坐标点的对应位置。
四、混合注意力机制 在混合注意力机制中，通道注意力和空间注意力可以通过串联、或者并联的方式进行组合。
混合注意力机制的代表模型是：卷积注意力模块（Convolutional Block Attention Module，CBAM），它包括通道注意力模块CAM、和空间注意力模块SAM。
CBAM的模型结构如下，它对输入的特征图，首先进行通道注意力模块处理；得到的结果，再经过空间注意力模块处理，最后得到调整后特征。
通道注意力模块CAM
CAM的输入是特征图，维度设为HxWxC；其中H是指特征图的高度，W是指宽度，C是指通道数。
它的思路流程是：
首先对输入的特征图，进行全局池化和平均池化；（在空间维度进行池化，压缩空间尺寸；便于后面学习通道的特征）然后将得到全局和评价池化的结果，送入到多层感知机中MLP学习；（基于MLP学习通道维度的特征，和各个通道的重要性）最后将MLP输出额结果，进行“加”操作，接着经过Sigmoid函数的映射处理，得到最终的“通道注意力值”。 计算公式如下：
空间注意力模块SAM
SAM的输入是CAM输出的特征图。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/26428621e95cb3e2a03828b8718a75d3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-21T21:36:06+08:00" />
<meta property="article:modified_time" content="2022-09-21T21:36:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">视觉 注意力机制——通道注意力、空间注意力、自注意力</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="%E5%89%8D%E8%A8%80">前言</h3> 
<p>本文介绍注意力机制的概念和基本原理，并站在计算机视觉CV角度，进一步介绍通道注意力、空间注意力、混合注意力、自注意力等。</p> 
<p></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:40px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E4%B8%80%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">一、注意力机制</a></p> 
<p id="%E4%BA%8C%E3%80%81%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%E3%80%81%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">二、通道注意力机制</a></p> 
<p id="%E4%B8%89%E3%80%81%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><a href="#%E4%B8%89%E3%80%81%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">三、空间注意力机制</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%B7%B7%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%C2%A0-toc" style="margin-left:40px;"><a href="#%E5%9B%9B%E3%80%81%E6%B7%B7%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%C2%A0" rel="nofollow">四、混合注意力机制 </a></p> 
<p id="%E4%BA%94%E3%80%81%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><a href="#%E4%BA%94%E3%80%81%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">五、自注意力机制</a></p> 
<p id="%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9F%BA%E7%A1%80-toc" style="margin-left:40px;"><a href="#%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9F%BA%E7%A1%80" rel="nofollow">六、注意力基础</a></p> 
<p id="1.1%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86-toc" style="margin-left:80px;"><a href="#1.1%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86" rel="nofollow"> 6.1 注意力机制原理</a></p> 
<p id="1.2%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#1.2%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B" rel="nofollow">6.2 注意力机制计算过程</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h3 id="%E4%B8%80%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">一、注意力机制</h3> 
<p>我们可以通过眼睛看到各种各样的事物，感知世界上的大量信息；可以让自己免受海量信息的干扰，是因为人的选择能力，可以<span style="color:#b95514;"><strong>选择重要的信息</strong></span>，而<span style="color:#1a439c;"><strong>忽视不重要信息</strong></span>。</p> 
<p><strong>举个例子</strong>，下面有一张图片，当我们看到这张图片的时候会下意识把注意力集中到熊猫的身上，而忽略背景。</p> 
<p><img alt="" height="401" src="https://images2.imgbox.com/26/a2/PypZadF9_o.png" width="597"></p> 
<blockquote> 
 <p>即：在观看这幅图像的时候，并非能够对图片的所有信息给予相同的关注度，而是将注意力着重放在某个局部区域。</p> 
</blockquote> 
<p>同样，希望网络也具有这种能力，从而在网络中引入了注意力机制。注意力机制，是对输入进行加权再输出，希望网络关注到的地方给较大的权重，不希望网络注意的地方给较小的权重。</p> 
<p></p> 
<p><strong>再举个例子</strong>，在自然语言处理领域，在分析一句话的时候，并不是所有的词的信息都需要被关注，可以选择重要的词分析，即可理解句子所传达的语义。</p> 
<p></p> 
<p></p> 
<h3 id="%E4%BA%8C%E3%80%81%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">二、通道注意力机制</h3> 
<p>通道注意力机制的代表模型是：压缩和激励网络（Squeeze-and-Excitation Networks，SENet）。SENet 分为<span style="color:#b95514;"><strong>压缩和激励两个部分</strong></span>，其中<span style="color:#511b78;">压缩部分的目的是对全局空间信息进行压缩，然后在通道维度进行特征学习，形成各个通对道的重要性</span>，最后通过激励部分对各个通道进行分配不同权重的。</p> 
<p><img alt="" height="266" src="https://images2.imgbox.com/6c/84/hIjSVgDS_o.png" width="893"></p> 
<p>上图是SE模块的结构， 在<span style="color:#1c7331;"><strong>压缩部分</strong></span>，输入的元素特征图的维度是 H×W×C，H、W 和 C 分别代表高度、宽度和通道数。压缩部分的功能是将维数从 H×W×C 压缩至1×1×C，即把 H×W 压缩为 1×1 维，这个过程由全局平均池化实现。</p> 
<p>在<span style="color:#1a439c;"><strong>激励部分</strong></span>，需要将压缩部分得到的 1×1×C 的维度融入全连接层，预测各个通道的重要程度，然后再激励到前面特征图对应通道上进行操作。采用简单的门控机制与Sigmoid 激活函数。</p> 
<blockquote> 
 <p>小结：在通道注意力机制，学习各个通道的重要性时，是先对特征图的空间进行压缩，然后在通道维度进行学习，得到各个通道的重要性。</p> 
</blockquote> 
<p></p> 
<h3 id="%E4%B8%89%E3%80%81%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">三、空间注意力机制</h3> 
<p>空间注意力机制的代表模型是：空间变换神经网络（Spatial Transformer Networks，STN），STN 能够<span style="color:#b95514;"><strong>对各种形变数据在空间中进行转换</strong></span>并<span style="color:#1a439c;"><strong>自动捕获重要区域特征</strong></span>。它能够保证图像在经过裁剪、平移或者旋转等操作后，依然可以获得和操作前的原始图像相同的结果。</p> 
<p>举个例子，在MNIST 数字分类的中应用STN，该分类过程一共包含 4 个步骤：</p> 
<ol><li>MNIST中的数字，是经过随机平移、缩放和旋转处理；把它们输入到STN网络中；</li><li>通过STN网络，预测前面输入数字的变换（是平移了？还是缩放了？或是旋转了？）</li><li>STN网络预测出“变换前的数字”，即没经过变换的数字是怎样的</li><li>最终进行分类预测</li></ol> 
<p><img alt="" height="344" src="https://images2.imgbox.com/ef/35/zKe52utD_o.png" width="494"></p> 
<p> STN 网络包括局部网络、参数化网络采样（网络生成器）和差分图像采样。</p> 
<p>局部网络：预测输入数字的变换（是平移了？还是缩放了？或是旋转了？）</p> 
<p>网络生成器：获得输出特征图坐标点在输入特征图中坐标点的对应位置。</p> 
<p><img alt="" height="361" src="https://images2.imgbox.com/20/6c/2prgREmI_o.png" width="858"></p> 
<p></p> 
<p></p> 
<h3 id="%E5%9B%9B%E3%80%81%E6%B7%B7%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%C2%A0">四、混合注意力机制 </h3> 
<p>在混合注意力机制中，通道注意力和空间注意力可以通过串联、或者并联的方式进行组合。</p> 
<p>混合注意力机制的代表模型是：卷积注意力模块（Convolutional Block Attention Module，CBAM），它包括通道注意力模块CAM、和空间注意力模块SAM。</p> 
<p>CBAM的模型结构如下，它对输入的特征图，首先进行通道注意力模块处理；得到的结果，再经过空间注意力模块处理，最后得到调整后特征。</p> 
<p><img alt="" height="226" src="https://images2.imgbox.com/77/a0/CqkL5ZJn_o.png" width="654"></p> 
<p></p> 
<p><strong>通道注意力模块CAM</strong></p> 
<p>CAM的输入是特征图，维度设为HxWxC；其中H是指特征图的高度，W是指宽度，C是指通道数。</p> 
<p>它的思路流程是：</p> 
<ol><li>首先对输入的特征图，进行全局池化和平均池化；（在空间维度进行池化，压缩空间尺寸；便于后面学习通道的特征）</li><li>然后将得到全局和评价池化的结果，送入到多层感知机中MLP学习；（基于MLP学习通道维度的特征，和各个通道的重要性）</li><li>最后将MLP输出额结果，进行“加”操作，接着经过Sigmoid函数的映射处理，得到最终的“通道注意力值”。</li></ol> 
<p><img alt="" height="205" src="https://images2.imgbox.com/0b/fa/XxOEkRrw_o.png" width="675"></p> 
<p>计算公式如下：</p> 
<p><img alt="" height="88" src="https://images2.imgbox.com/a9/06/9X4Wyrh9_o.png" width="476"></p> 
<p></p> 
<p><strong>空间注意力模块SAM</strong></p> 
<p>SAM的输入是CAM输出的特征图。</p> 
<p>它的思路流程是：</p> 
<ol><li>首先对输入的特征图，进行全局池化和平均池化；（在通道维度进行池化，压缩通道大小；便于后面学习空间的特征）</li><li>然后将全局池化和平均池化的结果，按照通道拼接；得到特征图维度是HxWx2，</li><li>最后对拼接的结果，进行卷积操作，得到特征图维度是HxWx1；接着通过激活函数处理。</li></ol> 
<p><img alt="" height="247" src="https://images2.imgbox.com/dd/01/6Zkz3KXm_o.png" width="719"></p> 
<p>计算公式如下：</p> 
<p><img alt="" height="85" src="https://images2.imgbox.com/58/76/D43CRvVj_o.png" width="420"></p> 
<p></p> 
<h3 id="%E4%BA%94%E3%80%81%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">五、自注意力机制</h3> 
<p>背景</p> 
<p>  在注意力机制引入计算机视觉前，主要是靠叠加卷积层与池化层来进行特征提取，并扩大感受野。举个例子，在语义分割中，Deeplab系列提出的带有<span style="color:#1c7331;"><strong>多尺度空洞卷积的 ASPP 模块</strong></span>：</p> 
<ul><li>ASPP对输入的特征图，采用不同dilation rate 的空洞卷积进行卷积操作，以多个不同比例获取图像的上下文信息。</li><li>ASPP模块只能利用空洞卷积从<span style="color:#b95514;"><strong>像素点周围</strong></span>的<span style="color:#b95514;"><strong>少数点去</strong></span>获取上下文信息，而不能形成<span style="color:#511b78;"><strong>密集的全局上下文信息</strong></span>。</li></ul> 
<blockquote> 
 <p>为了获得<span style="color:#1a439c;">密集</span>的全局上下文信息，从而<span style="color:#1a439c;">建立像素两两之间的依赖关系</span>，引入“自注意力机制”。</p> 
</blockquote> 
<p></p> 
<h3 id="%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9F%BA%E7%A1%80">六、注意力基础</h3> 
<h4 id="1.1%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86"> 6.1 注意力机制原理</h4> 
<p>注意力机制在语义分割和图像描述生成方面被广泛使用。使用注意力处理任务时，不同信息的重要程度由权值来体现。</p> 
<p>注意力机制对<span style="color:#b95514;"><strong>不同信息关注度</strong></span>的<span style="color:#ad720d;"><strong>区分体现在权值分配</strong></span>，注意力机制可以视为<span style="color:#1a439c;"><strong>查询矩阵</strong></span>、<span style="color:#1a439c;"><strong>键</strong></span>以及<span style="color:#1a439c;"><strong>加权平均值</strong></span>构成了多层感知机(Multilayer Perceptron, MLP)。</p> 
<p>注意力的思想，类似于寻址。给定 Query，去 Source 中计算 Query和不同 Key 的相关性，即计算 Source 中不同 Value 值的权重系数；Value 的加权平均结果可以作为注意力值。</p> 
<p><img alt="" height="269" src="https://images2.imgbox.com/0e/fe/2nKhkfgw_o.png" width="605"></p> 
<p>注意力的计算公式如下：<br><img alt="Attention(Query , Source)=\sum_{i=1}^{Lx}Similarity(Query , Key_{i})*Value_{i}" class="mathcode" src="https://images2.imgbox.com/3d/88/8HD5QHio_o.png"></p> 
<p>其中，Lx代表Source的长度。</p> 
<p></p> 
<h4 id="1.2%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B">6.2 注意力机制计算过程</h4> 
<p>大多数方法采用的注意力机制计算过程可以细化为如下三个阶段。</p> 
<p>三阶段的注意力机制计算流程：</p> 
<ul><li>第一阶段是计算 Query和不同 Key 的相关性，即计算不同 Value 值的权重系数；</li><li>第二阶段对上一阶段的输出进行归一化处理，将数值的范围映射到 0 和 1 之间。</li><li>第三阶段，对值和每个值对应的权重相乘的结果做累加操作，从而获得注意力数值。</li></ul> 
<p><img alt="" height="663" src="https://images2.imgbox.com/25/f8/wXGe5eov_o.png" width="793"></p> 
<p></p> 
<p>公式化表示：</p> 
<p>第一阶段是计算 Query和不同 Key 的相关性，即计算不同 Value 值的权重系数；相关性计算主要包括<span style="color:#1c7331;"><strong>点积</strong></span>、<span style="color:#1a439c;"><strong>余弦相似性</strong></span>或者引入<span style="color:#b95514;"><strong>神经网络</strong></span>这三种方法。计算方式分别如下：<br><img alt="" height="168" src="https://images2.imgbox.com/ad/74/wnD2lQGJ_o.png" width="381"></p> 
<p> 第二阶段对上一阶段的输出进行归一化处理，将数值的范围映射到 0 和 1 之间。其中，ai表第 i 个值被分为的权重值。</p> 
<p><img alt="" height="104" src="https://images2.imgbox.com/3f/da/qgL2h23O_o.png" width="270"></p> 
<p> 第三阶段，对值和每个值对应的权重相乘的结果做累加操作，从而获得注意力数值。</p> 
<p><img alt="" height="57" src="https://images2.imgbox.com/ca/60/fE5CE19o_o.png" width="321"></p> 
<p></p> 
<p></p> 
<p></p> 
<p>参考文献</p> 
<p>[1] 谢雨杉. 基于深度神经网络的图像语义分割技术研究[D].成都：电子科技大学，2022.</p> 
<p>[2] 冀芒来. 基于注意力机制的道路驾驶场景实时语义分割[D].吉林：吉林大学，2022.</p> 
<p></p> 
<p>本文只是简单介绍了注意力机制中的通道注意力、空间注意力、自注意力，后续文章会分别详细介绍，其中的模型包括：SK-Net、ResNeSt、DANet、PFANet、SOCA、ECA-Net等等</p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0b0ba309875545acdeedcccaf16857bc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Linux下实现Mysql的主从复制】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/64d4e600d0397e0b875dc9abeaa26f8d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Ubuntu下安装OpenCV4.6.0并使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>