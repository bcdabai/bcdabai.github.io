<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>学习Hadoop&#43;spark集群错误笔记备忘 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="学习Hadoop&#43;spark集群错误笔记备忘" />
<meta property="og:description" content="Hadoop&#43;Spark错误i笔记： 环境：Hadoop2.9.1&#43;Spark2.3.1&#43;JKD1.8&#43;centos6.9 32bit &#43; hive2.3.3
Hadoop 1.
Java HotSpot(TM) Client VM warning: You have loaded library /usr/local/bigdata/hadoop/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now. It&#39;s highly recommended that you fix the library with &#39;execstack -c &lt;libfile&gt;&#39;, or link it with &#39;-z noexecstack&#39;. 参考：https://blog.csdn.net/milhua/article/details/78711895 解决： hadoop-env.sh和yarn-env.sh中添加如下两行：
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}/lib/native export HADOOP_OPTS=&#34;-Djava.library.path=$HADOOP_PREFIX/lib&#34; 2.无论是32未机器还是64位机器都报这个错误，郁闷。。。。
18/08/06 20:05:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c4e1ae736870bfa91733a8f05ce39928/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-06T21:29:02+08:00" />
<meta property="article:modified_time" content="2018-08-06T21:29:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">学习Hadoop&#43;spark集群错误笔记备忘</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>Hadoop+Spark错误i笔记： <br> 环境：Hadoop2.9.1+Spark2.3.1+JKD1.8+centos6.9 32bit + hive2.3.3</p> 
<h3 id="hadoop">Hadoop</h3> 
<p>1.</p> 
<pre class="prettyprint"><code class=" hljs applescript">Java HotSpot(TM) Client VM warning: You have loaded library /usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/lib/native/libhadoop.so<span class="hljs-number">.1</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> which might have disabled stack guard. The VM will <span class="hljs-keyword">try</span> <span class="hljs-keyword">to</span> fix <span class="hljs-keyword">the</span> stack guard now.
It's highly recommended <span class="hljs-keyword">that</span> you fix <span class="hljs-keyword">the</span> library <span class="hljs-keyword">with</span> 'execstack -c &lt;libfile&gt;', <span class="hljs-keyword">or</span> link <span class="hljs-keyword">it</span> <span class="hljs-keyword">with</span> '-z noexecstack'.</code></pre> 
<p>参考：<a href="https://blog.csdn.net/milhua/article/details/78711895">https://blog.csdn.net/milhua/article/details/78711895</a> <br> 解决： <br> hadoop-env.sh和yarn-env.sh中添加如下两行：</p> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">${HADOOP_PREFIX}</span>/lib/native  
<span class="hljs-keyword">export</span> HADOOP_OPTS=<span class="hljs-string">"-Djava.library.path=<span class="hljs-variable">$HADOOP_PREFIX</span>/lib"</span>  
</code></pre> 
<p>2.无论是32未机器还是64位机器都报这个错误，郁闷。。。。</p> 
<pre class="prettyprint"><code class=" hljs oxygene"><span class="hljs-number">18</span>/<span class="hljs-number">08</span>/<span class="hljs-number">06</span> <span class="hljs-number">20</span>:<span class="hljs-number">05</span>:<span class="hljs-number">13</span> WARN util.NativeCodeLoader: Unable <span class="hljs-keyword">to</span> load native-hadoop <span class="hljs-keyword">library</span> <span class="hljs-keyword">for</span> your <span class="hljs-keyword">platform</span>... <span class="hljs-keyword">using</span> builtin-java classes <span class="hljs-keyword">where</span> applicable
stopping yarn daemons</code></pre> 
<p>参考：<a href="https://blog.csdn.net/l1028386804/article/details/51538611">https://blog.csdn.net/l1028386804/article/details/51538611</a> <br> 解决： <br> 在//usr/local/hadoop-2.5.2/etc/hadoop/log4j.properties文件中添加</p> 
<pre class="prettyprint"><code class=" hljs avrasm">log4j<span class="hljs-preprocessor">.logger</span><span class="hljs-preprocessor">.org</span><span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.util</span><span class="hljs-preprocessor">.NativeCodeLoader</span>=ERROR
</code></pre> 
<p><strong>SPARK</strong></p> 
<p>1.spark on yarn</p> 
<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-label">SLF4J:</span> Class path contains multiple SLF4J bindings.
<span class="hljs-label">SLF4J:</span> Found binding <span class="hljs-keyword">in</span> [jar:file:/tmp/hadoop-root/nm-local-dir/usercache/root/filecache/<span class="hljs-number">22</span>/__spark_libs__1623923019181416508<span class="hljs-preprocessor">.zip</span>/slf4j-log4j12-<span class="hljs-number">1.7</span><span class="hljs-number">.16</span><span class="hljs-preprocessor">.jar</span>!/org/slf4j/impl/StaticLoggerBinder<span class="hljs-preprocessor">.class</span>]
<span class="hljs-label">SLF4J:</span> Found binding <span class="hljs-keyword">in</span> [jar:file:/usr/local/bigdata/hadoop/share/hadoop/common/lib/slf4j-log4j12-<span class="hljs-number">1.7</span><span class="hljs-number">.25</span><span class="hljs-preprocessor">.jar</span>!/org/slf4j/impl/StaticLoggerBinder<span class="hljs-preprocessor">.class</span>]
<span class="hljs-label">SLF4J:</span> See http://www<span class="hljs-preprocessor">.slf</span>4j<span class="hljs-preprocessor">.org</span>/codes<span class="hljs-preprocessor">.html</span><span class="hljs-preprocessor">#multiple_bindings for an explanation.</span>
<span class="hljs-label">SLF4J:</span> Actual binding is of type [org<span class="hljs-preprocessor">.slf</span>4j<span class="hljs-preprocessor">.impl</span><span class="hljs-preprocessor">.Log</span>4jLoggerFactory]</code></pre> 
<p>问题：jar包冲突 <br> 解决：find / -name “slf4j*”</p> 
<pre class="prettyprint"><code class=" hljs perl">[root<span class="hljs-variable">@centos01</span> conf]<span class="hljs-comment"># find / -name "slf4j*"</span>
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/common/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/common/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/spark/jars/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">16</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/spark/jars/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">16</span>.jar
[root<span class="hljs-variable">@centos01</span> conf]<span class="hljs-comment"># mv /usr/local/bigdata/spark/jars/slf4j-api-1.7.16.jar /usr/local/bigdata/spark/jars/slf4j-api-1.7.16.jar.bak</span>
[root<span class="hljs-variable">@centos01</span> conf]<span class="hljs-comment"># mv /usr/local/bigdata/spark/jars/slf4j-log4j12-1.7.16.jar /usr/local/bigdata/spark/jars/slf4j-log4j12-1.7.16.jar.bak</span>
[root<span class="hljs-variable">@centos01</span> conf]<span class="hljs-comment"># find / -name "slf4j*"</span>
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/common/lib/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/hadoop/share/hadoop/common/lib/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">25</span>.jar
/usr/<span class="hljs-keyword">local</span>/bigdata/spark/jars/slf4j-log4j12-<span class="hljs-number">1.7</span>.<span class="hljs-number">16</span>.jar.bak
/usr/<span class="hljs-keyword">local</span>/bigdata/spark/jars/slf4j-api-<span class="hljs-number">1.7</span>.<span class="hljs-number">16</span>.jar.bak</code></pre> 
<p>3.</p> 
<pre class="prettyprint"><code class=" hljs http"><span class="hljs-attribute">java.lang.NoClassDefFoundError</span>: <span class="hljs-string">org/apache/hadoop/fs/FSDataInputStream</span></code></pre> 
<p>原因： 从spark1.4以后，所有spark的编译都是没有将hadoop的classpath编译进去的，所以必须在spark-env.sh中指定hadoop中的所有jar包。 <br> 参考： <a href="https://www.cnblogs.com/yanghuabin/p/8329205.html" rel="nofollow">https://www.cnblogs.com/yanghuabin/p/8329205.html</a> <br> 解决：spark-env.sh：</p> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">export</span> SPARK_DIST_CLASSPATH=$(<span class="hljs-variable">${HADOOP_HOME}</span>/bin/hadoop classpath)</code></pre> 
<p><strong>HIVE</strong></p> 
<pre class="prettyprint"><code class=" hljs avrasm">Caused by: java<span class="hljs-preprocessor">.net</span><span class="hljs-preprocessor">.URISyntaxException</span>: Relative path <span class="hljs-keyword">in</span> absolute URI: ${system:java<span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.tmpdir</span>%<span class="hljs-number">7</span>D/$%<span class="hljs-number">7</span>Bhive<span class="hljs-preprocessor">.session</span><span class="hljs-preprocessor">.id</span>%<span class="hljs-number">7</span>D_resources</code></pre> 
<p>解决：hive-site.xml <br> 将$ {system:java.io.tmpdir}全部改为自定义路径，如：/home/tmpdir</p> 
<p>接着：</p> 
<pre class="prettyprint"><code class=" hljs avrasm">hive&gt; show tables<span class="hljs-comment">;</span>
<span class="hljs-label">FAILED:</span> SemanticException org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.ql</span><span class="hljs-preprocessor">.metadata</span><span class="hljs-preprocessor">.HiveException</span>: java<span class="hljs-preprocessor">.lang</span><span class="hljs-preprocessor">.RuntimeException</span>: Unable to instantiate org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.hive</span><span class="hljs-preprocessor">.ql</span><span class="hljs-preprocessor">.metadata</span><span class="hljs-preprocessor">.SessionHiveMetaStoreClient</span></code></pre> 
<p>都是版本惹的祸，谁让我总追求最新版本呢。 <br> 解决： 退出hive, 执行：schematool -dbType mysql -initSchema 初始化元数据表。参考：<a href="https://blog.csdn.net/hhj724/article/details/79094138">https://blog.csdn.net/hhj724/article/details/79094138</a></p> 
<p>2.</p> 
<pre class="prettyprint"><code class=" hljs livecodeserver">ParseException <span class="hljs-built_in">line</span> <span class="hljs-number">3</span>:<span class="hljs-number">0</span> cannot recognize input near <span class="hljs-string">'timestamp'</span> <span class="hljs-string">'bigint'</span> <span class="hljs-string">','</span> <span class="hljs-operator">in</span> column name <span class="hljs-operator">or</span> primary key <span class="hljs-operator">or</span> foreign key</code></pre> 
<p>timestamp， date 字段为hive保留字，加上反斜杠即可保留，如：`date`, `timestamp` 。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ceb67331f24d6c8b00b4f0929e8bc3d1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Javascript内置对象之常用event对象</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eb273f86f0e76096f31a833c03a08e49/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">设计模式之Builder模式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>