<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习简单概念和pytorch代码-2 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习简单概念和pytorch代码-2" />
<meta property="og:description" content="机器学习简单概念和pytorch代码-2 学习率的选择和调校
特征工程 特征工程是数据预处理和分析过程中的一个关键步骤，主要用于机器学习和数据挖掘。它涉及到从原始数据中选择、修改和创建新的特征（即数据的属性或变量），以便提高模型的性能。在机器学习中，特征工程对于提高模型的准确性和效率至关重要。它包括以下几个主要步骤：
特征选择：从现有的特征集中选择最重要的特征，以减少维度并提高模型的效率。
特征提取：将原始数据转换为能够更好地表示问题的特征。这通常涉及到提取信息或减少维度，例如通过主成分分析（PCA）。
特征构造：基于现有数据创造新的特征，以揭示数据中的潜在模式或关系。
特征转换：对特征进行标准化、归一化或其他转换，使模型更容易处理。例如，将所有特征缩放到相同的范围。
特征编码：将非数值特征转换为数值格式，如将分类数据转换为独热编码（One-Hot Encoding）。
特征工程的主要目的是通过这些技术改进模型的性能，使其能够更有效地学习、理解和预测数据。在许多机器学习任务中，好的特征工程往往比选择高级模型更为重要。
多项式回归 import torch import torch.nn as nn import torch.optim as optim import numpy as np import matplotlib.pyplot as plt # 检查CUDA是否可用，并设置device变量 device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;) print(torch.cuda.is_available()) # 创建数据集 x = torch.linspace(-3, 3, 100).unsqueeze(1).to(device) # x data (tensor), shape=(100, 1) y = 1 &#43; 2 * x &#43; 3 * x ** 2 &#43; torch.randn(x.size()).to(device) * 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3e1ab4c0a86ad0a05efd61956c5a76bb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-07T17:17:07+08:00" />
<meta property="article:modified_time" content="2024-01-07T17:17:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习简单概念和pytorch代码-2</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="pytorch2_0"></a>机器学习简单概念和pytorch代码-2</h3> 
<p>学习率的选择和调校<br> <img src="https://images2.imgbox.com/87/5b/m8EfKtEu_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_3"></a>特征工程</h3> 
<p>特征工程是数据预处理和分析过程中的一个关键步骤，主要用于机器学习和数据挖掘。它涉及到从原始数据中选择、修改和创建新的特征（即数据的属性或变量），以便提高模型的性能。在机器学习中，特征工程对于提高模型的准确性和效率至关重要。它包括以下几个主要步骤：</p> 
<ol><li> <p><strong>特征选择</strong>：从现有的特征集中选择最重要的特征，以减少维度并提高模型的效率。</p> </li><li> <p><strong>特征提取</strong>：将原始数据转换为能够更好地表示问题的特征。这通常涉及到提取信息或减少维度，例如通过主成分分析（PCA）。</p> </li><li> <p><strong>特征构造</strong>：基于现有数据创造新的特征，以揭示数据中的潜在模式或关系。</p> </li><li> <p><strong>特征转换</strong>：对特征进行标准化、归一化或其他转换，使模型更容易处理。例如，将所有特征缩放到相同的范围。</p> </li><li> <p><strong>特征编码</strong>：将非数值特征转换为数值格式，如将分类数据转换为独热编码（One-Hot Encoding）。</p> </li></ol> 
<p>特征工程的主要目的是通过这些技术改进模型的性能，使其能够更有效地学习、理解和预测数据。在许多机器学习任务中，好的特征工程往往比选择高级模型更为重要。</p> 
<h3><a id="_17"></a>多项式回归</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 检查CUDA是否可用，并设置device变量</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 创建数据集</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># x data (tensor), shape=(100, 1)</span>
y <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.5</span>  <span class="token comment"># noisy y data (tensor), shape=(100, 1)</span>

<span class="token comment"># 定义多项式模型</span>
<span class="token keyword">class</span> <span class="token class-name">PolyModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>PolyModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>poly <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 一个线性层，输入特征为3（x, x^2, 常数项）</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        poly_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 构造多项式特征</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>poly<span class="token punctuation">(</span>poly_x<span class="token punctuation">)</span>

<span class="token comment"># 实例化模型、定义损失函数和优化器</span>
model <span class="token operator">=</span> PolyModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
epochs <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

    <span class="token comment"># 反向传播和优化</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果</span>
predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将数据移回CPU来进行绘图</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Original data'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Fitted line'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/18/ae/eUENhBCR_o.png" alt="在这里插入图片描述"><br> 使用scikit-learn</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> PolynomialFeatures
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token punctuation">,</span> r2_score

<span class="token comment"># 生成数据</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.5</span>
x <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span>  <span class="token comment"># 将x转换成二维数组，用于后续处理</span>

<span class="token comment"># 创建多项式特征</span>
poly_features <span class="token operator">=</span> PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> include_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
x_poly <span class="token operator">=</span> poly_features<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
model <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_poly<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment"># 预测</span>
y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_poly<span class="token punctuation">)</span>

<span class="token comment"># 计算评估指标</span>
mse <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
r2 <span class="token operator">=</span> r2_score<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>

<span class="token comment"># 打印系数和评估指标</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Model coefficients:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Model intercept:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Mean squared error:"</span><span class="token punctuation">,</span> mse<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Coefficient of determination (R^2):"</span><span class="token punctuation">,</span> r2<span class="token punctuation">)</span>

<span class="token comment"># 绘制结果</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Original data"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Fitted line"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/d2/d3/ka1qrHSH_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="logistic_regression_118"></a>logistic regression</h3> 
<p>Logistic回归是一种广泛用于分类任务的统计方法，尤其是在二分类问题中非常常见。尽管名称中包含“回归”，它实际上是一种分类算法，而不是回归算法。它的核心思想是利用logistic函数（或称为sigmoid函数）来估算概率，从而将线性回归模型的输出转换为介于0和1之间的概率值。</p> 
<h4><a id="LogisticSigmoid_121"></a>Logistic函数（Sigmoid函数）</h4> 
<p>Logistic回归的核心是logistic函数，也称为sigmoid函数。这个函数的公式是：</p> 
<p>[ \sigma(z) = \frac{1}{1 + e^{-z}} ]</p> 
<p>这里的(z)通常是特征和权重的线性组合，即(z = w_1x_1 + w_2x_2 + … + w_nx_n + b)。sigmoid函数将任何实数映射到(0, 1)区间，这使得它可以被解释为概率。</p> 
<h4><a id="_129"></a>二分类</h4> 
<p>在二分类问题中，Logistic回归模型预测样本属于某个类别的概率。如果这个概率大于0.5，我们可以将样本分类为正类（通常标记为1）；如果小于0.5，则分类为负类（标记为0）。</p> 
<h4><a id="_133"></a>模型训练</h4> 
<p>Logistic回归模型通过最大化观测数据的似然函数来进行训练。这通常通过一种名为“逻辑损失”或“交叉熵损失”的损失函数来实现。模型训练的目标是找到一组权重，使得模型对训练数据的分类尽可能准确。</p> 
<h4><a id="_137"></a>应用领域</h4> 
<p>Logistic回归由于其简单性和高效性，在许多领域都有广泛的应用，如医疗疾病预测、信用评分、市场营销响应预测等。它也是许多复杂分类算法和神经网络的基础。</p> 
<h4><a id="_141"></a>扩展</h4> 
<p>虽然最常见的是二分类的Logistic回归，但它也可以被扩展到多分类问题（例如，使用softmax函数代替sigmoid函数）。在多分类Logistic回归中，模型会估计一个样本属于每个类别的概率，并将其分类到概率最高的类别。</p> 
<pre><code class="prism language-python"><span class="token comment"># 导入必要的库</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_classification

<span class="token comment"># 设置随机种子，以便结果可复现</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 检查CUDA是否可用，并设置device变量</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment"># 创建数据集</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_classification<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> n_redundant<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> n_informative<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                           random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> n_clusters_per_class<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 转换数据类型</span>
features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义Logistic回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegressionModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> y_pred

<span class="token comment"># 实例化模型，并移动到GPU（如果可用）</span>
model <span class="token operator">=</span> LogisticRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
epochs <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">)</span>

    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

    <span class="token comment"># 反向传播和优化</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果（注意：绘图部分需要在CPU上进行）</span>
features_cpu <span class="token operator">=</span> features<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
labels_cpu <span class="token operator">=</span> labels<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
model_cpu <span class="token operator">=</span> model<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">plot_decision_boundary</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    y_min<span class="token punctuation">,</span> y_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span> x_max<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span> y_max<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 预测整个网格</span>
    Z <span class="token operator">=</span> model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>view<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Feature 1'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Feature 2'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Logistic Regression Decision Boundary'</span><span class="token punctuation">)</span>

plot_decision_boundary<span class="token punctuation">(</span>features_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/9b/19/Snh3m6ph_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Decision_Boundary_227"></a>决策边界（Decision Boundary）</h3> 
<p>决策边界（Decision Boundary）是在分类问题中用来区分不同类别的边界。在一个分类模型中，决策边界定义了输入空间中一组点，这些点被模型划分为不同的类别。根据模型的复杂性和特征的数量，决策边界可以是直线、曲线或多维曲面。</p> 
<h4><a id="_231"></a>在不同类型的模型中的决策边界</h4> 
<ul><li> <p><strong>线性模型</strong>：在线性模型（如线性回归、Logistic回归）中，决策边界是一个直线（在二维空间）或一个平面（在三维空间）。例如，在二维空间中，Logistic回归的决策边界可能是一条直线，将数据点分为两部分，一部分属于正类（class 1），另一部分属于负类（class 0）。</p> </li><li> <p><strong>非线性模型</strong>：在非线性模型中（如决策树、支持向量机（SVM）等），决策边界可能是曲线或复杂的形状。这使得模型能够更好地捕捉数据中的复杂模式。</p> </li></ul> 
<h4><a id="_237"></a>决策边界的作用</h4> 
<ul><li> <p><strong>分类</strong>：决策边界是用来确定新的数据点应该被分配到哪个类别的基础。数据点的位置相对于决策边界决定了其分类。</p> </li><li> <p><strong>模型解释</strong>：通过可视化决策边界，我们可以对模型的行为有一个直观的理解。例如，决策边界可以帮助我们理解模型是否过拟合或欠拟合。</p> </li><li> <p><strong>特征重要性</strong>：在某些情况下，决策边界的形状和位置可以反映出不同特征对模型决策过程的影响。</p> </li></ul> 
<h4><a id="_245"></a>可视化决策边界</h4> 
<p>在二维空间中，决策边界通常可以通过绘制图形直观地展示。例如，你可以在二维散点图中画出分类模型的决策边界，以展示模型是如何将数据点分为不同类别的。在更高维的空间中，决策边界的可视化变得更加复杂，通常需要使用降维技术或选择特定的两个维度进行可视化。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_moons

<span class="token comment"># 设置随机种子</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 创建一个更复杂的数据集</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_moons<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> noise<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 定义GPU设备（如果可用）</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

<span class="token comment"># 将数据移动到GPU（如果可用）</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">ComplexModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ComplexModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 输入层到隐藏层</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏层</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># 隐藏层到输出层</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 实例化模型并移动到GPU（如果可用）</span>
model <span class="token operator">=</span> ComplexModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
epochs <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制决策边界</span>
<span class="token keyword">def</span> <span class="token function">plot_decision_boundary</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    y_min<span class="token punctuation">,</span> y_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span> x_max<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span> y_max<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 预测整个网格</span>
    Z <span class="token operator">=</span> model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>view<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Feature 1'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Feature 2'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Logistic Regression Decision Boundary'</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制（注意需要将数据和模型移到CPU）</span>
plot_decision_boundary<span class="token punctuation">(</span>model<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/90/96/5N6eFtky_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e8/81/wSYeNCoC_o.png" alt="在这里插入图片描述"><br> 使用平方误差函数在逻辑回归中产生的成本函数效果不好<br> <img src="https://images2.imgbox.com/01/9c/ST2UP9uO_o.png" alt="在这里插入图片描述"><br> 逻辑回归的损失函数</p> 
<h3><a id="_329"></a>过拟合</h3> 
<p>过拟合（Overfitting）是机器学习中一个常见的问题，它发生在模型对训练数据学得“太好”时，以至于它过度捕捉了训练数据中的噪声和细节，而不能很好地泛化到新的、未见过的数据上。简而言之，过拟合是模型在训练数据上表现出色，但在验证数据或测试数据上表现不佳的情况。</p> 
<h4><a id="_332"></a>过拟合的特征和原因</h4> 
<ol><li><strong>高方差</strong>：过拟合模型通常表现出高方差，即模型对训练数据的小变动非常敏感。</li><li><strong>模型过于复杂</strong>：如果模型比需要解决的问题复杂得多，它可能会学到数据中的随机噪声而不是潜在的模式。</li><li><strong>训练时间过长</strong>：特别是在神经网络中，如果训练时间过长，模型可能开始记忆训练数据，而不是学习泛化的特征。</li><li><strong>数据量不足</strong>：如果训练数据不够多，模型可能无法学习到足够泛化的特征。</li></ol> 
<h4><a id="_339"></a>如何检测过拟合</h4> 
<ul><li><strong>性能差异</strong>：一个明显的过拟合迹象是训练误差远远小于验证误差。</li><li><strong>学习曲线</strong>：绘制训练误差和验证误差随时间的变化，如果训练误差持续下降，而验证误差开始增加，这可能是过拟合的迹象。</li></ul> 
<h4><a id="_344"></a>如何防止过拟合</h4> 
<ol><li><strong>增加数据量</strong>：更多的数据可以帮助模型学习更泛化的特征。</li><li><strong>数据增强</strong>：在图像处理中，通过旋转、缩放、裁剪等方式增强数据可以增加数据的多样性。</li><li><strong>减少模型复杂度</strong>：选择更简单的模型或减少模型中的参数数量。</li><li><strong>正则化</strong>：例如L1或L2正则化，可以限制模型权重的大小，防止模型变得过于复杂。</li><li><strong>早期停止</strong>：在训练过程中，一旦验证误差开始增加，立即停止训练。</li><li><strong>交叉验证</strong>：使用交叉验证来更好地估计模型在新数据上的性能。</li><li><strong>Dropout</strong>：在神经网络中，Dropout可以随机地暂时“丢弃”一部分神经元，防止网络对特定的特征过度依赖。</li></ol> 
<p>总之，过拟合是一个需要在模型设计和训练过程中持续关注的问题，通过上述策略可以有效地减少过拟合的风险，提高模型的泛化能力。</p> 
<h3><a id="_355"></a>特性选择</h3> 
<p>特征选择（Feature Selection）是在构建机器学习模型的过程中选择最重要的特征（输入变量）的过程。这是机器学习的关键步骤之一，因为选择正确的特征集合可以提高模型的性能，同时减少计算成本和模型复杂度。</p> 
<h4><a id="_358"></a>特征选择的重要性</h4> 
<ol><li><strong>提高性能</strong>：去除不相关或冗余的特征可以提高模型的准确性。</li><li><strong>减少过拟合</strong>：减少特征数量可以降低模型复杂度，从而减少过拟合的风险。</li><li><strong>减少训练时间</strong>：较少的特征意味着模型训练所需的计算量较小。</li><li><strong>提高模型可解释性</strong>：具有较少特征的模型通常更容易解释和理解。</li></ol> 
<h4><a id="_365"></a>特征选择的方法</h4> 
<ol><li> <p><strong>过滤方法（Filter Methods）</strong>：这些方法在训练模型之前选择特征。它们通常基于统计测试（如相关性或卡方测试）来评估特征的重要性。</p> </li><li> <p><strong>包装方法（Wrapper Methods）</strong>：这些方法将特征选择视为搜索问题，其中不同的特征组合被训练和评估。例子包括向前选择（Forward Selection）、向后消除（Backward Elimination）和递归特征消除（Recursive Feature Elimination, RFE）。</p> </li><li> <p><strong>嵌入方法（Embedded Methods）</strong>：这些方法在模型训练过程中进行特征选择。例如，使用L1正则化的线性模型（如Lasso）可以在训练过程中选择特征。</p> </li><li> <p><strong>维度缩减</strong>：虽然不严格是特征选择（因为它创建新的特征组合），方法如主成分分析（PCA）和线性判别分析（LDA）可以减少特征空间的维度。</p> </li></ol> 
<h4><a id="_375"></a>特征选择的注意事项</h4> 
<ul><li><strong>数据泄露</strong>：在特征选择过程中应避免使用未来数据，以防止数据泄露。</li><li><strong>特征重要性的依赖性</strong>：某些特征选择方法可能依赖于特定类型的模型。</li><li><strong>特征间的相互作用</strong>：在某些情况下，单独的特征可能不重要，但当与其他特征组合时却很重要。</li></ul> 
<p>总之，特征选择是一个关键的步骤，可以显著提高机器学习模型的性能和效率。正确的特征选择不仅可以提高模型的精确度，还可以减少计算成本和提高模型的可解释性。<br> <img src="https://images2.imgbox.com/b9/62/jgkOm7tJ_o.png" alt="在这里插入图片描述"><br> 进行正规化防止过拟合<br> 在PyTorch中实现带有正则化的线性回归并使用GPU加速，可以通过在损失函数中加入一个正则项来完成。在机器学习中，常见的正则化方法有L1正则化（也称为Lasso回归）和L2正则化（也称为Ridge回归）。以下是一个使用L2正则化（Ridge回归）的线性回归模型的示例：</p> 
<ol><li><strong>导入必要的库</strong>：导入PyTorch及相关库。</li><li><strong>创建数据集</strong>：生成一些用于线性回归的合成数据。</li><li><strong>定义线性回归模型</strong>：创建一个简单的线性回归模型。</li><li><strong>定义损失函数和正则化</strong>：定义均方误差损失并加入L2正则化。</li><li><strong>选择优化器</strong>：选择一个优化器，如SGD或Adam。</li><li><strong>在GPU上训练模型</strong>：如果可用，利用GPU进行训练。</li></ol> 
<h4><a id="_393"></a>示例代码</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 设置随机种子以确保结果可重现</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 创建数据集</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.5</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token comment"># 移动数据到GPU</span>

<span class="token comment"># 定义线性回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegressionModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearRegressionModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 实例化模型并移动到GPU</span>
model <span class="token operator">=</span> LinearRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>

<span class="token comment"># 损失函数（均方误差）和L2正则化</span>
<span class="token keyword">def</span> <span class="token function">criterion</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">,</span> model<span class="token punctuation">,</span> reg_lambda<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
    l2_reg <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        l2_reg <span class="token operator">+=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss <span class="token operator">+</span> reg_lambda <span class="token operator">*</span> l2_reg

<span class="token comment"># 优化器</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
epochs <span class="token operator">=</span> <span class="token number">1000</span>
reg_lambda <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># L2正则化系数</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">,</span> model<span class="token punctuation">,</span> reg_lambda<span class="token punctuation">)</span>

    <span class="token comment"># 反向传播和优化</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果（注意：需要将数据移到CPU）</span>
predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Original data'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> predicted<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Fitted line'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>在这个代码示例中，我们使用均方误差损失函数，并添加了一个L2正则化项。L2正则化项是模型参数的平方和，乘以一个正则化系数<code>reg_lambda</code>。这种正则化有助于防止模型过拟合，使得模型参数不会变得过大。</p> 
<p>请确保你的环境已经安装了PyTorch，并且你的机器具有NVIDIA GPU以及相应的CUDA支持。如果没有GPU，这段代码仍然可以在CPU上运行，只需将所有<code>.to('cuda')</code>调用改为<code>.to('cpu')</code>或直接删除这些调用即可。<br> <img src="https://images2.imgbox.com/aa/4a/KLn4aZYn_o.png" alt="在这里插入图片描述"><br> 在PyTorch中实现带有正则化的逻辑回归并使用GPU加速，可以通过在损失函数中加入一个正则项来完成。以下是一个使用L2正则化的逻辑回归模型的示例：</p> 
<ol><li><strong>导入必要的库</strong>：导入PyTorch及相关库。</li><li><strong>创建数据集</strong>：生成一些用于逻辑回归的合成数据。</li><li><strong>定义逻辑回归模型</strong>：创建一个简单的逻辑回归模型。</li><li><strong>定义损失函数和正则化</strong>：定义二元交叉熵损失并加入L2正则化。</li><li><strong>选择优化器</strong>：选择一个优化器，如SGD或Adam。</li><li><strong>在GPU上训练模型</strong>：如果可用，利用GPU进行训练。</li></ol> 
<h4><a id="_472"></a>示例代码</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_classification
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 设置随机种子以确保结果可重现</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 创建数据集</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_classification<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> n_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> n_clusters_per_class<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token comment"># 使用GPU</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>  <span class="token comment"># 使用GPU</span>

<span class="token comment"># 定义逻辑回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegressionModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 实例化模型并移动到GPU</span>
model <span class="token operator">=</span> LogisticRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>

<span class="token comment"># 损失函数（二元交叉熵）和L2正则化</span>
<span class="token keyword">def</span> <span class="token function">criterion</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">,</span> model<span class="token punctuation">,</span> reg_lambda<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
    l2_reg <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        l2_reg <span class="token operator">+=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss <span class="token operator">+</span> reg_lambda <span class="token operator">*</span> l2_reg

<span class="token comment"># 优化器</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
epochs <span class="token operator">=</span> <span class="token number">1000</span>
reg_lambda <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># L2正则化系数</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">,</span> model<span class="token punctuation">,</span> reg_lambda<span class="token punctuation">)</span>

    <span class="token comment"># 反向传播和优化</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果（注意：需要将数据移到CPU）</span>
predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'rainbow'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Logistic Regression with L2 Regularization'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>在这个代码示例中，我们使用二元交叉熵损失函数，并添加了一个L2正则化项。L2正则化项是模型参数的平方和，乘以一个正则化系数<code>reg_lambda</code>。这种正则化有助于防止模型过拟合，使得模型参数不会变得过大。</p> 
<p>请确保你的环境已经安装了PyTorch，并且你的机器具有NVIDIA GPU以及相应的CUDA支持。如果没有GPU，这段代码仍然可以在CPU上运行，只需将所有<code>.to('cuda')</code>调用改为<code>.to('cpu')</code>或直接删除这些调用即可。<br> <img src="https://images2.imgbox.com/95/8c/uODjpdHe_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a397992aefe2697aeb3f22f7bddd934/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ALiBi线性偏置注意力</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/71187d6c0319f06b65b396eac291a7f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">存储数据保护技术——HyperClone克隆与HyperMirror卷镜像技术介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>