<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习笔记（一）DNN-在mnist数据集上用tensorflow搭建dnn - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习笔记（一）DNN-在mnist数据集上用tensorflow搭建dnn" />
<meta property="og:description" content="本文代码运行的环境为:
ubuntu 16.04 64cuda=9.0cudnn=7.0.5tensorflow=1.9.0python=3.6.4(anaconda 3.5.1) 本文包含的知识点有:
DNN基本概念DNN和多层感知机区别神经网络层数到底怎么回事Mnist数据集介绍tensorflow定义网络结构tensorflow定义损失函数tensorflow选择优化算法tensorflow定义测试指标tensorflow模型的保存和加载 1.从感知机到DNN 感知机(Perception)就不细讲了,讲清楚需要大量篇幅.可以参见网上感知机的简单理解或Using neural nets to recognize handwritten digits等.其中的思想并不简单.
多层感知机MLP(Multi Layer Perception)由感知机推广而来,是一种前馈神经网络,有多个神经元层.DNN(Deep Neural Network)是Hinton大神在2006年提出的概念,也是是一种前馈人工神经网络,DNN与MLP的不同在于,DNN在做有监督学习前要先做非监督学习(一般使用RBM或Autoencoder)，然后将非监督学习学到的权值当作有监督学习的初值进行训练.
比如CNN后面的全连接层我们成为MLP比较合适,而一个使用无监督预训练权重的多层前馈神经网络,我们称之为DNN比较合适.
但日常使用中,何必分这么细呢对不对.MLP和DNN所表达的网络结构是相同的,所以MLP就是DNN,DNN就是MLP,DNN名字明显高大上,所以以下统一称为DNN. DNN常见网络结构如下:
这是一个三层的神经网络.这里提一下神经网络的层数,类比下感知机就明白了,感知机有输入层和输出层却叫单层感知机.我们说神经网络层数的时候,这里的&#34;层&#34;是带有运算单元和激活函数的层数,所以不把输入层计算在内.所以双隐层&#43;输入层是一个三层神经网络.
首先看下数据集吧.
2.数据集Mnist Mnist已经用&#34;烂&#34;了,但有些人可能还不是很了解,下面简要介绍下.
Mnist数据可从THE MNIST DATABASE获取.训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据.
它有7万张黑底白字手写的0-9数字图片，其中60000张为训练集,10000张为测试集.本文调用tensorflow中的read_data_sets函数,会把训练集分为55000的训练集，和5000张的验证集.当然也可以自己分.每张图片大小为 28x28 像素，图片中纯黑色的像素值为0，纯白色像素值为1.
3.实战 第一步,配置基本参数
import tensorflow as tf import numpy as np from tensorflow.contrib.layers import fully_connected from tensorflow.examples.tutorials.mnist import input_data # load data and configure parameters mnist = input_data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/16fd23ffca944112f627a115b0d38500/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-23T00:22:26+08:00" />
<meta property="article:modified_time" content="2019-05-23T00:22:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习笔记（一）DNN-在mnist数据集上用tensorflow搭建dnn</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>本文代码运行的环境为:</p> 
 <ul><li>ubuntu 16.04 64</li><li>cuda=9.0</li><li>cudnn=7.0.5</li><li>tensorflow=1.9.0</li><li>python=3.6.4(anaconda 3.5.1)</li></ul> 
</blockquote> 
<blockquote> 
 <p>本文包含的知识点有:</p> 
 <ul><li>DNN基本概念</li><li>DNN和多层感知机区别</li><li>神经网络层数到底怎么回事</li><li>Mnist数据集介绍</li><li>tensorflow定义网络结构</li><li>tensorflow定义损失函数</li><li>tensorflow选择优化算法</li><li>tensorflow定义测试指标</li><li>tensorflow模型的保存和加载</li></ul> 
</blockquote> 
<h3><a id="1DNN_20"></a>1.从感知机到DNN</h3> 
<p>感知机(Perception)就不细讲了,讲清楚需要大量篇幅.可以参见网上<a href="https://www.cnblogs.com/hapjin/p/6714526.html" rel="nofollow">感知机的简单理解</a>或<a href="http://neuralnetworksanddeeplearning.com/chap1.html" rel="nofollow">Using neural nets to recognize handwritten digits</a>等.其中的思想并不简单.</p> 
<p>多层感知机MLP(Multi Layer Perception)由感知机推广而来,是一种前馈神经网络,有多个神经元层.DNN(Deep Neural Network)是Hinton大神在2006年提出的概念,也是是一种前馈人工神经网络,DNN与MLP的不同在于,DNN在做有监督学习前要先做非监督学习(一般使用RBM或Autoencoder)，然后将非监督学习学到的权值当作有监督学习的初值进行训练.</p> 
<p>比如CNN后面的全连接层我们成为MLP比较合适,而一个使用无监督预训练权重的多层前馈神经网络,我们称之为DNN比较合适.</p> 
<p>但日常使用中,何必分这么细呢对不对.MLP和DNN所表达的网络结构是相同的,所以MLP就是DNN,DNN就是MLP,DNN名字明显高大上,所以以下统一称为DNN. DNN常见网络结构如下:</p> 
<p><img src="https://images2.imgbox.com/3d/bb/P81uulb7_o.png" alt="dnn网络结构"><br> 这是一个三层的神经网络.这里提一下神经网络的层数,类比下感知机就明白了,感知机有输入层和输出层却叫单层感知机.我们说神经网络层数的时候,这里的"层"是带有运算单元和激活函数的层数,所以不把输入层计算在内.所以双隐层+输入层是一个三层神经网络.</p> 
<p>首先看下数据集吧.</p> 
<h3><a id="2Mnist_33"></a>2.数据集Mnist</h3> 
<p>Mnist已经用"烂"了,但有些人可能还不是很了解,下面简要介绍下.<br> Mnist数据可从<a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow">THE MNIST DATABASE</a>获取.训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据.<br> <img src="https://images2.imgbox.com/39/c5/xwL4mCG6_o.png" alt="Mnist数据"><br> 它有7万张黑底白字手写的0-9数字图片，其中60000张为训练集,10000张为测试集.本文调用tensorflow中的read_data_sets函数,会把训练集分为55000的训练集，和5000张的验证集.当然也可以自己分.每张图片大小为 28x28 像素，图片中纯黑色的像素值为0，纯白色像素值为1.</p> 
<h3><a id="3_39"></a>3.实战</h3> 
<p>第一步,配置基本参数</p> 
<pre><code class="prism language-Python">import tensorflow as tf
import numpy as np
from tensorflow.contrib.layers import fully_connected
from tensorflow.examples.tutorials.mnist import input_data

# load data and configure parameters
mnist = input_data.read_data_sets("MNIST_data/")
lr = 0.1
n_inputs = 28*28
n_hidden1 = 300
n_hidden2 = 100
n_outputs= 10
epochs = 10
batch_size = 50
iterations = mnist.train.num_examples // batch_size
</code></pre> 
<p>这里使用input_data.read_data_sets会读取目录"MNIST_data"下的数据,如果没有目录则创建目录,把数据集下载到目录"MNIST_data"下面并读取数据.数据集分为三部分,mnist.train,mnist.evaluation和mnist.test,分别有55000,5000,10000张图片.</p> 
<p>第二步,定义静态图</p> 
<pre><code class="prism language-Python">x = tf.placeholder(tf.float32, shape=(None, n_inputs), name='x')
y = tf.placeholder(tf.int64, shape=(None), name='y')

with tf.name_scope('dnn'):
    hidden1 = fully_connected(x, n_hidden1, activation_fn=tf.nn.relu, scope='hidden1')
    hidden2 = fully_connected(hidden1, n_hidden2, activation_fn=tf.nn.relu, scope='hidden2')
    logits = fully_connected(hidden2, n_outputs, activation_fn=None, scope='logits') # 输出层不需要激活函数
    
with tf.name_scope('loss'):
    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)
    loss = tf.reduce_mean(entropy, name='loss')
    
with tf.name_scope('train'):
    optimizer = tf.train.GradientDescentOptimizer(lr)
    train = optimizer.minimize(loss)    # apply_gradients(compute_gradients)
    
with tf.name_scope('metrics'):
    correct = tf.nn.in_top_k(logits, y, 1)
    acc = tf.reduce_mean(tf.cast(correct, tf.float32), name='acc')
</code></pre> 
<p>第三步,调用静态图<br> 初始化变量:</p> 
<pre><code class="prism language-Python">init = tf.global_variables_initializer()
saver = tf.train.Saver()    # defalt: save all variables 
</code></pre> 
<p>训练数据,保存tensorflow模型:</p> 
<pre><code class="prism language-Python">with tf.Session() as sess:
    tf.summary.FileWriter('./log', sess.graph)
    init.run()  # sess.run(init)
    for epoch in range(epochs):
        acc_train = 0.0
        for iteration in range(iterations):
            x_batch, y_batch = mnist.train.next_batch(batch_size)
            _, acc_batch = sess.run([train, acc], feed_dict={x:x_batch, y:y_batch})
            acc_train += acc_batch
        acc_eval = sess.run(acc, feed_dict={x:mnist.validation.images, y:mnist.validation.labels})
        print(epoch+1, 'Train_acc:', acc_train/iterations,'Eval_acc', acc_eval)
		
    saver.save(sess, 'model/dnn.ckpt')
</code></pre> 
<p>加载tensorflow模型,测试数据:</p> 
<pre><code class="prism language-Python">with tf.Session() as sess:
    saver.restore(sess, 'model/dnn.ckpt')
    acc_test = acc.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels})
    print("Acc_test:{0}".format(acc_test))
</code></pre> 
<p>结果如下图所示:<br> <img src="https://images2.imgbox.com/76/9a/59Dp7QT8_o.png" alt="result"></p> 
<p>在这份代码中,验证集其实可有可无.<br> 验证集的用法一般是用来选择在训练过程中表现比较好的模型.训练结束后,把选择的模型加载,在测试集上测试,也就是说,测试集只有到最后一步才会用到.为什么这样呢,如果没有验证集,我们选择最优模型在测试集上测试,可能因为效果过拟合而导致精度不高.而加上验证集后,在验证集上表现较好的模型,我们可以认为其泛化性能较强,因此选择这个模型为最终模型,拿到测试集上进行测试.<br> 而在本文中为了简化训练过程,没有这么做.读者可以自行尝试,后续实战也有范例.</p> 
<h3><a id="_124"></a>参考:</h3> 
<blockquote> 
 <p><a href="https://www.cnblogs.com/pinard/p/6418668.html" rel="nofollow">https://www.cnblogs.com/pinard/p/6418668.html</a><br> <a href="http://neuralnetworksanddeeplearning.com/index.html" rel="nofollow">http://neuralnetworksanddeeplearning.com/index.html</a><br> <a href="https://baike.baidu.com/item/DNN/19974079?fr=aladdin" rel="nofollow">https://baike.baidu.com/item/DNN/19974079?fr=aladdin</a><br> <a href="https://www.cnblogs.com/jiaxin359/p/9011457.html#_label1" rel="nofollow">https://www.cnblogs.com/jiaxin359/p/9011457.html#_label1</a><br> <a href="https://www.cnblogs.com/LHWorldBlog/p/8660315.html" rel="nofollow">https://www.cnblogs.com/LHWorldBlog/p/8660315.html</a></p> 
</blockquote> 
<h3><a id="_132"></a>广告</h3> 
<p>完整代码:<a href="https://github.com/wyl6/Deep-Learning/tree/master/dnn/tensorflow_mnist">https://github.com/wyl6/Deep-Learning/tree/master/dnn/tensorflow_mnist</a></p> 
<p>欢迎关注微信公众号：推荐算法工程师</p> 
<img src="https://images2.imgbox.com/53/77/GVJcK4Yg_o.jpg" width="200" height="200"> 
<p>公众号分享博主的推荐系统学习经验和心得,欢迎交流</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1f68a3932e0fd299c11a179f99c3569a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">LANMP安全配置之Apache安全配置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/73b013a987157161a80191f22442f440/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Pytorch学习笔记（I）——预训练模型（十一）：ResNet152网络结构</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>