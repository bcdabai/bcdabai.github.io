<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python词云 wordcloud库详细使用教程 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python词云 wordcloud库详细使用教程" />
<meta property="og:description" content="文章目录 前言使用wordcloud生成词云的步骤API参考分词简介英文分词中文分词，jieba matplotlib库简介实例从一段文本建立词云根据蒙版建立词云从词频建立词云从图片颜色建立词云 传入中文字体路径解决乱码问题 前言 “词云”这个概念由美国西北大学新闻学副教授、新媒体专业主任里奇·戈登（Rich Gordon）于提出，词云是一种可视化描绘单词或词语出现在文本数据中频率的方式，它主要是由随机分布在词云图的单词或词语构成，出现频率较高的单词或词语则会以较大的形式呈现出来，而频率越低的单词或词语则会以较小的形式呈现。词云主要提供了一种观察社交媒体网站上的热门话题或搜索关键字的一种方式，它可以对网络文本中出现频率较高的“关键词”予以视觉上的突出，形成“关键词云层”或“关键词渲染”，从而过滤掉大量的文本信息，使浏览网页者只要一眼扫过文本就可以领略文本的主旨。
例如：（图片来自于网络）
你也想做出这么具有视觉震撼效果的词云吗？借助python的wordcloud库便可实现。
wordcloud库不是python内置库，需要安装。windows&#43;R，打开cmd，然后在命令行输入：
pip install wordcloud 等待安装完成即可。
关于wordcloud库最详细的使用教程，可参考：
wordcloud官方文档
本文是在作者参考官网后，然后结合自己的示例整理出。源代码和相关资料下载资源（0积分下载）：
https://download.csdn.net/download/weixin_55697913/87697233
使用wordcloud生成词云的步骤 读取文件，分词整理
可能会用到字符串相关函数、jieba库等。
配置对象参数，加载词云文本
创建一个WordCloud对象，使用.generate()方法加载文本。
计算词频，输出词云文件
使用to_file()方法输出到文件。或者利用其他库（如pyplot）展示图像。
生成词云时，wordcloud 默认会以空格或标点为分隔符对目标文本进行分词处理。
对于中文文本，分词处理需要由用户来完成，jieba库是常见的中文分词库。
一般步骤是先将文本分词处理，然后以空格拼接，再调用wordcloud库函数。
处理中文时还需要指定中文字体，见本文末尾传入中文字体路径解决乱码问题。
API参考 最重要的一个API：
class wordcloud.WordCloud(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color=&#39;black&#39;, max_font_size=None, font_step=1, mode=&#39;RGB&#39;, relative_scaling=&#39;auto&#39;, regexp=None, collocations=True, colormap=None, normalize_plurals=True, contour_width=0, contour_color=&#39;black&#39;, repeat=False, include_numbers=False, min_word_length=0, collocation_threshold=30) 重要参数详解：
font_path：字体路径。使用中文很可能产生乱码，需要下载专门的中文字体，然后将路径传入。width, height：画布的大小。mask：蒙版（熟悉ps的小伙伴应该很清楚），可以传入一个图像当做蒙版，这时width，height会被忽略。蒙版的纯白色部分将没有文字，其他颜色部分将有文字。min_font_size：词云最小字体的大小。max_font_size同理。max_words：最大词语的数量。stopwords：set of strings or None，出现在停用词里的词将不会出现在词云中。如果None，则使用默认的stopwords。如果使用.generate_from_frequencies方法，则会被忽略。background_color：背景颜色，可以直接用white、black等字符串。repeat：bool, default=False。是否可以重复单词。color_func：callable, default=None。可以传入一个函数或者后面提到的ImageColorGenerator，用于给词云上色。 方法：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/25875aacdb160f0fcb12288e9d35269c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-16T12:04:11+08:00" />
<meta property="article:modified_time" content="2023-09-16T12:04:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python词云 wordcloud库详细使用教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">前言</a></li><li><a href="#wordcloud_17" rel="nofollow">使用wordcloud生成词云的步骤</a></li><li><a href="#API_31" rel="nofollow">API参考</a></li><li><a href="#_73" rel="nofollow">分词简介</a></li><li><ul><li><a href="#_75" rel="nofollow">英文分词</a></li><li><a href="#jieba_87" rel="nofollow">中文分词，jieba</a></li></ul> 
  </li><li><a href="#matplotlib_131" rel="nofollow">matplotlib库简介</a></li><li><a href="#_157" rel="nofollow">实例</a></li><li><ul><li><a href="#_174" rel="nofollow">从一段文本建立词云</a></li><li><a href="#_193" rel="nofollow">根据蒙版建立词云</a></li><li><a href="#_222" rel="nofollow">从词频建立词云</a></li><li><a href="#_288" rel="nofollow">从图片颜色建立词云</a></li></ul> 
  </li><li><a href="#_317" rel="nofollow">传入中文字体路径解决乱码问题</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>前言</h2> 
<p>“词云”这个概念由美国西北大学新闻学副教授、新媒体专业主任里奇·戈登（Rich Gordon）于提出，词云是一种可视化描绘单词或词语出现在文本数据中频率的方式，它主要是由随机分布在词云图的单词或词语构成，出现频率较高的单词或词语则会以较大的形式呈现出来，而频率越低的单词或词语则会以较小的形式呈现。词云主要提供了一种观察社交媒体网站上的热门话题或搜索关键字的一种方式，它可以对网络文本中出现频率较高的“关键词”予以视觉上的突出，形成“关键词云层”或“关键词渲染”，从而过滤掉大量的文本信息，使浏览网页者只要一眼扫过文本就可以领略文本的主旨。<br> 例如：（图片来自于网络）<br> <img src="https://images2.imgbox.com/ca/6d/tlTVLXno_o.png" alt="在这里插入图片描述"></p> 
<p>你也想做出这么具有视觉震撼效果的词云吗？借助python的wordcloud库便可实现。<br> wordcloud库不是python内置库，需要安装。windows+R，打开cmd，然后在命令行输入：</p> 
<pre><code class="prism language-python">pip install wordcloud
</code></pre> 
<p>等待安装完成即可。<br> 关于wordcloud库最详细的使用教程，可参考：<br> <a href="https://amueller.github.io/word_cloud/index.html" rel="nofollow">wordcloud官方文档</a><br> 本文是在作者参考官网后，然后结合自己的示例整理出。源代码和相关资料下载资源（0积分下载）：<br> <a href="https://download.csdn.net/download/weixin_55697913/87697233">https://download.csdn.net/download/weixin_55697913/87697233</a></p> 
<h2><a id="wordcloud_17"></a>使用wordcloud生成词云的步骤</h2> 
<ol><li> <p>读取文件，分词整理<br> 可能会用到字符串相关函数、jieba库等。</p> </li><li> <p>配置对象参数，加载词云文本<br> 创建一个WordCloud对象，使用<code>.generate()</code>方法加载文本。</p> </li><li> <p>计算词频，输出词云文件<br> 使用<code>to_file()</code>方法输出到文件。或者利用其他库（如<code>pyplot</code>）展示图像。</p> </li></ol> 
<p>生成词云时，wordcloud 默认会以<strong>空格</strong>或<strong>标点</strong>为分隔符对目标文本进行分词处理。<br> 对于中文文本，分词处理需要由用户来完成，jieba库是常见的中文分词库。<br> 一般步骤是先将文本分词处理，然后以空格拼接，再调用wordcloud库函数。<br> 处理中文时还需要指定中文字体，见本文末尾<a href="#%E4%BC%A0%E5%85%A5%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E8%B7%AF%E5%BE%84%E8%A7%A3%E5%86%B3%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98" rel="nofollow">传入中文字体路径解决乱码问题</a>。</p> 
<h2><a id="API_31"></a>API参考</h2> 
<p>最重要的一个API：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">wordcloud</span><span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
 margin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ranks_only<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> prefer_horizontal<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
 scale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> color_func<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> max_words<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> min_font_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> 
 stopwords<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> background_color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> 
 max_font_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> font_step<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'RGB'</span><span class="token punctuation">,</span> 
 relative_scaling<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> regexp<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> collocations<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
 colormap<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> normalize_plurals<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> contour_width<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
 contour_color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> repeat<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> include_numbers<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> 
 min_word_length<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> collocation_threshold<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>
</code></pre> 
<p>重要参数详解：</p> 
<ul><li><code>font_path</code>：字体路径。使用中文很可能产生乱码，需要下载专门的中文字体，然后将路径传入。</li><li><code>width, height</code>：画布的大小。</li><li><code>mask</code>：蒙版（熟悉ps的小伙伴应该很清楚），可以传入一个图像当做蒙版，这时width，height会被忽略。蒙版的纯白色部分将没有文字，其他颜色部分将有文字。</li><li><code>min_font_size</code>：词云最小字体的大小。max_font_size同理。</li><li><code>max_words</code>：最大词语的数量。</li><li><code>stopwords</code>：set of strings or None，出现在停用词里的词将不会出现在词云中。如果None，则使用默认的stopwords。如果使用<code>.generate_from_frequencies</code>方法，则会被忽略。</li><li><code>background_color</code>：背景颜色，可以直接用white、black等字符串。</li><li><code>repeat</code>：bool, default=False。是否可以重复单词。</li><li><code>color_func</code>：callable, default=None。可以传入一个函数或者后面提到的<code>ImageColorGenerator</code>，用于给词云上色。</li></ul> 
<p>方法：</p> 
<table><thead><tr><th>方法</th><th>用法</th></tr></thead><tbody><tr><td>generate(text)</td><td>根据给定的text产生词云，text一般是用空格或者标点符号分割的单词</td></tr><tr><td>generate_from_text(text)</td><td>跟generate(text)完全等效</td></tr><tr><td>generate_from_frequencies(frequencies[, …])</td><td>根据词频建立词云，词频越大字体越大。参数frequencies是一个字典，从单词到频率的映射</td></tr><tr><td>fit_words(frequencies)</td><td>跟generate_from_frequencies完全等效</td></tr><tr><td>to_file(filename)</td><td>将产生的词云保存至文件</td></tr></tbody></table> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">wordcloud</span><span class="token punctuation">.</span>ImageColorGenerator<span class="token punctuation">(</span>image<span class="token punctuation">,</span> default_color<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre> 
<p>参数：</p> 
<ul><li><code>image</code>：nd-array, shape (height, width, 3)</li></ul> 
<p>作用：<br> 基于一张图片建立的<code>ImageColorGenerator</code>，可以当做<code>WordCloud</code>类的<code>color_func</code>参数，用于给词云上色。传入一张RGB图片即可，是一个numpy格式的图片。词云上的每个词的染色，是这张图片上对应的矩形区域的颜色平均值。</p> 
<h2><a id="_73"></a>分词简介</h2> 
<p>分词，简单来说就是将一段长句子分成一个个的词语。要生成词云肯定是需要以词语为单位的，所以我们需要提前完成分词操作。</p> 
<h3><a id="_75"></a>英文分词</h3> 
<p>对于英文句子，其本身就有空格和标点符号，所以很多情况下我们直接传入句子即可。例如：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> wordcloud

sentence<span class="token operator">=</span><span class="token string">'Long ago, there was a big cat in the house. He caught many mice while they were stealing food.'</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'img1.jpg'</span><span class="token punctuation">)</span>
</code></pre> 
<p>效果展示：<br> <img src="https://images2.imgbox.com/81/bc/OSFnTkaf_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="jieba_87"></a>中文分词，jieba</h3> 
<p>对于中文句子，词与词之间没有分隔符，分词需要我们自己完成。jieba库是一个优秀的中文分词库，如果没有安装，请：</p> 
<pre><code class="prism language-python">pip install jieba
</code></pre> 
<p>在jieba中最常用的函数就是<code>jieba.lcut()</code>函数，我们传入一个句子，返回分词后的词语列表。几个最常用的函数是：</p> 
<table><thead><tr><th>方法</th><th>用法</th></tr></thead><tbody><tr><td>jieba.lcut(s)</td><td>精确模式，词与词之间没有重合，返回一个列表类型</td></tr><tr><td>jieba.lcut(s, cut_all=True)</td><td>全模式，得到所有可能的词，返回一个列表类型</td></tr><tr><td>jieba.lcut_for_search(s)</td><td>搜索引擎模式，返回一个列表类型</td></tr></tbody></table> 
<p>例如：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba

list0<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span><span class="token string">'真正的勇士，敢于直面惨淡的人生，敢于正视淋漓的鲜血这是怎样的哀痛者和幸福者？'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list0<span class="token punctuation">)</span>
sentence<span class="token operator">=</span><span class="token string">"中华人民共和国"</span>
list1<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
list2<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
list3<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut_for_search<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list3<span class="token punctuation">)</span>
输出：
<span class="token punctuation">[</span><span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'的'</span><span class="token punctuation">,</span> <span class="token string">'勇士'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'敢于'</span><span class="token punctuation">,</span> <span class="token string">'直面'</span><span class="token punctuation">,</span> <span class="token string">'惨淡'</span><span class="token punctuation">,</span> <span class="token string">'的'</span><span class="token punctuation">,</span> <span class="token string">'人生'</span><span class="token punctuation">,</span> <span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token string">'敢于'</span><span class="token punctuation">,</span> <span class="token string">'正视'</span><span class="token punctuation">,</span> <span class="token string">'淋漓'</span><span class="token punctuation">,</span> 
<span class="token string">'的'</span><span class="token punctuation">,</span> <span class="token string">'鲜血'</span><span class="token punctuation">,</span> <span class="token string">'这是'</span><span class="token punctuation">,</span> <span class="token string">'怎样'</span><span class="token punctuation">,</span> <span class="token string">'的'</span><span class="token punctuation">,</span> <span class="token string">'哀痛'</span><span class="token punctuation">,</span> <span class="token string">'者'</span><span class="token punctuation">,</span> <span class="token string">'和'</span><span class="token punctuation">,</span> <span class="token string">'幸福'</span><span class="token punctuation">,</span> <span class="token string">'者'</span><span class="token punctuation">,</span> <span class="token string">'？'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'中华人民共和国'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'中华'</span><span class="token punctuation">,</span> <span class="token string">'中华人民'</span><span class="token punctuation">,</span> <span class="token string">'中华人民共和国'</span><span class="token punctuation">,</span> <span class="token string">'华人'</span><span class="token punctuation">,</span> <span class="token string">'人民'</span><span class="token punctuation">,</span> <span class="token string">'人民共和国'</span><span class="token punctuation">,</span> <span class="token string">'共和'</span><span class="token punctuation">,</span> <span class="token string">'共和国'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'中华'</span><span class="token punctuation">,</span> <span class="token string">'华人'</span><span class="token punctuation">,</span> <span class="token string">'人民'</span><span class="token punctuation">,</span> <span class="token string">'共和'</span><span class="token punctuation">,</span> <span class="token string">'共和国'</span><span class="token punctuation">,</span> <span class="token string">'中华人民共和国'</span>
</code></pre> 
<p>分词完成后，一般是利用空格连接分词之后的词语，然后传入wordcloud对象：</p> 
<pre><code class="prism language-python">list1<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span><span class="token string">'真正的勇士，敢于直面惨淡的人生，敢于正视淋漓的鲜血这是怎样的哀痛者和幸福者？'</span><span class="token punctuation">)</span>
sentence<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list1<span class="token punctuation">)</span>
<span class="token comment"># 注意，需要传入中文字体路径，不然很可能出现乱码。</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'img1.jpg'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/1a/7b/Bd9I3pN4_o.jpg" alt="在这里插入图片描述"><br> 需要特别注意传入中文很可能产生乱码，最好传入中文字体路径，详情见本文末尾<a href="#%E4%BC%A0%E5%85%A5%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E8%B7%AF%E5%BE%84%E8%A7%A3%E5%86%B3%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98" rel="nofollow">传入中文字体路径解决乱码问题</a>。</p> 
<h2><a id="matplotlib_131"></a>matplotlib库简介</h2> 
<p>maplotlib是一个优秀的python绘图库，经常用在科学绘图中。二维图、三维图、折线图、柱状图、饼状图、热力图……它都能绘制。最常用到的是其子库<code>matplotlib.pyplot</code>。<br> 如果未安装，请：</p> 
<pre><code class="prism language-python">pip install matplotlib
</code></pre> 
<p>我们可以利用matplotlib库将生成的词云方便地展示出来。但是这一步不是必须的，因为wordcloud就自带了保存至文件的方法<code>to_file</code>。但是涉及到多子图绘制等，就必须用到它了。<br> 一般来说我们之间调用<code>plt.imshow</code>函数，将生成的wordcloud对象传入，然后调用<code>plt.show</code>函数将图展示出来即可，例如：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> wordcloud
<span class="token keyword">import</span> jieba

list1<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span><span class="token string">'真正的勇士，敢于直面惨淡的人生，敢于正视淋漓的鲜血这是怎样的哀痛者和幸福者？'</span><span class="token punctuation">)</span>
sentence<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list1<span class="token punctuation">)</span>
<span class="token comment"># 注意，需要传入中文字体路径，不然很可能出现乱码。</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
<span class="token comment"># wc.to_file('img1.jpg')</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wc<span class="token punctuation">)</span> <span class="token comment"># 传入wordcloud对象</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span> <span class="token comment"># 关闭坐标轴</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 将图片展示出来</span>
</code></pre> 
<p>效果：<br> <img src="https://images2.imgbox.com/ae/59/cBQBnAz5_o.png" alt="在这里插入图片描述"><br> 需要说明的是，可以直接将生成的词云利用<code>to_file</code>方法保存至文件，并不一定需要使用到matplotlib库，仅仅是个人习惯而已。</p> 
<h2><a id="_157"></a>实例</h2> 
<p>本文会用到<code>wordcloud</code>库，除此之外，还会用到<code>jieba</code>和<code>matplotlib</code>。<br> <code>jieba</code>库是一个优秀的中文分词库，<code>matplotlib</code>是一个常用的Python 2D绘图库，其子库<code>matplotlib.pyplot</code>提供了多种绘图方法，这两个库不是python内置的库，需要自行安装：</p> 
<pre><code class="prism language-python">pip install matplotlib
pip install jieba
</code></pre> 
<p>在<code>jieba</code>库中，常用的是<code>jieba.lcut()</code>函数，传入一个中文字符串，返回分词后的单词列表。</p> 
<p>关于<code>jieba</code>库和<code>matplotlib</code>库的使用不是本文的重点内容，大家可自行在网上查阅相关资料。</p> 
<p>下文的实例将会用到下面的库：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> wordcloud
<span class="token keyword">import</span> jieba
</code></pre> 
<h3><a id="_174"></a>从一段文本建立词云</h3> 
<p>从一段文本建立词云时，默认单词是以空格或者标点分开的。使用<code>generate</code>或<code>generate_from_text</code>这两种方法，完全等价。</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''从一段文本建立词云'''</span>
text<span class="token operator">=</span><span class="token triple-quoted-string string">'''面对世界经济复苏乏力、局部冲突和动荡频发、全球性问题加剧的外部环境，
面对我国经济发展进入新常态等一系列深刻变化，我们坚持稳中求进工作总基调，迎难而上，开拓进取，
取得了改革开放和社会主义现代化建设的历史性成就。'''</span>
<span class="token comment"># 宋体</span>
words<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment"># 使用jieba库进行中文分词</span>
text<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span> <span class="token comment"># wordcloud 默认会以空格或标点为分隔符对目标文本进行分词处理</span>
wd<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simsun.ttc'</span><span class="token punctuation">)</span>
wd<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment"># 生成词云</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wd<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span> <span class="token comment"># 关闭坐标轴</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 将图展示出来</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/1e/55/9kulwgMn_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_193"></a>根据蒙版建立词云</h3> 
<p>这部分根据可口可乐的广告建立词云（cocacola快给我打钱）<br> 先用ps自己画一个蒙版（准确来说是抠图）<br> <img src="https://images2.imgbox.com/95/40/iO86tkQn_o.jpg" alt="在这里插入图片描述"></p> 
<p>然后网上辛苦搜集了广告语：<br> <img src="https://images2.imgbox.com/6c/f5/IksAEg3f_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''从蒙版建立词云'''</span>
str1<span class="token operator">=</span><span class="token string">''</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/cocacola.txt'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
   <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
       str1<span class="token operator">+=</span>line<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 去掉前面四个数字年份</span>
words<span class="token operator">=</span><span class="token builtin">set</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>str1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 重复词太多，用set除去重复词</span>
text<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
mask<span class="token operator">=</span>plt<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./imgs/可口可乐.jpg'</span><span class="token punctuation">)</span>
<span class="token comment"># 黑体</span>
stopwords<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">,</span>mask<span class="token operator">=</span>mask<span class="token punctuation">,</span>background_color<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'./imgs/from_mask.jpg'</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/09/85/WtydYlkk_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_222"></a>从词频建立词云</h3> 
<p>还是可口可乐广告。使用generate_from_frequencies或者fit_words方法，完全等价。</p> 
<pre><code class="prism language-python">generate_from_frequencies<span class="token punctuation">(</span>frequencies<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>max_font_size<span class="token punctuation">:</span> Any <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> WordCloud
</code></pre> 
<p><code>frequencies</code>：dict from string to float，从单词到频率的映射。</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''从频率建立词云'''</span>
str1<span class="token operator">=</span><span class="token string">''</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/cocacola.txt'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
        str1<span class="token operator">+=</span>line<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 去掉前面四个数字年份</span>
words<span class="token operator">=</span>jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>str1<span class="token punctuation">)</span> 

<span class="token comment"># 统计词频</span>
fre<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
stopwords<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'你'</span><span class="token punctuation">,</span><span class="token string">'的'</span><span class="token punctuation">,</span><span class="token string">'和'</span><span class="token punctuation">,</span><span class="token string">'是'</span><span class="token punctuation">,</span><span class="token string">'了'</span><span class="token punctuation">,</span><span class="token string">'会'</span><span class="token punctuation">,</span><span class="token string">'才'</span><span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">'---'</span><span class="token punctuation">,</span><span class="token string">'!'</span><span class="token punctuation">,</span><span class="token string">'—'</span><span class="token punctuation">,</span><span class="token string">'----'</span><span class="token punctuation">,</span><span class="token string">'只'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
    <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span> <span class="token comment"># 除去停用词</span>
        fre<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token operator">=</span>fre<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
    
<span class="token comment"># 可选用停用词。发现fre中有大量无关的词汇，</span>
<span class="token comment"># 如'你','的','和','是','了','会','才','\n','---','!','—','----','只'</span>
<span class="token comment"># 但是需要注意，如果使用generate_from_frequencies，会忽略stopwords，所以要在传入的字典中去掉停用词</span>
mask<span class="token operator">=</span>plt<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./imgs/可口可乐.jpg'</span><span class="token punctuation">)</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">,</span>mask<span class="token operator">=</span>mask<span class="token punctuation">,</span>
                       background_color<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">,</span>stopwords<span class="token operator">=</span>stopwords<span class="token punctuation">)</span> <span class="token comment"># 这里传入stopwords其实没用，得去掉fre中的停用词</span>
wc<span class="token punctuation">.</span>generate_from_frequencies<span class="token punctuation">(</span>fre<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'./imgs/from_frequency.jpg'</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">'''或者这样做'''</span>
<span class="token comment"># wc.fit_words(fre)</span>
<span class="token comment"># wc.to_file('./imgs/from_fit_words.jpg')</span>
<span class="token triple-quoted-string string">'''或者不用统计，直接来'''</span>
<span class="token comment"># text=' '.join(words)</span>
<span class="token comment"># wc.generate(text)</span>
<span class="token comment">#wc.to_file('./imgs/from_gene.jpg')</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/73/fa/6KZ86DXo_o.png" alt="在这里插入图片描述"><br> 可见统计词频后，除了一些关键词，其他词的大小明显变小了。<br> 注意，上图中除了可口可乐，其他字都变得很小，是因为可口可乐出现的次数太多了，而此前词语出现的次数只有它的零头：</p> 
<pre><code class="prism language-python">list1<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> fre<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
list1<span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>list1<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>list1<span class="token punctuation">)</span>
输出：
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'可口可乐'</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'，'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'可乐'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'带来'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'口渴'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
<span class="token punctuation">(</span><span class="token string">'就是'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'一杯'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生活'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'在'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'哪里'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'就'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
<span class="token punctuation">(</span><span class="token string">'有'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre> 
<p>可见<code>'可口可乐'</code>出现得实在太多了，挤掉了其他字的空间，并且第二名居然是个中文逗号<code>，</code>。<br> 为了让图更加“好看一些”，我们可以去掉<code>'可口可乐'</code>和中文逗号<code>，</code>：</p> 
<pre><code class="prism language-python"><span class="token keyword">del</span> fre<span class="token punctuation">[</span><span class="token string">'，'</span><span class="token punctuation">]</span>
<span class="token keyword">del</span> fre<span class="token punctuation">[</span><span class="token string">'可口可乐'</span><span class="token punctuation">]</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">,</span>mask<span class="token operator">=</span>mask<span class="token punctuation">,</span>
                       background_color<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">)</span> <span class="token comment"># 这里传入stopwords其实没用，得去掉fre中的停用词</span>
wc<span class="token punctuation">.</span>fit_words<span class="token punctuation">(</span>fre<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wc<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/49/3d/oGAm0Y5u_o.png" alt="在这里插入图片描述"><br> 这样词云终于正常了。<br> 要想做出好看的词云，数据预处理非常重要！！！我们需要去掉标点符号、空白、停用词等可能会影响词云的无关元素。</p> 
<h3><a id="_288"></a>从图片颜色建立词云</h3> 
<p>如果又想词云保存某种形状，同时还附带上图片的颜色，可以从图片颜色建立词云。<br> 例如，用一张王者荣耀李元芳的图片建立词云：（图片来自于网络）<br> <img src="https://images2.imgbox.com/7c/e1/Q8TZLFyj_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''根据图片颜色建立词云'''</span>
image<span class="token operator">=</span>plt<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./imgs/李元芳.jpg'</span><span class="token punctuation">)</span>
<span class="token comment"># 构造ImageColorGenerator</span>
color_generator<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>ImageColorGenerator<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
text<span class="token operator">=</span><span class="token string">'李元芳'</span>
<span class="token comment"># 注意需要指定repeat=True，因为只有一个词</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">,</span>
                       mask<span class="token operator">=</span>image<span class="token punctuation">,</span>background_color<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">,</span>repeat<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wc<span class="token punctuation">)</span>
<span class="token comment"># 或者在构建wc时就传入color_func</span>
<span class="token comment"># wc=wordcloud.WordCloud(font_path='C:\Windows\Fonts\simhei.ttf',mask=image,background_color='white',color_func=color_generator,repeat=True)</span>
axes<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wc<span class="token punctuation">.</span>recolor<span class="token punctuation">(</span>color_func<span class="token operator">=</span>color_generator<span class="token punctuation">)</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token keyword">for</span> ax <span class="token keyword">in</span> axes<span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_axis_off<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'./imgs/李元芳词云.jpg'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>效果：</p> 
<p><img src="https://images2.imgbox.com/16/6a/sA7oLcAj_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_317"></a>传入中文字体路径解决乱码问题</h2> 
<p>wordcloud在产生中文文本词云时会出现乱码（产生的汉字是方框），如下图：</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''中文字体乱码'''</span>
text<span class="token operator">=</span><span class="token string">'中文 字体 乱码'</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'./imgs/中文字体乱码.jpg'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/33/95/wjUKcgtP_o.png" alt="在这里插入图片描述"></p> 
<p>为了解决这个问题，需要传入电脑中安装的中文字体路径，font_path。<br> 以我们常用的windows系统为例，系统中一般已经安装了中文字体，可进入C:\Windows\Fonts文件夹下，查看可用的中文字体。如下图：<br> <img src="https://images2.imgbox.com/7f/26/7fqWTgro_o.png" alt="在这里插入图片描述"></p> 
<p>例如，想要使用黑体，可对黑体右键-属性-安全，复制其路径即可：<br> <img src="https://images2.imgbox.com/ec/e4/RGjJdDmD_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment"># 传入中文字体路径解决乱码问题</span>
text<span class="token operator">=</span><span class="token string">'记得 传入 中文 字体 路径'</span>
wc<span class="token operator">=</span>wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>font_path<span class="token operator">=</span><span class="token string">'C:\Windows\Fonts\simhei.ttf'</span><span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
wc<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'./imgs/记得传入中文字体路径.jpg'</span><span class="token punctuation">)</span>
</code></pre> 
<p>问题成功解决：<br> <img src="https://images2.imgbox.com/85/f7/vJ8AhTqc_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4820c1b9ae10e18ee9ad064c39195789/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【达梦数据库】分布式计算集群DMDPC原理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0516037d6d3fad086744c0be5c6d8438/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">P1586 四方定理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>