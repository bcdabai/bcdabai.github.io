<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Redis介绍 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Redis介绍" />
<meta property="og:description" content="第1章 关系型与非关系型 关系型： mysql oracle
非关系型：redis mongo ES
第2章 Redis重要特性 AK47 1.速度快 c语言写的
代码优雅
单线程架构
2.支持多种数据结构 字符串，哈希，列表，集合，有序集合，地理位置
3.丰富的功能 天然计数器
健过期功能
消息队列
4.支持客户端语言多 php,java,python
5.数据持久化 所有的数据都运行在内存中
支持2种格式持久化数据AOF RDB AOF&amp;RDB
6.自带多种高可用架构 主从
哨兵
集群
第3章 redis应用场景 1.缓存-键过期时间 把session会话存在redis,过期删除
缓存用户信息，缓存Mysql部分数据，用户先访问redis，redis没有再访问mysql，然后回写给redis
商城优惠卷过期时间
2.排行榜-列表&amp;有序集合 热度/点击数排行榜
直播间礼物积分排行
3.计数器-天然支持计数器 帖子浏览数
视频播放数
评论数
点赞/踩
4.社交网络-集合 粉丝
共同好友
兴趣爱好
标签
5.消息队列-发布订阅 配合ELK缓存收集来的日志
第4章 Redis安装部署 1.redis官网 https://redis.io/
2.版本选择 2.x very old
3.x redis-cluster
4.x 混合持久化
5.x 新增加了流处理类型 最新稳定版
3.规划目录 /data/soft 下载目录" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/bede63a09ba8a62c00360abca2fe4675/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-15T23:21:41+08:00" />
<meta property="article:modified_time" content="2020-11-15T23:21:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Redis介绍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1__1"></a>第1章 关系型与非关系型</h2> 
<p>关系型： mysql oracle<br> 非关系型：redis mongo ES</p> 
<h2><a id="2_Redis_AK47_6"></a>第2章 Redis重要特性 AK47</h2> 
<h3><a id="1_7"></a>1.速度快</h3> 
<p>c语言写的<br> 代码优雅<br> 单线程架构</p> 
<h3><a id="2_11"></a>2.支持多种数据结构</h3> 
<p>字符串，哈希，列表，集合，有序集合，地理位置</p> 
<h3><a id="3_13"></a>3.丰富的功能</h3> 
<p>天然计数器<br> 健过期功能<br> 消息队列</p> 
<h3><a id="4_17"></a>4.支持客户端语言多</h3> 
<p>php,java,python</p> 
<h3><a id="5_19"></a>5.数据持久化</h3> 
<p>所有的数据都运行在内存中<br> 支持2种格式持久化数据AOF RDB AOF&amp;RDB</p> 
<h3><a id="6_22"></a>6.自带多种高可用架构</h3> 
<p>主从<br> 哨兵<br> 集群</p> 
<h2><a id="3_redis_27"></a>第3章 redis应用场景</h2> 
<h3><a id="1_28"></a>1.缓存-键过期时间</h3> 
<p>把session会话存在redis,过期删除<br> 缓存用户信息，缓存Mysql部分数据，用户先访问redis，redis没有再访问mysql，然后回写给redis<br> 商城优惠卷过期时间</p> 
<h3><a id="2_32"></a>2.排行榜-列表&amp;有序集合</h3> 
<p>热度/点击数排行榜<br> 直播间礼物积分排行</p> 
<h3><a id="3_35"></a>3.计数器-天然支持计数器</h3> 
<p>帖子浏览数<br> 视频播放数<br> 评论数<br> 点赞/踩</p> 
<h3><a id="4_40"></a>4.社交网络-集合</h3> 
<p>粉丝<br> 共同好友<br> 兴趣爱好<br> 标签</p> 
<h3><a id="5_45"></a>5.消息队列-发布订阅</h3> 
<p>配合ELK缓存收集来的日志</p> 
<h2><a id="4_Redis_47"></a>第4章 Redis安装部署</h2> 
<h3><a id="1redis_48"></a>1.redis官网</h3> 
<p>https://redis.io/</p> 
<h3><a id="2_50"></a>2.版本选择</h3> 
<p>2.x very old<br> 3.x redis-cluster<br> 4.x 混合持久化<br> 5.x 新增加了流处理类型 最新稳定版</p> 
<h3><a id="3_55"></a>3.规划目录</h3> 
<p>/data/soft 下载目录<br> /opt/redis_6379/{conf,logs,pid} 安装目录,日志目录,pid目录,配置目录<br> /data/redis_6379/ 数据目录</p> 
<h3><a id="4_59"></a>4.安装命令</h3> 
<p>mkdir /data/soft -p<br> cd /data/soft<br> wget http://download.redis.io/releases/redis-5.0.7.tar.gz<br> tar xf redis-5.0.7.tar.gz -C /opt/<br> ln -s /opt/redis-5.0.7 /opt/redis<br> cd /opt/redis<br> make<br> make install</p> 
<h3><a id="5_68"></a>5.配置文件</h3> 
<p>mkdir -p /opt/redis_6379/{conf,pid,logs}<br> mkdir -p /data/redis_6379<br> cat &gt;/opt/redis_6379/conf/redis_6379.conf&lt;&lt; EOF<br> daemonize yes<br> bind 127.0.0.1 10.0.0.51<br> port 6379<br> pidfile /opt/redis_6379/pid/redis_6379.pid<br> logfile /opt/redis_6379/logs/redis_6379.log<br> EOF</p> 
<h3><a id="6_78"></a>6.启动命令</h3> 
<p>redis-server /opt/redis_6379/conf/redis_6379.conf</p> 
<h3><a id="7_80"></a>7.检查</h3> 
<p>ps -ef|grep redis<br> netstat -lntup|grep 6379</p> 
<h3><a id="8redis_83"></a>8.连接redis终端</h3> 
<p>[root@db01 ~]# redis-cli<br> 127.0.0.1:6379&gt;<br> 127.0.0.1:6379&gt; set k1 v1<br> OK<br> 127.0.0.1:6379&gt; get k1<br> “v1”<br> 127.0.0.1:6379&gt;</p> 
<h3><a id="9_91"></a>9.关闭命令</h3> 
<p>kill<br> pkill<br> redis-cli<br> &gt;SHUTDOWN<br> - redis-cli shutdown</p> 
<h3><a id="10system_97"></a>10.system启动配置</h3> 
<p>groupadd -g 1000 redis<br> useradd -u 1000 -g 1000 -M -s /sbin/nologin<br> chown -R redis:redis /data/redis*<br> chown -R redis:redis /opt/redis*<br> cat &gt;/usr/lib/systemd/system/redis.service&lt;&lt;EOF<br> [Unit]<br> Description=Redis persistent key-value database<br> After=network.target<br> After=network-online.target<br> Wants=network-online.target</p> 
<p>[Service]<br> ExecStart=/usr/local/bin/redis /opt/redis_6379/conf/redis_6379.conf --supervised systemd<br> ExecStop=/usr/local/bin/redis-cli -h $(ifconfig eth0|awk ‘NR==2{print $2}’) -p 6379 shutdown<br> Type=notify<br> User=redis<br> Group=redis<br> RuntimeDirectory=redis<br> RuntimeDirectoryMode=0755</p> 
<p>[Install]<br> WantedBy=multi-user.target<br> EOF<br> systemctl daemon-reload<br> systemctl start redis</p> 
<h2><a id="5_Redis_124"></a>第5章 Redis全局命令</h2> 
<p>全局命令是指对所有数据类型都通用的命令</p> 
<h3><a id="0redis_126"></a>0.redis数据格式</h3> 
<p>key:value<br> 键:值</p> 
<h3><a id="1key_129"></a>1.写入测试key</h3> 
<p>set k1 v1<br> set k2 v2<br> set k3 v3</p> 
<h3><a id="2key_133"></a>2.查看所有的key</h3> 
<p>！！！危险命令！！！此操作未满30岁禁止请在家人的看管下执行<br> keys *</p> 
<h3><a id="3key_136"></a>3.查看有多少个key</h3> 
<p>DBSIZE</p> 
<h3><a id="4Key_138"></a>4.查看某个Key是否存在</h3> 
<p>EXISTS k1</p> 
<p>状态码：<br> 0 表示这个key不存在<br> 1 表示这个key存在<br> N 表示存在N个key<br> 5.删除key<br> DEL k1<br> DEL k1 k2</p> 
<p>状态码：<br> 0 表示这个key不存在<br> 1 表示这个key存在，并且删除成功了<br> N 表示N个key存在，并且删除成功了N个key<br> 6.键过期<br> 设置过期时间<br> EXPIRE k1 10</p> 
<p>状态码：<br> 0 这个key不存在<br> 1 这个key存在，并且设置过期时间成功<br> 查看keys是否过期<br> TTL k1</p> 
<p>状态码：<br> -1 这个key存在,并且没有设定存活周期，永不过期<br> -2 这个key不存在<br> N 这个key存在，并且在N秒后过期<br> 取消过期时间：<br> 第一种方法：<br> PERSIST k1</p> 
<p>第二种方法：<br> set k1 v1</p> 
<p>结论：<br> 过期后的key会被直接删除</p> 
<h2><a id="6__176"></a>第6章 字符串操作</h2> 
<h3><a id="1key_177"></a>1.设置一个key</h3> 
<p>set k1 v1</p> 
<h3><a id="2key_179"></a>2.查看一个key</h3> 
<p>get k1</p> 
<h3><a id="3key_181"></a>3.设置多个key</h3> 
<p>MSET k1 v1 k2 v2 k3 v3 k4 v4</p> 
<h3><a id="4key_183"></a>4.查看多个key</h3> 
<p>MGET k1 k2 k3 k4</p> 
<h3><a id="5_185"></a>5.天然计数器</h3> 
<p>加1:<br> SET k1 1<br> INCR k1<br> GET k1</p> 
<p>加N：<br> INCRBY k1 100</p> 
<p>减1:<br> INCRBY k1 -1</p> 
<p>减N:<br> INCRBY k1 -100</p> 
<h2><a id="7__199"></a>第7章 列表操作</h2> 
<h3><a id="1_200"></a>1.插入列表</h3> 
<p>LPUSH: 从列表左侧插入数据<br> RPUSH: 从列表右侧插入数据</p> 
<h3><a id="2_203"></a>2.查看列表长度</h3> 
<p>LLEN list1</p> 
<h3><a id="3_205"></a>3.查看列表内容</h3> 
<p>LRANGE list1 0 -1</p> 
<h3><a id="4_207"></a>4.删除列表元素</h3> 
<p>LPOP: 从列表左边删除一个元素<br> RPOP: 从列表右边删除一个元素</p> 
<p>LPOP list1<br> RPOP list1</p> 
<h3><a id="5_213"></a>5.删除整个列表</h3> 
<p>DEL list1</p> 
<h2><a id="8_hash_215"></a>第8章 hash操作</h2> 
<h3><a id="1mysqlredis_216"></a>1.mysql数据如何缓存到redis</h3> 
<p>mysql存储格式：<br> user<br> id name job age<br> 1 bobo IT 28<br> 2 json py 25<br> 3 hao bug 26</p> 
<p>hash类型存储格式：<br> key field value field value<br> user:1 name bobo job IT age 28<br> user:2 name json job py age 25<br> user:3 name hao job bug age 26</p> 
<h3><a id="2Hash_229"></a>2.创建一个Hash数据</h3> 
<p>HMSET user:1 name bobo job IT age 28<br> HMSET user:2 name json job py age 29<br> HMSET user:3 name hao job bug age 19</p> 
<h3><a id="3hash_233"></a>3.查看hash里指定的值</h3> 
<p>select name from user where id =1 ;</p> 
<p>HMGET user:1 name<br> HMGET user:1 name job age</p> 
<h3><a id="4Hash_238"></a>4.查看Hash里所有的值</h3> 
<p>select * from user where id =1 ;</p> 
<p>HGETALL user:1</p> 
<h2><a id="9__set_242"></a>第9章 集合操作 set</h2> 
<h3><a id="1_243"></a>1.创建集合</h3> 
<p>SADD set1 1 2 3<br> SADD set2 1 3 5 7</p> 
<h3><a id="2_246"></a>2.查看集合成员</h3> 
<p>SMEMBERS set1<br> SMEMBERS set2</p> 
<h3><a id="3_249"></a>3.查看集合的交集</h3> 
<p>127.0.0.1:6379&gt; SINTER set1 set2</p> 
<ol><li>“1”</li><li>“3”</li></ol> 
<h3><a id="4_253"></a>4.查看集合的并集</h3> 
<p>127.0.0.1:6379&gt; SUNION set1 set2</p> 
<ol><li>“1”</li><li>“2”</li><li>“3”</li><li>“5”</li><li>“7”</li></ol> 
<h3><a id="5_260"></a>5.查看集合的差集</h3> 
<p>127.0.0.1:6379&gt; SDIFF set1 set2</p> 
<ol><li>“2”</li></ol> 
<p>127.0.0.1:6379&gt; SDIFF set2 set1</p> 
<ol><li>“5”</li><li>“7”</li></ol> 
<h3><a id="6_267"></a>6.删除一个成员</h3> 
<p>SREM set1 1</p> 
<h3><a id="7_269"></a>7.注意</h3> 
<p>集合不允许出现重复的值，自动去重</p> 
<h2><a id="10__271"></a>第10章 有序集合操作</h2> 
<h3><a id="1_272"></a>1.添加成员</h3> 
<p>ZADD SZ3 100 json<br> ZADD SZ3 90 bobo<br> ZADD SZ3 99 xiaocancan<br> ZADD SZ3 98 bughao</p> 
<h3><a id="2_277"></a>2.计算成员个数</h3> 
<p>ZCARD SZ3</p> 
<h3><a id="3_279"></a>3.计算某个成员分数</h3> 
<p>ZSCORE SZ3 json</p> 
<h3><a id="4_281"></a>4.按照降序查看成员名次：</h3> 
<p>ZRANK SZ3 json<br> ZRANK SZ3 bobo</p> 
<h3><a id="5_284"></a>5.按照升序查看成员名次：</h3> 
<p>ZREVRANK SZ3 json<br> ZREVRANK SZ3 bobo</p> 
<h3><a id="6_287"></a>6.删除成员</h3> 
<p>ZREM SZ3 json</p> 
<h3><a id="7_289"></a>7.增加成员分数</h3> 
<p>ZINCRBY SZ3 2 xiaocancan<br> ZSCORE SZ3 xiaocancan</p> 
<h3><a id="8_292"></a>8.返回指定排名范围的成员</h3> 
<p>ZRANGE SZ3 0 3<br> ZRANGE SZ3 0 3 WITHSCORES</p> 
<h3><a id="9_295"></a>9.返回指定分数范围的成员</h3> 
<p>ZRANGEBYSCORE SZ3 95 100<br> ZRANGEBYSCORE SZ3 95 100 WITHSCORES</p> 
<h3><a id="10_298"></a>10.返回指定分数范围的成员的个数</h3> 
<p>ZCOUNT SZ3 90 110</p> 
<h2><a id="11__300"></a>第11章 持久化</h2> 
<p><img src="https://images2.imgbox.com/d2/d0/M08mq6vM_o.png" alt="在这里插入图片描述"><br> RDB流程图<br> <img src="https://images2.imgbox.com/44/3a/vqC0bsmm_o.png" alt="在这里插入图片描述"><br> AOF流程图</p> 
<h3><a id="1RDBAOF_305"></a>1.RDB和AOF介绍</h3> 
<p>RDB：类似于快照的形式，当前内存里的状态持久化到硬盘里<br> 优点：压缩格式/恢复速度快<br> 缺点：不是实时的，可能会丢失数据,操作比较重</p> 
<p>AOF：类似于mysql的binlog，可以设置为每秒/每次操作以追加的形式持久化<br> 优点：安全，最多损失1秒的数据，可读<br> 缺点：文件比较大，恢复速度慢</p> 
<h3><a id="2RDB_313"></a>2.配置RDB</h3> 
<p>save 900 1<br> save 300 10<br> save 60 10000<br> dbfilename redis.rdb<br> dir /data/redis_6379/</p> 
<h3><a id="3RDB_319"></a>3.RDB结论</h3> 
<p>1.没有配置save参数时，shutdown不会持久化保存<br> 2.没有配置save参数时，可以手动执行bgsave触发持久化<br> 3.在配置了save参数后，shutdown,kill,pkill都会自动触发bgsave<br> 4.恢复的时候，rdb文件名要和配置文件里写的一样。<br> 5.RDB高版本兼容低版本，低版本不兼容高版本</p> 
<h3><a id="4AOF_325"></a>4.AOF配置</h3> 
<p>appendonly yes<br> appendfilename “redis.aof”<br> appendfsync everysec</p> 
<h3><a id="5AOF_329"></a>5.AOF重写机制</h3> 
<p>执行的命令 aof记录 redis的数据<br> set k1 v1 set k1 k1<br> set k2 v2 set k2 k1 k2<br> set k3 v3 set k3 k1 k2 k3<br> del k1 del k1 k2 k3<br> del k2 del k2 k3<br> 实际有意义的只有一条记录：<br> set k3</p> 
<h3><a id="6aofrdb_338"></a>6.aof和rdb实验</h3> 
<p>实验背景：<br> aof和rdb同时存在的时候，redis重启会读取哪一个数据？<br> 实验步骤：<br> set k1 v1<br> set k2 v2<br> bgsave<br> RDB k1 k2<br> mv redis.rdb /opt/</p> 
<p>flushall<br> set k3 v3<br> set k4 v4<br> AOF k3 k4<br> mv redis.aof /opt/</p> 
<p>pkill redis<br> rm -rf /data/redis_6379/*<br> mv /opt/redis.rdb .<br> mv /opt/redis.aof .</p> 
<p>redis-server /opt/redis_6379/conf/redis.conf<br> redis-cli<br> keys *<br> 结论：<br> 当aof和rdb同时存在时，重启redis会优先读取aof的内容</p> 
<h3><a id="7rdbaof_364"></a>7.如何选择是rdb还是aof</h3> 
<p>https://redis.io/topics/persistence<br> 1.开启混合模式<br> 2.开启aof<br> 3.不开启rdb<br> 4.rdb采用定时任务的方式定时备份</p> 
<h3><a id="8aof_370"></a>8.aof文件故障模拟实验结论</h3> 
<p>1.aof文件损坏之后，使用修复工具，一刀流，从aof文件出错的地方开始到最后全部删掉<br> 2.任何操作之前，先备份数据<br> 3.aof备份一般情况最多损失1秒的数据</p> 
<h3><a id="9_374"></a>9.实验：如果设置了过期时间，恢复数据会如何处理</h3> 
<p>1.aof文件会记录下过期的时间<br> 2.恢复的时候会去对比记录的过期时间和当前时间，如果超过了，就删除key<br> 3.key的过期时间不受备份恢复影响</p> 
<h2><a id="12_redis_378"></a>第12章 redis用户认证</h2> 
<p>1.写入配置文件<br> requirepass cookzhang<br> 2.使用密码登陆<br> 第一种：<br> [root@db01 ~]# redis-cli<br> 127.0.0.1:6379&gt; AUTH cookzhang<br> OK<br> 127.0.0.1:6379&gt; set k1 v1<br> OK</p> 
<p>第二种：<br> redis-cli -a cookz get k1<br> 3.为什么redis的密码认证这么简单？<br> 1.redis一般都部署在内网环境，默认是比较安全的环境<br> 2.有同学担心密码写在配置文件里，开发不允许登陆到Linux服务器上，但是可以连接到redis,设个密码安全些</p> 
<h2><a id="13__394"></a>第13章 禁用或重命名危险命令</h2> 
<h3><a id="1_395"></a>1.禁用危险命令</h3> 
<p>rename-command CONFIG “”<br> rename-command KEYS “”<br> rename-command SHUTDOWN “”<br> rename-command FLUSHALL “”<br> rename-command DEL “”<br> rename-command FLUSHDB “”</p> 
<h3><a id="2jsonshutdown_kill_402"></a>2.来自json的灵魂拷问：shutdown禁用了 让后用kill?</h3> 
<p>rename-command CONFIG “”<br> rename-command KEYS “”<br> rename-command SHUTDOWN “qq526195417”<br> rename-command FLUSHALL “”<br> rename-command DEL “byebye”<br> rename-command FLUSHDB “”</p> 
<h2><a id="14_Redis_409"></a>第14章 Redis主从复制</h2> 
<h3><a id="1_410"></a>1.快速部署第二台服务器</h3> 
<p>rsync -avz 10.0.0.51:/opt/* /opt/*<br> mkdir /data/redis_6379/ -p<br> cd /opt/redis<br> make install<br> sed -i ‘s#51#52#g’ /opt/redis_6379/conf/redis_6379.conf<br> redis-server /opt/redis_6379/conf/redis_6379.conf</p> 
<h3><a id="2db01_417"></a>2.db01插入测试命令</h3> 
<p>for i in {1…1000};do redis-cli -h 10.0.0.51 set ${i} ${i};done</p> 
<h3><a id="3_419"></a>3.配置主从复制</h3> 
<p>方法1:临时生效<br> redis-cli -h 10.0.0.52 slaveof 10.0.0.51 6379<br> 方法2:写进配置文件<br> slaveof 10.0.0.51 6379</p> 
<h3><a id="4_424"></a>4.主从复制的流程</h3> 
<p>1.简单流程：<br> 1.从节点发送同步请求到主节点<br> 2.主节点接收到从节点的请求之后,做了如下操作</p> 
<ul><li>立即执行bgsave将当前内存里的数据持久化到磁盘上</li><li>持久化完成之后,将rdb文件发送给从节点</li></ul> 
<p>3.从节点从主节点接收到rdb文件之后,做了如下操作</p> 
<ul><li>清空自己的数据</li><li>载入从主节点接收的rdb文件到自己的内存里</li></ul> 
<p>4.后面的操作就是和主节点实时的了</p> 
<h3><a id="5_436"></a>5.取消复制</h3> 
<pre><code>SLAVEOF no one
</code></pre> 
<h3><a id="6_438"></a>6.主从复制注意</h3> 
<p>1.从节点只读不可写<br> 2.从节点不会自动故障转移,它会一直同步主节点<br> 10.0.0.52:6379&gt; set k1 v1<br> (error) READONLY You can’t write against a read only slave.<br> 3.主从复制故障转移需要人工介入</p> 
<ul><li>修改代码指向REDIS的IP地址</li><li>从节点需要执行SLAVEOF no one<br> 4.从节点会清空自己原有的数据,如果同步的对象写错了,就会导致数据丢失<br> 5.从库和主库后续的同步依靠的是redis的SYNC协议，而不是RDB文件，RDB文件只是第一次建立同步时使用。<br> 6.从库也可以正常的持久化文件</li></ul> 
<h3><a id="7_449"></a>7.安全的操作</h3> 
<p>无论是同步,无论是主节点还是从节点,请先备份一下数据</p> 
<h2><a id="15_Redis_452"></a>第15章 Redis哨兵</h2> 
<p><img src="https://images2.imgbox.com/4a/73/eOEV5XyV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_456"></a>1.哨兵的作用</h3> 
<p>1.解决了主从复制故障需要人为干预的问题<br> 2.提供了自动的高可用解决方案</p> 
<h3><a id="2_459"></a>2.目录和端口规划</h3> 
<p>redis节点： 6379<br> 哨兵节点： 26379</p> 
<h3><a id="33redis_462"></a>3.部署3台redis单节点</h3> 
<p>db01操作：<br> pkill redis<br> cat &gt;/opt/redis_6379/conf/redis_6379.conf &lt;&lt;EOF<br> daemonize yes<br> bind 127.0.0.1 10.0.0.51<br> port 6379<br> pidfile “/opt/redis_6379/pid/redis_6379.pid”<br> logfile “/opt/redis_6379/logs/redis_6379.log”<br> dbfilename “redis.rdb”<br> dir “/data/redis_6379”<br> appendonly yes<br> appendfilename “redis.aof”<br> appendfsync everysec<br> EOF<br> systemctl start redis<br> redis-cli<br> db02和db03的操作：<br> pkill redis<br> rm -rf /opt/redis*<br> rsync -avz 10.0.0.51:/usr/local/bin/redis-* /usr/local/bin<br> rsync -avz 10.0.0.51:/usr/lib/systemd/system/redis.service /usr/lib/systemd/system/<br> mkdir /opt/redis_6379/{conf,logs,pid} -p<br> mkdir /data/redis_6379 -p<br> cat &gt;/opt/redis_6379/conf/redis_6379.conf &lt;&lt;EOF<br> daemonize yes<br> bind 127.0.0.1 $(ifconfig eth0|awk ‘NR==2{print $2}’)<br> port 6379<br> pidfile “/opt/redis_6379/pid/redis_6379.pid”<br> logfile “/opt/redis_6379/logs/redis_6379.log”<br> dbfilename “redis.rdb”<br> dir “/data/redis_6379”<br> appendonly yes<br> appendfilename “redis.aof”<br> appendfsync everysec<br> EOF<br> useradd redis -M -s /sbin/nologin<br> chown -R redis:redis /opt/redis*<br> chown -R redis:redis /data/redis*<br> systemctl daemon-reload<br> systemctl start redis<br> redis-cli</p> 
<h3><a id="4_504"></a>4.配置主从复制</h3> 
<p>redis-cli -h 10.0.0.52 slaveof 10.0.0.51 6379<br> redis-cli -h 10.0.0.53 slaveof 10.0.0.51 6379<br> redis-cli -h 10.0.0.51 info Replication</p> 
<h3><a id="53_508"></a>5.部署哨兵节点-3台机器都操作</h3> 
<p>mkdir -p /data/redis_26379<br> mkdir -p /opt/redis_26379/{conf,pid,logs}<br> cat &gt;/opt/redis_26379/conf/redis_26379.conf &lt;&lt; EOF<br> bind $(ifconfig eth0|awk ‘NR==2{print $2}’)<br> port 26379<br> daemonize yes<br> logfile /opt/redis_26379/logs/redis_26379.log<br> dir /data/redis_26379<br> sentinel monitor myredis 10.0.0.51 6379 2<br> sentinel down-after-milliseconds myredis 3000<br> sentinel parallel-syncs myredis 1<br> sentinel failover-timeout myredis 18000<br> EOF<br> chown -R redis:redis /data/redis*<br> chown -R redis:redis /opt/redis*<br> 参数解释：<br> sentinel monitor mymaster 10.0.0.51 6379 2<br> #mymaster 主节点别名 主节点 ip 和端口， 判断主节点失败， 两个 sentinel 节点同意<br> sentinel down-after-milliseconds mymaster 3000<br> #选项指定了 Sentinel 认为服务器已经断线所需的毫秒数。<br> sentinel parallel-syncs mymaster 1<br> #向新的主节点发起复制操作的从节点个数， 1 轮询发起复制<br> sentinel failover-timeout mymaster 180000<br> #故障转移超时时间</p> 
<h3><a id="6system3_533"></a>6.编写哨兵system配置文件-3台机器都操作</h3> 
<p>cat &gt;/usr/lib/systemd/system/redis-sentinel.service&lt;&lt;EOF<br> [Unit]<br> Description=Redis persistent key-value database<br> After=network.target<br> After=network-online.target<br> Wants=network-online.target</p> 
<p>[Service]<br> ExecStart=/usr/local/bin/redis-sentinel /opt/redis_26379/conf/redis_26379.conf --supervised systemd<br> ExecStop=/usr/local/bin/redis-cli -h $(ifconfig eth0|awk ‘NR==2{print $2}’) -p 26379 shutdown<br> Type=notify<br> User=redis<br> Group=redis<br> RuntimeDirectory=redis<br> RuntimeDirectoryMode=0755</p> 
<p>[Install]<br> WantedBy=multi-user.target<br> EOF<br> systemctl daemon-reload</p> 
<h3><a id="7_554"></a>7.启动哨兵并检查</h3> 
<p>systemctl start redis-sentinel</p> 
<h3><a id="8_556"></a>8.验证主节点</h3> 
<p>redis-cli -h 10.0.0.51 -p 26379 Sentinel get-master-addr-by-name myredis<br> redis-cli -h 10.0.0.52 -p 26379 Sentinel get-master-addr-by-name myredis<br> redis-cli -h 10.0.0.53 -p 26379 Sentinel get-master-addr-by-name myredis</p> 
<h3><a id="9_560"></a>9.模拟故障转移</h3> 
<p>关闭主节点服务上的所有redis进程<br> 观察其他2个节点会不会发生选举<br> 查看配置文件里会不会自动更新<br> 查看新的主节点能不能写入<br> 查看从节点能否正常同步</p> 
<h3><a id="10_566"></a>10.模拟故障修复上线</h3> 
<p>启动单节点<br> 启动哨兵</p> 
<h3><a id="11jsonredis___569"></a>11.来自json的灵魂发问：能够给redis 节点加权 来确定优先备选主节点嘛?</h3> 
<p>流程说明：<br> 设置其他节点的权重为0<br> 手动发起重新选举<br> 观察所有节点消息是否同步<br> 观察切换结果是否符合预期<br> 命令解释：<br> 查询命令:CONFIG GET slave-priority<br> 设置命令:CONFIG SET slave-priority 0<br> 主动切换:sentinel failover myredis<br> 操作命令：<br> redis-cli -h 10.0.0.52 -p 6379 CONFIG SET slave-priority 0<br> redis-cli -h 10.0.0.53 -p 6379 CONFIG SET slave-priority 0<br> redis-cli -h 10.0.0.51 -p 26379 sentinel failover myredis<br> 验证选举结果：<br> redis-cli -h 10.0.0.51 -p 26379 Sentinel get-master-addr-by-name myredis<br> 第16章 手动部署Redis集群<br> <img src="https://images2.imgbox.com/67/02/DppAR35V_o.png" alt="在这里插入图片描述"></p> 
<p>集群架构图1<br> <img src="https://images2.imgbox.com/b7/bd/ni60sHK4_o.png" alt="在这里插入图片描述"></p> 
<p>集群架构图2</p> 
<h3><a id="1_593"></a>1.哨兵的不足</h3> 
<p>资源利用率不高<br> 主库压力大<br> 连接过程繁琐</p> 
<h3><a id="2_597"></a>2.集群重要概念</h3> 
<p>redis集群，无论有几个节点，一共只有16384个槽<br> 所有的槽位都必须分配，哪怕有1个槽位不正常，整个集群都不能用<br> 每个节点的槽的顺序不重要，重点是数量<br> hash算法足够随机，足够平均<br> 每个槽被分配到数据的概率是相当的<br> 集群的高可用依赖于主从复制<br> 集群拥有自己的配置文件，动态更新，不要手欠修改<br> 集群通讯会使用基础端口号+10000的端口，这个是自动创建的，不是配置文件配置的<br> 集群槽位分配比例允许误差在%2之间</p> 
<h3><a id="3_607"></a>3.目录规划</h3> 
<p>主节点 6380<br> 从节点 6381</p> 
<h3><a id="4db01_610"></a>4.db01的操作</h3> 
<p>ssh-keygen<br> ssh-copy-id 10.0.0.52<br> ssh-copy-id 10.0.0.53<br> pkill redis<br> mkdir -p /opt/redis_{6380,6381}/{conf,logs,pid}<br> mkdir -p /data/redis_{6380,6381}<br> cat &gt;/opt/redis_6380/conf/redis_6380.conf&lt;&lt;EOF<br> bind 10.0.0.51<br> port 6380<br> daemonize yes<br> pidfile “/opt/redis_6380/pid/redis_6380.pid”<br> logfile “/opt/redis_6380/logs/redis_6380.log”<br> dbfilename “redis_6380.rdb”<br> dir “/data/redis_6380/”<br> appendonly yes<br> appendfilename “redis.aof”<br> appendfsync everysec<br> cluster-enabled yes<br> cluster-config-file nodes_6380.conf<br> cluster-node-timeout 15000<br> EOF<br> cd /opt/<br> cp redis_6380/conf/redis_6380.conf redis_6381/conf/redis_6381.conf<br> sed -i ‘s#6380#6381#g’ redis_6381/conf/redis_6381.conf<br> chown -R redis:redis /opt/redis_*<br> chown -R redis:redis /data/redis_*<br> cat &gt;/usr/lib/systemd/system/redis-master.service&lt;&lt;EOF<br> [Unit]<br> Description=Redis persistent key-value database<br> After=network.target<br> After=network-online.target<br> Wants=network-online.target</p> 
<p>[Service]<br> ExecStart=/usr/local/bin/redis-server /opt/redis_6380/conf/redis_6380.conf --supervised systemd<br> ExecStop=/usr/local/bin/redis-cli -h $(ifconfig eth0|awk ‘NR==2{print $2}’) -p 6380 shutdown<br> Type=notify<br> User=redis<br> Group=redis<br> RuntimeDirectory=redis<br> RuntimeDirectoryMode=0755</p> 
<p>[Install]<br> WantedBy=multi-user.target<br> EOF<br> cd /usr/lib/systemd/system/<br> cp redis-master.service redis-slave.service<br> sed -i ‘s#6380#6381#g’ redis-slave.service<br> systemctl daemon-reload<br> systemctl start redis-master<br> systemctl start redis-slave<br> ps -ef|grep redis<br> rsync -avz /opt/redis_638* 10.0.0.52:/opt/<br> rsync -avz /opt/redis_638* 10.0.0.53:/opt/<br> rsync -avz /usr/lib/systemd/system/redis-<em>.service 10.0.0.52:/usr/lib/systemd/system/redis-master.service<br> rsync -avz /usr/lib/systemd/system/redis-</em>.service 10.0.0.53:/usr/lib/systemd/system/redis-master.service</p> 
<h3><a id="5db02_667"></a>5.db02的操作</h3> 
<p>pkill redis<br> find /opt/redis_638* -type f -name "<em>.conf"|xargs sed -i “/bind/s#51#52#g”<br> cd /usr/lib/systemd/system/<br> sed -i ‘s#51#52#g’ redis-</em>.service<br> mkdir –p /data/redis_{6380,6381}<br> chown -R redis:redis /opt/redis_*<br> chown -R redis:redis /data/redis_*<br> systemctl daemon-reload<br> systemctl start redis-master<br> systemctl start redis-slave<br> ps -ef|grep redis</p> 
<h3><a id="6db03_679"></a>6.db03的操作</h3> 
<p>pkill redis<br> find /opt/redis_638* -type f -name "<em>.conf"|xargs sed -i “/bind/s#51#53#g”<br> cd /usr/lib/systemd/system/<br> sed -i ‘s#51#53#g’ redis-</em>.service<br> mkdir –p /data/redis_{6380,6381}<br> chown -R redis:redis /opt/redis_*<br> chown -R redis:redis /data/redis_*<br> systemctl daemon-reload<br> systemctl start redis-master<br> systemctl start redis-slave<br> ps -ef|grep redis</p> 
<h3><a id="7_691"></a>7.集群手动发现节点</h3> 
<p>redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.52 6380<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.53 6380<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.51 6381<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.52 6381<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.53 6381<br> redis-cli -h db01 -p 6380 CLUSTER NODES</p> 
<h3><a id="8_698"></a>8.集群手动分配槽位</h3> 
<p>1.槽位规划<br> db01:6380 5461 0-5460<br> db02:6380 5461 5461-10921<br> db03:6380 5462 10922-16383<br> 2.分配槽位<br> redis-cli -h db01 -p 6380 CLUSTER ADDSLOTS {0…5460}<br> redis-cli -h db02 -p 6380 CLUSTER ADDSLOTS {5461…10921}<br> redis-cli -h db03 -p 6380 CLUSTER ADDSLOTS {10922…16383}<br> 3.查看集群状态<br> redis-cli -h db01 -p 6380 CLUSTER NODES<br> redis-cli -h db01 -p 6380 CLUSTER INFO</p> 
<h3><a id="9_710"></a>9.手动部署复制关系</h3> 
<p>0.先获取集群节点信息<br> redis-cli -h db01 -p 6380 CLUSTER NODES<br> 1.先删除所有6381的内容和不需要内容<br> 6380的ID 10.0.0.51<br> 6380的ID 10.0.0.53<br> 6380的ID 10.0.0.52<br> 2.画图<br> 3.确定复制关系<br> redis-cli -h db01 -p 6381 CLUSTER REPLICATE 52的6380的ID<br> redis-cli -h db02 -p 6381 CLUSTER REPLICATE 53的6380的ID<br> redis-cli -h db03 -p 6381 CLUSTER REPLICATE 51的6380的ID<br> 4.检查复制关系<br> redis-cli -h db01 -p 6380 CLUSTER NODES</p> 
<h3><a id="10_724"></a>10.集群插入数据</h3> 
<p>1.尝试插入一条数据发现报错<br> 10.0.0.51:6380&gt; set k1 v1<br> (error) MOVED 12706 10.0.0.53:6380<br> 2.目前的现象<br> 在db01的6380节点插入数据提示报错<br> 报错内容提示应该移动到db03的6380上<br> 在db03的6380上执行相同的插入命令可以插入成功<br> 在db01的6380节点插入数据有时候可以,有时候不行<br> 使用-c参数后,可以正常插入命令,并且节点切换到了提示的对应节点上<br> 3.问题原因<br> 因为集群模式有ASK路由规则,加入-c参数后,会自动跳转到目标节点处理<br> 并且最后由目标节点返回信息</p> 
<p><img src="https://images2.imgbox.com/ac/68/DRXhyfrZ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="11_741"></a>11.验证集群是否足够足迹足够平均</h3> 
<p>0.写入测试数据<br> for i in {1…10000};do redis-cli -c -h db01 -p 6380 set k_${i} v_${i};echo ${i};done<br> 1.验证足够平均:<br> DBSIZE<br> 2.验证足够随机：<br> redis-cli -c -h db03 -p 6380 keys * &gt; keys_all.txt<br> cat keys_all.txt |awk -F “_” ‘{print $2}’|sort -rn<br> 3.允许节点的key在2%误差的依据来源：<br> [root@db01 /opt/redis/src]# redis-cli --cluster rebalance 10.0.0.51 6380<br> &gt;&gt;&gt; Performing Cluster Check (using node 10.0.0.51:6380)<br> [OK] All nodes agree about slots configuration.<br> &gt;&gt;&gt; Check for open slots…<br> &gt;&gt;&gt; Check slots coverage…<br> [OK] All 16384 slots covered.<br> *** No rebalancing needed! All nodes are within the 2.00% threshold.<br> 4.检查集群健康状态：<br> [root@db01 /opt/redis/src]# redis-cli --cluster info 10.0.0.51 6380<br> 10.0.0.51:6380 (ccaa5dcb…) -&gt; 3343 keys | 5461 slots | 1 slaves.<br> 10.0.0.53:6380 (a69e46ea…) -&gt; 3343 keys | 5462 slots | 1 slaves.<br> 10.0.0.52:6380 (b2719c41…) -&gt; 3314 keys | 5461 slots | 1 slaves.<br> [OK] 10000 keys in 3 masters.<br> 0.61 keys per slot on average.</p> 
<h2><a id="17__764"></a>第17章 实战-槽位分配错误如何调整</h2> 
<h3><a id="1_765"></a>1.故障背景</h3> 
<p>某日某豪接到任务，需要部署redis集群结果不小心无脑复制粘贴，把所有的槽都分配给了1个节点，还没发现，然后就交付使用了，过了1天才发现问题。<br> 而此时，已经有不少数据写入了，如何在不丢失数据的情况下解决这个问题？</p> 
<h3><a id="2_768"></a>2.前提</h3> 
<p>数据不能丢，最好不中断业务</p> 
<h3><a id="3_770"></a>3.实验现象</h3> 
<p>[root@db01 ~]# redis-cli --cluster info 10.0.0.51 6380<br> 10.0.0.51:6380 (ccaa5dcb…) -&gt; 1000 keys | 16384 slots | 3 slaves.<br> 10.0.0.53:6380 (a69e46ea…) -&gt; 0 keys | 0 slots | 0 slaves.<br> 10.0.0.52:6380 (b2719c41…) -&gt; 0 keys | 0 slots | 0 slaves.<br> [OK] 1000 keys in 3 masters.<br> 0.06 keys per slot on average.<br> 解决思路1：备份数据，重做集群，导入数据<br> 来自json的灵魂发问：<br> redis.cof的数据 集群重做后 aof文件里面的数据能被hash嘛?</p> 
<p>备份数据：<br> redis-cli -c -h db01 -p 6380<br> db01:6380&gt; BGREWRITEAOF<br> cp redis.aof redis.aof-1000.bak</p> 
<p>重做集群：<br> redis-cli -h db01 -p 6380 FLUSHALL<br> redis-cli -h db02 -p 6380 FLUSHALL<br> redis-cli -h db03 -p 6380 FLUSHALL</p> 
<p>redis-cli -h db01 -p 6380 CLUSTER RESET<br> redis-cli -h db02 -p 6380 CLUSTER RESET<br> redis-cli -h db03 -p 6380 CLUSTER RESET</p> 
<p>redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.52 6380<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.53 6380<br> redis-cli -h db01 -p 6380 CLUSTER NODES</p> 
<p>redis-cli -h db01 -p 6380 CLUSTER ADDSLOTS {0…5460}<br> redis-cli -h db02 -p 6380 CLUSTER ADDSLOTS {5461…10921}<br> redis-cli -h db03 -p 6380 CLUSTER ADDSLOTS {10922…16383}</p> 
<p>redis-cli --cluster info 10.0.0.51 6380</p> 
<p>实验结论：<br> 重启后所有的数据还是在db01上。<br> db01重启后数据虽然可以写入，但是访问的时候还是按照正常的hash规则去分配的，所以db01的数据实际上是没用的。<br> 所以这样的方法是不可行的。</p> 
<p>相关日志：<br> 16790:M 12 Mar 2020 10:08:08.875 # I have keys for slot 5812, but the slot is assigned to another node. Setting it to importing state.<br> 16790:M 12 Mar 2020 10:08:08.875 # I have keys for slot 5821, but the slot is assigned to another node. Setting it to importing state.<br> 16790:M 12 Mar 2020 10:08:08.875 # I have keys for slot 5842, but the slot is assigned to another node. Setting it to importing state.<br> 解决思路2:获得所有key的名称，导出再导入<br> 0.重新制作一个测试集群，槽位分布和线上出错的一样<br> 1.将线上环境里的aof导出来<br> 2.恢复到测试的集群里<br> 3.收集所有的key<br> redis-cli -c -h db01 -p 6380 keys * &gt; keys_all.txt<br> 4.编写脚本遍历所有的key获取值<br> cat &gt;get_key.sh&lt;&lt;EOF<br> #!/bin/bash<br> for key in <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         c 
        
       
         a 
        
       
         t 
        
       
         k 
        
       
         e 
        
       
         y 
        
        
        
          s 
         
        
          a 
         
        
       
         l 
        
       
         l 
        
       
         . 
        
       
         t 
        
       
         x 
        
       
         t 
        
       
         ) 
        
       
         d 
        
       
         o 
        
       
         v 
        
       
         a 
        
       
         l 
        
       
         u 
        
       
         e 
        
       
         = 
        
       
      
        (cat keys_all.txt) do value= 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord">.</span><span class="mord mathdefault">t</span><span class="mord mathdefault">x</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span></span></span></span></span>(redis-cli -c -h 10.0.0.51 -p 6380 get ${key})<br> echo redis-cli -c -h 10.0.0.51 -p 6380 set ${key} ${value} &gt;&gt; backup_all_key.txt<br> done<br> EOF</p> 
<p>5.按照正常槽位分配去重新初始化集群<br> redis-cli -h db01 -p 6380 FLUSHALL<br> redis-cli -h db02 -p 6380 FLUSHALL<br> redis-cli -h db03 -p 6380 FLUSHALL<br> redis-cli -h db01 -p 6380 CLUSTER RESET<br> redis-cli -h db02 -p 6380 CLUSTER RESET<br> redis-cli -h db03 -p 6380 CLUSTER RESET<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.52 6380<br> redis-cli -h db01 -p 6380 CLUSTER MEET 10.0.0.53 6380<br> redis-cli -h db01 -p 6380 CLUSTER NODES<br> redis-cli -h db01 -p 6380 CLUSTER ADDSLOTS {0…5460}<br> redis-cli -h db02 -p 6380 CLUSTER ADDSLOTS {5461…10921}<br> redis-cli -h db03 -p 6380 CLUSTER ADDSLOTS {10922…16383}<br> redis-cli --cluster info 10.0.0.51 6380</p> 
<p>6.执行导入脚本<br> bash backup_all_key.txt</p> 
<p>7.检查是否导入成功<br> redis-cli --cluster info 10.0.0.51 6380</p> 
<p>8.测试环境没问题之后再去生产环境操作<br> 解决思路3: 流水线 pipline<br> 前提条件：<br> 1.了解aof格式<br> 2.了解新版本redis默认是开启混合模式的<br> 3.需要修改为普通的aof格式并重启<br> 4.恢复时使用-c参数无效，需要在每一个节点都执行</p> 
<p>命令：<br> redis-cli -c -h 10.0.0.51 -p 6380 --pipe &lt; redis.aof<br> redis-cli -c -h 10.0.0.52 -p 6380 --pipe &lt; redis.aof<br> redis-cli -c -h 10.0.0.53 -p 6380 --pipe &lt; redis.aof<br> 解决思路4: 使用redis-cli工具重新分配槽位<br> 重新分配槽位<br> redis-cli --cluster reshard 10.0.0.51:6380</p> 
<p>第一次交互：输入迁出的槽的数量<br> How many slots do you want to move (from 1 to 16384)? 5461</p> 
<p>第二次交互：输入接受的ID<br> What is the receiving node ID? db02的6380的ID</p> 
<p>第三次交互：输入发送者的ID<br> Please enter all the source node IDs.<br> Type ‘all’ to use all the nodes as source nodes for the hash slots.<br> Type ‘done’ once you entered all the source nodes IDs.<br> Source node #1: db01的6390的ID<br> Source node #2: done</p> 
<p>第四次交互：YES!</p> 
<p>重复上面的操作，知道所有的节点槽位都分配正确<br> 解决思路5:直接使用工具在线导入<br> redis-cli --cluster import 10.0.0.51:6380 --cluster-copy --cluster-replace --cluster-from 10.0.0.51:6379<br> 第18章 使用工具自动部署redis集群<br> 1.恢复集群初始化<br> redis-cli -h db01 -p 6380 FLUSHALL<br> redis-cli -h db02 -p 6380 FLUSHALL<br> redis-cli -h db03 -p 6380 FLUSHALL<br> redis-cli -h db01 -p 6381 FLUSHALL<br> redis-cli -h db02 -p 6381 FLUSHALL<br> redis-cli -h db03 -p 6381 FLUSHALL<br> redis-cli -h db01 -p 6380 CLUSTER RESET<br> redis-cli -h db02 -p 6380 CLUSTER RESET<br> redis-cli -h db03 -p 6380 CLUSTER RESET<br> redis-cli -h db01 -p 6381 CLUSTER RESET<br> redis-cli -h db02 -p 6381 CLUSTER RESET<br> redis-cli -h db03 -p 6381 CLUSTER RESET<br> redis-cli -h db01 -p 6380 CLUSTER NODES<br> 2.使用工具初始化<br> redis-cli --cluster create 172.16.69.163:6380 172.16.69.164:6380 172.16.69.165:6380 172.16.69.163:6381 172.16.69.164:6381 172.16.69.165:6381 --cluster-replicas 1<br> 3.检查集群<br> redis-cli --cluster info 10.0.0.51 6380<br> redis-cli -h db01 -p 6380 CLUSTER NODES<br> redis-cli --cluster check 10.0.0.51 6380</p> 
<h2><a id="19__906"></a>第19章 使用工具扩容</h2> 
<p><img src="https://images2.imgbox.com/66/c9/YowFzCrL_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1json_910"></a>1.来自json的灵魂发问：</h3> 
<p>迁移时候槽的数据咋办？<br> 需要停库吗？<br> 访问受影响吗？<br> 从库呢？</p> 
<h3><a id="2_915"></a>2.如何设计实验验证数据是否受影响？</h3> 
<p>迁移的过程中<br> 一个窗口不断的写数据<br> 一个窗口不断的读数据<br> 观察是否会中断</p> 
<h3><a id="3_920"></a>3.创建新节点</h3> 
<p>mkdir -p /opt/redis_{6390,6391}/{conf,logs,pid}<br> mkdir -p /data/redis_{6390,6391}<br> cd /opt/<br> cp redis_6380/conf/redis_6380.conf redis_6390/conf/redis_6390.conf<br> cp redis_6380/conf/redis_6380.conf redis_6391/conf/redis_6391.conf<br> sed -i ‘s#6380#6390#g’ redis_6390/conf/redis_6390.conf<br> sed -i ‘s#6380#6391#g’ redis_6391/conf/redis_6391.conf<br> redis-server /opt/redis_6390/conf/redis_6390.conf<br> redis-server /opt/redis_6391/conf/redis_6391.conf<br> ps -ef|grep redis<br> redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6390<br> redis-cli -c -h db01 -p 6380 cluster meet 10.0.0.51 6391<br> redis-cli -c -h db01 -p 6380 cluster nodes</p> 
<h3><a id="4_934"></a>4.使用工具扩容步骤</h3> 
<p>重新分配槽位<br> redis-cli --cluster reshard 10.0.0.51:6380</p> 
<p>第一次交互：每个节点分配多少个槽位<br> How many slots do you want to move (from 1 to 16384)? 4096</p> 
<p>第二次交互：接受节点的ID是什么<br> What is the receiving node ID? 6390的ID</p> 
<p>第三次交互：哪些节点需要导出<br> Source node #1: all</p> 
<p>第四次交互：确认是否执行<br> Do you want to proceed with the proposed reshard plan (yes/no)? yes</p> 
<h2><a id="20__949"></a>第20章 使用工具缩容</h2> 
<p><img src="https://images2.imgbox.com/5d/d9/BF3H6t8p_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_953"></a>1.操作命令</h3> 
<p>重新分配槽位<br> redis-cli --cluster reshard 10.0.0.51:6380</p> 
<p>第一次交互：需要迁移多少个槽位<br> How many slots do you want to move (from 1 to 16384)? 1365</p> 
<p>第二次交互：接受节点的ID是什么<br> What is the receiving node ID? db01的6380的ID</p> 
<p>第三次交互：哪些节点需要导出<br> Source node #1: db01的6390的ID<br> Source node #2: done</p> 
<p>第四次交互：确认<br> Do you want to proceed with the proposed reshard plan (yes/no)? yes</p> 
<p>重复上面的操作，直到6390所有的槽位都被分配出去了</p> 
<p>检查集群状态，确认6390没有槽位了<br> redis-cli --cluster info 10.0.0.51:6380</p> 
<p>使用工具删除节点了<br> redis-cli --cluster del-node 10.0.0.51:6390 6390的ID<br> redis-cli --cluster del-node 10.0.0.51:6391 6391的ID</p> 
<h3><a id="2__978"></a>2.提问：公司先用的是哨兵然后在改集群 如何迁移数据</h3> 
<p>用槽位分配解决方法：<br> 1.搭建好Redis集群并互相发现<br> 2.把所有的key都分配到db01上<br> 3.把哨兵里的数据AOF持久化<br> 4.拷贝到db01上，启动集群节点<br> 5.重新分配槽位迁移到其他2个节点</p> 
<h2><a id="21__985"></a>第21章 .验证集群高可用</h2> 
<h3><a id="1_986"></a>1.提问：故障的主库修复后启动会变成备胎吗？</h3> 
<h3><a id="2_987"></a>2.实验结论：</h3> 
<p>1.主库挂了，从库会自动接替主库的角色，集群恢复正常会受超时时间控制<br> 2.老得主库修复上线后，会自动变成从库，同步新的主库<br> 3.主动发起集群角色切换：<br> CLUSTER FAILOVER</p> 
<h2><a id="22__992"></a>第22章 模拟分配时故障</h2> 
<h3><a id="1_993"></a>1.模拟场景：迁移数据时人为中断了，导致槽的状态不对</h3> 
<p>[11213-&lt;-a69e46ea7560684a7061ddb6dc3f854a1ef3dbd4] 51<br> [11213-&gt;-ccaa5dcb0f0320332100594d629122b2702660d5] 53</p> 
<h3><a id="2_996"></a>2.使用工具修复：</h3> 
<p>redis-cli --cluster fix 10.0.0.51:6380</p> 
<h3><a id="3_998"></a>3.手动修复：</h3> 
<p>CLUSTER SETSLOT STABLE</p> 
<h2><a id="23__1000"></a>第23章 使用工具维护集群的好处</h2> 
<p>工具有很多判断条件，更加严谨，健壮性更好<br> 删除槽，使用工具会判断，如果槽里有数据，就不执行<br> 添加节点使用工具会判断，如果新增加的节点本身不为空，不允许加入到集群里<br> 删除节点使用工具会判断，如果本删除节点本身还有槽，不允许删除</p> 
<h2><a id="24__1005"></a>第24章 数据迁移</h2> 
<h3><a id="1_1006"></a>1.新版本直接使用工具迁移</h3> 
<p>不加copy参数相当于mv，老数据迁移成功就删掉了<br> redis-cli --cluster import 10.0.0.51:6380 --cluster-from 10.0.0.51:6379<br> 添加copy参数相当于cp,老数据迁移成功后会保留<br> redis-cli --cluster import 10.0.0.51:6380 --cluster-copy --cluster-from 10.0.0.51:6379<br> 添加replace参数会覆盖掉同名的数据，对新集群新增加的数据不受影响<br> redis-cli --cluster import 10.0.0.51:6380 --cluster-copy --cluster-replace --cluster-from 10.0.0.51:6379<br> 验证迁移期间边写边导会不会影响: 同时开2个终端，一个写入key，<br> for i in {1…1000};do redis-cli set k_<span class="katex--inline">KaTeX parse error: Expected group after '_' at position 6: {i} v_̲</span>{i};sleep 0.2;echo ${i};done<br> 一个执行导入命令<br> redis-cli --cluster import 10.0.0.51:6380 --cluster-copy --cluster-replace --cluster-from 10.0.0.51:6379<br> 得出结论：<br> 只会导入当你执行导入命令那一刻时，当前被导入节点的所有数据，类似于快照，对于后面再写入的数据不会更新</p> 
<h2><a id="25_key_1019"></a>第25章 分析key的大小</h2> 
<h3><a id="0_1020"></a>0.使用自带工具分析</h3> 
<p>redis-cli --bigkeys</p> 
<h3><a id="1_1022"></a>1.使用第三方工具分析</h3> 
<p>1.安装命令<br> yum install python-pip gcc python-devel -y<br> cd /opt/<br> git clone https://github.com/sripathikrishnan/redis-rdb-tools<br> cd redis-rdb-tools<br> pip install python-lzf<br> python setup.py install<br> 2.生成测试数据<br> redis-cli -h db01 -p 6379 set txt $(cat txt.txt)<br> 3.执行bgsave生成rdb文件<br> redis-cli -h db01 -p 6379 BGSAVE<br> 4.使用工具分析<br> cd /data/redis_6379/<br> rdb -c memory redis_6379.rdb -f redis_6379.rdb.csv<br> 5.过滤分析<br> awk -F"," ‘{print $4,$3}’ redis_6379.rdb.csv |sort -r<br> 6.汇报领导<br> 将结果整理汇报给领导,询问开发这个key是否可以删除</p> 
<h2><a id="26_redis_1041"></a>第26章 redis的内存管理</h2> 
<h3><a id="1_1042"></a>1.设置最大内存限制</h3> 
<p>config set maxmemory 2G</p> 
<h3><a id="2_1044"></a>2.内存回收机制</h3> 
<p>生产上一定要限制redis的内存使用大小。<br> 当达到内存使用限制之后redis会出发对应的控制策略<br> redis支持6种策略：<br> 1.noevicition 默认策略，不会删除任务数据，拒绝所有写入操作并返回客户端错误信息，此时只响应读操作<br> 2.volatile-lru 根据LRU算法删除设置了超时属性的key，指导腾出足够空间为止，如果没有可删除的key，则退回到noevicition策略<br> 3.allkeys-lru 根据LRU算法删除key，不管数据有没有设置超时属性<br> 4.allkeys-random 随机删除所有key<br> 5.volatile-random 随机删除过期key<br> 5.volatile-ttl 根据key的ttl，删除最近要过期的key</p> 
<h3><a id="3redis_1054"></a>3.生产上redis限制多大内存</h3> 
<p>先空出来系统一半内存<br> 48G 一共<br> 24G 系统<br> 24G redis<br> redis先给8G内存 满了之后，分析结果告诉老大和开发，让他们排查一下是否所有的key都是必须的<br> redis再给到12G内存 满了之后，分析结果告诉老大和开发，让他们排查一下是否所有的key都是必须的<br> redis再给到16G内存 满了之后，分析结果告诉老大和开发，让他们排查一下是否所有的key都是必须的<br> 等到24G都用完了之后，汇报领导，要考虑买内存了。<br> 等到35G的时候，就要考虑是加内存，还是扩容机器。</p> 
<h2><a id="27__1064"></a>第27章 性能测试</h2> 
<p>redis-benchmark -n 10000 -q</p> 
<h2><a id="28__1066"></a>第28章 集群相关命令</h2> 
<p>redis-cli -h db01 -p 6380<br> CLUSTER NODES<br> CLUSTER MEET 10.0.0.52 6380<br> CLUSTER INFO<br> CLUSTER REPLICATE<br> CLUSTER ADDSLOTS<br> CLUSTER RESET<br> CLUSTER FAILOVER<br> CLUSTER SETSLOT STABLE<br> redis-cli --cluster info 10.0.0.51 6380<br> redis-cli --cluster rebalance 10.0.0.51 6380<br> redis-cli --cluster del-node<br> redis-cli --cluster fix 10.0.0.51:6380</p> 
<h2><a id="29__1080"></a>第29章 命令总结</h2> 
<h3><a id="1_1081"></a>1.全局命令</h3> 
<p>keys *<br> DBSIZE<br> EXISTS k1<br> EXPIRE k1 10<br> TTL k1<br> DEL k1</p> 
<h3><a id="2_1089"></a>2.字符串:</h3> 
<p>set k1 v1<br> get k1</p> 
<p>mset k1 v1 k2 v2 k3 v3<br> mget k1 k2 k3</p> 
<p>incr k1<br> incrby k1 N</p> 
<h3><a id="3_1099"></a>3.列表：</h3> 
<p>LPUSH<br> RPUSH<br> LPOP<br> RPOP</p> 
<p>LLEN<br> LRANGE list1 0 -1</p> 
<p>HASH:<br> HMSET<br> HGET<br> HMGET<br> HGETALL</p> 
<h3><a id="4_1114"></a>4.集合：</h3> 
<p>SADD<br> SDIFF<br> SINTER<br> SUNION<br> SREM</p> 
<h3><a id="5_1121"></a>5.有序集合：</h3> 
<p>ZADD<br> ZCARD<br> ZSCORE<br> ZRANK<br> ZREVRANK<br> ZRANGE<br> ZRANGEBYSCORE<br> ZINCRBY<br> ZCOUNT</p> 
<h3><a id="6_1133"></a>6.脚本控制</h3> 
<p>[root@db01 ~]# cat redis_shell.sh</p> 
<pre><code class="prism language-shell"><span class="token shebang important">#!/bin/bash</span>

USAG<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">echo</span> <span class="token string">"sh <span class="token variable">$0</span> {start|stop|restart|login|ps|tail} PORT"</span>
<span class="token punctuation">}</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$#</span>"</span> <span class="token operator">=</span> 1 <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    REDIS_PORT<span class="token operator">=</span><span class="token string">'6379'</span>
<span class="token keyword">elif</span> 
    <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$#</span>"</span> <span class="token operator">=</span> 2 -a -z <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token keyword">echo</span> <span class="token string">"<span class="token variable">$2</span>"</span><span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s#[0-9]##g'</span><span class="token variable">)</span></span>"</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    REDIS_PORT<span class="token operator">=</span><span class="token string">"<span class="token variable">$2</span>"</span>
<span class="token keyword">else</span>
    USAG
    <span class="token keyword">exit</span> 0
<span class="token keyword">fi</span>

REDIS_IP<span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">hostname</span> -I<span class="token operator">|</span><span class="token function">awk</span> <span class="token string">'{print <span class="token variable">$1</span>}'</span><span class="token variable">)</span></span>
PATH_DIR<span class="token operator">=</span>/opt/redis_cluster/redis_<span class="token variable">${REDIS_PORT}</span>/
PATH_CONF<span class="token operator">=</span>/opt/redis_cluster/redis_<span class="token variable">${REDIS_PORT}</span>/conf/redis_<span class="token variable">${REDIS_PORT}</span>.conf
PATH_LOG<span class="token operator">=</span>/opt/redis_cluster/redis_<span class="token variable">${REDIS_PORT}</span>/logs/redis_<span class="token variable">${REDIS_PORT}</span>.log

CMD_START<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    redis-server <span class="token variable">${PATH_CONF}</span>
<span class="token punctuation">}</span>

CMD_SHUTDOWN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    redis-cli -c -h <span class="token variable">${REDIS_IP}</span> -p <span class="token variable">${REDIS_PORT}</span> <span class="token function">shutdown</span>
<span class="token punctuation">}</span>

CMD_LOGIN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    redis-cli -c -h <span class="token variable">${REDIS_IP}</span> -p <span class="token variable">${REDIS_PORT}</span>
<span class="token punctuation">}</span>

CMD_PS<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token function">ps</span> -ef<span class="token operator">|</span><span class="token function">grep</span> redis
<span class="token punctuation">}</span>

CMD_TAIL<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token function">tail</span> -f <span class="token variable">${PATH_LOG}</span>
<span class="token punctuation">}</span>

<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
    start<span class="token punctuation">)</span>
        CMD_START
        CMD_PS
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    stop<span class="token punctuation">)</span>
        CMD_SHUTDOWN
        CMD_PS
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    restart<span class="token punctuation">)</span>
        CMD_START
        CMD_SHUTDOWN
        CMD_PS
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    login<span class="token punctuation">)</span>
        CMD_LOGIN
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    ps<span class="token punctuation">)</span>
        CMD_PS
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    tail<span class="token punctuation">)</span>
        CMD_TAIL
        <span class="token punctuation">;</span><span class="token punctuation">;</span>
    *<span class="token punctuation">)</span>
        USAG
esac
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/53e16ac535c99e1e8097d10c54c29d46/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CMakeList 中 find_library 用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e9d1ca489bb34c394f78148b29650713/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">7-26 单词长度（15分）你的程序要读入一行文本，其中以空格分隔为若干个单词，以.结束。你要输出每个单词的长度。这里的单词与语言无关，可以包括各种符号，比如it‘s算一个单词，长度为4。注意，行中可</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>