<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>BEVFusion（北大&amp;阿里）环境搭建教程 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="BEVFusion（北大&amp;阿里）环境搭建教程" />
<meta property="og:description" content="BEVFusion环境搭建 论文题目：BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework
论文地址：https://arxiv.org/pdf/2205.13790.pdf
代码地址：ADLab-AutoDrive/BEVFusion: Offical PyTorch implementation of “BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework” (github.com)
前言：这是今年新发的一篇论文，我在第一次阅读时，代码还未开源，前几天发现开源了，而且这个框架做的很清晰，可以基于这个工作熟悉一下融合方案，也能稍稍改进一下。
笔者环境：
sys.platform: linux
Python: 3.8.3 | packaged by conda-forge | (default, Jun 1 2020, 17:43:00) [GCC 7.5.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr
NVCC: Build cuda_11.5.r11.5/compiler.30672275_0
GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
PyTorch: 1.8.0&#43;cu111
PyTorch compiling details: PyTorch built with:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c5ed633710f2bcc05f5fd11d1e68f2e6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-30T17:18:27+08:00" />
<meta property="article:modified_time" content="2023-10-30T17:18:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">BEVFusion（北大&amp;阿里）环境搭建教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="BEVFusion_0"></a>BEVFusion环境搭建</h2> 
<p>论文题目：BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework</p> 
<p>论文地址：<a href="https://arxiv.org/pdf/2205.13790.pdf" rel="nofollow">https://arxiv.org/pdf/2205.13790.pdf</a></p> 
<p>代码地址：<a href="https://github.com/ADLab-AutoDrive/BEVFusion">ADLab-AutoDrive/BEVFusion: Offical PyTorch implementation of “BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework” (github.com)</a></p> 
<p>前言：这是今年新发的一篇论文，我在第一次阅读时，代码还未开源，前几天发现开源了，而且这个框架做的很清晰，可以基于这个工作熟悉一下融合方案，也能稍稍改进一下。</p> 
<p>笔者环境：</p> 
<blockquote> 
 <p>sys.platform: linux<br> Python: 3.8.3 | packaged by conda-forge | (default, Jun 1 2020, 17:43:00) [GCC 7.5.0]<br> CUDA available: True<br> GPU 0,1: NVIDIA GeForce RTX 3090<br> CUDA_HOME: /usr<br> NVCC: Build cuda_11.5.r11.5/compiler.30672275_0<br> GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0<br> PyTorch: 1.8.0+cu111<br> PyTorch compiling details: PyTorch built with:</p> 
 <ul><li>GCC 7.3</li><li>C++ Version: 201402</li><li>Intel® Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel® 64 architecture applications</li><li>Intel® MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)</li><li>OpenMP 201511 (a.k.a. OpenMP 4.5)</li><li>NNPACK is enabled</li><li>CPU capability usage: AVX2</li><li>CUDA Runtime 11.1</li><li>NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86</li><li>CuDNN 8.0.5</li><li>Magma 2.5.2</li><li>Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,</li></ul> 
 <p>TorchVision: 0.9.0+cu111<br> OpenCV: 4.6.0<br> MMCV: 1.4.0<br> MMCV Compiler: GCC 7.3<br> MMCV CUDA Compiler: 11.1<br> MMDetection: 2.11.0<br> MMDetection3D: 0.11.0+9d3e162</p> 
</blockquote> 
<p>说人话：torch1.8.0+cuda111，显卡是3090，其余环境根据根据官方文档配的</p> 
<h3><a id="_44"></a>一、安装</h3> 
<h4><a id="1BEVFusion_46"></a>1、克隆BEVFusion代码</h4> 
<pre><code class="prism language-python">git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>ADLab<span class="token operator">-</span>AutoDrive<span class="token operator">/</span>BEVFusion<span class="token punctuation">.</span>git
</code></pre> 
<h4><a id="2_52"></a>2、新建虚拟环境</h4> 
<pre><code class="prism language-python">conda create <span class="token operator">-</span>n bevfusion python<span class="token operator">=</span><span class="token number">3.8</span><span class="token number">.3</span>
conda activate bevfusion <span class="token comment">#激活</span>
</code></pre> 
<h4><a id="3cudatorch_59"></a>3、根据cuda版本安装torch</h4> 
<p>尽量选择1.7或者1.8，cuda版本要对应<br> <strong>2022年11月22日更新：尽量选1.7吧，1.8的bug导致训练有些问题</strong><br> <strong>2022年12月2日更新：最近太忙，前几天发现1.7的torch不适合在这个项目上用，具体原因和3090显卡有关，缺少相关库（3090最低支持cuda11.1，torch1.7最高支持cuda11.0）</strong></p> 
<pre><code class="prism language-python">pip install torch<span class="token operator">=</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">+</span>cu111 torchvision<span class="token operator">=</span><span class="token number">0.9</span><span class="token number">.0</span><span class="token operator">+</span>cu111 torchaudio<span class="token operator">==</span><span class="token number">0.8</span><span class="token number">.0</span> <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>download<span class="token punctuation">.</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>whl<span class="token operator">/</span>torch_stable<span class="token punctuation">.</span>html
</code></pre> 
<h4><a id="4mmcvfull_69"></a>4、安装mmcv-full</h4> 
<p>这里要根据自己的torch和cuda来，另外，BEVFusion官方文档推荐1.4.0版本</p> 
<p>从以下网址找到自己合适的版本</p> 
<pre><code>https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html
</code></pre> 
<p>其中cu_version代表cuda版本，torch_version代表torch版本，</p> 
<p>例如，我的是torch1.8.0+cuda111，所以我的地址是：</p> 
<pre><code>https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html
</code></pre> 
<p>因为创建的环境是python3.8，所以选择cp38，别忘了mmcv-full版本是1.4.0，下载whl文件，并传到服务器上，然后pip whl文件（不再赘述pip安装whl了，百度一下）</p> 
<p><img src="https://images2.imgbox.com/eb/5d/2Nm6TZvi_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5MMDetection_92"></a>5、安装MMDetection</h4> 
<p>下面是BEVFusion官方推荐的环境</p> 
<blockquote> 
 <p>python=3.8.3<br> mmdet=2.11.0 (<strong>please install mmdet in mmdetection-2.11.0</strong>)<br> mmcv=1.4.0<br> mmdet3d=0.11.0<br> numpy=1.19.2<br> torch=1.7.0<br> torchvision=0.8.0</p> 
</blockquote> 
<p>注意<strong>please install mmdet in mmdetection-2.11.0</strong>，作者已经在仓库中放了这个文件夹，我们直接进入这个文件夹<br> <img src="https://images2.imgbox.com/c6/38/iUhxJ43Z_o.png" alt="在这里插入图片描述"></p> 
<p>然后执行：</p> 
<pre><code class="prism language-python">pip install <span class="token operator">-</span>r requirements<span class="token operator">/</span>build<span class="token punctuation">.</span>txt
pip install <span class="token operator">-</span>v <span class="token operator">-</span>e <span class="token punctuation">.</span>  <span class="token comment"># or "python setup.py develop"(推荐执行后者)</span>
</code></pre> 
<h4><a id="6MMDetection3D_113"></a>6、安装MMDetection3D</h4> 
<p>退回到BEVFusion根目录下，执行下面指令</p> 
<pre><code class="prism language-python">pip install <span class="token operator">-</span>v <span class="token operator">-</span>e <span class="token punctuation">.</span>  <span class="token comment"># or "python setup.py develop"（推荐执行后者）</span>
</code></pre> 
<p>至此配置完毕</p> 
<p>以下是我的环境</p> 
<blockquote> 
 <p>Package Version Editable project location</p> 
 <hr> 
 <p>absl-py 1.3.0<br> addict 2.4.0<br> anyio 3.6.2<br> argon2-cffi 21.3.0<br> argon2-cffi-bindings 21.2.0<br> asttokens 2.1.0<br> attrs 22.1.0<br> backcall 0.2.0<br> beautifulsoup4 4.11.1<br> black 22.10.0<br> bleach 5.0.1<br> cachetools 5.2.0<br> certifi 2022.9.24<br> cffi 1.15.1<br> charset-normalizer 2.1.1<br> click 8.1.3<br> contourpy 1.0.6<br> cycler 0.11.0<br> Cython 0.29.32<br> debugpy 1.6.3<br> decorator 5.1.1<br> defusedxml 0.7.1<br> depthwise-conv2d-implicit-gemm 0.0.0<br> descartes 1.1.0<br> entrypoints 0.4<br> exceptiongroup 1.0.4<br> executing 1.2.0<br> fastjsonschema 2.16.2<br> filelock 3.8.0<br> fire 0.4.0<br> flake8 5.0.4<br> fonttools 4.38.0<br> google-auth 2.14.1<br> google-auth-oauthlib 0.4.6<br> grpcio 1.50.0<br> h5py 3.7.0<br> huggingface-hub 0.11.0<br> idna 3.4<br> imageio 2.22.4<br> importlib-metadata 5.0.0<br> importlib-resources 5.10.0<br> iniconfig 1.1.1<br> ipykernel 6.17.1<br> ipython 8.6.0<br> ipython-genutils 0.2.0<br> ipywidgets 8.0.2<br> jedi 0.18.1<br> Jinja2 3.1.2<br> joblib 1.2.0<br> jsonschema 4.17.0<br> jupyter 1.0.0<br> jupyter_client 7.4.6<br> jupyter-console 6.4.4<br> jupyter_core 5.0.0<br> jupyter-server 1.23.2<br> jupyterlab-pygments 0.2.2<br> jupyterlab-widgets 3.0.3<br> kiwisolver 1.4.4<br> llvmlite 0.31.0<br> loguru 0.6.0<br> lyft-dataset-sdk 0.0.8<br> Markdown 3.4.1<br> MarkupSafe 2.1.1<br> matplotlib 3.6.2<br> matplotlib-inline 0.1.6<br> mccabe 0.7.0<br> mistune 2.0.4<br> mmcls 0.24.1<br> mmcv-full 1.4.0<br> mmdet 2.11.0 /home/wistful/work/my_bevfusion/mmdetection-2.11.0<br> mmdet3d 0.11.0 /home/wistful/work/my_bevfusion<br> mmpycocotools 12.0.3<br> msgpack 1.0.4<br> msgpack-numpy 0.4.8<br> multimethod 1.9<br> mypy-extensions 0.4.3<br> nbclassic 0.4.8<br> nbclient 0.7.0<br> nbconvert 7.2.5<br> nbformat 5.7.0<br> nest-asyncio 1.5.6<br> networkx 2.2<br> ninja 1.11.1<br> notebook 6.5.2<br> notebook_shim 0.2.2<br> numba 0.48.0<br> numpy 1.23.4<br> nuscenes-devkit 1.1.9<br> oauthlib 3.2.2<br> opencv-python 4.6.0.66<br> packaging 21.3<br> pandas 1.4.4<br> pandocfilters 1.5.0<br> parso 0.8.3<br> pathspec 0.10.2<br> pexpect 4.8.0<br> pickleshare 0.7.5<br> Pillow 9.3.0<br> pip 22.3.1<br> pkgutil_resolve_name 1.3.10<br> platformdirs 2.5.4<br> plotly 5.11.0<br> pluggy 1.0.0<br> plyfile 0.7.4<br> prettytable 3.5.0<br> prometheus-client 0.15.0<br> prompt-toolkit 3.0.32<br> protobuf 3.20.3<br> psutil 5.9.4<br> ptyprocess 0.7.0<br> pure-eval 0.2.2<br> pyasn1 0.4.8<br> pyasn1-modules 0.2.8<br> pycocotools 2.0.6<br> pycodestyle 2.9.1<br> pycparser 2.21<br> pyflakes 2.5.0<br> Pygments 2.13.0<br> pyparsing 3.0.9<br> pyquaternion 0.9.9<br> pyrsistent 0.19.2<br> pytest 7.2.0<br> python-dateutil 2.8.2<br> pytz 2022.6<br> PyWavelets 1.4.1<br> PyYAML 6.0<br> pyzmq 24.0.1<br> qtconsole 5.4.0<br> QtPy 2.3.0<br> requests 2.28.1<br> requests-oauthlib 1.3.1<br> rsa 4.9<br> scikit-image 0.19.3<br> scikit-learn 1.1.3<br> scipy 1.9.3<br> Send2Trash 1.8.0<br> setuptools 65.5.1<br> Shapely 1.8.5.post1<br> six 1.16.0<br> sniffio 1.3.0<br> soupsieve 2.3.2.post1<br> stack-data 0.6.1<br> tabulate 0.9.0<br> tenacity 8.1.0<br> tensorboard 2.11.0<br> tensorboard-data-server 0.6.1<br> tensorboard-plugin-wit 1.8.1<br> tensorpack 0.11<br> termcolor 2.1.0<br> terminado 0.17.0<br> terminaltables 3.1.10<br> threadpoolctl 3.1.0<br> tifffile 2022.10.10<br> timm 0.6.11<br> tinycss2 1.2.1<br> toml 0.10.2<br> tomli 2.0.1<br> torch 1.8.0+cu111<br> torchaudio 0.8.0<br> torchpack 0.3.1<br> torchvision 0.9.0+cu111<br> tornado 6.2<br> tqdm 4.64.1<br> traitlets 5.5.0<br> trimesh 2.35.39<br> typing_extensions 4.4.0<br> urllib3 1.26.12<br> wcwidth 0.2.5<br> webencodings 0.5.1<br> websocket-client 1.4.2<br> Werkzeug 2.2.2<br> wheel 0.38.4<br> widgetsnbextension 4.0.3<br> yapf 0.32.0<br> zipp 3.10.0</p> 
 <hr> 
 <p>sys.platform: linux<br> Python: 3.8.3 | packaged by conda-forge | (default, Jun 1 2020, 17:43:00) [GCC 7.5.0]<br> CUDA available: True<br> GPU 0,1: NVIDIA GeForce RTX 3090<br> CUDA_HOME: /usr/local/cuda<br> NVCC: Build cuda_11.1.TC455_06.29069683_0<br> GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0<br> PyTorch: 1.8.0+cu111<br> PyTorch compiling details: PyTorch built with:</p> 
 <ul><li>GCC 7.3</li><li>C++ Version: 201402</li><li>Intel® Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel® 64 architecture applications</li><li>Intel® MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)</li><li>OpenMP 201511 (a.k.a. OpenMP 4.5)</li><li>NNPACK is enabled</li><li>CPU capability usage: AVX2</li><li>CUDA Runtime 11.1</li><li>NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86</li><li>CuDNN 8.0.5</li><li>Magma 2.5.2</li><li>Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,</li></ul> 
 <p>TorchVision: 0.9.0+cu111<br> OpenCV: 4.6.0<br> MMCV: 1.4.0<br> MMCV Compiler: GCC 7.3<br> MMCV CUDA Compiler: 11.1<br> MMDetection: 2.20.0<br> MMDetection3D: 0.11.0+9d3e162</p> 
</blockquote> 
<h3><a id="_337"></a>二、组织数据集</h3> 
<p>注意，一般来说使用mmdetection3d框架的工作，要把数据集组织到<strong>mmdetection3d/data</strong>下，BEVFusion整个目录就是mmdetection3d的组织格式。所以<strong>要把数据集组织到BEVFusion/data下</strong></p> 
<blockquote> 
 <p>It is recommended to symlink the dataset root to <code>$MMDETECTION3D/data</code>. If your folder structure is different from the following, you may need to change the corresponding paths in config files.</p> 
</blockquote> 
<p>数据集组织我就不再赘述了，按照官方说明的组织形式组织好</p> 
<blockquote> 
 <p>mmdetection3d<br> ├── mmdet3d<br> ├── tools<br> ├── configs<br> ├── data<br> │ ├── nuscenes<br> │ │ ├── maps<br> │ │ ├── samples<br> │ │ ├── sweeps<br> │ │ ├── v1.0-test<br> | | ├── v1.0-trainval<br> │ ├── kitti<br> │ │ ├── ImageSets<br> │ │ ├── testing<br> │ │ │ ├── calib<br> │ │ │ ├── image_2<br> │ │ │ ├── velodyne<br> │ │ ├── training<br> │ │ │ ├── calib<br> │ │ │ ├── image_2<br> │ │ │ ├── label_2<br> │ │ │ ├── velodyne<br> │ ├── waymo<br> │ │ ├── waymo_format<br> │ │ │ ├── training<br> │ │ │ ├── validation<br> │ │ │ ├── testing<br> │ │ │ ├── gt.bin<br> │ │ ├── kitti_format<br> │ │ │ ├── ImageSets<br> │ ├── lyft<br> │ │ ├── v1.01-train<br> │ │ │ ├── v1.01-train (train_data)<br> │ │ │ ├── lidar (train_lidar)<br> │ │ │ ├── images (train_images)<br> │ │ │ ├── maps (train_maps)<br> │ │ ├── v1.01-test<br> │ │ │ ├── v1.01-test (test_data)<br> │ │ │ ├── lidar (test_lidar)<br> │ │ │ ├── images (test_images)<br> │ │ │ ├── maps (test_maps)<br> │ │ ├── train.txt<br> │ │ ├── val.txt<br> │ │ ├── test.txt<br> │ │ ├── sample_submission.csv<br> │ ├── scannet<br> │ │ ├── meta_data<br> │ │ ├── scans<br> │ │ ├── batch_load_scannet_data.py<br> │ │ ├── load_scannet_data.py<br> │ │ ├── scannet_utils.py<br> │ │ ├── README.md<br> │ ├── sunrgbd<br> │ │ ├── OFFICIAL_SUNRGBD<br> │ │ ├── matlab<br> │ │ ├── sunrgbd_data.py<br> │ │ ├── sunrgbd_utils.py<br> │ │ ├── README.md</p> 
</blockquote> 
<p>（以上数据集不用全需要的，自己需要哪个组织哪个）</p> 
<p>然后利用BEVFusion/tools/create_data.py脚本组织文件就行了，放一下组织nuScenes数据集成功的截图吧</p> 
<p><img src="https://images2.imgbox.com/3e/77/pZZoN67T_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_413"></a>三、训练与测试</h3> 
<h4><a id="1_415"></a>1、分布式训练</h4> 
<pre><code class="prism language-python"><span class="token comment"># first train camera stream</span>
<span class="token punctuation">.</span><span class="token operator">/</span>tools<span class="token operator">/</span>dist_train<span class="token punctuation">.</span>sh configs<span class="token operator">/</span>bevfusion<span class="token operator">/</span>cam_stream<span class="token operator">/</span>bevf_pp_4x8_2x_nusc_cam<span class="token punctuation">.</span>py <span class="token number">8</span>
<span class="token comment"># then train LiDAR stream</span>
<span class="token punctuation">.</span><span class="token operator">/</span>tools<span class="token operator">/</span>dist_train<span class="token punctuation">.</span>sh configs<span class="token operator">/</span>bevfusion<span class="token operator">/</span>lidar_stream<span class="token operator">/</span>hv_pointpillars_secfpn_sbn<span class="token operator">-</span>all_4x8_2x_nus<span class="token operator">-</span>3d<span class="token punctuation">.</span>py <span class="token number">8</span>
<span class="token comment"># then train BEVFusion</span>
<span class="token punctuation">.</span><span class="token operator">/</span>tools<span class="token operator">/</span>dist_train<span class="token punctuation">.</span>sh configs<span class="token operator">/</span>bevfusion<span class="token operator">/</span>bevf_pp_2x8_1x_nusc<span class="token punctuation">.</span>py <span class="token number">8</span>
</code></pre> 
<p><code>./tools/dist_train.sh configs/bevfusion/cam_stream/bevf_pp_4x8_2x_nusc_cam.py 8</code>中，8代表GPU个数</p> 
<p>使用sh文件进行训练和测试时，可能会遇到无权限的问题，使用<code>chmod 777 tools/dist_train.sh</code>进行权限更改即可<br> <img src="https://images2.imgbox.com/25/fc/6qDD2o2p_o.png" alt="在这里插入图片描述"></p> 
<p>其中，配置文件我就不再叙述，可以使用官方的简单测试，如果需要使用自己的配置文件，请参考mmdetection3d官方文档</p> 
<p>值得注意的是，我在使用分布式和非分布式方法做测试的时候，非分布式运行正常，分布式仍然提示找不到数据集，我搜寻资料得知是因为工作路径的原因导致的，我用<code>print(os.getcwd())</code>打印了一下，发现使用非分布式训练时，工作路径<code>/home/wistful/work/my_bevfusion/mmdetection3d/tools</code>下，即在BEVFusion/mmdetection3d/tools下，而使用分布式训练时，工作路径在<code>/home/wistful/work/my_bevfusion</code>下，即在BEVFusion根目录下。所以我使用<code>os.chdir('/home/wistful/work/my_bevfusion/mmdetection3d/tools')</code>将工作路径改变了一下，问题解决<br> <img src="https://images2.imgbox.com/42/02/sgGDdTSg_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2_438"></a>2、非分布式训练</h4> 
<p>直接在pycharm中根据各参数设置一下，训练即可，不再叙述。</p> 
<h4><a id="3_444"></a>3、测试</h4> 
<pre><code class="prism language-prthon">./tools/dist_test.sh configs/bevfusion/bevf_pp_2x8_1x_nusc.py ./work_dirs/bevfusion_pp.pth 8 --eval bbox
 # 前者是配置文件，后者是GPU个数

# 如需可视化
./tools/dist_test.sh configs/bevfusion/bevf_pp_2x8_1x_nusc.py ./work_dirs/bevfusion_pp.pth 8 --eval bbox --show-dir YourVisualResultsDir --show --eval bbox #根据test.py的参数看一下
</code></pre> 
<p>可视化结果会保存在你指定的目录下，如下所示<br> <img src="https://images2.imgbox.com/f9/85/g1NQlk4w_o.png" alt="在这里插入图片描述"><br> 导入CloudCampare查看<br> <img src="https://images2.imgbox.com/bc/b6/EOMNQuh0_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/055d0adca977145b3d67e7e612b7ff5a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Charles的安装及证书配置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c84621efe4c684446013b25b61d62e3a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue3 &#43; elememt-plus 表单生成器</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>