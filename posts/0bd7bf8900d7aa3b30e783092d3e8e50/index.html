<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ç¬¬P7å‘¨ï¼šå’–å•¡è±†è¯†åˆ«ï¼ˆVGG-16å¤ç°ï¼‰ - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ç¬¬P7å‘¨ï¼šå’–å•¡è±†è¯†åˆ«ï¼ˆVGG-16å¤ç°ï¼‰" />
<meta property="og:description" content="&gt;- **ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/rbOOmire8OocQ90QM78DRA) ä¸­çš„å­¦ä¹ è®°å½•åšå®¢** &gt;- **ğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶](https://mtyjkh.blog.csdn.net/)** ä¸€ã€å‰æœŸå·¥ä½œ
import torch import torch.nn as nn import torchvision.transforms as transforms import torchvision from torchvision import transforms, datasets import os,PIL,pathlib,warnings warnings.filterwarnings(&#34;ignore&#34;) #å¿½ç•¥è­¦å‘Šä¿¡æ¯ device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;) device 2. å¯¼å…¥æ•°æ®
import os,PIL,random,pathlib data_dir = &#39;./7-data/&#39; data_dir = pathlib.Path(data_dir) data_paths = list(data_dir.glob(&#39;*&#39;)) classeNames = [str(path).split(&#34;\\&#34;)[1] for path in data_paths] classeNames # å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863 train_transforms = transforms.Compose([ transforms.Resize([224, 224]), # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸ # transforms." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/0bd7bf8900d7aa3b30e783092d3e8e50/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-15T22:39:19+08:00" />
<meta property="article:modified_time" content="2023-12-15T22:39:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ç¬¬P7å‘¨ï¼šå’–å•¡è±†è¯†åˆ«ï¼ˆVGG-16å¤ç°ï¼‰</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<pre><code class="hljs">&gt;- **ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/rbOOmire8OocQ90QM78DRA) ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**
&gt;- **ğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶](https://mtyjkh.blog.csdn.net/)**</code></pre> 
<p>ä¸€ã€å‰æœŸå·¥ä½œ</p> 
<p></p> 
<pre><code class="language-python">import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision
from torchvision import transforms, datasets
import os,PIL,pathlib,warnings

warnings.filterwarnings("ignore")             #å¿½ç•¥è­¦å‘Šä¿¡æ¯

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device</code></pre> 
<p><br><br> 2. å¯¼å…¥æ•°æ®</p> 
<pre><code class="language-python">import os,PIL,random,pathlib

data_dir = './7-data/'
data_dir = pathlib.Path(data_dir)

data_paths  = list(data_dir.glob('*'))
classeNames = [str(path).split("\\")[1] for path in data_paths]
classeNames</code></pre> 
<pre><code class="language-python">
# å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863
train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    # transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

test_transform = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

total_data = datasets.ImageFolder("./7-data/",transform=train_transforms)
total_data
</code></pre> 
<p>3. åˆ’åˆ†æ•°æ®é›†<br><br><br><br><br><br> äºŒã€æ‰‹åŠ¨æ­å»ºVGG-16æ¨¡å‹<br><br> VGG-16ç»“æ„è¯´æ˜ï¼š<br><br> â—13ä¸ªå·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰ï¼Œåˆ†åˆ«ç”¨blockX_convXè¡¨ç¤º<br> â—3ä¸ªå…¨è¿æ¥å±‚ï¼ˆFully connected Layerï¼‰ï¼Œåˆ†åˆ«ç”¨fcXä¸predictionsè¡¨ç¤º<br> â—5ä¸ªæ± åŒ–å±‚ï¼ˆPool layerï¼‰ï¼Œåˆ†åˆ«ç”¨blockX_poolè¡¨ç¤º<br><br> VGG-16åŒ…å«äº†16ä¸ªéšè—å±‚ï¼ˆ13ä¸ªå·ç§¯å±‚å’Œ3ä¸ªå…¨è¿æ¥å±‚ï¼‰ï¼Œæ•…ç§°ä¸ºVGG-16<br><br> è¿™é‡Œï¼Œæˆ‘åˆ¶ä½œäº†ä¸€ä¸ªè§†é¢‘æ¥å±•ç¤ºVGG-16çš„ä¼ æ’­è¿‡ç¨‹</p> 
<p class="img-center"><img alt="play" height="299" src="https://images2.imgbox.com/10/6e/XNCGUISu_o.png" width="534"></p> 
<p>0:00/0:22</p> 
<p>å€é€Ÿ</p> 
<p class="img-center"><img alt="volumeUp" height="299" src="https://images2.imgbox.com/6c/89/K2R188cB_o.png" width="534"></p> 
<p class="img-center"><img alt="fullscreen" height="299" src="https://images2.imgbox.com/17/1b/pf6TbbTD_o.png" width="534"></p> 
<p class="img-center"><img alt="fullscreen" height="299" src="https://images2.imgbox.com/8c/f8/Kgx25yzA_o.png" width="534"></p> 
<p></p> 
<p>VGG-16ç½‘ç»œåŠ¨ç”»å±•ç¤º</p> 
<p>FC7</p> 
<p>FE8</p> 
<p>FC6</p> 
<p>7*7*512</p> 
<p>1*1*512</p> 
<p>1*1*1000</p> 
<p>1*1*512</p> 
<p>CONV5</p> 
<p>CONV4</p> 
<p>14*14*512</p> 
<p>CONV3</p> 
<p>28*28*512</p> 
<p>CONV2</p> 
<p>56*56*256</p> 
<p>112*112*128</p> 
<p>CONVOLUTION+RELU</p> 
<p>KåŒå­¦å•Šåˆ¶ä½œ</p> 
<p>MAX POOLING</p> 
<p>CONVI</p> 
<p>ç™¾åº¦/è°·æ­Œ/å¾®ä¿¡æœç´¢:KåŒå­¦å•Š</p> 
<p>224*224*64</p> 
<p>FULLY CONNECTED+RELU</p> 
<p></p> 
<p class="img-center"><img alt="image.png" height="579" src="https://images2.imgbox.com/8b/d1/D8Csb5hZ_o.png" width="1075"></p> 
<p><br> 1. æ­å»ºæ¨¡å‹<br><br><br><br> 2. æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…<br><br><br> ä¸‰ã€ è®­ç»ƒæ¨¡å‹<br> 1. ç¼–å†™è®­ç»ƒå‡½æ•°<br><br><br> 2. ç¼–å†™æµ‹è¯•å‡½æ•°<br><br> æµ‹è¯•å‡½æ•°å’Œè®­ç»ƒå‡½æ•°å¤§è‡´ç›¸åŒï¼Œä½†æ˜¯ç”±äºä¸è¿›è¡Œæ¢¯åº¦ä¸‹é™å¯¹ç½‘ç»œæƒé‡è¿›è¡Œæ›´æ–°ï¼Œæ‰€ä»¥ä¸éœ€è¦ä¼ å…¥ä¼˜åŒ–å™¨<br><br><br> 3. æ­£å¼è®­ç»ƒ<br><br> model.train()ã€model.eval()è®­ç»ƒè¥å¾€æœŸæ–‡ç« ä¸­æœ‰è¯¦ç»†çš„ä»‹ç»ã€‚<br><br> ğŸ“Œå¦‚æœå°†ä¼˜åŒ–å™¨æ¢æˆ SGD ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿè¯·è‡ªè¡Œæ¢ç´¢æ¥ä¸‹æ¥å‘ç”Ÿçš„è¯¡å¼‚äº‹ä»¶çš„åŸå› ã€‚<br><br><br><br> å››ã€ ç»“æœå¯è§†åŒ–<br> 1. Lossä¸Accuracyå›¾<br><br> Â </p> 
<p>TRAINING AND VALIDATION ACCURACY</p> 
<p>TRAINING AND</p> 
<p>VALIDATION LOSS</p> 
<p>1.4</p> 
<p>1.0</p> 
<p>TRAINING LOSS</p> 
<p>1.2</p> 
<p>TEST LOSS</p> 
<p>1.0</p> 
<p>0.8</p> 
<p>0.8</p> 
<p>0.6</p> 
<p>0.6</p> 
<p>0.4</p> 
<p>0.4</p> 
<p>0.2</p> 
<p>TRAINING ACCURACY</p> 
<p>TEST ACCURACY</p> 
<p>0.0</p> 
<p>75</p> 
<p>35</p> 
<p>15</p> 
<p>35</p> 
<p>25</p> 
<p>20</p> 
<p>40</p> 
<p>30</p> 
<p>40</p> 
<p>30</p> 
<p></p> 
<p class="img-center"><img alt="output_29_0.png" height="293" src="https://images2.imgbox.com/a2/a5/CjfXzqyj_o.png" width="980"></p> 
<p><br> 2. æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹<br> Â </p> 
<p>Pythonå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>2</p> 
<p>3</p> 
<p>4</p> 
<p>5</p> 
<p>6</p> 
<p>7</p> 
<p>8</p> 
<p>9</p> 
<p>10</p> 
<p>11</p> 
<p>12</p> 
<p>13</p> 
<p>14</p> 
<p>15</p> 
<p>16</p> 
<p>17</p> 
<p>18</p> 
<p>from PIL import Image</p> 
<p></p> 
<p>classes = list(total_data.class_to_idx)</p> 
<p></p> 
<p>def predict_one_image(image_path, model, transform, classes):</p> 
<p>test_img = Image.open(image_path).convert('RGB')</p> 
<p>plt.imshow(test_img) # å±•ç¤ºé¢„æµ‹çš„å›¾ç‰‡</p> 
<p></p> 
<p>test_img = transform(test_img)</p> 
<p>img = test_img.to(device).unsqueeze(0)</p> 
<p>model.eval()</p> 
<p>output = model(img)</p> 
<p></p> 
<p>_,pred = torch.max(output,1)</p> 
<p>pred_class = classes[pred]</p> 
<p>print(f'é¢„æµ‹ç»“æœæ˜¯ï¼š{pred_class}')</p> 
<p></p> 
<p>Pythonå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>2</p> 
<p>3</p> 
<p>4</p> 
<p>5</p> 
<p># é¢„æµ‹è®­ç»ƒé›†ä¸­çš„æŸå¼ ç…§ç‰‡</p> 
<p>predict_one_image(image_path='./7-data/Dark/dark (1).png',</p> 
<p>model=model,</p> 
<p>transform=train_transforms,</p> 
<p>classes=classes)</p> 
<p></p> 
<p>Plain Textå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>é¢„æµ‹ç»“æœæ˜¯ï¼šDark</p> 
<p></p> 
<p>25</p> 
<p>50</p> 
<p>75</p> 
<p>100</p> 
<p>125</p> 
<p>150</p> 
<p>175</p> 
<p>200</p> 
<p>50</p> 
<p>100</p> 
<p>150</p> 
<p>200</p> 
<p></p> 
<p class="img-center"><img alt="output_32_1.png" height="415" src="https://images2.imgbox.com/f3/70/nEXruA37_o.png" width="420"></p> 
<p><br> 3. æ¨¡å‹è¯„ä¼°<br> Â </p> 
<p>Pythonå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>2</p> 
<p>best_model.eval()</p> 
<p>epoch_test_acc, epoch_test_loss = test(test_dl, best_model, loss_fn)</p> 
<p>Pythonå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>epoch_test_acc, epoch_test_loss</p> 
<p>Plain Textå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>(0.9916666666666667, 0.035762640996836126)</p> 
<p>Pythonå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>2</p> 
<p># æŸ¥çœ‹æ˜¯å¦ä¸æˆ‘ä»¬è®°å½•çš„æœ€é«˜å‡†ç¡®ç‡ä¸€è‡´</p> 
<p>epoch_test_acc</p> 
<p>Plain Textå¤åˆ¶ä»£ç </p> 
<p>1</p> 
<p>0.9916666666666667</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a9cae59370acdce7d84ed3fb45537eb5/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">netcatç‘å£«å†›åˆ€</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f5b8f6319787dd7ad25da988c29fb426/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">UDS DTCè€åŒ–æœºåˆ¶</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>