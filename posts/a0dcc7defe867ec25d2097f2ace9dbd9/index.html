<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>收藏丨8个常用中文OCR数据集，附下载链接 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="收藏丨8个常用中文OCR数据集，附下载链接" />
<meta property="og:description" content="扫一扫识别文字、拍照翻译、拍照搜题、车牌自动识别……这些随处可见的功能，给我们的工作和生活带来了极大的便利，其背后都离不开OCR技术的支持。
随着深度学习技术的发展，智能OCR算法与应用也越来越丰富，对相关数据的需求也增加。
许多小伙伴反馈中文OCR数据集不好找，今天我们贴心地帮大家整理了8个常用的中文OCR数据集资源，记得收藏。
No.1 MSRA-TD500 (MSRA Text Detection 500 Database) 下载链接：
https://opendatalab.com/MSRA-TD500
MSRA-TD500由华中科技大学于 2012 年在 CVPR 发布，是一个用于测试和评估多方向、多语言文字检测算法的自然图像数据集，包含500幅拍摄于室内（办公室和商场）和室外（街道）场景的自然图像。室内的图像主要包括标识、门牌和标牌等，室外的图像主要是路牌和广告牌等。图像的分辨率较高，介于1294*864和1920*1280之间。
该数据集由两部分构成：训练集、测试集。训练集中一共有300幅图像，通过随机抽样的形式从原始数据集中抽取出来。余下的200幅图像构成测试集。
数据集中的所有图像都经过完整标注。数据集的基本单元是文本行而非单词。
MSRA-TD500数据集样例（图源：参考资料[1]）
MSRA-TD500数据集中的典型图像以及文字的标准矩形框 每一个矩形框对应一个文本行。红色的矩形框表示其中的文字被标记为“困难”。在MSRA-TD500数据集中，难以检测的文字（一般由低分辨率、模糊和遮挡等因素造成）会被标记为“困难”。
No.2 Chinses Text in the Wild(CTW) 下载链接：
https://ctwdataset.github.io/
由清华大学与腾讯共同推出的一个大型中文自然文本数据集（Chinese Text in the Wild，CTW）。该数据集包含 32,285 张图像和 1,018,402 个中文字符。
每张图像尺寸为2048*2048，数据集大小为31GB。CTW以（8:1:1）的比例将数据集分为：
训练集（25887张图像，812872个中文字符）；
测试集（3269张图像，103519个中文字符）；
验证集（3129张图像，103519个中文字符）；
这些图像源于腾讯街景，从中国的几十个不同城市中捕捉得到。数据多样、复杂，它包含了平面文本、凸出文本、城市街景文本、乡镇街景文本、弱照明条件下的文本、远距离文本、部分显示文本等。
CTW数据集样例示意（图源：参考资料[2]）
对于每张图像，数据集中都标注了所有中文字符。对每个中文字符，数据集都标注了其真实字符、边界框和 6 个属性以指出其是否被遮挡、有复杂的背景、被扭曲、3D 凸出、艺术化，和手写体等。
No.3 Reading Chinses Text in the Wild(RCTW-17) 下载链接：
https://rctw.vlrlab.net/dataset.html
ICDAR（国际文档分析和识别大会）在2017年发起了一项专注于中文检测和识别比赛项目（RCTW），RCTW-17为竞赛数据集，它由12263张包含中文的自然场景图片组成，其中大部分是直接由摄像头或手机拍摄，少部分为生成图像，并且每张图像至少包含一行中文。图像尺寸不规则，数据集大小为11.4GB。
数据的标注均通过标注工具手工标注完成，通过绘制四边形来标注一个文本行，而不是以单词为单位进行标注，每个文本行的内容以UTF-8字符串进行标注。在数据集中存在字体、布局和语言等多样性。
数据集划分为两部分：训练集和验证集。训练集包含8034张图片，测试集包含4229张图片。
RCTW-17数据集样例示意（图源：参考资料[3]）
No.4 ICPR MWI 2018挑战赛 下载链接：
https://tianchi.aliyun.com/competition/entrance/231685/information
ICPR MWI 大赛提供的包含2000张图像的官方数据集，主要由合成图像，产品描述，网络广告构成。该数据集数据量充分，中英文混合，涵盖数十种字体，字体大小不一，多种版式，背景复杂。数据集大小为2GB。其中训练集10000张，测试集10000张。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/a0dcc7defe867ec25d2097f2ace9dbd9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-11T11:34:50+08:00" />
<meta property="article:modified_time" content="2022-07-11T11:34:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">收藏丨8个常用中文OCR数据集，附下载链接</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p style="margin-left:0;"><span style="color:#444444;">扫一扫识别文字、拍照翻译、拍照搜题、车牌自动识别……这些随处可见的功能，给我们的工作和生活带来了极大的便利，其背后都离不开OCR技术的支持。</span></p> 
</blockquote> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">随着深度学习技术的发展，智能OCR算法与应用也越来越丰富，对相关数据的需求也增加。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">许多小伙伴反馈中文OCR数据集不好找，今天我们贴心地帮大家整理了8个常用的中文OCR数据集资源，记得收藏。</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.1 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">MSRA-TD500 (MSRA Text Detection 500 Database)</span></strong></h2> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#007aaa;"><a class="link-info" href="https://opendatalab.com/MSRA-TD500" rel="nofollow" title="https://opendatalab.com/MSRA-TD500">https://opendatalab.com/MSRA-TD500</a></span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">MSRA-TD500由华中科技大学于 2012 年在 CVPR 发布，是一个用于测试和评估多方向、多语言文字检测算法的自然图像数据集，包含500幅拍摄于室内（办公室和商场）和室外（街道）场景的自然图像。室内的图像主要包括标识、门牌和标牌等，室外的图像主要是路牌和广告牌等。图像的分辨率较高，介于1294*864和1920*1280之间。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">该数据集由两部分构成：训练集、测试集。训练集中一共有300幅图像，通过随机抽样的形式从原始数据集中抽取出来。余下的200幅图像构成测试集。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">数据集中的所有图像都经过完整标注。数据集的基本单元是文本行而非单词。</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="615" src="https://images2.imgbox.com/a1/58/BUabFDcC_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">MSRA-TD500数据集样例（图源：参考资料[1]）</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">MSRA-TD500数据集中的典型图像以及文字的标准矩形框 每一个矩形框对应一个文本行。红色的矩形框表示其中的文字被标记为“困难”。在MSRA-TD500数据集中，难以检测的文字（一般由低分辨率、模糊和遮挡等因素造成）会被标记为“困难”。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.2 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">Chinses Text in the Wild(CTW)</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://ctwdataset.github.io/</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">由清华大学与腾讯共同推出的一个大型中文自然文本数据集（Chinese Text in the Wild，CTW）。该数据集包含 32,285 张图像和 1,018,402 个中文字符。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">每张图像尺寸为2048*2048，数据集大小为31GB。CTW以（8:1:1）的比例将数据集分为：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">训练集（25887张图像，812872个中文字符）；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">测试集（3269张图像，103519个中文字符）；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">验证集（3129张图像，103519个中文字符）；</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">这些图像源于腾讯街景，从中国的几十个不同城市中捕捉得到。数据多样、复杂，它包含了平面文本、凸出文本、城市街景文本、乡镇街景文本、弱照明条件下的文本、远距离文本、部分显示文本等。</span></span></p> 
<p style="margin-left:0;"><img alt="" height="579" src="https://images2.imgbox.com/65/08/TN3vCMkt_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">CTW数据集样例示意（图源：参考资料[2]）</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">对于每张图像，数据集中都标注了所有中文字符。对每个中文字符，数据集都标注了其真实字符、边界框和 6 个属性以指出其是否被遮挡、有复杂的背景、被扭曲、3D 凸出、艺术化，和手写体等。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.3 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">Reading Chinses Text in the Wild(RCTW-17)</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://rctw.vlrlab.net/dataset.html</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">ICDAR（国际文档分析和识别大会）在2017年发起了一项专注于中文检测和识别比赛项目（RCTW），RCTW-17为竞赛数据集，它由12263张包含中文的自然场景图片组成，其中大部分是直接由摄像头或手机拍摄，少部分为生成图像，并且每张图像至少包含一行中文。图像尺寸不规则，数据集大小为11.4GB。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">数据的标注均通过标注工具手工标注完成，通过绘制四边形来标注一个文本行，而不是以单词为单位进行标注，每个文本行的内容以UTF-8字符串进行标注。在数据集中存在字体、布局和语言等多样性。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">数据集划分为两部分：训练集和验证集。训练集包含8034张图片，测试集包含4229张图片。</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="472" src="https://images2.imgbox.com/6b/7a/fpG4kYyJ_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">RCTW-17数据集样例示意（图源：参考资料[3]）</span></span></p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.4 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">ICPR MWI 2018挑战赛</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://tianchi.aliyun.com/competition/entrance/231685/information</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">ICPR MWI 大赛提供的包含2000张图像的官方数据集，主要由合成图像，产品描述，网络广告构成。该数据集数据量充分，中英文混合，涵盖数十种字体，字体大小不一，多种版式，背景复杂。数据集大小为2GB。其中训练集10000张，测试集10000张。</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="761" src="https://images2.imgbox.com/04/fd/aHu9BOMG_o.png" width="769"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">ICPR MWI 2018数据集标注样例，红框代表标注的文本框（图源：参考资料[4]）</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.5 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">ShopSign</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://github.com/chongshengzhang/shopsign</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">该数据由河南大学科研团队发布的，是一个大规模中英文自然场景文本数据集，其包含25770张街景中文招牌图像，196010条文本行。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">ShopSign中的图像是在不同的场景（市中心到偏远地区）中使用50多种不同的手机拍摄。相比于CTW，其包含了4000张夜间图像，同时也包含了2516对图像来对一个sign获取水平和多视角的图片。其包含多种分辨率，包括3024*4032、1920*1080、2180*720等。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">CMT主要包含了几个主要发达城市，而ShopSign包含的地理范围广（北京、上海、厦门、新疆、蒙古、牡丹江、葫芦岛和河南省的一些城市和小城镇），包括许多街景车辆无法到达的郊区或小城镇。CMT使用了固定的拍摄角度，而ShopSign使用了多种角度进行拍摄。[5]</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="1122" src="https://images2.imgbox.com/d5/74/zh0dmI1l_o.png" width="1058"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">ShopSign数据集中广告牌样例示意（图源：参考资料[5]）</span></span></p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="191" src="https://images2.imgbox.com/8a/21/fmsynho0_o.png" width="1005"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">ShopSign数据集中广告牌分类示意（图源：参考资料[5]）</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">注释包括了每个文本行的四边形边界框的坐标（顺序：左上、右上、右下、左下）以及相对应的文本行的相应文本。ShopSign仅仅处理广告牌上的文本。</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.6 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">ICDAR2019-LSVT</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://github.com/chongshengzhang/shopsign</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">ICDAR 2019-LSVT（Large-scale Street View Text with Partial Labeling，弱标注大规模街景文字识别）国际学术竞赛公开的大规模弱标注场景文字数据集。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">数据集采自中国街景，并由街景图片中的文字行区域（例如店铺标牌、地标等等）截取出来而形成。是首个提出弱标注数据的场景文字数据集，其中包括5万张精标注街景图像、40万张弱标注街景图像，总计45万张。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">所有图像都经过一些预处理，将文字区域利用仿射变化，等比映射为一张高为48像素的图片。</span></span></p> 
<p style="margin-left:0;"><img alt="" height="499" src="https://images2.imgbox.com/22/11/GasYlCIN_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">LSVT数据集精标注示意（图源：参考资料[6]）</span></span></p> 
<p style="margin-left:0;"><img alt="" height="364" src="https://images2.imgbox.com/5f/5f/MqUmI4VZ_o.png" width="1027"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">LSVT数据集弱标注示意（图源：参考资料[6]）</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.7 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">TotalText</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://opendatalab.com/TotalText</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">Total-Text是最大弯曲文本数据集之一-ArT（任意形状文本数据集）训练集中的一部分。该数据集共1555张图像，11459文本行，包含水平文本，倾斜文本，弯曲文本。文件大小441MB。大部分为英文文本，少量中文文本。其中训练集有1255张图像，测试集有300张图像。</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="431" src="https://images2.imgbox.com/8f/6b/yadLUE2s_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">TotalText数据集样例示意（图源：OpenDataLab）</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"></p> 
<h2 style="margin-left:0px;"><strong><em><span style="background-color:#0080ff;"><span style="color:#ffffff;"> No.8 </span></span></em></strong><strong><em> </em></strong></h2> 
<h2 style="margin-left:0px;"><strong><span style="color:#0080ff;">Caffe-ocr中文合成数据</span></strong></h2> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#222222;">下载链接：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#007aaa;">https://github.com/senlinuc/caffe_ocr</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">共360万张图片，图像分辨率为280*32，文件大小约为8.6GB。数据利用中文语料库（新闻+文言文），通过字体、大小、灰度、模糊、透视、拉伸等变化随机生成，字典中包含汉字、标点、英文、数字共5990个字符（语料字频统计，全角半角合并）。</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#222222;">每个样本固定10个字符，字符随机截取自语料库中的句子。按9:1分成训练集、验证集，测试集约6万张。</span></span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="214" src="https://images2.imgbox.com/17/8c/26brwZRx_o.png" width="1080"></p> 
<p style="margin-left:0;text-align:center;"><span style="background-color:#ffffff;"><span style="color:#888888;">Caffe-ocr数据集样例示意（图源：参考资料[7]）</span></span></p> 
<p style="margin-left:0;"></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><strong><span style="color:#888888;">参考资料</span></strong></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[1]http://www.iapr-tc11.org/dataset/MSRA-TD500/Detecting_Texts_of_Arbitrary_Orientations_in_Natural_Images.pdf</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[2]https://ctwdataset.github.io/</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[3]https://arxiv.org/pdf/1708.09585v2.pdf</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[4]https://tianchi.aliyun.com/competition/entrance/231685/information</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[5]https://arxiv.org/pdf/1903.10412v1.pdf</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[6]https://rrc.cvc.uab.es/?ch=16</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#ffffff;"><span style="color:#888888;">[7]https://github.com/senlinuc/caffe_ocr</span></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cbf91620a3000f87351a33a697220155/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">挑战更高难度的多目标跟踪，MOT20数据集使用指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/63c73baf9146da19b27c9784bc93e3c5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Kubernetes基础</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>