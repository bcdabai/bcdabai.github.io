<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>第十二周：机器学习周报 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="第十二周：机器学习周报" />
<meta property="og:description" content="目录
摘要
Abstract
1 What is GNN？
2 Why need GNN？
3 Spatial-based GNN
3.1 模型一：NN4G（Neural Network for Graph）
3.2 模型二：DCNN（Diffusion-Convolution Neural Network）
3.3 模型三：DGC（Diffusion Graph Convolution）
3.4 模型四：MoNET（Mixture Model Networks）
3.5 模型五：GAT（Graph Attention Networks）
4 Spectral-based GNN
4.1 图信号的傅里叶变换
4.2 拉普拉斯变换
4.3 频率
4.4 能量差
4.5 分析与合成
4.6 Filter
4.7 最终形态
4.7 方法的弊端 5 GNN模型代码分析
总结
摘要 图神经网络（GNN）与其他模型不同的是它的输入和输出都是图，GNN可以通过卷积将图的结构和每个节点和边的特征转化为一般的神经网络的输入，GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）。本周学习GNN的两种卷积方式，Spatial-based GNN方法采用类似CNN的卷积得到每个隐藏层的值，再将所有层的值集合成为整个graph的输出，Spectral-based GNN方法通过傅里叶变换与逆傅里叶变换得到图神经网络的卷积输出。
Abstract The difference between Graph Neural Network(GNN) and other models is that its input and output are graphs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9869a9dee53f7600df90d65afaaad3da/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-16T21:56:15+08:00" />
<meta property="article:modified_time" content="2023-07-16T21:56:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">第十二周：机器学习周报</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>目录</strong></p> 
<p style="margin-left:0px;"><a href="#%E6%91%98%E8%A6%81" rel="nofollow">摘要</a></p> 
<p style="margin-left:0px;"><a href="#Abstract" rel="nofollow">Abstract</a></p> 
<p style="margin-left:0px;"><a href="#1%20What%20is%20GNN%EF%BC%9F" rel="nofollow">1 What is GNN？</a></p> 
<p style="margin-left:0px;"><a href="#2%20Why%20need%20GNN%EF%BC%9F" rel="nofollow">2 Why need GNN？</a></p> 
<p style="margin-left:0px;"><a href="#3%20Spatial-based%20GNN" rel="nofollow">3 Spatial-based GNN</a></p> 
<p style="margin-left:40px;"><a href="#3.1%20%E6%A8%A1%E5%9E%8B%E4%B8%80%EF%BC%9ANN4G%EF%BC%88Neural%20Network%20for%20Graph%EF%BC%89" rel="nofollow">3.1 模型一：NN4G（Neural Network for Graph）</a></p> 
<p style="margin-left:40px;"><a href="#3.2%20%E6%A8%A1%E5%9E%8B%E4%BA%8C%EF%BC%9ADCNN%EF%BC%88Diffusion-Convolution%20Neural%20Network%EF%BC%89" rel="nofollow">3.2 模型二：DCNN（Diffusion-Convolution Neural Network）</a></p> 
<p style="margin-left:40px;"><a href="#3.3%20%E6%A8%A1%E5%9E%8B%E4%B8%89%EF%BC%9ADGC%EF%BC%88Diffusion%20Graph%20Convolution%EF%BC%89" rel="nofollow">3.3 模型三：DGC（Diffusion Graph Convolution）</a></p> 
<p style="margin-left:40px;"><a href="#3.4%20%E6%A8%A1%E5%9E%8B%E5%9B%9B%EF%BC%9AMoNET%EF%BC%88Mixture%20Model%20Networks%EF%BC%89" rel="nofollow">3.4 模型四：MoNET（Mixture Model Networks）</a></p> 
<p style="margin-left:40px;"><a href="#3.5%20%E6%A8%A1%E5%9E%8B%E4%BA%94%EF%BC%9AGAT%EF%BC%88Graph%20Attention%20Networks%EF%BC%89" rel="nofollow">3.5 模型五：GAT（Graph Attention Networks）</a></p> 
<p style="margin-left:0px;"><a href="#4%20Spectral-based%20GNN" rel="nofollow">4 Spectral-based GNN</a></p> 
<p style="margin-left:40px;"><a href="#4.1%20%E5%9B%BE%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2" rel="nofollow">4.1 图信号的傅里叶变换</a></p> 
<p style="margin-left:40px;"><a href="#4.2%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%8F%98%E6%8D%A2" rel="nofollow">4.2 拉普拉斯变换</a></p> 
<p style="margin-left:40px;"><a href="#4.3%20%E9%A2%91%E7%8E%87" rel="nofollow">4.3 频率</a></p> 
<p style="margin-left:40px;"><a href="#4.4%20%E8%83%BD%E9%87%8F%E5%B7%AE" rel="nofollow">4.4 能量差</a></p> 
<p style="margin-left:40px;"><a href="#4.5%20%E5%88%86%E6%9E%90%E4%B8%8E%E5%90%88%E6%88%90" rel="nofollow">4.5 分析与合成</a></p> 
<p style="margin-left:40px;"><a href="#4.6%20Filter" rel="nofollow">4.6 Filter</a></p> 
<p style="margin-left:40px;"><a href="#4.7%20%E6%9C%80%E7%BB%88%E5%BD%A2%E6%80%81" rel="nofollow">4.7 最终形态</a></p> 
<p style="margin-left:40px;"><a href="#4.7%20%E6%96%B9%E6%B3%95%E7%9A%84%E5%BC%8A%E7%AB%AF%C2%A0" rel="nofollow">4.7 方法的弊端 </a></p> 
<p style="margin-left:0px;"><a href="#5%20GNN%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90" rel="nofollow">5 GNN模型代码分析</a></p> 
<p style="margin-left:0px;"><a href="#%C2%A0%E6%80%BB%E7%BB%93" rel="nofollow"> 总结</a></p> 
<hr> 
<p> </p> 
<h2>摘要</h2> 
<p>图神经网络（GNN）与其他模型不同的是它的输入和输出都是图，GNN可以通过卷积将图的结构和每个节点和边的特征转化为一般的神经网络的输入，GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）。本周学习GNN的两种卷积方式，Spatial-based GNN方法采用类似CNN的卷积得到每个隐藏层的值，再将所有层的值集合成为整个graph的输出，Spectral-based GNN方法通过傅里叶变换与逆傅里叶变换得到图神经网络的卷积输出。</p> 
<h2>Abstract</h2> 
<p>The difference between  Graph Neural Network(GNN) and other models is that its input and output are graphs. GNN can transform the graph structure and the characteristics of each node and edge into the input of general neural network through convolution. There are two methods for convolution in GNN, one is Spatial-based and the other is Spectral-based. This week, we will learn two convolution methods of GNN. Spatial-based GNN method uses convolution similar to CNN to get the value of each hidden layer, and then sets the values of all layers into the output of the whole graph. Spectral-based GNN method obtains the convolution output of graph neural network through Fourier transform and inverse Fourier transform.</p> 
<h2>1 What is GNN？</h2> 
<p>简单来说GNN就是Graph + Nerual Networks，而这里的Graph的粗略定义就是有节点有边的图形，并不是图片而是数据结构中的图，而是一种结构化的数据。<strong>关键问题就是将graph的结构和图中每个节点和边的特征转化为一般的神经网络的输入（张量）。</strong></p> 
<p><img src="https://images2.imgbox.com/5e/8e/TgVBSBqL_o.png" alt="169ea0bf65a941c9a84007eb9eb9040f.png"></p> 
<p>GNN考虑所有的特征并将其转化为神经网络可以输入的向量，就需要用到类似于CNN的Convolution（卷积），而GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）。</p> 
<p><img src="https://images2.imgbox.com/aa/c8/DtXVQRUi_o.png" alt="08c49a8904ca4aaca16a6b14f11455fa.png"></p> 
<h2>2 Why need GNN？</h2> 
<p>当我们在做classfication的时候数据以图的形式出现，而这张图非常大，拥有很多的节点，并且节点之间互相影响，那数据集就会非常大，我们需要考虑节点之间的各种联系，因此需要用到GNN。</p> 
<p><img src="https://images2.imgbox.com/35/e2/Up36MrLL_o.png" alt="ee15b9741b654c9e83f6f961531c0d0d.png"></p> 
<p>例如在一个故事中存在很多个角色，每个角色都有对应的特征，例如姓名职业等，要从这些角色中找到一个杀人凶手，寻找的这个过程可以看成是一个classfication的问题，训练一个分类器，将一个角色（即该角色的各个特征）放入训练出来的classifier，判断该角色是否是杀人凶手。</p> 
<p><img src="https://images2.imgbox.com/e0/18/T4I6Zw61_o.png" alt="b806c40685d54c19822ba34274f513a5.png"></p> 
<p>但是问题是角色之间存在一张庞大的关系网，两两角色之间都存在一定的关系，而这些关系在做classfication的时候可以得到额外的信息，帮助我们做更好的model。因此需要考虑全部的关系，这就必须要用到graph neural network。</p> 
<p> </p> 
<h2>3 Spatial-based GNN</h2> 
<p> Spatial-based GNN需要做空间域的卷积，也就是在空间上的卷积，需要做两步，第一步是aggregate，aggregate类似于CNN中的convolution也就是卷积，CNN 中的卷积核在计算某一个像素点的 feature 的时候，可以看成把这个像素点周围的像素点的特征按照一定的权重加权求和，Spatial-GNN 想要把这种卷积操作直接推广到 Graph 上，即用邻节点的特征更新下一隐藏层的状态，第二步是readout，把所有节点的特征集合起来代表整个graph。</p> 
<p><img src="https://images2.imgbox.com/9a/3d/H6D35Qx1_o.png" alt="733601a4f2024b9bac505f712ed6745c.png"></p> 
<p> GNN在空间上的卷积和readout有很多种方法</p> 
<h3>3.1 模型一：NN4G（Neural Network for Graph）</h3> 
<p>NN4G是在<strong>上一层</strong>的数据基础上更新下一层隐藏层的特征，我们可以认为它的计算方法 COMBINE 的就是上层自己的特征经过一个线性变换。</p> 
<p>每个隐藏层都是一个图，有若干个节点，每个节点都有一个对应的权值，权值与上一层相联系，某一节点的权值=（上一层该节点的所有相邻节点的权值之和）✖一个待学习的参数+该点本身的值与一个参数矩阵的乘积（<img src="https://images2.imgbox.com/6b/28/NRGA5Fsy_o.png" alt="eq?x_%7B3%7D">是这个节点本来值）。</p> 
<p> </p> 
<p><img src="https://images2.imgbox.com/3a/b5/SKMHSheq_o.png" alt="c289cf6ef81741bdb9100ab0081ee084.png"></p> 
<p>Readout的计算方法：对每一个隐藏层计算均值，然后分别乘以可训练矩阵后加起来。</p> 
<p><img src="https://images2.imgbox.com/85/a9/OSiyPFuy_o.png" alt="046f9abc622045ba8c0014c5a234ded0.png"></p> 
<p>通过卷积的过程可以将各种特征作为输入放入全连接网络中，但是全连接网络中的神经元是固定的，因此对于每个输入的图来说，通过卷积之后的输入网络的向量维度都应该是一样。对于每个图NN4G都是使用固定数量的隐藏层对应固定的神经元，然后将每层的均值输入全连接神经网络。</p> 
<blockquote> 
 <p>AGGREGATE：求和之后做一个 Transform<br> COMBINE：求和之后再加上自身做一个 Transform 的结果。<br> READOUT：先通过平均操作求除每一层的图的表示方式，然后将所有层的图表示加权求和得到最终的图的表示。</p> 
</blockquote> 
<h3>3.2 模型二：DCNN（Diffusion-Convolution Neural Network）</h3> 
<p>DCNN的每一层都是以<strong>原始的</strong>数据进行更新，第K个隐藏层的某一点的值=原图中与这个点距离为K的点的值取平均值✖待学习的参数。（mean(d(3,.)=1)代表距离节点<img src="https://images2.imgbox.com/7b/0b/L7qBWrAO_o.png" alt="eq?v_%7B3%7D"> 为1，mean(d(3,.)=2)代表距离节点<img src="https://images2.imgbox.com/52/a1/MRasG4Mw_o.png" alt="eq?v_%7B3%7D"> 为2的所有节点特征的均值）</p> 
<p><img src="https://images2.imgbox.com/a2/18/gd3dnz5y_o.png" alt="ddb654a4602b4c38ba03141636fe7513.png"></p> 
<p>通过上面的方法求得每一层网络中所有节点，将这些向量组成一个矩阵<img src="https://images2.imgbox.com/46/43/9TZahbVz_o.png" alt="eq?H%5E%7Bi%7D">以后，<img src="https://images2.imgbox.com/2a/4b/heaurW1F_o.png" alt="eq?H%5E%7Bi%7D">代表第 i层的矩阵，假设有 n 个节点，特征维度为 d ，那么这个矩阵就是一个 <img src="https://images2.imgbox.com/43/69/T4n1g6XK_o.png" alt="eq?n%5Ctimes%20d"> 的矩阵，然后i层，就有一个<img src="https://images2.imgbox.com/6f/7e/LjEj8e5W_o.png" alt="eq?i%5Ctimes%20n%5Ctimes%20d"> 的一个张量。</p> 
<p>把每个<img src="https://images2.imgbox.com/fe/be/nrrbvug9_o.png" alt="eq?H%5E%7Bi%7D">中对应的节点<img src="https://images2.imgbox.com/61/6d/W06aUF1f_o.png" alt="eq?h_%7Bj%7D%5E%7Bi%7D">都串起来，也就是将<img src="https://images2.imgbox.com/71/4a/tBcEZznA_o.png" alt="eq?i%5Ctimes%20n%5Ctimes%20d">张量中的取出长度为<img src="https://images2.imgbox.com/86/cf/hFwBYAdf_o.png" alt="eq?i">的一行，也就是某一节点的特征，然后 <img src="https://images2.imgbox.com/9c/ac/pTp9WOox_o.png" alt="eq?i%5Ctimes%20n%5Ctimes%20d">张量就成了一个 <img src="https://images2.imgbox.com/3f/49/uNSFQZow_o.png" alt="eq?i%5Ctimes%20d">的矩阵，然后做一个 Transform （乘以一个参数矩阵<img src="https://images2.imgbox.com/b2/7f/UkRVVfas_o.png" alt="eq?w">），最后得到这个节点的特征向量<img src="https://images2.imgbox.com/66/c8/QOVELdy3_o.png" alt="eq?y%5E%7Bi%7D">。</p> 
<p><img src="https://images2.imgbox.com/0a/6d/mGt5GrMi_o.png" alt="d9b2fe2d2b594c4eb630eb1cde42b0d7.png"></p> 
<p>最后像NN4G一样将结果放入一个全连接网络，最后得到一个数值。</p> 
<h3>3.3 模型三：DGC（Diffusion Graph Convolution）</h3> 
<p>与DCNN不同的是将所有层的结果进行相加，即<img src="https://images2.imgbox.com/e8/ba/6TWq3wRa_o.png" alt="eq?i">个<img src="https://images2.imgbox.com/fe/bb/4I8Pc9Aj_o.png" alt="eq?n%5Ctimes%20d">的矩阵进行相加，与DCNN的区别是一个结果是得到一张图一个结果是得到一个数值。</p> 
<p><img src="https://images2.imgbox.com/b9/ae/cFFOmfMJ_o.png" alt="fb6ba13b850b485d8293717a771210d3.png"></p> 
<h3>3.4 模型四：MoNET（Mixture Model Networks）</h3> 
<p>之前只是简单的相加<strong>，并没有考虑到一个节点的邻居跟邻居之间的区别</strong>（有的邻居可能更重要一点，每个邻居对该点的影响程度不一样）。</p> 
<p><img src="https://images2.imgbox.com/ae/8b/GRmWaiTG_o.png" alt="77cc67a5f1ca4c548bec5bff2496eaf5.png"></p> 
<h3>3.5 模型五：GAT（Graph Attention Networks）</h3> 
<p>在基础的图神经网络上加上了注意力机制，<strong>不止是简单的weighted sum, 不是像之前那样定的weight ，而且要让他自己去学习每个节点的注意力权重。</strong>对邻居做Attention，就是不同的邻居给出不同的weight。</p> 
<p><img src="https://images2.imgbox.com/92/66/JzOzxI9y_o.png" alt="49bf64ddcdda448b81efe053fd08e59a.png"></p> 
<p><img src="https://images2.imgbox.com/e4/98/zMfMqFUp_o.png" alt="9f3a4e8ba931432b9f955d2cc96f93e6.png"></p> 
<h2>4 Spectral-based GNN</h2> 
<p>CNN在卷积的时候会确定一个卷积核，这就是一个特定大小的过滤器，每次只需要考虑kernel范围的信息。但是GNN不行，因为每个节点的邻居都不一样，无法想CNN一样用一个九宫格定义图中某一节点的邻居节点。所以要把图在空间的结构进行思想转换，<strong>将输入的图进行傅里叶转换，采用谱域实现类似的过滤器来做卷积，在给定的卷积核再做傅立叶变化，对两次傅立叶变化的结果相乘，再将结果做反的傅立叶变化得到下一层的图。</strong></p> 
<p><img src="https://images2.imgbox.com/c0/94/Is4ujC0a_o.png" alt="d752aa2ca50649c3a502fe82995b7707.png"></p> 
<p>根据卷积定理，<strong>两信号在空域（或时域）卷积的傅里叶变换等于这俩个信号在频域中的傅里叶变换的乘积</strong></p> 
<p><img src="https://images2.imgbox.com/ba/f2/2bCpneTm_o.png" alt="ccd34d06ff434f5cae569c6ca8569b33.png"></p> 
<p>卷积操作就可以这样定义：首先将空域上的信号<img class="mathcode" src="https://images2.imgbox.com/07/fe/P0mFubxQ_o.png" alt="eq?f_%7B1%7D%28t%29">转换到频域信号 <img class="mathcode" src="https://images2.imgbox.com/30/b2/PUMRfBHW_o.png" alt="eq?F_%7B1%28w%29%7D">，<img class="mathcode" src="https://images2.imgbox.com/ae/3b/ua7nrMW7_o.png" alt="eq?f_%7B2%7D%28t%29">转换到频域<img class="mathcode" src="https://images2.imgbox.com/21/98/aRx7Fso8_o.png" alt="eq?F_%7B2%28w%29%7D">，然后将频域信号相乘，再将相乘后的结果通过傅里叶反变换转回空域，这个就是<strong>谱域图卷积的实现思路（将空域转换到频域上处理，处理完再返回</strong>）。</p> 
<p>那如何进行傅里叶变换呢？需要用到信号系统相关知识。</p> 
<h3>4.1 图信号的傅里叶变换</h3> 
<p>任何一个周期函数都能等价为一系列的正（余）弦函数的和，这就是傅里叶级数。将一个周期函数经过傅里叶变换，也就是将一个时域上的函数表达，转换为其频域和相位的表示。通过对图片的傅里叶变换，可以根据变化后数据的频率特征，提取图片中的特征，如低频率的轮廓特征，高频率的细节特征。</p> 
<p><img src="https://images2.imgbox.com/32/e3/ngRMGMRd_o.png" alt="31500f6474234bcfb23d8bb81f05dc18.png"></p> 
<blockquote> 
 <p><strong>定义</strong></p> 
 <p>D为度矩阵，它对角线上的值是从 i 节点出发的所有边的权重之和（对角矩阵）。</p> 
 <p>拉普拉斯矩阵（L）是度矩阵（D）减去邻接矩阵（A），即L = D - A。拉普拉斯矩阵是对称半正定矩阵，因此该矩阵的特征值一定非负，一定有n个线性无关的特征向量，它们是n维空间中的一组标准正交基，组成正交矩阵。</p> 
 <p>将拉普拉斯矩阵（L）进行特征分解即谱分解，是将矩阵分解为其特征值和特征向量表示的矩阵之积的方法。<img src="https://images2.imgbox.com/a6/0d/G2ap9aUJ_o.png" alt="eq?L%3DU%5CLambda%20U%5E%7BT%7D">，其中<img src="https://images2.imgbox.com/73/61/6pYX5tvK_o.png" alt="eq?%5CLambda">为特征值矩阵，<img src="https://images2.imgbox.com/0d/e4/lxidhzKA_o.png" alt="eq?U">为特征向量</p> 
</blockquote> 
<p>在如下的图中，定义一个图上的信号<img src="https://images2.imgbox.com/76/04/HQkNC7PI_o.png" alt="eq?f%28i%29">，我们把<img src="https://images2.imgbox.com/b3/59/NxOxErJY_o.png" alt="eq?f%28i%29">看做是一个信号的属性大小，，<strong>它可以是一个向量也可以是一个标量</strong>，假设有4个节点，每一个节点上有一个信号值，（此文中假定f(0)、f(1)等4个信号都是标量）</p> 
<p><img src="https://images2.imgbox.com/3f/b5/lmB2CTV5_o.png" alt="745a789cf75f4972a56cb3f62a705ee4.png"></p> 
<h3>4.2 拉普拉斯变换</h3> 
<p>对该图做傅里叶变换，计算该图的拉普拉斯矩阵，以及对拉普拉斯矩阵进行谱分解得到特征值和特征向量。</p> 
<p><img src="https://images2.imgbox.com/e0/0f/vG4wc1ao_o.png" alt="0054f8f88515414ebbf650778bdeb07c.png"></p> 
<h3>4.3 频率</h3> 
<p>将图做傅里叶变化后，将矩阵L进行特征分解，上图中每个特征值<img src="https://images2.imgbox.com/1b/42/4koTOn20_o.png" alt="eq?%5Clambda%20_%7Bi%7D">对应的特征向量<img src="https://images2.imgbox.com/05/fb/228qkFnS_o.png" alt="eq?U">都对应其相应点在该特征值频率下的强度大小，可根据上图计算的特征值<img src="https://images2.imgbox.com/bd/b6/hmsv0e1J_o.png" alt="eq?%5Clambda%20_%7Bi%7D">和特征向量<img src="https://images2.imgbox.com/48/7a/O79jb80a_o.png" alt="eq?u_%7Bi%7D">将原图在频率上表达。</p> 
<p><img src="https://images2.imgbox.com/30/40/wZZxJyxL_o.png" alt="dfa0ac07a54e4baf865fd44a1994a73a.png"></p> 
<p>当频率很低的时候每个都一样的强度，当频率越来越高的时候，每一个信号的强度变化越来越大。<strong>因此频率越大，相邻两点之间的信号变化量就越大，</strong>通过这个更好理解frequency的概念。</p> 
<p><img src="https://images2.imgbox.com/cd/3b/8aX62lOY_o.png" alt="eb486a39e3694c3d83d259e5fce5bfa4.png"></p> 
<h3>4.4 能量差</h3> 
<p>将信号乘以一个拉普拉斯矩阵<img src="https://images2.imgbox.com/78/f6/tMWv6HEH_o.png" alt="eq?L">，即对其做拉普拉斯变化。下面计算表明，对信号做拉普拉斯变换得到的结果，可以表示某节点与其所有邻域节点的能量差之和。</p> 
<p><img src="https://images2.imgbox.com/0d/13/yfQTIwFZ_o.png" alt="a6a4966720264bb28adcd67e4e5052bd.png"></p> 
<p>如果要看能量差的话需要看平方，平方方式如下</p> 
<p><img src="https://images2.imgbox.com/8a/02/pgw4rclo_o.png" alt="90ba3d19605f4a249adbf48be5c3508f.png"></p> 
<p>通过等式可以发现当信号越平滑即频率低的时候，相邻两个信号能量差越小，当频率越大，两个相邻信号能量差越大。因此<img class="mathcode" src="https://images2.imgbox.com/28/b3/zQQyWX6M_o.png" alt="eq?f%5E%7Bt%7DLf">代表节点之间的能量概念，<strong>可以当作频率来使用</strong>，为什么这么说呢？<img src="https://images2.imgbox.com/0f/e9/scmG1TxL_o.png" alt="9ea6207b6a8a49b89198e9ab115d73d6.png"></p> 
<p>最后<img class="mathcode" src="https://images2.imgbox.com/d6/a9/aQSeXhIE_o.png" alt="eq?f%5E%7Bt%7DLf">可以得到<img class="mathcode" src="https://images2.imgbox.com/f0/78/hfo3gdUc_o.png" alt="eq?%5Clambda">，也就是频率值。所以<strong>特征值<img class="mathcode" src="https://images2.imgbox.com/ea/34/UIL3zWX3_o.png" alt="eq?%5Clambda">代表的是对应的特征向量的频率大小，也可以代表两两节点之间的信号的能量差。</strong></p> 
<h3><strong>4.5 分析与合成</strong></h3> 
<p>假设给出一个时域的信号，想要转换出它在谱域上面不同频率大小对应的组成部分大小是多少，那么做这件事情的时候就是做傅里叶变换。怎么在graph上也用同样的方式，把一个graph上的信号转换到它的频域，方法如下：</p> 
<p><img src="https://images2.imgbox.com/65/fd/atyf4boC_o.png" alt="2ac6bb6222f240338b0ba65864f452b3.png"></p> 
<p> <strong>频域到时域的转化就是将各个频域的频率乘以各自在频域的响应值，然后加和。</strong></p> 
<h3><strong>4.6 Filter</strong></h3> 
<p>前面知识的学习就是为了找出一个可以在graph上做filter的方式，在graph上做filter首先要定义出来在graph上怎么做傅里叶变换和逆傅里叶变换，才能通过这两种方法将它变换到谱域，然后再谱域上之间相乘，这个过程就是做filter，做完filter之后再将它逆变换回到vertex domain。</p> 
<p><img class="mathcode" src="https://images2.imgbox.com/30/0a/NOzD8fv3_o.png" alt="eq?X%5E%7B%27%7D%3DXH"></p> 
<p><img src="https://images2.imgbox.com/fc/14/D16ArkWr_o.png" alt="d8f90a0d3fbc4e21844c2df5fc0f11ec.png"></p> 
<p>推广到Spectral Graph Theory做filter也是一样的东西，<img class="mathcode" src="https://images2.imgbox.com/70/b8/rNbcEZ3l_o.png" alt="eq?%5Chat%7Bx%7D">就是信号x通过图理论变换得到的信号，然后将它乘以某一个filter的频率反应就可以得到经过filter的信号<img class="mathcode" src="https://images2.imgbox.com/e8/94/oOShvJXL_o.png" alt="eq?%5Chat%7By%7D">。</p> 
<p><img src="https://images2.imgbox.com/6c/8c/VCKYU2RB_o.png" alt="c4ea5aee32db457fb31036b2a9f75794.png"></p> 
<h3><strong>4.7 最终形态</strong></h3> 
<p>经过傅里叶变换、拉普拉斯变换以及逆傅里叶变换，<strong>最终就是要学一个拉普拉斯函数<img class="mathcode" src="https://images2.imgbox.com/c5/2b/oI2GVCwl_o.png" alt="eq?g_%7B%5Ctheta%20%7D%28%5CLambda%20%29"></strong></p> 
<p><img src="https://images2.imgbox.com/b6/63/TdaTs1ir_o.png" alt="a11a40b8e9064659b1b7badd33fac1a0.png"></p> 
<p><img src="https://images2.imgbox.com/d3/92/Aulo9Cpf_o.png" alt="ab7396b81cdc4076a39b5e6312597d30.png"></p> 
<p>总结：<strong>这个模型要做的就是当给出一个信号向量x，希望模型可以学习一个Filter叫做<img src="https://images2.imgbox.com/a2/3a/GkBDABjs_o.png" alt="eq?g_%7B%5Ctheta%20%7D%28%5CLambda%20%29">，这个<img src="https://images2.imgbox.com/09/d3/ECLZVwt7_o.png" alt="eq?g_%7B%5Ctheta%20%7D%28%5CLambda%20%29">经过Filter之后可以得到一个信号y，也就是做完卷积之后得到y。</strong>将U放进去之后，通过线性代数可以得到一个拉普拉斯函数与x相乘可以得到一个经过Filter的信号向量y。</p> 
<h3>4.7 方法的弊端 </h3> 
<p>一是Filter学习的复杂程度随着输入图的规格变化而变化，如果输入图的大小不一样，那么Filter的参数量会有很明显的差距，每输入一次就要学习一次。</p> 
<p>二是机器可能会学习到一些我们不想让它学到的信号。因为此方法机器学的<strong><img class="mathcode" src="https://images2.imgbox.com/e7/b0/Yg4F7ChA_o.png" alt="eq?g_%7B%5Ctheta%20%7D%28%5CLambda%20%29"></strong>可以是任何函数，有些函数会计算不相邻的节点的信号，导致整个Graph的信号互相影响，这就失去了Filter的意义。</p> 
<h2>5 GNN模型代码分析</h2> 
<pre><code class="language-python">import numpy as np

# 这个图是一个有向无环图(DAG)
# -1 代表什么也不连
# 图用二维列表，第一行代表节点编号，第二行为对应节点的指向节点
graph = [
    [0,0,1,2,3],
    [1,2,3,3,4]
]

# 定义5个节点的初始特征值
embeddings = [
    [1,2,3],
    [2,6,5],
    [2,3,7],
    [7,8,6],
    [1,0,0]
]

# 定义聚合的权重w全为1
w = [1,1,1,1,1]

# 下面开始图神经网络的聚合过程（训练过程）
# 在这里每个节点只按照方向聚合一层
for i in range(len(graph[0])):  # 每个节点
    # 先寻找指向节点i的节点们
    temp_roots = []
    for j, eve in enumerate(graph[1]):
        if eve == i:
            temp_roots.append(graph[0][j])
    temp_roots.append(i)
    # 此时temp_roots存储了节点i的根节点以及节点i自己的编号
    around = [
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]
    ]
    # 将temp_roots中的几点对应的around替换成当前的embedding
    for every_node_id in temp_roots:
        around[every_node_id] = embeddings[every_node_id]
    # 开始更新节点i的特征：自己之前的特征+周围节点特征的平均
    embeddings[i] = np.matmul(np.array(w),np.array(around))

# 输出更新一层后的embeddings
print(embeddings)

</code></pre> 
<p><img src="https://images2.imgbox.com/6d/a2/G2X8MVbY_o.png" alt="f274f339befb4a04aaf6219dc006d50f.png"></p> 
<h2> 总结</h2> 
<p>图神经网络（GNN）是一种处理图结构数据的深度学习方法。与CNN、RNN等传统神经网络处理的数据结构不同，图神经网络专门处理不规则的图结构数据，需要考虑节点之间的关系，因此需要一种新的方式来表示节点和边。在时域上图神经网络是将每个节点的特征与其周围节点的特征进行聚合，形成新的节点表示。在频域上图神经网路就是把数据先transform到频域上，用filter处理，然后再转回到空域的过程。</p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/29c7b2cde806f1312a966f70d5d6d978/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Stm32 旋转编码器简介</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9fcbf99ce0d265e329ea424d15bd97e9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Stm32定时器</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>