<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于深度学习的Image Inpainting (图像修复)论文推荐(持续更新) - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于深度学习的Image Inpainting (图像修复)论文推荐(持续更新)" />
<meta property="og:description" content="传统的图形学和视觉的研究方法，主要还是基于数学和物理的方法。然而随着近几年深度学习在视觉领域取得的卓越的效果，视觉领域研究的前沿已经基本被深度学习占领。在这样的形势之下，越来越多的图形学研究者也开始将目光投向深度学习。在图形学和视觉交叉的领域，一系列问题的研究正在围绕深度学习火热展开，特别是在图像编辑(image editing)和图像生成(image generation)方面，已经初见成效。今天我们讨论的问题，图像补全(image inpainting)，正是介于图像编辑和图像生成之间的一个问题。
图像补全最初是一个传统图形学的问题。问题本身很直观：在一幅图像上挖一个洞，如何利用其它的信息将这个洞补全，并且让人眼无法辨别出补全的部分。这个问题对我们人类似乎很容易，比如下面这个洞，大家很容易脑补出洞里应该有窗户和门，背景是墙，如果还有一些绘画天赋的话，大概就能想象着把它补出来。但是这个任务对于计算机却显得格外困难，首先这个问题没有唯一确定的解，其次如何利用其它的信息？如何判断补全结果是否足够真实？
以深度学习为代表的机器学习，正在逐渐席卷整个图形学研究领域。研究者们逐渐发现，当传统的基于物理的模型发展遇到瓶颈的时候，机器学习的方法也许能够帮助我们解释这些复杂的数理模型。毕竟只有理解了图像的深层结构，才能更好地指导图像的生成和处理。
文章推荐
1. CVPR 2016的Context-Encoders（CNN&#43;GAN， 鼻祖级的 NN修复方法） 链接： Feature Learning by Inpainting; Github代码:
pathak22/context-encoder​github.com
2. CVPR 2017的High Resolution Inpainting(Context-Encoders&#43;CNNMRF) 链接： High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis; Github代码:
leehomyc/Faster-High-Res-Neural-Inpainting​github.com
3. ICCV 2017的on demanding learning(感觉也是Context-Encoders的衍生版...) 链接：
On-Demand Learning for Deep Image Restoration， Github代码:
rhgao/on-demand-learning​github.com
4. SIGGRAPH 2017 (ACM ToG)的Globally and Locally Consistent Image Completion (CE中加入Global&#43;Local两个判别器的改进)， Github代码:
1)https://github.com/satoshiiizuka/siggraph2017_inpainting​github.com
2)https://github.com/shinseung428/GlobalLocalImageCompletion_TF
其中第二个实现稍微不同于原论文。但是展示效果非常棒。
5. ICLR 2018的New AI Imaging Technique Reconstructs Photos with Realistic Results Image Inpainting for Irregular Holes UsingPartial Convolutions 号称秒杀PS的AI图像修复神器，来自于Nvidia 研究团队。引入了局部卷积，能够修复任意非中心、不规则区域），代码还没有放出来" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/f3a36dd383df478924288f0da3daf1dc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-06-25T15:47:44+08:00" />
<meta property="article:modified_time" content="2018-06-25T15:47:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于深度学习的Image Inpainting (图像修复)论文推荐(持续更新)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p> </p> 
<p>传统的图形学和视觉的研究方法，主要还是基于数学和物理的方法。然而随着近几年深度学习在视觉领域取得的卓越的效果，视觉领域研究的前沿已经基本被深度学习占领。在这样的形势之下，越来越多的图形学研究者也开始将目光投向深度学习。在图形学和视觉交叉的领域，一系列问题的研究正在围绕深度学习火热展开，特别是在图像编辑(image editing)和图像生成(image generation)方面，已经初见成效。今天我们讨论的问题，图像补全(image inpainting)，正是介于图像编辑和图像生成之间的一个问题。</p> 
<p>图像补全最初是一个传统图形学的问题。问题本身很直观：在一幅图像上挖一个洞，如何利用其它的信息将这个洞补全，并且让人眼无法辨别出补全的部分。这个问题对我们人类似乎很容易，比如下面这个洞，大家很容易脑补出洞里应该有窗户和门，背景是墙，如果还有一些绘画天赋的话，大概就能想象着把它补出来。但是这个任务对于计算机却显得格外困难，首先这个问题没有唯一确定的解，其次如何利用其它的信息？如何判断补全结果是否足够真实？</p> 
<p> </p> 
<p><span style="color:#1a1a1a;">以深度学习为代表的机器学习，正在逐渐席卷整个图形学研究领域。研究者们逐渐发现，当传统的基于物理的模型发展遇到瓶颈的时候，机器学习的方法也许能够帮助我们解释这些复杂的数理模型。毕竟只有理解了图像的深层结构，才能更好地指导图像的生成和处理。</span></p> 
<p> </p> 
<p> </p> 
<p><strong>文章推荐</strong></p> 
<p> </p> 
<hr> 
<p>1. <strong>CVPR 2016</strong>的<strong>Context-Encoders</strong>（CNN+GAN， <strong><em>鼻祖级的 </em></strong>NN修复方法） </p> 
<p>链接： <strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1604.07379" rel="nofollow">Feature Learning by Inpainting</a></strong>; </p> 
<p>Github代码:</p> 
<p><a class="LinkCard LinkCard--hasImage" href="https://link.zhihu.com/?target=https%3A//github.com/pathak22/context-encoder" rel="nofollow">pathak22/context-encoder​github.com<img alt="图标" class="LinkCard-image LinkCard-image--square" src="https://images2.imgbox.com/6a/eb/JN9Vru21_o.jpg"></a></p> 
<p>2. <strong>CVPR 2017</strong>的<strong>High Resolution Inpainting</strong>(Context-Encoders+CNNMRF) </p> 
<p> 链接： <strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.09969" rel="nofollow">High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis</a></strong>; </p> 
<p>Github代码:</p> 
<p><a class="LinkCard LinkCard--hasImage" href="https://link.zhihu.com/?target=https%3A//github.com/leehomyc/Faster-High-Res-Neural-Inpainting" rel="nofollow">leehomyc/Faster-High-Res-Neural-Inpainting​github.com<img alt="图标" class="LinkCard-image LinkCard-image--square" src="https://images2.imgbox.com/47/11/KNkTDlmm_o.png"></a></p> 
<p>3. <strong>ICCV 2017</strong>的<strong>on demanding learning</strong>(感觉也是Context-Encoders的衍生版...) </p> 
<p> 链接：</p> 
<p><strong><a class="wrap external" href="https://link.zhihu.com/?target=http%3A//vision.cs.utexas.edu/projects/on_demand_learning/" rel="nofollow">On-Demand Learning for Deep Image Restoration</a></strong>， </p> 
<p>Github代码:</p> 
<p><a class="LinkCard LinkCard--noImage" href="https://link.zhihu.com/?target=https%3A//github.com/rhgao/on-demand-learning" rel="nofollow">rhgao/on-demand-learning​github.com</a></p> 
<p> </p> 
<p>4. <strong>SIGGRAPH 2017 (ACM ToG)</strong>的<strong><a class="wrap external" href="https://link.zhihu.com/?target=http%3A//hi.cs.waseda.ac.jp/~iizuka/projects/completion/en/" rel="nofollow">Globally and Locally Consistent Image Completion</a></strong> </p> 
<p>(CE中加入Global+Local两个判别器的改进)， </p> 
<p>Github代码:</p> 
<p>1)<a class="LinkCard LinkCard--noImage" href="https://link.zhihu.com/?target=https%3A//github.com/satoshiiizuka/siggraph2017_inpainting" rel="nofollow">https://github.com/satoshiiizuka/siggraph2017_inpainting​github.com</a></p> 
<p>2)<a href="https://github.com/shinseung428/GlobalLocalImageCompletion_TF">https://github.com/shinseung428/GlobalLocalImageCompletion_TF</a></p> 
<p>  其中第二个实现稍微不同于原论文。但是展示效果非常棒。</p> 
<p><img alt="" class="has" height="574" src="https://images2.imgbox.com/16/4f/6x9Kh6fi_o.png" width="586"></p> 
<p>5.<strong> ICLR 2018</strong>的<strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//news.developer.nvidia.com/new-ai-imaging-technique-reconstructs-photos-with-realistic-results/" rel="nofollow">New AI Imaging Technique Reconstructs Photos with Realistic Results</a></strong> </p> 
<p><a href="https://arxiv.org/pdf/1804.07723.pdf" rel="nofollow">Image Inpainting for Irregular Holes UsingPartial Convolutions </a> </p> 
<p>号称秒杀PS的AI图像修复神器，来自于Nvidia 研究团队。引入了局部卷积，能够修复任意非中心、不规则区域），代码还没有放出来</p> 
<p><a class="LinkCard LinkCard--noImage" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1804.07723" rel="nofollow">[1804.07723] Image Inpainting for Irregular Holes Using Partial Convolutions​arxiv.org</a></p> 
<p> </p> 
<p>6. <strong>CVPR 2018</strong>的<strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1801.07892" rel="nofollow">Generative Image Inpainting with Contextual Attention</a></strong>，</p> 
<p>一作大佬<strong><a class="wrap external" href="https://link.zhihu.com/?target=http%3A//jiahuiyu.com/" rel="nofollow">jiahui Yu</a></strong> 后续还有个工作: <strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1806.03589" rel="nofollow">Free-Form Image Inpainting with Gated Convolution</a></strong>,</p> 
<p> Github代码：</p> 
<p><a class="LinkCard LinkCard--hasImage" href="https://link.zhihu.com/?target=https%3A//github.com/JiahuiYu/generative_inpainting" rel="nofollow">JiahuiYu/generative_inpainting​github.com<img alt="图标" class="LinkCard-image LinkCard-image--square" src="https://images2.imgbox.com/98/01/tT5HfWas_o.jpg"></a></p> 
<p> </p> 
<p>7. 哈工大左旺孟老师他们也有一篇<strong><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1801.09392" rel="nofollow">Shift-Net: Image Inpainting via Deep Feature Rearrangement</a></strong> </p> 
<p>效果也不错，代码还没有放</p> 
<p> </p> 
<p><br><span style="color:#1a1a1a;">8.</span>Deep image prior </p> 
<p>项目主页：<a href="https://dmitryulyanov.github.io/deep_image_prior" rel="nofollow">https://dmitryulyanov.github.io/deep_image_prior</a></p> 
<p>适用场景： <br> 1）难以建模图像退化过程 <br> 2）难以得到训练图像进行监督训练 </p> 
<p> </p> 
<p>9.</p> 
<p><strong>ECCV 2018</strong>的<strong><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1711.08590.pdf" rel="nofollow">Contextual-based Image Inpainting</a></strong>，<strong>inpainting</strong>大佬<strong><a href="https://link.zhihu.com/?target=http%3A//www.harryyang.org/" rel="nofollow">Chao Yang</a>(NPS的一作)</strong>等人的又一力作:</p> 
<p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1711.08590" rel="nofollow">Contextual-based Image Inpainting​arxiv.org</a></p> 
<p> </p> 
<p>10.<strong>ArXiv 2019 EdgeConnect</strong>：使用对抗边缘学习进行生成图像修复</p> 
<p><strong>论文链接：<a href="https://arxiv.org/abs/1901.00212" rel="nofollow">ArXiv</a> | <a href="https://github.com/knazeri/edge-connect#citation">BibTex</a></strong></p> 
<p><strong>项目地址：<a href="https://github.com/knazeri/edge-connect#testing">https://github.com/knazeri/edge-connect#testing</a></strong></p> 
<p>EdgeConnect，一种基于边缘补全的图像修复新方法,这篇文章将图像修复的工作分成了两个部分，首先利用利用启发式的生成模型得到了缺失部分的边缘信息，随后将边缘信息作为图像缺失的先验部分和图像一起送入修复网络进行图像重建。（from 安大略技术大学）</p> 
<p>具体来说，作者们提出了一个二阶段生成对抗网络 EdgeConnect，它包括一个边缘生成器，然后是一个图像补全网络。边缘生成器在图像的缺失区域（规则和不规则）生成预测边缘，然后图像补全网络使用预测边缘作为先验填充缺失区域。研究者通过公开可用的数据集 CelebA、Places2 和 Paris StreetView 对模型进行端到端评估，并表明它在数量和质量上优于当前最先进的技术。</p> 
<h4><br> 详见<a href="https://blog.csdn.net/Gavinmiaoc/article/details/87873462">这里</a></h4> 
<p> </p> 
<p>11. <strong>ACM MM 2018</strong>的<strong><a href="https://link.zhihu.com/?target=https%3A//dl.acm.org/citation.cfm%3Fid%3D3240625" rel="nofollow">Semantic Image Inpainting with Progressive Generative Networks</a>，</strong>简称<strong>PGN，采用了由外至内的步进式修补策略</strong>，Github代码：</p> 
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/crashmoon/Progressive-Generative-Networks" rel="nofollow">crashmoon/Progressive-Generative-Networks​github.com</a></p> 
<p> </p> 
<p> </p> 
<p>12. <strong>NIPS 2018</strong>的<strong><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1810.08771" rel="nofollow">Image Inpainting via Generative Multi-column Convolutional Neural Networks</a></strong>，用了不少trick，</p> 
<p>Github代码：</p> 
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/shepnerd/inpainting_gmcnn" rel="nofollow">shepnerd/inpainting_gmcnn​github.com<img alt="图标" class="has" src="https://images2.imgbox.com/f3/09/CUeMIb1A_o.jpg"></a></p> 
<p> </p> 
<p>13. <strong>CVPR 2019</strong>的<strong><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.05945" rel="nofollow">Foreground-aware Image Inpainting</a></strong>, 思路类似于上面的工作，也是先推断生成<strong>轮廓边缘</strong>，辅助缺失区域进行修复，不知道上面的哥们看了这篇会是什么感受...速度也很重要啊...</p> 
<p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.05945" rel="nofollow">Foreground-aware Image Inpainting​arxiv.org</a></p> 
<p> </p> 
<p> </p> 
<p>14. <strong>CVPR 2019</strong>的<strong><a href="https://link.zhihu.com/?target=http%3A//www.chuanxiaz.com/publication/pluralistic/" rel="nofollow">Pluralistic Image Completion</a>，</strong></p> 
<p>论文与Github代码：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1903.04227" rel="nofollow">https://arxiv.org/abs/1903.04227​arxiv.org</a></p> 
<p> </p> 
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/lyndonzheng/Pluralistic-Inpainting" rel="nofollow">lyndonzheng/Pluralistic-Inpainting​github.com<img alt="图标" class="has" src="https://images2.imgbox.com/16/be/r2Z6G3uD_o.jpg"></a></p> 
<p> </p> 
<p>15. <strong>IJCAI 2019</strong>的<strong><a href="https://link.zhihu.com/?target=http%3A//sigma.whu.edu.cn/newspage.php%3Fq%3D2019_05_17" rel="nofollow">MUSICAL: Multi-Scale Image Contextual Attention Learning for Inpainting</a></strong>，武汉大学杜博老师组的工作（注：第一作者为我校计院的一名<strong>本科生</strong>...广大CV狗瑟瑟发抖!）。引入一个多尺度的上下文注意力模块，避免信息滥用/误用导致的纹理模糊等问题,损失函数部分联合了风格损失、感知损失、对抗损失，来保证补绘内容的一致性和清晰水平。</p> 
<p><a href="https://link.zhihu.com/?target=http%3A//sigma.whu.edu.cn/newspage.php%3Fq%3D2019_05_17" rel="nofollow">武汉大学地学智能感知与机器学习研究组​sigma.whu.edu.cn<img alt="图标" class="has" src="https://images2.imgbox.com/63/64/Co9imVlH_o.jpg"></a></p> 
<p> </p> 
<p>16. <strong>ArXiv 2019</strong>的<strong><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1905.12384" rel="nofollow">Coherent Semantic Attention for Image Inpainting</a></strong>，论文作者为<a href="https://www.zhihu.com/people/kuma-48-65/activities" rel="nofollow">@Kuma</a> , 文中提出了一个全新的<strong>Attention模块</strong>，该模块不仅有效的利用了<strong>上下文信息</strong>同时能够捕捉到<strong>生成补丁之间的相关性</strong>。同时提出了一个<strong>新的损失函数</strong>配合模块的工作，最后利用一个新的<strong>特征感知辨别器对细节效果进行加强，</strong>代码过段时间会公开<strong>。</strong></p> 
<p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1905.12384" rel="nofollow">Coherent Semantic Attention for Image Inpainting​arxiv.org</a></p> 
<p> </p> 
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/KumapowerLIU" rel="nofollow">KumapowerLIU - Overview​github.com<img alt="图标" class="has" src="https://images2.imgbox.com/9d/c4/me3CC6UI_o.png"></a></p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p><span style="color:#1a1a1a;">参考链接：</span></p> 
<p><span style="color:#1a1a1a;">1.https://www.zhihu.com/question/56801298</span></p> 
<p><span style="color:#1a1a1a;">2.https://blog.csdn.net/muyiyushan/article/details/79093806</span></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a26d8790b4db1fc870f0c5d32c047c84/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">g&#43;&#43; 编译指令备忘</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e72bace52f4bca4f25e9b07669e3df2d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ArcMap 字段计算器（Field Calculator）的使用总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>