<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI大模型专题：原生多模态大模型Gemini - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="AI大模型专题：原生多模态大模型Gemini" />
<meta property="og:description" content="今天分享的AI系列深度研究报告：《AI大模型专题：原生多模态大模型Gemini》。
（报告出品方：谷歌DeepMind）
报告共计：68页
模型架构 Gemini 模型建立在 Transformer 解码器(Vaswani 等人，2017)之上，通过架构和模型优化的改进得 到增强，以实现大规模的稳定训练，并在 Google 的张量处理单元上优化推理。它们经过训练以支 持 32k 上下文长度，采用高效的注意力机制(例如，多查询注意力(Shazeer, 2019))。我们的第一个 版本，Gemini 1.0，包括三种主要尺寸，以支持广泛的应用程序。
Gemini 模型经过训练，可以适应文本输入与各种各样的音频和视觉输入交织在一起，比如自然 图像、图表、截图、pdf 和视频，它们可以产生文本和图像输出(见图 2)。Gemini 模型的视觉编码 灵感来自我们自己在 Flamingo (Alayrac 等人，2022)、CoCa (Yu 等人，2022a)和 PaLI (Chen 等人， 2022)上的基础工作。有一个重要的区别，即模型从一开始就是多模态的，并且可以使用离散的图 像标记原生输出图像(Ramesh et al.， 2021;Yu et al.， 2022b)。
视频理解是通过将视频编码为大上下文窗口中的一系列帧来完成的。视频帧或图像可以与文本 或音频自然交错，作为模型输入的一部分。模型可以处理可变的输入分辨率，以便花费更多的计算 需要细粒度理解的任务。此外，Gemini 可以直接从通用语音模型(USM) (Zhang et al.， 2023)特征中 摄取 16kHz 的音频信号。这使得模型能够捕捉音频被天真地映射到文本输入时通常会丢失的细微 差别(例如，请参阅网站上的音频理解演示)。
训练 Gemini 系列模型需要在训练算法、数据集和基础设施方面进行创新。对于 Pro 模型，我们 的基础设施和学习算法的固有可扩展性使我们能够在几周内完成预训练，利用 Ultra 的一小部分资 源。Nano 系列模型利用蒸馏和训练算法的额外进步，为各种任务(如摘要和阅读理解)生产一流的小 型语言模型，为我们的下一代设备体验提供动力。
培训基础设施 我们使用 TPUv5e 和 TPUv4 (Jouppi 等人，2023)来训练 Gemini 模型，具体取决于它们的大小和 配置。GeminiUltra 训练中心在多个数据中心使用了大量的 TPUv4 加速器。这代表了我们之前的 旗舰型号 PaLM-2 的规模显着增加，这带来了新的基础设施挑战。加速器数量的增加会导致整个 系统中硬件的平均故障时间成比例地减少。我们最小化了计划重调度和抢占的比率，但由于宇宙 射线等外部因素，在如此大规模的所有硬件加速器中，真正的机器故障是司空见惯的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/409c0aa7996c94cb8380610a9b397e3f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-11T15:02:52+08:00" />
<meta property="article:modified_time" content="2023-12-11T15:02:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI大模型专题：原生多模态大模型Gemini</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>今天分享的<strong>AI系列</strong>深度研究报告：《<strong>AI大模型专题：原生多模态大模型Gemini</strong>》。</p> 
<p>（报告出品方：谷歌DeepMind）</p> 
<p>报告共计：68页</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="" height="890" src="https://images2.imgbox.com/71/61/CWNUCeBO_o.png" width="793"></p> 
<h2>模型架构</h2> 
<p>Gemini 模型建立在 Transformer 解码器(Vaswani 等人，2017)之上，通过架构和模型优化的改进得 到增强，以实现大规模的稳定训练，并在 Google 的张量处理单元上优化推理。它们经过训练以支 持 32k 上下文长度，采用高效的注意力机制(例如，多查询注意力(Shazeer, 2019))。我们的第一个 版本，Gemini 1.0，包括三种主要尺寸，以支持广泛的应用程序。</p> 
<p>Gemini 模型经过训练，可以适应文本输入与各种各样的音频和视觉输入交织在一起，比如自然 图像、图表、截图、pdf 和视频，它们可以产生文本和图像输出(见图 2)。Gemini 模型的视觉编码 灵感来自我们自己在 Flamingo (Alayrac 等人，2022)、CoCa (Yu 等人，2022a)和 PaLI (Chen 等人， 2022)上的基础工作。有一个重要的区别，即模型从一开始就是多模态的，并且可以使用离散的图 像标记原生输出图像(Ramesh et al.， 2021;Yu et al.， 2022b)。</p> 
<p>视频理解是通过将视频编码为大上下文窗口中的一系列帧来完成的。视频帧或图像可以与文本 或音频自然交错，作为模型输入的一部分。模型可以处理可变的输入分辨率，以便花费更多的计算 需要细粒度理解的任务。此外，Gemini 可以直接从通用语音模型(USM) (Zhang et al.， 2023)特征中 摄取 16kHz 的音频信号。这使得模型能够捕捉音频被天真地映射到文本输入时通常会丢失的细微 差别(例如，请参阅网站上的音频理解演示)。</p> 
<p>训练 Gemini 系列模型需要在训练算法、数据集和基础设施方面进行创新。对于 Pro 模型，我们 的基础设施和学习算法的固有可扩展性使我们能够在几周内完成预训练，利用 Ultra 的一小部分资 源。Nano 系列模型利用蒸馏和训练算法的额外进步，为各种任务(如摘要和阅读理解)生产一流的小 型语言模型，为我们的下一代设备体验提供动力。</p> 
<p></p> 
<p class="img-center"><img alt="" height="984" src="https://images2.imgbox.com/3d/ea/XsODMmVi_o.png" width="793"></p> 
<h2>培训基础设施</h2> 
<p>我们使用 TPUv5e 和 TPUv4 (Jouppi 等人，2023)来训练 Gemini 模型，具体取决于它们的大小和 配置。GeminiUltra 训练中心在多个数据中心使用了大量的 TPUv4 加速器。这代表了我们之前的 旗舰型号 PaLM-2 的规模显着增加，这带来了新的基础设施挑战。加速器数量的增加会导致整个 系统中硬件的平均故障时间成比例地减少。我们最小化了计划重调度和抢占的比率，但由于宇宙 射线等外部因素，在如此大规模的所有硬件加速器中，真正的机器故障是司空见惯的。</p> 
<p>TPU 加速器主要通过高速芯片间互连进行通信，但在 GeminiUltra 规模下，我们使用谷歌的集 群内和集群间网络在多个数据中心中组合 SuperPods。谷歌的网络延迟和带宽足以支持常用的同步训练范式，利用 superpods 内部的模型并行性和 superpods 之间的数据并行性。</p> 
<p>Jax (Brad bu ry et al.，2 018 )和 Path way s (Barham et al.，202 2 )的“单控制器”编程模型允许单个 Py tho n 进程协调整个训练运行，极大地简化了开发工作流。XL A 编译器中的 GSP M D 分区器(Xu et al.， 202 1 )对训练步长计算进行分区，MegaScale XLA 编译器(XL A, 2 019 )通过静态调度适当的集合， 使它们在步长时间变化很小的情况下最大限度地与计算重叠。</p> 
<p>空前规模的训练总是会出现新的有趣的系统故障模式——在这种情况下，我们需要解决的问 题之一是“无声数据损坏(SDC)”(Dixit 等人，2021;Hochschild et al.， 2021;Vishwanathan et al.， 2015)。虽然这种情况非常罕见，但 Gemini 的规模意味着我们可以预期 SDC 事件每隔一两个星期 就会影响训练。快速检测和移除故障硬件需要几种新技术，利用确定性重放来隔离不正确的计算， 并结合空闲机器和热备用上的主动 SDC 扫描仪。我们完全确定的基础设施使我们能够在 Ultra 模 型的开发过程中快速识别根本原因(包括硬件故障)，这是稳定训练的关键因素。</p> 
<p></p> 
<p class="img-center"><img alt="" height="902" src="https://images2.imgbox.com/80/4f/oeSM1Ah8_o.png" width="793"></p> 
<h2>训练数据集</h2> 
<p>Gemini 模型是在一个多模态和多语言的数据集上训练的。我们的预训练数据集使用来自网络文档、 书籍和代码的数据，包括图像、音频和视频数据。</p> 
<p>将高质量过滤器应用于所有数据集，使用启发式规则和基于模型的分类器。我们还执行安全 过滤，以删除有害内容。我们从训练语料库中过滤我们的评估集。最终的数据混合和权重是通过 较小模型上的消融来确定的。我们分阶段训练以在训练期间改变混合组成-在训练结束时增加领域 相关数据的权重。我们发现，数据质量对一个高性能的模型至关重要，并相信围绕寻找预训练的 最佳数据集分布仍然存在许多有趣的问题。</p> 
<p></p> 
<p class="img-center"><img alt="" height="769" src="https://images2.imgbox.com/4f/a9/mxzlaWyk_o.png" width="793"></p> 
<h2>评价</h2> 
<p>Gemini 模型本身是多模态的，因为它们是通过文本、图像、音频和视频联合训练的。一个开放 的问题是，这种联合训练是否可以产生一个在每个域都具有强大能力的模型——即使与仅为单个 域量身定制的模型和方法相比。我们发现情况就是这样:Gemini 在广泛的文本、图像、音频和视 频基准上树立了一个新的艺术状态。</p> 
<p><strong>学术标准：</strong>我们将 Gemini Pro 和 Ultra与一套外部法学硕士和我们之前最好的型号 PaLM 2 进行了比较，涵盖 了推理、阅读理解、STEM 和编码等一系列基于文本的学术基准。我们将这些结果报告在表 2 中。 总体而言，我们发现 Gemini Pro 的性能优于 GPT-3.5 等推理优化模型，并与市面上几种功能最强 大的模型相媲美，而 Gemini Ultra 的性能优于当前所有模型。在本节中，我们将检查其中的一些发现。</p> 
<p><strong>能力趋势：</strong>我们调查了 Gemini 模型家族的能力趋势，通过在六种不同能力的 50 多个基准测试中对它们进行 整体评估，注意到在上一节中讨论了一些最值得注意的基准测试。这些能力是:涵盖开卷/闭卷检索 和问答任务的“事实性”;“长上下文”涵盖长形式的摘要、检索和问答任务;“数学/科学”，包括 数学问题求解、定理证明、科学考试等任务;需要算术、科学和常识推理的“推理”任务;以多种语 言进行翻译、总结和推理的“多语言”任务。请参阅附录，了解每个能力所包含的详细任务列表。</p> 
<p></p> 
<p class="img-center"><img alt="" height="871" src="https://images2.imgbox.com/df/ae/toPiHF9H_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="929" src="https://images2.imgbox.com/44/e8/5peSocDB_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="859" src="https://images2.imgbox.com/09/d5/jOc5yXGP_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="941" src="https://images2.imgbox.com/6a/23/22oExAZb_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="879" src="https://images2.imgbox.com/89/d2/z5fiq14z_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="746" src="https://images2.imgbox.com/a4/17/ymM0pRBh_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="894" src="https://images2.imgbox.com/b3/64/bWxbasKp_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="886" src="https://images2.imgbox.com/0c/e2/cKGXhMmi_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="922" src="https://images2.imgbox.com/e3/92/ufSNvyWi_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="" height="882" src="https://images2.imgbox.com/16/41/AdUZmMno_o.png" width="793"></p> 
<h2>负责部署</h2> 
<p>在 Gemini 模型的开发过程中，我们遵循结构化的方法进行负责任的部署，以识别、测量和管理我们模型的可预见的下游社会影响，这与谷歌之前发布的人工智能技术一致(Kavukcuoglu 等人，2022)。</p> 
<p><strong>影响评估：</strong>我们开发模型影响评估，以识别、评估和记录与先进 Gemini 模型开发相关的关键下游社会效益和 危害。这些依据先前关于语言模型风险的学术文献(Weidinger 等人，2021 年)，以及来自全行业进 行的类似先前练习的发现(Anil 等人，2023;人为,2023;OpenAI, 2023a)，持续与内部和外部的专家 进行接触，以及非结构化地尝试发现新的模型漏洞。关注领域包括:事实性、儿童安全、有害内容、 网络安全、生物风险、代表性和包容性。这些评估与模型开发同步更新。 影响评估用于指导缓解措施和产品交付工作，并为部署决策提供信息。Gemini 影响评估跨越了 Gemini 模型的不同功能，使用谷歌的人工智能原则评估这些功能的潜在后果。</p> 
<p><strong>模型的政策：</strong>基于对已知和预期影响的这种理解，我们制定了一套“模型策略”来指导模型的开发和评估。模型 政策定义作为负责任开发的标准化标准和优先级方案，并作为发布就绪的标志。Gemin i 模范政策涵盖了许多领域，包括:儿童安全、仇恨言论、事实准确性、公平和包容，以及骚扰。</p> 
<p><strong>评估：</strong>为了根据政策领域和影响评估中确定的其他关键风险领域来评估 Gemini 模型，我们在模型开发的 生命周期中开发了一套评估。 外部评估由谷歌以外的合作伙伴进行，以确定盲点。外部团体就一系列问题对我们的模型进行压 力测试，包括白宫承诺中列出的领域，7 并通过结构化评估和非结构化红色团队的混合进行测试。这 些评估的设计是独立的，结果定期报告给谷歌 Deep Mind 团队。 除了这一套外部评估之外，专家内部团队还在 Gemini 政策和安全等领域对我们的模型进行持 续的红队。这些活动包括涉及复杂的对抗性攻击以识别新漏洞的非结构化流程。然后可以利用发 现潜在弱点来减轻风险并改进内部的评估方法。我们致力于持续的模型透明度，并计划随着时间 的推移分享来自我们的评估套件的其他结果。</p> 
<p></p> 
<p class="img-center"><img alt="" height="784" src="https://images2.imgbox.com/a5/7d/ZwT0ZYaT_o.png" width="604"></p> 
<p></p> 
<p class="img-center"><img alt="" height="671" src="https://images2.imgbox.com/d7/ae/OVTTtvbT_o.png" width="618"></p> 
<h2>讨论与结论</h2> 
<p>除了最先进的基准测试结果之外，我们最兴奋的是 Gemini 模型支持的新用例。Gcmini 模型解析复杂图像(如图表或信息图)的新功能，对图像、音频和文本的交错序列进行推理，并生成交错的文本和图像作为响应，从而打开了各种各样的新应用程序。正如整个报告和附录中的数字所示，Gcmimi 可以在教育、解决日常问题、多语言交流、信息总结、提取和创造力等领域采用新的方法。我们希望这些模型的用户能发现各种有益的新用途，而我们在自己的调查中只触及了皮毛。</p> 
<p>尽管它们的能力令人印象深刻，但我们应该注意到，法学硕士的使用也有局限性。继续需要对法学硕士产生的“幻觉”进行持续的研究和开发，以确保模型输出更加可靠和可验证。尽管法学硕士在考试中取得了令人印象深刻的成绩，但他们也很难完成需要高级推理能力的任务，比如厌果理解、逻辑推理和反事实推理。这强调了需要更具挑战性和更强大的评估来衡量他们的真实理解，因为目前最先进的法学硕士已经饱和了许多基准。</p> 
<p>Gcmmi 是我们解决智能、推进科学和造福人类的使命的又一步，我们热切地希望看到谷歌和其他公司的同事如何使用这些模型。我们在机器学习、数据、基础设施和负责任的开发方面进行了许多创新，这些都是谷歌十多年来一直在追求的领域。我们在本报告中提出的模型为我们更广泛的未来目标提供了强大的基础，该目标是开发一个大规模的、模块化的系统，该系统将在许多模态中具有广泛的泛化能力。</p> 
<p></p> 
<p class="img-center"><img alt="" height="551" src="https://images2.imgbox.com/4b/35/Uoeuf0Xb_o.png" width="644"></p> 
<p></p> 
<p class="img-center"><img alt="" height="802" src="https://images2.imgbox.com/8f/66/6Sd1nbop_o.png" width="575"></p> 
<p>报告共计：68页</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/15c6e59c649bc9bac1154917521f4876/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Swin-Transformer图像分类</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/92612a7c86d1204981013721c99425db/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Stream流操作List集合一些常用方法封装</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>