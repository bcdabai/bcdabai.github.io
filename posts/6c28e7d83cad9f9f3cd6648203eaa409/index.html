<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Linux下CLOSE-WAIT过多分析与解决 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Linux下CLOSE-WAIT过多分析与解决" />
<meta property="og:description" content="查看链接状态
netstat -ant|awk &#39;/^tcp/ {&#43;&#43;S[$NF]} END {for(a in S) print (a,S[a])}&#39; 情景描述：系统产生大量“Too many open files”
原因分析：在服务器与客户端通信过程中，因服务器发生了socket未关导致的closed_wait发生，致使监听port打开的句柄数到了1024个，且均处于close_wait的状态，最终造成配置的port被占满出现“Too many open files”，无法再进行通信。
close_wait状态出现的原因是被动关闭方未关闭socket造成，如附件图所示：
解决办法：有两种措施可行
一、解决：
原因是因为调用ServerSocket类的accept()方法和Socket输入流的read()方法时会引起线程阻塞，所以应该用setSoTimeout()方法设置超时（缺省的设置是0，即超时永远不会发生）；超时的判断是累计式的，一次设置后，每次调用引起的阻塞时间都从该值中扣除，直至另一次超时设置或有超时异常抛出。
比如，某种服务需要三次调用read()，超时设置为1分钟，那么如果某次服务三次read()调用的总时间超过1分钟就会有异常抛出，如果要在同一个Socket上反复进行这种服务，就要在每次服务之前设置一次超时。
二、规避：
调整系统参数，包括句柄相关参数和TCP/IP的参数；
注意：
/proc/sys/fs/file-max 是整个系统可以打开的文件数的限制，由sysctl.conf控制；
ulimit修改的是当前shell和它的子进程可以打开的文件数的限制，由limits.conf控制；
lsof是列出系统所占用的资源,但是这些资源不一定会占用打开文件号的；比如：共享内存,信号量,消息队列,内存映射等,虽然占用了这些资源,但不占用打开文件号；
因此，需要调整的是当前用户的子进程打开的文件数的限制，即limits.conf文件的配置；
如果cat /proc/sys/fs/file-max值为65536或甚至更大，不需要修改该值；
若ulimit -a ；其open files参数的值小于4096（默认是1024), 则采用如下方法修改open files参数值为8192；方法如下：
1.使用root登陆，修改文件/etc/security/limits.conf
vi /etc/security/limits.conf 添加
xxx - nofile 8192
xxx 是一个用户，如果是想所有用户生效的话换成 * ，设置的数值与硬件配置有关，别设置太大了。
#&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt; * soft nofile 8192 * hard nofile 8192 #所有的用户每个进程可以使用8192个文件描述符。
2.使这些限制生效
确定文件/etc/pam.d/login 和/etc/pam.d/sshd包含如下行：
session required pam_limits." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6c28e7d83cad9f9f3cd6648203eaa409/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-29T15:39:13+08:00" />
<meta property="article:modified_time" content="2020-05-29T15:39:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Linux下CLOSE-WAIT过多分析与解决</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>查看链接状态</p> 
<pre><code class="prism language-bash"><span class="token function">netstat</span> -ant<span class="token operator">|</span><span class="token function">awk</span> <span class="token string">'/^tcp/ {++S[<span class="token variable">$NF</span>]} END {for(a in S) print (a,S[a])}'</span>
</code></pre> 
<p>情景描述：系统产生大量“Too many open files”<br> 原因分析：在服务器与客户端通信过程中，因服务器发生了socket未关导致的closed_wait发生，致使监听port打开的句柄数到了1024个，且均处于close_wait的状态，最终造成配置的port被占满出现“Too many open files”，无法再进行通信。<br> close_wait状态出现的原因是被动关闭方未关闭socket造成，如附件图所示：</p> 
<p>解决办法：有两种措施可行<br> 一、解决：<br> 原因是因为调用ServerSocket类的accept()方法和Socket输入流的read()方法时会引起线程阻塞，所以应该用setSoTimeout()方法设置超时（缺省的设置是0，即超时永远不会发生）；超时的判断是累计式的，一次设置后，每次调用引起的阻塞时间都从该值中扣除，直至另一次超时设置或有超时异常抛出。<br> 比如，某种服务需要三次调用read()，超时设置为1分钟，那么如果某次服务三次read()调用的总时间超过1分钟就会有异常抛出，如果要在同一个Socket上反复进行这种服务，就要在每次服务之前设置一次超时。<br> 二、规避：<br> 调整系统参数，包括句柄相关参数和TCP/IP的参数；</p> 
<p>注意：<br> /proc/sys/fs/file-max 是整个系统可以打开的文件数的限制，由sysctl.conf控制；<br> ulimit修改的是当前shell和它的子进程可以打开的文件数的限制，由limits.conf控制；<br> lsof是列出系统所占用的资源,但是这些资源不一定会占用打开文件号的；比如：共享内存,信号量,消息队列,内存映射等,虽然占用了这些资源,但不占用打开文件号；<br> 因此，需要调整的是当前用户的子进程打开的文件数的限制，即limits.conf文件的配置；<br> 如果cat /proc/sys/fs/file-max值为65536或甚至更大，不需要修改该值；<br> 若ulimit -a ；其open files参数的值小于4096（默认是1024), 则采用如下方法修改open files参数值为8192；方法如下：<br> 1.使用root登陆，修改文件/etc/security/limits.conf<br> vi /etc/security/limits.conf 添加<br> xxx - nofile 8192<br> xxx 是一个用户，如果是想所有用户生效的话换成 * ，设置的数值与硬件配置有关，别设置太大了。</p> 
<pre><code class="prism language-bash"><span class="token comment">#&lt;domain&gt;      &lt;type&gt;     &lt;item&gt;         &lt;value&gt; </span>

*         soft    nofile    8192 
*         hard    nofile    8192 
</code></pre> 
<p>#所有的用户每个进程可以使用8192个文件描述符。<br> 2.使这些限制生效<br> 确定文件/etc/pam.d/login 和/etc/pam.d/sshd包含如下行：<br> session required pam_limits.so<br> 然后用户重新登陆一下即可生效。<br> 3. 在bash下可以使用ulimit -a 参看是否已经修改：</p> 
<p>一、 修改方法：（暂时生效,重新启动服务器后,会还原成默认值）</p> 
<pre><code class="prism language-bash">sysctl -w net.ipv4.tcp_keepalive_time<span class="token operator">=</span>600   
sysctl -w net.ipv4.tcp_keepalive_probes<span class="token operator">=</span>2 
sysctl -w net.ipv4.tcp_keepalive_intvl<span class="token operator">=</span>2 
</code></pre> 
<p>注意：Linux的内核参数调整的是否合理要注意观察，看业务高峰时候效果如何。</p> 
<p>二、 若做如上修改后，可起作用；则做如下修改以便永久生效。<br> vi /etc/sysctl.conf</p> 
<p>若配置文件中不存在如下信息，则添加：</p> 
<pre><code class="prism language-bash">net.ipv4.tcp_keepalive_time <span class="token operator">=</span> 1800 
net.ipv4.tcp_keepalive_probes <span class="token operator">=</span> 3 
net.ipv4.tcp_keepalive_intvl <span class="token operator">=</span> 15 
</code></pre> 
<p>编辑完 /etc/sysctl.conf,要重启network 才会生效</p> 
<pre><code class="prism language-bash">/etc/rc.d/init.d/network restart 
</code></pre> 
<p>然后，执行sysctl命令使修改生效，基本上就算完成了。</p> 
<pre><code class="prism language-bash"> /sbin/sysctl -p
</code></pre> 
<hr> 
<p>修改原因：</p> 
<p>当客户端因为某种原因先于服务端发出了FIN信号，就会导致服务端被动关闭，若服务端不主动关闭socket发FIN给Client，此时服务端Socket会处于CLOSE_WAIT状态（而不是LAST_ACK状态）。通常来说，一个CLOSE_WAIT会维持至少2个小时的时间（系统默认超时时间的是7200秒，也就是2小时）。如果服务端程序因某个原因导致系统造成一堆CLOSE_WAIT消耗资源，那么通常是等不到释放那一刻，系统就已崩溃。因此，解决这个问题的方法还可以通过修改TCP/IP的参数来缩短这个时间，于是修改tcp_keepalive_*系列参数：<br> tcp_keepalive_time：</p> 
<pre><code class="prism language-bash">/proc/sys/net/ipv4/tcp_keepalive_time 
INTEGER，默认值是7200<span class="token punctuation">(</span>2小时<span class="token punctuation">)</span> 
</code></pre> 
<p>当keepalive打开的情况下，TCP发送keepalive消息的频率。建议修改值为1800秒。</p> 
<pre><code class="prism language-bash">tcp_keepalive_probes：INTEGER 
/proc/sys/net/ipv4/tcp_keepalive_probes 
INTEGER，默认值是9 
</code></pre> 
<p>TCP发送keepalive探测以确定该连接已经断开的次数。(注意:保持连接仅在SO_KEEPALIVE套接字选项被打开是才发送.次数默认不需要修改,当然根据情形也可以适当地缩短此值.设置为5比较合适)</p> 
<pre><code class="prism language-bash">tcp_keepalive_intvl：INTEGER 
/proc/sys/net/ipv4/tcp_keepalive_intvl 
INTEGER，默认值为75 
</code></pre> 
<p>当探测没有确认时，重新发送探测的频度。探测消息发送的频率（在认定连接失效之前，发送多少个TCP的keepalive探测包）。乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，也就是没有活动的连接将在大约11分钟以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,15是个比较合适的值)</p> 
<p>【检测办法】</p> 
<ol><li> <p>系统不再出现“Too many open files”报错现象。</p> </li><li> <p>处于TIME_WAIT状态的sockets不会激长。</p> </li></ol> 
<p>在 Linux 上可用以下语句看了一下服务器的TCP状态(连接状态数量统计)：</p> 
<pre><code class="prism language-bash"><span class="token function">netstat</span> -n <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'/^tcp/ {++S[<span class="token variable">$NF</span>]} END {for(a in S) print a, S[a]}'</span> 
</code></pre> 
<p>返回结果范例如下：</p> 
<pre><code class="prism language-bash">ESTABLISHED 1423 
FIN_WAIT1 1 
FIN_WAIT2 262 
SYN_SENT 1 
TIME_WAIT 962
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b7f083a9961de2afda2c2f3b5ac2985c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Maya Python设置当前动画进度</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4f1c8f56b8909db06e58ea5250f91ccc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Maya Python调用Maya窗口选择文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>