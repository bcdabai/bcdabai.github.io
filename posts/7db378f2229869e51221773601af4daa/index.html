<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>kubeadm搭建1.20.7版本k8s - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="kubeadm搭建1.20.7版本k8s" />
<meta property="og:description" content="资源 服务器名称ip地址服务master1（2C/4G，cpu核心数要求大于2）192.168.100.10docker、kubeadm、kubelet、kubectl、flannelnode01（2C/2G）192.168.100.30docker、kubeadm、kubelet、kubectl、flannelnode02（2C/2G）192.168.100.40docker、kubeadm、kubelet、kubectl、flannelnode03（2C/2G）192.168.100.50docker、kubeadm、kubelet、kubectl、flannel 1、在所有节点上安装Docker和kubeadm
2、部署Kubernetes Master
3、部署容器网络插件
4、部署 Kubernetes Node，将节点加入Kubernetes集群中
环境准备 所有节点，关闭防火墙规则，关闭selinux，关闭swap交换 systemctl stop firewalld systemctl disable firewalld setenforce 0 iptables -F swapoff -a	#交换分区必须要关闭 #加载 ip_vs 模块 for i in $(ls /usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs|grep -o &#34;^[^.]*&#34;);do echo $i; /sbin/modinfo -F filename $i &gt;/dev/null 2&gt;&amp;1 &amp;&amp; /sbin/modprobe $i;done 修改主机名 hostnamectl set-hostname master1 hostnamectl set-hostname node01 hostnamectl set-hostname node02 hostnamectl set-hostname node03 免密打通 ssh-keygen -t rsa cd ~/.ssh/ ssh-copy-id -i id_rsa.pub root@192.168.100.30 ssh-copy-id -i id_rsa." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7db378f2229869e51221773601af4daa/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-10T14:56:56+08:00" />
<meta property="article:modified_time" content="2023-12-10T14:56:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">kubeadm搭建1.20.7版本k8s</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>资源</h2> 
<table><thead><tr><th align="left">服务器名称</th><th>ip地址</th><th>服务</th></tr></thead><tbody><tr><td align="left">master1（2C/4G，cpu核心数要求大于2）</td><td>192.168.100.10</td><td>docker、kubeadm、kubelet、kubectl、flannel</td></tr><tr><td align="left">node01（2C/2G）</td><td>192.168.100.30</td><td>docker、kubeadm、kubelet、kubectl、flannel</td></tr><tr><td align="left">node02（2C/2G）</td><td>192.168.100.40</td><td>docker、kubeadm、kubelet、kubectl、flannel</td></tr><tr><td align="left">node03（2C/2G）</td><td>192.168.100.50</td><td>docker、kubeadm、kubelet、kubectl、flannel</td></tr></tbody></table> 
<p>1、在所有节点上安装Docker和kubeadm<br> 2、部署Kubernetes Master<br> 3、部署容器网络插件<br> 4、部署 Kubernetes Node，将节点加入Kubernetes集群中</p> 
<h2><a id="_16"></a>环境准备</h2> 
<h5><a id="selinuxswap_18"></a>所有节点，关闭防火墙规则，关闭selinux，关闭swap交换</h5> 
<pre><code>systemctl stop firewalld
systemctl disable firewalld
setenforce 0
iptables -F
swapoff -a						#交换分区必须要关闭
#加载 ip_vs 模块
for i in $(ls /usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs|grep -o "^[^.]*");do echo $i; /sbin/modinfo -F filename $i &gt;/dev/null 2&gt;&amp;1 &amp;&amp; /sbin/modprobe $i;done
</code></pre> 
<h5><a id="_30"></a>修改主机名</h5> 
<pre><code>hostnamectl set-hostname master1
hostnamectl set-hostname node01
hostnamectl set-hostname node02
hostnamectl set-hostname node03
</code></pre> 
<h5><a id="_39"></a>免密打通</h5> 
<pre><code>ssh-keygen -t rsa
cd ~/.ssh/
ssh-copy-id -i id_rsa.pub root@192.168.100.30
ssh-copy-id -i id_rsa.pub root@192.168.100.40
ssh-copy-id -i id_rsa.pub root@192.168.100.50
</code></pre> 
<h5><a id="hosts_49"></a>所有节点修改hosts文件</h5> 
<pre><code>vim /etc/hosts
192.168.100.10 master1
192.168.100.30 node01
192.168.100.40 node02
192.168.100.50 node03

scp /etc/hosts node01:/etc
scp /etc/hosts node02:/etc
scp /etc/hosts node03:/etc
</code></pre> 
<h5><a id="_63"></a>调整内核参数</h5> 
<pre><code>cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF
#开启网桥模式，可将网桥的流量传递给iptables链
net.bridge.bridge-nf-call-ip6tables=1
net.bridge.bridge-nf-call-iptables=1
#关闭ipv6协议
net.ipv6.conf.all.disable_ipv6=1
net.ipv4.ip_forward=1
EOF

## 生效参数
sysctl --system  
</code></pre> 
<h2><a id="docker_81"></a>所有节点安装docker</h2> 
<pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2 
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 
yum install docker-ce docker-ce-cli containerd.io -y

mkdir /etc/docker
cat &gt; /etc/docker/daemon.json &lt;&lt;EOF
{
  "registry-mirrors": ["https://q7n9qid7.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  }
}
EOF
#使用Systemd管理的Cgroup来进行资源控制与管理，因为相对Cgroupfs而言，Systemd限制CPU、内存等资源更加简单和成熟稳定。
#日志使用json-file格式类型存储，大小为100M，保存在/var/log/containers目录下，方便ELK等日志系统收集和管理日志。
</code></pre> 
<pre><code>systemctl daemon-reload
systemctl restart docker.service
systemctl enable docker.service 
</code></pre> 
<pre><code>docker info | grep "Cgroup Driver"
#Cgroup Driver: systemd
</code></pre> 
<h2><a id="kubeadmkubeletkubectl_116"></a>所有节点安装kubeadm，kubelet和kubectl</h2> 
<h5><a id="kubernetes_118"></a>定义kubernetes源</h5> 
<pre><code>cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre> 
<pre><code>yum install -y kubelet-1.20.7 kubeadm-1.20.7 kubectl-1.20.7
</code></pre> 
<h5><a id="kubelet_136"></a>开机自启kubelet</h5> 
<pre><code>systemctl enable kubelet.service
#K8S通过kubeadm安装出来以后都是以Pod方式存在，即底层是以容器方式运行，所以kubelet必须设置开机自启
</code></pre> 
<h5><a id="_143"></a>查看初始化需要的镜像</h5> 
<pre><code>kubeadm config images list
</code></pre> 
<h2><a id="k8s_151"></a>导入k8s镜像</h2> 
<h3><a id="k8s_153"></a>方法一：无k8s镜像搭建方法</h3> 
<h4><a id="master_156"></a>master上执行</h4> 
<h5><a id="k8s1207_158"></a>下载k8s-1.20.7镜像</h5> 
<pre><code>kubeadm config images pull --kubernetes-version v1.20.7 --image-repository registry.aliyuncs.com/google_containers
</code></pre> 
<pre><code>docker images
</code></pre> 
<h5><a id="tag_168"></a>镜像重新打tag</h5> 
<pre><code>docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.20.7 k8s.gcr.io/kube-proxy:v1.20.7  
docker tag registry.aliyuncs.com/google_containers/kube-apiserver:v1.20.7 k8s.gcr.io/kube-apiserver:v1.20.7 
docker tag registry.aliyuncs.com/google_containers/kube-controller-manager:v1.20.7 k8s.gcr.io/kube-controller-manager:v1.20.7 
docker tag registry.aliyuncs.com/google_containers/kube-scheduler:v1.20.7 k8s.gcr.io/kube-scheduler:v1.20.7
docker tag registry.aliyuncs.com/google_containers/etcd:3.4.13-0 k8s.gcr.io/etcd:3.4.13-0
docker tag registry.aliyuncs.com/google_containers/coredns:1.7.0 k8s.gcr.io/coredns:1.7.0 
docker tag registry.aliyuncs.com/google_containers/pause:3.2 k8s.gcr.io/pause:3.2   
</code></pre> 
<h5><a id="k8s_180"></a>导出k8s镜像</h5> 
<pre><code>mkdir kubeadm-basic.images
cd kubeadm-basic.images

docker save k8s.gcr.io/kube-proxy:v1.20.7 -o kube-proxy.tar
docker save k8s.gcr.io/kube-apiserver:v1.20.7 -o kube-apiserver.tar
docker save k8s.gcr.io/kube-controller-manager:v1.20.7 -o kube-controller-manager.tar
docker save k8s.gcr.io/kube-scheduler:v1.20.7 -o kube-scheduler.tar
docker save k8s.gcr.io/etcd:3.4.13-0 -o etcd.tar
docker save k8s.gcr.io/coredns:1.7.0 -o coredns.tar
docker save k8s.gcr.io/pause:3.2 -o pause.tar
</code></pre> 
<h5><a id="k8s_195"></a>打包k8s镜像</h5> 
<pre><code>tar -czvf kubeadm-basic.images.tar.gz kubeadm-basic.images/*
</code></pre> 
<h5><a id="_node__node__bash_optloadimagessh_201"></a>复制镜像和脚本到 node 节点，并在 node 节点上执行脚本 bash /opt/load-images.sh</h5> 
<pre><code>scp -r kubeadm-basic.images.tar.gz root@node01:/opt
scp -r kubeadm-basic.images.tar.gz root@node02:/opt
scp -r kubeadm-basic.images.tar.gz root@node03:/opt
</code></pre> 
<h4><a id="_210"></a>所有节点上执行</h4> 
<pre><code>cd /opt
tar -zxvf kubeadm-basic.images.tar.gz
for i in $(ls /opt/kubeadm-basic.images/*.tar); do docker load -i $i; done
</code></pre> 
<h3><a id="k8s_218"></a>方法二：已有k8s镜像搭建方法</h3> 
<h5><a id="_master__kubeadmbasicimagestargz__opt__220"></a>在 master 节点上传 kubeadm-basic.images.tar.gz 压缩包至 /opt 目录</h5> 
<pre><code>cd /opt
tar zxvf kubeadm-basic.images.tar.gz

for i in $(ls /opt/kubeadm-basic.images/*.tar); do docker load -i $i; done
</code></pre> 
<h5><a id="_node__229"></a>复制镜像和脚本到 node 节点</h5> 
<pre><code>scp -r kubeadm-basic.images root@node01:/opt
scp -r kubeadm-basic.images root@node02:/opt
scp -r kubeadm-basic.images root@node03:/opt
</code></pre> 
<h5><a id="_237"></a>所有节点上执行</h5> 
<pre><code>cd /opt
for i in $(ls /opt/kubeadm-basic.images/*.tar); do docker load -i $i; done
</code></pre> 
<h2><a id="master_246"></a>master上执行</h2> 
<h3><a id="kubeadm_248"></a>初始化kubeadm</h3> 
<pre><code>kubeadm config print init-defaults &gt; /opt/kubeadm-config.yaml
</code></pre> 
<pre><code>cd /opt/
vim kubeadm-config.yaml
......
11 localAPIEndpoint:
12   advertiseAddress: 192.168.100.10		#指定master节点的IP地址
13   bindPort: 6443
......
34 kubernetesVersion: v1.20.7				#指定kubernetes版本号
35 networking:
36   dnsDomain: cluster.local
37   podSubnet: "10.244.0.0/16"				#指定pod网段，10.244.0.0/16用于匹配flannel默认网段
38   serviceSubnet: 10.96.0.0/16			#指定service网段
39 scheduler: {}
--- #末尾再添加以下内容
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs						#把默认的service调度方式改为ipvs模式
ipvs:
  strictARP: true
  scheduler: rr
</code></pre> 
<pre><code>kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log
#--upload-certs 参数可以在后续执行加入节点时自动分发证书文件，k8sV1.15版本以下替换为 --experimental-upload-certs
#tee kubeadm-init.log 用以输出日志
</code></pre> 
<pre><code>Your Kubernetes control-plane has initialized successfully!
To start using your cluster, you need to run the following as a regular user:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:
export KUBECONFIG=/etc/kubernetes/admin.conf
You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.100.10:6443 --token abcdef.0123456789abcdef \
--discovery-token-ca-cert-hash sha256:8be27369ddd5c8cad17eef27825754d921d71c58d1cc9c56cee4988fd86417ef
</code></pre> 
<h6><a id="_kubeadminit__303"></a>查看 kubeadm-init 日志</h6> 
<pre><code>less kubeadm-init.log
</code></pre> 
<h6><a id="kubernetes_309"></a>kubernetes配置文件目录</h6> 
<pre><code>ls /etc/kubernetes/
</code></pre> 
<h6><a id="ca_315"></a>存放ca等证书和密码的目录</h6> 
<pre><code>ls /etc/kubernetes/pki
</code></pre> 
<h5><a id="k8s_config_321"></a>创建k8s config</h5> 
<pre><code>mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre> 
<h2><a id="_331"></a>所有节点上执行</h2> 
<pre><code>kubeadm join 192.168.100.10:6443 --token abcdef.0123456789abcdef \
	--discovery-token-ca-cert-hash sha256:8be27369ddd5c8cad17eef27825754d921d71c58d1cc9c56cee4988fd86417ef
</code></pre> 
<h2><a id="master_339"></a>master上执行</h2> 
<h4><a id="_341"></a>自动补全</h4> 
<pre><code>echo "source &lt;(kubectl completion bash)" /etc/profile
source /etc/profile
</code></pre> 
<h2><a id="flannel_347"></a>部署网络插件flannel</h2> 
<h3><a id="_flannel__349"></a>创建 flannel 资源</h3> 
<pre><code>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
kubectl apply -f kube-flannel.yml
##注意flannel镜像名称和yaml内的是否一致
</code></pre> 
<pre><code>## 同步到所有节点
scp /opt/cni/bin/flannel node01:/opt/cni/bin
scp /opt/cni/bin/flannel node02:/opt/cni/bin
scp /opt/cni/bin/flannel node03:/opt/cni/bin
</code></pre> 
<h3><a id="master_365"></a>在master节点查看节点状态（需要等几分钟）</h3> 
<pre><code>kubectl get nodes
</code></pre> 
<pre><code>NAME      STATUS     ROLES                  AGE   VERSION
master1   Ready      control-plane,master   78m   v1.20.7
node01    Ready      &lt;none&gt;                 78m   v1.20.7
node02    NotReady   &lt;none&gt;                 78m   v1.20.7
node03    NotReady   &lt;none&gt;                 78m   v1.20.7

</code></pre> 
<pre><code>kubectl get pods -n kube-system
</code></pre> 
<pre><code>NAME                             READY   STATUS    RESTARTS   AGE
coredns-bccdc95cf-c9w6l          1/1     Running   0          71m
coredns-bccdc95cf-nql5j          1/1     Running   0          71m
etcd-master                      1/1     Running   0          71m
kube-apiserver-master            1/1     Running   0          70m
kube-controller-manager-master   1/1     Running   0          70m
kube-proxy-558p8                 1/1     Running   0          2m53s
kube-proxy-nwd7g                 1/1     Running   0          2m56s
kube-proxy-wd87d                 1/1     Running   0          2m54s
kube-proxy-qpz8t                 1/1     Running   0          71m
kube-scheduler-master            1/1     Running   0          70m
</code></pre> 
<pre><code>kubectl get pods -n kube-flannel
</code></pre> 
<pre><code>NAME                    READY   STATUS    RESTARTS   AGE
kube-flannel-ds-2k5b9   1/1     Running   0          2m53s
kube-flannel-ds-fhx2c   1/1     Running   0          2m55s
kube-flannel-ds-g6z6q   1/1     Running   0          2m50s
kube-flannel-ds-nkrrj   1/1     Running   0          2m51s
</code></pre> 
<h2><a id="_412"></a>验证</h2> 
<h5><a id="node__414"></a>node节点上 登录到镜像仓库，获取镜像</h5> 
<pre><code>docker login -u lp1078802338 -p  registry.cn-hangzhou.aliyuncs.com
</code></pre> 
<h5><a id="pod_420"></a>创建pod</h5> 
<pre><code>kubectl create deployment nginx-deployment --image=registry.cn-hangzhou.aliyuncs.com/lp-k8s-prometheus/nginx:v1 --replicas=1
</code></pre> 
<pre><code>## 最好看一下pod在哪个节点上，然后登录node 使用docker拉取，不然会很慢
kubectl get pods -o wide
NAME               READY   STATUS    RESTARTS   AGE     IP           NODE     NOMINATED NODE   READINESS GATES
nginx-deployment   1/1     Running   0          5m49s   10.244.1.2   node01   &lt;none&gt;           &lt;none&gt;

##node节点上执行
docker pull registry.cn-hangzhou.aliyuncs.com/lp-k8s-prometheus/nginx:v1

v1: Pulling from lp-k8s-prometheus/nginx
a2abf6c4d29d: Pull complete
a9edb18cadd1: Pull complete
589b7251471a: Pull complete
186b1aaa4aa6: Pull complete
b4df32aa5a72: Pull complete
a0bcbecc962e: Pull complete
</code></pre> 
<pre><code>docker images

REPOSITORY                                                  TAG        IMAGE ID       CREATED         SIZE
registry.cn-hangzhou.aliyuncs.com/lp-k8s-prometheus/nginx   v1         605c77e624dd   23 months ago   141MB
</code></pre> 
<pre><code>##master上执行
kubectl get pods -o wide

NAME                                    READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES
pod/nginx-deployment-799b5654d5-b8nqv   1/1     Running   0          27s   10.244.1.3   node01   &lt;none&gt;           &lt;none&gt;
</code></pre> 
<h5><a id="podserverNodePort_459"></a>将pod的server类型改成NodePort</h5> 
<pre><code>kubectl expose deployment nginx-deployment --port=80 --type=NodePort
</code></pre> 
<pre><code>kubectl get pod,svc -o wide

NAME                                    READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES
pod/nginx-deployment-799b5654d5-b8nqv   1/1     Running   0          27s   10.244.1.3   node01   &lt;none&gt;           &lt;none&gt;

NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR
service/kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        70m   &lt;none&gt;
service/nginx-deployment   NodePort    10.97.191.117   &lt;none&gt;        80:30619/TCP   8s    app=nginx-deployment
</code></pre> 
<h5><a id="_476"></a>打开浏览器验证</h5> 
<pre><code>http://node01:30619
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1a91e3deb07b57fa7896a027b7f702d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python报错PermissionError: [Errno 13] Permission denied: ‘xxx‘解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b1acb87851ceb686d74cc66efeb7e18b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">解决 JavaScript中 添加 if 判断，require 始终执行的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>