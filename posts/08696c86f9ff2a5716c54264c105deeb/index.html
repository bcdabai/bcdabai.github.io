<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>推荐算法－NFM - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="推荐算法－NFM" />
<meta property="og:description" content="推荐算法－NFM FM对于特征的组合仅限于二阶，缺少对特征之间深层次关系的抽取。因此，NFM提出来就是在FM的基础上引入神经网络，实现对特征的深层次抽取。NFM的模型结构图如下所示：
模型的结构如上图所示，首先输入就是离散化的特征，然后再进行embedding操作，获得每一个特征的向量表示。接着就到了Bi-interaction Pooling层，这里其实就是FM部分。FM的公式如下图所示：
去掉最外层的累加号，我们得到的是一个长度为K的向量，也就是embedding部分的长度。然后再对这个向量送入几层全连接层即可，最后输出ctr预估值。这就是NFM的整体思路。
代码实现 权重构建，就是初始化一下embedding部分的数据，以及全连接部分的权重。然后就可以实现计算图了。
权重部分如下：
def _initWeights(self): weights = dict() # embedding weights[&#39;feature_embedding&#39;] = tf.Variable(tf.random_normal(shape=[self.featureSize, self.embeddingSize], mean=0.0, stddev=0.001), name=&#39;feature_embedding&#39;) weights[&#39;feature_bias&#39;] = tf.Variable(tf.random_normal(shape=[self.featureSize, 1], mean=0.0, stddev=0.001), name=&#39;feature_embedding&#39;) weights[&#39;bias&#39;] = tf.Variable(tf.random_normal(shape=[1]), name=&#39;bias&#39;) # deep weights[&#39;layers_{}&#39;.format(0)] = tf.Variable(tf.random_normal(shape=[self.embeddingSize, self.deepLayers[0]], mean=0, stddev=0.001), name=&#39;layers_{}&#39;.format(0)) weights[&#39;bias_{}&#39;.format(0)] = tf.Variable(tf.random_normal(shape=[1, self.deepLayers[0]]), name=&#39;bias_{}&#39;.format(0)) for i in range(1, len(self.deepLayers)): weights[&#39;layers_{}&#39;.format(i)] = tf.Variable(tf.random_normal(shape=[self.deepLayers[i-1], self.deepLayers[i]], mean=0.0, stddev=0.001), name=&#39;bias_{}&#39;.format(i)) weights[&#39;bias_{}&#39;.format(i)] = tf.Variable(tf.random_normal(shape=[1, self.deepLayers[i]]), name=&#39;bias_{}&#39;.format(i)) weights[&#39;layers_output&#39;] = tf.Variable(tf.random_normal(shape=[self.deepLayers[-1], 1], mean=0.0, stddev=0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/08696c86f9ff2a5716c54264c105deeb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-22T10:45:15+08:00" />
<meta property="article:modified_time" content="2019-05-22T10:45:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">推荐算法－NFM</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="NFM_0"></a>推荐算法－NFM</h2> 
<p>  FM对于特征的组合仅限于二阶，缺少对特征之间深层次关系的抽取。因此，NFM提出来就是在FM的基础上引入神经网络，实现对特征的深层次抽取。NFM的模型结构图如下所示：<br> <img src="https://images2.imgbox.com/3c/64/jKWHAHzc_o.png" alt="在这里插入图片描述"><br>   模型的结构如上图所示，首先输入就是离散化的特征，然后再进行embedding操作，获得每一个特征的向量表示。接着就到了Bi-interaction Pooling层，这里其实就是FM部分。FM的公式如下图所示：<br> <img src="https://images2.imgbox.com/e8/d7/ID6p5hB8_o.png" alt="在这里插入图片描述"><br> 去掉最外层的累加号，我们得到的是一个长度为K的向量，也就是embedding部分的长度。然后再对这个向量送入几层全连接层即可，最后输出ctr预估值。这就是NFM的整体思路。</p> 
<h2><a id="_7"></a>代码实现</h2> 
<p>  权重构建，就是初始化一下embedding部分的数据，以及全连接部分的权重。然后就可以实现计算图了。<br>   权重部分如下：</p> 
<pre><code>    def _initWeights(self):

        weights = dict()
        # embedding
        weights['feature_embedding'] = tf.Variable(tf.random_normal(shape=[self.featureSize, self.embeddingSize],
                                                                    mean=0.0, stddev=0.001), name='feature_embedding')
        weights['feature_bias'] = tf.Variable(tf.random_normal(shape=[self.featureSize, 1], mean=0.0, stddev=0.001), name='feature_embedding')
        weights['bias'] = tf.Variable(tf.random_normal(shape=[1]), name='bias')

        # deep

        weights['layers_{}'.format(0)] = tf.Variable(tf.random_normal(shape=[self.embeddingSize, self.deepLayers[0]],
                                                                      mean=0, stddev=0.001), name='layers_{}'.format(0))
        weights['bias_{}'.format(0)] = tf.Variable(tf.random_normal(shape=[1, self.deepLayers[0]]), name='bias_{}'.format(0))

        for i in range(1, len(self.deepLayers)):
            weights['layers_{}'.format(i)] = tf.Variable(tf.random_normal(shape=[self.deepLayers[i-1], self.deepLayers[i]],
                                                                          mean=0.0, stddev=0.001), name='bias_{}'.format(i))
            weights['bias_{}'.format(i)] = tf.Variable(tf.random_normal(shape=[1, self.deepLayers[i]]), name='bias_{}'.format(i))

        weights['layers_output'] = tf.Variable(tf.random_normal(shape=[self.deepLayers[-1], 1], mean=0.0, stddev=0.001),
                                               name='layers_output')
        weights['bias_output'] = tf.Variable(tf.random_normal(shape=[1]), name='bias_output')

        return weights
</code></pre> 
<p>  计算图部分：</p> 
<pre><code>    def _initGraph(self):
        self.weights = self._initWeights()

        self.featureIndex = tf.placeholder(shape=[None, None], dtype=tf.int32)
        self.featureValue = tf.placeholder(shape=[None, None], dtype=tf.float32)
        self.label = tf.placeholder(shape=[None, 1], dtype=tf.float32)
        self.dropoutKeepDeep = tf.placeholder(tf.float32, shape=[None], name='dropout_deep_deep')
        self.trainPhase = tf.placeholder(tf.bool, name='train_phase')

        # embedding
        self.embedding = tf.nn.embedding_lookup(self.weights['feature_embedding'], self.featureIndex)
        featureValue = tf.reshape(self.featureValue, shape=[-1, self.fieldSize, 1])
        self.embedding = tf.multiply(self.embedding, featureValue)  # none fieldSize embeddingSize

        # 一次项
        self.yFirstOrder = tf.nn.embedding_lookup(self.weights['feature_bias'], self.featureIndex)
        self.yFirstOrder = tf.reduce_sum(tf.multiply(self.yFirstOrder, featureValue), 2)

        # square-&gt;sum
        self.squaredSum = tf.reduce_sum(tf.square(self.embedding), 1)

        # sum-&gt;square
        self.sumedSquare = tf.square(tf.reduce_sum(self.embedding, 1))

        self.ySecondOrder = 0.5 * tf.subtract(self.sumedSquare, self.squaredSum)

        # deep

        self.yDeep = self.ySecondOrder
        for i in range(0, len(self.deepLayers)):
            self.yDeep = tf.matmul(self.yDeep, self.weights['layers_{}'.format(i)]) + self.weights['bias_{}'.format(i)]
            self.yDeep = self.deepLayerActivation(self.yDeep)
            self.yDeep = tf.nn.dropout(self.yDeep, self.dropoutDeep[i + 1])

        # bias
        # self.y_bias = self.weights['bias'] * tf.ones_like(self.label)

        # out
        self.out = tf.add_n([tf.reduce_sum(self.yFirstOrder, axis=1, keep_dims=True),
                             tf.reduce_sum(self.yDeep, axis=1, keep_dims=True)])
</code></pre> 
<p>  OK，NFM就简单介绍这些。思路相比与前面几篇比较简单，实现相对容易一些。</p> 
<h2><a id="_86"></a>参考</h2> 
<p><a href="https://www.comp.nus.edu.sg/~xiangnan/papers/sigir17-nfm.pdf" rel="nofollow">https://www.comp.nus.edu.sg/~xiangnan/papers/sigir17-nfm.pdf</a><br> <a href="https://www.jianshu.com/p/4e65723ee632" rel="nofollow">https://www.jianshu.com/p/4e65723ee632</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4638ace46fa23916abe0c35c66f899b9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">20190507(select()函数)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dec8d1268bd4bc5209918f6624827dd3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Multiple annotations found at this line: Invalid location of tag  (form). No end tag (form）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>