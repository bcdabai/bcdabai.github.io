<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI大模型时代下运维开发探索第二篇：基于大模型(LLM)的数据仓库 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="AI大模型时代下运维开发探索第二篇：基于大模型(LLM)的数据仓库" />
<meta property="og:description" content="在SREWorks社区聚集了很多进行运维数仓建设的同学，大家都会遇到类似的挑战和问题：
数仓中存储大量数据消耗成本，但很多存储的数据却并没有消费。进数仓的ETL学习成本高、管理成本高，相关同学配合度低，以及上游结构改动后ETL却迟迟无人调整。数仓中数据的时效性、准确性问题，导致很多场景无法完全依赖数仓展开。 上面的种种让推广数仓的同学很犯难：明明花了大力气构建了统一数仓，但却又受限于各种问题，无法让其价值得到完全的落地。本文旨在阐述一种基于LLM的数仓构建方案，从架构层面解决上述的三个问题。
一、方案设计 从需求出发，再次思考一下我们进行运维数仓构建的初衷：用一句SQL可以查询或统计到所有我们关注的运维对象的情况。虽然有很多方案能做，但总结一下，就是这样两种抽象模型：Push 或 Pull。
Push的方式是我们去主动管理数据的ETL链路，比如使用Flink、MaxCompute等大数据方案将数据进行加工放到数仓中。在需要查询的时候，直接SELECT数仓就能出结果。这类方案的问题在于：1. ETL管理维护成本高。2. 数据准确性较数据源有所下降。Pull的方式是我们不去主动拉所有的数据，在执行时候再去各个数据源找数据，比较具有代表性的就是Presto。这种方案的优点就是不用进行ETL管理以及数据准确性较好，毕竟是实时拉的。但问题就在于这种方案把复杂性都后置到了查询那一刻，查询速度过慢就成了问题。 那么是否有一种方案能将这两种模型结合起来，取其中的优点呢？经过这段时间对于大模型熟悉，我认为这个方案是可行的，于是尝试设计了一下流程图：
二、基于LLM的SQL预查询 相信大家在使用了类似Presto的联邦查询（Federated Query），都会对此印象深刻，原本要好多个for循环的代码，放到里面只要一个select-join就能解决。但Presto本身的定位就是为分析型的负载设计，我们无法把它置于一些高频查询的关键链路上。
联邦查询的SQL和for循环的代码，看起来似乎只隔了一层纱，现在大模型的出现就直接把这层纱给捅破了。我们的思路也非常简单：既然大模型可以非常方便地把用户需求转换成SQL，那么把用户SQL转换成代码似乎也不是一件难事。
import os import sys from openai import OpenAI import traceback from io import StringIO from contextlib import redirect_stdout, redirect_stderr client = OpenAI() def get_script(content): return content.split(&#34;```python&#34;)[1].split(&#34;```&#34;)[0] def execute_python(code_str: str): stdout = StringIO() stderr = StringIO() return_head = 1000 context = {} try: # 重定向stdout和stderr，执行代码 with redirect_stdout(stdout), redirect_stderr(stderr): exec(code_str, context) except Exception: stderr.write(traceback.format_exc()) # 获取执行后的stdout, stderr和context stdout_value = stdout." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/74dc2ccf4a4f798c4e11f63cd0ba8d17/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T13:52:47+08:00" />
<meta property="article:modified_time" content="2023-12-29T13:52:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI大模型时代下运维开发探索第二篇：基于大模型(LLM)的数据仓库</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="ud57f2ded">在SREWorks社区聚集了很多进行运维数仓建设的同学，大家都会遇到类似的挑战和问题：</p> 
<ul><li id="u8f1d3533">数仓中存储大量数据消耗成本，但很多存储的数据却并没有消费。</li><li id="u46fa354d">进数仓的ETL学习成本高、管理成本高，相关同学配合度低，以及上游结构改动后ETL却迟迟无人调整。</li><li id="u39859641">数仓中数据的时效性、准确性问题，导致很多场景无法完全依赖数仓展开。</li></ul> 
<p id="u65a41310">上面的种种让推广数仓的同学很犯难：明明花了大力气构建了统一数仓，但却又受限于各种问题，无法让其价值得到完全的落地。本文旨在阐述一种基于LLM的数仓构建方案，从架构层面解决上述的三个问题。</p> 
<h2 id="beaST">一、方案设计</h2> 
<p id="ud54f9e4e">从需求出发，再次思考一下我们进行运维数仓构建的初衷：用一句SQL可以查询或统计到所有我们关注的运维对象的情况。虽然有很多方案能做，但总结一下，就是这样两种抽象模型：Push 或 Pull。</p> 
<ul><li id="uc53ce5a4"><strong>Push的方式</strong>是我们去主动管理数据的ETL链路，比如使用Flink、MaxCompute等大数据方案将数据进行加工放到数仓中。在需要查询的时候，直接SELECT数仓就能出结果。这类方案的问题在于：1. ETL管理维护成本高。2. 数据准确性较数据源有所下降。</li><li id="uf1fa208a"><strong>Pull的方式</strong>是我们不去主动拉所有的数据，在执行时候再去各个数据源找数据，比较具有代表性的就是Presto。这种方案的优点就是不用进行ETL管理以及数据准确性较好，毕竟是实时拉的。但问题就在于这种方案把复杂性都后置到了查询那一刻，查询速度过慢就成了问题。</li></ul> 
<p id="u92e3c2e4">那么是否有一种方案能将这两种模型结合起来，取其中的优点呢？经过这段时间对于大模型熟悉，我认为这个方案是可行的，于是尝试设计了一下流程图：</p> 
<p></p> 
<p class="img-center"><img alt="" height="849" id="w6oIw" src="https://images2.imgbox.com/97/2f/7asFZ7bR_o.jpg" width="1200"></p> 
<h2 id="IQgkB">二、基于LLM的SQL预查询</h2> 
<p id="u7783f4d6">相信大家在使用了类似Presto的联邦查询（Federated Query），都会对此印象深刻，原本要好多个for循环的代码，放到里面只要一个select-join就能解决。但Presto本身的定位就是为分析型的负载设计，我们无法把它置于一些高频查询的关键链路上。</p> 
<p id="u7c862b86">联邦查询的SQL和for循环的代码，看起来似乎只隔了一层纱，现在大模型的出现就直接把这层纱给捅破了。我们的思路也非常简单：既然大模型可以非常方便地把用户需求转换成SQL，那么把用户SQL转换成代码似乎也不是一件难事。</p> 
<pre id="ffNWt"><code>import os
import sys
from openai import OpenAI
import traceback
from io import StringIO
from contextlib import redirect_stdout, redirect_stderr

client = OpenAI()

def get_script(content):
    return content.split("```python")[1].split("```")[0]

def execute_python(code_str: str):

    stdout = StringIO()
    stderr = StringIO()
    return_head = 1000

    context = {}

    try:
        # 重定向stdout和stderr，执行代码
        with redirect_stdout(stdout), redirect_stderr(stderr):
            exec(code_str, context)
    except Exception:
        stderr.write(traceback.format_exc())

    # 获取执行后的stdout, stderr和context
    stdout_value = stdout.getvalue()[0:return_head]
    stderr_value = stderr.getvalue()[0:return_head]

    return {"stdout": stdout_value.strip(), "stderr": stderr_value.strip()}


prompt = """
你是一个数据库专家，我会给你一段SQL，请你转换成可执行的Python代码。
当前有2个数据库的连接信息，分别是:

1. 数据库名称 processes 连接串 mysql://root@test-db1.com:3306/processes
下面是这个数据库的表结构
```
CREATE TABLE `process_table` (
  `process_name` varchar(100) DEFAULT NULL,
  `start_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `server_name` varchar(100) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
```

2. 数据库名称 servers 连接串 mysql://root@test-db2.com:3306/servers
下面是这个数据库的表结构
···
CREATE TABLE `server_table` (
  `server_name` varchar(100) DEFAULT NULL,
  `ip` varchar(100) DEFAULT NULL,
  `zone` varchar(100) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
···


在编写Python代码的时候，不要把所有的数据库的信息都传入，请根据SQL的内容按需传入。
返回结果中只有Python代码，如要描述信息全部放在注释中。Python的执行结果需要是JSON格式的数据。
下面用户会给出你需要转换的SQL：
"""

query_sql = "select * from processes.process_table a join servers.server_table b on a.server_name = b.server_name where b.zone = 'ZoneA';"

messages = [
    {"role": "system", "content": prompt},
    {"role": "user", "content": query_sql}
]

res = client.chat.completions.create(messages=messages, model="gpt-4")

print(res.choices[0].message.content)

exec_result = execute_python(get_script(res.choices[0].message.content))

print("result:")
print(exec_result)

if exec_result["stderr"] == "" and exec_result["stdout"] != "":
    print(exec_result["stdout"])
    sys.exit(0)
</code></pre> 
<p id="u4565d04d">这个例子，确实相当简单直接，连langchain都不需要，我们基于OpenAI的接口直接实现联邦查询的能力：</p> 
<ul><li id="u9232059b">事先将连接串和数据结构准备好，输入给LLM。</li><li id="uf5d04e29">将SQL语句输入给LLM，确保SQL中的表名和数据结构中的表名一致，避免LLM混淆。</li><li id="ua0ea6f9c">将LLM给出的代码直接执行，便获得了查询结果。</li></ul> 
<p id="u5f7b0da0">下面我们来看看运行的结果</p> 
<pre id="E9HVs"><code>```python
# Import required libraries
import pandas as pd
from sqlalchemy import create_engine

# Create connection engines
engine1 = create_engine('mysql://root@test-db1.com:3306/processes')
engine2 = create_engine('mysql://root@test-db2.com:3306/servers')

# Query data from process_table in processes database
df1 = pd.read_sql('SELECT * FROM `process_table`', engine1)

# Query data from server_table in servers database
df2 = pd.read_sql('SELECT * FROM `server_table` WHERE `zone` = "ZoneA"', engine2)

# Merge both dataframes on server_name
result = pd.merge(df1, df2, how='inner', on='server_name')

# Convert dataframe to JSON
out_json = result.to_json(orient='records')

print(out_json)
```
关于此代码：
我们首先导入了必要的库，然后使用提供的凭据创建了两个数据库连接。然后，我们分别从两个数据库中查询数据。接着，我们根据"server_name"合并这两个数据框，最后我们将结果转换为JSON格式。
result:
{'stdout': '[{"process_name":"Process1","start_time":1703259365000,"end_time":1703266565000,"server_name":"Server1","zone":"ZoneA"},{"process_name":"Process2","start_time":1703262965000,"end_time":1703270165000,"server_name":"Server2","zone":"ZoneA"}]', 'stderr': ''}
[{"process_name":"Process1","start_time":1703259365000,"end_time":1703266565000,"server_name":"Server1","zone":"ZoneA"},{"process_name":"Process2","start_time":1703262965000,"end_time":1703270165000,"server_name":"Server2","zone":"ZoneA"}]</code></pre> 
<p id="u5cac5f76">真实运行起来，确实LLM给的代码比较随机，一会儿使用pandas处理数据，一会儿使用pymysql处理数据，存在非常大的不确定性，但是结果是确定的。多试几次之后，我们发现这个结果还是不稳定，有时候会写一些存在瑕疵的代码，导致报错。基于我们在上一篇已经讲清楚的思维链的模型，我们可以给它加上一个报错反馈链路，让它自行修改问题代码。</p> 
<pre id="xGUFZ"><code>for i in range(3):
    print("第", i + 1, "次重试")
    messages = [
        {"role": "system", "content": prompt + "\n" + query_sql},
    ]

    if exec_result["stderr"] != "":
        messages.append({"role": "user", "content": res.choices[0].message.content + "\n\n" + exec_result["stderr"] + "\n执行报错，请根据报错修正，再次生成代码"})
    else:
        messages.append({"role": "user", "content": res.choices[0].message.content + "\n\n" + "执行没有任何返回，请再次生成代码"})

    res = client.chat.completions.create(messages=messages, model="gpt-4")
    print(res.choices[0].message.content)
    exec_result = execute_python(get_script(res.choices[0].message.content))

    print("result:")
    print(exec_result)

    if exec_result["stderr"] == "" and exec_result["stdout"] != "":
        print(exec_result["stdout"])
        sys.exit(0)

print("查询失败")</code></pre> 
<p id="ub18fa235">有了这层错误反馈之后，我们会发现这个查询就非常稳定了，虽然有些时候LLM产生的代码会出错，但是通过报错信息自行修改优化之后，能够保持产出结果稳定（不过自动修改报错的查询，时延明显会比较长一些）。</p> 
<table id="CWo5B"><tbody><tr><td></td><td> <p id="u0099a588"><strong>总计</strong></p> </td><td colspan="2"> <p id="uf90cb19a"><strong>一次正确</strong></p> </td><td colspan="2"> <p id="uff155f56"><strong>二次正确</strong></p> </td><td colspan="2"> <p id="u047d7209"><strong>三次正确</strong></p> </td><td colspan="2"> <p id="ue70e6c8c"><strong>失败</strong></p> </td></tr><tr><td> <p id="u1dabef91">次数</p> </td><td> <p id="u2993519e">20</p> </td><td> <p id="u97d14dd1">7</p> </td><td> <p id="u9455cc0e">35%</p> </td><td> <p id="u1b765e3a">9</p> </td><td> <p id="u26a80462">45%</p> </td><td> <p id="u0c49d282">0</p> </td><td> <p id="uf1337e0a">0</p> </td><td> <p id="ub9b74dc4">4</p> </td><td> <p id="u4fd02716">20%</p> </td></tr><tr><td> <p id="uc0af1eaa">平均耗时</p> </td><td> <p id="u5ca2c011">43.0s</p> </td><td colspan="2"> <p id="uacc31832">13.2s</p> </td><td colspan="2"> <p id="u7e5eb837">45.3s</p> </td><td colspan="2"> <p id="ucd15c865">N/A</p> </td><td colspan="2"> <p id="u07589426">91.2s</p> </td></tr></tbody></table> 
<p id="u6d535623"><strong>从20次的测试中，可以看出一次查询的成功率在30%左右，通过报错反馈优化，成功率就能达到80%。</strong>通过观察每个查询语句，基本可以发现使用pandas的代码编写准确率高很多，后续如果需要优化prompt，可以在再增加一些使用依赖库上的指引，编写成功率会更高。同时我们也发现，如果有些代码一开始方向就错误的话，通过报错反馈优化也救不回来，三次成功率为零就是一个很好的说明。当前测试用的LLM推理速度较慢，如果本地化部署LLM理论上推理速度还能更快不少。</p> 
<p id="u68f5611a">当前，基于LLM的查询表现上可以和Presto已经比较近似了，但有些地方会比Presto要更强：</p> 
<ul><li id="u47d5e087"><strong>数据源扩展</strong>：presto需要进行适配器的开发才能对接其他数据源，而LLM的方案你只要教会LLM怎么查询特定数据源就行了，事实上可能都不用教，因为它有几乎所有的编程知识。</li><li id="u763296a8"><strong>白盒化以及复杂查询优化</strong>：针对复杂场景如果存在一些查询准确性问题，需要去preso引擎中排查原因并不简单。但LLM的方案是按照人可阅读的代码来了，你可以要求它按照你熟悉的编程语言编写，你甚至可以要求它写的代码每行都加上注释。</li></ul> 
<p id="u27899cb2">当然，和Presto一样，基于LLM的查询方案，只能被放到预查询中，在生产链路中并不能每次都让LLM去生成查询代码，这太慢了。那么有没有办法让它的查询提速呢？可以的。还记得我们在文章开头提过的Push和Pull的模式吗？联邦查询是基于Pull的模式展开的，而流式ETL是基于Push模式展开的，我们如果把查询语句直接翻译成流式ETL的语句，预先将需要的数据处理到一个数据库中，那是不是就完全可以规避掉性能问题了呢？</p> 
<h2 id="nmeQ7">三、基于LLM的流计算处理</h2> 
<p id="ud7146dc0">和分析型的查询相比，流计算的数据同步逻辑显然简单很多，只要分析SQL，按需求字段进行同步即可。这里就不贴完整的代码了，就把相关部分的prompt贴出来。</p> 
<pre id="HxRvW"><code>当前有2个数据库的连接信息，分别是:

1. 数据库名称 processes 连接串 mysql://root@test-db1.com:3306/processes
下面是这个数据库的表结构
```
CREATE TABLE `process_table` (
  `process_name` varchar(100) DEFAULT NULL,
  `start_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `server_name` varchar(100) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
```

2. 数据库名称 servers 连接串 mysql://root@test-db2.com:3306/servers
下面是这个数据库的表结构
···
CREATE TABLE `server_table` (
  `server_name` varchar(100) DEFAULT NULL,
  `ip` varchar(100) DEFAULT NULL,
  `zone` varchar(100) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
···


你是一个Flink专家，我会给你一段需求SQL，请你根据需求SQL，分析出哪些字段被需要，编写合适的Flink SQL预先处理到clickhouse中。
原有的表在clickhouse中依然保持原有的表名，保持一对一的映射。
Flink SQL处理的目标是使得用户能在clickhouse中在完全不改动需求SQL的情况下正确执行。
在Flink SQL中只进行数据同步，不要加数据处理逻辑。
请在结果中直接给出一份完整的Flink SQL代码，不要任何文字说明，如果有说明的地方在代码中用注释标出。

下面用户会给需求SQL：
select a.process_name,b.server_name from processes.process_table a join servers.server_table b on a.server_name = b.server_name where b.zone = 'ZoneA';</code></pre> 
<p id="u0930d299">我们可以看到这份prompt和上一章生成查询代码的prompt几乎没有太大差别，只是对于其生成的目标做了修改，明确告诉它要生成Flink SQL。下面就是LLM生成的Flink SQL：</p> 
<pre id="ufiyo"><code>-- 创建Flink SQL连接到数据库processes的process_table
CREATE TABLE process_table (
  process_name STRING,
  server_name STRING
) WITH (
  'connector' = 'mysql-cdc',  -- 使用 MySQL CDC 连接器
  'hostname' = 'test-db1.com',  -- 源数据库主机名
  'port' = '3306',  -- 源数据库端口
  'username' = 'root',  -- 源数据库用户名
  'database-name' = 'processes',  -- 源数据库名
  'table-name' = 'process_table'  -- 源数据库表名
);

-- 创建Flink SQL连接到数据库servers的server_table
CREATE TABLE server_table (
  server_name STRING,
  zone STRING
) WITH (
  'connector' = 'mysql-cdc',  -- 使用 MySQL CDC 连接器
  'hostname' = 'test-db2.com',  -- 源数据库主机名
  'port' = '3306',  -- 源数据库端口
  'username' = 'root',  -- 源数据库用户名
  'database-name' = 'servers',  -- 源数据库名
  'table-name' = 'server_table'  -- 源数据库表名
);

-- 创建到ClickHouse的连接，保持和源数据库对应关系
CREATE TABLE clickhouse_process_table (
  process_name STRING,
  server_name STRING
) WITH (
  'connector' = 'clickhouse',
  'url' = 'clickhouse://localhost:8123',
  'table-name' = 'process_table'
);

CREATE TABLE clickhouse_server_table (
  server_name STRING,
  zone STRING
) WITH (
  'connector' = 'clickhouse',
  'url' = 'clickhouse://localhost:8123',
  'table-name' = 'server_table'
);

-- Flink SQL同步数据
INSERT INTO clickhouse_process_table
SELECT process_name, server_name
FROM process_table;

INSERT INTO clickhouse_server_table
SELECT server_name, zone
FROM server_table;</code></pre> 
<p id="uc9bc8811">如我们所预期的，LLM给出了准确的Flink SQL语句，并且还根据查询需求的SQL，它只同步了会查到的字段，用不到的字段就没有同步（比如server中的ip字段没有用到）。在这样一条链路中，我们同样可以类似第三章使用的报错反馈自优化的方式，提高生成代码的稳定性，使得其生成的代码可以直接在生产中部署运行，在这里我们就不做过多展开了。</p> 
<h2 id="atPiX">四、总结</h2> 
<p id="u9ace0b56">一份需求查询SQL，利用LLM生成两份代码，一份用于Pull：直接查询返回结果，预查询调试用；一份用于Push：构建消费链路进实时数仓。基于LLM，实现真正意义上从需求出发的ETL生产链路构建，大概包含如下优点：</p> 
<ul><li id="u501d62ee"><strong>避免ETL过程的过度加工</strong>：按需加字段，不会加工太多用不到字段浪费计算、浪费存储。</li><li id="u7d5a4a20"><strong>降低使用者维护ETL加工过程成本</strong>：虽然Flink SQL的可维护性已经很好了，但是面向计算过程的SQL编写方式还是让很多用户不适应。如果直接用查询SQL来进行自动生成，就大大降低了维护的门槛。</li><li id="u220db7fc"><strong>统一数据链路：</strong>以查询为驱动的数据模型，可以使得使用者始终面向数据源表进行需求思考。ETL实时计算产生的数据会更像一个物化视图，这样在做实时数据准确性校验时也更加方便。</li></ul> 
<p id="u62a93b1e">如果您当前还在为数仓的构建所困扰，可以尝试一下这个基于LLM的方案，欢迎大家在SREWorks数智运维社区沟通交流。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/552de878579663b06dfcf4128482f308/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">鸿蒙应用开发培训笔记02：应用开发入门</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7ea65713ea7b161d8f9fd1b0d4780da8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">证明：如果一个字符串的最小循环节是不完全循环节，那么该字符串没有完全循环节</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>