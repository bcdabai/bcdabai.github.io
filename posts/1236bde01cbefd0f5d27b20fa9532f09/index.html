<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>spark部署及提交任务 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="spark部署及提交任务" />
<meta property="og:description" content="1.spark部署模式 1.1 Local模式 Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置master。
local: 所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式。local[K]: 指定使用几个线程来运行计算，比如local[4]就是运行4个worker线程。通常我们的cpu有几个core，就指定几个线程，最大化利用cpu的计算能力local[*]: 这种模式直接帮你按照cpu最多cores来设置线程数了。 /bin/spark-submit \ --cluster cluster_name \ --master local[*] \ ... 这几种local模式都是运行在本地的单机版模式，通常用于练手和测试，而实际的大规模计算就需要下面要介绍的cluster模式。
1.2 cluster模式 cluster模式肯定就是运行很多机器上了，但是它又分为以下三种模式，区别在于谁去管理资源调度。（说白了，就好像后勤管家，哪里需要资源，后勤管家要负责调度这些资源）
1.2.1 standalone模式 这种模式下，Spark会自己负责资源的管理调度。它将cluster中的机器分为master机器和worker机器，master通常就一个，可以简单的理解为那个后勤管家，worker就是负责干计算任务活的苦劳力。具体怎么配置可以参考Spark Standalone Mode
使用standalone模式示例：
/bin/spark-submit \ --cluster cluster_name \ --master spark://host:port \ ... --master就是指定master那台机器的地址和端口，我想这也正是--master参数名称的由来吧。
1.2.2 mesos模式 这里就很好理解了，如果使用mesos来管理资源调度，自然就应该用mesos模式了，示例如下：
/bin/spark-submit \ --cluster cluster_name \ --master mesos://host:port \ ... 1.2.3 yarn模式 同样，如果采用yarn来管理资源调度，就应该用yarn模式，由于很多时候我们需要和mapreduce使用同一个集群，所以都采用Yarn来管理资源调度，这也是生产环境大多采用yarn模式的原因。yarn模式又分为yarn cluster模式和yarn client模式：
yarn cluster: 这个就是生产环境常用的模式，所有的资源调度和计算都在集群环境上运行，客户端只负责提交应用程序。Driver 运行在Application Master中， 当用户提交了作业之后，就可以关于关闭Client，作业会继续在YARN上运行， 因而YARN-cluster模式不适合进行交互式类型的作业yarn client: Spark Driver在本机运行，而计算任务在cluster上。可以使Spark Application和客户端进行交互。Application Master仅仅向YARN请求Executor，Client会和请求的Container的通信来调度它们工作，Client是不能离开的 YARN的两种运行模式_夏末的初雪的博客-CSDN博客_yarn模式
2.提交任务 spark-submit \ --master yarn \ --queue test_queue \ --deploy-mode client \ --driver-memory 10g \ --executor-cores 2 \ --executor-memory 1G \ --num-executors 8 \ --class com." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/1236bde01cbefd0f5d27b20fa9532f09/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-28T23:51:33+08:00" />
<meta property="article:modified_time" content="2023-11-28T23:51:33+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">spark部署及提交任务</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1.spark部署模式</h2> 
<p style="text-align:center;"><img alt="" height="358" src="https://images2.imgbox.com/b8/66/siAKuWRF_o.png" width="600"></p> 
<p></p> 
<h3>1.1 Local模式</h3> 
<p>Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置master。</p> 
<ul><li><strong>local: </strong>所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式。</li><li><strong>local[K]: </strong>指定使用几个线程来运行计算，比如local[4]就是运行4个worker线程。通常我们的cpu有几个core，就指定几个线程，最大化利用cpu的计算能力</li><li><strong>local[*]:</strong> 这种模式直接帮你按照cpu最多cores来设置线程数了。</li></ul> 
<pre><code class="language-bash">/bin/spark-submit \

--cluster cluster_name \

--master local[*] \

...</code></pre> 
<p>这几种local模式都是运行在本地的单机版模式，通常用于练手和测试，而实际的大规模计算就需要下面要介绍的cluster模式。</p> 
<h3><a name="t1"></a>1.2 cluster模式</h3> 
<p>cluster模式肯定就是运行很多机器上了，但是它又分为以下三种模式，区别在于谁去管理资源调度。（说白了，就好像后勤管家，哪里需要资源，后勤管家要负责调度这些资源）</p> 
<h4><a name="t2"></a>1.2.1 standalone模式</h4> 
<p>这种模式下，Spark会自己负责资源的管理调度。它将cluster中的机器分为master机器和worker机器，master通常就一个，可以简单的理解为那个后勤管家，worker就是负责干计算任务活的苦劳力。具体怎么配置可以参考<a href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="nofollow" title="Spark Standalone Mode">Spark Standalone Mode</a></p> 
<p>使用standalone模式示例：</p> 
<pre><code class="language-bash">/bin/spark-submit \
--cluster cluster_name \
--master spark://host:port \
...</code></pre> 
<p>--master就是指定master那台机器的地址和端口，我想这也正是--master参数名称的由来吧。</p> 
<h4><a name="t3"></a>1.2.2 mesos模式</h4> 
<p>这里就很好理解了，如果使用mesos来管理资源调度，自然就应该用mesos模式了，示例如下：</p> 
<pre><code class="language-bash">/bin/spark-submit \
--cluster cluster_name \
--master mesos://host:port \
...</code></pre> 
<h4>1.2.3 yarn模式</h4> 
<p>同样，如果采用yarn来管理资源调度，就应该用yarn模式，由于很多时候我们需要和mapreduce使用同一个集群，所以都采用Yarn来管理资源调度，这也是生产环境大多采用yarn模式的原因。yarn模式又分为yarn cluster模式和yarn client模式：</p> 
<ul><li><strong>yarn cluster: </strong>这个就是生产环境常用的模式，所有的资源调度和计算都在集群环境上运行，客户端只负责提交应用程序。<span style="color:#fe2c24;">Driver 运行在Application Master中</span>， 当用户提交了作业之后，就可以关于关闭Client，作业会继续在YARN上运行， 因而YARN-cluster模式不适合进行交互式类型的作业</li><li><strong>yarn client: </strong>Spark Driver在本机运行，而计算任务在cluster上。可以使Spark Application和客户端进行交互。Application Master仅仅向YARN请求Executor，Client会和请求的Container的通信来调度它们工作，Client是不能离开的</li></ul> 
<p><a href="https://blog.csdn.net/qq_27717921/article/details/81152969" title="YARN的两种运行模式_夏末的初雪的博客-CSDN博客_yarn模式">YARN的两种运行模式_夏末的初雪的博客-CSDN博客_yarn模式</a></p> 
<h2>2.提交任务</h2> 
<pre><code class="language-bash">spark-submit \
--master yarn \
--queue test_queue \
--deploy-mode client \
--driver-memory 10g \
--executor-cores 2 \
--executor-memory 1G \
--num-executors 8  \
--class com.data.Test  \
hdfs:user/test.jar arg1 arg2


spark-sql \ 
--queue test_queue \
--deploy-mode client \ 
--num-executors 10 \
--executor-memory 10g \
--executor-cores 5


spark-shell \
--queue test_queue</code></pre> 
<p></p> 
<h2>3.参数说明</h2> 
<table border="1" cellpadding="1" cellspacing="1"><thead><tr><th style="width:144px;">参数</th><th style="width:265px;">参数说明</th><th style="width:280px;">举例</th></tr></thead><tbody><tr><td style="width:144px;">--master</td><td style="width:265px;">master的地址，即提交任务在哪里执行</td><td style="width:280px;">--master yarn</td></tr><tr><td style="width:144px;">--deploy-mode</td><td style="width:265px;">driver程序运行的位置</td><td style="width:280px;"> <p>client：driver程序运行在client端</p> <p>cluster：driver程序运行在某个worker上</p> </td></tr><tr><td style="width:144px;">--queue</td><td style="width:265px;">提交大yarn集群使用的队列</td><td style="width:280px;">--queue test</td></tr><tr><td style="width:144px;">--num-executors</td><td style="width:265px;">启动executor个数，默认2，在yarn中使用</td><td style="width:280px;">--num-executors 100，设置的太多的话，队列可能无法给予充分的资源</td></tr><tr><td style="width:144px;">--executor-memory</td><td style="width:265px;">每个executor的内存，默认1G</td><td style="width:280px;">--executor-memory 10G</td></tr><tr><td style="width:144px;">--executor-cores</td><td style="width:265px;">每个executor的核数，在yarn或者standalone下使用</td><td style="width:280px;">--executor-core 2</td></tr><tr><td style="width:144px;">--class</td><td style="width:265px;">程序的主类，主要是Java或scala</td><td style="width:280px;"></td></tr><tr><td style="width:144px;">--jars</td><td style="width:265px;">spark依赖的jar，逗号分割</td><td style="width:280px;">hoodie-hive-0.4.7.jar,hoodie-common-0.4.7.jar</td></tr><tr><td style="width:144px;">--py-files</td><td style="width:265px;">依赖的python文件</td><td style="width:280px;">--py-files test.py</td></tr><tr><td style="width:144px;">--driver-cores</td><td style="width:265px;">设置Driver的core个数，默认为1</td><td style="width:280px;">--driver-cores 2</td></tr><tr><td style="width:144px;">--driver-memory</td><td style="width:265px;">设置Driver的内存大小，默认为1G</td><td style="width:280px;">--driver-memory 5G</td></tr><tr><td style="width:144px;">--conf key=value</td><td style="width:265px;">设置spark 属性值</td><td style="width:280px;">--conf spark.executor.memoryOverhead=4G</td></tr><tr><td style="width:144px;">--packages</td><td style="width:265px;"> <p>包含在driver 和executor 的 classpath 中的 jar 的 maven 坐标，写法为  <code>groupId:artifactId:version</code></p> <p>在首次运行的时候会自动下载</p> </td><td style="width:280px;">org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0</td></tr></tbody></table>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ad334ee50fd21dd2efbd8e83710df915/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">002-getopt_long()</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/958ec895dd08340f87fee64c39083e34/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Ubuntu上安装、使用Redis的详细教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>