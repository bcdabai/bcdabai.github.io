<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[R语言]稳健回归 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[R语言]稳健回归" />
<meta property="og:description" content="原文来自：稳健回归
INTRODUCTION 我们以线性回归中的一些概念开始关于稳健回归的讨论。
残差： 预测值（基于回归方程）与实际观察值之间的差。
离群值： 在线性回归中，离群值是具有大量残差的观察值。换句话说，鉴于其对预测变量的价值，这是一个因变量不寻常的观察结果。离群值可能表示样本特性，或者可能表示数据输入错误或其他问题。
杠杆： 对预测变量具有极高价值的观察点具有很高的杠杆作用。杠杆作用是对自变量偏离均值的程度的度量。高杠杆点可能会对回归系数的估计产生很大影响。
影响： 如果删除观察结果会显着改变回归系数的估计值，则认为该观察结果具有影响力。可以将影响视为杠杆和离群值的产物。
库克距离： 一种结合了杠杆作用和观测值残差信息的度量。
可以在使用最小二乘回归的任何情况下使用稳健回归。在拟合最小二乘回归时，我们可能会发现一些离群值或高杠杆点。我们已经确定这些数据点不是数据输入错误，也不是来自与我们大多数数据不同的总体。因此，我们没有令人信服的理由将它们排除在分析之外。稳健的回归可能是一个很好的策略，因为这是从完全排除这些异常点与包括所有数据点OLS回归的折中方案。稳健回归的想法是根据这些观察的表现如何对观察进行不同的加权。粗略地说，它是加权和最小二乘回归的一种形式。
在MASS包中，使用rlm在命令可以实现稳健回归的几个版本。在此，我们将展示使用 Huber 和 bisquare权重的M估计。M估计定义了权重函数，使估计方程变为 ∑ i = 1 n w i ( y i − x T b ) x T = 0 \sum_{i=1}^{n} w_i (y_i - x^Tb)x^T = 0 ∑i=1n​wi​(yi​−xTb)xT=0. 但是这一权重又取决于残差。这一方程使用迭代重加权最小平方法（Iteratively Reweighted Least Squares，IRLS）求解。例如，第j步迭代的稀疏矩阵为： B j = [ X T W j − 1 X ] − 1 X T W j − 1 Y B_j =[X^TW_{j-1}X]^{-1}X^TW_{j-1}Y Bj​=[XTWj−1​X]−1XTWj−1​Y." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/8fff711d5ac9f9aa391bb41aa3f48a3b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-30T17:12:15+08:00" />
<meta property="article:modified_time" content="2020-12-30T17:12:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[R语言]稳健回归</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>原文来自：<a href="https://stats.idre.ucla.edu/r/dae/robust-regression/" rel="nofollow">稳健回归</a></p> 
<h3><a id="INTRODUCTION_1"></a>INTRODUCTION</h3> 
<p>我们以线性回归中的一些概念开始关于稳健回归的讨论。</p> 
<p><strong>残差：</strong> 预测值（基于回归方程）与实际观察值之间的差。</p> 
<p><strong>离群值：</strong> 在线性回归中，离群值是具有大量残差的观察值。换句话说，鉴于其对预测变量的价值，这是一个因变量不寻常的观察结果。离群值可能表示样本特性，或者可能表示数据输入错误或其他问题。</p> 
<p><strong>杠杆：</strong> 对预测变量具有极高价值的观察点具有很高的杠杆作用。杠杆作用是对自变量偏离均值的程度的度量。高杠杆点可能会对回归系数的估计产生很大影响。</p> 
<p><strong>影响：</strong> 如果删除观察结果会显着改变回归系数的估计值，则认为该观察结果具有影响力。可以将影响视为杠杆和离群值的产物。</p> 
<p><strong>库克距离：</strong> 一种结合了杠杆作用和观测值残差信息的度量。</p> 
<p>可以在使用最小二乘回归的任何情况下使用稳健回归。在拟合最小二乘回归时，我们可能会发现一些离群值或高杠杆点。我们已经确定这些数据点不是数据输入错误，也不是来自与我们大多数数据不同的总体。因此，我们没有令人信服的理由将它们排除在分析之外。稳健的回归可能是一个很好的策略，因为这是从完全排除这些异常点与包括所有数据点OLS回归的折中方案。稳健回归的想法是根据这些观察的表现如何对观察进行不同的加权。粗略地说，它是加权和最小二乘回归的一种形式。</p> 
<p>在MASS包中，使用rlm在命令可以实现稳健回归的几个版本。在此，我们将展示使用 Huber 和 bisquare权重的M估计。M估计定义了权重函数，使估计方程变为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ∑ 
         
         
         
           i 
          
         
           = 
          
         
           1 
          
         
        
          n 
         
        
        
        
          w 
         
        
          i 
         
        
       
         ( 
        
        
        
          y 
         
        
          i 
         
        
       
         − 
        
        
        
          x 
         
        
          T 
         
        
       
         b 
        
       
         ) 
        
        
        
          x 
         
        
          T 
         
        
       
         = 
        
       
         0 
        
       
      
        \sum_{i=1}^{n} w_i (y_i - x^Tb)x^T = 0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.104em; vertical-align: -0.29971em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: -0.000005em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.804292em;"><span class="" style="top: -2.40029em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.29971em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span style="margin-right: 0.02691em;" class="mord mathdefault">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.02691em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.09133em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.13889em;" class="mord mathdefault mtight">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.13889em;" class="mord mathdefault mtight">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span></span></span></span></span>. 但是这一权重又取决于残差。这一方程使用迭代重加权最小平方法（Iteratively Reweighted Least Squares，IRLS）求解。例如，第j步迭代的稀疏矩阵为：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          B 
         
        
          j 
         
        
       
         = 
        
       
         [ 
        
        
        
          X 
         
        
          T 
         
        
        
        
          W 
         
         
         
           j 
          
         
           − 
          
         
           1 
          
         
        
       
         X 
        
        
        
          ] 
         
         
         
           − 
          
         
           1 
          
         
        
        
        
          X 
         
        
          T 
         
        
        
        
          W 
         
         
         
           j 
          
         
           − 
          
         
           1 
          
         
        
       
         Y 
        
       
      
        B_j =[X^TW_{j-1}X]^{-1}X^TW_{j-1}Y 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span style="margin-right: 0.05017em;" class="mord mathdefault">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.05017em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.05724em;" class="mord mathdefault mtight">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.12744em; vertical-align: -0.286108em;"></span><span class="mopen">[</span><span class="mord"><span style="margin-right: 0.07847em;" class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.13889em;" class="mord mathdefault mtight">T</span></span></span></span></span></span></span></span><span class="mord"><span style="margin-right: 0.13889em;" class="mord mathdefault">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span style="margin-right: 0.05724em;" class="mord mathdefault mtight">j</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span style="margin-right: 0.07847em;" class="mord mathdefault">X</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span style="margin-right: 0.07847em;" class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.13889em;" class="mord mathdefault mtight">T</span></span></span></span></span></span></span></span><span class="mord"><span style="margin-right: 0.13889em;" class="mord mathdefault">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span style="margin-right: 0.05724em;" class="mord mathdefault mtight">j</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span style="margin-right: 0.22222em;" class="mord mathdefault">Y</span></span></span></span></span>. 迭代重复该过程一直持续到收敛为止。在Huber加权中，残差小的观测值的权重为1，而残差越大，权重就越小。这由权重函数的定义所决定的。如果使用bisquare加权，所有具有非零残差的情况，权重都有所降低。</p> 
<h3><a id="_19"></a>示例数据说明</h3> 
<p>对于下面的数据分析，我们将使用 Alan Agresti 和Barbara Finlay（Prentice Hall，1997）在《社会科学统计方法》第三版中出现的犯罪数据集 。变量包括各州 ID（<strong>sid</strong>），州名（<strong>state</strong>），每10万人的暴力罪犯（<strong>crime</strong>），每1,000,000人中的谋杀罪犯（<strong>murder</strong>），居住在大都市区的比例（<strong>pctmetro</strong>），白人的比例（<strong>pctwhite</strong>），高中或以上学历的人口百分比（<strong>pcths</strong>），生活在贫困线以下的人口百分比（<strong>poverty</strong>）和单亲父母的人口百分比（<strong>single</strong>）。它有51个观测值。我们将使用<strong>poverty</strong> 和<strong>single</strong>预测<strong>crime</strong>.</p> 
<pre><code class="prism language-r">library<span class="token punctuation">(</span>foreign<span class="token punctuation">)</span>
library<span class="token punctuation">(</span>MASS<span class="token punctuation">)</span>

cdata <span class="token operator">&lt;-</span> read.dta<span class="token punctuation">(</span><span class="token string">"https://stats.idre.ucla.edu/stat/data/crime.dta"</span><span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>cdata<span class="token punctuation">)</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">      sid          state               crime            murder          pctmetro         pctwhite    
 Min.   <span class="token operator">:</span> <span class="token number">1.0</span>   Length<span class="token operator">:</span><span class="token number">51</span>          Min.   <span class="token operator">:</span>  <span class="token number">82.0</span>   Min.   <span class="token operator">:</span> <span class="token number">1.600</span>   Min.   <span class="token operator">:</span> <span class="token number">24.00</span>   Min.   <span class="token operator">:</span><span class="token number">31.80</span>  
 <span class="token number">1</span>st Qu.<span class="token operator">:</span><span class="token number">13.5</span>   Class <span class="token operator">:</span>character   <span class="token number">1</span>st Qu.<span class="token operator">:</span> <span class="token number">326.5</span>   <span class="token number">1</span>st Qu.<span class="token operator">:</span> <span class="token number">3.900</span>   <span class="token number">1</span>st Qu.<span class="token operator">:</span> <span class="token number">49.55</span>   <span class="token number">1</span>st Qu.<span class="token operator">:</span><span class="token number">79.35</span>  
 Median <span class="token operator">:</span><span class="token number">26.0</span>   Mode  <span class="token operator">:</span>character   Median <span class="token operator">:</span> <span class="token number">515.0</span>   Median <span class="token operator">:</span> <span class="token number">6.800</span>   Median <span class="token operator">:</span> <span class="token number">69.80</span>   Median <span class="token operator">:</span><span class="token number">87.60</span>  
 Mean   <span class="token operator">:</span><span class="token number">26.0</span>                      Mean   <span class="token operator">:</span> <span class="token number">612.8</span>   Mean   <span class="token operator">:</span> <span class="token number">8.727</span>   Mean   <span class="token operator">:</span> <span class="token number">67.39</span>   Mean   <span class="token operator">:</span><span class="token number">84.12</span>  
 <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">38.5</span>                      <span class="token number">3</span>rd Qu.<span class="token operator">:</span> <span class="token number">773.0</span>   <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">10.350</span>   <span class="token number">3</span>rd Qu.<span class="token operator">:</span> <span class="token number">83.95</span>   <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">92.60</span>  
 Max.   <span class="token operator">:</span><span class="token number">51.0</span>                      Max.   <span class="token operator">:</span><span class="token number">2922.0</span>   Max.   <span class="token operator">:</span><span class="token number">78.500</span>   Max.   <span class="token operator">:</span><span class="token number">100.00</span>   Max.   <span class="token operator">:</span><span class="token number">98.50</span>  
     pcths          poverty          single     
 Min.   <span class="token operator">:</span><span class="token number">64.30</span>   Min.   <span class="token operator">:</span> <span class="token number">8.00</span>   Min.   <span class="token operator">:</span> <span class="token number">8.40</span>  
 <span class="token number">1</span>st Qu.<span class="token operator">:</span><span class="token number">73.50</span>   <span class="token number">1</span>st Qu.<span class="token operator">:</span><span class="token number">10.70</span>   <span class="token number">1</span>st Qu.<span class="token operator">:</span><span class="token number">10.05</span>  
 Median <span class="token operator">:</span><span class="token number">76.70</span>   Median <span class="token operator">:</span><span class="token number">13.10</span>   Median <span class="token operator">:</span><span class="token number">10.90</span>  
 Mean   <span class="token operator">:</span><span class="token number">76.22</span>   Mean   <span class="token operator">:</span><span class="token number">14.26</span>   Mean   <span class="token operator">:</span><span class="token number">11.33</span>  
 <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">80.10</span>   <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">17.40</span>   <span class="token number">3</span>rd Qu.<span class="token operator">:</span><span class="token number">12.05</span>  
 Max.   <span class="token operator">:</span><span class="token number">86.60</span>   Max.   <span class="token operator">:</span><span class="token number">26.40</span>   Max.   <span class="token operator">:</span><span class="token number">22.10</span>  
</code></pre> 
<h3><a id="_48"></a>使用普通最小二乘回归</h3> 
<pre><code class="prism language-r">summary<span class="token punctuation">(</span>ols <span class="token operator">&lt;-</span> lm<span class="token punctuation">(</span>crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data <span class="token operator">=</span> cdata<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">Call<span class="token operator">:</span>
lm<span class="token punctuation">(</span>formula <span class="token operator">=</span> crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data <span class="token operator">=</span> cdata<span class="token punctuation">)</span>

Residuals<span class="token operator">:</span>
    Min      <span class="token number">1</span>Q  Median      <span class="token number">3</span>Q     Max 
<span class="token operator">-</span><span class="token number">811.14</span> <span class="token operator">-</span><span class="token number">114.27</span>  <span class="token operator">-</span><span class="token number">22.44</span>  <span class="token number">121.86</span>  <span class="token number">689.82</span> 

Coefficients<span class="token operator">:</span>
             Estimate Std. Error t value Pr<span class="token punctuation">(</span><span class="token operator">&gt;</span><span class="token operator">|</span>t<span class="token operator">|</span><span class="token punctuation">)</span>    
<span class="token punctuation">(</span>Intercept<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1368.189</span>    <span class="token number">187.205</span>  <span class="token operator">-</span><span class="token number">7.308</span> <span class="token number">2.48e-09</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
poverty         <span class="token number">6.787</span>      <span class="token number">8.989</span>   <span class="token number">0.755</span>    <span class="token number">0.454</span>    
single        <span class="token number">166.373</span>     <span class="token number">19.423</span>   <span class="token number">8.566</span> <span class="token number">3.12e-11</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Signif. codes<span class="token operator">:</span>  <span class="token number">0</span> ‘<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>’ <span class="token number">0.001</span> ‘<span class="token operator">*</span><span class="token operator">*</span>’ <span class="token number">0.01</span> ‘<span class="token operator">*</span>’ <span class="token number">0.05</span> ‘.’ <span class="token number">0.1</span> ‘ ’ <span class="token number">1</span>

Residual standard error<span class="token operator">:</span> <span class="token number">243.6</span> on <span class="token number">48</span> degrees of freedom
Multiple R<span class="token operator">-</span>squared<span class="token operator">:</span>  <span class="token number">0.7072</span><span class="token punctuation">,</span>	Adjusted R<span class="token operator">-</span>squared<span class="token operator">:</span>  <span class="token number">0.695</span> 
F<span class="token operator">-</span>statistic<span class="token operator">:</span> <span class="token number">57.96</span> on <span class="token number">2</span> and <span class="token number">48</span> DF<span class="token punctuation">,</span>  p<span class="token operator">-</span>value<span class="token operator">:</span> <span class="token number">1.578e-13</span>
</code></pre> 
<p>我们来看一下普通最小二乘回归的诊断图</p> 
<pre><code class="prism language-r">opar <span class="token operator">&lt;-</span> par<span class="token punctuation">(</span>mfrow <span class="token operator">=</span> c<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> oma <span class="token operator">=</span> c<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plot<span class="token punctuation">(</span>ols<span class="token punctuation">,</span> las <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果如下：<br> <img src="https://images2.imgbox.com/76/7b/VNjUBjI2_o.png" alt="回归诊断">从这些图中，我们可以确定观测值9、25和51对我们的模型可能存在问题。我们可以查看这些观察值，以了解它们所代表的状态。</p> 
<pre><code class="prism language-r">par<span class="token punctuation">(</span>opar<span class="token punctuation">)</span>
cdata<span class="token punctuation">[</span>c<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">   sid state
<span class="token number">9</span>    <span class="token number">9</span>    fl
<span class="token number">25</span>  <span class="token number">25</span>    ms
<span class="token number">51</span>  <span class="token number">51</span>    dc
</code></pre> 
<p>哥伦比亚特区，佛罗里达州和密西西比州的杠杆率很高或残差很大。我们可以显示具有较大Cook值的观测值。常规的截止点是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
         / 
        
       
         4 
        
       
      
        n/4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">n</span><span class="mord">/</span><span class="mord">4</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
      
        n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">n</span></span></span></span></span>是数据集中的观察数。我们将使用此条件来选择要显示的值。</p> 
<pre><code class="prism language-r">d1 <span class="token operator">&lt;-</span> cooks.distance<span class="token punctuation">(</span>ols<span class="token punctuation">)</span>
r <span class="token operator">&lt;-</span> stdres<span class="token punctuation">(</span>ols<span class="token punctuation">)</span>
a <span class="token operator">&lt;-</span> cbind<span class="token punctuation">(</span>cdata<span class="token punctuation">,</span> d1<span class="token punctuation">,</span> r<span class="token punctuation">)</span>
a<span class="token punctuation">[</span>d1 <span class="token operator">&gt;</span> <span class="token number">4</span><span class="token operator">/</span><span class="token number">51</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">   sid state crime murder pctmetro pctwhite pcths poverty single        d1         r
<span class="token number">1</span>    <span class="token number">1</span>    ak   <span class="token number">761</span>    <span class="token number">9.0</span>     <span class="token number">41.8</span>     <span class="token number">75.2</span>  <span class="token number">86.6</span>     <span class="token number">9.1</span>   <span class="token number">14.3</span> <span class="token number">0.1254750</span> <span class="token operator">-</span><span class="token number">1.397418</span>
<span class="token number">9</span>    <span class="token number">9</span>    fl  <span class="token number">1206</span>    <span class="token number">8.9</span>     <span class="token number">93.0</span>     <span class="token number">83.5</span>  <span class="token number">74.4</span>    <span class="token number">17.8</span>   <span class="token number">10.6</span> <span class="token number">0.1425891</span>  <span class="token number">2.902663</span>
<span class="token number">25</span>  <span class="token number">25</span>    ms   <span class="token number">434</span>   <span class="token number">13.5</span>     <span class="token number">30.7</span>     <span class="token number">63.3</span>  <span class="token number">64.3</span>    <span class="token number">24.7</span>   <span class="token number">14.7</span> <span class="token number">0.6138721</span> <span class="token operator">-</span><span class="token number">3.562990</span>
<span class="token number">51</span>  <span class="token number">51</span>    dc  <span class="token number">2922</span>   <span class="token number">78.5</span>    <span class="token number">100.0</span>     <span class="token number">31.8</span>  <span class="token number">73.1</span>    <span class="token number">26.4</span>   <span class="token number">22.1</span> <span class="token number">2.6362519</span>  <span class="token number">2.616447</span>
</code></pre> 
<p>因为DC不是州，所以我们可能应该先删除DC。我们将其包括在分析中只是为了表明它具有大的Cook距离并演示如何使用rlm。现在我们来看一下残差。我们将生成一个名为的新变量absr1，它是残差的绝对值（因为残差的符号无关紧要）。然后，我们打印出具有最高绝对残差值的十个观测值。</p> 
<pre><code class="prism language-r">rabs <span class="token operator">&lt;-</span> abs<span class="token punctuation">(</span>r<span class="token punctuation">)</span>
a <span class="token operator">&lt;-</span> cbind<span class="token punctuation">(</span>cdata<span class="token punctuation">,</span> d1<span class="token punctuation">,</span> r<span class="token punctuation">,</span> rabs<span class="token punctuation">)</span>
asorted <span class="token operator">&lt;-</span> a<span class="token punctuation">[</span>order<span class="token punctuation">(</span><span class="token operator">-</span>rabs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
asorted<span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">   sid state crime murder pctmetro pctwhite pcths poverty single         d1         r     rabs
<span class="token number">25</span>  <span class="token number">25</span>    ms   <span class="token number">434</span>   <span class="token number">13.5</span>     <span class="token number">30.7</span>     <span class="token number">63.3</span>  <span class="token number">64.3</span>    <span class="token number">24.7</span>   <span class="token number">14.7</span> <span class="token number">0.61387212</span> <span class="token operator">-</span><span class="token number">3.562990</span> <span class="token number">3.562990</span>
<span class="token number">9</span>    <span class="token number">9</span>    fl  <span class="token number">1206</span>    <span class="token number">8.9</span>     <span class="token number">93.0</span>     <span class="token number">83.5</span>  <span class="token number">74.4</span>    <span class="token number">17.8</span>   <span class="token number">10.6</span> <span class="token number">0.14258909</span>  <span class="token number">2.902663</span> <span class="token number">2.902663</span>
<span class="token number">51</span>  <span class="token number">51</span>    dc  <span class="token number">2922</span>   <span class="token number">78.5</span>    <span class="token number">100.0</span>     <span class="token number">31.8</span>  <span class="token number">73.1</span>    <span class="token number">26.4</span>   <span class="token number">22.1</span> <span class="token number">2.63625193</span>  <span class="token number">2.616447</span> <span class="token number">2.616447</span>
<span class="token number">46</span>  <span class="token number">46</span>    vt   <span class="token number">114</span>    <span class="token number">3.6</span>     <span class="token number">27.0</span>     <span class="token number">98.4</span>  <span class="token number">80.8</span>    <span class="token number">10.0</span>   <span class="token number">11.0</span> <span class="token number">0.04271548</span> <span class="token operator">-</span><span class="token number">1.742409</span> <span class="token number">1.742409</span>
<span class="token number">26</span>  <span class="token number">26</span>    mt   <span class="token number">178</span>    <span class="token number">3.0</span>     <span class="token number">24.0</span>     <span class="token number">92.6</span>  <span class="token number">81.0</span>    <span class="token number">14.9</span>   <span class="token number">10.8</span> <span class="token number">0.01675501</span> <span class="token operator">-</span><span class="token number">1.460885</span> <span class="token number">1.460885</span>
<span class="token number">21</span>  <span class="token number">21</span>    me   <span class="token number">126</span>    <span class="token number">1.6</span>     <span class="token number">35.7</span>     <span class="token number">98.5</span>  <span class="token number">78.8</span>    <span class="token number">10.7</span>   <span class="token number">10.6</span> <span class="token number">0.02233128</span> <span class="token operator">-</span><span class="token number">1.426741</span> <span class="token number">1.426741</span>
<span class="token number">1</span>    <span class="token number">1</span>    ak   <span class="token number">761</span>    <span class="token number">9.0</span>     <span class="token number">41.8</span>     <span class="token number">75.2</span>  <span class="token number">86.6</span>     <span class="token number">9.1</span>   <span class="token number">14.3</span> <span class="token number">0.12547500</span> <span class="token operator">-</span><span class="token number">1.397418</span> <span class="token number">1.397418</span>
<span class="token number">31</span>  <span class="token number">31</span>    nj   <span class="token number">627</span>    <span class="token number">5.3</span>    <span class="token number">100.0</span>     <span class="token number">80.8</span>  <span class="token number">76.7</span>    <span class="token number">10.9</span>    <span class="token number">9.6</span> <span class="token number">0.02229184</span>  <span class="token number">1.354149</span> <span class="token number">1.354149</span>
<span class="token number">14</span>  <span class="token number">14</span>    il   <span class="token number">960</span>   <span class="token number">11.4</span>     <span class="token number">84.0</span>     <span class="token number">81.0</span>  <span class="token number">76.2</span>    <span class="token number">13.6</span>   <span class="token number">11.5</span> <span class="token number">0.01265689</span>  <span class="token number">1.338192</span> <span class="token number">1.338192</span>
<span class="token number">20</span>  <span class="token number">20</span>    md   <span class="token number">998</span>   <span class="token number">12.7</span>     <span class="token number">92.8</span>     <span class="token number">68.9</span>  <span class="token number">78.4</span>     <span class="token number">9.7</span>   <span class="token number">12.0</span> <span class="token number">0.03569623</span>  <span class="token number">1.287087</span> <span class="token number">1.287087</span>
</code></pre> 
<h3><a id="_136"></a>使用稳健回归</h3> 
<p>现在让我们运行第一个稳健的回归。通过迭代的重新加权最小二乘法（IRLS）进行稳健的回归。运行稳定回归的指令是rlm在MASS包。有几种加权功能可用于IRLS。在本示例中，我们将首先使用Huber权重。然后，我们将查看由IRLS流程创建的最终权重。这可能非常有用。</p> 
<pre><code class="prism language-r">summary<span class="token punctuation">(</span>rr.huber <span class="token operator">&lt;-</span> rlm<span class="token punctuation">(</span>crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data <span class="token operator">=</span> cdata<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">Call<span class="token operator">:</span> rlm<span class="token punctuation">(</span>formula <span class="token operator">=</span> crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data <span class="token operator">=</span> cdata<span class="token punctuation">)</span>
Residuals<span class="token operator">:</span>
    Min      <span class="token number">1</span>Q  Median      <span class="token number">3</span>Q     Max 
<span class="token operator">-</span><span class="token number">846.09</span> <span class="token operator">-</span><span class="token number">125.80</span>  <span class="token operator">-</span><span class="token number">16.49</span>  <span class="token number">119.15</span>  <span class="token number">679.94</span> 

Coefficients<span class="token operator">:</span>
            Value      Std. Error t value   
<span class="token punctuation">(</span>Intercept<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1423.0373</span>   <span class="token number">167.5899</span>    <span class="token operator">-</span><span class="token number">8.4912</span>
poverty         <span class="token number">8.8677</span>     <span class="token number">8.0467</span>     <span class="token number">1.1020</span>
single        <span class="token number">168.9858</span>    <span class="token number">17.3878</span>     <span class="token number">9.7186</span>

Residual standard error<span class="token operator">:</span> <span class="token number">181.8</span> on <span class="token number">48</span> degrees of freedom
</code></pre> 
<p>我们来看一下各观测点的权重。</p> 
<pre><code class="prism language-r">hweights <span class="token operator">&lt;-</span> data.frame<span class="token punctuation">(</span>state <span class="token operator">=</span> cdata<span class="token operator">$</span>state<span class="token punctuation">,</span> resid <span class="token operator">=</span> rr.huber<span class="token operator">$</span>resid<span class="token punctuation">,</span> weight <span class="token operator">=</span> rr.huber<span class="token operator">$</span>w<span class="token punctuation">)</span>
hweights2 <span class="token operator">&lt;-</span> hweights<span class="token punctuation">[</span>order<span class="token punctuation">(</span>rr.huber<span class="token operator">$</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
hweights2<span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">   state      resid    weight
<span class="token number">25</span>    ms <span class="token operator">-</span><span class="token number">846.08536</span> <span class="token number">0.2889618</span>
<span class="token number">9</span>     fl  <span class="token number">679.94327</span> <span class="token number">0.3595480</span>
<span class="token number">46</span>    vt <span class="token operator">-</span><span class="token number">410.48310</span> <span class="token number">0.5955740</span>
<span class="token number">51</span>    dc  <span class="token number">376.34468</span> <span class="token number">0.6494131</span>
<span class="token number">26</span>    mt <span class="token operator">-</span><span class="token number">356.13760</span> <span class="token number">0.6864625</span>
<span class="token number">21</span>    me <span class="token operator">-</span><span class="token number">337.09622</span> <span class="token number">0.7252263</span>
<span class="token number">31</span>    nj  <span class="token number">331.11603</span> <span class="token number">0.7383578</span>
<span class="token number">14</span>    il  <span class="token number">319.10036</span> <span class="token number">0.7661169</span>
<span class="token number">1</span>     ak <span class="token operator">-</span><span class="token number">313.15532</span> <span class="token number">0.7807432</span>
<span class="token number">20</span>    md  <span class="token number">307.19142</span> <span class="token number">0.7958154</span>
<span class="token number">19</span>    ma  <span class="token number">291.20817</span> <span class="token number">0.8395172</span>
<span class="token number">18</span>    la <span class="token operator">-</span><span class="token number">266.95752</span> <span class="token number">0.9159411</span>
<span class="token number">2</span>     al  <span class="token number">105.40319</span> <span class="token number">1.0000000</span>
<span class="token number">3</span>     ar   <span class="token number">30.53589</span> <span class="token number">1.0000000</span>
<span class="token number">4</span>     az  <span class="token operator">-</span><span class="token number">43.25299</span> <span class="token number">1.0000000</span>
</code></pre> 
<p>我们可以粗略地看到，随着绝对残差的减少，权重也会增加。换句话说，残差较大的情况倾向于权重降低。此输出向我们显示，密西西比州的观测值将被最大程度地降低权重。佛罗里达州的权重也将大大降低。上面未显示的所有观察值的权重均为1。在OLS回归中，所有情况的权重均为1。因此，稳健回归中权重接近1的案例越多，OLS和稳健回归的结果越接近。</p> 
<p>接下来，让我们运行相同的模型，但是使用双向平方加权函数。同样，我们可以看一下权重。</p> 
<pre><code class="prism language-r">rr.bisquare <span class="token operator">&lt;-</span> rlm<span class="token punctuation">(</span>crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data<span class="token operator">=</span>cdata<span class="token punctuation">,</span> psi <span class="token operator">=</span> psi.bisquare<span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>rr.bisquare<span class="token punctuation">)</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">Call<span class="token operator">:</span> rlm<span class="token punctuation">(</span>formula <span class="token operator">=</span> crime <span class="token operator">~</span> poverty <span class="token operator">+</span> single<span class="token punctuation">,</span> data <span class="token operator">=</span> cdata<span class="token punctuation">,</span> psi <span class="token operator">=</span> psi.bisquare<span class="token punctuation">)</span>
Residuals<span class="token operator">:</span>
    Min      <span class="token number">1</span>Q  Median      <span class="token number">3</span>Q     Max 
<span class="token operator">-</span><span class="token number">905.59</span> <span class="token operator">-</span><span class="token number">140.97</span>  <span class="token operator">-</span><span class="token number">14.98</span>  <span class="token number">114.65</span>  <span class="token number">668.38</span> 

Coefficients<span class="token operator">:</span>
            Value      Std. Error t value   
<span class="token punctuation">(</span>Intercept<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1535.3338</span>   <span class="token number">164.5062</span>    <span class="token operator">-</span><span class="token number">9.3330</span>
poverty        <span class="token number">11.6903</span>     <span class="token number">7.8987</span>     <span class="token number">1.4800</span>
single        <span class="token number">175.9303</span>    <span class="token number">17.0678</span>    <span class="token number">10.3077</span>

Residual standard error<span class="token operator">:</span> <span class="token number">202.3</span> on <span class="token number">48</span> degrees of freedom
</code></pre> 
<p>我们来看一下各观测点的权重：</p> 
<pre><code class="prism language-r">biweights <span class="token operator">&lt;-</span> data.frame<span class="token punctuation">(</span>state <span class="token operator">=</span> cdata<span class="token operator">$</span>state<span class="token punctuation">,</span> resid <span class="token operator">=</span> rr.bisquare<span class="token operator">$</span>resid<span class="token punctuation">,</span> weight <span class="token operator">=</span> rr.bisquare<span class="token operator">$</span>w<span class="token punctuation">)</span>
biweights2 <span class="token operator">&lt;-</span> biweights<span class="token punctuation">[</span>order<span class="token punctuation">(</span>rr.bisquare<span class="token operator">$</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
biweights2<span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
</code></pre> 
<p>结果为</p> 
<pre><code class="prism language-r">   state     resid      weight
<span class="token number">25</span>    ms <span class="token operator">-</span><span class="token number">905.5931</span> <span class="token number">0.007652565</span>
<span class="token number">9</span>     fl  <span class="token number">668.3844</span> <span class="token number">0.252870542</span>
<span class="token number">46</span>    vt <span class="token operator">-</span><span class="token number">402.8031</span> <span class="token number">0.671495418</span>
<span class="token number">26</span>    mt <span class="token operator">-</span><span class="token number">360.8997</span> <span class="token number">0.731136908</span>
<span class="token number">31</span>    nj  <span class="token number">345.9780</span> <span class="token number">0.751347695</span>
<span class="token number">18</span>    la <span class="token operator">-</span><span class="token number">332.6527</span> <span class="token number">0.768938330</span>
<span class="token number">21</span>    me <span class="token operator">-</span><span class="token number">328.6143</span> <span class="token number">0.774103322</span>
<span class="token number">1</span>     ak <span class="token operator">-</span><span class="token number">325.8519</span> <span class="token number">0.777662383</span>
<span class="token number">14</span>    il  <span class="token number">313.1466</span> <span class="token number">0.793658594</span>
<span class="token number">20</span>    md  <span class="token number">308.7737</span> <span class="token number">0.799065530</span>
<span class="token number">19</span>    ma  <span class="token number">297.6068</span> <span class="token number">0.812596833</span>
<span class="token number">51</span>    dc  <span class="token number">260.6489</span> <span class="token number">0.854441716</span>
<span class="token number">50</span>    wy <span class="token operator">-</span><span class="token number">234.1952</span> <span class="token number">0.881660897</span>
<span class="token number">5</span>     ca  <span class="token number">201.4407</span> <span class="token number">0.911713981</span>
<span class="token number">10</span>    ga <span class="token operator">-</span><span class="token number">186.5799</span> <span class="token number">0.924033113</span>
</code></pre> 
<p>我们可以看到，使用bisquare 加权函数比使用Huber 加权函数给密西西比州的加权显着更低，并且这两种不同加权方法的参数估计值也不同。在比较常规OLS回归和稳健回归的结果时，如果结果非常不同，最好使用稳健回归的结果。较大的差异表明模型参数受到异常值的高度影响。不同的权函数各有利弊。Huber权重可能会遇到严重的离群值，而Bisquare权重可能会难以收敛或可能产生多个解。</p> 
<p>两次分析的结果有很大不同，尤其是在系数single和常数（intercept）方面。虽然通常我们对常量不感兴趣，但是如果将一个或两个预测变量居中，则该常量将很有用。另一方面，注意到这poverty两种分析在统计上都不显着，而single在两种分析中均显着。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/056a7df5b8f6e50171110a0cc7da2965/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">js文件引用i18n国际化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b922f553331d9c72ff5ad5d1cacf59ff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">网络信号_网络信号总是连接超时？手机信号增强器值得你入手</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>