<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>目标检测新范式！港大同济伯克利提出Sparse R-CNN，代码刚刚开源！ - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="目标检测新范式！港大同济伯克利提出Sparse R-CNN，代码刚刚开源！" />
<meta property="og:description" content="​Sparse R-CNN: End-to-End Object Detection with Learnable Proposals
沿着目标检测领域中Dense和Dense-to-Sparse的框架，Sparse R-CNN建立了一种彻底的Sparse框架， 脱离anchor box，reference point，Region Proposal Network(RPN)等概念，无需Non-Maximum Suppression(NMS)后处理， 在标准的COCO benchmark上使用ResNet-50 FPN单模型在标准3x training schedule达到了44.5 AP和 22 FPS。
代码: https://github.com/PeizeSun/SparseR-CNN
论文链接: https://msc.berkeley.edu/research/autonomous-vehicle/sparse_rcnn.pdf
1. Motivation
我们先简单回顾一下目标检测领域中主流的两大类方法。
第一大类是从非Deep时代就被广泛应用的dense detector，例如DPM，YOLO，RetinaNet，FCOS。在dense detector中， 大量的object candidates例如sliding-windows，anchor-boxes， reference-points等被提前预设在图像网格或者特征图网格上，然后直接预测这些candidates到gt的scaling/offest和物体类别。第二大类是dense-to-sparse detector，例如，R-CNN家族。这类方法的特点是对一组sparse的candidates预测回归和分类，而这组sparse的candidates来自于dense detector。 这两类框架推动了整个领域的学术研究和工业应用。目标检测领域看似已经饱和，然而dense属性的一些固有局限总让人难以满意：
NMS 后处理many-to-one 正负样本分配prior candidates的设计 所以，一个很自然的思考方向就是：能不能设计一种彻底的sparse框架？最近，DETR给出了一种sparse的设计方案。candidates是一组sparse的learnable object queries，正负样本分配是one-to-one的optimal bipartite matching，无需nms直接输出最终的检测结果。然而，DETR中每个object query都和全局的特征图做attention交互，这本质上也是dense。而我们认为，sparse的检测框架应该体现在两个方面：sparse candidates和sparse feature interaction。基于此，我们提出了Sparse R-CNN。
Sparse R-CNN抛弃了anchor boxes或者reference point等dense概念，直接从a sparse set of learnable proposals出发，没有NMS后处理，整个网络异常干净和简洁，可以看做是一个全新的检测范式。
2.Sparse R-CNN
Sparse R-CNN的object candidates是一组可学习的参数，N*4，N代表object candidates的个数，一般为100～300，4代表物体框的四个边界。这组参数和整个网络中的其他参数一起被训练优化。That&#39;s it，完全没有dense detector中成千上万的枚举。这组sparse的object candidates作为proposal boxes用以提取Region of Interest(RoI)，预测回归和分类。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ca24a1dbc9b0f33989104fe1eb64b54e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-27T12:36:06+08:00" />
<meta property="article:modified_time" content="2020-11-27T12:36:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">目标检测新范式！港大同济伯克利提出Sparse R-CNN，代码刚刚开源！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>​<em>Sparse R-CNN: End-to-End Object Detection with Learnable Proposals</em></p> 
<p><img alt="" src="https://images2.imgbox.com/3e/2f/6Ns1Qfgo_o.png" width="1080"></p> 
<p> </p> 
<blockquote> 
 <p>沿着目标检测领域中Dense和Dense-to-Sparse的框架，Sparse R-CNN建立了一种彻底的Sparse框架， 脱离anchor box，reference point，Region Proposal Network(RPN)等概念，无需Non-Maximum Suppression(NMS)后处理， 在标准的COCO benchmark上使用ResNet-50 FPN单模型在标准3x training schedule达到了44.5 AP和 22 FPS。</p> 
</blockquote> 
<p> </p> 
<p>代码: <a href="https://github.com/PeizeSun/SparseR-CNN"><strong>https://github.com/PeizeSun/SparseR-CNN</strong></a></p> 
<p>论文链接: </p> 
<p><a href="https://msc.berkeley.edu/research/autonomous-vehicle/sparse_rcnn.pdf" rel="nofollow">https://msc.berkeley.edu/research/autonomous-vehicle/sparse_rcnn.pdf</a></p> 
<h3> </h3> 
<p>1. Motivation</p> 
<p><img alt="" src="https://images2.imgbox.com/bd/fc/2VVpmwnP_o.png" width="1080"></p> 
<p> </p> 
<p>我们先简单回顾一下目标检测领域中主流的两大类方法。</p> 
<ul><li>第一大类是从非Deep时代就被广泛应用的dense detector，例如DPM，YOLO，RetinaNet，FCOS。在dense detector中， 大量的object candidates例如sliding-windows，anchor-boxes， reference-points等被提前预设在图像网格或者特征图网格上，然后直接预测这些candidates到gt的scaling/offest和物体类别。</li><li>第二大类是dense-to-sparse detector，例如，R-CNN家族。这类方法的特点是对一组sparse的candidates预测回归和分类，而这组sparse的candidates来自于dense detector。</li></ul> 
<p>这两类框架推动了整个领域的学术研究和工业应用。目标检测领域看似已经饱和，然而dense属性的一些固有局限总让人难以满意：</p> 
<ul><li>NMS 后处理</li><li>many-to-one 正负样本分配</li><li>prior candidates的设计</li></ul> 
<p>所以，一个很自然的思考方向就是：能不能设计一种彻底的sparse框架？最近，DETR给出了一种sparse的设计方案。candidates是一组sparse的learnable object queries，正负样本分配是one-to-one的optimal bipartite matching，无需nms直接输出最终的检测结果。然而，DETR中每个object query都和全局的特征图做attention交互，这本质上也是dense。而我们认为，sparse的检测框架应该体现在两个方面：sparse candidates和sparse feature interaction。基于此，我们提出了Sparse R-CNN。</p> 
<p>Sparse R-CNN抛弃了anchor boxes或者reference point等dense概念，直接从a sparse set of learnable proposals出发，没有NMS后处理，整个网络异常干净和简洁，可以看做是一个全新的检测范式。</p> 
<p><img alt="" src="https://images2.imgbox.com/14/ab/6NLwMvT9_o.png" width="905"></p> 
<p> </p> 
<h3> </h3> 
<p>2.Sparse R-CNN</p> 
<p>Sparse R-CNN的object candidates是一组可学习的参数，N*4，N代表object candidates的个数，一般为100～300，4代表物体框的四个边界。这组参数和整个网络中的其他参数一起被训练优化。That's it，完全没有dense detector中成千上万的枚举。这组sparse的object candidates作为proposal boxes用以提取Region of Interest(RoI)，预测回归和分类。</p> 
<p><img alt="" src="https://images2.imgbox.com/0f/0f/MXoXUqVe_o.png" width="603"></p> 
<p> </p> 
<p>这组学习到的proposal boxes可以理解为图像中可能出现物体的位置的统计值，这样coarse的表征提取出来的RoI feature显然不足以精确定位和分类物体。于是，我们引入一种特征层面的candidates，proposal features，这也是一组可学习的参数，N*d，N代表object candidates的个数，与proposal boxes一一对应，d代表feature的维度，一般为256。这组proposal features与proposal boxes提取出来的RoI feature做一对一的交互，从而使得RoI feature的特征更有利于定位和分类物体。相比于原始的2-fc Head，我们的设计称为Dynamic Instance Interactive Head.</p> 
<p><img alt="" src="https://images2.imgbox.com/40/7c/CPCO22Lg_o.png" width="584"></p> 
<p> </p> 
<p>Sparse R-CNN的两个显著特点就是sparse object candidates和sparse feature interaction，既没有dense的成千上万的candidates，也没有dense的global feature interaction。Sparse R-CNN可以看作是目标检测框架从dense到dense-to-sparse到sparse的一个方向拓展。</p> 
<h3> </h3> 
<p>3. Architecture Design</p> 
<p>Sparse R-CNN的网络设计原型是R-CNN家族。</p> 
<ul><li>Backbone是基于ResNet的FPN。</li><li>Head是一组iterative的Dynamic Instance Interactive Head，上一个head的output features和output boxes作为下一个head的proposal features和proposal boxes。Proposal features在与RoI features交互之前做self-attention。</li><li>训练的损失函数是基于optimal bipartite matching的set prediction loss。</li></ul> 
<p><img alt="" src="https://images2.imgbox.com/fb/e8/VXJlA6Dx_o.png" width="1080"></p> 
<p> </p> 
<p> </p> 
<p>从Faster R-CNN(40.2 AP)出发，直接将RPN替换为a sparse set of learnable proposal boxes，AP降到18.5；引入iterative结构提升AP到32.2；引入dynamic instance interaction最终提升到42.3 AP。</p> 
<h3> </h3> 
<p>4. Performance</p> 
<p>我们沿用了Detectron2的3x training schedule，因此将Sparse R-CNN和Detectorn2中的detectors做比较（很多方法没有报道3x的性能，所以没有列出)。同时，我们也列出了同样不需要NMS后处理的DETR和Deformable DETR的性能。Sparse R-CNN在检测精度，推理时间和训练收敛速度都展现了相当有竞争力的性能。</p> 
<p><img alt="" src="https://images2.imgbox.com/9e/22/wjxi01Of_o.png" width="1080"></p> 
<p> </p> 
<h3> </h3> 
<p>5. Conclusion</p> 
<p>R-CNN和Fast R-CNN出现后的一段时期内，目标检测领域的一个重要研究方向是提出更高效的region proposal generator。Faster R-CNN和RPN作为其中的佼佼者展现出广泛而持续的影响力。Sparse R-CNN首次展示了简单的一组可学习的参数作为proposal boxes即可达到comparable的性能。我们希望我们的工作能够带给大家一些关于end-to-end object detection的启发。</p> 
<p> </p> 
<p><em>接下来，给大家介绍一下租用GPU做实验的方法，我们是在智星云租用的GPU，使用体验很好。具体大家可以参考：智星云官网：</em><em> </em><a href="http://www.ai-galaxy.cn/" rel="nofollow"><em>http://www.ai-galaxy.cn/</em></a><em>，淘宝店：</em><a href="https://shop36573300.taobao.com/" rel="nofollow"><em>https://shop36573300.taobao.com/</em></a><em>公众号</em><em>: </em><em>智星</em><em>AI</em></p> 
<p><img alt="" src="https://images2.imgbox.com/21/dd/yyFnfNKZ_o.png" width="367"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f0bc002a387444746b0928ef57c759a4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">pom文件下载</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6d3b3b4d08d9591e7f8b72afc7ec136f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[已解决] xshell连接不上linux虚拟机，找了无数方法，终于成功了，</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>