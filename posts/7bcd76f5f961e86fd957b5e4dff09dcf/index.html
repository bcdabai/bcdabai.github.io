<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Airflow2.0&#43;celery&#43;redis任务调度部署及使用 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Airflow2.0&#43;celery&#43;redis任务调度部署及使用" />
<meta property="og:description" content="Airflow任务调度 （本文档内容有同事贡献部分，该部分标记为蓝色，对同事表示感谢）
目录
一、环境
二、基础参数
三、任务类型
四、使用步骤
五、需要解决的问题（绿色表示已解决）
六、注意事项
一、环境 版本：airflow 2.0.0；python 3.6
部署方式：集群部署，运行在anaconda3的虚拟环境 (airflow)
* 节点7 [webserver、schuduler、worker]
* 节点8 [worker]
* 节点9 [worker、schuduler]
官网文档（最新）：http://airflow.apache.org/docs/apache-airflow/stable/start.html
非官方翻译中文文档（1.10.2）：https://airflow.apachecn.org/#/
二、基础参数 default_args = {
&#39;owner&#39;: &#39;***&#39;,
&#39;start_date&#39;: days_ago(1),
&#39;email&#39;: [&#39;xxx@qq.com&#39;],
&#39;email_on_failure&#39;: True,
&#39;email_on_retry&#39;: False,
&#39;retries&#39;: 1,
&#39;retry_delay&#39;: timedelta(seconds=50),
&#39;pool&#39;: &#39;test&#39;,
&#39;priority_weight&#39;: 100
}
baseoperator(
:param task_id: a unique, meaningful id for the task
:type task_id: str
:param owner: the owner of the task, using the unix username is recommended" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7bcd76f5f961e86fd957b5e4dff09dcf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-10T11:51:10+08:00" />
<meta property="article:modified_time" content="2021-04-10T11:51:10+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Airflow2.0&#43;celery&#43;redis任务调度部署及使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="Airflow%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6">Airflow任务调度</h2> 
<p> </p> 
<p>（本文档内容有同事贡献部分，该部分标记为蓝色，对同事表示感谢）</p> 
<h4> </h4> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E7%8E%AF%E5%A2%83-toc" style="margin-left:80px;"><a href="#%E4%B8%80%E3%80%81%E7%8E%AF%E5%A2%83" rel="nofollow">一、环境</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0-toc" style="margin-left:80px;"><a href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0" rel="nofollow">二、基础参数</a></p> 
<p id="%E4%B8%89%E3%80%81%E4%BB%BB%E5%8A%A1%E7%B1%BB%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%E4%B8%89%E3%80%81%E4%BB%BB%E5%8A%A1%E7%B1%BB%E5%9E%8B" rel="nofollow">三、任务类型</a></p> 
<p id="%E5%9B%9B%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4-toc" style="margin-left:80px;"><a href="#%E5%9B%9B%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4" rel="nofollow">四、使用步骤</a></p> 
<p id="%E4%BA%94%E3%80%81%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E7%BB%BF%E8%89%B2%E8%A1%A8%E7%A4%BA%E5%B7%B2%E8%A7%A3%E5%86%B3%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E4%BA%94%E3%80%81%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E7%BB%BF%E8%89%B2%E8%A1%A8%E7%A4%BA%E5%B7%B2%E8%A7%A3%E5%86%B3%EF%BC%89" rel="nofollow">五、需要解决的问题（绿色表示已解决）</a></p> 
<p id="%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-toc" style="margin-left:80px;"><a href="#%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9" rel="nofollow">六、注意事项</a></p> 
<hr id="hr-toc"> 
<h4>一、环境</h4> 
<p>版本：airflow 2.0.0；python 3.6</p> 
<p>部署方式：集群部署，运行在anaconda3的虚拟环境 (airflow)</p> 
<p>* 节点7 [webserver、schuduler、worker]</p> 
<p>* 节点8 [worker]</p> 
<p>* 节点9 [worker、schuduler]</p> 
<p>官网文档（最新）：http://airflow.apache.org/docs/apache-airflow/stable/start.html</p> 
<p>非官方翻译中文文档（1.10.2）：https://airflow.apachecn.org/#/</p> 
<h4 id="%E4%BA%8C%E3%80%81%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0">二、基础参数</h4> 
<blockquote> 
 <p>default_args = {<!-- --></p> 
 <p style="text-indent:33px;">'owner': '***',</p> 
 <p style="text-indent:33px;">'start_date': days_ago(1),</p> 
 <p style="text-indent:33px;">'email': ['xxx@qq.com'],</p> 
 <p style="text-indent:33px;">'email_on_failure': True,</p> 
 <p style="text-indent:33px;">'email_on_retry': False,</p> 
 <p style="text-indent:33px;">'retries': 1,</p> 
 <p style="text-indent:33px;">'retry_delay': timedelta(seconds=50),</p> 
 <p style="text-indent:33px;">'pool': 'test',</p> 
 <p style="text-indent:33px;">'priority_weight': 100</p> 
 <p>}</p> 
</blockquote> 
<blockquote> 
 <p>baseoperator(</p> 
 <p style="text-indent:33px;">:param task_id: a unique, meaningful id for the task</p> 
 <p style="text-indent:33px;">:type task_id: str</p> 
 <p style="text-indent:33px;">:param owner: the owner of the task, using the unix username is recommended</p> 
 <p style="text-indent:33px;">:type owner: str</p> 
 <p style="text-indent:33px;">:param email: the 'to' email address(es) used in email alerts. This can be a</p> 
 <p style="text-indent:33px;">single email or multiple ones. Multiple addresses can be specified as a</p> 
 <p style="text-indent:33px;">comma or semi-colon separated string or by passing a list of strings.</p> 
 <p style="text-indent:33px;">:type email: str or list[str]</p> 
 <p style="text-indent:33px;">:param email_on_retry: Indicates whether email alerts should be sent when a</p> 
 <p style="text-indent:33px;">task is retried</p> 
 <p style="text-indent:33px;">:type email_on_retry: bool</p> 
 <p style="text-indent:33px;">:param email_on_failure: Indicates whether email alerts should be sent when</p> 
 <p style="text-indent:33px;">a task failed</p> 
 <p style="text-indent:33px;">:type email_on_failure: bool</p> 
 <p style="text-indent:33px;">:param retries: the number of retries that should be performed before</p> 
 <p style="text-indent:33px;">failing the task</p> 
 <p style="text-indent:33px;">:type retries: int</p> 
 <p style="text-indent:33px;">:param retry_delay: delay between retries</p> 
 <p style="text-indent:33px;">:type retry_delay: datetime.timedelta</p> 
 <p style="text-indent:33px;">:param retry_exponential_backoff: allow progressive longer waits between</p> 
 <p style="text-indent:33px;">retries by using exponential backoff algorithm on retry delay (delay</p> 
 <p style="text-indent:33px;">will be converted into seconds)</p> 
 <p style="text-indent:33px;">:type retry_exponential_backoff: bool</p> 
 <p style="text-indent:33px;">:param max_retry_delay: maximum delay interval between retries</p> 
 <p style="text-indent:33px;">:type max_retry_delay: datetime.timedelta</p> 
 <p style="text-indent:33px;">:param start_date: The ``start_date`` for the task, determines</p> 
 <p style="text-indent:33px;">...详见baseoperator源码，注：baseoperator即基础operator。</p> 
 <p>)</p> 
</blockquote> 
<h4 id="%E4%B8%89%E3%80%81%E4%BB%BB%E5%8A%A1%E7%B1%BB%E5%9E%8B">三、任务类型</h4> 
<ol><li> <p>Bashoperator（运行方式为执行bash命令）。例如：</p> </li></ol> 
<blockquote> 
 <p>run_this = BashOperator(</p> 
 <p style="text-indent:33px;">task_id='run_after_loop',</p> 
 <p style="text-indent:33px;">bash_command='echo 1',</p> 
 <p style="text-indent:33px;">dag=dag</p> 
 <p>)</p> 
</blockquote> 
<p>注：可以通过ssh命令在远程机器上执行脚本或命令</p> 
<p>2.ExternalTaskSensor（可以用作dag之间依赖，感知前置dag或task执行状态，不必重复执行上层依赖）。例如：</p> 
<blockquote> 
 <p>child_1 = ExternalTaskSensor (</p> 
 <p style="text-indent:33px;">task_id = 'henry_1',</p> 
 <p style="text-indent:33px;">external_dag_id = 'henry_test',</p> 
 <p style="text-indent:33px;"># external_task_id = "task_1",</p> 
 <p style="text-indent:33px;">dag = dag</p> 
 <p>)</p> 
</blockquote> 
<p>3.LatestOnlyOperator（只运行最新的）。可以跳过在 DAG 的最近计划运行期间未运行的任务。例如：</p> 
<blockquote> 
 <p>dag = DAG(</p> 
 <p style="text-indent:33px;">dag_id='latest_only_with_trigger', </p> 
 <p style="text-indent:33px;">schedule_interval=dt.timedelta(hours=4), </p> 
 <p style="text-indent:33px;">start_date=dt.datetime(2016, 9, 20),</p> 
 <p>) </p> 
 <p>latest_only = LatestOnlyOperator(task_id='latest_only', dag=dag)</p> 
</blockquote> 
<p>4.ExternalTaskMarker（继承自DummyOperator, 该task被clear之后，下游的依赖任务也会递归的全都clear，默认深度10）暂时弃用。</p> 
<blockquote> 
 <p>parent_task = ExternalTaskMarker(</p> 
 <p style="text-indent:33px;">task_id="parent_task",</p> 
 <p style="text-indent:33px;">external_dag_id="example_external_task_marker_child",</p> 
 <p style="text-indent:33px;">external_task_id="child_task1",</p> 
 <p style="text-indent:33px;">dag = dag</p> 
 <p>)</p> 
</blockquote> 
<p><span style="color:#3399ea;">5. TriggerDagRunOperator（直接触发下游dag运行）</span></p> 
<blockquote> 
 <p><span style="color:#3399ea;">t2 = TriggerDagRunOperator(</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;">task_id='trigger_dag',</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;">trigger_dag_id='dag_1',</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># 被触发执行的dag的execution_date，str / datetime.datetime，加这个参数执行报错...</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># execution_date=datetime.datetime(2021, 3, 5, 8, 20),</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># reset_dag_run=True,</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># wait_for_completion=False,</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># Poke interval to check dag run status when wait_for_completion=True.</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;"># poke_interval=60,</span></p> 
 <p style="text-indent:33px;"><span style="color:#3399ea;">dag=dag,</span></p> 
 <p><span style="color:#3399ea;">)</span></p> 
</blockquote> 
<h4 id="%E5%9B%9B%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4">四、使用步骤</h4> 
<p>使用时，依次执行命令： </p> 
<p>1）source /home/***/anaconda3/bin/activate airflow     # 激活虚拟环境</p> 
<p>2）cd /home/***/airflow/dags    # 进入任务dags目录，然后创建自己名称的文件夹，将任务放入自己名下便于管理</p> 
<p>3）构建.py任务文件</p> 
<p>4）执行（依实际需要操作，可在web页面操作）</p> 
<p>* python 任务文件确保编译没问题</p> 
<p>* 运行task：airflow dags run &lt;dag_id&gt; &lt;task_id&gt; &lt;execution_date&gt;</p> 
<p>* 重跑/回溯历史任务：airflow dags backfill &lt;dag_id&gt;-s START_DATE -e END_DATE</p> 
<h4 id="%E4%BA%94%E3%80%81%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E7%BB%BF%E8%89%B2%E8%A1%A8%E7%A4%BA%E5%B7%B2%E8%A7%A3%E5%86%B3%EF%BC%89">五、需要解决的问题（绿色表示已解决）</h4> 
<p><span style="color:#86ca5e;">1.打通airflow和任务的时间参数，让页面操作的时间范围能正确带入到任务脚本</span></p> 
<p># The execution date as YYYY-MM-DD date ="{<!-- -->{ ds }}"t = BashOperator( task_id='test_env', bash_command='/tmp/test.sh ', dag=dag, env={'EXECUTION_DATE': date})</p> 
<p> </p> 
<pre><code>这里， {<!-- -->{ ds }}是一个宏，并且由于BashOperator的env参数是使用 Jinja 模板化的，因此执行日期将作为 Bash 脚本中名为EXECUTION_DATE的环境变量提供。

您可以将 Jinja 模板与文档中标记为“模板化”的每个参数一起使用。模板替换发生在调用运算符的 pre_execute 函数之前。

注意，由于airflow实际上接管了日期参数，多日重跑或者回溯的数据，实际上是由多个单日的任务组合而成，也就意味着原有的本身支持批量跑数的python脚本要改成单天执行的脚本，或者直接在bashoperator的bash_command中添加两个一样的时间参数{<!-- -->{ ds }}，如 bash_command="python test.py {<!-- -->{ ds }} {<!-- -->{ ds }}"，（不过原有脚本的一些功能可能就会发生改变，比如原来在时间范围循环内执行完多天统一发送邮件的，现在的效果则变成每天一封邮件）。
</code></pre> 
<p> </p> 
<p> </p> 
<p><span style="color:#86ca5e;">2.任务报警（邮件需要修改配置文件，配置邮件服务，才能使任务脚本中的邮件报警生效）</span></p> 
<p>直接修改airflow.cfg保存退出即可生效，不需要执行任何airflow命令。不要执行airflow initdb。</p> 
<p># smtp server here</p> 
<p>smtp_host = smtp.exmail.qq.com(注意这里不要输错，第二个位置是exmail而不是email)</p> 
<p>smtp_starttls = False</p> 
<p>smtp_ssl = True</p> 
<p># Example: smtp_user = airflow</p> 
<p>smtp_user = 发件用户，一般和下面的发件人一致即可</p> 
<p># Example: smtp_password = airflow</p> 
<p>smtp_password = </p> 
<p>smtp_port = 465</p> 
<p>smtp_mail_from = 发件人</p> 
<p> </p> 
<p>任务文件中示例：</p> 
<p>default_args = {<!-- --></p> 
<p>    'owner': '***',</p> 
<p>    'start_date': days_ago(1),</p> 
<p>    'email': ['xxx@.com'],</p> 
<p>    'email_on_failure': True,</p> 
<p>    'email_on_retry': False,</p> 
<p>    'retries': 1,</p> 
<p>    'retry_delay': timedelta(seconds=5),</p> 
<p>}</p> 
<p> </p> 
<p>邮件内容效果：</p> 
<p><img alt="" height="192" src="https://images2.imgbox.com/93/4a/mwcf9QeT_o.png" width="605"></p> 
<p> </p> 
<p><span style="color:#86ca5e;">3.任务队列以及优先级问题（先搭建集群后使用celery的queue）</span></p> 
<p>default_args里面增加了：</p> 
<p>'queue':'ribao','pool':'daily','priority_weight':100</p> 
<p>之后，任务执行异常，之前会正常执行各部分task且失败后会发送邮件，但是增加了这三个参数之后，重跑和例行都不会执行子task也不会发送失败邮件（看起来压根没有按照正常的步骤执行任务）。增加之后删除这3项参数，当天执行重跑也会产生相应的异常，第二天例行之后才会正常执行失败并且发送邮件。</p> 
<p>注：这里的queue和pool含义不同，假如启动celery的worker的时候指定了 -q  参数，那么该worker就会专门被指定用来跑该queue的任务，之后提交该名称的queue任务的时候，就会由该worker来执行。</p> 
<p>实际使用的时候，只需要添加pool和priority_weight属性即可实现日常需求。</p> 
<p> </p> 
<p><span style="color:#86ca5e;">4.任务命名规范</span></p> 
<p>web页面是按照字母a-z排序的，同时后几位也会按按位比较大小。</p> 
<p><img alt="" height="129" src="https://images2.imgbox.com/7e/0c/Zp5Eh8mi_o.png" width="253"><img alt="" height="130" src="https://images2.imgbox.com/81/94/5uwfLzlE_o.png" width="287"></p> 
<p>同时dag名称是唯一的（task_id只作用在本dag内，不同dag的taskid可以同名），所以正式的dag命名：</p> 
<p>年月日_人名首字母_根据业务或功能自行命名，如：</p> 
<p>20210303_人名首字母_业务</p> 
<p>年月日首先避免了绝大多数重名风险，人名首字母进一步将名称重名的可能性锁定在本人任务重，极大程度减少和别人任务同名的可能。</p> 
<p> </p> 
<p><span style="color:#86ca5e;">5.是否更新到airflow2.0（使用节点7、节点8/节点9另外搭建2.0，不影响之前的单点1.10）</span></p> 
<p>已解决，直接部署了2.0</p> 
<p><span style="color:#86ca5e;">6.使用celery构建集群</span></p> 
<p>celery的监控页面flower:<a href="http://10.0.64.9:5555" rel="nofollow">http://***:5555</a>。执行单位是task，同一个dag的不同task可能被分配到不同的worker执行，可以从flower页面看到执行节点。</p> 
<p>考虑节点7作为主节点，节点8作为子节点，节点9作为子节点。</p> 
<p>mysql取消使用docker的原因：docker可以部署mysql服务，但是本地物理机需要安装mysql客户端，但是物理机安装客户端的时候，会对已有的mariadb进行依赖升级，而已有的mariadb的一些依赖被hadoop一些组件所依赖。害怕影响集群，所以这种方式也不保险。索性使用运维提供的二进制安装包方式绕过依赖问题安装mysql5.7以及客户端，依赖问题不存在了，也就没有使用docker的必要了。</p> 
<p>但是经过测试，mysql5.7及之前版本，容易发生死锁问题，由于行级锁。并且也不支持scheduler HA，所以直接换为docker的mysql8，但是mysql8又有其他问题，比如源码无法正确识别mysql8版本，导致执行不合版本的sql语句。故重新测试安装postgresql9.6/10，最后现在使用postgresql10，并启动2个scheduler。</p> 
<p> </p> 
<p><strong>说明：redis使用docker搭建了哨兵，但是airflow配置broker里面需要填写一个redis地址，但是哨兵是3个，分别监控各自的redis，并不能起到一个类似zookeeper的作用（它通过api可以告知主节点的ip，但是不能自动直接连接到主节点，所以暂时仍然在airflow.cfg里面手动填写一个redis主节点的地址）。</strong></p> 
<p><strong>然后redis也更换为rabbitmq，但是未能解决web页面的按钮功能失效，比如重跑回溯任务偶发失败。所以应该是airflow的bug问题，而非redis不如rabbitmq，并且，rabbitmq在使用时，celery不能很好检测到其worker运行状态，必须重新启动rabbitmq和scheduler，然后worker才能工作，但是flower始终显示worker离线，但是换成redis就立即能够识别出worker在线状态。后来也将result_backend也换为redis和amqp，都未能解决按钮失效功能。并且官方强烈建议backend存入传统意义上的数据库，索性换回redis+postgresql组合。</strong></p> 
<p>最重要的还是airflow的dag脚本文件。</p> 
<p>老架构：</p> 
<p><img alt="" height="270" src="https://images2.imgbox.com/73/7c/0fxG2Iw7_o.png" width="683"></p> 
<p> </p> 
<p>现有架构：</p> 
<p><img alt="" height="620" src="https://images2.imgbox.com/b2/19/M9n2Mvik_o.png" width="1001"></p> 
<p><span style="color:#86ca5e;">7.配置日志组件（先测试hdfs路径是否能够使用）</span></p> 
<p>应该是不行了。。</p> 
<p>各节点的logs文件夹的内容是不一样的，也就是不同的机器执行任务产生的日志不同（执行什么，产生什么）。</p> 
<p><span style="color:#86ca5e;">8.dag文件必须放在启动scheduler的节点（节点7）。或者修改配置文件，目前配置文件都是本机的dags目录，但是worker节点不检测任务文件。</span></p> 
<p>9.目前的任务都是先登录到节点10上然后进行操作，需要注意大批量迁移后，大量连接登录的问题（连接数限制问题）。</p> 
<p>10.celery的flower的时区是否需要修改（需要修改celery的源码，最后再说）</p> 
<p>11.测试externaltaskmarker和externaltasksensor，在上游任务重跑后，会有怎样的效果。并且在这两个实例中execution_date的使用。</p> 
<p>这两个部件在web页面使用有问题，客户端命令可以较为正常运行，但是sensor仍然不会随着marker的清理而自动重跑。基本需要客户端手动执行命令才能正常。基本上只有第一次执行遇到前置失败会报警。 1</p> 
<p><span style="color:#86ca5e;">12.编辑一个任务，定期清理logs文件夹的历史文件，因为批量使用后，会产生大量的日志。后来查看发现，日志量大的主要是scheduler产生的，所以设定了任务，每天自动清理logs/scheduler下的当日的前天的目录。</span></p> 
<p><span style="color:#86ca5e;">13.编写一个dags文件夹分发的任务，每次有人更新了自己的任务文件，就要手动重跑该任务，更新dags文件夹到节点8和节点9.</span></p> 
<p><span style="color:#86ca5e;">14.任务超时设置问题，因为现有任务尤其是spark的任务通常都要几分钟甚至更久，但是目前airflow的默认的超时判定好像都很短，这个值要</span></p> 
<p><span style="color:#86ca5e;">置的大一点。</span></p> 
<h4 id="%E5%85%AD%E3%80%81%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">六、注意事项</h4> 
<ol><li><strong>不要在bash_command中使用nohup，否则airflow会认为该任务已经执行完毕，无法正常检测结果，直接把nohup去掉执行即可，日志会自动记录在airflow的执行日志中。</strong></li><li><strong>命令要在operator（task）中执行，因为不同的task可能会被分配到不同的节点分别执行。比如不要在在两个task中间执行一个os.system()。</strong></li><li><strong>每新加、修改dags之后，都重跑一下sync_all_dags这个任务的最新一次，这是基础任务，用于同步三台几点的任务文件，同时也备份到hdfs了，如果忘记重跑的话，每个小时也会自动刷新一次。新任务没同步，不会影响老任务。不同步A，直接运行A，会报错，因为worker节点本身并没有任务文件，airflow本身的例子不报错，是因为每台节点都有例子文件。一个文件中的dag的任务会分到不同worker执行，是的，随机的，并且调度节点本身不执行任务。</strong>  <em>步骤：建立.py任务文件，用airflow环境的python执行该文件编译，在airflow的web页面将sync_all_dags的最后一次任务的状态置为clear重跑。</em></li><li><span style="color:#3399ea;"><strong> 一些会引发Scheduler进程退出的操作，务必避免：</strong>（1）<strong>List Dag Run 页面，标记一个已完成任务为running后，再删除该任务；</strong></span></li><li><strong>有时修改完老的dag，web页面会显示不正常，即便删除也不正常，可用客户端命令进行一次回溯，页面便可恢复正常。</strong></li><li><span style="color:#3399ea;"><strong>手动触发dag会改变最新的execution_date, 打乱预定执行计划，可通过airflow dags next-execution &lt;dag_id&gt; 查看下次调度时间</strong></span></li><li><strong>Airflow调度dag时，将dag文件中配置的start_date（当interval是间隔）或者start_date后第一个满足cron表达式的时间（当interval是cron表达式）视为基准时间，前者第一次实际运行的时间为:start_date加上一个周期的scheduler_interval，而后者第一次实际运行时间是start_date后第二个满足cron表达式的时间。之后的调度根据上一次的execution_date来进行，就不再依赖dag文件中的配置。</strong></li><li><strong>utc和cst时间：和execution有关的时间基本都是utc(是celery的时区)时间，需要减去8小时。注意当start_date加上一个周期的scheduler_interval是utc时间，比如start_date=days_ago(1)+scheduler_interval='0 0 * * *'的时候，实际执行时间是今早的8:00。所以scheduler_interval要减去8小时，如果跨天比如想设定一个凌晨的2:19，那么就把原来的days_ago()括号里面加一，然后scheduler_interval设置为"19 18 * * *"。</strong></li></ol> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/865558a256aceb02e3da50a4f533fb16/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">memcached php 函数,PHP:Memcached::flush()的用法_Memcached类</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/22de10df5da64d99d7a6ac6989d183a6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">红黑树_插入操作(实例)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>