<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>第3章 大数据kafka采集数据（Dstream创建） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="第3章 大数据kafka采集数据（Dstream创建）" />
<meta property="og:description" content="上篇：第2章 Dstream入门
Spark Streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到Spark Streaming 的 Maven
工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。每个接收器都以 Spark
执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 CPU 核心。此外，我们还需要有可用的 CPU
核心来处理数据。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。例如，如果我们想要在流计算应用中运行
10 个接收器，那么至少需要为应用分配 11 个 CPU 核心。所以如果在本地模式运行，不要使用local[1]。
1、文件数据源 用法及说明 文件数据流：能够读取所有HDFS API兼容的文件系统文件，通过fileStream方法进行读取，Spark Streaming 将会监控 dataDirectory 目录并不断处理移动进来的文件，记住目前不支持嵌套目录。
代码实现：
package com.study.bigdatabase.streaming import org.apache.spark.SparkConf import org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream} import org.apache.spark.streaming.{Seconds, StreamingContext} object SparkStreaming02_FoleDataSource { def main(args: Array[String]): Unit = { //使用SparkStreaming完成WordCount //Sprak配置对象 val sparkConf = new SparkConf().setMaster(&#34;local[*]&#34;).setAppName(&#34;SparkStreaming01_WordCount&#34;) //实时数据分析环境对象 //采集周期：以指定的时间为周期采集实时数据 val streamingContext = new StreamingContext(sparkConf,Seconds(5)) //从指定文件夹中采集数据 val fileDStream: DStream[String] = streamingContext." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c1cfb39fd76c16a91725daa36c1e5063/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-02-11T23:01:52+08:00" />
<meta property="article:modified_time" content="2020-02-11T23:01:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">第3章 大数据kafka采集数据（Dstream创建）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>上篇：<a href="https://blog.csdn.net/weixin_39868387/article/details/104262226">第2章 Dstream入门</a></p> 
<hr> 
<blockquote> 
 <p><strong>Spark Streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到Spark Streaming 的 Maven<br> 工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。每个接收器都以 Spark<br> 执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 CPU 核心。此外，我们还需要有可用的 CPU<br> 核心来处理数据。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。例如，如果我们想要在流计算应用中运行<br> 10 个接收器，那么至少需要为应用分配 11 个 CPU 核心。所以如果在本地模式运行，不要使用local[1]。</strong></p> 
</blockquote> 
<h3><a id="1_12"></a>1、文件数据源</h3> 
<h5><a id="_14"></a>用法及说明</h5> 
<p>文件数据流：能够读取所有HDFS API兼容的文件系统文件，通过fileStream方法进行读取，Spark Streaming 将会监控 dataDirectory 目录并不断处理移动进来的文件，记住目前不支持嵌套目录。</p> 
<p>代码实现：</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>study<span class="token punctuation">.</span>bigdatabase<span class="token punctuation">.</span>streaming

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

object SparkStreaming02_FoleDataSource <span class="token punctuation">{<!-- --></span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token comment">//使用SparkStreaming完成WordCount</span>

    <span class="token comment">//Sprak配置对象</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"SparkStreaming01_WordCount"</span><span class="token punctuation">)</span>

    <span class="token comment">//实时数据分析环境对象</span>
    <span class="token comment">//采集周期：以指定的时间为周期采集实时数据</span>
    val streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span><span class="token function">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//从指定文件夹中采集数据</span>
    val fileDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span><span class="token function">textFileStream</span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">)</span>

    <span class="token comment">//将采集的数据进行分解（扁平化）</span>
    val wordDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> fileDStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将数据进行结构的转换方便统计分析</span>
    val mapDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将转换结构后的数据进行聚合处理</span>
    val wordToSumDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapDStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">//将结果 打印出来</span>
    wordToSumDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//注意：不能停止采集功能</span>
    <span class="token comment">//streamingContext.stop()</span>

    <span class="token comment">//启动采集器</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//Drvier等待采集器的执行：</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>


<span class="token punctuation">}</span>

</code></pre> 
<p><strong>注意事项：</strong><br> 1）文件需要有相同的数据格式；<br> 2）文件进入 dataDirectory的方式需要通过移动或者重命名来实现；<br> 3）一旦文件移动进目录，则不能再修改，即便修改了也不会读取新数据；</p> 
<h3><a id="2_71"></a>2、案例实操</h3> 
<p>具体代码实现：</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>study<span class="token punctuation">.</span>bigdatabase<span class="token punctuation">.</span>streaming

<span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>BufferedReader<span class="token punctuation">,</span> InputStreamReader<span class="token punctuation">}</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span>StorageLevel
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>receiver<span class="token punctuation">.</span>Receiver
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token comment">//自定义采集器</span>
object SparkStreaming03_MyReceiver <span class="token punctuation">{<!-- --></span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token comment">//使用SparkStreaming完成WordCount</span>

    <span class="token comment">//Sprak配置对象</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"SparkStreaming01_WordCount"</span><span class="token punctuation">)</span>

    <span class="token comment">//实时数据分析环境对象</span>
    <span class="token comment">//采集周期：以指定的时间为周期采集实时数据</span>
    val streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span><span class="token function">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//从指定文件夹中采集数据</span>
    val receiverDStream<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span><span class="token function">receiverStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyReceiver</span><span class="token punctuation">(</span><span class="token string">"hadoop105"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将采集的数据进行分解（扁平化）</span>
    val wordDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> receiverDStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将数据进行结构的转换方便统计分析</span>
    val mapDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将转换结构后的数据进行聚合处理</span>
    val wordToSumDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapDStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">//将结果 打印出来</span>
    wordToSumDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//注意：不能停止采集功能</span>
    <span class="token comment">//streamingContext.stop()</span>

    <span class="token comment">//启动采集器</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//Drvier等待采集器的执行：</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>

<span class="token comment">//声明采集器</span>
<span class="token comment">//(1)继承Receiver</span>
<span class="token keyword">class</span>  <span class="token class-name">MyReceiver</span><span class="token punctuation">(</span>host<span class="token operator">:</span>String<span class="token punctuation">,</span>port<span class="token operator">:</span>Int<span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">Receiver</span><span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>

  var socket<span class="token operator">:</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>Socket <span class="token operator">=</span> null

  def <span class="token function">receive</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    socket <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>Socket</span><span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span>

    val reader<span class="token operator">:</span> BufferedReader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputStreamReader</span><span class="token punctuation">(</span>socket<span class="token punctuation">.</span>getInputStream<span class="token punctuation">,</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    var line<span class="token operator">:</span> String <span class="token operator">=</span> null

    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>line <span class="token operator">=</span> reader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//将采集的数据存储到采集器的内部进行转换</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"END"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">return</span>
      <span class="token punctuation">}</span> <span class="token keyword">else</span><span class="token punctuation">{<!-- --></span>

      <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">store</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

  override def <span class="token function">onStart</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Runnable</span> <span class="token punctuation">{<!-- --></span>


      override def <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token function">receive</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>

  override def <span class="token function">onStop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
     <span class="token keyword">if</span><span class="token punctuation">(</span>socket <span class="token operator">!=</span>null<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
       socket<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
       socket <span class="token operator">=</span>null
     <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>（1）启动三台集群</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> spark<span class="token operator">-</span><span class="token number">2.1</span><span class="token number">.1</span><span class="token operator">-</span>bin<span class="token operator">-</span>hadoop2<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">]</span># start<span class="token operator">-</span>all<span class="token punctuation">.</span>sh

<span class="token comment">//查看进程</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> spark<span class="token operator">-</span><span class="token number">2.1</span><span class="token number">.1</span><span class="token operator">-</span>bin<span class="token operator">-</span>hadoop2<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">]</span># jps
<span class="token number">13056</span> DataNode
<span class="token number">13221</span> SecondaryNameNode
<span class="token number">12135</span> SparkSubmit
<span class="token number">13511</span> NodeManager
<span class="token number">12952</span> NameNode
<span class="token number">13820</span> Jps
<span class="token number">13405</span> ResourceManager

</code></pre> 
<p>（2）发送采集数据</p> 
<pre><code class="prism language-java"><span class="token comment">//发送数据</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> spark<span class="token operator">-</span><span class="token number">2.1</span><span class="token number">.1</span><span class="token operator">-</span>bin<span class="token operator">-</span>hadoop2<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">]</span># nc <span class="token operator">-</span>lk <span class="token number">9999</span>
<span class="token comment">//打印数据内容</span>
Hello Scala
Hello SparkSql
Hello SparkStreaming
<span class="token number">2222222222</span>


</code></pre> 
<p>启动程序，打印数据<br> <img src="https://images2.imgbox.com/83/aa/nR8MesuL_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h3><a id="3Kafka_204"></a>3、Kafka数据源（重点）</h3> 
<p><strong>用法及说明</strong></p> 
<blockquote> 
 <p><strong>在工程中需要引入 Maven 工件 spark- streaming-kafka_2.10 来使用它。包内提供的 KafkaUtils<br> 对象可以在 StreamingContext 和 JavaStreamingContext 中以你的 Kafka 消息创建出<br> DStream。由于 KafkaUtils 可以订阅多个主题，因此它创建出的 DStream<br> 由成对的主题和消息组成。要创建出一个流数据，需要使用 StreamingContext 实例、一个由逗号隔开的 ZooKeeper<br> 主机列表字符串、消费者组的名字(唯一名字)，以及一个从主题到针对这个主题的接收器线程数的映射表来调用 createStream() 方法。</strong></p> 
</blockquote> 
<h3><a id="_213"></a>案例实操</h3> 
<p>需求：通过SparkStreaming从Kafka读取数据，并将读取过来的数据做简单计算(WordCount)，最终打印到控制台。</p> 
<p>（1）导入依赖</p> 
<pre><code class="prism language-java"><span class="token generics function"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>spark<span class="token operator">-</span>streaming<span class="token operator">-</span>kafka<span class="token operator">-</span><span class="token number">0</span><span class="token operator">-</span><span class="token number">8</span>_2<span class="token punctuation">.</span><span class="token number">11</span><span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span><span class="token number">2.1</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
<span class="token generics function"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>kafka<span class="token operator">-</span>clients<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics function"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span><span class="token number">0.11</span><span class="token number">.0</span><span class="token number">.2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre> 
<p>（2）启动zookeeper</p> 
<pre><code class="prism language-java"><span class="token comment">//启动zookeeper</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> zookeeper<span class="token operator">-</span><span class="token number">3.4</span><span class="token number">.5</span><span class="token punctuation">]</span># bin<span class="token operator">/</span>zkServer<span class="token punctuation">.</span>sh start
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop106</span> zookeeper<span class="token operator">-</span><span class="token number">3.4</span><span class="token number">.5</span><span class="token punctuation">]</span># bin<span class="token operator">/</span>zkServer<span class="token punctuation">.</span>sh start
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop107</span> zookeeper<span class="token operator">-</span><span class="token number">3.4</span><span class="token number">.5</span><span class="token punctuation">]</span># bin<span class="token operator">/</span>zkServer<span class="token punctuation">.</span>sh start

<span class="token comment">//查看zookeeper状态</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> zookeeper<span class="token operator">-</span><span class="token number">3.4</span><span class="token number">.5</span><span class="token punctuation">]</span># bin<span class="token operator">/</span>zkServer<span class="token punctuation">.</span>sh status
JMX enabled by <span class="token keyword">default</span>
Using config<span class="token operator">:</span> <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>hadoop<span class="token operator">/</span>module<span class="token operator">/</span>zookeeper<span class="token operator">-</span><span class="token number">3.4</span><span class="token number">.5</span><span class="token operator">/</span>bin<span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span>/conf<span class="token operator">/</span>zoo<span class="token punctuation">.</span>cfg
Mode<span class="token operator">:</span> follower

</code></pre> 
<p>（4）启动kafka（shell操作）</p> 
<pre><code class="prism language-java"><span class="token comment">//启动kafka</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh config<span class="token operator">/</span>server<span class="token punctuation">.</span>properties <span class="token operator">&amp;</span>

<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop106</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh config<span class="token operator">/</span>server<span class="token punctuation">.</span>properties <span class="token operator">&amp;</span>

<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop107</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh config<span class="token operator">/</span>server<span class="token punctuation">.</span>properties <span class="token operator">&amp;</span>

<span class="token comment">//查看详细进程</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> <span class="token operator">~</span><span class="token punctuation">]</span># jps <span class="token operator">-</span>l
<span class="token number">13221</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hdfs<span class="token punctuation">.</span>server<span class="token punctuation">.</span>namenode<span class="token punctuation">.</span>SecondaryNameNode
<span class="token number">12135</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>deploy<span class="token punctuation">.</span>SparkSubmit
<span class="token number">13511</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>server<span class="token punctuation">.</span>nodemanager<span class="token punctuation">.</span>NodeManager
<span class="token number">12952</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hdfs<span class="token punctuation">.</span>server<span class="token punctuation">.</span>namenode<span class="token punctuation">.</span>NameNode
<span class="token number">14233</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>zookeeper<span class="token punctuation">.</span>server<span class="token punctuation">.</span>quorum<span class="token punctuation">.</span>QuorumPeerMain
<span class="token number">14297</span> kafka<span class="token punctuation">.</span>Kafka
<span class="token number">13405</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>server<span class="token punctuation">.</span>resourcemanager<span class="token punctuation">.</span>ResourceManager
<span class="token number">14877</span> sun<span class="token punctuation">.</span>tools<span class="token punctuation">.</span>jps<span class="token punctuation">.</span>Jps

<span class="token comment">//显示当前topics</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>zookeeper hadoop105<span class="token operator">:</span><span class="token number">2181</span> <span class="token operator">--</span>list


<span class="token comment">//创建atguigu</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>create <span class="token operator">--</span>zookeeper hadoop105<span class="token operator">:</span><span class="token number">2181</span> <span class="token operator">--</span>partitions <span class="token number">3</span> <span class="token operator">--</span>replication<span class="token operator">-</span>factor <span class="token number">2</span> <span class="token operator">--</span>topic bigdata
Created topic <span class="token string">"bigdata"</span><span class="token punctuation">.</span>


<span class="token comment">//生产者生产数据</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>broker<span class="token operator">-</span>list  hadoop105<span class="token operator">:</span><span class="token number">2181</span>  <span class="token operator">--</span>topic bigdata

<span class="token comment">//删除topic</span>
<span class="token punctuation">[</span>root<span class="token annotation punctuation">@hadoop105</span> kafka<span class="token punctuation">]</span># bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>delete <span class="token operator">--</span>zookeeper hadoop105 <span class="token operator">--</span>topic bigdata

</code></pre> 
<p>（5）具体代码实现：</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>study<span class="token punctuation">.</span>bigdatabase<span class="token punctuation">.</span>streaming


<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>KafkaUtils
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token comment">//自定义采集器</span>
object SparkStreaming04_KafkaSource <span class="token punctuation">{<!-- --></span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token comment">//使用SparkStreaming完成WordCount</span>

    <span class="token comment">//Sprak配置对象</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"SparkStreaming01_WordCount"</span><span class="token punctuation">)</span>

    <span class="token comment">//实时数据分析环境对象</span>
    <span class="token comment">//采集周期：以指定的时间为周期采集实时数据</span>
    val streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span><span class="token function">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//从kafka中采集数据</span>
    val kafkaDStream<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> String<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span><span class="token function">createStream</span><span class="token punctuation">(</span>
      streamingContext<span class="token punctuation">,</span>
      <span class="token string">"hadoop105:2181"</span><span class="token punctuation">,</span>
      <span class="token string">"atguigu"</span><span class="token punctuation">,</span>
      <span class="token function">Map</span><span class="token punctuation">(</span><span class="token string">"atguigu"</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment">//分为三个分区</span>
    <span class="token punctuation">)</span>

    <span class="token comment">//将采集的数据进行分解（扁平化）</span>
    val wordDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> kafkaDStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>t<span class="token operator">=</span><span class="token operator">&gt;</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将数据进行结构的转换方便统计分析</span>
    val mapDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将转换结构后的数据进行聚合处理</span>
    val wordToSumDStream<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapDStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">//将结果 打印出来</span>
    wordToSumDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//注意：不能停止采集功能</span>
    <span class="token comment">//streamingContext.stop()</span>

    <span class="token comment">//启动采集器</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//Drvier等待采集器的执行：</span>
    streamingContext<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>



</code></pre> 
<p>启动程序，控制台打印：<br> <img src="https://images2.imgbox.com/f6/47/dFDuGOMs_o.png" alt="在这里插入图片描述"><br> 执行过程中，可能会出错：</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">11</span> <span class="token number">23</span><span class="token operator">:</span><span class="token number">00</span><span class="token operator">:</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">172</span><span class="token punctuation">]</span> ERROR Error when sending message to topic bigdata with key<span class="token operator">:</span> null<span class="token punctuation">,</span> value<span class="token operator">:</span> <span class="token number">6</span> bytes with error<span class="token operator">:</span> <span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>internals<span class="token punctuation">.</span>ErrorLoggingCallback<span class="token punctuation">)</span>
org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>errors<span class="token punctuation">.</span>TimeoutException<span class="token operator">:</span> Failed to update metadata after <span class="token number">60000</span> ms<span class="token punctuation">.</span>

</code></pre> 
<p>详细看错误…</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/767e2eae86b2d41f8bf9d97ad304aab8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">解决 The type java.lang.CharSequence cannot be resolved. It is indirectly referenced from required .cl</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4ad670c71a08a80d97346f7c2669d97e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">将Flask项目发布到公网，部署到云服务器</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>