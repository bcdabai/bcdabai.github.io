<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Apache Impala - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Apache Impala" />
<meta property="og:description" content="1. 简介 Impala 是Hadoop生态中的一个开源的、原生的分析数据库。
它的作用：
在Hadoop上做BI查询
Impala时延低、高并行的特点，非常适合做分析查询。弥补只能做批处理的Hive的不足。Impala支持多租户线性扩展。统一的基础架构
使用Hadoop集群相同的文件、数据格式、元数据、安全、资源管理框架。不需要改变基础架构和做数据迁移备份。快速的处理能力
使用和Hive相同的元数据和ODBC驱动。同样支持SQL，上手容易
不用造轮子。企业级安全
Impala与原生Hadoop安全和Kerberos认证集成。通过哨兵模块，可以保证正确的用户和应用是得到授权使用正确的数据。开源扩展了Haodoop用户生态圈
使用Impala，无论是使用SQL查询还是BI应用，更多的用户可以使用同一个仓库和元数据库。 使用Impala我们可以实时查询储存在HDFS或是HBase上的数据。
Impala和Hive有相同的元数据，SQL语法（HQL），ODBC驱动和用户界面（Hue Beeswax）。因此提供了一个熟悉的、统一的可以进行批和实时查询的平台。
2. 架构 为了降低延迟，Impala改进MapReduce可以直接通过一个接近商业并行RDBMS的、专门的、分布式查询引擎访问数据。性能比Hive快的多。
这个架构有许多优势：
数据节点上的本地处理避免了网络瓶颈。使用一个单一的、公开的、统一的元数据存储。耗时的数据格式转换不再需要。避免了开销。所有的数据都是可以立刻查询，做ETL时没有延迟。所有硬件都可以被Impala查询使用单机即可扩展。 3. 怎么用 3.1 解决方案： 客户端：包括Hue， ODBC客户端，JDBC客户端和Impala Shell. 这些接口实现查询和管理任务。Hive的元数据。让Impala知道有哪些databases可用，这些数据库的结构登。在使用create, drop, alter schema, load data into tables等SQL时，相关的元数据改变会自动广播给所有Impala节点，通过专门的catalog service。Impala是个进程运行在数据节点，coordinates 和 executes 查询。 每个Impala实例receive, plan 和 coordinate 来自 Impala 客户端的查询。Queries都被分布在Impala节点上，这些节点是workers的角色，并行的执行每个query的fragments。HBase和HDFS的数据可以被Impala查询。 3.2 query执行过程 用户程序通过 ODBC 和 JDBC 这样的统一查询接口，发送SQL queries 给 Impala。用户程序可以连接任意集群中的 impalad。这个 impalad 成为这个查询的 coordinator.Impala 解析这个 query， 然后分析它并决定集群中的 impalad 实例们应该实现哪些 tasks。然后以最优效率来计划这个 execution。HDFS 和 HBase 上的数据可以通过本地的 impalad 实例们去访问到。每个 impalad 会返回数据给到 coordinating的那个 impalad，然后这个 coordinator impalad 把这些结果返回给客户端。 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c3b07478a30a5aff2cef68c3ca3d34d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-11T18:40:14+08:00" />
<meta property="article:modified_time" content="2022-04-11T18:40:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Apache Impala</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="1__0"></a>1. 简介</h3> 
<p>Impala 是Hadoop生态中的一个开源的、原生的分析数据库。<br> 它的作用：</p> 
<ul><li>在Hadoop上做BI查询<br> Impala时延低、高并行的特点，非常适合做分析查询。弥补只能做批处理的Hive的不足。Impala支持多租户线性扩展。</li><li>统一的基础架构<br> 使用Hadoop集群相同的文件、数据格式、元数据、安全、资源管理框架。不需要改变基础架构和做数据迁移备份。</li><li>快速的处理能力<br> 使用和Hive相同的元数据和ODBC驱动。同样支持SQL，上手容易<br> 不用造轮子。</li><li>企业级安全<br> Impala与原生Hadoop安全和Kerberos认证集成。通过哨兵模块，可以保证正确的用户和应用是得到授权使用正确的数据。</li><li>开源</li><li>扩展了Haodoop用户生态圈<br> 使用Impala，无论是使用SQL查询还是BI应用，更多的用户可以使用同一个仓库和元数据库。</li></ul> 
<p>使用Impala我们可以实时查询储存在HDFS或是HBase上的数据。<br> Impala和Hive有相同的元数据，SQL语法（HQL），ODBC驱动和用户界面（Hue Beeswax）。因此提供了一个熟悉的、统一的可以进行批和实时查询的平台。</p> 
<h3><a id="2__20"></a>2. 架构</h3> 
<p>为了降低延迟，Impala改进MapReduce可以直接通过一个接近商业并行RDBMS的、专门的、分布式查询引擎访问数据。性能比Hive快的多。<br> <img src="https://images2.imgbox.com/cd/a5/ViYUHSWQ_o.png" alt="在这里插入图片描述"><br> 这个架构有许多优势：</p> 
<ul><li>数据节点上的本地处理避免了网络瓶颈。</li><li>使用一个单一的、公开的、统一的元数据存储。</li><li>耗时的数据格式转换不再需要。避免了开销。</li><li>所有的数据都是可以立刻查询，做ETL时没有延迟。</li><li>所有硬件都可以被Impala查询使用</li><li>单机即可扩展。</li></ul> 
<h3><a id="3__31"></a>3. 怎么用</h3> 
<h4><a id="31__32"></a>3.1 解决方案：</h4> 
<ul><li>客户端：包括Hue， ODBC客户端，JDBC客户端和Impala Shell. 这些接口实现查询和管理任务。</li><li>Hive的元数据。让Impala知道有哪些databases可用，这些数据库的结构登。在使用create, drop, alter schema, load data into tables等SQL时，相关的元数据改变会自动广播给所有Impala节点，通过专门的catalog service。</li><li>Impala是个进程运行在数据节点，coordinates 和 executes 查询。 每个Impala实例receive, plan 和 coordinate 来自 Impala 客户端的查询。Queries都被分布在Impala节点上，这些节点是workers的角色，并行的执行每个query的fragments。</li><li>HBase和HDFS的数据可以被Impala查询。</li></ul> 
<h4><a id="32_query_37"></a>3.2 query执行过程</h4> 
<ol><li>用户程序通过 ODBC 和 JDBC 这样的统一查询接口，发送SQL queries 给 Impala。用户程序可以连接任意集群中的 impalad。这个 impalad 成为这个查询的 coordinator.</li><li>Impala 解析这个 query， 然后分析它并决定集群中的 impalad 实例们应该实现哪些 tasks。然后以最优效率来计划这个 execution。</li><li>HDFS 和 HBase 上的数据可以通过本地的 impalad 实例们去访问到。</li><li>每个 impalad 会返回数据给到 coordinating的那个 impalad，然后这个 coordinator impalad 把这些结果返回给客户端。</li></ol> 
<h4><a id="33_Impala_42"></a>3.3 Impala支持的特性</h4> 
<ul><li>包括 SELECT, joins, and aggregate functions 的 HQL</li><li>HDFS HBase 和 S3这样的分布式文件系统。 
  <ul><li>HDFS的一些文件格式：text, parquet, avro, Sequence, RCFiles.</li><li>压缩格式：Snappy. GZIP, Deflate, BZIP</li></ul> </li><li>常见的接口</li><li>JDBC Driver</li><li>ODBC driver</li><li>Hue Beeswax 和 Impala Query UI</li><li>impala-shell 命令行接口</li><li>Kerberos 授权</li></ul> 
<h3><a id="4_Impala_server_53"></a>4 Impala server组成</h3> 
<p>Impala server是一个分布式的，MPP架构的数据库引擎。它包含不同的daemon processes，他们运行在集群里具体的hosts上。</p> 
<h4><a id="The_Impala_Daemon_55"></a>The Impala Daemon</h4> 
<p>Impala 最核心的就是 Impala daemon，实际上代表的就是 impalad 进程，Impala daemon 的几个核心功能是：</p> 
<ul><li>对文件的读和写</li><li>接受由impala-shell 命令，Hue，JDBC 和 ODBC 发送过来的queries。</li><li>并行化这些queries，把工作在集群里进行分配。</li><li>把互相的这些query结果发回给 coordinator.<br> Impala daemons 怎么来进行部署？</li><li>HDFS 和 Impala是放在一起的。每个Impala daemon 都在一个 DataNode上运行。</li><li>Impala是分开部署在一个计算集群上，并且远程的读取 HDFS, HBase S3上的文件。<br> Impala daemons不断与 StateStore进行通信， 来确认哪些个 daemons是健康的、可以接受新的work。<br> 在集群中任意 impala daemon creates, alters, or drops 任意 type的 object，或者 INSERT, LOAD DATA 声明被处理时，所有的impala daemons 接受来自 catalogd daemon 的广播信息。这个机制最小化了REFRESH 或是 INVALIDATE METADATA statements的使用。<br> impala 2.9及以上可以控制哪些个hosts可以作为 query coordinators 以及 那些可以作为 query executor，来提升打击群在面对高并发任务时的可扩展性。</li></ul> 
<h3><a id="The_Impala_StateStore_67"></a>The Impala StateStore</h3> 
<ul><li>StateStore检查所有 Impala daemons的状态。持续接力它的检查结果给每一个 daemons。实际由 <code>statestored</code> 这样的 daemon 进程来表示。只需要这样一个进程在集群里的一个host上，当一个impala daemon 由于 硬件问题、网络错误、软件问题或是其他原因下线了时， StateStore通知所有其他的 Impala daemons，因此，未来的queries就可以避免请求这些连接不上的 impala daemon。</li><li>因为StateStore是在集群有问题时<strong>或是</strong>广播元数据给coordinators时发挥作用的，因此并不总是对 Impala 集群的运作很重要。</li><li>如果在StateStore down掉的时候，执行一个DDL语句，那些访问DDL刚创建的新表的queries会失败。</li><li>大部分对负载均衡及高可用的考虑用在了 impalad daemon上，statestored和 catalogd daemons对高可用并没有特别的要求，因为这些daemons上出问题不会导致data loss， 如果这些 daemons 由于一个host停机而变得不可用，你可以停止 Impala service， 删除 Impala StateStores 和 Impala Catalog Server roles， 添加这些roles 到另一个host上，然后重启 Impala services。</li></ul> 
<h3><a id="The_Impala_Catalog_Service_72"></a>The Impala Catalog Service</h3> 
<ul><li>Catalog Service 转发由 Impala SQL语句导致的元数据更改 给集群里所有Impala Daemons。physically由 <code>catalogd</code> 表示。只需一个这样的进程在集群里的一个host上。因为requests是要通过 StateStore daemon的，因此自然的，让statestored 和 catalogd 服务在一个host上是有道理的。</li><li>Catalog service避免使用 REFRESH 和 INVALIDATE METADATA 语句，当 Impala 执行语句导致元数据发生改变时。 当你用Hive create a table, load data, 以及类似操作时，你需要先在一个Impala daemon上 REFRESH 或者 INVALIDATE METADATA，再执行一个query。（or by manuplating data files directly in HDFS, and in these cases, the statements only need to be issued on one Impala daemon rather than on all daemons.)</li></ul> 
<p>使用 ##load_catalog_in_background 可以控制什么时候一个表的元数据被加载。</p> 
<ul><li>如果设置成 false。 一个表的元数据在它被第一次引用时加载。这意味着第一次这样的query会比之后的要慢。默认是 false</li><li>如果设置成 true，catalog service尝试加载一个表的元数据即使没有 query需要那个元数据。所以元数据可能已经被加载，当这query第一次执行的时候。当以下情景建议设置成 true：</li><li>幕后的加载干扰到具体查询元数据的加载。发生在启动或者验证元数据之后。可能会随机导致无法诊断的长时间查询。</li><li>当Impala加载从未使用过的表的元数据。可能会增加catalog size以及catalog service 和 impala daemon的memory占用。<br> 关于负载均衡和高可用的考虑与上边statestored相同。</li></ul> 
<h3><a id="5_Impala_82"></a>5 开发Impala应用</h3> 
<p>核心开发的语言是SQL，也可以用Java和其他语言来通过许多BI工具使用的标准JDBC和ODBC接口来交互。对于一些特别的分析工作，你可以通过C++或Java编写的UDF来补充SQL函数。</p> 
<h4><a id="Impala_SQL_84"></a>Impala SQL的语法</h4> 
<p>与HQL高度兼容。支持HQL语句、数据类型、内置函数的子集。Impala同样包含额外内置的函数来用作工业开发，用来简化从非Hadoop系统移植SQL。<br> 对于传统数据库和数据仓库，以下SQL语法很相似：</p> 
<ul><li><code>SELECT</code>语句，包括WHERE, GROUP BY, ORDER BY, WITH 子句。</li><li>支持分区表。减少查询的I/O开销</li><li>Impala1.2及以上，支持UDF。<br> 语法不一样，需要学习的地方：</li><li>Impala SQL 注重 查询，所以包含较少的DML. 没有UPDATE 或 DELETE 语句。通过 DROP TABLE 或 ALTER TABLE…DROP PARTITION语句来丢弃数据，或者通过INSERT OVERWRITE 语句来替换数据。</li><li>数据的创造是由 INSERT语句实现。有两种变型，INSERT INTO是来追加到已经存在的数据后， INSERT OVERWRITE是来代替分区或表中所有内容。类似于 TRUNCATE TABLE 后边加 INSERT。INSERT … SELECT 比 INSERT … VALUES 更高效，当只用一个操作从一个表中复制或变换大量数据到另一个表时。</li><li>Hive 与 Impala 可以互用对方创建的表和元数据。其他hadoop生态组件也可以写Parquet avro格式的文件，impala可以查询他们。</li><li>数仓风格，Impala SQL可以对于读取逗号分隔，制表位分割的文本文件，并且在 CREATE TABLE 语句中重新制定分隔符。你可以创建外部表来读取存在的数据文件。但是不能移动和转换他们。</li><li>使用STRING可以不要求字符串类型的长度限制，使用CHAR(), VARCHAR()可以进行限制。</li></ul> 
<h4><a id="_96"></a>编程接口</h4> 
<ul><li>impala-shell</li><li>Hue</li><li>JDBC (linux BI tools)</li><li>ODBC( non-linux BI tools)<br> 每个impalad daemon process 运行在不同的nodes，可以监听不同端口的请求。impala-shell和Hue通过一个端口路由到impalad daemons。JDBC 和 ODBC是不一样端口。</li></ul> 
<h3><a id="6_ImpalaHadoop_102"></a>6 Impala如何与Hadoop生态结合</h3> 
<p>Impala可以作为消费者和生产者与其他Hadoop组成交换数据。</p> 
<ul><li>与Hive工作<br> Impala query optimizer可以利用表统计数字和列统计数字。Hive种用ANAYLIZE TABLE语句。 Impala种用COMPUTE STATS语句。</li></ul> 
<h4><a id="Hive_Impala_106"></a>Hive和 Impala的元数据</h4> 
<ul><li>除了之前和Hive相同的元数据，Impala追踪数据文件其他更低等级的元数据。 
  <ul><li>HDFS数据块的物理位置</li></ul> </li><li>对于有大量数据和许多分区的表来说，回溯所有元数据是耗时的，在有些情况下，需要几分钟。因此，每个Impala 节点可以缓存所有的这些元数据为了未来针对同一个表的queries。</li><li>如果表的定义或表中数据更新，所有其他集群中Impala daemons必须受到最新的元数据来代替旧的缓存的元数据，在发起一个针对那个表的query之前。对于所有DDL和DML statements，这个元数据的更新是自动的，由catalogd来负责维护。</li><li>对于那些Hive创建的DDL和DML，或者是手动对HDFS中文件修改，你仍需要使用REFRESH语句（新数据文件被加入已存在的表），或者是INVALIDATE METADATA语句（对于完全新的表，或者在删了个表，实现了一次HDFS rebalance operation，或者删除了数据文件。） 发起INVALIDATE METADATA 本身是找回元库种追踪的所有表的元数据。如果你知道个别表被修改，你应该用REFRESH table_name。</li></ul> 
<h4><a id="Impala_HDFS_112"></a>Impala 咋用HDFS</h4> 
<p>Impala主要使用HDFS作为主要数据存储介质。Impala依赖HDFS的冗余机制来实现高可用。Impala中的表就说再HDFS中的，使用类似的HDFS的文件格式和压缩格式。当对应目录下有文件作为一个新的表，Impala会全部读取他们，不论文件的名字。新的数据被加到文件中以Impala控制的名字。</p> 
<h4><a id="ImpalaHBase_114"></a>Impala咋用HBase</h4> 
<p>HBase是HDFS的替代对于Impala来说。它是一个在HDFS之上建立的数据库存储系统，没有内置SQL支持。许多Hadoop使用者都会配置并用它存储大量（通常稀疏）的数据集。通过定义Impala中的表并且将他们映射到对应的HBase表中，你可以通过Impala查询HBase中的内容，甚至可以实现impala和HBase的联表查询。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0538e21e143def5004f07124e47d4ef7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Delphi】逻辑型 Boolean 转字符串 简单方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e71dbadd072714bbf0597709a6d4898/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">第十三届蓝桥杯——java B组（部分题目）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>