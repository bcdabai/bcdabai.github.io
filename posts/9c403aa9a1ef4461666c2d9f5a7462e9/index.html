<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Nebula Exchange 工具 Hive 数据导入的踩坑之旅 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Nebula Exchange 工具 Hive 数据导入的踩坑之旅" />
<meta property="og:description" content="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-TqS8lfBK-1610349254003)(https://www-cdn.nebula-graph.com.cn/nebula-blog/nebula-exchange-hive-import-best-practice.png)]
摘要：本文由社区用户 xrfinbj 贡献，主要介绍 Exchange 工具从 Hive 数仓导入数据到 Nebula Graph 的流程及相关的注意事项。
1 背景 公司内部有使用图数据库的场景，内部通过技术选型确定了 Nebula Graph 图数据库，还需要验证 Nebula Graph 数据库在实际业务场景下的查询性能。所以急迫的需要导入数据到 Nebula Graph 并验证。在这个过程中发现通过 Exchange 工具从 hive 数仓导入数据到 Nebula Graph 文档不是很全，所以把这个流程中踩到的坑记录下来，回馈社区，避免后人走弯路。
本文主要基于我之前发在论坛的 2 篇帖子：
exchange 如何导入 hive 数据问题exchange 执行从 hive 导入数据报错 2 环境信息 Nebula Graph 版本：nebula:nightly部署方式（分布式 / 单机 / Docker / DBaaS）：Mac 电脑 Docker 部署硬件信息 磁盘（SSD / HDD）：Mac 电脑 SSDCPU、内存信息：16 G 数仓环境（Mac 电脑搭建的本地数仓）： Hive 3.1.2Hadoop 3.2.1 Exchange 工具：https://github.com/vesoft-inc/nebula-java/tree/v1.0/tools/exchange 编译后生成 jar 包" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9c403aa9a1ef4461666c2d9f5a7462e9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-11T15:15:18+08:00" />
<meta property="article:modified_time" content="2021-01-11T15:15:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Nebula Exchange 工具 Hive 数据导入的踩坑之旅</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-TqS8lfBK-1610349254003)(https://www-cdn.nebula-graph.com.cn/nebula-blog/nebula-exchange-hive-import-best-practice.png)]</p> 
<p>摘要：本文由社区用户 xrfinbj 贡献，主要介绍 Exchange 工具从 Hive 数仓导入数据到 Nebula Graph 的流程及相关的注意事项。</p> 
<h3><a id="1__4"></a>1 背景</h3> 
<p>公司内部有使用图数据库的场景，内部通过技术选型确定了 Nebula Graph 图数据库，还需要验证 Nebula Graph 数据库在实际业务场景下的查询性能。所以急迫的需要导入数据到 Nebula Graph 并验证。在这个过程中发现通过 Exchange 工具从 hive 数仓导入数据到 Nebula Graph 文档不是很全，所以把这个流程中踩到的坑记录下来，回馈社区，避免后人走弯路。</p> 
<p>本文主要基于我之前发在论坛的 2 篇帖子：</p> 
<ul><li><a href="https://discuss.nebula-graph.com.cn/t/topic/1773" rel="nofollow">exchange 如何导入 hive 数据问题</a></li><li><a href="https://discuss.nebula-graph.com.cn/t/topic/1759" rel="nofollow">exchange 执行从 hive 导入数据报错</a></li></ul> 
<h3><a id="2__12"></a>2 环境信息</h3> 
<ul><li>Nebula Graph 版本：nebula:nightly</li><li>部署方式（分布式 / 单机 / Docker / DBaaS）：Mac 电脑 Docker 部署</li><li>硬件信息 
  <ul><li>磁盘（SSD / HDD）：Mac 电脑 SSD</li><li>CPU、内存信息：16 G</li></ul> </li><li>数仓环境（Mac 电脑搭建的本地数仓）： 
  <ul><li>Hive 3.1.2</li><li>Hadoop 3.2.1</li></ul> </li><li>Exchange 工具：<a href="https://github.com/vesoft-inc/nebula-java/tree/v1.0/tools/exchange">https://github.com/vesoft-inc/nebula-java/tree/v1.0/tools/exchange</a></li></ul> 
<p>编译后生成 jar 包</p> 
<ul><li>Spark<br> spark-2.4.7-bin-hadoop2.7 (conf 目录下配置 Hadoop 3.2.1 对应的 core-site.xml，hdfs-site.xml，hive-site.xml 设置 spark-env.sh)<br> Scala code runner version 2.13.3 – Copyright 2002-2020, LAMP/EPFL and Lightbend, Inc.</li></ul> 
<h4><a id="3__30"></a>3 配置</h4> 
<h4><a id="1__Nebula_Graph_DDL_32"></a>1 Nebula Graph DDL</h4> 
<pre><code>CREATE SPACE test_hive(partition_num=10, replica_factor=1); --创建图空间，本示例中假设只需要一个副本
USE test_hive; --选择图空间 test
CREATE TAG tagA(idInt int, idString string, tboolean bool, tdouble double); -- 创建标签 tagA
CREATE TAG tagB(idInt int, idString string, tboolean bool, tdouble double); -- 创建标签 tagB
CREATE EDGE edgeAB(idInt int, idString string, tboolean bool, tdouble double); -- 创建边类型 edgeAB
</code></pre> 
<h4><a id="2_Hive_DDL_42"></a>2 Hive DDL</h4> 
<pre><code>CREATE TABLE `tagA`(                               
   `id` bigint,                                     
   `idInt` int,                            
   `idString` string,                                 
   `tboolean` boolean,                                 
   `tdouble` double) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\001' LINES TERMINATED BY '\n';
insert into tagA select 1,1,'str1',true,11.11;
insert into tagA select 2,2,"str2",false,22.22;

CREATE TABLE `tagB`(                               
   `id` bigint,                                     
   `idInt` int,                            
   `idString` string,                                 
   `tboolean` boolean,                                 
   `tdouble` double) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\001' LINES TERMINATED BY '\n';
insert into tagB select 3,3,"str 3",true,33.33;
insert into tagB select 4,4,"str 4",false,44.44;

CREATE TABLE `edgeAB`(                               
   `id_source` bigint,                                     
   `id_dst` bigint,         
   `idInt` int,                            
   `idString` string,                                 
   `tboolean` boolean,                                 
   `tdouble` double) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\001' LINES TERMINATED BY '\n';
insert into edgeAB select 1,3,5,"edge 1",true,55.55;
insert into edgeAB select 2,4,6,"edge 2",false,66.66;
</code></pre> 
<h4><a id="3__nebula_applicationconf__74"></a>3 我的最新 nebula_application.conf 文件</h4> 
<p>注意看exec、fields、nebula.fields、vertex、source、target字段映射</p> 
<pre><code>{
  # Spark relation config
  spark: {
    app: {
      name: Spark Writer
    }

    driver: {
      cores: 1
      maxResultSize: 1G
    }

    cores {
      max: 4
    }
  }

  # Nebula Graph relation config
  nebula: {
    address:{
      graph: ["192.168.1.110:3699"]
      meta: ["192.168.1.110:45500"]
    }
    user: user
    pswd: password
    space: test_hive

    connection {
      timeout: 3000
      retry: 3
    }

    execution {
      retry: 3
    }

    error: {
      max: 32
      output: /tmp/error
    }
    rate: {
      limit: 1024
      timeout: 1000
    }
  }

  # Processing tags
  tags: [
    # Loading from Hive
    {
      name: tagA
      type: {
        source: hive
        sink: client
      }
      exec: "select id,idint,idstring,tboolean,tdouble from nebula.taga"
      fields: [id,idstring,tboolean,tdouble]
      nebula.fields: [idInt,idString,tboolean,tdouble]
      vertex: id
      batch: 256
      partition: 10
    }
    {
      name: tagB
      type: {
        source: hive
        sink: client
      }
      exec: "select id,idint,idstring,tboolean,tdouble from nebula.tagb"
      fields: [id,idstring,tboolean,tdouble]
      nebula.fields: [idInt,idString,tboolean,tdouble]
      vertex: id
      batch: 256
      partition: 10
    }
  ]

  # Processing edges
  edges: [
    # Loading from Hive
    {
      name: edgeAB
      type: {
        source: hive
        sink: client
      }
      exec: "select id_source,id_dst,idint,idstring,tboolean,tdouble from nebula.edgeab"
      fields: [id_source,idstring,tboolean,tdouble]
      nebula.fields: [idInt,idString,tboolean,tdouble]
      source: id_source
      target: id_dst
      batch: 256
      partition: 10
    }
  ]
}

</code></pre> 
<h3><a id="4__178"></a>4 执行导入</h3> 
<h4><a id="41__nebula__180"></a>4.1 确保 nebula 服务启动</h4> 
<h4><a id="42__Hive__182"></a>4.2 确保 Hive 表和数据就绪</h4> 
<h4><a id="43__sparksql_cli__Hive__Spark__184"></a>4.3 执行 spark-sql cli 查看 Hive 表以及数据是否正常以确保 Spark 环境没问题</h4> 
<p><img src="https://images2.imgbox.com/b0/37/snqd7y9F_o.png" alt="Nebula Exchange 工具 Hive 数据导入的踩坑之旅"></p> 
<h4><a id="44__Spark__188"></a>4.4 一切配置工作就绪后，执行 Spark 命令：</h4> 
<pre><code>spark-submit --class com.vesoft.nebula.tools.importer.Exchange --master “local[4]” /xxx/exchange-1.0.1.jar -c /xxx/nebula_application.conf -h
</code></pre> 
<h4><a id="45___db_dump___194"></a>4.5 导入成功后 可以借助 db_dump 工具查看导入数据量 验证正确性</h4> 
<pre><code>./db_dump --mode=stat --space=xxx --db_path=/home/xxx/data/storage0/nebula   --limit 20000000
</code></pre> 
<h3><a id="5__200"></a>5 踩坑以及说明</h3> 
<ul><li>第一个坑就是 spark-submit 命令没有加 -h 参数</li><li>Nebula Graph 中 tagName 是大小写敏感的，tags 的配置中 name 配置的应该是 Nebula Graph 的 tag 名</li><li>Hive的 int 和 Nebula Graph 的 int 不一致，Hive 里面的 bigint 对应 Nebula Graph 的 int</li></ul> 
<h4><a id="_206"></a>其他说明：</h4> 
<ul><li>由于 Nebula Graph 底层存储是 kv，重复插入其实是覆盖，update 操作用 insert 替代性能会高些</li><li>文档里面不全的地方可能暂时只有一边看源码解决，一边去论坛问（开发同学也不容易又要紧张的开发又要回答用户的疑问）</li><li>导入数据、Compact 以及操作建议：<a href="https://docs.nebula-graph.com.cn/manual-CN/3.build-develop-and-administration/5.storage-service-administration/compact/" rel="nofollow">https://docs.nebula-graph.com.cn/manual-CN/3.build-develop-and-administration/5.storage-service-administration/compact/</a></li><li>我已经验证如下两个场景: 
  <ul><li>用 Spark 2.4 从 Hive 2（Hadoop 2）中导入数据到 Nebula Graph</li><li>用 Spark 2.4 从 Hive3（Hadoop 3）中导入数据到 Nebula Graph</li></ul> </li></ul> 
<p>说明：Exchange 目前还不支持 Spark 3，编译后运行报错，所以没法验证 Spark 3 环境</p> 
<h4><a id="_217"></a>还有一些疑问</h4> 
<ul><li>nebula_application.conf 文件的参数 batch 和 rate.limit 应该如何设置？参数如何抉择？</li><li>Exchange 工具 Hive 数据导入原理（Spark 这块我也是最近现学现用）</li></ul> 
<h3><a id="6_Exchange__Debug_222"></a>6 Exchange 源码 Debug</h3> 
<p>Spark Debug 部分参考博客：<a href="https://dzone.com/articles/how-to-attach-a-debugger-to-apache-spark" rel="nofollow">https://dzone.com/articles/how-to-attach-a-debugger-to-apache-spark</a></p> 
<p>通过 Exchange 源码的学习和 Debug 能加深对 Exchange 原理的理解，同时也能发现一些文档描述不清晰的地方，比如 <a href="https://docs.nebula-graph.com.cn/nebula-exchange/use-exchange/ex-ug-import-sst/" rel="nofollow">导入 SST 文件</a> 和 <a href="https://docs.nebula-graph.com.cn/manual-CN/3.build-develop-and-administration/5.storage-service-administration/data-import/download-and-ingest-sst-file/" rel="nofollow">Download and Ingest</a> 只有结合源码看才能发现文档描述不清晰逻辑不严谨的问题。</p> 
<p>通过源码 Debug 也能发现一些简单的参数配置问题。</p> 
<p>进入正题：</p> 
<p>步骤一：</p> 
<pre><code>export SPARK_SUBMIT_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=4000
</code></pre> 
<p>步骤二：</p> 
<pre><code>spark-submit --class com.vesoft.nebula.tools.importer.Exchange --master “local” /xxx/exchange-1.1.0.jar -c /xxx/nebula_application.conf -h
Listening for transport dt_socket at address: 4000
</code></pre> 
<p>步骤三：IDEA 配置</p> 
<p><img src="https://images2.imgbox.com/7d/8d/fnLTjDeI_o.png" alt="IDEA 配置"></p> 
<p>步骤四：在 IDEA 里面点击 Debug</p> 
<p><img src="https://images2.imgbox.com/e7/4e/yToMvHEh_o.png" alt="IDEA Debug"></p> 
<h3><a id="7__253"></a>7 建议与感谢</h3> 
<p>感谢 vesoft 提供了宇宙性能最强的 Nebula Graph 图数据库，能解决业务中很多实际问题，中途这点痛不算什么（看之前的分享，360 数科他们那个痛才是真痛）。中途遇到的问题都有幸得到社区及时的反馈解答，再次感谢</p> 
<p><strong>很期待 Exchange 支持 Nebula Graph 2.0</strong></p> 
<h3><a id="_259"></a>参考资料</h3> 
<ul><li><a href="https://discuss.nebula-graph.com.cn/t/topic/1721" rel="nofollow">exchange和Spark Writer什么关系？</a></li><li><a href="https://docs.nebula-graph.com.cn/manual-CN/3.build-develop-and-administration/5.storage-service-administration/data-import/spark-writer/" rel="nofollow">Spark Writer 手册</a></li><li><a href="https://docs.nebula-graph.com.cn/nebula-exchange/about-exchange/ex-ug-what-is-exchange/" rel="nofollow">Spark Writer 手册</a></li></ul> 
<p>喜欢这篇文章？来来来，给我们的 <a href="https://github.com/vesoft-inc/nebula">GitHub</a> 点个 star 表鼓励啦~~ 🙇‍♂️🙇‍♀️ [手动跪谢]</p> 
<p>交流图数据库技术？交个朋友，Nebula Graph 官方小助手微信：<a href="https://www-cdn.nebula-graph.com.cn/nebula-blog/nbot.png" rel="nofollow">NebulaGraphbot</a> 拉你进交流群~~</p> 
<h3><a id="_269"></a>推荐阅读</h3> 
<ul><li><a href="https://nebula-graph.com.cn/posts/best-practices-import-data-spark-nebula-graph/" rel="nofollow">在 Spark 数据导入中的一些实践细节</a></li><li><a href="https://nebula-graph.com.cn/posts/how-to-import-data-from-neo4j-to-nebula-graph/" rel="nofollow">Neo4j 导入 Nebula Graph 的实现原理与实践</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/905e2a418605c86b7f9a8ef4b43151c6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">蚁群算法原理及c&#43;&#43;实现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1d7882dc06430edc3afd9ed07a6609f1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">用户操作日志记录字段修改前后值</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>