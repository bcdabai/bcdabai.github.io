<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>全面梳理：准确率,精确率,召回率,查准率,查全率,假阳性,真阳性,PRC,ROC,AUC,F1 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="全面梳理：准确率,精确率,召回率,查准率,查全率,假阳性,真阳性,PRC,ROC,AUC,F1" />
<meta property="og:description" content="二分类问题的结果有四种：
逻辑在于，你的预测是positive-1和negative-0，true和false描述你本次预测的对错
true positive-TP：预测为1，预测正确即实际1
false positive-FP：预测为1，预测错误即实际0
true negative-TN：预测为0，预测正确即实际0
false negative-FN：预测为0，预测错误即实际1
【混淆矩阵】
直观呈现以上四种情况的样本数
【准确率】accuracy
正确分类的样本/总样本：(TP&#43;TN)/(ALL)
在不平衡分类问题中难以准确度量：比如98%的正样本只需全部预测为正即可获得98%准确率
【精确率】【查准率】precision
TP/(TP&#43;FP)：在你预测为1的样本中实际为1的概率
查准率在检索系统中：检出的相关文献与检出的全部文献的百分比，衡量检索的信噪比
【召回率】【查全率】recall
TP/(TP&#43;FN)：在实际为1的样本中你预测为1的概率
查全率在检索系统中：检出的相关文献与全部相关文献的百分比，衡量检索的覆盖率
实际的二分类中，positive-1标签可以代表健康也可以代表生病，但一般作为positive-1的指标指的是你更关注的样本表现，比如“是垃圾邮件”“是阳性肿瘤”“将要发生地震”。
因此在肿瘤判断和地震预测等场景：
要求模型有更高的【召回率】recall，是个地震你就都得给我揪出来不能放过
在垃圾邮件判断等场景：
要求模型有更高的【精确率】precision，你给我放进回收站里的可都得确定是垃圾，千万不能有正常邮件啊
【ROC】
常被用来评价一个二值分类器的优劣
ROC曲线的横坐标为false positive rate（FPR）：FP/(FP&#43;TN)
假阳性率，即实际无病，但根据筛检被判为有病的百分比。
在实际为0的样本中你预测为1的概率
纵坐标为true positive rate（TPR）：TP/(TP&#43;FN)
真阳性率，即实际有病，但根据筛检被判为有病的百分比。
在实际为1的样本中你预测为1的概率，此处即【召回率】【查全率】recall
接下来我们考虑ROC曲线图中的四个点和一条线。
第一个点，(0,1)，即FPR=0,TPR=1，这意味着无病的没有被误判，有病的都全部检测到，这是一个完美的分类器，它将所有的样本都正确分类。
第二个点，(1,0)，即FPR=1，TPR=0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。
第三个点，(0,0)，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，没病的没有被误判但有病的全都没被检测到，即全部选0
类似的，第四个点（1,1），分类器实际上预测所有的样本都为1。
经过以上的分析可得到：ROC曲线越接近左上角，该分类器的性能越好。
【ROC是如何画出来的】
分类器有概率输出，50%常被作为阈值点，但基于不同的场景，可以通过控制概率输出的阈值来改变预测的标签，这样不同的阈值会得到不同的FPR和TPR。
从0%-100%之间选取任意细度的阈值分别获得FPR和TPR，对应在图中，得到的ROC曲线，阈值的细度控制了曲线的阶梯程度或平滑程度。
一个没有过拟合的二分类器的ROC应该是梯度均匀的，如图紫线
此图为PRC， precision recall curve，原理类似
ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。而Precision-Recall曲线会变化剧烈，故ROC经常被使用。
【AUC】
AUC（Area Under Curve）被定义为ROC曲线下的面积，完全随机的二分类器的AUC为0.5，虽然在不同的阈值下有不同的FPR和TPR，但相对面积更大，更靠近左上角的曲线代表着一个更加稳健的二分类器。
同时针对每一个分类器的ROC曲线，又能找到一个最佳的概率切分点使得自己关注的指标达到最佳水平。
【AUC的排序本质】
大部分分类器的输出是概率输出，如果要计算准确率，需要先把概率转化成类别，就需要手动设置一个阈值，而这个超参数的确定会对优化指标的计算产生过于敏感的影响
AUC从Mann–Whitney U statistic的角度来解释：随机从标签为1和标签为0的样本集中分别随机选择两个样本，同时分类器会输出两样本为1的概率，那么我们认为分类器对“标签1样本的预测概率&gt;对标签0样本的预测概率 ”的概率等价于AUC。
因而AUC反应的是分类器对样本的排序能力，这样也可以理解AUC对不平衡样本不敏感的原因了。
【作为优化目标的各类指标】
最常用的分类器优化及评价指标是AUC和logloss，最主要的原因是：不同于accuracy，precision等，这两个指标不需要将概率输出转化为类别，而是可以直接使用概率进行计算。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3587ed90c6c7de658ba00f2c4cdc0248/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-04-14T21:40:26+08:00" />
<meta property="article:modified_time" content="2019-04-14T21:40:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">全面梳理：准确率,精确率,召回率,查准率,查全率,假阳性,真阳性,PRC,ROC,AUC,F1</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p> </p> 
<p>二分类问题的结果有四种：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/c7/e1/jRuNmuSm_o.jpg" width="504"></p> 
<p>逻辑在于，<strong>你的预测是positive-1和negative-0，true和false描述你本次预测的对错</strong></p> 
<p>true positive-TP：预测为1，预测正确即实际1</p> 
<p>false positive-FP：预测为1，预测错误即实际0</p> 
<p>true negative-TN：预测为0，预测正确即实际0</p> 
<p>false negative-FN：预测为0，预测错误即实际1</p> 
<p> </p> 
<p>【混淆矩阵】</p> 
<p>直观呈现以上四种情况的样本数</p> 
<p> </p> 
<p>【准确率】accuracy</p> 
<p>正确分类的样本/总样本：(TP+TN)/(ALL)</p> 
<p>在不平衡分类问题中难以准确度量：比如98%的正样本只需全部预测为正即可获得98%准确率</p> 
<p> </p> 
<p>【精确率】【查准率】precision</p> 
<p>TP/(TP+FP)：在你预测为1的样本中实际为1的概率</p> 
<p>查准率在检索系统中：检出的<strong>相关</strong>文献与<strong>检出的全部文献</strong>的百分比，衡量<strong>检索的信噪比</strong></p> 
<p> </p> 
<p>【召回率】【查全率】recall</p> 
<p>TP/(TP+FN)：在实际为1的样本中你预测为1的概率</p> 
<p>查全率在检索系统中：检出的<strong>相关</strong>文献与<strong>全部相关</strong>文献的百分比，衡量<strong>检索的覆盖率</strong></p> 
<p> </p> 
<p>实际的二分类中，positive-1标签可以代表健康也可以代表生病，但一般作为<strong>positive-1</strong>的指标指的是<strong>你更关注的样本表现</strong>，比如“是垃圾邮件”“是阳性肿瘤”“将要发生地震”。</p> 
<p>因此在肿瘤判断和地震预测等场景：</p> 
<p><strong>要求模型有更高的【召回率】recall</strong>，是个地震你就都得给我揪出来不能放过</p> 
<p>在垃圾邮件判断等场景：</p> 
<p><strong>要求模型有更高的【精确率】precision，</strong>你给我放进回收站里的可都得确定是垃圾，千万不能有正常邮件啊</p> 
<p> </p> 
<p>【ROC】</p> 
<p>常被用来评价一个二值分类器的优劣</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/81/96/fM5fsB5D_o.jpg" width="500"></p> 
<p>ROC曲线的横坐标为false positive rate（FPR）：<strong>FP/(FP+TN)</strong></p> 
<p>假阳性率，即实际无病，但根据筛检被判为有病的百分比。</p> 
<p>在实际为0的样本中你预测为1的概率</p> 
<p>纵坐标为true positive rate（TPR）：<strong>TP/(TP+FN)</strong></p> 
<p>真阳性率，即实际有病，但根据筛检被判为有病的百分比。</p> 
<p>在实际为1的样本中你预测为1的概率，此处即【召回率】【查全率】recall</p> 
<p> </p> 
<p>接下来我们考虑ROC曲线图中的四个点和一条线。</p> 
<p>第一个点，(0,1)，即FPR=0,TPR=1，这意味着<strong>无病的没有被误判，有病的都全部检测到</strong>，这是一个完美的分类器，它将所有的样本都正确分类。</p> 
<p>第二个点，(1,0)，即FPR=1，TPR=0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。</p> 
<p>第三个点，(0,0)，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，没病的没有被误判但有病的全都没被检测到，即全部选0</p> 
<p>类似的，第四个点（1,1），分类器实际上预测所有的样本都为1。</p> 
<p>经过以上的分析可得到：ROC曲线越接近左上角，该分类器的性能越好。</p> 
<p> </p> 
<p>【ROC是如何画出来的】</p> 
<p>分类器有概率输出，50%常被作为阈值点，但基于不同的场景，可以通过控制概率输出的阈值来改变预测的标签，这样不同的阈值会得到不同的FPR和TPR。</p> 
<p>从0%-100%之间选取任意细度的阈值分别获得FPR和TPR，对应在图中，得到的ROC曲线，阈值的细度控制了曲线的阶梯程度或平滑程度。</p> 
<p>一个没有过拟合的二分类器的ROC应该是梯度均匀的，如图紫线</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/fc/42/BQFQUyoP_o.jpg" width="720"></p> 
<p>此图为PRC， precision recall curve，原理类似</p> 
<p>ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。而Precision-Recall曲线会变化剧烈，故ROC经常被使用。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/71/9d/jqnQlL7u_o.jpg" width="600"></p> 
<p> </p> 
<p>【AUC】</p> 
<p>AUC（Area Under Curve）被定义为ROC曲线下的面积，完全随机的二分类器的AUC为0.5，虽然在不同的阈值下有不同的FPR和TPR，但相对面积更大，更靠近左上角的曲线代表着一个更加稳健的二分类器。</p> 
<p>同时针对每一个分类器的ROC曲线，又能找到一个最佳的概率切分点使得自己关注的指标达到最佳水平。</p> 
<p> </p> 
<p>【AUC的排序本质】</p> 
<p>大部分分类器的输出是概率输出，如果要计算准确率，需要先把概率转化成类别，就需要手动设置一个阈值，而这个超参数的确定会对优化指标的计算产生过于敏感的影响</p> 
<p>AUC从Mann–Whitney U statistic的角度来解释：随机从标签为1和标签为0的样本集中分别随机选择两个样本，同时分类器会输出两样本为1的概率，那么我们认为分类器对<strong>“标签1样本的预测概率&gt;对标签0样本的预测概率 ”的概率</strong>等价于AUC。</p> 
<p>因而AUC反应的是分类器对样本的排序能力，这样也可以理解AUC对不平衡样本不敏感的原因了。</p> 
<p> </p> 
<p>【作为优化目标的各类指标】</p> 
<p>最常用的分类器优化及评价指标是AUC和logloss，最主要的原因是：不同于accuracy，precision等，这两个指标不需要将概率输出转化为类别，而是可以直接使用概率进行计算。</p> 
<p>顺便贴上logloss的公式</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/73/47/Ai22y7ao_o.jpg" width="376"></p> 
<ul><li>N：样本数</li><li>M：类别数，比如上面的多类别例子，M就为4</li><li>yij：第i个样本属于分类j时为为1，否则为0</li><li>pij：第i个样本被预测为第j类的概率</li></ul> 
<p> </p> 
<p>【F1】</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/45/a1/hgs9MaeG_o.jpg" width="211"></p> 
<p>F1兼顾了分类模型的准确率和召回率，可以看作是模型准确率和召回率的<strong>调和平均数</strong>，最大值是1，最小值是0。</p> 
<p> </p> 
<p>额外补充【AUC为优化目标的模型融合手段<strong>rank_avg</strong>】：</p> 
<p>在拍拍贷风控比赛中，印象中一个前排队伍基于AUC的排序本质，使用rank_avg融合了最后的几个基础模型。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/48/ac/eJoxMGgH_o.jpg" width="237"></p> 
<p>rank_avg这种融合方法适合排序评估指标，比如auc之类的</p> 
<p>其中weight_i为该模型权重，权重为1表示平均融合</p> 
<p>rank_i表示样本的升序排名 ，也就是越靠前的样本融合后也越靠前</p> 
<p>能较快的利用排名融合多个模型之间的差异，而不用去加权样本的概率值融合</p> 
<p> </p> 
<p>贴一段源码：</p> 
<pre class="has"><code>#三模型的概率输出
xgb_7844 = pd.read_csv('xgb_7844.csv')
svm_771 = pd.read_csv('svm_771.csv')
xgb_787 = pd.read_csv('xgb_787.csv')

#score概率变为排名
xgb_7844.score = xgb_7844.score.rank()
svm_771.score = svm_771.score.rank()
xgb_787.score = xgb_787.score.rank()

#排名加权融合的结果丧失了概率指义，但AUC的计算不用关系绝对大小，只关心相对大小
pred = 0.7*xgb_787.score + 0.2*xgb_7844.score + 0.1*svm_771.score

#AUC的计算
auc = int(roc_auc_score(val.target.values,pred.values)*10000)</code></pre> 
<p><img alt="" class="has" src="https://images2.imgbox.com/cc/49/coyH5H8e_o.jpg" width="331"></p> 
<p>M为正类样本的数目，N为负类样本的数目，rank为分类器给出的排名。</p> 
<p>可以发现整个计算过程中连直接的概率输出值都不需要，仅关心相对排名，所以只要保证submit的那一组输出的rank是有意义的即可，并不一定需要必须输出概率。</p> 
<p>转：https://zhuanlan.zhihu.com/p/34079183</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aeecc1c796e8c032059b702d0cca950a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">neo4j - 查询效率的几种优化思路</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eda6b671e8daf5ed818f5e6782c5a062/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java实现迷宫问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>