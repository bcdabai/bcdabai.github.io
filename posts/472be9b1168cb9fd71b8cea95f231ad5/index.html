<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用Alexnet模型识别猫和狗 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用Alexnet模型识别猫和狗" />
<meta property="og:description" content="一、测试平台
python：3.6.5
tensorflow：1.6.0
keras：2.1.5
二、前期准备
1、数据收集：本例收集了25000张小猫、小狗的图片，二者各占一半，当然，训练集数据多多益善；
2、数据集预处理：
①猫和狗的图片分别重命名，命名格式为：“cat.number”/“dog.number”,其中number=1，2，3，4……n。文件重命名这一块如果有问题请参考：图片批量重命名；
②将猫和狗的图片放在文件夹：“./data/image/pre_train/”这个文件夹下，并在同一目录创建文件夹train（“./data/image/train/”）；
③将预训练的数据集中的图片resize成需要的大小（本例中Alexnet模型input的图片大小为（-1，224，224，3）），所以我们将pre_train文件夹下的图片resize成（224，224），并存储在train文件夹下；这一步如果有疑问，请参考文章：resize训练集图片大小并存储的方法
④在data文件夹下新建空的dataset.txt文件，根据train文件夹中已训练好的数据集制作label，格式为&#34;cat.number.jpg;0&#34;/“dog.number.jpg;1”
③、④步代码块如下：
#coding=utf-8 [1] &#39;&#39;&#39; 对收集到的数据进行预处理，以减小训练时间； 1、我们将搜集到的图片存放在与软件脚本同一根目录下的&#39;./data/image/pre_train/&#39;文件夹下； 2、我们使用Image模块从pre_train文件夹读取图片，resize，并存储入&#39;./data/image/train/&#39;文件夹； &#39;&#39;&#39; from PIL import Image import os src_path = &#39;./data/image/pre_train/&#39; dst_path = &#39;./data/image/train/&#39; filelist=os.listdir(src_path) for img in filelist: image=Image.open(src_path&#43;img) image_resize=image.resize((224,224),resample=2) &#39;&#39;&#39; # image.resize(size,resample=0) #sesam用于表示改变图像过程中的插值方法，0：双线性插值；1：最邻近插值；2：双三次插值；3|面积插值法 # 参考：python: PIL的Image.resize()函数： &#39;&#39;&#39; image_resize.save(dst_path&#43;img) [2] &#39;&#39;&#39; 生成标签label &#39;&#39;&#39; import os photos=os.listdir(&#39;./data/image/train/&#39;) #os.listdir:用于返回一个由文件名和目录组成的列表 with open(&#39;./data/dataset.txt&#39;,&#39;w&#39;) as f: for photo in photos: name=photo.split(&#39;.&#39;)[0] if name==&#39;cat&#39;: f.write(photo&#43;&#39;;0\n&#39;) #\n:换行 elif name==&#39;dog&#39;: f." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/472be9b1168cb9fd71b8cea95f231ad5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-03T21:35:17+08:00" />
<meta property="article:modified_time" content="2021-04-03T21:35:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用Alexnet模型识别猫和狗</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>一、测试平台</p> 
<p>python：3.6.5<br> tensorflow：1.6.0<br> keras：2.1.5</p> 
<p>二、前期准备</p> 
<p>1、数据收集：本例收集了25000张小猫、小狗的图片，二者各占一半，当然，训练集数据多多益善；<br> 2、数据集预处理：</p> 
<p>①猫和狗的图片分别重命名，命名格式为：“cat.number”/“dog.number”,其中number=1，2，3，4……n。文件重命名这一块如果有问题请参考：<a href="https://blog.csdn.net/weixin_40163266/article/details/114683100?spm=1001.2014.3001.5501">图片批量重命名</a>；</p> 
<p>②将猫和狗的图片放在文件夹：“./data/image/pre_train/”这个文件夹下，并在同一目录创建文件夹train（“./data/image/train/”）；</p> 
<p>③将预训练的数据集中的图片resize成需要的大小（本例中Alexnet模型input的图片大小为（-1，224，224，3）），所以我们将pre_train文件夹下的图片resize成（224，224），并存储在train文件夹下；这一步如果有疑问，请参考文章：<a href="https://blog.csdn.net/weixin_40163266/article/details/115314453?spm=1001.2014.3001.5501">resize训练集图片大小并存储的方法</a></p> 
<p>④在data文件夹下新建空的dataset.txt文件，根据train文件夹中已训练好的数据集制作label，格式为"cat.number.jpg;0"/“dog.number.jpg;1”</p> 
<p>③、④步代码块如下：</p> 
<pre><code class="prism language-python"><span class="token comment">#coding=utf-8</span>

<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token triple-quoted-string string">'''
对收集到的数据进行预处理，以减小训练时间；
1、我们将搜集到的图片存放在与软件脚本同一根目录下的'./data/image/pre_train/'文件夹下；
2、我们使用Image模块从pre_train文件夹读取图片，resize，并存储入'./data/image/train/'文件夹；
'''</span>

<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> os

src_path <span class="token operator">=</span> <span class="token string">'./data/image/pre_train/'</span>
dst_path <span class="token operator">=</span> <span class="token string">'./data/image/train/'</span>

filelist<span class="token operator">=</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>src_path<span class="token punctuation">)</span>
<span class="token keyword">for</span> img <span class="token keyword">in</span> filelist<span class="token punctuation">:</span>
    image<span class="token operator">=</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>src_path<span class="token operator">+</span>img<span class="token punctuation">)</span>
    image_resize<span class="token operator">=</span>image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>resample<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token triple-quoted-string string">'''
    # image.resize(size,resample=0)  #sesam用于表示改变图像过程中的插值方法，0：双线性插值；1：最邻近插值；2：双三次插值；3|面积插值法
    # 参考：python: PIL的Image.resize()函数：
    '''</span>
    image_resize<span class="token punctuation">.</span>save<span class="token punctuation">(</span>dst_path<span class="token operator">+</span>img<span class="token punctuation">)</span>


<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>

<span class="token triple-quoted-string string">'''
生成标签label
'''</span>
<span class="token keyword">import</span> os

photos<span class="token operator">=</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token string">'./data/image/train/'</span><span class="token punctuation">)</span>  <span class="token comment">#os.listdir:用于返回一个由文件名和目录组成的列表</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/dataset.txt'</span><span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> photo <span class="token keyword">in</span> photos<span class="token punctuation">:</span>
        name<span class="token operator">=</span>photo<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> name<span class="token operator">==</span><span class="token string">'cat'</span><span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>photo<span class="token operator">+</span><span class="token string">';0\n'</span><span class="token punctuation">)</span>  <span class="token comment">#\n:换行</span>
        <span class="token keyword">elif</span> name<span class="token operator">==</span><span class="token string">'dog'</span><span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>photo<span class="token operator">+</span><span class="token string">';1\n'</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>三、训练<br> Alexnet模型如下所示<br> <img src="https://images2.imgbox.com/1d/bb/gvI1YRx2_o.png" alt="在这里插入图片描述"><br> 注释：<br> 1、一张原始图片被resize到(224,224,3)；<br> 2、使用步长为4x4，大小为11的卷积核对图像进行卷积，输出的特征层为96层，输出的shape为(55,55,96)；<br> 3、使用步长为2的最大池化层进行池化，此时输出的shape为(27,27,96)<br> 4、使用步长为1x1，大小为5的卷积核对图像进行卷积，输出的特征层为256层，输出的shape为(27,27,256)；<br> 5、使用步长为2的最大池化层进行池化，此时输出的shape为(13,13,256)；<br> 6、使用步长为1x1，大小为3的卷积核对图像进行卷积，输出的特征层为384层，输出的shape为(13,13,384)；<br> 7、使用步长为1x1，大小为3的卷积核对图像进行卷积，输出的特征层为384层，输出的shape为(13,13,384)；<br> 8、使用步长为1x1，大小为3的卷积核对图像进行卷积，输出的特征层为256层，输出的shape为(13,13,256)；<br> 9、使用步长为2的最大池化层进行池化，此时输出的shape为(6,6,256)；<br> 10、两个全连接层，最后输出为1000类</p> 
<p>代码块：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> TensorBoard<span class="token punctuation">,</span> ModelCheckpoint<span class="token punctuation">,</span> ReduceLROnPlateau<span class="token punctuation">,</span> EarlyStopping
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam
<span class="token keyword">from</span> model<span class="token punctuation">.</span>AlexNet <span class="token keyword">import</span> AlexNet

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> utils
<span class="token keyword">import</span> cv2
<span class="token keyword">from</span> keras <span class="token keyword">import</span> backend <span class="token keyword">as</span> K

K<span class="token punctuation">.</span>set_image_dim_ordering<span class="token punctuation">(</span><span class="token string">'tf'</span><span class="token punctuation">)</span>


<span class="token comment"># K.image_data_format()=="channel_first"</span>

<span class="token keyword">def</span> <span class="token function">generate_arrays_from_file</span><span class="token punctuation">(</span>lines<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 获取总长度</span>
    n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> <span class="token number">1</span><span class="token punctuation">:</span>
        X_train <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        Y_train <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 获取一个batch_size大小的数据</span>
        <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>     <span class="token comment">#shuffle:洗牌</span>
            name <span class="token operator">=</span> lines<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment"># 从文件中读取图像</span>
            img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>r<span class="token string">".\data\image\train"</span> <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> name<span class="token punctuation">)</span>
            img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
            img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">255</span>
            X_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
            Y_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>lines<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment"># 读完一个周期后重新开始</span>
            i <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> n  <span class="token comment">#取模，返回除法的余数</span>
        <span class="token comment"># 处理图像</span>
        X_train<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
        <span class="token comment">#X_train = utils.resize_image(X_train, (224, 224))</span>
        <span class="token comment">#X_train = X_train.reshape(-1, 224, 224, 3)  #-1是模糊控制的意思，n,h,w,c，n=-1代表取值不固定</span>
        Y_train <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>Y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment">#np_utils.to_categorical(y_train,2)将原来标签（sample,label）转化为一行两列的 独热码</span>
        <span class="token keyword">yield</span> <span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>  <span class="token comment">#并发编程中完成一个“并发”程序</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    <span class="token comment"># 模型保存的位置</span>
    log_dir <span class="token operator">=</span> <span class="token string">"./logs/"</span>

    <span class="token comment"># 打开数据集的txt</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>r<span class="token string">".\data\dataset.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 打乱行，这个txt主要用于帮助读取数据来训练</span>
    <span class="token comment"># 打乱的数据更有利于训练</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">10101</span><span class="token punctuation">)</span>  <span class="token comment">#预先使用random.seed(x)设定好种子之后，其中x可以是任意数字，比如10，先调用它的情况下，使用random生成的随数将会是同一个，设置的seed()值仅有一个有效</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">)</span>

    <span class="token comment"># 90%用于训练，10%用于估计。</span>
    num_val <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
    num_train <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span> <span class="token operator">-</span> num_val

    <span class="token comment"># 建立AlexNet模型</span>
    model <span class="token operator">=</span> AlexNet<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 保存的方式，3世代保存一次</span>
    checkpoint_period1 <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>   <span class="token comment">#checkpoint:检查站</span>
        log_dir <span class="token operator">+</span> <span class="token string">'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'</span><span class="token punctuation">,</span>
        monitor<span class="token operator">=</span><span class="token string">'acc'</span><span class="token punctuation">,</span>   <span class="token comment">#monitor:三代保存一次</span>
        save_weights_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        period<span class="token operator">=</span><span class="token number">3</span>  <span class="token comment">#period：周期</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 学习率下降的方式，acc三次不下降就下降学习率继续训练</span>
    reduce_lr <span class="token operator">=</span> ReduceLROnPlateau<span class="token punctuation">(</span>   <span class="token comment">#plateau:稳定水平，达到平衡时期</span>
        monitor<span class="token operator">=</span><span class="token string">'acc'</span><span class="token punctuation">,</span>
        factor<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment">#factor：要素</span>
        patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>  <span class="token comment">#patience：耐心</span>
        verbose<span class="token operator">=</span><span class="token number">1</span>    <span class="token comment">#verboss:冗长的</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span>
    early_stopping <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span>
        monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>
        min_delta<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
        patience<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># 交叉熵</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>   <span class="token comment">#compile：编译；     categorical_crossentropy：交叉熵</span>
                  optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment">#optimizer:优化器</span>
                  metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token comment">#metrics:度量；  accuracy:精度，准确度</span>

    <span class="token comment"># 一次的训练集大小</span>
    batch_size <span class="token operator">=</span> <span class="token number">128</span>  <span class="token comment">#batch：一批</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train on {} samples, val on {} samples, with batch size {}.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_train<span class="token punctuation">,</span> num_val<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 开始训练</span>
    model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>generate_arrays_from_file<span class="token punctuation">(</span>lines<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train<span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        steps_per_epoch<span class="token operator">=</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_train <span class="token operator">//</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token triple-quoted-string string">'''
                        #由于generator（)函数循环没有终止条件，fit_generator也不知道一个epoch什么时候结束，所以我们需要动手指定steps_per_epoch参数
                        一般的数值即为len(y)//batch_size.如果过数据集大小不能整除batch_size,而且你打算使用最后一个batch的数据（该batch比batch_size要小），
                        此时使用np.ceil(len(y)//batch_size)
                        '''</span>
                        validation_data<span class="token operator">=</span>generate_arrays_from_file<span class="token punctuation">(</span>lines<span class="token punctuation">[</span>num_train<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        validation_steps<span class="token operator">=</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_val <span class="token operator">//</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
                        initial_epoch<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                        callbacks<span class="token operator">=</span><span class="token punctuation">[</span>checkpoint_period1<span class="token punctuation">,</span> reduce_lr<span class="token punctuation">]</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>save_weights<span class="token punctuation">(</span>log_dir <span class="token operator">+</span> <span class="token string">'last1.h5'</span><span class="token punctuation">)</span>
</code></pre> 
<p>训练结束后，“./logs/”文件夹将生成last1.h5文件，预测环节将调用这个文件</p> 
<p>四、预测</p> 
<p>1、在"./data/model/"文件夹下，新建text文件，并命名为“index_word”,写入：<br> <img src="https://images2.imgbox.com/84/79/PbqWkJyI_o.png" alt="在这里插入图片描述"><br> 预测时，可以通过下面四行代码，调用index_word文件。</p> 
<pre><code class="prism language-python"><span class="token comment">#coding=utf-8</span>

<span class="token comment">#读index_word.txt文档，给预测提供结果</span>

<span class="token keyword">def</span> <span class="token function">print_answer</span><span class="token punctuation">(</span>argmax<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"./data/model/index_word.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        synset <span class="token operator">=</span> <span class="token punctuation">[</span>l<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">";"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>   <span class="token comment">#[:-1]从0到位置为-1的数，这里主要是为了过滤换行符“\n”</span>

    <span class="token comment">#print(synset[argmax])</span>
    <span class="token keyword">return</span> synset<span class="token punctuation">[</span>argmax<span class="token punctuation">]</span>
</code></pre> 
<p>2、预测新图片时，我们不能保证输入图片的尺寸一定是满足要求的，所以还是要对输入的图片resize，</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> utils
<span class="token keyword">import</span> cv2
<span class="token keyword">from</span> keras <span class="token keyword">import</span> backend <span class="token keyword">as</span> K
<span class="token keyword">from</span> model<span class="token punctuation">.</span>AlexNet <span class="token keyword">import</span> AlexNet

K<span class="token punctuation">.</span>set_image_dim_ordering<span class="token punctuation">(</span><span class="token string">'tf'</span><span class="token punctuation">)</span>   <span class="token comment">#tf1版本的用法，'tf'的意思是;数据按照nhwc分布</span>

<span class="token comment">#将预测图片resize成（224，224）</span>
<span class="token keyword">def</span> <span class="token function">resize_image</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scpoe<span class="token punctuation">(</span><span class="token string">'resize image'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> image<span class="token punctuation">:</span>
            i<span class="token operator">=</span>cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>i<span class="token punctuation">,</span>size<span class="token punctuation">)</span>
            images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
        images<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        <span class="token keyword">return</span> images

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> AlexNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span><span class="token string">"./logs/last1.h5"</span><span class="token punctuation">)</span>  <span class="token comment">#调用last1.h5文件</span>
    img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"./Test.jpg"</span><span class="token punctuation">)</span>
    img_RGB <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>img<span class="token punctuation">,</span>cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
    img_nor <span class="token operator">=</span> img_RGB<span class="token operator">/</span><span class="token number">255</span>
    img_nor <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>img_nor<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
    img_resize <span class="token operator">=</span> resize_image<span class="token punctuation">(</span>img_nor<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#utils.print_answer(np.argmax(model.predict(img)))</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>utils<span class="token punctuation">.</span>print_answer<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">"ooo"</span><span class="token punctuation">,</span>img<span class="token punctuation">)</span>
    cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/43a183d1fd411766ba925b90fb751b99/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">交换排序算法之快速排序-C语言版（带图详细）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a4111c33b81633b125336db2967c1124/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">GitBash中文乱码解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>