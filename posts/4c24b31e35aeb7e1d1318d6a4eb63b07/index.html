<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>HDFS写数据流程 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="HDFS写数据流程" />
<meta property="og:description" content="HDFS写数据流程 概述 客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本
步骤图 详细过程 客户端执行写入操作
DistributedFileSystem用RPC调用元数据节点，在文件系统的命名空间中创建一个新的文件。元数据节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后创建新文件。DistributedFileSystem返回DFSOutputStream，客户端用于写数据。客户端开始写入数据，DFSOutputStream将数据分成块，写入data queue。Data queue由Data Streamer读取，并通知元数据节点分配数据节点，用来存储数据块。分配的数据节点放在一个pipeline里。Data Streamer将数据块写入pipeline中的第一个数据节点。第一个数据节点将数据块发送给第二个数据节点。DFSOutputStream为发出去的数据块保存了ack queue，等待pipeline中的数据节点告知数据已经写入成功。如果数据节点在写入的过程中失败： 关闭pipeline，将ack queue中的数据块放入data queue的开始。当前的数据块在已经写入的数据节点中被元数据节点赋予新的标示，则错误节点重启后能够察觉其数据块是过时的，会被删除。失败的数据节点从pipeline中移除，另外的数据块则写入pipeline中的另一个数据节点。元数据节点则被通知此数据块是复制块数不足，将来会再创建备份。当客户端结束写入数据，则调用stream的close函数。此操作将所有的数据块写入pipeline中的数据节点，并等待ack queue返回成功。最后通知元数据节点写入完毕。 部分参考：http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/4c24b31e35aeb7e1d1318d6a4eb63b07/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-03-20T13:21:55+08:00" />
<meta property="article:modified_time" content="2018-03-20T13:21:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">HDFS写数据流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2 id="hdfs写数据流程"> 
 <center>
   HDFS写数据流程 
 </center></h2> 
<h3 id="概述">概述</h3> 
<p>客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本</p> 
<h3 id="步骤图">步骤图</h3> 
<p><img src="https://images2.imgbox.com/90/98/8X33eOwJ_o.png" alt="HDFS写数据步骤图" title=""></p> 
<h3 id="详细过程">详细过程</h3> 
<p>客户端执行写入操作</p> 
<ul><li>DistributedFileSystem用RPC调用元数据节点，在文件系统的命名空间中创建一个新的文件。</li><li>元数据节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后创建新文件。</li><li>DistributedFileSystem返回DFSOutputStream，客户端用于写数据。</li><li>客户端开始写入数据，DFSOutputStream将数据分成块，写入data queue。</li><li>Data queue由Data Streamer读取，并通知元数据节点分配数据节点，用来存储数据块。分配的数据节点放在一个pipeline里。</li><li>Data Streamer将数据块写入pipeline中的第一个数据节点。第一个数据节点将数据块发送给第二个数据节点。</li><li>DFSOutputStream为发出去的数据块保存了ack queue，等待pipeline中的数据节点告知数据已经写入成功。</li><li>如果数据节点在写入的过程中失败： <br> 
  <ul><li>关闭pipeline，将ack queue中的数据块放入data queue的开始。</li><li>当前的数据块在已经写入的数据节点中被元数据节点赋予新的标示，则错误节点重启后能够察觉其数据块是过时的，会被删除。</li><li>失败的数据节点从pipeline中移除，另外的数据块则写入pipeline中的另一个数据节点。</li><li>元数据节点则被通知此数据块是复制块数不足，将来会再创建备份。</li></ul></li><li>当客户端结束写入数据，则调用stream的close函数。此操作将所有的数据块写入pipeline中的数据节点，并等待ack queue返回成功。最后通知元数据节点写入完毕。</li></ul> 
<p>部分参考：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html" rel="nofollow">http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d00fa8ad460d79cae74cbb9adf4527a3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">查看服务器被远程登录的事件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0c30c622ae8993787b33b8ecd1f7a619/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">启动hive错误：Exception in thread &#34;main&#34; java.lang.IllegalArgumentException</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>