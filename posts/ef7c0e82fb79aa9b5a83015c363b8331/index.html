<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大语言模型系列-word2vec - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大语言模型系列-word2vec" />
<meta property="og:description" content="文章目录 前言一、word2vec的网络结构和流程1.Skip-Gram模型2.CBOW模型 二、word2vec的训练机制1. Hierarchical softmax2. Negative Sampling 总结 前言 在前文大语言模型系列-总述已经提到传统NLP的一般流程：
创建语料库 =&gt; 数据预处理 =&gt; 分词向量化 =&gt; 特征选择 =&gt; 建模（RNN、LSTM等） 传统的分词向量化的手段是进行简单编码（如one-hot），存在如下缺点：
如果词库过大， one-hot编码生成的向量会造成维度灾难one-hot编码生成的向量是稀疏的，它们之间的距离相等，无法捕捉单词之间的语义关系。one-hot编码是固定的，无法在训练过程中进行调整。 因此，出现了词嵌入（word embedding）的概念，通过word embedding模型生成的向量是密集的，具有相似含义的单词在向量空间中距离较近，可以捕捉单词之间的语义关系。并且Word Embedding模型的权重可以在训练过程中进行调整，以便更好地捕捉词汇之间的语义关系。
word2vec就是一种经典的词嵌入（word embedding）模型，由Tomas Mikolov等人在2013年提出，它通过学习将单词映射到连续向量空间中的表示，以捕捉单词之间的语义关系。
提示：以下是本篇文章正文内容，下面内容可供参考
一、word2vec的网络结构和流程 Word2Vec是轻量级的神经网络，其模型仅仅包括输入层、隐藏层和输出层，根据学习思路的不同，分为两种训练方式：Skip-Gram和CBOW（Continuous Bag of Words）。其中，Skip-gram是已知当前词的情况下预测上下文的表示，CBOW则是在已知上下文的情况下预测当前词的表示。通过这种表示学习，学得映射矩阵，将原始离散数据空间映射到新的连续向量空间（实际上起到了降维的作用）。
将单词使用one-hot编码输入网络进行训练，获得参数矩阵 W V × N W_{V×N} WV×N​输入层的每个单词one-hot编码x（V-dim）与矩阵W相乘，即 x ⋅ W V × N x \cdot W_{V×N} x⋅WV×N​，得到其word embedding（N-dim） 1.Skip-Gram模型 2.CBOW模型 二、word2vec的训练机制 假设语料库中有V个不同的单词，hidden layer取128，则word2vec两个权值矩阵维度都是[V,128]，我们使用的语料库往往十分庞大，这也会导致权值矩阵的庞大，即神经网络的参数规模的庞大，在使用SGD对庞大的神经网络进行学习时，将是十分缓慢的。
word2vec提出两种加快训练速度的方式，一种是Hierarchical softmax，另一种是Negative Sampling。
1. Hierarchical softmax 和传统的神经网络输出不同的是，word2vec的hierarchical softmax结构是把输出层改成了一颗哈夫曼树，其中图中白色的叶子节点表示词汇表中所有的V个词，黑色节点表示非叶子节点，每一个叶子节点也就是每一个单词,都对应唯一的一条从root节点出发的路径。我们的目的是使的 w = w 0 w=w_0 w=w0​这条路径的概率最大，即: P ( w = w 0 ∣ w I ) P(w=w_0|w_I) P(w=w0​∣wI​)最大，假设最后输出的条件概率是 P ( w = w 0 ∣ w 2 ) P(w=w_0|w_2) P(w=w0​∣w2​)最大，那么只需要去更新从根结点到 w 2 w_2 w2​这一个叶子结点的路径上面节点的向量即可，而不需要更新所有的词的出现概率，这样大大的缩小了模型训练更新的时间。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ef7c0e82fb79aa9b5a83015c363b8331/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-17T14:43:44+08:00" />
<meta property="article:modified_time" content="2024-01-17T14:43:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大语言模型系列-word2vec</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">前言</a></li><li><a href="#word2vec_23" rel="nofollow">一、word2vec的网络结构和流程</a></li><li><ul><li><a href="#1SkipGram_30" rel="nofollow">1.Skip-Gram模型</a></li><li><a href="#2CBOW_32" rel="nofollow">2.CBOW模型</a></li></ul> 
  </li><li><a href="#word2vec_36" rel="nofollow">二、word2vec的训练机制</a></li><li><ul><li><a href="#1_Hierarchical_softmax_42" rel="nofollow">1. Hierarchical softmax</a></li><li><a href="#2_Negative_Sampling_58" rel="nofollow">2. Negative Sampling</a></li></ul> 
  </li><li><a href="#_80" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_4"></a>前言</h2> 
<p>在前文<a href="https://blog.csdn.net/long11350/article/details/135607574?spm=1001.2014.3001.5501">大语言模型系列-总述</a>已经提到传统NLP的一般流程：</p> 
<pre><code>创建语料库 =&gt; 数据预处理 =&gt; 分词向量化 =&gt; 特征选择 =&gt; 建模（RNN、LSTM等）
</code></pre> 
<p>传统的分词向量化的手段是进行简单编码（如one-hot），存在如下缺点：</p> 
<ul><li>如果词库过大， one-hot编码生成的向量会造成维度灾难</li><li>one-hot编码生成的向量是稀疏的，它们之间的距离相等，无法捕捉单词之间的语义关系。</li><li>one-hot编码是固定的，无法在训练过程中进行调整。</li></ul> 
<p>因此，出现了词嵌入（word embedding）的概念，通过word embedding模型生成的向量是密集的，具有相似含义的单词在向量空间中距离较近，可以捕捉单词之间的语义关系。并且Word Embedding模型的权重可以在训练过程中进行调整，以便更好地捕捉词汇之间的语义关系。</p> 
<p><strong>word2vec就是一种经典的词嵌入（word embedding）模型，由Tomas Mikolov等人在2013年提出，它通过学习将单词映射到连续向量空间中的表示，以捕捉单词之间的语义关系。</strong></p> 
<hr> 
<p><code>提示：以下是本篇文章正文内容，下面内容可供参考</code></p> 
<h2><a id="word2vec_23"></a>一、word2vec的网络结构和流程</h2> 
<p>Word2Vec是轻量级的神经网络，其模型仅仅包括输入层、隐藏层和输出层，根据学习思路的不同，分为两种训练方式：Skip-Gram和CBOW（Continuous Bag of Words）。其中，Skip-gram是已知当前词的情况下预测上下文的表示，CBOW则是在已知上下文的情况下预测当前词的表示。通过这种表示学习，学得映射矩阵，将原始离散数据空间映射到新的连续向量空间（实际上起到了降维的作用）。</p> 
<ul><li>将单词使用one-hot编码</li><li>输入网络进行训练，获得参数矩阵<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           W 
          
          
          
            V 
           
          
            × 
           
          
            N 
           
          
         
        
       
         W_{V×N} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span></li><li>输入层的每个单词one-hot编码x（V-dim）与矩阵W相乘，即<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          x 
         
        
          ⋅ 
         
         
         
           W 
          
          
          
            V 
           
          
            × 
           
          
            N 
           
          
         
        
       
         x \cdot W_{V×N} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4445em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，得到其word embedding（N-dim）</li></ul> 
<h3><a id="1SkipGram_30"></a>1.Skip-Gram模型</h3> 
<p><img src="https://images2.imgbox.com/ed/d9/Zokfc1Q8_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2CBOW_32"></a>2.CBOW模型</h3> 
<p><img src="https://images2.imgbox.com/5a/1b/3pfps9NW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/77/e0/iXJh7Mhz_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="word2vec_36"></a>二、word2vec的训练机制</h2> 
<p>假设语料库中有V个不同的单词，hidden layer取128，则word2vec两个权值矩阵维度都是[V,128]，我们使用的语料库往往十分庞大，这也会导致权值矩阵的庞大，即神经网络的参数规模的庞大，在使用SGD对庞大的神经网络进行学习时，将是十分缓慢的。</p> 
<p>word2vec提出两种加快训练速度的方式，一种是Hierarchical softmax，另一种是Negative Sampling。</p> 
<h3><a id="1_Hierarchical_softmax_42"></a>1. Hierarchical softmax</h3> 
<p>和传统的神经网络输出不同的是，word2vec的hierarchical softmax结构是把输出层改成了一颗哈夫曼树，其中图中白色的叶子节点表示词汇表中所有的V个词，黑色节点表示非叶子节点，每一个叶子节点也就是每一个单词,都对应唯一的一条从root节点出发的路径。我们的目的是使的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         w 
        
       
         = 
        
        
        
          w 
         
        
          0 
         
        
       
      
        w=w_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>这条路径的概率最大，即: <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ( 
        
       
         w 
        
       
         = 
        
        
        
          w 
         
        
          0 
         
        
       
         ∣ 
        
        
        
          w 
         
        
          I 
         
        
       
         ) 
        
       
      
        P(w=w_0|w_I) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>最大，假设最后输出的条件概率是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ( 
        
       
         w 
        
       
         = 
        
        
        
          w 
         
        
          0 
         
        
       
         ∣ 
        
        
        
          w 
         
        
          2 
         
        
       
         ) 
        
       
      
        P(w=w_0|w_2) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>最大，那么只需要去更新从根结点到<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          2 
         
        
       
      
        w_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>这一个叶子结点的路径上面节点的向量即可，而不需要更新所有的词的出现概率，这样大大的缩小了模型训练更新的时间。</p> 
<p><img src="https://images2.imgbox.com/29/aa/hiyrSCBS_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>ps：</p> 
 <ul><li>给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。</li><li>我们知道在输入softmax之前，可以简单认为神经网络输出的大体含义为每个单词的频率，可以将其视为权值，然后通过哈夫曼树编码。这样在训练时，如果我们要计算Leaf2（观看）的概率，只需计算从Root到Leaf2路径上的节点的概率即可，而不需要考虑其他叶子节点，从而大大降低计算复杂度。<br> <img src="https://images2.imgbox.com/7b/25/uwXicCC7_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8c/34/kzlZucU6_o.png" alt="在这里插入图片描述"></li></ul> 
</blockquote> 
<p>Hierarchical softmax的优点如下：</p> 
<p>1）从利用softmax计算概率值改为利用Huffman树计算概率值，计算复杂度从O(V)变成了O(logV)<br> 2）由于使用霍夫曼树是高频的词靠近树根，这样高频词需要更少的时间会被找到（贪心优化思想）</p> 
<h3><a id="2_Negative_Sampling_58"></a>2. Negative Sampling</h3> 
<p>我们已经知道，对于每个训练样本，word2vec都需要计算并更新所有词汇表中的词的权重。这在大规模的词汇表上会变得非常昂贵，尤其是当词汇表非常大时。</p> 
<p>Hierarchical softmax通过哈夫曼树，使得对于每个训练样本，只需要更新路径节点权重即可，大大减少了参数量和计算成本。Negative Sampling则通过只更新与当前训练样本相关的一小部分词的权重，以此来降低计算成本。具体步骤如下：</p> 
<ol><li>对于输入的中心词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
       
         w_c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，设置窗口大小m，该窗口大小内的词为正样本（即<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
          
          
            c 
           
          
            − 
           
          
            m 
           
          
         
        
          , 
         
        
          . 
         
        
          . 
         
        
          . 
         
        
          , 
         
         
         
           w 
          
          
          
            c 
           
          
            + 
           
          
            m 
           
          
         
        
       
         w_{c-m},...,w_{c+m} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6389em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，不包括<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
       
         w_c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>）</li><li>按照一定的概率分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
         
         
           w 
          
         
           ~ 
          
         
        
          ) 
         
        
       
         P(\tilde w) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>从词典中抽取K个负样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            w 
           
          
            ~ 
           
          
         
           1 
          
         
        
          , 
         
         
          
          
            w 
           
          
            ~ 
           
          
         
           2 
          
         
        
          , 
         
        
          . 
         
        
          . 
         
        
          . 
         
        
          , 
         
         
          
          
            w 
           
          
            ~ 
           
          
         
           k 
          
         
        
       
         \tilde w_1, \tilde w_2,..., \tilde w_k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8623em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，那么{<!-- --><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
          , 
         
         
          
          
            w 
           
          
            ~ 
           
          
         
           k 
          
         
        
       
         w_c,\tilde w_k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8623em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>}为负样本，其中k=1,2,…,K</li><li>则给定中心词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
       
         w_c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，预测<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           j 
          
         
        
       
         w_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
          ∈ 
         
        
          [ 
         
        
          c 
         
        
          − 
         
        
          m 
         
        
          , 
         
        
          c 
         
        
          + 
         
        
          m 
         
        
          ] 
         
        
       
         j∈[c-m,c+m] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">m</span><span class="mclose">]</span></span></span></span></span>）由如下事件集构成：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
       
         w_c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           j 
          
         
        
       
         w_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>共同出现，以及<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
         
           c 
          
         
        
       
         w_c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>不和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            w 
           
          
            ~ 
           
          
         
           k 
          
         
        
       
         \tilde w_k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8179em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>共同出现</li></ol> 
<p>Negative Sampling的优点如下：</p> 
<p>1）将多分类问题转换成K+1个二分类问题，从而减少计算量，计算复杂度由O(V)变成了O(K)，加快了训练速度。<br> 2）保证模型训练效果，因为目标词只跟相近的词有关，没有必要使用全部的单词作为负例来更新它们的权重。</p> 
<hr> 
<h2><a id="_80"></a>总结</h2> 
<p>和之前的方法相比，word2vec能够考虑上下文并获得低维的词向量表示，但word2vec无法解决多义词问题，没有语境信息，原因是word embedding是静态的（词和向量是一对一的关系），并且词嵌入和实际任务模型分开，使得整个训练过程不是端到端的。<br> <img src="https://images2.imgbox.com/df/d0/Izg0FItO_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2a04442755d1b87a021f5ee75aa9d037/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">一篇综述洞悉医学大型语言模型的原理，应用和挑战</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bd4b4db9630fe7b4b7d77575e4dc099c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言经典练习3——[NOIP2008]ISBN号码与圣诞树</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>