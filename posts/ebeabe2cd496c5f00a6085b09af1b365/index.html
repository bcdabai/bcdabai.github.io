<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用自己的数据利用pytorch搭建自编码器提取特征 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用自己的数据利用pytorch搭建自编码器提取特征" />
<meta property="og:description" content="使用自己的数据利用pytorch搭建自编码器提取特征 1、定义编码器（Encoder）和解码器（Decoder）模型2、定义自编码器（Autoencoder）模型3、定义自定义数据集（MyDataset）4、参数初始化5、加载数据集6、构造数据集7、定义损失函数和优化器8、训练自编码器模型9、特征提取10、完整代码 使用PyTorch实现的自编码器模型，它的作用是对一个数据集进行特征提取。具体步骤如下： 1、定义编码器（Encoder）和解码器（Decoder）模型 它们分别由两个全连接层组成。
2、定义自编码器（Autoencoder）模型 它包含一个编码器和一个解码器。
3、定义自定义数据集（MyDataset） 它用于加载数据集，构造tensor数据集。
4、参数初始化 定义超参数。
5、加载数据集 提取需要的特征和标签，对特征进行数据标准化。
6、构造数据集 构造tensor数据集并封装为可迭代对象，创建Dataloader对象，用于批量读取数据。
7、定义损失函数和优化器 初始化模型、损失函数和优化器
8、训练自编码器模型 训练模型，并输出每个epoch的损失值。
9、特征提取 使用训练好的自编码器模型对数据集进行特征提取，并将提取的特征保存为csv文件。
需要注意的是，这段代码没有包含模型的测试部分，但是在训练之后，可以使用训练好的自编码器模型对新的数据进行特征提取。
10、完整代码 # -*- coding: utf-8 -*- # @Time : 2023/5/25 14:29 # @Author : huangjian # @File : AE.py import torch import torch.nn as nn from torch.utils.data import DataLoader, Dataset import pandas as pd from sklearn import preprocessing # 定义编码器 class Encoder(nn.Module): def __init__(self, input_dim, hidden_dim, latent_dim): super(Encoder, self)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ebeabe2cd496c5f00a6085b09af1b365/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-25T16:16:41+08:00" />
<meta property="article:modified_time" content="2023-05-25T16:16:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用自己的数据利用pytorch搭建自编码器提取特征</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>使用自己的数据利用pytorch搭建自编码器提取特征</h4> 
 <ul><li><a href="#1EncoderDecoder_3" rel="nofollow">1、定义编码器（Encoder）和解码器（Decoder）模型</a></li><li><a href="#2Autoencoder_6" rel="nofollow">2、定义自编码器（Autoencoder）模型</a></li><li><a href="#3MyDataset_9" rel="nofollow">3、定义自定义数据集（MyDataset）</a></li><li><a href="#4_12" rel="nofollow">4、参数初始化</a></li><li><a href="#5_14" rel="nofollow">5、加载数据集</a></li><li><a href="#6_17" rel="nofollow">6、构造数据集</a></li><li><a href="#7_19" rel="nofollow">7、定义损失函数和优化器</a></li><li><a href="#8_21" rel="nofollow">8、训练自编码器模型</a></li><li><a href="#9_24" rel="nofollow">9、特征提取</a></li><li><a href="#10_29" rel="nofollow">10、完整代码</a></li></ul> 
</div> 
<br> 使用PyTorch实现的自编码器模型，它的作用是对一个数据集进行特征提取。具体步骤如下： 
<p></p> 
<h2><a id="1EncoderDecoder_3"></a>1、定义编码器（Encoder）和解码器（Decoder）模型</h2> 
<p>它们分别由两个全连接层组成。</p> 
<h2><a id="2Autoencoder_6"></a>2、定义自编码器（Autoencoder）模型</h2> 
<p>它包含一个编码器和一个解码器。</p> 
<h2><a id="3MyDataset_9"></a>3、定义自定义数据集（MyDataset）</h2> 
<p>它用于加载数据集，构造tensor数据集。</p> 
<h2><a id="4_12"></a>4、参数初始化</h2> 
<p>定义超参数。</p> 
<h2><a id="5_14"></a>5、加载数据集</h2> 
<p>提取需要的特征和标签，对特征进行数据标准化。</p> 
<h2><a id="6_17"></a>6、构造数据集</h2> 
<p>构造tensor数据集并封装为可迭代对象，创建Dataloader对象，用于批量读取数据。</p> 
<h2><a id="7_19"></a>7、定义损失函数和优化器</h2> 
<p>初始化模型、损失函数和优化器</p> 
<h2><a id="8_21"></a>8、训练自编码器模型</h2> 
<p>训练模型，并输出每个epoch的损失值。</p> 
<h2><a id="9_24"></a>9、特征提取</h2> 
<p>使用训练好的自编码器模型对数据集进行特征提取，并将提取的特征保存为csv文件。</p> 
<p>需要注意的是，这段代码没有包含模型的测试部分，但是在训练之后，可以使用训练好的自编码器模型对新的数据进行特征提取。</p> 
<h2><a id="10_29"></a>10、完整代码</h2> 
<pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># @Time : 2023/5/25 14:29</span>
<span class="token comment"># @Author : huangjian</span>
<span class="token comment"># @File : AE.py</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing


<span class="token comment"># 定义编码器</span>
<span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


<span class="token comment"># 定义解码器</span>
<span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Decoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


<span class="token comment"># 定义自编码器</span>
<span class="token keyword">class</span> <span class="token class-name">Autoencoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Autoencoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


<span class="token comment"># 定义自定义数据集</span>
<span class="token keyword">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 参数初始化</span>
input_size <span class="token operator">=</span> <span class="token number">9</span>     <span class="token comment"># 输入数据维度</span>
hidden_size <span class="token operator">=</span> <span class="token number">64</span>     <span class="token comment"># 隐藏层维度</span>
output_size <span class="token operator">=</span> <span class="token number">6</span>     <span class="token comment"># 输出维度</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>     <span class="token comment"># 学习率</span>
num_epochs <span class="token operator">=</span> <span class="token number">50</span>     <span class="token comment"># 迭代次数</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>     <span class="token comment"># 每次迭代的批次大小</span>
feature_select <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">,</span> <span class="token string">'day_of_week'</span><span class="token punctuation">,</span> <span class="token string">'is_weekend'</span><span class="token punctuation">,</span> <span class="token string">'is_holiday'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">,</span>
                  <span class="token string">'is_start_of_semester'</span><span class="token punctuation">,</span> <span class="token string">'is_during_semester'</span><span class="token punctuation">,</span> <span class="token string">'month'</span><span class="token punctuation">,</span> <span class="token string">'hour'</span><span class="token punctuation">]</span>

<span class="token comment"># 加载数据集</span>
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dataset.csv"</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">)</span>

<span class="token comment"># 提取特征和标签</span>
x_data<span class="token punctuation">,</span> y_data <span class="token operator">=</span> data<span class="token punctuation">[</span>feature_select<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span>

<span class="token comment"># 数据标准化</span>
standardScaler <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
standardScaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
x_train <span class="token operator">=</span> standardScaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>

<span class="token comment"># 加载数据集</span>
train_dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 模型初始化</span>
autoencoder <span class="token operator">=</span> Autoencoder<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
<span class="token comment"># 定义损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>autoencoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> data
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> autoencoder<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch [{}/{}], Loss: {:.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 测试模型</span>
autoencoder<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        feature <span class="token operator">=</span> autoencoder<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>
    features <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>features<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>features<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
features <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
features<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"AE_features.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e9cfd44e8fb63002c9a54f6f235850af/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">粘性定位设置导航栏滚动字体会透过去</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c89df05858dc5ec39fa50c94550d7d3d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">编写函数将一个M * N的矩阵转置成 N * M 的矩阵</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>