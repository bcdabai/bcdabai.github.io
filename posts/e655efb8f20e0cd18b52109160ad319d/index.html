<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>详细解读：MIT经典的语义分割数据集ADE20K，附下载链接 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="详细解读：MIT经典的语义分割数据集ADE20K，附下载链接" />
<meta property="og:description" content="小伙伴们，乐于分享的OpenDataLab来啦！这次，给大家带来一份ADE20K 数据集的详细使用“攻略”，助大家模型训练一臂之力。
这个由MIT 发布的大型数据集，可用于场景感知、解析、分割、多物体识别和语义理解，不容错过。
一、数据集简介 发布方：MIT CSAIL Computer Vision Group
发布时间：2016
背景：视觉场景的语义理解是计算机视觉的关键问题。尽管社区在数据收集方面做出了努力，但仍然很少有图像数据集涵盖广泛的场景和对象类别，而且缺乏具有用于场景理解的逐像素注释。
简介：ADE20K涵盖了场景、对象、对象部分的各种注释，在某些情况下甚至是部分的部分。有25k张复杂日常场景的图像，其中包含自然空间环境中的各种对象。每个图像平均有19.5个实例和10.5个对象类。
二、数据集详细信息 1. 标注数据量
● 训练集：20210张图像
● 验证集：2000张图像
● 测试集：3000张图像
2. 标注类别
数据集的标注包含三种视觉概念：
● 离散对象（discrete object），它是具有明确定义的形状的事物，例如汽车、人；
● 包含无定形背景区域的东西（stuff），例如草、天空；
● 对象部分（object part），它是某些具有功能意义的现有对象实例的组件，例如头部或腿部。
三种视觉概念共标注类别3169类，其中离散对象和无定形背景区域的东西有2693类。对象部分有476类。
3. 可视化
图1：第一行显示样本图像，第二行显示对象的标注，第三行显示对象部分的标注。颜色方案同时编码对象类别和对象实例，即不同的对象类别具有较大的色差，而来自同一对象类别的不同实例具有较小的色差（例如，第一张图像中的不同人实例具有略微不同的颜色）。
三、数据集任务定义及介绍 1. 场景解析 ● 定义
场景解析是将整个图像密集地分割成语义类，其中每个像素都被分配一个类标签，例如树的区域和建筑物的区域。
● 基准
作者选择 ADE20K 数据集中按其总像素比排名的前150个类别，并构建 ADE20K 的场景解析基准，称为 SceneParse150。
在150个类别中，有35个东西类（即墙壁、天空、道路）和115个离散对象类（即汽车、人、桌子）。150个类的标注像素占数据集所有像素的92.75%，其中无定形背景区域的东西类占60.92%，离散对象类占31.83%。
结果以通常用于语义分割的四个指标报告：
- Pixel accuracy（像素精度）：表示正确分类的像素的比例；
- Mean accuracy（平均准确度）：表示在所有类别中平均正确分类的像素的比例；
- Mean IoU（平均 IoU）：表示预测像素和真实像素之间的交并比，在所有类上平均；
- Weighted IoU（加权IoU）：表示按每个类的总像素比加权的 IoU。
2. 实例分割 ● 定义" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/e655efb8f20e0cd18b52109160ad319d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-11T10:57:54+08:00" />
<meta property="article:modified_time" content="2022-07-11T10:57:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">详细解读：MIT经典的语义分割数据集ADE20K，附下载链接</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>小伙伴们，乐于分享的OpenDataLab来啦！这次，给大家带来一份ADE20K 数据集的详细使用“攻略”，助大家模型训练一臂之力。</p> 
<p>这个由MIT 发布的大型数据集，可用于场景感知、解析、分割、多物体识别和语义理解，不容错过。</p> 
<p></p> 
<h2><strong>一、数据集简介</strong></h2> 
<p><strong>发布方：</strong>MIT CSAIL Computer Vision Group</p> 
<p><strong>发布时间：</strong>2016</p> 
<p><strong>背景：</strong>视觉场景的语义理解是计算机视觉的关键问题。尽管社区在数据收集方面做出了努力，但仍然很少有图像数据集涵盖广泛的场景和对象类别，而且缺乏具有用于场景理解的逐像素注释。</p> 
<p><strong>简介：</strong>ADE20K涵盖了场景、对象、对象部分的各种注释，在某些情况下甚至是部分的部分。有25k张复杂日常场景的图像，其中包含自然空间环境中的各种对象。每个图像平均有19.5个实例和10.5个对象类。</p> 
<p></p> 
<h2>二、<strong>数据集详细信息</strong></h2> 
<p><strong>1. 标注数据量</strong></p> 
<p>● 训练集：20210张图像</p> 
<p>● 验证集：2000张图像</p> 
<p>● 测试集：3000张图像</p> 
<p></p> 
<p><strong>2. 标注类别</strong></p> 
<p>数据集的标注包含三种视觉概念：</p> 
<p>● 离散对象（discrete object），它是具有明确定义的形状的事物，例如汽车、人；</p> 
<p>● 包含无定形背景区域的东西（stuff），例如草、天空；</p> 
<p>● 对象部分（object part），它是某些具有功能意义的现有对象实例的组件，例如头部或腿部。</p> 
<p>三种视觉概念共标注类别3169类，其中离散对象和无定形背景区域的东西有2693类。对象部分有476类。</p> 
<p><br><strong>3. 可视化</strong></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/69/f4/vYTHiqT8_o.png"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">图1：第一行显示样本图像，第二行显示对象的标注，第三行显示对象部分的标注。颜色方案同时编码对象类别和对象实例，即不同的对象类别具有较大的色差，而来自同一对象类别的不同实例具有较小的色差（例如，第一张图像中的不同人实例具有略微不同的颜色）。</span></p> 
<p style="text-align:center;"></p> 
<p></p> 
<h2><strong>三、数据集任务定义及介绍</strong></h2> 
<h3><strong>1. 场景解析</strong></h3> 
<p><strong>● 定义</strong></p> 
<p>场景解析是将整个图像密集地分割成语义类，其中每个像素都被分配一个类标签，例如树的区域和建筑物的区域。</p> 
<p></p> 
<p><strong>● 基准</strong></p> 
<p>作者选择 ADE20K 数据集中按其总像素比排名的前150个类别，并构建 ADE20K 的场景解析基准，称为 <strong>SceneParse150</strong>。</p> 
<p>在150个类别中，有35个东西类（即墙壁、天空、道路）和115个离散对象类（即汽车、人、桌子）。150个类的标注像素占数据集所有像素的92.75%，其中无定形背景区域的东西类占60.92%，离散对象类占31.83%。</p> 
<p></p> 
<p>结果以通常用于语义分割的四个指标报告：</p> 
<p><strong>- Pixel accuracy（像素精度）：</strong>表示正确分类的像素的比例；</p> 
<p><strong>- Mean accuracy（平均准确度）：</strong>表示在所有类别中平均正确分类的像素的比例；</p> 
<p><strong>- Mean IoU（平均 IoU）：</strong>表示预测像素和真实像素之间的交并比，在所有类上平均；</p> 
<p><strong>- Weighted IoU（加权IoU）：</strong>表示按每个类的总像素比加权的 IoU。</p> 
<p></p> 
<h3><strong>2. 实例分割</strong></h3> 
<p><strong><strong>● 定义</strong></strong></p> 
<p>实例分割是检测图像中的对象实例，并进一步生成对象的精确分割掩码。它与场景解析任务的不同之处在于，场景解析中没有分割区域的实例概念，而在实例分割中，如果场景中有三个人，则需要网络对每个人区域进行分割。</p> 
<p></p> 
<p><strong>● 基准</strong></p> 
<p>为了对实例分割的性能进行基准测试，作者从完整数据集中选择了100个前景对象类别，将其称为 InstSeg100。InstSeg100 中对象实例总数为 218K，平均每个对象类别有2.2K个实例，每个图像有10个实例；除船舶外的所有对象都有超过100个实例。</p> 
<p></p> 
<p>结果以如下指标报告：</p> 
<p>一个总体度量平均精度 mAP，以及不同对象尺度上的度量，用mAP_S（小于32×32像素的对象）、mAP_M（在32×32和96×96像素之间）和 mAP_L（大于96×96像素）。</p> 
<p></p> 
<h2><strong>四、数据集文件结构解读</strong></h2> 
<p><strong>目录结构：</strong>（语言：Python）</p> 
<pre><code>ADE20K_2021_17_01/</code><code>    images/</code><code>        training/</code><code>            cultural/</code><code>                apse__indoor/</code><code>                    &lt;filename0&gt;.jpg         # 原图像</code><code>                    &lt;filename0&gt;_seg.png     # 分割图，通道R和G编码对象类别ID，</code><code>                                            # 通道B编码实例ID</code><code>                    &lt;filename0&gt;_parts_{i}.png </code><code>                                            # 部件分割图,i表示第i层部件，如car</code><code>                                            # 属于第一层部件，wheel属于第二层部件</code><code>                    &lt;filename0&gt;.json        # 存储图像中所有实例的多边形，属性等信息</code><code>                    &lt;filename0&gt;/            # 存储图像中所有实例mask的目录</code><code>                        instance_000_&lt;filename0&gt;.png</code><code>                        instance_001_&lt;filename0&gt;.png</code><code>                    ...</code><code>                ...</code><code>            ...</code><code>        validation/</code><code>            cultural/</code><code>                apse__indoor/</code><code>                    &lt;filename1&gt;.jpg</code><code>                    &lt;filename1&gt;_seg.png</code><code>                    &lt;filename1&gt;_aprts_{i}.png</code><code>                    &lt;filename1&gt;.json</code><code>                    &lt;filename1&gt;/</code><code>                        instance_000_&lt;filename1&gt;.png</code><code>                        instance_001_&lt;filename1&gt;.png</code><code>                        ...</code><code>                    ...</code><code>                ...</code><code>            ...</code><code>    index_ade20k.pkl                    # 数据和存储图像的文件夹的统计信息</code></pre> 
<p><strong>&lt;filename&gt;.json文件格式：</strong></p> 
<pre><code>{<!-- --></code><code>    "annotation": {<!-- --></code><code>        "filename": "&lt;filename&gt;.jpg",   # 图像名称</code><code>        "folder": "ADE20K_2021_17_01/images/ADE/training/urban/street",</code><code>                                        # 图像存储的相对路径</code><code>        "imsize": [                     # 图像高、宽、通道数</code><code>            1536,</code><code>            2048,</code><code>            3</code><code>        ],</code><code>        "source": {                     # 图像来源信息</code><code>            "folder": "static_sun_database/s/street",</code><code>            "filename": "labelme_acyknxirsfolpon.jpg",</code><code>            "origin": ""</code><code>        },</code><code>        "scene": [                      # 图像场景信息</code><code>            "outdoor",</code><code>            "urban",</code><code>            "street"</code><code>        ],</code><code>        "object": [                     # 标注实例列表</code><code>            {<!-- --></code><code>                "id":0,                 # 实例ID</code><code>                "name":"traffic light, traffic signal, stoplight",</code><code>                                        # 实例标签</code><code>                "name_ndx": 2836,       # 实例标签</code><code>                "hypernym": [           # 上位词</code><code>                    "traffic light, traffic signal, stoplight",</code><code>                    "light",</code><code>                    "visual signal",</code><code>                    "signal, signaling, sign",</code><code>                    "communication",</code><code>                    "abstraction, abstract entity",</code><code>                    "entity"</code><code>                ],</code><code>                "raw_name": "traffic light",</code><code>                "attributes": [],       # 属性</code><code>                "depth_ordering_rank": 1,</code><code>                                        # 深度顺序</code><code>                "occluded": "no",       # 遮挡情况</code><code>                "crop": "0",</code><code>                "parts": {              # 部件信息</code><code>                    "hasparts": [],</code><code>                    "ispartof": [],</code><code>                    "part_level": 0</code><code>                },</code><code>                "instance_mask": "&lt;filename&gt;/instance_000_&lt;filename&gt;.png",</code><code>                                        # 对应的实例mask</code><code>                "polygon": {            # 多边形坐标</code><code>                    "x": [346, ...],</code><code>                    "y": [781, ...]</code><code>                },</code><code>                "saved_date": "18-Dec-2005 06:56:48"</code><code>            },</code><code>            ...</code><code>        ]</code>
</pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/42/aa/8Yqe4frc_o.png"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">图2: index_ade20k.pkl 文件用Python打开后的格式</span></p> 
<p></p> 
<h3><strong>index_ade20k.pkl 里各个字段含义：</strong></h3> 
<p><strong>'filename'：</strong>长度为 N=27574 的数组，带有图像文件名。</p> 
<p></p> 
<p><strong>'folder'：</strong>包含图像文件夹名称的长度为 N 的数组。</p> 
<p></p> 
<p><strong>'objectIsPart'：</strong>是对象部分的对象类别. 大小为 [C, N] 的数组，计算一个对象在每个图像中成为一部分的次数。objectIsPart[c,i]=m 如果在图像 i 中对象类 c 是另一个对象的一部分 m 次。</p> 
<p></p> 
<p><strong>'objectPresence'：</strong>大小为 [C, N] 的数组，每个图像的对象计数。objectPresence(c,i)=n 如果在图像 i 中有 n 个对象类 c 的实例。</p> 
<p></p> 
<p><strong>'objectcounts'：</strong>长度为 C 的数组，每个对象类的实例数。</p> 
<p></p> 
<p><strong>'objectnames'：</strong>带有对象类名的长度为 C 的数组。</p> 
<p></p> 
<p><strong>'proportionClassIsPart'：</strong>长度为 C 的数组，其中 c 类作为一部分的次数比例。如果 ratioClassIsPart[c]=0 则意味着这是一个主要对象（例如，汽车、椅子……）。</p> 
<p></p> 
<p><strong>'scene'：</strong>长度为 N 的数组，为每个图像提供场景名称（与 Places 数据库相同的类）</p> 
<p></p> 
<p><strong>'wordnet_found'：</strong>长度为 C 的数组。它表示是否在 Wordnet 中找到了对象名。</p> 
<p></p> 
<p><strong>'wordnet_level1'：</strong>长度为C 的列表。WordNet 关联的列表。</p> 
<p></p> 
<p><strong>'wordnet_synset'：</strong>长度为 C 的列表。每个对象名称的 WordNet 同义词集。</p> 
<p></p> 
<p><strong>'wordnet_hypernym'：</strong>长度为 C 的列表。每个对象名称的 WordNet 上位词列表。</p> 
<p></p> 
<p><strong>'wordnet_gloss'：</strong>长度为 C 的列表。存的是WordNet同义词集合对应的定义。</p> 
<p></p> 
<p><strong>'wordnet_frequency'：</strong>长度为 C 的数组。每个WordNet同义词集合出现的次数。</p> 
<p></p> 
<p><strong>'description'：</strong>对index ade20k.pkl中每个字段的描述。</p> 
<p></p> 
<h2><strong>五、数据集资源</strong></h2> 
<p>OpenDataLab平台已经上架了ADE20K数据集，为大家提供了完整的数据集信息、流畅的下载速度，快来体验吧！</p> 
<p><strong><a class="link-info" href="https://opendatalab.com/ADE20K_2021" rel="nofollow" title="ADE20K 2021数据集">ADE20K 2021数据集</a></strong></p> 
<p></p> 
<p></p> 
<p><strong>参考资料：</strong></p> 
<p>[1]官网：<a class="link-info" href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" rel="nofollow" title="https://groups.csail.mit.edu/vision/datasets/ADE20K/">https://groups.csail.mit.edu/vision/datasets/ADE20K/</a></p> 
<p>[2]论文：Semantic Understanding of Scenes through ADE20K Dataset. Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso and Antonio Torralba. International Journal on Computer Vision (IJCV).[PDF]</p> 
<p>[3]Github：<a class="link-info" href="https://github.com/CSAILVision/ADE20K" title="https://github.com/CSAILVision/ADE20K">https://github.com/CSAILVision/ADE20K</a></p> 
<p></p> 
<p>更多数据集上架动态、更全面的数据集内容解读、最牛大佬在线答疑、最活跃的同行圈子……欢迎添加微信<strong>opendatalab_yunying </strong>加入OpenDataLab官方交流群。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d3244f0a41e069369fd5be665982d6b5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">java通过TCP实现HL7医疗系统传输协议</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7ac963da83364261ab05d853145600eb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">多目标跟踪（MOT）数据集资源整理分享</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>