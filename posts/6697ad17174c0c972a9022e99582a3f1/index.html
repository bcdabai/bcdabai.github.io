<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>流式数据湖存储技术，Apache Paimon是什么？ - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="流式数据湖存储技术，Apache Paimon是什么？" />
<meta property="og:description" content="流式数据湖存储技术，Apache Paimon是什么？ 00 导读01 什么是 Apache Paimon02 开放的数据格式03 大规模实时更新04 数据表局部更新05 流批一体数据读写 来源：https://paimon.apache.org/
00 导读 2023年3月12日，Flink Table Store 项目顺利通过投票，正式进入 Apache 软件基金会 (ASF) 的孵化器，改名为 Apache Paimon (incubating)。
Flink 社区希望能够将 Flink 的 Streaming 实时计算能力和 Lakehouse 新架构优势进一步结合，推出新一代的 Streaming Lakehouse 技术，促进数据在数据湖上真正实时流动起来，并为用户提供实时离线一体化的开发体验。
01 什么是 Apache Paimon Apache Paimon (incubating) 是一项流式数据湖存储技术，可以为用户提供高吞吐、低延迟的数据摄入、流式订阅以及实时查询能力。
Paimon 采用开放的数据格式和技术理念，可以与 Apache Flink / Spark / Trino 等诸多业界主流计算引擎进行对接，共同推进 Streaming Lakehouse 架构的普及和发展。
02 开放的数据格式 Paimon 以湖存储的方式基于分布式文件系统管理元数据，并采用开放的 ORC、Parquet、Avro 文件格式，支持各大主流计算引擎，包括 Flink、Spark、Hive、Trino、Presto。未来会对接更多引擎，包括 Doris 和 Starrocks。
03 大规模实时更新 得益于 LSM 数据结构的追加写能力，Paimon 在大规模的更新数据输入的场景中提供了出色的性能。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6697ad17174c0c972a9022e99582a3f1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-30T14:21:26+08:00" />
<meta property="article:modified_time" content="2023-03-30T14:21:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">流式数据湖存储技术，Apache Paimon是什么？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>流式数据湖存储技术，Apache Paimon是什么？</h4> 
 <ul><li><a href="#00__5" rel="nofollow">00 导读</a></li><li><a href="#01__Apache_Paimon_16" rel="nofollow">01 什么是 Apache Paimon</a></li><li><a href="#02__26" rel="nofollow">02 开放的数据格式</a></li><li><a href="#03__30" rel="nofollow">03 大规模实时更新</a></li><li><a href="#04__52" rel="nofollow">04 数据表局部更新</a></li><li><a href="#05__64" rel="nofollow">05 流批一体数据读写</a></li></ul> 
</div> 
<p></p> 
<blockquote> 
 <p>来源：<a href="https://paimon.apache.org/" rel="nofollow">https://paimon.apache.org/</a></p> 
</blockquote> 
<h2><a id="00__5"></a>00 导读</h2> 
<p>2023年3月12日，<code>Flink Table Store</code> 项目顺利通过投票，正式进入 Apache 软件基金会 (ASF) 的孵化器，改名为 <code>Apache Paimon (incubating)</code>。</p> 
<p>Flink 社区希望能够将 Flink 的 Streaming 实时计算能力和 Lakehouse 新架构优势进一步结合，推出新一代的 Streaming Lakehouse 技术，促进数据在数据湖上真正实时流动起来，并为用户提供实时离线一体化的开发体验。</p> 
<h2><a id="01__Apache_Paimon_16"></a>01 什么是 Apache Paimon</h2> 
<p><font color="green"><code>Apache Paimon (incubating)</code> 是一项流式数据湖存储技术，可以为用户提供高吞吐、低延迟的数据摄入、流式订阅以及实时查询能力</font>。</p> 
<p>Paimon 采用开放的数据格式和技术理念，可以与 Apache Flink / Spark / Trino 等诸多业界主流计算引擎进行对接，共同推进 Streaming Lakehouse 架构的普及和发展。</p> 
<p><img src="https://images2.imgbox.com/d7/c5/7yDgVrk5_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="02__26"></a>02 开放的数据格式</h2> 
<p>Paimon 以湖存储的方式基于分布式文件系统管理元数据，并采用开放的 <code>ORC、Parquet、Avro</code> 文件格式，支持各大主流计算引擎，包括 <code>Flink、Spark、Hive、Trino、Presto</code>。未来会对接更多引擎，包括 Doris 和 Starrocks。</p> 
<h2><a id="03__30"></a>03 大规模实时更新</h2> 
<p>得益于 <code>LSM</code> 数据结构的追加写能力，Paimon 在大规模的更新数据输入的场景中提供了出色的性能。</p> 
<p>Paimon 创新的结合了 <code>湖存储 + LSM + 列式格式 (ORC, Parquet)</code>，为湖存储带来大规模实时更新能力，Paimon 的 LSM 的文件组织结构如下：</p> 
<p><img src="https://images2.imgbox.com/cf/52/wFfRYCqJ_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p><font color="green">高性能更新</font>：LSM 的 Minor Compaction，保障写入的性能和稳定性</p> </li><li> <p><font color="green">高性能合并</font>：LSM 的有序合并效率非常高</p> </li><li> <p><font color="green">高性能查询</font>：LSM 的 基本有序性，保障查询可以基于主键做文件的 Skipping</p> </li></ul> 
<p>在最新的版本中，Paimon 集成了 Flink CDC，通过 Flink DataStream 提供了两个核心能力：</p> 
<ol><li> <p>实时同步 Mysql 单表到 Paimon 表，并且实时将上游 Mysql 表结构（Schema）的变更同步到下游的 Paimon 表中。</p> </li><li> <p>实时同步 Mysql 整库级别的表结构和数据到 Paimon 中，同时支持表结构变更的同步，并且在同步过程中复用资源，只用少量资源，就可以同步大量的表。</p> </li></ol> 
<p>通过与 Flink CDC 的整合，Paimon 可以让的业务数据简单高效的流入数据湖中。</p> 
<h2><a id="04__52"></a>04 数据表局部更新</h2> 
<p><font color="blue">在数据仓库的业务场景下，经常会用到宽表数据模型，宽表模型通常是指将业务主体相关的指标、维表、属性关联在一起的模型表，也可以泛指将多个事实表和多个维度表相关联到一起形成的宽表</font>。</p> 
<p>Paimon 的 Partial-Update 合并引擎可以根据相同的主键实时合并多条流，形成 Paimon 的一张大宽表，依靠 LSM 的延迟 Compaction 机制，以较低的成本完成合并。合并后的表可以提供批读和流读：</p> 
<ol><li>批读：在批读时，读时合并仍然可以完成 Projection Pushdown，提供高性能的查询。</li><li>流读：下游可以看到完整的、合并后的数据，而不是部分列。</li></ol> 
<p><img src="https://images2.imgbox.com/3c/04/IyXqbAUp_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="05__64"></a>05 流批一体数据读写</h2> 
<p>Paimon 作为一个流批一体的数据湖存储，提供流写流读、批写批读，你使用 Paimon 来构建 Streaming Pipeline，并且数据沉淀到存储中。</p> 
<p>在 Flink Streaming 作业实时更新的同时，可以 OLAP 查询各个 Paimon 表的历史和实时数据，并且也可以通过 Batch SQL，对之前的分区 Backfill，批读批写。</p> 
<p><img src="https://images2.imgbox.com/67/7b/brVX1xK0_o.png" alt="在这里插入图片描述"></p> 
<p>不管输入如何更新，或者业务要求如何合并 (比如 partial-update)，使用 Paimon 的 Changelog 生成功能，总是能够在流读时获取完全正确的变更日志。</p> 
<p><mark>当面对主键表时，为什么你需要完整的 Changelog</mark>：</p> 
<ol><li> <p>你的输入并不是完整的 changelog，比如丢失了 UPDATE_BEFORE (-U)，比如同个主键有多条 INSERT 数据，这就会导致下游的流读聚合有问题，同个主键的多条数据应该被认为是更新，而不是重复计算。</p> </li><li> <p>当你的表是 Partial Update，下游需要看到完整的、合并后的数据，才可以正确的流处理。</p> </li></ol> 
<p>你可以使用 Lookup 来实时生成 Changelog：</p> 
<p><img src="https://images2.imgbox.com/66/fd/uQI1ihxH_o.png" alt="在这里插入图片描述"></p> 
<p>如果你觉得成本过大，你也可以解耦 Commit 和 Changelog 生成，通过 Full-Compaction 和对应较大的时延，以非常低的成本生成 Changelog。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6d5f5d9a7b054b5c3ef5705d5fb574b3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Kafka学习篇1：Docker安装Kafka（单机默认参数版，依赖于Zookeeper）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8adfa5a588ad83d35b10b94bd34f4319/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言 —— 数组</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>