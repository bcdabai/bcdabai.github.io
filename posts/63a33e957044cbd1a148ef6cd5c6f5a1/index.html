<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TVM: Deep Learning模型的优化编译器(强烈推荐, 附踩坑记录) - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TVM: Deep Learning模型的优化编译器(强烈推荐, 附踩坑记录)" />
<meta property="og:description" content="（前排提醒，本文的人文内容部分稍稍带有艺术加工，请保持一定的幽默感进行阅读）
关注我最近想法的同学应该知道我最近都在把玩TVM，今天终于使用TVM得到了非常满意的结果，而专栏也很长时间没更新了，于是来安利(水)一篇。
本来可能用不到TVM，项目其实进展的很顺利，我们初始的tensorflow模型在android端得到了满意的latency，我也可以照常一边修炼我的仙,继续和有奶大定律, 自由单子, Kan-Extension等邪魔外道搏斗…一边稳稳的推进项目进度。
无奈scientist一意孤行要上Pytorch, 于是我们换了一个Pytorch模型…
先不说同样的SSD魔改模型，Pytorch在android端比tensorflow整整慢了5倍，光是把Pytorch模型移植到Android上都让开发团队整整褪层皮(Pytorch对Android的支持简直为0，tensorflow的工程支持相对pytorch简直无敌)。而这时候已经花了好多时间，项目眼看要delay…
头都炸了的我在打算手撸OpenCL调优之前，去问了下我们组的CV大神该怎么办，大神微微一笑，转身随风而去，只听云端传来3个字：“TVM~~~~~&#34;
于是我就开始TVM的研究(踩坑)之路, 到今天为止终于把所有的路都踩平了之后，成功把我们的Pytorch模型用Auto-TVM调优成功且部署在了我们的android系统上，性能整整提高了8倍，比我们之前的tensorflow模型还要快。更重要的是，通过TVM，我们的调优完全不couple与硬件和模型Framework，就算以后换模型，换终端，或者哪天scientist想不开要换回tensorflow或是使用MXNet都无所谓，用auto-TVM自动调调就行了（只可惜了我的Cuda C编程调优都白学了）。
简单介绍下Auto-TVM的调优终端设备的用法
你可以有很多手机平板设备，安装好TVM RPC这个App之后，可以在App里输入Tracker的IP和端口，进行设备注册(另外输入一个设备ID来让Auto-TVM tuning程序找到)。Tracker是一个Python的程序，git clone TVM之后，按教程编译好，就可以按这个教程启动Tracker。Auto-TVM tuning程序也是一个python程序，它会连接Tracker(也可以和Tracker是一台机器)找到相应的设备ID的IP，然后和设备直接用RPC通信，Auto-TVM程序会根据程序预设的target(比如是不是arm cpu，要不要用OpenCL…) 来把你想要优化的Deep Learning模型直接编译为设备的machine code, 通过TVM RPC把code部署在终端，终端的TVM RPC App会测试这个模型的inference performance，然后回报给Auto-TVM tuning程序，然后Auto-TVM tuning程序会根据反馈，重新计算该如何优化编译，重新生成新的模型的machine code再次部署… 如此循环…直到达到预设的实验次数(比如2000),或太多次实验都没有提高提前结束(比如第一次就找到了最优优化结果)。最后TVM会根据调优时得到的最佳“编译参数”来最终编译你的deeplearning 模型为终端模型的machine code，最终完成优化编译过程。 以上只是简单介绍，具体请看TVM的论文，和去TVM官网看 tutorial，写得非常详细切提供了很多很好理解的范例代码。我的最终的tuning程序，就是魔改其中一个范例程序而来。
TVM踩坑记录
TVM目前还只是0.6版本，很多东西还不稳定，由于开发环境各异，有时候需要工程师自己解决一些开发团队在开发时没有碰到的问题，但是这些问题相对与TVM提供的巨大优势相比，都是小问题啦（工程能力越强，魔改力越强，你就可以越早体验新技术带来的好处呀。）。（我遇到的最坑的问题其实是公司网络各种IP禁止访问，封端口，使得android机和开发服务器一直连不上, 最终还是在自己的电脑上装了虚拟机，自建了一个小LAN才解决的这个问题）
1. 编译tvm4j-core出错: cannot find symbol [ERROR] symbol: class SharedSecrets
JDK11会遇到这个问题，因为JDK11已经把sun.misc.SharedSecrets换到别的地方了，建议不要尝试修改TVM源代码来fix这个问题，因为你会遇到其他更多问题，请下载JDK8，把JAVA_HOME设为JDK8的，一切就会很顺利
2. Android TVM RPC编译出错: #error &#34;Unable to determine endianness of your machine; use CMake to compile&#34;
Android RPC server fails to build" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/63a33e957044cbd1a148ef6cd5c6f5a1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-14T16:15:44+08:00" />
<meta property="article:modified_time" content="2021-02-14T16:15:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TVM: Deep Learning模型的优化编译器(强烈推荐, 附踩坑记录)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>（前排提醒，本文的人文内容部分稍稍带有艺术加工，请保持一定的幽默感进行阅读）</p> 
<p>关注我最近想法的同学应该知道我最近都在把玩TVM，今天终于使用TVM得到了非常满意的结果，而专栏也很长时间没更新了，于是来安利(水)一篇。</p> 
<p>本来可能用不到TVM，项目其实进展的很顺利，我们初始的tensorflow模型在android端得到了满意的latency，我也可以照常一边修炼我的仙,继续和有奶大定律, 自由单子, Kan-Extension等邪魔外道搏斗…一边稳稳的推进项目进度。</p> 
<p>无奈scientist一意孤行要上Pytorch, 于是我们换了一个Pytorch模型…</p> 
<p>先不说同样的SSD魔改模型，Pytorch在android端比tensorflow整整慢了5倍，光是把Pytorch模型移植到Android上都让开发团队整整褪层皮(Pytorch对Android的支持简直为0，tensorflow的工程支持相对pytorch简直无敌)。而这时候已经花了好多时间，项目眼看要delay…</p> 
<p>头都炸了的我在打算手撸OpenCL调优之前，去问了下我们组的CV大神该怎么办，大神微微一笑，转身随风而去，只听云端传来3个字：“T<sub>V</sub>M~~~~~"</p> 
<p>于是我就开始TVM的研究(踩坑)之路, 到今天为止终于把所有的路都踩平了之后，成功把我们的Pytorch模型用Auto-TVM调优成功且部署在了我们的android系统上，性能整整提高了8倍，比我们之前的tensorflow模型还要快。更重要的是，通过TVM，我们的调优完全不couple与硬件和模型Framework，就算以后换模型，换终端，或者哪天scientist想不开要换回tensorflow或是使用MXNet都无所谓，用auto-TVM自动调调就行了（只可惜了我的Cuda C编程调优都白学了）。</p> 
<p><strong>简单介绍下Auto-TVM的调优终端设备的用法</strong><br> <img src="https://images2.imgbox.com/df/09/u3HjuVgG_o.png" alt="在这里插入图片描述"></p> 
<ol><li>你可以有很多手机平板设备，安装好TVM RPC这个App之后，可以在App里输入Tracker的IP和端口，进行设备注册(另外输入一个设备ID来让Auto-TVM tuning程序找到)。</li><li>Tracker是一个Python的程序，git clone TVM之后，按教程编译好，就可以按这个<a href="https://link.zhihu.com/?target=https://github.com/dmlc/tvm/tree/master/apps/android_rpc">教程</a>启动Tracker。</li><li>Auto-TVM tuning程序也是一个python程序，它会连接Tracker(也可以和Tracker是一台机器)找到相应的设备ID的IP，然后和设备直接用RPC通信，Auto-TVM程序会根据程序预设的target(比如是不是arm cpu，要不要用OpenCL…) 来把你想要优化的Deep Learning模型直接编译为设备的machine code, 通过TVM RPC把code部署在终端，终端的TVM RPC App会测试这个模型的inference performance，然后回报给Auto-TVM tuning程序，然后Auto-TVM tuning程序会根据反馈，重新计算该如何优化编译，重新生成新的模型的machine code再次部署… 如此循环…直到达到预设的实验次数(比如2000),或太多次实验都没有提高提前结束(比如第一次就找到了最优优化结果)。最后TVM会根据调优时得到的最佳“编译参数”来最终编译你的deeplearning 模型为终端模型的machine code，最终完成优化编译过程。</li></ol> 
<p>以上只是简单介绍，具体请看TVM的论文，和去TVM官网看 tutorial，写得非常详细切提供了很多很好理解的范例代码。我的最终的tuning程序，就是魔改其中一个范例程序而来。</p> 
<p><strong>TVM踩坑记录</strong><br> TVM目前还只是0.6版本，很多东西还不稳定，由于开发环境各异，有时候需要工程师自己解决一些开发团队在开发时没有碰到的问题，但是这些问题相对与TVM提供的巨大优势相比，都是小问题啦（工程能力越强，魔改力越强，你就可以越早体验新技术带来的好处呀。）。（我遇到的最坑的问题其实是公司网络各种IP禁止访问，封端口，使得android机和开发服务器一直连不上, 最终还是在自己的电脑上装了虚拟机，自建了一个小LAN才解决的这个问题）</p> 
<p><strong>1. 编译tvm4j-core出错: cannot find symbol [ERROR] symbol: class SharedSecrets</strong><br> JDK11会遇到这个问题，因为JDK11已经把sun.misc.SharedSecrets换到别的地方了，建议不要尝试修改TVM源代码来fix这个问题，因为你会遇到其他更多问题，请下载JDK8，把JAVA_HOME设为JDK8的，一切就会很顺利</p> 
<p><strong>2. Android TVM RPC编译出错: #error "Unable to determine endianness of your machine; use CMake to compile"</strong><br> <a href="https://link.zhihu.com/?target=https://discuss.tvm.ai/t/android-rpc-server-fails-to-build/1461" rel="nofollow">Android RPC server fails to build</a></p> 
<p>按上边link里的修改endian.h文件即可，参见我下边的修改</p> 
<pre><code class="prism language-bash"><span class="token function">diff</span> --git a/include/dmlc/endian.h b/include/dmlc/endian.h
index 5bf53fb<span class="token punctuation">..</span>9422fce 100644
--- a/include/dmlc/endian.h
+++ b/include/dmlc/endian.h
@@ -23,7 +23,9 @@
 <span class="token comment">#elif defined(__EMSCRIPTEN__)</span>
 <span class="token comment">#define DMLC_LITTLE_ENDIAN 1</span>
 <span class="token comment">#else</span>
- <span class="token comment">#error "Unable to determine endianness of your machine; use CMake to compile"</span>
+ <span class="token comment">#include &lt;endian.h&gt;</span>
+ <span class="token comment">#define DMLC_LITTLE_ENDIAN (__BYTE_ORDER == __LITTLE_ENDIAN)</span>
+ /*<span class="token operator">!</span><span class="token comment">#error "Unable to determine endianness of your machine; use CMake to compile" */</span>
 <span class="token comment">#endif</span>
 <span class="token comment">#endif</span>
</code></pre> 
<p><strong>3. Auto-TVM运行时出错"Do not know how to handle return type code 113"</strong><br> <a href="https://link.zhihu.com/?target=https://discuss.tvm.ai/t/auto-tvm-failed-on-android-device-with-error-msg-of-do-not-know-how-to-handle-return-type-code-113/1808" rel="nofollow">Auto-TVM failed on Android Device, with error msg of “Do not know how to handle return type code 113”</a></p> 
<p>可以根据我上边在TVM Discussion里的自问自答来解决。</p> 
<p><strong>4. 找不到TVM_NDK_CC</strong><br> <a href="https://link.zhihu.com/?target=https://discuss.tvm.ai/t/solved-android-rpc-test-py-failed/1339" rel="nofollow">[SOLVED] Android_rpc_test.py failed</a></p> 
<p>按照dayanandasiet的回复设定TVM_NDK_CC即可</p> 
<pre><code class="prism language-bash">Follow the below steps to generate toolchian and try to generate application with below <span class="token function">export</span> <span class="token function">command</span>
Tool chain generate with below instruction
./make-standalone-toolchain.sh --platform<span class="token operator">=</span>android-24 --use-llvm --arch<span class="token operator">=</span>arm64 --install-dir<span class="token operator">=</span>/home/user/software/android-toolchain-arm64/
Download Java and SDK, <span class="token keyword">set</span> proper path
<span class="token function">export</span> TVM_NDK_CC<span class="token operator">=</span>/home/user/software/android-toolchain-arm64/bin/aarch64-linux-android-g++
<span class="token function">export</span> JAVA_HOME<span class="token operator">=</span>/usr/lib/jvm/java-8-openjdk-amd64
<span class="token function">export</span> ANDROID_HOME<span class="token operator">=</span>/home/user/software/android-sdk-linux
build mxnet model with nnvm with below config/parameter and use same library, param and graph on your android application
target <span class="token operator">=</span> “llvm -target<span class="token operator">=</span>arm64-linux-android”
target_host <span class="token operator">=</span> None
reference mobile_darknet_save.py 2
Compile application android deploy 1 using this config.mk 2 configuration <span class="token keyword">for</span> CPU flavor
</code></pre> 
<p><strong>5. LLVM only Large Small are allowd on AArch64</strong></p> 
<p><a href="https://link.zhihu.com/?target=https://github.com/dmlc/tvm/issues/2005">https://github.com/dmlc/tvm/issues/2005</a> 可解。</p> 
<p><strong>6. Auto-TVM自动优化时出错：Cannot find config for target=cuda</strong></p> 
<p>https://discuss.tvm.ai/t/what-does-this-warning-cannot-find-config-for-target-cuda-mean/798/3 不是什么大问题，某operator不能调，对我来说其他的可以调就行了。。。。</p> 
<p><strong>7. Auto-TVM自动优化OpenCL时出错: No OpenCL platform matched given existing options</strong></p> 
<p><a href="https://link.zhihu.com/?target=https://discuss.tvm.ai/t/no-opencl-platform-matched-given-existing-options/1848/6" rel="nofollow">No OpenCL platform matched given existing options</a></p> 
<p>也是自己问最终自己解决的，很反直觉，编译TVM的时候，选择OpenCL=OFF，就没有这个问题，选择OpenCL=ON，为终端Cross Compile OpenCL就不work了… 应该是bug.</p> 
<p><strong>8. Auto-TVM自动优化OpenCL时出错: CL_INVALID_WORK_GROUP_SIZE</strong><br> <a href="https://link.zhihu.com/?target=https://discuss.tvm.ai/t/cl-invalid-work-group-size-error-after-auto-tuning-for-opencl-on-android-device/1858/10" rel="nofollow">CL_INVALID_WORK_GROUP_SIZE error after auto-tuning for OpenCL on Android Device</a></p> 
<p>应该是我trial number设的太小了，以至于TVM找不到一个valid的kernel，顺着这个问题，发现了CL_INVALID_WORK_GROUP_SIZE的一个undocumented的错误源，即OpenCL kernel使用过多的register file也会造成CL_INVALID_WORK_GROUP_SIZE错误，这一点在查OpenCL文档的时候是查不到的, 有点tricky。</p> 
<p><strong>9. Auto-TVM自动优化时Android TVM RPC Crush，一切白调。。。</strong></p> 
<p>目前TVM还不支持checkpoint，不过我们可以很简单的魔改<strong>measure_methods.py</strong>这个文件，把190行set_task(): 这个函数里的check remote失败直接raise RuntimeError退出程序，改成循环多次check即可，这样使得Auto-TVM一方持续等待Android程序上线，比一点网络问题，或者终端问题，就废掉之前n多个小时的auto-tuning成果要好的多。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/45c66f205d0ef2ee1bfe87f75ede4c49/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">centos7ping不通外网</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/42ac54d43a7e297ce286a3558c275989/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ZigBee-CC2530单片机 - 实现外部电压值的测量</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>