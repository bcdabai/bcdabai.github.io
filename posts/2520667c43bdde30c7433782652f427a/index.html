<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CLIP算法的Loss详解 和 交叉熵CrossEntropy实现 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CLIP算法的Loss详解 和 交叉熵CrossEntropy实现" />
<meta property="og:description" content="CLIP：Contrastive Language–Image Pre-training(可对比语言-图像预训练算法)是OpenAI提出的多模态预训练的算法，在各种各样的**样本对(图像、文本)**上训练的神经网络。
具体参考：CLIP、OpenCLIP
其中，流程：
loss_i和loss_t的具体源码如下，参考 model.py：
def forward(self, image, text): image_features = self.encode_image(image) text_features = self.encode_text(text) # normalized features image_features = image_features / image_features.norm(dim=1, keepdim=True) text_features = text_features / text_features.norm(dim=1, keepdim=True) # cosine similarity as logits logit_scale = self.logit_scale.exp() logits_per_image = logit_scale * image_features @ text_features.t() logits_per_text = logits_per_image.t() # shape = [global_batch_size, global_batch_size] return logits_per_image, logits_per_text 其中，labels是torch.arange(batch_size, device=device).long()，参考train.py，具体如下
with torch.no_grad(): for i, batch in enumerate(dataloader): images, texts = batch images = images." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/2520667c43bdde30c7433782652f427a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-05T17:03:11+08:00" />
<meta property="article:modified_time" content="2022-08-05T17:03:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CLIP算法的Loss详解 和 交叉熵CrossEntropy实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>CLIP</strong>：Contrastive Language–Image Pre-training(可对比语言-图像预训练算法)是OpenAI提出的多模态预训练的算法，在各种各样的**样本对(图像、文本)**上训练的神经网络。</p> 
<p>具体参考：<a href="https://github.com/openai/CLIP">CLIP</a>、<a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a></p> 
<p><img src="https://images2.imgbox.com/e0/f1/R5eyitNi_o.png" alt="image-20220601180224080"></p> 
<p>其中，流程：</p> 
<p><img src="https://images2.imgbox.com/bb/4c/seryW9Xu_o.png" alt="image-20220601180639145"></p> 
<p><code>loss_i</code>和<code>loss_t</code>的具体源码如下，<a href="https://github.com/openai/CLIP/blob/main/clip/model.py">参考 model.py</a>：</p> 
<pre><code class="prism language-bash">    def forward<span class="token punctuation">(</span>self, image, text<span class="token punctuation">)</span>:
        image_features <span class="token operator">=</span> self.encode_image<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        text_features <span class="token operator">=</span> self.encode_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

        <span class="token comment"># normalized features</span>
        image_features <span class="token operator">=</span> image_features / image_features.norm<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">keepdim</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
        text_features <span class="token operator">=</span> text_features / text_features.norm<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">keepdim</span><span class="token operator">=</span>True<span class="token punctuation">)</span>

        <span class="token comment"># cosine similarity as logits</span>
        logit_scale <span class="token operator">=</span> self.logit_scale.exp<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logits_per_image <span class="token operator">=</span> logit_scale * image_features @ text_features.t<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logits_per_text <span class="token operator">=</span> logits_per_image.t<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># shape = [global_batch_size, global_batch_size]</span>
        <span class="token builtin class-name">return</span> logits_per_image, logits_per_text
</code></pre> 
<p>其中，labels是<code>torch.arange(batch_size, device=device).long()</code>，参考<a href="https://github.com/mlfoundations/open_clip/blob/main/src/training/train.py">train.py</a>，具体如下</p> 
<pre><code class="prism language-python">        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                images<span class="token punctuation">,</span> texts <span class="token operator">=</span> batch
                images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">,</span> non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                texts <span class="token operator">=</span> texts<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">,</span> non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

                <span class="token keyword">with</span> autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    image_features<span class="token punctuation">,</span> text_features<span class="token punctuation">,</span> logit_scale <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">,</span> texts<span class="token punctuation">)</span>
                    <span class="token comment"># features are accumulated in CPU tensors, otherwise GPU memory exhausted quickly</span>
                    <span class="token comment"># however, system RAM is easily exceeded and compute time becomes problematic</span>
                    all_image_features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_features<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    all_text_features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text_features<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    logit_scale <span class="token operator">=</span> logit_scale<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    logits_per_image <span class="token operator">=</span> logit_scale <span class="token operator">*</span> image_features @ text_features<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    logits_per_text <span class="token operator">=</span> logits_per_image<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>

                    batch_size <span class="token operator">=</span> images<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                    labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                    total_loss <span class="token operator">=</span> <span class="token punctuation">(</span>
                        F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits_per_image<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token operator">+</span>
                        F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits_per_text<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
</code></pre> 
<p>交叉熵函数：y就是label，<code>x_softmax[i][y[i]]</code>，表示在x_softmax中筛选第i个sample的第y[i]个值，作为log的输入，全部log负向求和，再求均值。</p> 
<ul><li>y所对应的就是CLIP的np.arange(n)，也就是依次是第0个位置~第n-1个位置，计算log。</li></ul> 
<pre><code class="prism language-python"><span class="token comment"># 定义softmax函数</span>
<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 利用numpy计算</span>
<span class="token keyword">def</span> <span class="token function">cross_entropy_np</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_softmax <span class="token operator">=</span> <span class="token punctuation">[</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    x_log <span class="token operator">=</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>x_softmax<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x_log<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss

<span class="token comment"># 测试逻辑</span>
x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.9269</span><span class="token punctuation">,</span> <span class="token number">1.4873</span><span class="token punctuation">,</span> <span class="token number">0.9007</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.1055</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
v1 <span class="token operator">=</span> cross_entropy_np<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"v1: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>v1<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># CrossEntropy输入期望: Class放在第2维，Batch放在第1维</span>

y <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>  <span class="token comment"># label的类型为long</span>

v2 <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"v2: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>v2<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>输出：</p> 
<pre><code class="prism language-bash">v1: <span class="token number">1.729491540989093</span>
v2: tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.7295</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>参考：</p> 
<ul><li><a href="https://blog.csdn.net/seasermy/article/details/95176357">arxiv文章下载很慢怎么办？</a></li><li><a href="https://zhuanlan.zhihu.com/p/397605652" rel="nofollow">CLIP-对比图文多模态预训练的读后感</a></li><li><a href="https://blog.csdn.net/weixin_43508499/article/details/107714080">CrossEntropy的numpy实现和Pytorch调用</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1d9f9eda7da280cbedbb79f8541fba64/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">K8S学习笔记之控制器statefulset</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2d571d029d724f0c75b9ff43be977ec7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Mac&amp;Vue】解决在MacOS下Vue-Cli无法使用80端口的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>