<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI芯片：寒武纪DianNao，英伟达NVDLA和谷歌TPU1的芯片运算架构对比分析 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="AI芯片：寒武纪DianNao，英伟达NVDLA和谷歌TPU1的芯片运算架构对比分析" />
<meta property="og:description" content="AI芯片：寒武纪DianNao，英伟达NVDLA和谷歌TPU1的芯片运算架构对比分析
evolone 2019-01-18 20:10:39 2972 收藏 9
展开
前面几篇博客分别分析了目前市面上能够找到的各家AI芯片的结构。
下面做一个阶段性的对比分析及总结。
AI芯片运算架构对比
整体来看，NVDLA的架构与寒武纪的DianNao比较像。所以，单位资源的性能应该是差不多的。
二者性能的区别，就看资源的多寡了。
寒武纪的DianNao，共16个PE，每个PE可以计算一个神经元，每个周期最多计算出16个神经元。
NVDLA共2个core。每个core有8个mac。每个mac有64个mul，可以计算4个神经元。所以，NVDLA每周期最多可以计算64个神经元。看作64个PE。
再看谷歌的TPU1，因为systolic array的尺寸是256X256，所以，每周期最多计算出256个神经元。看作256个PE。
这么来看，同频率下，姑且可以认为：NVDLA性能是DianNao的4倍， TPU1是NVDLA的4倍。
当然，上面的这种性能比较并不公平，因为三者内部的资源数量是不同的。
因为寒武纪DianNao的资源最少，所以以它为基准。
下面按照同样规模的资源来做比较：
寒武纪的DianNao，内部是16个PE。每个PE内部有16个mul和15个add，计算得到一个神经元。
NVDLA，一个core中有8个mac，每个mac有64个mul，可以计算输出4个神经元。可将每16个mul看作一个PE，计算得到一个神经元。
这么一看，DianNao与NVDLA的架构是一样的，效率应该也一样。
谷歌的TPU1，内部乘加单元组成的脉动阵列的尺寸是256x256=64K个mul_add。如果将尺寸缩小为16x16，那么也可看做每16个mul计算得到一个神经元。共有16个PE。
这么一看，貌似谷歌的TPU1的效率也和DianNao、NVDLA都一样。
其实不一样。
（1）芯片物理结构的弊端
NVDLA与DianNao都是一维的扁平结构，数据只有一个流动方向，输入数据并不能在mac相互间传递。只有在core顶层的时候去做数据共享，到了mac内部，就无法做到数据共享。
就算是强行进行数据共享，在实际设计芯片时有很大的弊端。
以寒武纪的DianNao为例，16个PE是并行的，数据同时到达，如果最大化共享，即16个PE的输入图像数据是同一份，那么很明显，必须在数据进入乘法器之前，同时将数据复制多份，分发给16个PE，或者说，同一份数据，需要同时驱动给16个PE。
主要有2个弊端：
（1）这个会涉及到信号的驱动能力。底层晶体管很有可能驱动能力不够。
（2）因为目前的芯片还只是二维平面的，也就是说，将一个PE看做一个方块，那么这16个PE是平铺在一个平面上的，那么必然是分散开的，那么数据从芯片的某个部位进来，这16个PE的数据接口与输入数据的距离肯定是有远有近，长度短的，需要的驱动小，长度大，需要的驱动大，这个怎么匹配？而且，如果走线太长，延迟会等比例增大，频率就得降低，信号完整性变差，如何保证能够将16份相同的数据同时并准确地传输到最远和最近的PE的接口上？这是个严重的问题。
估计就是因为这些原因，造成这种扁平的设计存在缺陷：如果频率想高一些，那么并行的PE就很少，要么就是增加并行的PE，但是会造成频率明显降低。比如寒武纪DianNao的频率是0.98GHz。
这是一个死结。
因为吞吐量简单来看，就是PE数量与频率的乘积，这样就造成，这种架构的吞吐量永远上不去。
实际上，DianNao和NVDLA内部的并行模块并不多。比如，DianNao内部只有16个PE并行，NVDLA每个CORE内部也只有8个mac并行。
反观谷歌的TPU1，采用的脉动阵列不是扁平结构，而是二维的平面结构，数据可以沿着两个相互垂直的方向分别传播。而且，最大的好处是，数据只是在相邻的乘加单元之间传递数据，并且单个方向上，数据只需要传递一份即可，这样，所需驱动小，而且可以很轻松地保证数据的传输距离的一致性，而且传输距离还非常短，可以做到比较高的频率，且频率与阵列的尺寸无关系。
所以，脉动阵列的结构，可以很轻松地做到很高的频率，尺寸还很大，比如TPU1得频率是700MHZ，尺寸是256X256.
简单对比一下：
AI芯片型号 频率 乘法器规模 简单的吞吐量
寒武纪DianNao 0.98GHz 16×16=256个乘法器 约等于 1G X 256=256G/s
谷歌TPU1 700MHz 256X256=64K个乘法器 约等于 64K X 700M=44800G/s
（2）数学理论上的弊端
DianNao和NVDLA的扁平化结构，还在数学上存在很大的弊端。
以DianNao为例：
一个PE中的16个mul是同时计算的，那么，卷积的filter的尺寸大小，会强烈影响计算效率。
假设一个卷积需要的乘法计算次数为N，
如果N&lt;16，那么一个PE可以一次就算出结果，但是会有16-N个mul资源浪费。可见N越小，越浪费。
如果N=16，那么最好了，PE不仅能够一次算出结果，还没有mul浪费。
如果N&gt;16，那么不好意思，一次只能算16个乘法，剩下的N-16，留着下次再算，或者调用其他PE去计算。但是这样就会增加不同PE间的连接关系，控制逻辑非常复杂，造成设计难度增大。
所以，DianNao和NVDLA的扁平化结构，对filter的尺寸是非常敏感的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/15d7538abee4551d1d021e7e341a3728/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-04T18:53:23+08:00" />
<meta property="article:modified_time" content="2020-05-04T18:53:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI芯片：寒武纪DianNao，英伟达NVDLA和谷歌TPU1的芯片运算架构对比分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>AI芯片：寒武纪DianNao，英伟达NVDLA和谷歌TPU1的芯片运算架构对比分析</p> 
<p>evolone 2019-01-18 20:10:39  2972  收藏 9<br> 展开<br> 前面几篇博客分别分析了目前市面上能够找到的各家AI芯片的结构。<br> 下面做一个阶段性的对比分析及总结。</p> 
<p>AI芯片运算架构对比<br> 整体来看，NVDLA的架构与寒武纪的DianNao比较像。所以，单位资源的性能应该是差不多的。<br> 二者性能的区别，就看资源的多寡了。<br> 寒武纪的DianNao，共16个PE，每个PE可以计算一个神经元，每个周期最多计算出16个神经元。<br> NVDLA共2个core。每个core有8个mac。每个mac有64个mul，可以计算4个神经元。所以，NVDLA每周期最多可以计算64个神经元。看作64个PE。<br> 再看谷歌的TPU1，因为systolic array的尺寸是256X256，所以，每周期最多计算出256个神经元。看作256个PE。</p> 
<p>这么来看，同频率下，姑且可以认为：NVDLA性能是DianNao的4倍， TPU1是NVDLA的4倍。<br> 当然，上面的这种性能比较并不公平，因为三者内部的资源数量是不同的。<br> 因为寒武纪DianNao的资源最少，所以以它为基准。<br> 下面按照同样规模的资源来做比较：<br> 寒武纪的DianNao，内部是16个PE。每个PE内部有16个mul和15个add，计算得到一个神经元。<br> NVDLA，一个core中有8个mac，每个mac有64个mul，可以计算输出4个神经元。可将每16个mul看作一个PE，计算得到一个神经元。<br> 这么一看，DianNao与NVDLA的架构是一样的，效率应该也一样。</p> 
<p>谷歌的TPU1，内部乘加单元组成的脉动阵列的尺寸是256x256=64K个mul_add。如果将尺寸缩小为16x16，那么也可看做每16个mul计算得到一个神经元。共有16个PE。</p> 
<p>这么一看，貌似谷歌的TPU1的效率也和DianNao、NVDLA都一样。<br> 其实不一样。<br> （1）芯片物理结构的弊端<br> NVDLA与DianNao都是一维的扁平结构，数据只有一个流动方向，输入数据并不能在mac相互间传递。只有在core顶层的时候去做数据共享，到了mac内部，就无法做到数据共享。<br> 就算是强行进行数据共享，在实际设计芯片时有很大的弊端。<br> 以寒武纪的DianNao为例，16个PE是并行的，数据同时到达，如果最大化共享，即16个PE的输入图像数据是同一份，那么很明显，必须在数据进入乘法器之前，同时将数据复制多份，分发给16个PE，或者说，同一份数据，需要同时驱动给16个PE。</p> 
<p>主要有2个弊端：<br> （1）这个会涉及到信号的驱动能力。底层晶体管很有可能驱动能力不够。<br> （2）因为目前的芯片还只是二维平面的，也就是说，将一个PE看做一个方块，那么这16个PE是平铺在一个平面上的，那么必然是分散开的，那么数据从芯片的某个部位进来，这16个PE的数据接口与输入数据的距离肯定是有远有近，长度短的，需要的驱动小，长度大，需要的驱动大，这个怎么匹配？而且，如果走线太长，延迟会等比例增大，频率就得降低，信号完整性变差，如何保证能够将16份相同的数据同时并准确地传输到最远和最近的PE的接口上？这是个严重的问题。<br> 估计就是因为这些原因，造成这种扁平的设计存在缺陷：如果频率想高一些，那么并行的PE就很少，要么就是增加并行的PE，但是会造成频率明显降低。比如寒武纪DianNao的频率是0.98GHz。<br> 这是一个死结。<br> 因为吞吐量简单来看，就是PE数量与频率的乘积，这样就造成，这种架构的吞吐量永远上不去。</p> 
<p>实际上，DianNao和NVDLA内部的并行模块并不多。比如，DianNao内部只有16个PE并行，NVDLA每个CORE内部也只有8个mac并行。</p> 
<p>反观谷歌的TPU1，采用的脉动阵列不是扁平结构，而是二维的平面结构，数据可以沿着两个相互垂直的方向分别传播。而且，最大的好处是，数据只是在相邻的乘加单元之间传递数据，并且单个方向上，数据只需要传递一份即可，这样，所需驱动小，而且可以很轻松地保证数据的传输距离的一致性，而且传输距离还非常短，可以做到比较高的频率，且频率与阵列的尺寸无关系。<br> 所以，脉动阵列的结构，可以很轻松地做到很高的频率，尺寸还很大，比如TPU1得频率是700MHZ，尺寸是256X256.</p> 
<p>简单对比一下：<br> AI芯片型号 频率 乘法器规模 简单的吞吐量<br> 寒武纪DianNao 0.98GHz 16×16=256个乘法器 约等于 1G X 256=256G/s<br> 谷歌TPU1 700MHz 256X256=64K个乘法器 约等于 64K X 700M=44800G/s</p> 
<p>（2）数学理论上的弊端<br> DianNao和NVDLA的扁平化结构，还在数学上存在很大的弊端。<br> 以DianNao为例：<br> 一个PE中的16个mul是同时计算的，那么，卷积的filter的尺寸大小，会强烈影响计算效率。<br> 假设一个卷积需要的乘法计算次数为N，<br> 如果N&lt;16，那么一个PE可以一次就算出结果，但是会有16-N个mul资源浪费。可见N越小，越浪费。<br> 如果N=16，那么最好了，PE不仅能够一次算出结果，还没有mul浪费。<br> 如果N&gt;16，那么不好意思，一次只能算16个乘法，剩下的N-16，留着下次再算，或者调用其他PE去计算。但是这样就会增加不同PE间的连接关系，控制逻辑非常复杂，造成设计难度增大。<br> 所以，DianNao和NVDLA的扁平化结构，对filter的尺寸是非常敏感的。</p> 
<p>不过，由于目前的深度学习算法除了第一层的input只有3个channel，内部计算用到的filter number 几乎都是16的整数倍，所以，在后面的计算当中，因为channel是16的整数倍，所以，当计算16n9个乘法，这时就会完全利用所有乘法器。</p> 
<p>此时，DianNao的乘法器满负荷运算，效率也很高。<br> 再来看看谷歌TPU1的脉动阵列。<br> 假设尺寸是16X16.<br> 那么，一个神经元的计算结果，必须经过一列16个乘加单元的处理，才能输出，看起来也不高效。<br> 客官等等，这个只是开始。<br> 脉动阵列最大的优点是，它不受filter尺寸的大小的限制，也就是说不管你的filter尺寸是多少，1X1，2X2，3X3。。。。1X3，2X5，。。。任何尺寸都可以，都不会浪费。<br> 为什么呢？<br> 因为，同一个channel的filter的所有乘加计算，都会按先后顺序进入同一乘加单元，所以，不管你的filter尺寸是多少，只管按照顺序一个一个依次输入即可。</p> 
<p>所以说，TPU1的脉动阵列二维结构和DianNao的一维结构，在数学上，都对filter的size免疫。几乎可以适应任何尺寸的filter。<br> 最后，</p> 
<p>根据以上分析，可以看出，DianNao及NVDLA的设计很优秀，效率高。<br> TPU的设计更加优秀，效率更高，而且TPU能很大程度上重复利用输入数据，尽可能减少输入数据占用的带宽，减少数据从硬盘到运算逻辑的搬运次数，可大幅度降低功耗，提高运算速度。<br> ————————————————<br> 版权声明：本文为CSDN博主「evolone」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br> 原文链接：https://blog.csdn.net/evolone/article/details/86545816</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d6e6253acefe68cc5e97b6e988bc3546/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ubuntu20环境下wine部分中文乱码方块</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f32614bc0a8843126c0b564272258ad1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">teamviewer或向日葵远程ubuntu系统不能调节屏幕分辨率</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>