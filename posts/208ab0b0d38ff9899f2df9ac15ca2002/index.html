<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>nginx 负载均衡时，一台tomcat宕机时的问题 自动切换(转自java版web项目-微信公众号)... - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="nginx 负载均衡时，一台tomcat宕机时的问题 自动切换(转自java版web项目-微信公众号)..." />
<meta property="og:description" content="如果Nginx没有仅仅只能代理一台服务器的话，那它也不可能像今天这么火，Nginx可以配置代理多台服务器，当一台服务器宕机之后，仍能保持系统可用。具体配置过程如下：
1. 在http节点下，添加upstream节点。
upstream linuxidc {
server 10.0.6.108:7080;
server 10.0.0.85:8980;
}
2. 将server节点下的location节点中的proxy_pass配置为：http:// &#43; upstream名称，即“
http://linuxidc”.
location / {
root html;
index index.html index.htm;
proxy_pass http://linuxidc;
}3. 现在负载均衡初步完成了。upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能 自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。适用于图片服务器集群和纯静态页面服务器集群。
除此之外，upstream还有其它的分配策略，分别如下：
weight（权重）
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。如下所示，10.0.0.88的访问比率要比10.0.0.77的访问比率高一倍。
upstream linuxidc{
server 10.0.0.77 weight=5;
server 10.0.0.88 weight=10;
}
ip_hash（访问ip）
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
upstream favresin{
ip_hash;
server 10.0.0.10:8080;
server 10.0.0.11:8080;
}
fair（第三方）
按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。
upstream favresin{ server 10.0.0.10:8080;
server 10.0.0.11:8080;
fair;
}
url_hash（第三方）
按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。
upstream resinserver{
server 10.0.0.10:7777;
server 10." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/208ab0b0d38ff9899f2df9ac15ca2002/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-12-19T16:06:00+08:00" />
<meta property="article:modified_time" content="2017-12-19T16:06:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">nginx 负载均衡时，一台tomcat宕机时的问题 自动切换(转自java版web项目-微信公众号)...</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="cnblogs_post_body" class="blogpost-body"> 
 <p>如果Nginx没有仅仅只能代理一台服务器的话，那它也不可能像今天这么火，Nginx可以配置代理多台服务器，当一台服务器宕机之后，仍能保持系统可用。具体配置过程如下：</p> 
 <p> </p> 
 <p>1. 在http节点下，添加upstream节点。</p> 
 <p>upstream linuxidc {<!-- --><br>      server 10.0.6.108:7080;<br>      server 10.0.0.85:8980;<br>}</p> 
 <p> </p> 
 <p> 2.  将server节点下的location节点中的proxy_pass配置为：http:// + upstream名称，即“<br>http://linuxidc”.</p> 
 <p><br>location / {<!-- --><br>            root  html;<br>            index  index.html index.htm;<br>            proxy_pass http://linuxidc;<br>}3.  现在负载均衡初步完成了。upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能 自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。适用于图片服务器集群和纯静态页面服务器集群。</p> 
 <p>    除此之外，upstream还有其它的分配策略，分别如下：</p> 
 <p>    weight（权重）</p> 
 <p>    指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。如下所示，10.0.0.88的访问比率要比10.0.0.77的访问比率高一倍。</p> 
 <p>upstream linuxidc{<!-- --><br>      server 10.0.0.77 weight=5;<br>      server 10.0.0.88 weight=10;<br>}</p> 
 <p>    ip_hash（访问ip）</p> 
 <p>    每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p> 
 <p>upstream favresin{<!-- --><br>      ip_hash;<br>      server 10.0.0.10:8080;<br>      server 10.0.0.11:8080;<br>}</p> 
 <p>    fair（第三方）</p> 
 <p>    按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。</p> 
 <p> upstream favresin{     <br>      server 10.0.0.10:8080;<br>      server 10.0.0.11:8080;<br>      fair;<br>}</p> 
 <p>url_hash（第三方）</p> 
 <p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</p> 
 <p>注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。</p> 
 <p> upstream resinserver{<!-- --><br>      server 10.0.0.10:7777;<br>      server 10.0.0.11:8888;<br>      hash $request_uri;<br>      hash_method crc32;<br>}</p> 
 <p> </p> 
 <p>upstream还可以为每个设备设置状态值，这些状态值的含义分别如下：</p> 
 <p>down 表示单前的server暂时不参与负载.</p> 
 <p>weight 默认为1.weight越大，负载的权重就越大。</p> 
 <p>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.</p> 
 <p>fail_timeout : max_fails次失败后，暂停的时间。</p> 
 <p>backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</p> 
 <p>upstream bakend{ #定义负载均衡设备的Ip及设备状态<br>      ip_hash;<br>      server 10.0.0.11:9090 down;<br>      server 10.0.0.11:8080 weight=2;<br>      server 10.0.0.11:6060;<br>      server 10.0.0.11:7070 backup;<br>}</p> 
 <p> </p> 
 <p>Nginx的配置与部署研究，Upstream负载均衡模块  http://www.linuxidc.com/Linux/2013-04/82526p2.htm</p> 
 <p> </p> 
 <p>CentOS 6.2实战部署Nginx+MySQL+PHP http://www.linuxidc.com/Linux/2013-09/90020.htm</p> 
 <p>使用Nginx搭建WEB服务器 http://www.linuxidc.com/Linux/2013-09/89768.htm</p> 
 <p> </p> 
 <p>搭建基于Linux6.3+Nginx1.2+PHP5+MySQL5.5的Web服务器全过程 http://www.linuxidc.com/Linux/2013-09/89692.htm</p> 
 <p>CentOS 6.3下Nginx性能调优 http://www.linuxidc.com/Linux/2013-09/89656.htm</p> 
 <p>CentOS 6.3下配置Nginx加载ngx_pagespeed模块 http://www.linuxidc.com/Linux/2013-09/89657.htm</p> 
 <p>CentOS 6.4安装配置Nginx+Pcre+php-fpm http://www.linuxidc.com/Linux/2013-08/88984.htm</p> 
 <p>Nginx安装配置使用详细笔记 http://www.linuxidc.com/Linux/2014-07/104499.htm</p> 
 <p>Nginx日志过滤 使用ngx_log_if不记录特定日志 http://www.linuxidc.com/Linux/2014-07/104686.htm</p> 
 <p> </p> 
 <p>用了nginx负载均衡后，在两台tomcat正常运行的情况下，访问http://localhost 速度非常迅速，通过测试程序也可以看出是得到的负载均衡的效果，但是我们试验性的把其中一台tomcat（server localhost:8080）关闭后，再查看http://localhost，发现反应呈现了一半反映时间快，一半反映时间非常非常慢的情况，但是最后都能得到正确结果.</p> 
 <p> </p> 
 <p>解决办法：</p> 
 <p>问题解决，主要是proxy_connect_timeout   这个参数， 这个参数是连接的超时时间。 我设置成1，表示是1秒后超时会连接到另外一台服务器。<br>#user  nobody;<br>worker_processes  1;<br><br>#error_log  logs/error.log;<br>#error_log  logs/error.log  notice;<br>#error_log  logs/error.log  info;<br><br>#pid        logs/nginx.pid;<br><br><br>events {<!-- --><br>    worker_connections  1024;<br>}<br><br><br>http {<!-- --><br>    include       mime.types;<br>    default_type  application/octet-stream;<br><br>     upstream localhost {<!-- --><br>       #ip_hash;<br>       server 127.0.0.1:8081;<br>       server 127.0.0.1:8080;<br>     }<br><br>    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '<br>    #                  '$status $body_bytes_sent "$http_referer" '<br>    #                  '"$http_user_agent" "$http_x_forwarded_for"';<br><br>    #access_log  logs/access.log  main;<br><br>    sendfile        on;<br>    #tcp_nopush     on;<br><br>    #keepalive_timeout  0;<br>    keepalive_timeout  65;<br><br>    #gzip  on;<br><br>    server {<!-- --><br>        listen       80;<br>        server_name  localhost;<br><br>    listen 80;<br>    server_name localhost;<br>    location /{<!-- --><br>    proxy_pass http://localhost;<br>    proxy_set_header Host $host;<br>    proxy_set_header X-Real-IP $remote_addr;<br>    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;<br><strong>    proxy_connect_timeout       1;<br>    proxy_read_timeout          1;<br>    proxy_send_timeout          1;</strong><br>    }<br>        #charset koi8-r;<br><br>        #access_log  logs/host.access.log  main;<br><br>        #error_page  404              /404.html;<br><br>        # redirect server error pages to the static page /50x.html<br>        #<br>        error_page   500 502 503 504  /50x.html;<br>        location = /50x.html {<!-- --><br>            root   html;<br>        }<br><br>        # proxy the PHP scripts to Apache listening on 127.0.0.1:80<br>        #<br>        #location ~ \.php$ {<!-- --><br>        #    proxy_pass   http://127.0.0.1;<br>        #}<br><br>        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000<br>        #<br>        #location ~ \.php$ {<!-- --><br>        #    root           html;<br>        #    fastcgi_pass   127.0.0.1:9000;<br>        #    fastcgi_index  index.php;<br>        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;<br>        #    include        fastcgi_params;<br>        #}<br><br>        # deny access to .htaccess files, if Apache's document root<br>        # concurs with nginx's one<br>        #<br>        #location ~ /\.ht {<!-- --><br>        #    deny  all;<br>        #}<br>    }<br><br><br>    # another virtual host using mix of IP-, name-, and port-based configuration<br>    #<br>    #server {<!-- --><br>    #    listen       8000;<br>    #    listen       somename:8080;<br>    #    server_name  somename  alias  another.alias;<br><br>    #    location / {<!-- --><br>    #        root   html;<br>    #        index  index.html index.htm;<br>    #    }<br>    #}<br><br><br>    # HTTPS server<br>    #<br>    #server {<!-- --><br>    #    listen       443;<br>    #    server_name  localhost;<br><br>    #    ssl                  on;<br>    #    ssl_certificate      cert.pem;<br>    #    ssl_certificate_key  cert.key;<br><br>    #    ssl_session_timeout  5m;<br><br>    #    ssl_protocols  SSLv2 SSLv3 TLSv1;<br>    #    ssl_ciphers  ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;<br>    #    ssl_prefer_server_ciphers   on;<br><br>    #    location / {<!-- --><br>    #        root   html;<br>    #        index  index.html index.htm;<br>    #    }<br>    #}<br><br>}</p> 
</div> 
<p>转载于:https://www.cnblogs.com/lxchma/p/8066278.html</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bf94dd332238093b0f583ffebdb35369/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux下增加Sawp分区</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/33ce948a5f646511a91521ec137e2ec6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Transform.Forward和Vector3.Forward的正确使用方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>