<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>kafka 开启认证授权 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="kafka 开启认证授权" />
<meta property="og:description" content="前言 1、前面自己写了一篇关于各个环境各个模式的安装的文章，大家可以去看看 kafka各种环境安装(window,linux,docker,k8s),包含KRaft模式
2、使用版本 kafka_2.13-3.4.1
3、kafka验证方式，有两大类如下，文档内容在 kafka官方文档的 第七节 security，强烈建议大家去看下，不想看英文的可以翻译中文后看
SSL （ 官方3.4.x SSL 文档链接）SASL （ 官方3.4.x SASL 文档链接） 4、而SASL 又细分如下 4 小类，这四种都可以使用
类型说明官方文档链接SASL/GSSAPI (Kerberos)使用的Kerberos认证，可以集成目录服务，比如AD。从Kafka0.9版本开始支持KerberosSASL/PLAIN使用简单用户名和密码形式。从Kafka0.10版本开始支持，不支持动态增加账户和密码SASL/PLAINSASL/SCRAM-SHA-256主要解决PLAIN动态更新问题以及安全机制，从Kafka0.10.2开始支持SCRAMSASL/SCRAM-SHA-512主要解决PLAIN动态更新问题以及安全机制，从Kafka0.10.2开始支持SCRAMSASL/OAUTHBEARER基于OAuth 2认证框架，从Kafka2.0版本开始支持OAUTHBEARER 5、在后面指定java 实现的时候，可以去源码里面找对应的，如下
6、需要先明确的一点是，用户认证和权限控制是两码事。用户认证是确认这个用户能否访问当前的系统，而权限控制是控制用户对当前系统中各种资源的访问权限。用户认证就是今天要讲的内容，而kafka的权限控制，则是对应 bin/kafka-acls.sh 工具所提供的一系列功能，这里不详细展开。
一、Linux 环境 在SASL/PLAIN 模式中 Kafka的SASL_SSL和SASL_PLAINTEXT是两种不同的安全协议，用于保护Kafka集群中的通信。它们提供了不同级别的安全性和身份验证选项：
SASL_SSL (Simple Authentication and Security Layer over SSL/TLS)：这是Kafka的高度安全的传输协议。它结合了SSL/TLS（用于加密通信）和SASL（用于身份验证）来提供强大的安全性。使用SASL_SSL，Kafka客户端和服务器之间的通信将是加密的，并且需要经过身份验证才能建立连接。常见的身份验证机制包括GSSAPI（Kerberos）、PLAIN（用户名和密码）等。SASL_SSL是Kafka中最安全的选项，适用于敏感数据和合规性要求高的场景。
SASL_PLAINTEXT (Simple Authentication and Security Layer over plaintext)：这是Kafka的另一种SASL支持方式，但不涉及加密。使用SASL_PLAINTEXT，身份验证是必需的，但通信不加密。这意味着数据在传输过程中是以明文形式传输的，因此对于保护数据隐私要求较低的场景或在内部网络中使用时，可以选择此选项。常见的身份验证机制也包括PLAIN（用户名和密码）等。
通常，SASL_SSL是更安全的选项，因为它不仅提供身份验证，还提供数据的加密，从而更好地保护了数据的隐私和完整性。但是，它的配置相对复杂，可能需要设置SSL/TLS证书和密钥以及身份验证机制。SASL_PLAINTEXT相对来说更容易配置，但数据在传输过程中不加密，可能不适用于对数据隐私有更高要求的场景。
你的选择应该根据你的具体安全需求来决定。在需要高度安全性的生产环境中，通常会选择SASL_SSL，而在开发和测试环境中，SASL_PLAINTEXT可能更为方便。无论选择哪种方式，都需要谨慎配置和管理Kafka的安全设置，以确保系统的安全性。
所以下面文章中的 SASL_PLAINTEXT 可以替换为 SASL_SSL，相应的配置可以改成如下（可以看官网的 SASL/PLAIN）这一节，采用的就是这种
3、下载后解压
tar -xzf kafka_2.13-3.4.1.tgz cd kafka_2.13-3.4.1 1.1、Kafka with KRaft 单节点 SASL/PLAIN 模式授权 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/24ccab63823d41e00d094d04d7c6299c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-28T17:03:32+08:00" />
<meta property="article:modified_time" content="2023-12-28T17:03:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">kafka 开启认证授权</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>前言</h2> 
<p><strong>1、前面自己写了一篇关于各个环境各个模式的安装的文章，大家可以去看看 <a href="https://blog.csdn.net/qq_38263083/article/details/132341449">kafka各种环境安装(window,linux,docker,k8s),包含KRaft模式</a></strong></p> 
<p>2、<strong>使用版本 kafka_2.13-3.4.1</strong></p> 
<p>3、kafka验证方式，有两大类如下，文档内容在 kafka官方文档的 第七节 security，<strong>强烈建议大家去看下，不想看英文的可以翻译中文后看</strong></p> 
<ul><li>SSL （ <a href="https://kafka.apache.org/34/documentation.html#security_ssl" rel="nofollow">官方3.4.x SSL 文档链接</a>）</li><li>SASL （ <a href="https://kafka.apache.org/34/documentation.html#security_sasl" rel="nofollow">官方3.4.x SASL 文档链接</a>）</li></ul> 
<p><img src="https://images2.imgbox.com/78/9d/iuiDN5wX_o.png" alt="在这里插入图片描述"></p> 
<p>4、而SASL 又细分如下 4 小类，这四种都可以使用</p> 
<table><thead><tr><th>类型</th><th>说明</th><th>官方文档链接</th></tr></thead><tbody><tr><td>SASL/GSSAPI (Kerberos)</td><td>使用的Kerberos认证，可以集成目录服务，比如AD。从Kafka0.9版本开始支持</td><td><a href="https://kafka.apache.org/34/documentation.html#security_sasl_kerberos" rel="nofollow">Kerberos</a></td></tr><tr><td>SASL/PLAIN</td><td>使用简单用户名和密码形式。从Kafka0.10版本开始支持，不支持动态增加账户和密码</td><td><a href="https://kafka.apache.org/34/documentation.html#security_sasl_plain" rel="nofollow">SASL/PLAIN</a></td></tr><tr><td>SASL/SCRAM-SHA-256</td><td>主要解决PLAIN动态更新问题以及安全机制，从Kafka0.10.2开始支持</td><td><a href="https://kafka.apache.org/34/documentation.html#security_sasl_scram" rel="nofollow">SCRAM</a></td></tr><tr><td>SASL/SCRAM-SHA-512</td><td>主要解决PLAIN动态更新问题以及安全机制，从Kafka0.10.2开始支持</td><td><a href="https://kafka.apache.org/34/documentation.html#security_sasl_scram" rel="nofollow">SCRAM</a></td></tr><tr><td>SASL/OAUTHBEARER</td><td>基于OAuth 2认证框架，从Kafka2.0版本开始支持</td><td><a href="https://kafka.apache.org/34/documentation.html#security_sasl_oauthbearer" rel="nofollow">OAUTHBEARER </a></td></tr></tbody></table> 
<p>5、在后面指定java 实现的时候，可以去源码里面找对应的，如下<br> <img src="https://images2.imgbox.com/dc/bb/fWBXoH3w_o.png" alt="在这里插入图片描述"></p> 
<p>6、需要先明确的一点是，用户认证和权限控制是两码事。用户认证是确认这个用户能否访问当前的系统，而权限控制是控制用户对当前系统中各种资源的访问权限。用户认证就是今天要讲的内容，而kafka的权限控制，则是对应 <code>bin/kafka-acls.sh</code> 工具所提供的一系列功能，这里不详细展开。</p> 
<h2><a id="Linux__29"></a>一、Linux 环境</h2> 
<p>在<code>SASL/PLAIN </code> 模式中 Kafka的SASL_SSL和SASL_PLAINTEXT是两种不同的安全协议，用于保护Kafka集群中的通信。它们提供了不同级别的安全性和身份验证选项：</p> 
<ol><li> <p><strong>SASL_SSL (Simple Authentication and Security Layer over SSL/TLS)</strong>：这是Kafka的高度安全的传输协议。它结合了SSL/TLS（用于加密通信）和SASL（用于身份验证）来提供强大的安全性。使用SASL_SSL，Kafka客户端和服务器之间的通信将是加密的，并且需要经过身份验证才能建立连接。常见的身份验证机制包括GSSAPI（Kerberos）、PLAIN（用户名和密码）等。SASL_SSL是Kafka中最安全的选项，适用于敏感数据和合规性要求高的场景。</p> </li><li> <p><strong>SASL_PLAINTEXT (Simple Authentication and Security Layer over plaintext)</strong>：这是Kafka的另一种SASL支持方式，但不涉及加密。使用SASL_PLAINTEXT，<strong>身份验证是必需的，但通信不加密</strong>。这意味着数据在传输过程中是以明文形式传输的，因此对于保护数据隐私要求较低的场景或在内部网络中使用时，可以选择此选项。常见的身份验证机制也包括PLAIN（用户名和密码）等。</p> </li></ol> 
<p>通常，SASL_SSL是更安全的选项，因为它不仅提供身份验证，还提供数据的加密，从而更好地保护了数据的隐私和完整性。但是，它的配置相对复杂，可能需要设置SSL/TLS证书和密钥以及身份验证机制。SASL_PLAINTEXT相对来说更容易配置，但数据在传输过程中不加密，可能不适用于对数据隐私有更高要求的场景。</p> 
<p>你的选择应该根据你的具体安全需求来决定。在需要高度安全性的生产环境中，通常会选择SASL_SSL，而在开发和测试环境中，SASL_PLAINTEXT可能更为方便。无论选择哪种方式，都需要谨慎配置和管理Kafka的安全设置，以确保系统的安全性。</p> 
<p><strong>所以下面文章中的 SASL_PLAINTEXT 可以替换为 SASL_SSL，相应的配置可以改成如下（可以看官网的 <a href="https://kafka.apache.org/34/documentation.html#security_sasl_plain" rel="nofollow">SASL/PLAIN</a>）这一节，采用的就是这种</strong></p> 
<p><img src="https://images2.imgbox.com/37/7f/Ogda37hx_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0e/9a/HKNenF2Z_o.png" alt="在这里插入图片描述"></p> 
<p>3、下载后解压</p> 
<pre><code class="prism language-shell"><span class="token function">tar</span> <span class="token parameter variable">-xzf</span> kafka_2.13-3.4.1.tgz
<span class="token builtin class-name">cd</span> kafka_2.13-3.4.1
</code></pre> 
<h3><a id="11Kafka_with_KRaft__SASLPLAIN___52"></a>1.1、Kafka with KRaft 单节点 <code>SASL/PLAIN </code> 模式授权</h3> 
<h4><a id="111_54"></a>1.1.1、服务端</h4> 
<h5><a id="1111_55"></a>1.1.1.1、编写服务端授权文件</h5> 
<p>1、编写授权文件 <code>kafka_server_jaas.conf</code>，此配置定义了两个用户（admin 和 client ）。代理使用 KafkaServer 部分中的属性用户名和密码来启动与其他代理的连接。在此示例中，admin 是代理间通信的用户。属性集 <code>user_用户名定义</code> 是连接到代理的所有用户的密码，代理验证所有客户端连接。</p> 
<pre><code class="prism language-shell"><span class="token comment"># 因为我这里是使用 kraft 模式启动，所以，就把服务端的配置都放在这里了</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config/kraft

<span class="token comment"># 创建文件内容如下</span>
<span class="token function">vim</span> kafka_server_jaas.conf

<span class="token comment">### 末尾 分号一定不能忘记</span>
KafkaServer <span class="token punctuation">{<!-- --></span>
    org.apache.kafka.common.security.plain.PlainLoginModule required
    <span class="token assign-left variable">username</span><span class="token operator">=</span><span class="token string">"admin"</span>
    <span class="token assign-left variable">password</span><span class="token operator">=</span><span class="token string">"admin-secret"</span>
    <span class="token assign-left variable">user_admin</span><span class="token operator">=</span><span class="token string">"admin-secret"</span>
    <span class="token assign-left variable">user_client</span><span class="token operator">=</span><span class="token string">"client-secret"</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/20/f4/lgOoiAGI_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1112_78"></a>1.1.1.2、编写服务端启动脚本</h5> 
<p>1、复制kafka服务端启动脚本</p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/bin/
<span class="token function">cp</span> kafka-server-start.sh kafka-server-start-sasl.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/7c/bf/PsG27vSd_o.png" alt="在这里插入图片描述"></p> 
<p>2、修改我们copy的启动脚本，将我们前面将要创建的配置文件（<code>kafka_jaas.conf</code>），给指定进去</p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/bin
<span class="token function">vim</span> kafka-server-start-sasl.sh

<span class="token comment"># 将export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"修改为：</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">"-Xmx1G -Xms1G -Djava.security.auth.login.config=/opt/kafka/kafka_2.13-3.4.1/config/kraft/kafka_server_jaas.conf"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/0f/3c/9EeanVUq_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1113___serverproperties_99"></a>1.1.1.3、修改服务端 配置文件 server.properties</h5> 
<p>1、我这边是启动的 kraft 模式，所以我就修改对应的 kraft 目录下的配置文件即可</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入kraft/config目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config/kraft

<span class="token comment"># copy并编辑server.properties文件</span>
<span class="token function">cp</span> server.properties  server-sasl.properties

<span class="token comment"># 修改</span>
<span class="token function">vim</span> server-sasl.properties

<span class="token comment"># 修改以下内容</span>
<span class="token comment">###</span>
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>SASL_PLAINTEXT://:9092,CONTROLLER://:9093
<span class="token assign-left variable">inter.broker.listener.name</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">advertised.listeners</span><span class="token operator">=</span>SASL_PLAINTEXT://192.168.173.129:9092
<span class="token assign-left variable">sasl.enabled.mechanisms</span><span class="token operator">=</span>PLAIN
<span class="token assign-left variable">sasl.mechanism.inter.broker.protocol</span><span class="token operator">=</span>PLAIN
<span class="token comment">###</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/15/e0/8COhWlom_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/67/08/Sujj9V4f_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="112_125"></a>1.1.2、客户端</h4> 
<h5><a id="1121_126"></a>1.1.2.1、编写客户端授权文件</h5> 
<pre><code class="prism language-shell"><span class="token comment"># 因为我这里是使用 kraft 模式启动，所以，就把客户端的配置都放在这里了</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config/kraft

<span class="token comment"># 创建文件内容如下</span>
<span class="token function">vim</span> kafka_client_jaas.conf

<span class="token comment">### 末尾 分号一定不能忘记</span>
KafkaClient <span class="token punctuation">{<!-- --></span>
  org.apache.kafka.common.security.plain.PlainLoginModule required
    <span class="token assign-left variable">username</span><span class="token operator">=</span><span class="token string">"client"</span>
    <span class="token assign-left variable">password</span><span class="token operator">=</span><span class="token string">"client-secret"</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/66/59/vmsjuyR1_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1122_144"></a>1.1.2.2、编写消费者启动脚本</h5> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/bin

<span class="token comment"># copy 并修改 </span>
<span class="token function">cp</span> kafka-console-consumer.sh kafka-console-consumer-sasl.sh

<span class="token comment"># 修改，指定我们前面写的客户端配置文件</span>
<span class="token function">vim</span> kafka-console-consumer-sasl.sh

<span class="token comment"># ★ 将export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"修改为：</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">"-Xmx512M -Djava.security.auth.login.config=/opt/kafka/kafka_2.13-3.4.1/config/kraft/kafka_client_jaas.conf"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/2f/33/ZKhzY9l6_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1123_consumerproperties_159"></a>1.1.2.3、编写消费者启动脚本的配置文件 consumer.properties</h5> 
<pre><code class="prism language-shell"><span class="token comment"># 进入kafka/config目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config

<span class="token comment"># copy编辑consumer-sasl.properties内容</span>
<span class="token function">cp</span> consumer.properties  consumer-sasl.properties
<span class="token function">vim</span> consumer-sasl.properties

<span class="token comment">###</span>
<span class="token assign-left variable">security.protocol</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">sasl.mechanism</span><span class="token operator">=</span>PLAIN
<span class="token comment">###</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/49/8f/d64nQAC7_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1124_178"></a>1.1.2.4、编写生产者启动脚本</h5> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/bin

<span class="token comment"># copy 并修改 </span>
<span class="token function">cp</span> kafka-console-producer.sh kafka-console-producer-sasl.sh

<span class="token comment"># 修改，指定我们前面写的客户端配置文件</span>
<span class="token function">vim</span> kafka-console-producer-sasl.sh

<span class="token comment"># ★ 将export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"修改为：</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">"-Xmx512M  -Djava.security.auth.login.config=/opt/kafka/kafka_2.13-3.4.1/config/kraft/kafka_client_jaas.conf"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ec/9d/pao0mJTF_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1123_producerproperties_197"></a>1.1.2.3、编写生产者启动脚本的配置文件 producer.properties</h5> 
<pre><code class="prism language-shell"><span class="token comment"># 进入kafka/config目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config

<span class="token comment"># copy编辑consumer-sasl.properties内容</span>
<span class="token function">cp</span> producer.properties  producer-sasl.properties
<span class="token function">vim</span> producer-sasl.properties

<span class="token comment">###</span>
<span class="token assign-left variable">security.protocol</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">sasl.mechanism</span><span class="token operator">=</span>PLAIN
<span class="token comment">###</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3b/6f/xCKgeF1v_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1115_216"></a>1.1.1.5、修改通用命令脚本的配置文件</h5> 
<p>1、什么是通用命令脚本，比如说，创建topic的脚本，它链接kafka也是需要认证的，所以，我们为这一类没有指定配置的脚本，创建一个通用的</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入kafka/config目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1/config/kraft
<span class="token comment"># 创建command_config文件</span>
<span class="token function">touch</span> command_config
<span class="token comment"># 编辑command_config内容</span>
<span class="token function">vim</span> command_config

<span class="token comment">###  千万注意 最后的分号 不能忘记了</span>
<span class="token assign-left variable">security.protocol</span><span class="token operator">=</span>SASL_PLAINTEXT
<span class="token assign-left variable">sasl.mechanism</span><span class="token operator">=</span>PLAIN
<span class="token assign-left variable">sasl.jaas.config</span><span class="token operator">=</span>org.apache.kafka.common.security.scram.ScramLoginModule required <span class="token assign-left variable">username</span><span class="token operator">=</span><span class="token string">"client"</span> <span class="token assign-left variable">password</span><span class="token operator">=</span><span class="token string">"client-secret"</span><span class="token punctuation">;</span>
<span class="token comment">###</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/5f/ff/6RGMQ4Si_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="113_237"></a>1.1.3、启动</h4> 
<p>1、完成上面的配置，那么我们就可以启动了，就是正常的 kraft 模式启动流程。</p> 
<h5><a id="1131_UUID_239"></a>1.1.3.1、生成集群 UUID</h5> 
<pre><code class="prism language-shell"><span class="token comment"># 进入到文件夹</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 创建 集群id</span>
<span class="token assign-left variable">KAFKA_CLUSTER_ID</span><span class="token operator">=</span><span class="token string">"<span class="token variable"><span class="token variable">$(</span>bin/kafka-storage.sh random-uuid<span class="token variable">)</span></span>"</span>
<span class="token comment"># 查看集群id是多少</span>
<span class="token builtin class-name">echo</span> <span class="token variable">$KAFKA_CLUSTER_ID</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ed/4a/mRoAYWhB_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1132_250"></a>1.1.3.2、格式化日志目录</h5> 
<p>1、使用上面的 <code>KAFKA_CLUSTER_ID </code> 参数，默认存储目录是<code>/tmp/kraft-combined-logs</code>，你可以修改配置文件的值</p> 
<blockquote> 
 <p>注意这里使用的是 <strong>config/kraft/sasl.properties</strong>, 你可以点进去看下配置，可以看到，当前的这个配置的角色是 broker，controller了，就不再需要zookeeper了.<br> <img src="https://images2.imgbox.com/70/0c/9Y9gkZDs_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
bin/kafka-storage.sh <span class="token function">format</span> <span class="token parameter variable">-t</span> <span class="token variable">$KAFKA_CLUSTER_ID</span> <span class="token parameter variable">-c</span> config/kraft/server-sasl.properties
</code></pre> 
<p><img src="https://images2.imgbox.com/d3/cd/aS61QT2u_o.png" alt="在这里插入图片描述"></p> 
<p>2、可以看到了 <code>/tmp/kraft-combined-logs</code> 文件夹也存在了</p> 
<p><img src="https://images2.imgbox.com/54/e0/yGN7jcay_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1133kafka__266"></a>1.1.3.3、启动kafka 服务</h5> 
<p>1、为了方便观察启动状态，这里就直接前台启动了</p> 
<blockquote> 
 <p>记得这里一定要用我们修改过后的脚本来启动 <strong><code>kafka-server-start-sasl.sh</code></strong>，这个脚本里面指定认证文件</p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 启动</span>
bin/kafka-server-start-sasl.sh config/kraft/server-sasl.properties

<span class="token comment"># 如果希望后台启动，则如下 加上 -daemon 即可  对应的日志文件在  /opt/kafka/kafka_2.13-3.4.1/logs 目录下，最新的日志文件是 erver.log</span>
bin/kafka-server-start-sasl.sh <span class="token parameter variable">-daemon</span> config/kraft/server-sasl.properties

<span class="token comment"># 关闭kafka ，如果是前台的，直接 CTRL C 关闭当前进程就好，如果是后台的，可以执行命令</span>
bin/kafka-server-stop.sh config/kraft/server-sasl.properties
</code></pre> 
<p><img src="https://images2.imgbox.com/87/9b/QIHCkoZX_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="114_283"></a>1.1.4、链接测试</h4> 
<h5><a id="1131_284"></a>1.1.3.1、不使用认证的方式脚本命令行（服务端会提示无法链接）</h5> 
<p>1、我们先不使用认证授权的文件链接试一下，会发现下面这三个都是无法访问的，可以看到对应的服务端输出的日志</p> 
<p>2、通用脚本</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 查看当前服务器中的所有 topic</span>
bin/kafka-topics.sh <span class="token parameter variable">--list</span> --bootstrap-server localhost:9092
</code></pre> 
<p><img src="https://images2.imgbox.com/5c/10/VzbSWphq_o.png" alt="在这里插入图片描述"></p> 
<p>3、消费者脚本</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 消费者链接</span>
bin/kafka-console-consumer.sh --bootstrap-server <span class="token number">127.0</span>.0.1:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --from-beginning 
</code></pre> 
<p><img src="https://images2.imgbox.com/21/e2/LcaB38Jy_o.png" alt="在这里插入图片描述"></p> 
<p>4、生产者脚本</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 生产者链接</span>
bin/kafka-console-producer.sh --bootstrap-server <span class="token number">127.0</span>.0.1:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/5e/f4/CvoBKkrY_o.png" alt="在这里插入图片描述"></p> 
<p>5、springBoot 项目，具体配置这里就不再细说了，链接之后，只要对kafak执行操作，就会如下错误，超时</p> 
<blockquote> 
 <p><strong>记得部署 kafka 的服务器开放 9092 端口，或者关闭防火墙</strong></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/40/0c/KroSIFWc_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/d5/6d/v90ig8Et_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1132_327"></a>1.1.3.2、使用认证的方式脚本命令行（链接成功）</h5> 
<p>1、通用脚本，第一开始因为这里还未创建过topic ，所以没有数据，后面可以再运行一下。</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 查看当前服务器中的所有 topic</span>
bin/kafka-topics.sh <span class="token parameter variable">--list</span> --bootstrap-server localhost:9092 --command-config /opt/kafka/kafka_2.13-3.4.1/config/kraft/command_config

<span class="token comment"># 创建topic </span>
bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">1</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span>  --command-config /opt/kafka/kafka_2.13-3.4.1/config/kraft/command_config
</code></pre> 
<p><img src="https://images2.imgbox.com/70/99/OqdkUdsR_o.png" alt="在这里插入图片描述"></p> 
<p>3、消费者脚本，执行完成后，页面会等待队列消息</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 消费者链接  --consumer.config 指定消费者配置文件</span>
bin/kafka-console-consumer-sasl.sh --bootstrap-server <span class="token number">127.0</span>.0.1:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --from-beginning <span class="token parameter variable">--consumer.config</span> config/consumer-sasl.properties
</code></pre> 
<p><img src="https://images2.imgbox.com/d9/69/822Pui6L_o.png" alt="在这里插入图片描述"></p> 
<p>4、生产者脚本</p> 
<pre><code class="prism language-shell"><span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> /opt/kafka/kafka_2.13-3.4.1
<span class="token comment"># 生产者链接  --producer.config  指定消费者配置文件</span>
bin/kafka-console-producer-sasl.sh --bootstrap-server <span class="token number">127.0</span>.0.1:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--producer.config</span> config/producer-sasl.properties
</code></pre> 
<p><img src="https://images2.imgbox.com/38/4f/qMDmoezw_o.png" alt="在这里插入图片描述"><br> 此刻，消费者控制台也收到消息了</p> 
<p><img src="https://images2.imgbox.com/6c/3d/zn2QfXu8_o.png" alt="在这里插入图片描述"></p> 
<p>5、springBoot 项目，增加账号密码，如下，<strong>后面的分号一定不能忘记</strong>，加上如下配置之后就可以了</p> 
<blockquote> 
 <p><strong>consumer和producer 需要统一配置配置(Kafka stream SASL/PLANTEXT配置也一样，统一配置对stream同样生效)</strong></p> 
</blockquote> 
<blockquote> 
 <p><strong>记得部署 kafka 的服务器开放 9092 端口，或者关闭防火墙</strong></p> 
</blockquote> 
<pre><code class="prism language-yml">    <span class="token key atrule">properties</span><span class="token punctuation">:</span>
      <span class="token key atrule">security.protocol</span><span class="token punctuation">:</span> SASL_PLAINTEXT
      <span class="token key atrule">sasl.mechanism</span><span class="token punctuation">:</span> PLAIN
      <span class="token key atrule">sasl.jaas.config</span><span class="token punctuation">:</span> org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client<span class="token punctuation">-</span>secret";
</code></pre> 
<p><img src="https://images2.imgbox.com/6b/b5/ck0Xce06_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12Kafka_with_KRaft__SSL__382"></a>1.2、Kafka with KRaft 单节点 <code>SSL</code> 模式授权</h3> 
<p>参考这篇文章：写的很好 <a href="https://blog.csdn.net/Vector97/article/details/128621682">kafka SSL认证</a></p> 
<h2><a id="kafkaui_kafka_387"></a>二、kafka-ui 链接开启认证授权的kafka</h2> 
<p>连接带认证的kafka集群在kafka-ui的github上面也有，但是文章写的不太全面。如果没有配置SASL_PLAINTEXT认证可以参考我之前写的这篇文章 <strong><a href="https://blog.csdn.net/qq_38263083/article/details/132341449">kafka各种环境安装(window,linux,docker,k8s),包含KRaft模式</a></strong></p> 
<h3><a id="21SASL_PLAINTEXT_390"></a>2.1、SASL_PLAINTEXT</h3> 
<p>1、连接SASL_PLAINTEXT认证的kafka需要添加如下三个环境变量，<code>KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG </code> 变量指定的用户名密码需要与实际情况一致。</p> 
<blockquote> 
 <p>我这里因为镜像已经前提下载过了，所以就没有显示下载镜像的步骤</p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">1992</span>:8080 <span class="token parameter variable">--name</span> kafka-ui  <span class="token punctuation">\</span>
<span class="token parameter variable">--restart</span><span class="token operator">=</span>always <span class="token punctuation">\</span>
<span class="token parameter variable">-v</span> /data/docker/kafka/kafka-ui/config.yml:/etc/kafkaui/dynamic_config.yaml <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_NAME</span><span class="token operator">=</span>local <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class="token operator">=</span><span class="token number">192.168</span>.173.129:9092 <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">DYNAMIC_CONFIG_ENABLED</span><span class="token operator">=</span><span class="token string">'true'</span> <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">AUTH_TYPE</span><span class="token operator">=</span>LOGIN_FORM   <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">SPRING_SECURITY_USER_NAME</span><span class="token operator">=</span>admin <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">SPRING_SECURITY_USER_PASSWORD</span><span class="token operator">=</span>admin <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL</span><span class="token operator">=</span>SASL_PLAINTEXT <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM</span><span class="token operator">=</span>PLAIN <span class="token punctuation">\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG</span><span class="token operator">=</span><span class="token string">'org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'</span> <span class="token punctuation">\</span>
provectuslabs/kafka-ui:latest
</code></pre> 
<p><img src="https://images2.imgbox.com/01/b4/2qv1wuBf_o.png" alt="在这里插入图片描述"></p> 
<p>2、如果报错，查看 <code>/data/docker/kafka/kafka-ui/config.yml</code> 文件是否存在，可以先提前创建，参数含义，大家也能看出来，如果有不明白的，大家可以参考我之前写的这篇文章 <strong><a href="https://blog.csdn.net/qq_38263083/article/details/132341449">kafka各种环境安装(window,linux,docker,k8s),包含KRaft模式</a></strong></p> 
<p>3、登录 <code>http://192.168.173.129:1992</code>,密码就是我们在启动时配置的 <code>-e SPRING_SECURITY_USER_NAME</code>和 <code>-e SPRING_SECURITY_USER_PASSWORD</code> admin admin</p> 
<p><img src="https://images2.imgbox.com/00/c1/4ohBMXYb_o.png" alt="在这里插入图片描述"></p> 
<p>4、登录进去如下，如果能获取带信息，就说明没有问题了<br> <img src="https://images2.imgbox.com/9b/2f/L4f7pkt3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22SSL_425"></a>2.2、SSL认证</h3> 
<p>1、连接SSL认证的kafka需要额外添加如下四个环境变量，其中<code>KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION</code> 变量指定的配置文件需要时在配置ssl时候提前生成的。</p> 
<p>2、另外注意 <code>KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD</code> 变量中指定的密码也是实际的密码。</p> 
<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token parameter variable">-p</span> <span class="token number">1993</span>:8080 <span class="token punctuation">\</span>
    <span class="token parameter variable">--name</span> kafka-ui-pwd <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_NAME</span><span class="token operator">=</span>kafka8082 <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class="token operator">=</span>localhost:8082 <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL</span><span class="token operator">=</span>SSL <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION</span><span class="token operator">=</span>/cert/client.truststore.jks <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD</span><span class="token operator">=</span>admin <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CLUSTERS_0_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM</span><span class="token operator">=</span><span class="token string">''</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">TZ</span><span class="token operator">=</span>Asia/Shanghai <span class="token punctuation">\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable"><span class="token environment constant">LANG</span></span><span class="token operator">=</span>C.UTF-8 <span class="token punctuation">\</span>
    <span class="token parameter variable">-v</span> /data/users/yulei/ssl_cert:/cert <span class="token punctuation">\</span>
    <span class="token parameter variable">-d</span> provectuslabs/kafka-ui:latest 
</code></pre> 
<h2><a id="docker__446"></a>三、docker 环境</h2> 
<h3><a id="31_KRaft__448"></a>3.1、使用 KRaft 模式单机安装</h3> 
<blockquote> 
 <p>可以参考 <a href="https://juejin.cn/post/7294556533932884020#heading-3" rel="nofollow">TechBits | Docker 部署（Bitnami镜像） Kafak-Kraft 模式配合Sasl加密认证</a> 这一篇文章</p> 
</blockquote> 
<blockquote> 
 <p>如果不需要授权，也可以参考我写的一篇文章 <a href="https://blog.csdn.net/qq_38263083/article/details/132341449">kafka各种环境安装(window,linux,docker,k8s),包含KRaft模式</a></p> 
</blockquote> 
<p>1、前置准备</p> 
<pre><code class="prism language-shell"><span class="token comment"># kafka的挂载</span>
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/docker/kafka/kafka_data
<span class="token function">chown</span> <span class="token parameter variable">-R</span> <span class="token number">1001</span>:1001 /data/docker/kafka/kafka_data
</code></pre> 
<p><img src="https://images2.imgbox.com/44/c7/kxJHTNb7_o.png" alt="在这里插入图片描述"></p> 
<p>2、将上述配置文件copy 一下，最后修改如下，<strong>注意替换其中的宿主机ip</strong></p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /opt/kafka/
<span class="token function">vim</span> kafka-KRaft-single-auth.yml
</code></pre> 
<pre><code class="prism language-yml"><span class="token comment"># 宿主机IP: 192.168.173.129</span>
<span class="token key atrule">version</span><span class="token punctuation">:</span> <span class="token string">"3"</span>

<span class="token key atrule">services</span><span class="token punctuation">:</span>
  <span class="token key atrule">kafka</span><span class="token punctuation">:</span>
    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">'bitnami/kafka:3.5.1'</span>
    <span class="token key atrule">hostname</span><span class="token punctuation">:</span> kafka
    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> kafka
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"9092:9092"</span>
    <span class="token key atrule">restart</span><span class="token punctuation">:</span> always
    <span class="token key atrule">environment</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> KAFKA_CFG_NODE_ID=0
      <span class="token punctuation">-</span> KAFKA_CFG_PROCESS_ROLES=controller<span class="token punctuation">,</span>broker
      <span class="token punctuation">-</span> KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka<span class="token punctuation">:</span><span class="token number">9093</span>
      <span class="token punctuation">-</span> KAFKA_CFG_LISTENERS=SASL_PLAINTEXT<span class="token punctuation">:</span>//<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">,</span>CONTROLLER<span class="token punctuation">:</span>//<span class="token punctuation">:</span><span class="token number">9093</span>
      <span class="token punctuation">-</span> KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER<span class="token punctuation">:</span>PLAINTEXT<span class="token punctuation">,</span>SASL_PLAINTEXT<span class="token punctuation">:</span>SASL_PLAINTEXT
      <span class="token punctuation">-</span> KAFKA_CFG_ADVERTISED_LISTENERS=SASL_PLAINTEXT<span class="token punctuation">:</span>//192.168.173.129<span class="token punctuation">:</span><span class="token number">9092</span>

      <span class="token punctuation">-</span> KAFKA_CLIENT_USERS=admin
      <span class="token punctuation">-</span> KAFKA_CLIENT_PASSWORDS=123456

      <span class="token punctuation">-</span> KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      <span class="token punctuation">-</span> KAFKA_CFG_SASL_MECHANISM_CONTROLLER_PROTOCOL=PLAIN
      <span class="token punctuation">-</span> KAFKA_CONTROLLER_USER=admin
      <span class="token punctuation">-</span> KAFKA_CONTROLLER_PASSWORD=123456

      <span class="token punctuation">-</span> KAFKA_CFG_INTER_BROKER_LISTENER_NAME=SASL_PLAINTEXT
      <span class="token punctuation">-</span> KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
      <span class="token punctuation">-</span> KAFKA_INTER_BROKER_USER=admin
      <span class="token punctuation">-</span> KAFKA_INTER_BROKER_PASSWORD=123456
    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"/data/docker/kafka/kafka_data:/bitnami"</span>
    <span class="token key atrule">networks</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> kafka_net



  <span class="token key atrule">kafka-ui</span><span class="token punctuation">:</span>
    <span class="token key atrule">image</span><span class="token punctuation">:</span> provectuslabs/kafka<span class="token punctuation">-</span>ui<span class="token punctuation">:</span>master
    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> kafka<span class="token punctuation">-</span>ui
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"8910:8080"</span>
    <span class="token key atrule">restart</span><span class="token punctuation">:</span> always
    <span class="token key atrule">environment</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> KAFKA_CLUSTERS_0_NAME=local  <span class="token comment">#先默认设置一个local的集群，至于认证信息，进入之后再配置</span>
      <span class="token punctuation">-</span> DYNAMIC_CONFIG_ENABLED=true
      <span class="token punctuation">-</span> AUTH_TYPE=LOGIN_FORM
      <span class="token punctuation">-</span> SPRING_SECURITY_USER_NAME=admin
      <span class="token punctuation">-</span> SPRING_SECURITY_USER_PASSWORD=admin
    <span class="token key atrule">depends_on</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> kafka
    <span class="token key atrule">networks</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> kafka_net

<span class="token key atrule">networks</span><span class="token punctuation">:</span>
  <span class="token key atrule">kafka_net</span><span class="token punctuation">:</span>
    <span class="token key atrule">driver</span><span class="token punctuation">:</span> bridge

</code></pre> 
<p>3、运行结果，其中zookeeper和kafka的镜像我已经提前下载好了，所以没有显示</p> 
<pre><code class="prism language-shell"><span class="token comment"># 记得删除停掉之前的 </span>
<span class="token comment"># docker-compose -f ./kafka-KRaft-single.yml down -v</span>
<span class="token function">docker-compose</span> <span class="token parameter variable">-f</span> kafka-KRaft-single-auth.yml up <span class="token parameter variable">-d</span> 
</code></pre> 
<p>4、访问 web-ui,账号密码 admin admin ，这个配置大家可以访问 github 去官方网站查看文档，说的还是很详细的 <a href="https://github.com/provectus/kafka-ui">github-kafka-ui</a></p> 
<pre><code>http://192.168.173.129:8080/
</code></pre> 
<p>5、在ui界面，配置我们的kafka集群，<strong>当然你也可以在创建 <code>kafka-ui</code>的时候，指定环境变量来直接配置kafka集群，看我以前的<code>kafka</code>系列文章重有说明，这里就直接在ui界面配置了。</strong><br> <img src="https://images2.imgbox.com/09/99/bHZvxa3F_o.png" alt="在这里插入图片描述"></p> 
<p>6、进入之后，配置相关信息后，点击下面的提交</p> 
<p><img src="https://images2.imgbox.com/f7/f6/JULBmL4T_o.png" alt="在这里插入图片描述"><br> 7、最后，就显示登录成功了</p> 
<p><img src="https://images2.imgbox.com/64/78/rXm8jCf9_o.png" alt="在这里插入图片描述"></p> 
<p>8、最后，保险起见，去看下 <code>kafka</code>和<code>kafka-ui</code>容器日志，查看无错误信息了，就可以了</p> 
<pre><code class="prism language-shell"><span class="token function">docker</span> logs <span class="token parameter variable">-f</span> <span class="token parameter variable">--tail</span> <span class="token number">200</span> kafka-ui
<span class="token function">docker</span> logs <span class="token parameter variable">-f</span> <span class="token parameter variable">--tail</span> <span class="token number">200</span> kafka
</code></pre> 
<h2><a id="_561"></a>结尾</h2> 
<p>1、kafka配置个账号密码… 确实有些麻烦！</p> 
<p>参考文章：</p> 
<ul><li> <p><a href="https://kafka.apache.org/34/documentation.html#security_sasl_plain" rel="nofollow">Authentication using SASL/PLAIN</a></p> </li><li> <p><a href="https://blog.csdn.net/qq_27047215/article/details/126800578">【保姆式通关宝典】使用Kraft快速搭建Kafka集群（含服务鉴权）</a></p> </li><li> <p><a href="https://blog.csdn.net/guaotianxia/article/details/121094383">kafka服务端设置用户和密码登录及springboot访问实现</a></p> </li><li> <p><a href="https://blog.csdn.net/d1240673769/article/details/124042854">Kafka配置用户名密码访问</a></p> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/497330d2855c07269bf47c55c37592fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Dependency not found解决方案（Springboot，绝对有效）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e9c64dd874bd6c79e7a5223ca2ee6d4b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">小米汽车正式亮相 雷军：目标是媲美保时捷与特斯拉</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>