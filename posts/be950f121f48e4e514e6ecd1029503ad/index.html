<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>tensorflow serving 动态加载更新模型 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="tensorflow serving 动态加载更新模型" />
<meta property="og:description" content="tensorflow serving是tensorflow用户服务器部署的方案，对于机器学习模型来说，是一个灵活的、高效能的服务系统，用来设计生产环境。tensorflow服务器保证相同的服务器架构和API，使得开发新的算法和实验变得容易。在这里不做过多介绍。 目前，tfs的模型加载有两种方式，第一种是通过在执行命令行时加载一个单模型的model_base_path的路径。：
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=8500 --model_name=test --model_base_path=/models/test/ 或者使用一个模型配置文件，示例如下：
/usr/local/bin/tensorflow_model_server --port=9000 --model_config_file=/serving/models.conf 这个模型配置文件格式官网上是没有的，得去github上去看，为了伸手党看着方便我直接放出来：
model_config_list: { config: { name: &#34;mymodel&#34;, base_path: &#34;/some/filesystem/path&#34;, model_platform: &#34;tensorflow&#34;, model_version_policy: { specific: { versions: 101, versions: 202 } } }, config: { name: &#34;mymodel2&#34;, base_path: &#34;/some/filesystem/path2&#34;, model_platform: &#34;tensorflow&#34;, model_version_policy: { latest: { num_versions: N } } }, } tensorflow模型支持同一个模型的不同版本的更新，但是现在模型加载了如果要新加一个模型的话除了重启服务外，暂时没有办法，通过在github里面的issue和pr里面各种找啊找，包括在源码里面看，总算找到了他的一种通过gRPC的接口进行模型热更新的方法，不需要重启服务，直接更新就可以了。但是还是个实验阶段，所以不一定能保证万无一失，为了伸手党们看着方便，我直接放代码了，要看懂的话，还是要对protobuf和gRPC的使用有一些了解。
from tensorflow_serving.apis import model_service_pb2 from tensorflow_serving.apis import model_service_pb2_grpc from tensorflow_serving.apis import model_management_pb2 from tensorflow_serving.config import model_server_config_pb2 from tensorflow_serving." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/be950f121f48e4e514e6ecd1029503ad/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-22T15:43:47+08:00" />
<meta property="article:modified_time" content="2018-08-22T15:43:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">tensorflow serving 动态加载更新模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>tensorflow serving是tensorflow用户服务器部署的方案，对于机器学习模型来说，是一个灵活的、高效能的服务系统，用来设计生产环境。tensorflow服务器保证相同的服务器架构和API，使得开发新的算法和实验变得容易。在这里不做过多介绍。 <br> 目前，tfs的模型加载有两种方式，第一种是通过在执行命令行时加载一个单模型的model_base_path的路径。：</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">bazel</span><span class="hljs-literal">-</span><span class="hljs-comment">bin/tensorflow_serving/model_servers/tensorflow_model_server</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">port=8500</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">model_name=test</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">model_base_path=/models/test/</span></code></pre> 
<p>或者使用一个模型配置文件，示例如下：</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">/usr/local/bin/tensorflow_model_server</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">port=9000</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span><span class="hljs-comment">model_config_file=/serving/models</span><span class="hljs-string">.</span><span class="hljs-comment">conf</span></code></pre> 
<p>这个模型配置文件格式官网上是没有的，得去github上去看，为了伸手党看着方便我直接放出来：</p> 
<pre class="prettyprint"><code class=" hljs css"><span class="hljs-tag">model_config_list</span>: <span class="hljs-rules">{
  <span class="hljs-rule"><span class="hljs-attribute">config</span>:<span class="hljs-value"> {
    name: <span class="hljs-string">"mymodel"</span>,
    base_path: <span class="hljs-string">"/some/filesystem/path"</span>,
    model_platform: <span class="hljs-string">"tensorflow"</span>,
    model_version_policy: {
       specific: {
        versions: <span class="hljs-number">101</span>,
        versions: <span class="hljs-number">202</span>
       </span></span></span>}
    }
  },
   <span class="hljs-tag">config</span>: <span class="hljs-rules">{
    <span class="hljs-rule"><span class="hljs-attribute">name</span>:<span class="hljs-value"> <span class="hljs-string">"mymodel2"</span>,
    base_path: <span class="hljs-string">"/some/filesystem/path2"</span>,
    model_platform: <span class="hljs-string">"tensorflow"</span>,
    model_version_policy: {
       latest: {
        num_versions: N
       </span></span></span>}
    }
  },
}</code></pre> 
<p>tensorflow模型支持同一个模型的不同版本的更新，但是现在模型加载了如果要新加一个模型的话除了重启服务外，暂时没有办法，通过在github里面的issue和pr里面各种找啊找，包括在源码里面看，总算找到了他的一种通过gRPC的接口进行模型热更新的方法，不需要重启服务，直接更新就可以了。但是还是个实验阶段，所以不一定能保证万无一失，为了伸手党们看着方便，我直接放代码了，要看懂的话，还是要对protobuf和gRPC的使用有一些了解。</p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-keyword">from</span> tensorflow_serving.apis <span class="hljs-keyword">import</span> model_service_pb2
<span class="hljs-keyword">from</span> tensorflow_serving.apis <span class="hljs-keyword">import</span> model_service_pb2_grpc
<span class="hljs-keyword">from</span> tensorflow_serving.apis <span class="hljs-keyword">import</span> model_management_pb2
<span class="hljs-keyword">from</span> tensorflow_serving.config <span class="hljs-keyword">import</span> model_server_config_pb2
<span class="hljs-keyword">from</span> tensorflow_serving.util <span class="hljs-keyword">import</span> status_pb2

<span class="hljs-keyword">import</span> grpc
<span class="hljs-keyword">import</span> sys
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">()</span>:</span>
  channel = grpc.insecure_channel(<span class="hljs-string">'yourip:yourport'</span>)
  stub = model_service_pb2_grpc.ModelServiceStub(channel)
  request = model_management_pb2.ReloadConfigRequest()  <span class="hljs-comment">##message ReloadConfigRequest</span>
  model_server_config = model_server_config_pb2.ModelServerConfig()

  config_list = model_server_config_pb2.ModelConfigList()<span class="hljs-comment">##message ModelConfigList</span>
  <span class="hljs-comment">####try to add</span>
  one_config = config_list.config.add() <span class="hljs-comment">#</span>
  one_config.name= <span class="hljs-string">"test1"</span>
  one_config.base_path = <span class="hljs-string">"/home/model/model1"</span>
  one_config.model_platform=<span class="hljs-string">"tensorflow"</span>

  model_server_config.model_config_list.CopyFrom(config_list) <span class="hljs-comment">#one of</span>

  request.config.CopyFrom(model_server_config)

  print(request.IsInitialized())
  print(request.ListFields())

  responese = stub.HandleReloadConfigRequest(request,<span class="hljs-number">10</span>)
  <span class="hljs-keyword">if</span> responese.status.error_code ==<span class="hljs-number">0</span>:
      print(<span class="hljs-string">"reload sucessfully"</span>)
  <span class="hljs-keyword">else</span>:
      print(<span class="hljs-string">"reload error!"</span>)
      print(responese.status.error_code)
      print(responese.status.error_message)
run()</code></pre> 
<p>这个里面我重新定义了一个模型，需要加的话自己根据自己的需要再加吧。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aff9bf2f5767d7ebcc831caac8a80d88/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">遍历文件夹的三种方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a1dd4a7c6ad1b30db09d89006e4ca754/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">js将图片转换为base64</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>