<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>NVDLA compiler - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="NVDLA compiler" />
<meta property="og:description" content="NVDLA简介 nvdia深度学习加速器(NVDLA)是一种免费开放式架构，具有可扩展性，高度可配置性，旨在简化集成和可移植性。NVDLA软件生态系统包括一个设备上的软件堆栈（开源版本的一部分），一个完整的培训基础架构，用于构建包含深度学习的新模型，以及将现有模型转换为可在设备上使用的形式的解析器软件。可以提供其自己的硬件平台以及软件内核：
NVDLA可以加速神经网络推理工作，可分两步完成
针对DLA硬件优化训练有素的神经网络，并将图形转换为DLA HW指令。转换后的图形将保存到称为可加载的平面缓冲区文件中。使用NVDLA编译器可以实现此目的，并且可以在主机系统上脱机执行。使用步骤1中的可加载程序在DLA上运行推理作业。这是使用NVDLA运行时实现的，并在目标系统上执行 NVDLA Compiler NVDLA编译器用于为DLA HW体系结构优化神经网络，并创建HW指令列表以在DLA上运行推理。NVDLA编译器可以从源代码构建，也可以直接使用预编译的二进制文件
root@6b9d78f7dd:# ./nvdla_compiler -h
Usage: ./nvdla_compiler [-options] --prototxt &lt;prototxt_file&gt; --caffemodel &lt;caffemodel_file&gt;
where options include:
-h print this help message
-o &lt;outputpath&gt; outputs wisdom files in &#39;outputpath&#39; directory
--profile &lt;basic|default|performance|fast-math&gt; computation profile (default: fast-math)
--cprecision &lt;fp16|int8&gt; compute precision (default: fp16)
--configtarget &lt;opendla-full|opendla-large|opendla-small&gt; target platform (default: nv_full)
--calibtable &lt;int8 calib file&gt; calibration table for INT8 networks (default: 0.00787)
--quantizationMode &lt;per-kernel|per-filter&gt; quantization mode for INT8 (default: per-kernel)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/4dcc5483a42deaef8502528e5b9b30db/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-14T13:25:21+08:00" />
<meta property="article:modified_time" content="2021-04-14T13:25:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">NVDLA compiler</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>NVDLA简介</h3> 
<p>nvdia深度学习加速器(NVDLA)是一种免费开放式架构，具有可扩展性，高度可配置性，旨在简化集成和可移植性。NVDLA软件生态系统包括一个设备上的软件堆栈（开源版本的一部分），一个完整的培训基础架构，用于构建包含深度学习的新模型，以及将现有模型转换为可在设备上使用的形式的解析器软件。可以提供其自己的硬件平台以及软件内核：</p> 
<p><span style="color:#24292e;">NVDLA可以加速神经网络推理工作，可分两步完成</span></p> 
<ol><li>针对DLA硬件优化训练有素的神经网络，并将图形转换为DLA HW指令。转换后的图形将保存到称为可加载的平面缓冲区文件中。使用NVDLA编译器可以实现此目的，并且可以在主机系统上脱机执行。</li><li>使用步骤1中的可加载程序在DLA上运行推理作业。这是使用NVDLA运行时实现的，并在目标系统上执行</li></ol> 
<h3>NVDLA Compiler</h3> 
<p>NVDLA编译器用于为DLA HW体系结构优化神经网络，并创建HW指令列表以在DLA上运行推理。NVDLA编译器可以从<a href="https://github.com/nvdla/sw/tree/master/umd/core/src/compiler">源代码</a>构建，也可以直接使用<a href="https://github.com/nvdla/sw/tree/master/prebuilt/x86-ubuntu">预编译的二进制文件</a></p> 
<blockquote> 
 <p>root@6b9d78f7dd:# ./nvdla_compiler -h<br> Usage: ./nvdla_compiler [-options] --prototxt &lt;prototxt_file&gt; --caffemodel &lt;caffemodel_file&gt;<br> where options include:<br>     -h                                                          print this help message<br>     -o &lt;outputpath&gt;                                             outputs wisdom files in 'outputpath' directory<br>     --profile &lt;basic|default|performance|fast-math&gt;             computation profile (default: fast-math)<br>     --cprecision &lt;fp16|int8&gt;                                    compute precision (default: fp16)<br>     --configtarget &lt;opendla-full|opendla-large|opendla-small&gt;   target platform (default: nv_full)<br>     --calibtable &lt;int8 calib file&gt;                              calibration table for INT8 networks (default: 0.00787)<br>     --quantizationMode &lt;per-kernel|per-filter&gt;                  quantization mode for INT8 (default: per-kernel)<br>     --batch                                                     batch size (default: 1)<br>     --informat &lt;ncxhwx|nchw|nhwc&gt;                               input data format (default: nhwc)</p> 
</blockquote> 
<p><strong>转换example（以resnet50 nv_full int8 为例）</strong></p> 
<p> </p> 
<blockquote> 
 <p>./nvdla_compiler --prototxt ResNet-50-deploy.prototxt --caffemodel ResNet-50-model.caffemodel -o . --profile fast-math --cprecision int8 --configtarget nv_full --calibtable resnet50.json --quantizationMode per-filter --batch 1 --informat nhwc</p> 
</blockquote> 
<p><strong>输出</strong></p> 
<p>一旦编译成功，它将在使用-o参数指定的输出目录中生成.nvdla文件。例如，在上述情况下，它将在curren目录中生成fast-math.nvdla</p> 
<p> </p> 
<p><strong>如果需要自行编译nvdla_compiler </strong></p> 
<blockquote> 
 <pre><code>cd umd
export TOP={sw-repo-root}/umd
make compiler

Note :
使用sdk中默认的libprotobuf.a可能链接会报错，这个需要根据自己的环境重新编译一下protobuf，命令如下
./configure --enable-shared
make
make check
sudo make install</code></pre> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6311fb6f95bb62c877e384dace92b9dc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">DataWhale集成学习Task7--投票法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6e5385bb986848751c6e8e665572176c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">白话一致性</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>