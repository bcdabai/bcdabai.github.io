<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>实践数据湖iceberg 第十课 快照删除 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="实践数据湖iceberg 第十课 快照删除" />
<meta property="og:description" content="系列文章目录 实践数据湖iceberg 第一课 入门
实践数据湖iceberg 第二课 iceberg基于hadoop的底层数据格式
实践数据湖iceberg 第三课 在sqlclient中，以sql方式从kafka读数据到iceberg
实践数据湖iceberg 第四课 在sqlclient中，以sql方式从kafka读数据到iceberg（升级版本到flink1.12.7）
实践数据湖iceberg 第五课 hive catalog特点
实践数据湖iceberg 第六课 从kafka写入到iceberg失败问题 解决
实践数据湖iceberg 第七课 实时写入到iceberg
实践数据湖iceberg 第八课 hive与iceberg集成
实践数据湖iceberg 第九课 合并小文件
实践数据湖iceberg 第十课 快照删除
文章目录 系列文章目录前言1.基于hive的catalog，对表进行小文件合并代码2. 合并运行过程3.是否能多次合并？总结 前言 如第九课所讲，对文件进行合并，只是生成新的合并文件和快照文件，没有对原来的小文件进行删除。 本节，测试一下旧的数据删除，删旧数据，需要通过删旧快照进行，详情请看下文 1.基于hive的catalog，对表进行小文件合并代码 package org.example import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment import org.apache.hadoop.conf.Configuration import org.apache.iceberg.catalog.{Namespace, TableIdentifier} import org.apache.iceberg.flink.{CatalogLoader, TableLoader} import org.apache.iceberg.flink.actions.Actions import org.apache.log4j.{Level, Logger} import org.slf4j.LoggerFactory import java.util import java.util.concurrent.TimeUnit object FlinkDataStreamSmallFileCompactTest { private var logger: org." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/abe45d2e8171c4cd7a0ed07b334f3f16/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-16T17:54:56+08:00" />
<meta property="article:modified_time" content="2022-02-16T17:54:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实践数据湖iceberg 第十课 快照删除</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>系列文章目录</h2> 
<font color="#999AAA"> </font> 
<p><a href="https://blog.csdn.net/spark_dev/article/details/122450257">实践数据湖iceberg 第一课 入门</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122470111">实践数据湖iceberg 第二课 iceberg基于hadoop的底层数据格式</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122541094">实践数据湖iceberg 第三课 在sqlclient中，以sql方式从kafka读数据到iceberg</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122556176">实践数据湖iceberg 第四课 在sqlclient中，以sql方式从kafka读数据到iceberg（升级版本到flink1.12.7）</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122561079">实践数据湖iceberg 第五课 hive catalog特点</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122581841">实践数据湖iceberg 第六课 从kafka写入到iceberg失败问题 解决</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122582268">实践数据湖iceberg 第七课 实时写入到iceberg</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122605544">实践数据湖iceberg 第八课 hive与iceberg集成</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122607026">实践数据湖iceberg 第九课 合并小文件</a><br> <a href="https://blog.csdn.net/spark_dev/article/details/122719017">实践数据湖iceberg 第十课 快照删除</a><br> <font color="#999AAA"></font></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">系列文章目录</a></li><li><a href="#_23" rel="nofollow">前言</a></li><li><a href="#1hivecatalog_29" rel="nofollow">1.基于hive的catalog，对表进行小文件合并代码</a></li><li><a href="#2__96" rel="nofollow">2. 合并运行过程</a></li><li><a href="#3_180" rel="nofollow">3.是否能多次合并？</a></li><li><a href="#_188" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr color="#000000" size='1"'> 
<hr color="#000000" size='1"'> 
<h2><a id="_23"></a>前言</h2> 
<font color="#999AAA"> 如第九课所讲，对文件进行合并，只是生成新的合并文件和快照文件，没有对原来的小文件进行删除。 本节，测试一下旧的数据删除，删旧数据，需要通过删旧快照进行，详情请看下文 </font> 
<h2><a id="1hivecatalog_29"></a>1.基于hive的catalog，对表进行小文件合并代码</h2> 
<pre><code class="prism language-c">package org<span class="token punctuation">.</span>example

import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment
import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration
import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>Namespace<span class="token punctuation">,</span> TableIdentifier<span class="token punctuation">}</span>
import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>flink<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>CatalogLoader<span class="token punctuation">,</span> TableLoader<span class="token punctuation">}</span>
import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>actions<span class="token punctuation">.</span>Actions
import org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span><span class="token punctuation">{<!-- --></span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
import org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span>LoggerFactory
import java<span class="token punctuation">.</span>util
import java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>TimeUnit
object FlinkDataStreamSmallFileCompactTest <span class="token punctuation">{<!-- --></span>
  private var logger<span class="token operator">:</span> org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span>Logger <span class="token operator">=</span> _
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    logger <span class="token operator">=</span> LoggerFactory<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span>this<span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getSimpleName<span class="token punctuation">)</span>
    Logger<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token string">"org.apache"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setLevel</span><span class="token punctuation">(</span>Level<span class="token punctuation">.</span>INFO<span class="token punctuation">)</span>
    Logger<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token string">"hive.metastore"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setLevel</span><span class="token punctuation">(</span>Level<span class="token punctuation">.</span>WARN<span class="token punctuation">)</span>
    Logger<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token string">"akka"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setLevel</span><span class="token punctuation">(</span>Level<span class="token punctuation">.</span>WARN<span class="token punctuation">)</span>

    <span class="token comment">// hadoop catalog</span>
    val tablePath <span class="token operator">=</span> <span class="token string">"hdfs:///user/hive/warehouse/iceberg_db/iceberg_table"</span>

    <span class="token comment">// hive catalog</span>
    val env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    System<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"HADOOP_USER_NAME"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span>
    val map <span class="token operator">=</span> new util<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span>String<span class="token punctuation">,</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"iceberg"</span><span class="token punctuation">)</span>
    map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"catalog-type"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">)</span>
    map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"property-version"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">)</span>
    map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"/warehouse"</span><span class="token punctuation">,</span> <span class="token string">"/user/hive/warehouse"</span><span class="token punctuation">)</span>
<span class="token comment">//    map.put("datanucleus.schema.autoCreateTables", "true")</span>
<span class="token comment">//    压缩小文件</span>
<span class="token comment">//    快照过期处理</span>
    map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"uri"</span><span class="token punctuation">,</span> <span class="token string">"thrift://hadoop101:9083"</span><span class="token punctuation">)</span>
    val iceberg_catalog <span class="token operator">=</span> CatalogLoader<span class="token punctuation">.</span><span class="token function">hive</span><span class="token punctuation">(</span>
      <span class="token string">"hive_catalog6"</span><span class="token punctuation">,</span><span class="token comment">//catalog名称</span>
      new <span class="token function">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      new util<span class="token punctuation">.</span><span class="token function">HashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    val identifier <span class="token operator">=</span> TableIdentifier<span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>Namespace<span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"iceberg_db6"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">//db名称</span>
      <span class="token string">"behavior_log_ib6"</span><span class="token punctuation">)</span><span class="token comment">//表名称</span>
    val loader <span class="token operator">=</span> TableLoader<span class="token punctuation">.</span><span class="token function">fromCatalog</span><span class="token punctuation">(</span>iceberg_catalog<span class="token punctuation">,</span> identifier<span class="token punctuation">)</span>
    loader<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    val table <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">loadTable</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    Actions<span class="token punctuation">.</span><span class="token function">forTable</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> table<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>rewriteDataFiles
      <span class="token punctuation">.</span><span class="token function">maxParallelism</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">targetSizeInBytes</span><span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>execute
    <span class="token comment">// 清除历史快照</span>
    val snapshot <span class="token operator">=</span> table<span class="token punctuation">.</span>currentSnapshot
    <span class="token comment">// val old = snapshot.timestampMillis - TimeUnit.MINUTES.toMillis(5)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>snapshot <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      table<span class="token punctuation">.</span>expireSnapshots
        <span class="token punctuation">.</span><span class="token function">expireOlderThan</span><span class="token punctuation">(</span>snapshot<span class="token punctuation">.</span>timestampMillis<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<font color="#999AAA"> </font> 
<h2><a id="2__96"></a>2. 合并运行过程</h2> 
<p>以下输出是，每间隔几秒执行一次<br> data目录最开始是17978 个，执行一段时间后，才执行查询命令<br> 分析日志：先合并data目录，再合并medata目录，data的文件个数由17978-&gt;22个，metadata有26226-&gt;8716。 metadata是否还能继续合并？</p> 
<pre><code class="prism language-c"><span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">5000</span>   <span class="token number">39995</span>  <span class="token number">994818</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata |wc</span>
  <span class="token number">26226</span>  <span class="token number">209803</span> <span class="token number">5269123</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">3578</span>   <span class="token number">28619</span>  <span class="token number">711840</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">3403</span>   <span class="token number">27219</span>  <span class="token number">677015</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">3213</span>   <span class="token number">25699</span>  <span class="token number">639205</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">3029</span>   <span class="token number">24227</span>  <span class="token number">602589</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">2713</span>   <span class="token number">21699</span>  <span class="token number">539705</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata |wc</span>
  <span class="token number">26226</span>  <span class="token number">209803</span> <span class="token number">5269123</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">2200</span>   <span class="token number">17595</span>  <span class="token number">437618</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata |wc</span>
  <span class="token number">26226</span>  <span class="token number">209803</span> <span class="token number">5269123</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
   <span class="token number">1703</span>   <span class="token number">13619</span>  <span class="token number">338715</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
     <span class="token number">22</span>     <span class="token number">171</span>    <span class="token number">4194</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
     <span class="token number">22</span>     <span class="token number">171</span>    <span class="token number">4194</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
     <span class="token number">22</span>     <span class="token number">171</span>    <span class="token number">4194</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
  <span class="token number">25344</span>  <span class="token number">202747</span> <span class="token number">5102415</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
  <span class="token number">24937</span>  <span class="token number">199491</span> <span class="token number">5025486</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
     <span class="token number">22</span>     <span class="token number">171</span>    <span class="token number">4194</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
  <span class="token number">24447</span>  <span class="token number">195571</span> <span class="token number">4932870</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
  <span class="token number">23667</span>  <span class="token number">189331</span> <span class="token number">4785445</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
  <span class="token number">20402</span>  <span class="token number">163211</span> <span class="token number">4168329</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
   <span class="token number">8716</span>   <span class="token number">69723</span> <span class="token number">1751708</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
   <span class="token number">8716</span>   <span class="token number">69723</span> <span class="token number">1751708</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/metadata|wc</span>
   <span class="token number">8716</span>   <span class="token number">69723</span> <span class="token number">1751708</span>
<span class="token punctuation">[</span>root@hadoop103 hadoop<span class="token punctuation">]</span>#    hadoop fs <span class="token operator">-</span>ls hdfs<span class="token operator">:</span><span class="token comment">//ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data |wc</span>
     <span class="token number">22</span>     <span class="token number">171</span>    <span class="token number">4194</span>
</code></pre> 
<p>合并后，data的内容：</p> 
<pre><code>[root@hadoop103 hadoop]#     hadoop fs -ls hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data
Found 21 items
-rw-r--r--   2 root supergroup     173182 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00000-0-3c21e5b1-54e8-42b1-8bdc-a0b8f1514ee1-00001.parquet
-rw-r--r--   2 root supergroup     173037 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00000-0-3c21e5b1-54e8-42b1-8bdc-a0b8f1514ee1-00002.parquet
-rw-r--r--   2 root supergroup     173149 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00000-0-3c21e5b1-54e8-42b1-8bdc-a0b8f1514ee1-00003.parquet
-rw-r--r--   2 root supergroup    3302206 2022-01-27 14:38 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00000-0-cdcc5019-0c59-41e4-80c6-1d4185455065-00001.parquet
-rw-r--r--   2 root supergroup        508 2022-01-26 11:35 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00000-0-dd8bc29f-831a-4904-830e-2ef56e4a4743-08707.parquet
-rw-r--r--   2 root supergroup     173032 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00001-0-139af0f5-d3ee-4f35-bd2e-73ce2aaf4792-00001.parquet
-rw-r--r--   2 root supergroup     173113 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00001-0-139af0f5-d3ee-4f35-bd2e-73ce2aaf4792-00002.parquet
-rw-r--r--   2 root supergroup     173124 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00001-0-139af0f5-d3ee-4f35-bd2e-73ce2aaf4792-00003.parquet
-rw-r--r--   2 root supergroup        552 2022-01-26 11:35 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00001-0-e9e8a782-fa82-4c4d-9786-c05b8aab251a-08707.parquet
-rw-r--r--   2 root supergroup       5995 2022-01-27 11:52 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00002-0-a0f46641-b14d-4f8b-a16e-4c768bcba775-00109.parquet
-rw-r--r--   2 root supergroup     173153 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00002-0-fe001b68-3753-44a7-adb4-63d43c8b3226-00001.parquet
-rw-r--r--   2 root supergroup     168653 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00002-0-fe001b68-3753-44a7-adb4-63d43c8b3226-00002.parquet
-rw-r--r--   2 root supergroup     173288 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00002-0-fe001b68-3753-44a7-adb4-63d43c8b3226-00003.parquet
-rw-r--r--   2 root supergroup     173023 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00002-0-fe001b68-3753-44a7-adb4-63d43c8b3226-00004.parquet
-rw-r--r--   2 root supergroup     173223 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00003-0-1d71db79-abf1-4088-9282-bc907e45e262-00001.parquet
-rw-r--r--   2 root supergroup     173039 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00003-0-1d71db79-abf1-4088-9282-bc907e45e262-00002.parquet
-rw-r--r--   2 root supergroup     172976 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00003-0-1d71db79-abf1-4088-9282-bc907e45e262-00003.parquet
-rw-r--r--   2 root supergroup     172950 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00003-0-1d71db79-abf1-4088-9282-bc907e45e262-00004.parquet
-rw-r--r--   2 root supergroup     540168 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00004-0-fea6f5d5-759f-4769-9ced-b3ecca214e36-00001.parquet
-rw-r--r--   2 root supergroup     173059 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00004-0-fea6f5d5-759f-4769-9ced-b3ecca214e36-00002.parquet
-rw-r--r--   2 root supergroup     172866 2022-01-27 14:16 hdfs://ns/user/hive/warehouse/hive_catalog6/iceberg_db6.db/behavior_log_ib6/data/00004-0-fea6f5d5-759f-4769-9ced-b3ecca214e36-00003.parquet
</code></pre> 
<h2><a id="3_180"></a>3.是否能多次合并？</h2> 
<p>只跑删快照代码，发现删不动了。<br> <img src="https://images2.imgbox.com/e2/9c/pWniUJpc_o.png" alt="在这里插入图片描述"><br> 合并代码继续跑，发现不再合并（跑了几次都是这样）<br> <img src="https://images2.imgbox.com/b3/01/yM4ZVd3E_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_188"></a>总结</h2> 
<font color="#999AAA"> </font> 
<p>数据文件减少明显，metadata还存在很多，没法减少（只减少为原来的1/3），经过分析删除的是snapshot文件和manifiest文件，metadata.json没有删除（剩余没删掉的就是metadata.json）。</p> 
<p>表数据没有变化的情况下，多次进行合并的效果跟合并一次是一样的。</p> 
<p><strong>有个疑问：对于分区表的小文件删除，是怎样的呢？能否支持基于分区进行合并？</strong><br> 请看下一课</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8d15dc102030ea35e0274c394ebdce00/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue-pdf 通过文件流预览pdf文件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f62a0d4232c3b7e076eda9563857fe5e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">蓝桥杯实用小技巧</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>