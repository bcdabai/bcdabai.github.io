<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Linux 上使用 Linux Shell 脚本自动化按天分割、压缩（延迟压缩）和定期清理日志文件... - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Linux 上使用 Linux Shell 脚本自动化按天分割、压缩（延迟压缩）和定期清理日志文件..." />
<meta property="og:description" content="2019-02-26 10:10:54
最近 Hgh这边有一个需求，需要对Linux服务器上的日志进行相应地自动化处理：
1) 定期清理：当分区的可使用空间超过一个预先设定好的阈值（如当分区的可使用空间超过 80 % 时）就自动清 理日志，清理周期是一天一次；
2) 按天分割：有的日志文件如 access.log 会不断地增长，现在需要对其进行分割操作（假设今天的日期是 2019 年 1 月 25 日，当时间到达 2019 年 1 月 26 日 0 点 0 分时，自动分割出一个 access.log.20190125 的日志文 件;
3) 压缩：对 access.log.20190125 这样的日志文件进行压缩，即生成压缩包 access.log.20190125.tar.gz 并删除日志文件 access.log.20190125 ；
4) 延迟压缩：有的开发可能需要查看最近几天的日志，为了方便开发查看日志，可对最近几天的日志文件进行延迟压缩的操作（假设今天的日期是 2019 年 1 月 25 日，根据开发的要求暂时不压缩最近一天的日志，则当时间到达 2019 年 1 月 26 日 0 点 0 分时，压缩的是 2019 年 1 月 24 日的日志文件 access.log.20190124 ，过了 24 小时以后再压缩 access." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/bd94d2e5b7d7d9810dc56d6a59fdcc9b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-02-26T10:21:00+08:00" />
<meta property="article:modified_time" content="2019-02-26T10:21:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Linux 上使用 Linux Shell 脚本自动化按天分割、压缩（延迟压缩）和定期清理日志文件...</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="con artical-content editor-preview-side"> 
 <p>2019-02-26 10:10:54<br>最近 Hgh这边有一个需求，需要对Linux服务器上的日志进行相应地自动化处理：<br>1) 定期清理：当分区的可使用空间超过一个预先设定好的阈值（如当分区的可使用空间超过 80 % 时）就自动清 理日志，清理周期是一天一次；<br>2) 按天分割：有的日志文件如 access.log 会不断地增长，现在需要对其进行分割操作（假设今天的日期是 2019 年 1 月 25 日，当时间到达 2019 年 1 月 26 日 0 点 0 分时，自动分割出一个 access.log.20190125 的日志文 件;<br>3) 压缩：对 access.log.20190125 这样的日志文件进行压缩，即生成压缩包 access.log.20190125.tar.gz 并删除日志文件 access.log.20190125 ；<br>4) 延迟压缩：有的开发可能需要查看最近几天的日志，为了方便开发查看日志，可对最近几天的日志文件进行延迟压缩的操作（假设今天的日期是 2019 年 1 月 25 日，根据开发的要求暂时不压缩最近一天的日志，则当时间到达 2019 年 1 月 26 日 0 点 0 分时，压缩的是 2019 年 1 月 24 日的日志文件 access.log.20190124 ，过了 24 小时以后再压缩 access.log.20190125 ）。</p> 
 <p>部署：<br>1 、编写脚本，在命令行界面输入：</p> 
 <p>[root@host ~]# vi /root/log.sh<br>键入小写字母 i ，进入编辑模式，将 “ 附录 ” 中的 log.sh 复制粘贴进去。</p> 
 <p>按一次 ESC 键退出编辑模式，然后键入 “ :wq ” 保存并退出。</p> 
 <p>2 、创建并修改配置文件，在命令行界面输入：</p> 
 <p>[root@host ~]# vi /root/log.config<br>键入小写字母 i ，进入编辑模式，将 “ 附录 ” 中的 log.config 复制粘贴进去（请根据实际需要修改相应地配置）。</p> 
 <p>按一次 ESC 键退出编辑模式，然后键入 “ :wq ” 保存并退出。</p> 
 <p>3 、为上述脚本赋予可执行权限，并创建日志文件：</p> 
 <p>[root@host ~]# chmod +x /root/log.sh<br>[root@host ~]# touch /root/log.log<br>4 、让上述脚本每天凌晨 0 点 0 分自动运行一次，在命令行界面输入：</p> 
 <p>[root@host ~]# echo "0 0 * sh /root/log.sh" &gt;&gt; /var/spool/cron/root<br>至此，部署完成。</p> 
 <p>应用举例：<br>Hgh将会通过应用举例的方式来说明这个脚本具体是如何使用的。</p> 
 <p>举例用的操作系统版本号如下所示：</p> 
 <p>[root@host ~]# cat /etc/redhat-release <br>CentOS Linux release 7.0.1406 (Core) <br>[root@host ~]#<br>简单使用和定期清理日志：<br>1 、先创建一些日志文件用来模拟生产环境：</p> 
 <p>[root@host ~]# mkdir -p /www/log/applog/<br>[root@host ~]# mkdir -p /www/log/accesslog/<br>[root@host ~]# echo 123 &gt; /www/log/applog/www.test.com.log<br>[root@host ~]# echo 123 &gt; /www/log/applog/www.test.net.log<br>[root@host ~]# echo 123 &gt; /www/log/accesslog/www.test.com.log<br>[root@host ~]# echo 123 &gt; /www/log/accesslog/www.test.net.log.20190128.00<br>[root@host ~]# echo 123 &gt; /www/log/accesslog/www.test.net.log.20190128.01<br>[root@host ~]# echo 123 &gt; /www/log/accesslog/www.test.net.log.20190128.02<br>现在使用 tree 命令来看一下日志文件夹的目录结构：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]#<br>2 、修改配置文件，具体配置如下所示：</p> 
 <p>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz<br>[root@host ~]#<br>这里解释说明一下上述配置的作用：</p> 
 <p>mount ：设置日志文件所在的挂载点，具体挂载点请用 df -h 命令查看；<br>mount_used_size_percent ：设置该挂载点最多可以使用多少空间，单位是百分比；<br>log_dir ：设置日志文件所在的文件夹，用于自动清理日志文件（从文件修改时间是最旧的日志文件开始删除，包括子文件夹下的日志文件），直到上述挂载点的可使用空间最多不超过 mount_used_size_percent 这个百分比为止（除非日志文件已经全部删除完毕）；<br>log_format_regex ：是一串正则表达式，用于自定义待删除的日志文件格式，防止误删除。<br>和上述配置的举例、注意事项：</p> 
 <p>（ 1 ）log_format_regex 举例和注意事项：</p> 
 <p>如待删除的日志文件均为压缩格式，则这么配置即可（其中 ” \ ” 是转义字符，” | ” 是 ” 或 ” ）：log_format_regex=(.tar|.gz|.tar.gz|.bz2|.tar.bz2|.bz|.tar.bz|.Z|.tar.Z|.tgz|.tar.tgz|.zip|.lha|.rar)$ ；<br>注意：请不要把 .log 这个关键字写入进去，因为很多正在写入的日志文件都是以 xxx.log 命名的，这些文件是不能匹配到并删除的。<br>和上述配置的取值范围：</p> 
 <p>mount ：该值必须配置且仅允许配置一次；<br>mount_used_size_percent ：该值必须配置且仅允许配置一次，取值范围在 50 ≤ x ≤ 85 之间；<br>log_dir ：该值必须配置且允许配置多次，如果文件夹不存在会将错误信息写入到日志文件 log.log 并终止运行；<br>log_format_regex ：该值必须配置且仅允许配置一次。<br>3 、现在我们来看看这个脚本是如何运行的，如果直接运行会弹出如下提示：</p> 
 <p>[root@host ~]# sh log.sh <br>Please run the script at 0 a.m.<br>[root@host ~]#<br>因为该脚本最主要的一个功能就是自动化按天分割日志文件，为了让该功能能够准确地运行，建议您在每天 0 点 0 分的时候才执行该脚本（或者说在每天 0 点 0 分的时候才执行 “ 按天分割日志 ” 的操作），所以 这里限制了该脚本的运行时间（该脚本只允许在每天 0 点 0 分至 0 点 59 分之间运行）。</p> 
 <p>那如何调试脚本呢？您需要这么运行：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]#<br>即开启调试模式，强行让脚本执行起来（请不用在生产环境上调试，以免误删除重要文件）。</p> 
 <p>同时，log.config 配置文件和 log.log 该脚本的日志文件默认是放置在 /root/ 目录下的，如果您想自定义路径，可以这么运行脚本：</p> 
 <p>[root@host ~]# sh log.sh config_file=/ricky/log.config<br>config file ( /ricky/log.config ) not found !<br>[root@host ~]# <br>[root@host ~]# sh log.sh log_file=/ricky/log.log<br>log file ( /ricky/log.log ) not found !<br>[root@host ~]# <br>[root@host ~]# sh log.sh config_file=/ricky/log.config log_file=/ricky/log.log<br>config file ( /ricky/log.config ) not found !<br>[root@host ~]# <br>[root@host ~]# sh log.sh log_file=/ricky/log.log config_file=/ricky/log.config<br>config file ( /ricky/log.config ) not found !<br>[root@host ~]# <br>[root@host ~]# sh log.sh log_file=/ricky/log.log config_file=/ricky/log.config debug_mode=yes<br>config file ( /ricky/log.config ) not found !<br>[root@host ~]#<br>如上所示，脚本会自动判断 config_file 和 log_file 这两个文件是否存在；如果这两个文件不存在，脚本会终止运行。</p> 
 <p>4 、此时 /www/log/ 的目录结构和 log.config 配置文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]# cat /root/log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz<br>[root@host ~]#<br>执行该脚本：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]#<br>脚本执行完毕后 /www/log/ 的目录结构和 log.log 日志文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]# cat /root/log.log <br>2019-01-29 09:35 - debug_mode is enabled ! Do NOT use in production environment !<br>2019-01-29 09:35 - Delete all the log files is completed , but did not reach the 50 % used precent !<br>2019-01-29 09:35 - === gz log ===<br>[root@host ~]#<br>此时 /www/log/ 目录结构无任何变化，因为我们在 log.config 配置文件里面配置了这两句：</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz<br>所以脚本只会在 /www/log/ 目录（包括子目录）里删除文件名带有 tar.gz 字样的文件，而 /www/log 目录下并无带有 tar.gz 字样的文件。</p> 
 <p>此时 log.log 日志文件里还记录了一条日志：</p> 
 <p>2019-01-29 09:35 - Delete all the log files is completed , but did not reach the 50 % used precent !<br>该日志的意思是说所有的日志文件已经删除完毕了（因为确实也不存在文件名带有 tar.gz 字样的文件了），但是挂载点 /www 的已使用空间依然超过了 50 % ，df -h 命令的执行结果如下所示：</p> 
 <p>[root@host ~]# df -h<br>Filesystem Size Used Avail Use% Mounted on<br>devtmpfs 3.9G 0 3.9G 0% /dev<br>tmpfs 3.9G 0 3.9G 0% /dev/shm<br>tmpfs 3.9G 369M 3.6G 10% /run<br>tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup<br>/dev/sda2 10G 6.5G 3.5G 66% /<br>/dev/sda5 48G 30G 18G 63% /www<br>/dev/sda1 197M 107M 90M 55% /boot<br>[root@host ~]#<br>5 、现在我们多创建几个文件再测试一次：</p> 
 <p>[root@host ~]# echo 456 &gt; /www/log/accesslog/www.test.net.log.tar<br>[root@host ~]# echo 456 &gt; /www/log/accesslog/www.test.net.log.tar.gz<br>[root@host ~]# echo 456 &gt; /www/log/applog/www.test.net.log.tar<br>[root@host ~]# echo 456 &gt; /www/log/applog/www.test.net.log.tar.gz<br>[root@host ~]# echo 456 &gt; /www/log/applog/www.test.net.tar.gz.log<br>[root@host ~]# <br>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ ├── www.test.net.log.20190128.02<br>│ ├── www.test.net.log.tar<br>│ └── www.test.net.log.tar.gz<br>└── applog<br>├── www.test.com.log<br>├── www.test.net.log<br>├── www.test.net.log.tar<br>├── www.test.net.log.tar.gz<br>└── www.test.net.tar.gz.log</p> 
 <p>2 directories, 11 files<br>[root@host ~]#<br>执行该脚本：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]#<br>查看 /www/log/ 目录我们可以发现，凡是文件名带有 tar.gz 字样的文件都删除掉了：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ ├── www.test.net.log.20190128.02<br>│ └── www.test.net.log.tar<br>└── applog<br>├── www.test.com.log<br>├── www.test.net.log<br>└── www.test.net.log.tar</p> 
 <p>2 directories, 8 files<br>[root@host ~]#<br>6 、如果您只想删除以 .tar.gz 结尾的文件，只需要这么配置：</p> 
 <p>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz$<br>[root@host ~]#<br>加一个正则表达式里的 $ 符号即可（即只匹配以 .tar.gz 结尾的文件），这样文件 www.test.net.tar.gz.log 就不会被删除了（亲测有效）。</p> 
 <p>7 、log_dir 允许配置多个值，如：</p> 
 <p>[root@host ~]# cat /root/log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log/accesslog<br>log_dir=/www/log/applog<br>log_dir=/tmp/applog<br>log_format_regex=.tar.gz<br>[root@host ~]#<br>脚本会预先判断这些文件夹是否存在，如果其中一个文件夹是不存在的，脚本会将错误信息写入到日志文件 log.log 并终止运行。具体报错信息如下所示：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# <br>[root@host ~]# cat log.log <br>2019-01-29 15:17 - debug_mode is enabled ! Do NOT use in production environment !<br>2019-01-29 15:17 - log_dir /tmp/applog does not exist !<br>[root@host ~]#<br>按天分割日志：<br>1 、修改配置文件，具体配置如下所示：</p> 
 <p>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>cut_log=/www/log/accesslog/www.test.com.log<br>[root@host ~]#<br>这里解释说明一下上述配置的作用：</p> 
 <p>cut_log ：设置需要进行按天分割的日志文件的文件路径。<br>和上述配置的举例：</p> 
 <p>（ 1 ）cut_log 举例：</p> 
 <p>比如：cut_log=/www/accesslog/www.test.com/access.log ，假设今天的日期是 2019 年 1 月 29 日，那么到了 2019 年 1 月 30 日凌晨 0 点 0 分会分卷一份 access.log.20190129 出来。<br>允许设置多条，如：<br>cut_log=/www/accesslog/www.test.com/access.log<br>cut_log=/www/accesslog/www.test.net/access.log<br>也可以不设置，如：<br>cut_log=<br>和上述配置的取值范围：</p> 
 <p>cut_log ：该值可不配置且允许配置多次，日志文件路径必须是绝对路径，如果文件不存在会将错误信息写入到日志文件 log.log 并终止运行。<br>2 、此时 /www/log/ 的目录结构和 log.config 配置文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log<br>/www/log<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]# <br>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>cut_log=/www/log/accesslog/www.test.com.log<br>cut_log=/www/log/applog/www.test.com.log<br>[root@host ~]#<br>当前两个日志文件 /www/log/accesslog/www.test.com.log 和 /www/log/applog/www.test.com.log 的内容如下所示：</p> 
 <p>[root@host ~]# cat /www/log/accesslog/www.test.com.log<br>123<br>[root@host ~]# cat /www/log/applog/www.test.com.log<br>123<br>[root@host ~]#<br>执行完脚本以后会发现多出了两个日志文件 /www/log/accesslog/www.test.com.log.20190129 和 /www/log/applog/www.test.com.log.20190129（假设执行脚本的时间是 2019 年 1 月 30 日 0 点 0 分）：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# <br>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.com.log.20190129<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>├── www.test.com.log.20190129<br>└── www.test.net.log</p> 
 <p>2 directories, 8 files<br>[root@host ~]#<br>同时原日志文件已经被清空：</p> 
 <p>[root@host ~]# cat /www/log/accesslog/www.test.com.log</p> 
 <p>[root@host ~]# cat /www/log/applog/www.test.com.log</p> 
 <p>[root@host ~]# cat /www/log/accesslog/www.test.com.log.20190129 <br>123<br>[root@host ~]# cat /www/log/applog/www.test.com.log.20190129 <br>123<br>[root@host ~]#<br>3 、脚本会预先判断这些文件是否存在，如果其中一个文件是不存在的，脚本会将错误信息写入到日志文件 log.log 并终止运行。此时 /www/log/ 的目录结构和 log.config 配置文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]# <br>[root@host ~]# <br>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>cut_log=/www/log/accesslog/www.test.com.log<br>cut_log=/www/log/applog/www.test.com.log123<br>[root@host ~]#<br>具体报错信息如下所示：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# cat log.log <br>2019-01-31 09:18 - debug_mode is enabled ! Do NOT use in production environment !<br>2019-01-31 09:18 - log_file /www/log/applog/www.test.com.log123 does not exist !<br>[root@host ~]#<br>压缩日志：<br>1 、修改配置文件，具体配置如下所示：</p> 
 <p>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>gz_log=/www/log/applog/www.test.com.log<br>gz_delay_day=<br>[root@host ~]#<br>这里解释说明一下上述配置的作用：</p> 
 <p>gz_log ：设置需要进行压缩的日志文件（支持自定义日期格式和模糊匹配）的文件路径；<br>gz_delay_day ：设置延迟压缩的天数。<br>和上述配置的举例：</p> 
 <p>（ 1 ）gz_log 举例：</p> 
 <p>支持自定义日期格式，其中：<br>” %YYYY ” 是年<br>” %MMMM ” 是月<br>” %DDDD ” 是日；<br>支持模糊匹配：比如文件 /tmp/app.log.2019-01-30-00 和 /tmp/app.log.2019-01-30-01 这两个文件 ，只需要这么设置 gz_log=/tmp/app.log.%YYYY-%MMMM-%DDDD 即可自动将上述两个文件一同打入压缩包 /tmp/app.log.2019-01-30.tar.gz 。<br>（ 2 ）gz_delay_day 举例：</p> 
 <p>支持延迟压缩日志文件：有的开发可能需要查看最近几天的日志，压缩后就不容易直接查看了；为了方便开发查看最近几天的日志，那么每天就不能压缩昨天的日志了，而是每天压缩前天或者大前天的日志，这样开发就还可以查看昨天或者前天的日志。比如：gz_delay_day=1 表示压缩昨天的日志，gz_delay_day=2 表示压缩前天的日志，gz_delay_day=3 表示压缩大前天的日志。<br>和上述配置的取值范围：</p> 
 <p>gz_log ：该值可不配置且允许配置多次，日志文件路径必须是绝对路径，如果文件不存在会将错误信息写入到日志文件 log.log 并终止运行；<br>gz_delay_day ：该值可不配置且仅允许配置一次，取值范围是 x ≥ 1 ，默认值是 1 。<br>2 、现在打算对日志文件 /www/log/applog/www.test.com.log 进行压缩，此时 /www/log/ 的目录结构和 log.config 配置文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]# <br>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>gz_log=/www/log/applog/www.test.com.log<br>gz_delay_day=<br>[root@host ~]#<br>当前日志文件 /www/log/applog/www.test.com.log 的内容如下所示：</p> 
 <p>[root@host ~]# cat /www/log/applog/www.test.com.log<br>123<br>[root@host ~]#<br>执行完脚本以后会发现多出了一个压缩包 www.test.com.log.tar.gz ，同时原日志文件 www.test.com.log 已经被删除：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>├── www.test.com.log.tar.gz<br>└── www.test.net.log</p> 
 <p>2 directories, 6 files<br>[root@host ~]#<br>我们解压看看：</p> 
 <p>[root@host ~]# mkdir /tmp/log/<br>[root@host ~]# mv /www/log/applog/www.test.com.log.tar.gz /tmp/log/ <br>[root@host ~]# cd /tmp/log/<br>[root@host log]# tar zxf www.test.com.log.tar.gz <br>[root@host log]# ls<br>www.test.com.log www.test.com.log.tar.gz<br>[root@host log]# <br>[root@host log]# cat www.test.com.log<br>123<br>[root@host log]#<br>可以看到日志文件 www.test.com.log 就是原来那个。</p> 
 <p>3 、我们现在来看看自定义日期格式和模糊匹配的使用，现在我们要压缩：</p> 
 <p>/www/log/accesslog/www.test.net.log.20190128.00<br>/www/log/accesslog/www.test.net.log.20190128.01<br>/www/log/accesslog/www.test.net.log.20190128.02<br>这三个日志文件，此时 /www/log/ 的目录结构和 log.config 配置文件如下所示：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.net.log.20190128.00<br>│ ├── www.test.net.log.20190128.01<br>│ └── www.test.net.log.20190128.02<br>└── applog<br>└── www.test.net.log</p> 
 <p>2 directories, 5 files<br>[root@host ~]# <br>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>gz_log=/www/log/accesslog/www.test.net.log.%YYYY%MMMM%DDDD<br>gz_delay_day=3<br>[root@host ~]#<br>假设今天的日期是 2019 年 1 月 31 日，那么 30 日是昨天，29 日是前天，28 日是大前天，所以 gz_delay_day 的值为 3 。</p> 
 <p>执行完脚本以后会发现多出了一个压缩包 www.test.net.log.20190128.tar.gz ，同时三个日志文件已经被删除：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ └── www.test.net.log.20190128.tar.gz<br>└── applog<br>└── www.test.net.log</p> 
 <p>2 directories, 3 files<br>[root@host ~]#<br>我们同样解压出来看看：</p> 
 <p>[root@host ~]# mkdir /tmp/log_20190128/<br>[root@host ~]# mv /www/log/accesslog/www.test.net.log.20190128.tar.gz /tmp/log_20190128/<br>[root@host ~]# cd /tmp/log_20190128/<br>[root@host log_20190128]# tar zxf www.test.net.log.20190128.tar.gz <br>[root@host log_20190128]# ls<br>www.test.net.log.20190128.00 www.test.net.log.20190128.01 www.test.net.log.20190128.02 www.test.net.log.20190128.tar.gz<br>[root@host log_20190128]#<br>可以看到三个日志文件都在压缩包中。</p> 
 <p>4 、其他自定义日期格式的例子，假设有的程序已经能够每小时自动生成一个日志文件，例如：</p> 
 <p>/www/log/accesslog/www.test.net.log.2019-01-30-00<br>/www/log/accesslog/www.test.net.log.2019-01-30-01<br>/www/log/accesslog/www.test.net.log.2019-01-30-02<br>……<br>/www/log/accesslog/www.test.net.log.2019-01-30-23<br>那么只需要这么设置即可：</p> 
 <p>gz_log=/www/log/accesslog/www.test.net.log.%YYYY-%MMMM-%DDDD<br>这样，上述 24 个日志文件将会在 2019 年 1 月 31 日 0 点 0 分统一压缩进压缩包 www.test.net.log.2019-01-30.tar.gz ，然后再删除上述 24 个日志文件。</p> 
 <p>按天分割和压缩（延迟压缩）的功能是可以互相独立使用的；当然也可以结合起来使用，具体请看下方的 “ 综合应用 ” 。</p> 
 <p>综合应用：<br>现在有如下所示的四个日志文件：</p> 
 <p>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ └── www.test.com.log.20190129<br>└── applog<br>├── www.test.net.log<br>└── www.test.net.log.20190129</p> 
 <p>2 directories, 4 files<br>[root@host ~]#<br>现在的需求是：</p> 
 <p>（ 1 ）当 /www 的挂载点的可使用空间超过 50 % 时，自动删除 /www/log/ 目录下（包括子目录）文件名带有 tar.gz 字样的文件，以释放硬盘空间。</p> 
 <p>（ 2 ）假设今天的日期是 2019 年 1 月 30 日，当时间走到 2019 年 1 月 31 日 0 点 0 分时，需要对日志文件做一个分割：</p> 
 <p>/www/log/accesslog/www.test.com.log → /www/log/accesslog/www.test.com.log.20190130<br>/www/log/applog/www.test.net.log → /www/log/applog/www.test.net.log.20190130<br>（ 3 ）然后再对前天的日志文件进行一个压缩：</p> 
 <p>/www/log/accesslog/www.test.com.log.20190129 → /www/log/accesslog/www.test.com.log.20190129.tar.gz<br>/www/log/applog/www.test.net.log.20190129 → /www/log/applog/www.test.net.log.20190129.tar.gz<br>那么，log.config 配置文件只需要这么配置即可：</p> 
 <p>[root@host ~]# cat log.config<br>mount=/www<br>mount_used_size_percent=50</p> 
 <p>log_dir=/www/log<br>log_format_regex=.tar.gz</p> 
 <p>cut_log=/www/log/accesslog/www.test.com.log<br>cut_log=/www/log/applog/www.test.net.log</p> 
 <p>gz_log=/www/log/accesslog/www.test.com.log.%YYYY%MMMM%DDDD<br>gz_log=/www/log/applog/www.test.net.log.%YYYY%MMMM%DDDD<br>gz_delay_day=2<br>[root@host ~]#<br>执行脚本后，结果如下所示：</p> 
 <p>[root@host ~]# sh log.sh debug_mode=yes<br>debug_mode is enabled ! Do NOT use in production environment !<br>[root@host ~]# <br>[root@host ~]# tree /www/log/<br>/www/log/<br>├── accesslog<br>│ ├── www.test.com.log<br>│ ├── www.test.com.log.20190129.tar.gz<br>│ └── www.test.com.log.20190130<br>└── applog<br>├── www.test.net.log<br>├── www.test.net.log.20190129.tar.gz<br>└── www.test.net.log.20190130</p> 
 <p>2 directories, 6 files<br>[root@host ~]#<br>至此，该脚本介绍完毕。</p> 
 <p>附录：<br>1 、log.sh ：<br>#!/bin/bash</p> 
 <p>config_file="/root/log.config"<br>log_file="/root/log.log"<br>debug_mode="no"</p> 
 <p>for i in $* ; do<br>if [[ "$i" =~ "config_file=" ]] ; then<br>config_file=echo $i | awk -F'=' '{print $2}'<br>elif [[ "$i" =~ "log_file=" ]] ; then<br>log_file=echo $i | awk -F'=' '{print $2}'<br>elif [[ "$i" =~ "debug_mode=" ]] ; then<br>debug_mode=echo $i | awk -F'=' '{print $2}'<br>fi<br>done</p> 
 <p>if [ ! -f "$config_file" ] ; then<br>echo "config file ( $config_file ) not found !"<br>exit<br>fi</p> 
 <p>if [ ! -f "$log_file" ] ; then<br>echo "log file ( $log_file ) not found !"<br>exit<br>fi</p> 
 <p>if [ "$debug_mode" == "no" -a "date '+%H'" != "00" ] ; then<br>echo Please run the script at 0 a.m.<br>exit<br>elif [ "$debug_mode" != "no" ] ; then<br>debug_mode="yes"<br>echo debug_mode is enabled ! Do NOT use in production environment !<br>echo $(date "+%F %H:%M") - debug_mode is enabled ! Do NOT use in production environment ! &gt;&gt; $log_file<br>fi</p> 
 <p>#1. get mount<br>config_file_flag=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep -c "mount="<br>if [ $config_file_flag == 1 ] ; then<br>mount=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "mount=" | awk -F'=' '{print $2}'<br>elif [ $config_file_flag == 0 ] ; then<br>echo $(date "+%F %H:%M") - "mount parameter is not found !" &gt;&gt; $log_file<br>exit<br>else<br>echo $(date "+%F %H:%M") - "mount parameter is too many !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>if [ df -h | grep "$mount" | awk -F' ' '{print $5}' | awk -F'%' '{print $1}' | grep -c '^[[:digit:]]*$' == 0 ] ; then<br>echo $(date "+%F %H:%M") - "mount parameter is error !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>#2. get mount_used_size_percent<br>config_file_flag=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep -c "mount_used_size_percent="<br>if [ $config_file_flag == 1 ] ; then<br>mount_used_size_percent=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "mount_used_size_percent=" | awk -F'=' '{print $2}'<br>elif [ $config_file_flag == 0 ] ; then<br>echo $(date "+%F %H:%M") - "mount_used_size_percent parameter is not found !" &gt;&gt; $log_file<br>exit<br>else<br>echo $(date "+%F %H:%M") - "mount_used_size_percent parameter is too many !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>if [ echo $mount_used_size_percent | grep -c '^[[:digit:]]*$' == 0 ] ; then<br>echo $(date "+%F %H:%M") - "mount_used_size_percent parameter is not number !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>if [ $mount_used_size_percent -lt 50 ] ; then<br>echo $(date "+%F %H:%M") - "mount_used_size_percent parameter requires more than or equal to 50 !" &gt;&gt; $log_file<br>exit<br>elif [ $mount_used_size_percent -gt 85 ] ; then<br>echo $(date "+%F %H:%M") - "mount_used_size_percent parameter requires less than or equal to 85 !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>#3. get log_format_regex<br>config_file_flag=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep -c "log_format_regex="<br>if [ $config_file_flag == 1 ] ; then<br>log_format_regex=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "log_format_regex=" | awk -F'=' '{print $2}'<br>elif [ $config_file_flag == 0 ] ; then<br>echo $(date "+%F %H:%M") - "log_format_regex parameter is not found !" &gt;&gt; $log_file<br>exit<br>else<br>echo $(date "+%F %H:%M") - "log_format_regex parameter is too many !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>#4. get log_dir_list<br>config_file_flag=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep -c "log_dir="<br>if [ $config_file_flag -ge 1 ] ; then<br>log_dir_list=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "log_dir=" | awk -F'=' '{print $2}'<br>elif [ $config_file_flag == 0 ] ; then<br>echo $(date "+%F %H:%M") - "log_dir parameter is not found !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>for log_dir in $log_dir_list ; do<br>if [ ! -d "$log_dir" ] ; then<br>echo $(date "+%F %H:%M") - "log_dir $log_dir does not exist !" &gt;&gt; $log_file<br>exit<br>fi<br>done</p> 
 <p>#5. delete log file<br>while [ df -h | grep "$mount" | awk -F' ' '{print $5}' | awk -F'%' '{print $1}' -gt $mount_used_size_percent ] ; do<br>while_flag=""<br>for log_dir in $log_dir_list ; do<br>if [ find $log_dir -type f | grep -cE $log_format_regex -gt 0 ] ; then<br>find $log_dir -type f | grep -E $log_format_regex | xargs ls -ta | tail -1 | xargs rm -f<br>while_flag=$while_flag"1"<br>else<br>while_flag=$while_flag"0"<br>fi<br>done<br>if [ echo $while_flag | grep -c 1 == 0 ] ; then<br>echo $(date "+%F %H:%M") - "Delete all the log files is completed , but did not reach the $mount_used_size_percent % used precent !" &gt;&gt; $log_file<br>break<br>fi<br>done</p> 
 <p>#6. get cut_log_list<br>cut_log_list=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "cut_log=" | awk -F'=' '{print $2}'</p> 
 <p>for cut_log in $cut_log_list ; do<br>if [ ! -f "$cut_log" ] ; then<br>echo $(date "+%F %H:%M") - "cut_log $cut_log does not exist !" &gt;&gt; $log_file<br>exit<br>fi<br>done</p> 
 <p>#7. cut log<br>yesterday=$(date -d "$(date) -1 day" +%Y%m%d)<br>for cut_log in $cut_log_list ; do<br>cp $cut_log $cut_log.$yesterday &amp;&amp; echo &gt; $cut_log<br>done</p> 
 <p>#8. get gz_log_list<br>config_file_flag=cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep -c "gz_delay_day="<br>if [ $config_file_flag == 0 -o $config_file_flag == 1 ] ; then</p> 
 <pre><code>if [ $config_file_flag == 1 ] ; then
        gz_delay_day=`cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "gz_delay_day=" | awk -F'=' '{print $2}'`
elif [ $config_file_flag == 0 ] ; then
        gz_delay_day=1
fi

if [ `echo $gz_delay_day | grep -c '^[[:digit:]]*$'` == 0 ] ; then
        echo $(date "+%F %H:%M") - "gz_delay_day parameter is not number !" &gt;&gt; $log_file
        exit
fi

if [ $gz_delay_day -lt 1 ] ; then
        echo $(date "+%F %H:%M") - "gz_delay_day parameter requires more than or equal to 1 !" &gt;&gt; $log_file
        exit
fi

gz_log_list=`cat $config_file | grep -v "#" | sed "s# ##g" | grep -vE "=$" | grep "gz_log=" | awk -F'=' '{print $2}'`
date_year=`date -d "$(date) - ${gz_delay_day} day" +%Y`
date_month=`date -d "$(date) - ${gz_delay_day} day" +%m`
date_day=`date -d "$(date) - ${gz_delay_day} day" +%d`

for gz_log in $gz_log_list ; do
        gz_log=`echo $gz_log | sed "s#%YYYY#$date_year#g" | sed "s#%MMMM#$date_month#g" | sed "s#%DDDD#$date_day#g"`
        if [ `ls "$gz_log"* | grep -v "${gz_log}.tar.gz" 2&gt;/dev/null | wc -l` == 0 ] ; then
                echo $(date "+%F %H:%M") - "gz_log $gz_log does not exist !" &gt;&gt; $log_file
                exit
        fi
done</code></pre> 
 <p>elif [ $config_file_flag -gt 1 ] ; then<br>echo $(date "+%F %H:%M") - "gz_delay_day parameter is too many !" &gt;&gt; $log_file<br>exit<br>fi</p> 
 <p>#9. gz log<br>echo $(date "+%F %H:%M") - "=== gz log ===" &gt;&gt; $log_file<br>for gz_log in $gz_log_list ; do<br>gz_log=echo $gz_log | sed "s#%YYYY#$date_year#g" | sed "s#%MMMM#$date_month#g" | sed "s#%DDDD#$date_day#g"<br>cd dirname ${gz_log}<br>echo dirname ${gz_log}" :" &gt;&gt; $log_file<br>log_filename=basename ${gz_log}<br>tar zcvf ${log_filename}.tar.gz --exclude=.tar.gz ${log_filename} &gt;&gt; $log_file<br>ls ${log_filename}* | grep -v "${log_filename}.tar.gz" | xargs rm -f<br>done<br>echo "===========================" &gt;&gt; $log_file<br>2 、log.config ：</p> 
 <p>mount：设置日志文件所在的挂载点，如：mount=/www ，具体挂载点请用 df -h 命令查看。<br>mount 取值范围：该值必须配置且仅允许配置一次。<br>mount_used_size_percent：设置该挂载点最多可以使用多少空间，单位是百分比。<br>mount_used_size_percent 取值范围：该值必须配置且仅允许配置一次，取值范围在 50 ≤ x ≤ 85 之间。<br>mount=<br>mount_used_size_percent=</p> 
 <p>log_dir：设置日志文件所在的文件夹，如：log_dir=/www/accesslog ，用于自动清理日志文件（从文件修改时间是最旧的日志文件开始删除，包括子文件夹下的日志文件），<br>直到上述挂载点的可使用空间最多不超过 mount_used_size_percent 这个百分比为止（除非日志文件已经全部删除完毕）。<br>log_dir 取值范围：该值必须配置且允许配置多次，如果文件夹不存在会将错误信息写入到日志文件 log.log 并终止运行。<br>允许设置多条，如：<br>log_dir=/www/accesslog<br>log_dir=/www/applog<br>log_dir=</p> 
 <p>log_format_regex：是一串正则表达式，用于自定义待删除的日志文件格式，防止误删除。<br>log_format_regex 取值范围：该值必须配置且仅允许配置一次。<br>1 、如待删除的日志文件均为压缩格式，则这么配置即可（其中 ” \ ” 是转义字符，” | ” 是 ” 或 ” ）：<br>log_format_regex=(.tar|.gz|.tar.gz|.bz2|.tar.bz2|.bz|.tar.bz|.Z|.tar.Z|.tgz|.tar.tgz|.zip|.lha|.rar)$ ；<br>2 、注意：请不要把 .log 这个关键字写入进去，因为很多正在写入的日志文件都是以 xxx.log 命名的，这些文件是不能匹配到并删除的。<br>log_format_regex=</p> 
 <p>cut_log：设置需要进行按天分割的日志文件的文件路径。<br>cut_log 的取值范围：该值可不配置且允许配置多次，日志文件路径必须是绝对路径，如果文件不存在会将错误信息写入到日志文件 log.log 并终止运行。<br>1 、比如：cut_log=/www/accesslog/www.test.com/access.log ，假设今天的日期是 2019 年 1 月 29 日，那么到了 2019 年 1 月 30 日凌晨 0 点 0 分会分卷一份 access.log.20190129 出来。<br>2 、允许设置多条，如：<br>cut_log=/www/accesslog/www.test.com/access.log<br>cut_log=/www/accesslog/www.test.net/access.log<br>3 、也可以不设置，如：<br>cut_log=<br>cut_log=</p> 
 <p>gz_log：设置需要进行压缩的日志文件（支持自定义日期格式和模糊匹配）的文件路径。<br>gz_log 的取值范围：该值可不配置且允许配置多次，日志文件路径必须是绝对路径，如果文件不存在会将错误信息写入到日志文件 log.log 并终止运行。<br>1 、支持自定义日期格式，其中：<br>" %YYYY " 是年<br>" %MMMM " 是月<br>" %DDDD " 是日<br>2 、支持模糊匹配：<br>比如文件 /tmp/app.log.2019-01-30-00 和 /tmp/app.log.2019-01-30-01 这两个文件 ，<br>只需要这么设置 gz_log=/tmp/app.log.%YYYY-%MMMM-%DDDD 即可自动将上述两个文件一同打入压缩包 /tmp/app.log.2019-01-30.tar.gz 。<br>gz_delay_day：设置延迟压缩的天数。<br>gz_delay_day 的取值范围：该值可不配置且仅允许配置一次，取值范围是 x ≥ 1 ，默认值是 1 。<br>1 、支持延迟压缩日志文件：有的开发可能需要查看最近几天的日志，压缩后就不容易直接查看了；<br>为了方便开发查看最近几天的日志，那么每天就不能压缩昨天的日志了，而是每天压缩前天或者大前天的日志，这样开发就还可以查看昨天或者前天的日志。<br>比如：gz_delay_day=1 表示压缩昨天的日志，gz_delay_day=2 表示压缩前天的日志，gz_delay_day=3 表示压缩大前天的日志。<br>gz_log=<br>gz_delay_day=</p> 
</div> 
<p>转载于:https://blog.51cto.com/hgh1882928/2354851</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ad987d5f084db27bf963833abfae581b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">三星soc平台Exynos4412介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/40b5b00eab49e9f8f2e2eba7c060e476/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C盘满了清理c盘</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>