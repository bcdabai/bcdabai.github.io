<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MicroPhoneInput 自动判定音源录入&#43;百度音频录入的问题 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="MicroPhoneInput 自动判定音源录入&#43;百度音频录入的问题" />
<meta property="og:description" content="需求：
进入音频录制状态，麦克风一直处于打开（录制状态）； 只有当真实收到外部音源时（比如有人说话）；才开始将这段音频作为真实录制的音频； 当没人说话2s，就截取这段音频作为有效音频发布出去。
（模仿实时流音频的发送）
1. 百度语音翻译和语音控制。
要求是一段音频流传上去进行处理，这个时候麦克风处于打开，不需要用户去点按钮录制；自动判定有效音频发送。
2.这里就需要用到 Microphone.GetPosition 来做判断
源码如下：
using System;
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.UI;
using System.Linq;
using System.IO;
namespace nn
{
public class testdemo : MonoBehaviour
{
private enum AudioRecordResultState { start, stop }
[SerializeField] private int maxClipLength = 300;
[HideInInspector] public bool isRecording = false;
private const int RECORD_TIME = 300;//最长录制5分钟
private const int ClearAudioTime = 10;//每隔10秒清空1个无效数据；就是没有音源记录的数据
private AudioClip recordedClip;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/33b4cd5db9c12f8c77e5135e3c11db64/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-09T19:19:24+08:00" />
<meta property="article:modified_time" content="2019-08-09T19:19:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MicroPhoneInput 自动判定音源录入&#43;百度音频录入的问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>需求：</p> 
<p>      进入音频录制状态，麦克风一直处于打开（录制状态）； 只有当真实收到外部音源时（比如有人说话）；才开始将这段音频作为真实录制的音频； 当没人说话2s，就截取这段音频作为有效音频发布出去。</p> 
<p>（模仿实时流音频的发送）</p> 
<p>1. 百度语音翻译和语音控制。</p> 
<p>  要求是一段音频流传上去进行处理，这个时候麦克风处于打开，不需要用户去点按钮录制；自动判定有效音频发送。</p> 
<p>2.这里就需要用到 Microphone.GetPosition 来做判断</p> 
<p>源码如下：</p> 
<blockquote> 
 <p>using System;<br> using System.Collections;<br> using System.Collections.Generic;<br> using UnityEngine;<br> using UnityEngine.UI;<br> using System.Linq;<br> using System.IO;</p> 
 <p>namespace nn<br> {<!-- --><br>     public class testdemo : MonoBehaviour<br>     {<!-- --><br>         private enum AudioRecordResultState { start, stop }<br>         [SerializeField] private int maxClipLength = 300;<br>         [HideInInspector] public bool isRecording = false;</p> 
 <p><br>         private const int RECORD_TIME = 300;//最长录制5分钟</p> 
 <p>        private const int ClearAudioTime = 10;//每隔10秒清空1个无效数据；就是没有音源记录的数据</p> 
 <p>        private AudioClip recordedClip;<br>         private int _sampleWindow = 128;<br>         private float recordTimer = 0.0f;</p> 
 <p>        private static string[] micArray;</p> 
 <p>        private float limateAudioLevel = 0.1f;<br>         /// &lt;summary&gt;<br>         /// 当前有记录真实人音了<br>         /// &lt;/summary&gt;<br>         private bool CurrentHaveRecordRealAudio = false;</p> 
 <p>        private AudioRecordResultState currentTyp = AudioRecordResultState.stop;</p> 
 <p>        private float disTime = 0;</p> 
 <p>        private int startsimple = 0;<br>         private float noAudiodisTime = 0;<br>         void Start()<br>         {<!-- --><br>             micArray = Microphone.devices;<br>             // Type[] allType = GetHotfixTypes();</p> 
 <p>            // BlockBaseDataTypeList = allType.Where(type =&gt; !type.IsAbstract).Where(type =&gt; typeof(MonoBehaviour) == type.BaseType).ToList();</p> 
 <p>            // Debug.LogError(allType.Length+"   "+BlockBaseDataTypeList.Count);</p> 
 <p>            Play();<br>         }<br>         public void Play()<br>         {<!-- --><br>             Debug.LogError("@@@@@@");<br>             if (micArray.Length == 0)<br>             {<!-- --><br>                 Debug.Log("No Record Device!");<br>                 return;<br>             }<br>             noAudiodisTime = Time.time + ClearAudioTime;<br>             CurrentHaveRecordRealAudio = false;<br>             if (recordedClip != null)<br>             {<!-- --><br>                 Microphone.End(null);<br>                 DestroyImmediate(recordedClip);<br>                 recordedClip = null;<br>             }</p> 
 <p>            recordedClip = Microphone.Start(null, false, RECORD_TIME, 16000 ); //44100<br>             float a = Microphone.GetPosition(null);<br>             while (!(Microphone.GetPosition(null) &gt; 0))<br>             {<!-- --><br>             }</p> 
 <p>            currentTyp = AudioRecordResultState.start;<br>             Debug.Log("StartRecord");<br>         }</p> 
 <p>        public void Stop() {<!-- --></p> 
 <p>            currentTyp = AudioRecordResultState.stop;<br>         }</p> 
 <p>        public Type[] GetHotfixTypes()<br>         {<!-- --><br>            <br>             foreach(var a in AppDomain.CurrentDomain.GetAssemblies())<br>             {<!-- --><br>                 Debug.LogError(a.FullName);<br>             }<br>             return null;</p> 
 <p>        }<br>         void Update()<br>         {<!-- --><br>             if (currentTyp == AudioRecordResultState.start)<br>             {<!-- --><br>                 float value = GetLevelMax();<br>                // Debug.LogError(value);<br>                 if (value &gt;= limateAudioLevel)<br>                 {<!-- --><br>                     disTime = Time.time + 2;</p> 
 <p>                    if (!CurrentHaveRecordRealAudio)<br>                     {<!-- --><br>                         Debug.LogError("!!!!!!!!!!!!!!$$$   "+ value);<br>                         startsimple = Microphone.GetPosition(null)-1;<br>                         startsimple = Mathf.Max(0, startsimple);<br>                         CurrentHaveRecordRealAudio = true;<br>                     }<br>                 }</p> 
 <p><br>                 if (CurrentHaveRecordRealAudio)<br>                 {<!-- --><br>                     if (value &lt; limateAudioLevel &amp;&amp; Time.time&gt;= disTime) {<!-- --><br>                         Debug.LogError("!!!!!!!!!!!!!!!!!!!!11111122222");<br>                         //todo sendAudio<br>                         SendAudio();<br>                     }<br>                  <br>                 }<br>                 else<br>                 {<!-- --><br>                     if (recordedClip != null&amp;&amp; Time.time&gt;= noAudiodisTime) {<!-- --><br>                         Debug.LogError(recordedClip.length+"!!!!!!!!!!!!!!!^^ "+ ClearAudioTime);<br>                         Play();<br>                     }<br>                    <br>                 }<br>             }<br>         }</p> 
 <p>        public void SendAudio() {<!-- --></p> 
 <p>            CurrentHaveRecordRealAudio = false;<br>             disTime = Time.time + 2;<br>             int endPoint = Microphone.GetPosition(null);<br>             var samples = new float[endPoint- startsimple];</p> 
 <p>            recordedClip.GetData(samples, startsimple);</p> 
 <p>            var newrecordedClip = AudioClip.Create(recordedClip.name,<br>                                    (endPoint - startsimple),<br>                                    recordedClip.channels,<br>                                    recordedClip.frequency,<br>                                    false);</p> 
 <p>            newrecordedClip.SetData(samples, 0);</p> 
 <p>            string file;<br>             var data = WavUtility.FromAudioClip(newrecordedClip, out file, true);<br>             Destroy(newrecordedClip);<br>         }</p> 
 <p><br>         /// &lt;summary&gt;<br>         /// 获取麦克风音量<br>         /// &lt;/summary&gt;<br>         /// &lt;returns&gt;&lt;/returns&gt;<br>         public float GetLevelMax()<br>         {<!-- --><br>             float levelMax = 0;<br>             float[] waveData = new float[_sampleWindow];<br>             int micPosition = Microphone.GetPosition(null) - (_sampleWindow + 1); // null means the first microphone<br>             if (micPosition &lt; 0) return 0;<br>             recordedClip.GetData(waveData, micPosition);</p> 
 <p>            // Getting a peak on the last 128 samples<br>             for (int i = 0; i &lt; _sampleWindow; i++)<br>             {<!-- --><br>                 float wavePeak = waveData[i] * waveData[i];<br>                 if (levelMax &lt; wavePeak)<br>                 {<!-- --><br>                     levelMax = wavePeak;<br>                 }<br>             }<br>             return levelMax;<br>         }</p> 
 <p>    }<br> }</p> 
</blockquote> 
<p> </p> 
<p>百度语音上传的注意事项：</p> 
<p>  麦克风需要16K录制  即 16000 ；而不是通常的44100；否则报音频质量差的问题</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4ecead405640579d5b3a7176ba5c55d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">pikachu靶场之SQL注入</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5d0c5e69e8b60f0660812ad83c5bee15/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">深度学习PyTorch（三）循环神经网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>