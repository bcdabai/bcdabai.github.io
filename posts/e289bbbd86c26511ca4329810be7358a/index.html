<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>电商API接口|爬虫案例|采集某东商品评论信息 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="电商API接口|爬虫案例|采集某东商品评论信息" />
<meta property="og:description" content="前言：
平常大家都有网上购物的习惯，在商品下面卖的好的产品基本都会有评论，当然也不排除有刷评论的情况，因为评论会影响我们的购物决策。今天主要分享用python&#43;re正则表达式获取京东商品评论。API接口获取京东平台商品详情SKU数据！
环境准备：
pyhon编译器版本python3.7.4
集成开发环境(IDE)pycharm版本2020.1.5
相关包的安装
pip install requests
整体框架：
分析商品评论网页
发送请求，获取响应内容
re正则表达式提取信息
pandas保存信息
运行主程序
总结
分析网页
打开京东官网，我搜的是电脑，因为是获取商品的评论，我选了评论数比较多的产品，然后可以在下方可以看到商品的评论。
接下来就是按F12，选择网页。然后点击第二页刷新网页。在往下拉的过程中可以看到有个productPageComments.......页面，点击然后看下预览。下方就可以看到评论信息comments，依次点开后查看第一个信息，网页往上拉返回可以看到网页的信息和我们要查看的信息一致。
正是我们需要找的信息，这里注意的是因为选择第二页刷新的信息，如果第一页刷新过，也有第一页的网页productPageComments,如何去辨别呢。我们可以看下参数信息，也就是查看载荷。
看下参数下面有个page：1。注意刷新的页面还是第二页。这个很容易判断是第一页。我们先滚动页面，继续找到productPageComments,然后可以看到载荷下面的参数page:0
也就是页面的规律是从0开始的，我们可以再验证一下，选择第三页刷新看载荷下方的参数，顺便看下参数是否有加密。
第三页可以发现page:2,说明页面就是从0开始的，然后看下其他的参数基本不变，没有出现加密的情况，变化的主要page。这就是我们要找的网页页面规律。
然后需要看下响应的内容，继续回到预览，可以看到一页有10条评论，初步判断格式比较像json格式，json格式的数据和python数据结构的字典比较类似，这里面涉及python的基本语法，不在这赘述。
2.发送请求，获取响应内容
首先看下标头信息
我们需要了解基本的请求网址，请求方法，状态码。
请求方法是get，后面就可以通过get方法向网页发送请求，有些网页是post。状态码是200,说明请求是ok的，如果遇到其他状态码，说明请求不成功，比如304，503。具体的状态码不在这赘述，可以网上查资料了解。不妨借助下ChatGPT的回答
ChatGPT的回答还是比较详细，给它点个赞
另外需要看的是请求标头下方的信息，比如cookie,user_agent。
cookie是用来存储用户信息，服务器会去识别用户的信息。一般请求头需要带上cookie来做浏览器的伪装。下面看下百科的解释
然后对比下ChatGPT的回答
user_agent（用户代理）是电脑的基本信息，电脑系统的版本，用的浏览器版本等，一般也是用来做浏览器的伪装。
然后看下ChatGPT对User_agent的解释
接下来看下具体的请求代码
注释：定义函数获取响应内容，带上请求头信息，用requests 和get方法发送请求，text就是响应的内容。
3.re正则表达式提取信息
re(regular expression)正则表达式的作用是精确匹配网页的信息，提取关键信息，功能也是比较强大，比如提取用来数字包括小数，整数等,还可以用来提取邮箱，身份证信息等。
下面看下ChatGPT回答
具体也可查阅其他资料详细了解其用法。
re提取信息的关键代码如下：
4.用pandas来保存信息。
相关代码如下
定义函数 参数是data,下面是字段名称，用pandas构造DataFrame保存到excel表格中。
5.运行主程序
考虑到程序的性能和评论的时效性，本次采集前50页信息，用for循环遍历每一页的url，然后批量获取每一页的信息。
相关代码如下
运行结果部分数据展示：
总共获取500条评论。
完整代码：
import requests import re import json import pandas as pd # 基本url BASE_URL = &#34;https://club.jd.com/comment/productPageComments.action?
callback=fetchJSON_comment98&amp;productId=100035712310&amp;score=0&amp;sortType=5" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/e289bbbd86c26511ca4329810be7358a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-26T09:07:08+08:00" />
<meta property="article:modified_time" content="2024-01-26T09:07:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">电商API接口|爬虫案例|采集某东商品评论信息</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="activity-name"></h2> 
<p><strong>前言</strong>：</p> 
<p>平常大家都有网上购物的习惯，在商品下面卖的好的产品基本都会有评论，当然也不排除有刷评论的情况，因为评论会影响我们的购物决策。今天主要分享用python+re正则表达式获取京东商品评论。<a class="link-info" href="http://o0b.cn/tinale" rel="nofollow" title="API接口获取京东平台商品详情">API接口获取京东平台商品详情</a>SKU数据！</p> 
<p><strong>环境准备</strong>：</p> 
<p>pyhon编译器版本python3.7.4</p> 
<p>集成开发环境(IDE)pycharm版本2020.1.5</p> 
<p>相关包的安装</p> 
<p>pip install requests</p> 
<p><strong>整体框架</strong>：</p> 
<ul><li> <p>分析商品评论网页</p> </li><li> <p>发送请求，获取响应内容</p> </li><li> <p>re正则表达式提取信息</p> </li><li> <p>pandas保存信息</p> </li><li> <p>运行主程序</p> </li><li> <p>总结</p> <p></p> <p></p> </li></ul> 
<ol><li> <p><strong>分析网页</strong></p> </li></ol> 
<p>打开京东官网，我搜的是电脑，因为是获取商品的评论，我选了评论数比较多的产品，然后可以在下方可以看到商品的评论。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="629" src="https://images2.imgbox.com/ca/1c/LiJdTOKq_o.png" width="1080"></p> 
<p>接下来就是按F12，选择网页。然后点击第二页刷新网页。在往下拉的过程中可以看到有个productPageComments.......页面，点击然后看下预览。下方就可以看到评论信息comments，依次点开后查看第一个信息，网页往上拉返回可以看到网页的信息和我们要查看的信息一致。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="490" src="https://images2.imgbox.com/5e/27/4Jk1XHVJ_o.png" width="1080"></p> 
<p>正是我们需要找的信息，这里注意的是因为选择第二页刷新的信息，如果第一页刷新过，也有第一页的网页productPageComments,如何去辨别呢。我们可以看下参数信息，也就是查看载荷。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="523" src="https://images2.imgbox.com/a9/72/YRxBKjDC_o.png" width="1080"></p> 
<p>看下参数下面有个page：1。注意刷新的页面还是第二页。这个很容易判断是第一页。我们先滚动页面，继续找到productPageComments,然后可以看到载荷下面的参数page:0</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="507" src="https://images2.imgbox.com/dc/8b/CdWtTlNr_o.png" width="1080"></p> 
<p>也就是页面的规律是从0开始的，我们可以再验证一下，选择第三页刷新看载荷下方的参数，顺便看下参数是否有加密。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="493" src="https://images2.imgbox.com/8d/08/LZCQZAxK_o.png" width="1080"></p> 
<p>第三页可以发现page:2,说明页面就是从0开始的，然后看下其他的参数基本不变，没有出现加密的情况，变化的主要page。这就是我们要找的网页页面规律。</p> 
<p>然后需要看下响应的内容，继续回到预览，可以看到一页有10条评论，初步判断格式比较像json格式，json格式的数据和python数据结构的字典比较类似，这里面涉及python的基本语法，不在这赘述。</p> 
<p><strong>2.发送请求，获取响应内容</strong></p> 
<p>首先看下标头信息</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="603" src="https://images2.imgbox.com/86/78/QUuNxjMV_o.png" width="1052"></p> 
<p>我们需要了解基本的请求网址，请求方法，状态码。</p> 
<p>请求方法是get，后面就可以通过get方法向网页发送请求，有些网页是post。状态码是200,说明请求是ok的，如果遇到其他状态码，说明请求不成功，比如304，503。具体的状态码不在这赘述，可以网上查资料了解。不妨借助下ChatGPT的回答</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="344" src="https://images2.imgbox.com/0e/e3/clGAhpm0_o.png" width="873"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="346" src="https://images2.imgbox.com/31/52/fZhl85Ql_o.png" width="793"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="349" src="https://images2.imgbox.com/9f/86/cKBpasJO_o.png" width="810"></p> 
<p>ChatGPT的回答还是比较详细，给它点个赞</p> 
<p class="img-center"><img alt="图片" height="128" src="https://images2.imgbox.com/27/e9/fmZ325gi_o.png" width="128"></p> 
<p>另外需要看的是请求标头下方的信息，比如cookie,user_agent。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="609" src="https://images2.imgbox.com/33/67/btnRNxdx_o.png" width="919"></p> 
<p>cookie是用来存储用户信息，服务器会去识别用户的信息。一般请求头需要带上cookie来做浏览器的伪装。下面看下百科的解释</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="120" src="https://images2.imgbox.com/f1/df/njizJX1m_o.png" width="833"></p> 
<p>然后对比下ChatGPT的回答</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="460" src="https://images2.imgbox.com/dd/5b/SE9NNi45_o.png" width="856"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="489" src="https://images2.imgbox.com/49/1d/MMB2q3Eu_o.png" width="1080"></p> 
<p>user_agent（用户代理）是电脑的基本信息，电脑系统的版本，用的浏览器版本等，一般也是用来做浏览器的伪装。</p> 
<p>然后看下ChatGPT对User_agent的解释</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="248" src="https://images2.imgbox.com/95/52/PjsfFnns_o.png" width="822"></p> 
<p>接下来看下具体的请求代码</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="391" src="https://images2.imgbox.com/34/c9/oDjBveTp_o.png" width="685"></p> 
<p>注释：定义函数获取响应内容，带上请求头信息，用requests 和get方法发送请求，text就是响应的内容。</p> 
<p><strong>3.re正则表达式提取信息</strong></p> 
<p>re(regular expression)正则表达式的作用是精确匹配网页的信息，提取关键信息，功能也是比较强大，比如提取用来数字包括小数，整数等,还可以用来提取邮箱，身份证信息等。</p> 
<p>下面看下ChatGPT回答</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="352" src="https://images2.imgbox.com/9e/4d/U3GgthtO_o.png" width="804"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="390" src="https://images2.imgbox.com/67/d9/jDVYT5Cy_o.png" width="734"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="432" src="https://images2.imgbox.com/9d/46/LNm2hMZ7_o.png" width="743"></p> 
<p>具体也可查阅其他资料详细了解其用法。</p> 
<p>re提取信息的关键代码如下：</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="496" src="https://images2.imgbox.com/cc/ed/Ls2DFGY0_o.png" width="685"></p> 
<p><strong>4.用pandas来保存信息。</strong></p> 
<p>相关代码如下</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="220" src="https://images2.imgbox.com/9b/8a/SeGumdos_o.png" width="682"></p> 
<p>定义函数 参数是data,下面是字段名称，用pandas构造DataFrame保存到excel表格中。</p> 
<p><strong>5.运行主程序</strong></p> 
<p>考虑到程序的性能和评论的时效性，本次采集前50页信息，用for循环遍历每一页的url，然后批量获取每一页的信息。</p> 
<p>相关代码如下</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="274" src="https://images2.imgbox.com/36/c3/tMujy4wV_o.png" width="672"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="320" src="https://images2.imgbox.com/d7/c8/yFnidPkV_o.png" width="683"></p> 
<p>运行结果部分数据展示：</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="408" src="https://images2.imgbox.com/c1/0e/sXQwkzTO_o.png" width="1080"></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="394" src="https://images2.imgbox.com/a7/0f/GPUO62iu_o.png" width="1080"></p> 
<p>总共获取500条评论。</p> 
<p>完整代码：</p> 
<pre>import requests
import re
import json
import pandas as pd
# 基本url
</pre> 
<p>BASE_URL = "https://club.jd.com/comment/productPageComments.action?</p> 
<p>callback=fetchJSON_comment98&amp;productId=100035712310&amp;score=0&amp;sortType=5</p> 
<p>&amp;page={}&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</p> 
<p># 定义函数访问页面<br> def scrape_url(n):<br> url = BASE_URL.format(n)<br> return url<br><br> def get_reviews_html(url):<br> # 请求头<br> headers = {<!-- --><br> 'cookie': '__jdu=1659013711311387516036; shshshfpa=96b8fa44-7940-4a82-dc6b-ae9ec11053d8-1671423464; shshshfpb=l3JPGq-Nsv3ryl-UYczuTVg; unpl=JF8EAMhnNSttXEhSBh0LG0IZTlsBW11YGx4LbDAHBllbHANXEwFIFBl7XlVdXxRKFB9sYxRUXVNLVA4ZBisSEXteXVdZDEsWC2tXVgQFDQ8VXURJQlZAFDNVCV9dSRZRZjJWBFtdT1xWSAYYRRMfDlAKDlhCR1FpMjVkXlh7VAQrAhwWGEpdVlhdCEkXA21uA1BdX0pWAisDKxUge21WWVwPSRYzblcEZB8MF1cBHwEZF11LWlBWXAhJEQNvZQVUX1FNUAUcAxkVIEptVw; __jdv=76161171|baidu-pinzhuan|t_288551095_baidupinzhuan|cpc|0f3d30c8dba7459bb52f2eb5eba8ac7d_0_5272781a847d41aa892f3c52ffc92b78|1677294929187; areaId=19; PCSYCityID=CN_440000_440300_0; shshshfpx=96b8fa44-7940-4a82-dc6b-ae9ec11053d8-1671423464; shshshfp=edea99a27fbc1b9e7a0a677bc566df49; __jdc=122270672; ip_cityCode=1601; ipLoc-djd=19-1607-4773-62121; jwotest_product=99; 3AB9D23F7A4B3C9B=JLXTWBOH4BNFVY37YNSE4B6N2OLXI7T6WIX336O237ZEYUEAF4RFRCLPN3AEBN5FK556TM2FSRQABIGENHAVETWTGA; jsavif=1; __jda=122270672.1659013711311387516036.1659013711.1677312527.1677330268.7; __jdb=122270672.1.1659013711311387516036|7.1677330268; shshshsID=426d0c1911285cc51524a751262039de_1_1677330269246; JSESSIONID=85D1CE4A20581F98C688EA0EFE2CB175.s1',<br> 'referer': 'https://item.jd.com/',<br> 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',<br> }<br> # 发送请求<br> response = requests.get(url=url,headers=headers)<br> # 获取响应内容<br> result = response.text<br> print(result)<br> return result<br> # 创建空列表，用来存放信息<br> data = []<br> def get_goods_contents(result):<br> # 提取评论内容<br> content = re.findall('"guid".*?"content":"(.*?)"',result)<br> # print(content)<br> # 提取产品尺寸<br> productSize = re.findall('productColor":"(.*?)"',result)<br> # print(productSize)<br> # 提取产品配置<br> productConfig = re.findall('"productSize":"(.*?)"',result)<br> # print(productConfig)<br> # 提取评论创建时间<br> creationTime = re.findall('"creationTime":"(.*?)"',result)<br> # 用for 循环批次把信息储存到data<br> for i in range(len(productSize)):<br> data.append([productSize[i],creationTime[i],productConfig[i],content[i]])<br> # print(data)<br> return data<br> def save_reviews(data):<br> columns = ['产品尺寸','评论时间','产品配置','产品评论']<br> df = pd.DataFrame(data,columns=columns)<br> df.to_excel('电脑评论.xlsx',encoding='utf-8')<br> # 运行主程序<br> if __name__=='__main__':<br> for i in range(0,50):<br> # 调用函数依次访问页面<br> url =scrape_url(n=i)<br> # 调用函数获取响应内容<br> result = get_reviews_html(url)<br> # 调用函数获取数据<br> data = get_goods_contents(result)<br> # 调用函数保存信息</p> 
<p>save_reviews(data)</p> 
<p></p> 
<p></p> 
<p></p> 
<p><strong>总结：</strong></p> 
<ol><li> <p>本次主要实战采集京东商品电脑商品信息评论，其他商品换关键词就可以。</p> </li><li> <p>文章借助了ChatGPT对一些概念做了一些解释，比如cookie，表达式。加深对基本概念的理解与运用。</p> </li><li> <p>这些评论如何清洗分析，去挖掘其中的商业价值？</p> </li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/10dddb463b86ee3f355cd344169e7111/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数字孪生系统的难点</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2592a9506f4d77e0a407096e3fdfdcb3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">三.逻辑架构</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>