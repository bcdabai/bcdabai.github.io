<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>å¤§åˆ›é¡¹ç›®æ¨è é¢˜ç›®ï¼šåƒåœ¾é‚®ä»¶(çŸ­ä¿¡)åˆ†ç±» ç®—æ³•å®ç° æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹  å¼€é¢˜ - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="å¤§åˆ›é¡¹ç›®æ¨è é¢˜ç›®ï¼šåƒåœ¾é‚®ä»¶(çŸ­ä¿¡)åˆ†ç±» ç®—æ³•å®ç° æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹  å¼€é¢˜" />
<meta property="og:description" content="æ–‡ç« ç›®å½• 1 å‰è¨€2 åƒåœ¾çŸ­ä¿¡/é‚®ä»¶ åˆ†ç±»ç®—æ³• åŸç†2.1 å¸¸ç”¨çš„åˆ†ç±»å™¨ - è´å¶æ–¯åˆ†ç±»å™¨ 3 æ•°æ®é›†ä»‹ç»4 æ•°æ®é¢„å¤„ç†5 ç‰¹å¾æå–6 è®­ç»ƒåˆ†ç±»å™¨7 ç»¼åˆæµ‹è¯•ç»“æœ8 å…¶ä»–æ¨¡å‹æ–¹æ³•9 æœ€å 1 å‰è¨€ ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯
åŸºäºæœºå™¨å­¦ä¹ çš„åƒåœ¾é‚®ä»¶åˆ†ç±»
è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼
ğŸ§¿ æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š
https://gitee.com/dancheng-senior/postgraduate
2 åƒåœ¾çŸ­ä¿¡/é‚®ä»¶ åˆ†ç±»ç®—æ³• åŸç† åƒåœ¾é‚®ä»¶å†…å®¹å¾€å¾€æ˜¯å¹¿å‘Šæˆ–è€…è™šå‡ä¿¡æ¯ï¼Œç”šè‡³æ˜¯ç”µè„‘ç—…æ¯’ã€æƒ…è‰²ã€ååŠ¨ç­‰ä¸è‰¯ä¿¡æ¯ï¼Œå¤§é‡åƒåœ¾é‚®ä»¶çš„å­˜åœ¨ä¸ä»…ä¼šç»™äººä»¬å¸¦æ¥å›°æ‰°ï¼Œè¿˜ä¼šé€ æˆç½‘ç»œèµ„æºçš„æµªè´¹ï¼›
ç½‘ç»œèˆ†æƒ…æ˜¯ç¤¾ä¼šèˆ†æƒ…çš„ä¸€ç§è¡¨ç°å½¢å¼ï¼Œç½‘ç»œèˆ†æƒ…å…·æœ‰å½¢æˆè¿…é€Ÿã€å½±å“åŠ›å¤§å’Œç»„ç»‡å‘åŠ¨ä¼˜åŠ¿å¼ºç­‰ç‰¹ç‚¹ï¼Œç½‘ç»œèˆ†æƒ…çš„å¥½åæå¤§åœ°å½±å“ç€ç¤¾ä¼šçš„ç¨³å®šï¼Œé€šè¿‡æé«˜èˆ†æƒ…åˆ†æèƒ½åŠ›æœ‰æ•ˆè·å–å‘å¸ƒèˆ†è®ºçš„æ€§è´¨ï¼Œé¿å…è´Ÿé¢èˆ†è®ºçš„ä¸è‰¯å½±å“æ˜¯äº’è”ç½‘é¢ä¸´çš„ä¸¥è‚ƒè¯¾é¢˜ã€‚
å°†é‚®ä»¶åˆ†ä¸ºåƒåœ¾é‚®ä»¶(æœ‰å®³ä¿¡æ¯)å’Œæ­£å¸¸é‚®ä»¶ï¼Œç½‘ç»œèˆ†è®ºåˆ†ä¸ºè´Ÿé¢èˆ†è®º(æœ‰å®³ä¿¡æ¯)å’Œæ­£é¢èˆ†è®ºï¼Œé‚£ä¹ˆï¼Œæ— è®ºæ˜¯åƒåœ¾é‚®ä»¶è¿‡æ»¤è¿˜æ˜¯ç½‘ç»œèˆ†æƒ…åˆ†æï¼Œéƒ½å¯çœ‹ä½œæ˜¯çŸ­æ–‡æœ¬çš„äºŒåˆ†ç±»é—®é¢˜ã€‚
2.1 å¸¸ç”¨çš„åˆ†ç±»å™¨ - è´å¶æ–¯åˆ†ç±»å™¨ è´å¶æ–¯ç®—æ³•è§£å†³æ¦‚ç‡è®ºä¸­çš„ä¸€ä¸ªå…¸å‹é—®é¢˜ï¼šä¸€å·ç®±å­æ”¾æœ‰çº¢è‰²çƒå’Œç™½è‰²çƒå„ 20 ä¸ªï¼ŒäºŒå·ç®±å­æ”¾æ²¹ç™½è‰²çƒ 10 ä¸ªï¼Œçº¢è‰²çƒ 30
ä¸ªã€‚ç°åœ¨éšæœºæŒ‘é€‰ä¸€ä¸ªç®±å­ï¼Œå–å‡ºæ¥ä¸€ä¸ªçƒçš„é¢œè‰²æ˜¯çº¢è‰²çš„ï¼Œè¯·é—®è¿™ä¸ªçƒæ¥è‡ªä¸€å·ç®±å­çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
åˆ©ç”¨è´å¶æ–¯ç®—æ³•è¯†åˆ«åƒåœ¾é‚®ä»¶åŸºäºåŒæ ·é“ç†ï¼Œæ ¹æ®å·²ç»åˆ†ç±»çš„åŸºæœ¬ä¿¡æ¯è·å¾—ä¸€ç»„ç‰¹å¾å€¼çš„æ¦‚ç‡ï¼ˆå¦‚ï¼šâ€œèŒ¶å¶â€è¿™ä¸ªè¯å‡ºç°åœ¨åƒåœ¾é‚®ä»¶ä¸­çš„æ¦‚ç‡å’Œéåƒåœ¾é‚®ä»¶ä¸­çš„æ¦‚ç‡ï¼‰ï¼Œå°±å¾—åˆ°åˆ†ç±»æ¨¡å‹ï¼Œç„¶åå¯¹å¾…å¤„ç†ä¿¡æ¯æå–ç‰¹å¾å€¼ï¼Œç»“åˆåˆ†ç±»æ¨¡å‹ï¼Œåˆ¤æ–­å…¶åˆ†ç±»ã€‚
è´å¶æ–¯å…¬å¼ï¼š
P(B|A)=P(A|B)*P(B)/P(A)
P(B|A)=å½“æ¡ä»¶ A å‘ç”Ÿæ—¶ï¼ŒB çš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ä»£å…¥ï¼šå½“çƒæ˜¯çº¢è‰²æ—¶ï¼Œæ¥è‡ªä¸€å·ç®±çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
P(A|B)=å½“é€‰æ‹©ä¸€å·ç®±æ—¶,å–å‡ºçº¢è‰²çƒçš„æ¦‚ç‡ã€‚
P(B)=ä¸€å·ç®±çš„æ¦‚ç‡ã€‚
P(A)=å–å‡ºçº¢çƒçš„æ¦‚ç‡ã€‚
ä»£å…¥åƒåœ¾é‚®ä»¶è¯†åˆ«ï¼š
P(B|A)=å½“åŒ…å«&#34;èŒ¶å¶&#34;è¿™ä¸ªå•è¯æ—¶ï¼Œæ˜¯åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
P(A|B)=å½“é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶æ—¶ï¼ŒåŒ…å«â€œèŒ¶å¶â€è¿™ä¸ªå•è¯çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
P(B)=åƒåœ¾é‚®ä»¶æ€»æ¦‚ç‡ã€‚
P(A)=â€œèŒ¶å¶â€åœ¨æ‰€æœ‰ç‰¹å¾å€¼ä¸­å‡ºç°çš„æ¦‚ç‡ã€‚
3 æ•°æ®é›†ä»‹ç» ä½¿ç”¨ä¸­æ–‡é‚®ä»¶æ•°æ®é›†ï¼šä¸¹æˆå­¦é•¿è‡ªå·±é‡‡é›†ï¼Œé€šè¿‡çˆ¬è™«ä»¥åŠäººå·¥ç­›é€‰ã€‚
æ•°æ®é›†â€œdataâ€ æ–‡ä»¶å¤¹ä¸­ï¼ŒåŒ…å«ï¼Œâ€œfullâ€ æ–‡ä»¶å¤¹å’Œ â€œdelayâ€ æ–‡ä»¶å¤¹ã€‚
â€œdataâ€ æ–‡ä»¶å¤¹é‡Œé¢åŒ…å«å¤šä¸ªäºŒçº§æ–‡ä»¶å¤¹ï¼ŒäºŒçº§æ–‡ä»¶å¤¹é‡Œé¢æ‰æ˜¯åƒåœ¾é‚®ä»¶æ–‡æœ¬ï¼Œä¸€ä¸ªæ–‡æœ¬ä»£è¡¨ä¸€ä»½é‚®ä»¶ã€‚â€œfullâ€ æ–‡ä»¶å¤¹é‡Œæœ‰ä¸€ä¸ª index" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3279768feeac49b924a54853789ba47f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-25T17:46:44+08:00" />
<meta property="article:modified_time" content="2024-01-25T17:46:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">å¤§åˆ›é¡¹ç›®æ¨è é¢˜ç›®ï¼šåƒåœ¾é‚®ä»¶(çŸ­ä¿¡)åˆ†ç±» ç®—æ³•å®ç° æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹  å¼€é¢˜</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>æ–‡ç« ç›®å½•</h4> 
 <ul><li><a href="#1__3" rel="nofollow">1 å‰è¨€</a></li><li><a href="#2____16" rel="nofollow">2 åƒåœ¾çŸ­ä¿¡/é‚®ä»¶ åˆ†ç±»ç®—æ³• åŸç†</a></li><li><ul><li><a href="#21____26" rel="nofollow">2.1 å¸¸ç”¨çš„åˆ†ç±»å™¨ - è´å¶æ–¯åˆ†ç±»å™¨</a></li></ul> 
  </li><li><a href="#3__57" rel="nofollow">3 æ•°æ®é›†ä»‹ç»</a></li><li><a href="#4__72" rel="nofollow">4 æ•°æ®é¢„å¤„ç†</a></li><li><a href="#5__149" rel="nofollow">5 ç‰¹å¾æå–</a></li><li><a href="#6__185" rel="nofollow">6 è®­ç»ƒåˆ†ç±»å™¨</a></li><li><a href="#7__227" rel="nofollow">7 ç»¼åˆæµ‹è¯•ç»“æœ</a></li><li><a href="#8__240" rel="nofollow">8 å…¶ä»–æ¨¡å‹æ–¹æ³•</a></li><li><a href="#9__338" rel="nofollow">9 æœ€å</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1__3"></a>1 å‰è¨€</h2> 
<p>ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯</p> 
<p><strong>åŸºäºæœºå™¨å­¦ä¹ çš„åƒåœ¾é‚®ä»¶åˆ†ç±»</strong></p> 
<p>è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼</p> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h2><a id="2____16"></a>2 åƒåœ¾çŸ­ä¿¡/é‚®ä»¶ åˆ†ç±»ç®—æ³• åŸç†</h2> 
<p>åƒåœ¾é‚®ä»¶å†…å®¹å¾€å¾€æ˜¯å¹¿å‘Šæˆ–è€…è™šå‡ä¿¡æ¯ï¼Œç”šè‡³æ˜¯ç”µè„‘ç—…æ¯’ã€æƒ…è‰²ã€ååŠ¨ç­‰ä¸è‰¯ä¿¡æ¯ï¼Œå¤§é‡åƒåœ¾é‚®ä»¶çš„å­˜åœ¨ä¸ä»…ä¼šç»™äººä»¬å¸¦æ¥å›°æ‰°ï¼Œè¿˜ä¼šé€ æˆç½‘ç»œèµ„æºçš„æµªè´¹ï¼›</p> 
<p>ç½‘ç»œèˆ†æƒ…æ˜¯ç¤¾ä¼šèˆ†æƒ…çš„ä¸€ç§è¡¨ç°å½¢å¼ï¼Œç½‘ç»œèˆ†æƒ…å…·æœ‰å½¢æˆè¿…é€Ÿã€å½±å“åŠ›å¤§å’Œç»„ç»‡å‘åŠ¨ä¼˜åŠ¿å¼ºç­‰ç‰¹ç‚¹ï¼Œç½‘ç»œèˆ†æƒ…çš„å¥½åæå¤§åœ°å½±å“ç€ç¤¾ä¼šçš„ç¨³å®šï¼Œé€šè¿‡æé«˜èˆ†æƒ…åˆ†æèƒ½åŠ›æœ‰æ•ˆè·å–å‘å¸ƒèˆ†è®ºçš„æ€§è´¨ï¼Œé¿å…è´Ÿé¢èˆ†è®ºçš„ä¸è‰¯å½±å“æ˜¯äº’è”ç½‘é¢ä¸´çš„ä¸¥è‚ƒè¯¾é¢˜ã€‚</p> 
<p>å°†é‚®ä»¶åˆ†ä¸ºåƒåœ¾é‚®ä»¶(æœ‰å®³ä¿¡æ¯)å’Œæ­£å¸¸é‚®ä»¶ï¼Œç½‘ç»œèˆ†è®ºåˆ†ä¸ºè´Ÿé¢èˆ†è®º(æœ‰å®³ä¿¡æ¯)å’Œæ­£é¢èˆ†è®ºï¼Œé‚£ä¹ˆï¼Œæ— è®ºæ˜¯åƒåœ¾é‚®ä»¶è¿‡æ»¤è¿˜æ˜¯ç½‘ç»œèˆ†æƒ…åˆ†æï¼Œéƒ½å¯çœ‹ä½œæ˜¯çŸ­æ–‡æœ¬çš„äºŒåˆ†ç±»é—®é¢˜ã€‚</p> 
<p><img src="https://images2.imgbox.com/93/38/BtQTRsYQ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="21____26"></a>2.1 å¸¸ç”¨çš„åˆ†ç±»å™¨ - è´å¶æ–¯åˆ†ç±»å™¨</h3> 
<p>è´å¶æ–¯ç®—æ³•è§£å†³æ¦‚ç‡è®ºä¸­çš„ä¸€ä¸ªå…¸å‹é—®é¢˜ï¼šä¸€å·ç®±å­æ”¾æœ‰çº¢è‰²çƒå’Œç™½è‰²çƒå„ 20 ä¸ªï¼ŒäºŒå·ç®±å­æ”¾æ²¹ç™½è‰²çƒ 10 ä¸ªï¼Œçº¢è‰²çƒ 30<br> ä¸ªã€‚ç°åœ¨éšæœºæŒ‘é€‰ä¸€ä¸ªç®±å­ï¼Œå–å‡ºæ¥ä¸€ä¸ªçƒçš„é¢œè‰²æ˜¯çº¢è‰²çš„ï¼Œè¯·é—®è¿™ä¸ªçƒæ¥è‡ªä¸€å·ç®±å­çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ</p> 
<p>åˆ©ç”¨è´å¶æ–¯ç®—æ³•è¯†åˆ«åƒåœ¾é‚®ä»¶åŸºäºåŒæ ·é“ç†ï¼Œæ ¹æ®å·²ç»åˆ†ç±»çš„åŸºæœ¬ä¿¡æ¯è·å¾—ä¸€ç»„ç‰¹å¾å€¼çš„æ¦‚ç‡ï¼ˆå¦‚ï¼šâ€œèŒ¶å¶â€è¿™ä¸ªè¯å‡ºç°åœ¨åƒåœ¾é‚®ä»¶ä¸­çš„æ¦‚ç‡å’Œéåƒåœ¾é‚®ä»¶ä¸­çš„æ¦‚ç‡ï¼‰ï¼Œå°±å¾—åˆ°åˆ†ç±»æ¨¡å‹ï¼Œç„¶åå¯¹å¾…å¤„ç†ä¿¡æ¯æå–ç‰¹å¾å€¼ï¼Œç»“åˆåˆ†ç±»æ¨¡å‹ï¼Œåˆ¤æ–­å…¶åˆ†ç±»ã€‚</p> 
<p><strong>è´å¶æ–¯å…¬å¼ï¼š</strong></p> 
<p>P(B|A)=P(A|B)*P(B)/P(A)</p> 
<p>P(B|A)=å½“æ¡ä»¶ A å‘ç”Ÿæ—¶ï¼ŒB çš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ä»£å…¥ï¼šå½“çƒæ˜¯çº¢è‰²æ—¶ï¼Œæ¥è‡ªä¸€å·ç®±çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ</p> 
<p>P(A|B)=å½“é€‰æ‹©ä¸€å·ç®±æ—¶,å–å‡ºçº¢è‰²çƒçš„æ¦‚ç‡ã€‚</p> 
<p>P(B)=ä¸€å·ç®±çš„æ¦‚ç‡ã€‚</p> 
<p>P(A)=å–å‡ºçº¢çƒçš„æ¦‚ç‡ã€‚</p> 
<p><strong>ä»£å…¥åƒåœ¾é‚®ä»¶è¯†åˆ«ï¼š</strong></p> 
<p>P(B|A)=å½“åŒ…å«"èŒ¶å¶"è¿™ä¸ªå•è¯æ—¶ï¼Œæ˜¯åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ</p> 
<p>P(A|B)=å½“é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶æ—¶ï¼ŒåŒ…å«â€œèŒ¶å¶â€è¿™ä¸ªå•è¯çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ</p> 
<p>P(B)=åƒåœ¾é‚®ä»¶æ€»æ¦‚ç‡ã€‚</p> 
<p>P(A)=â€œèŒ¶å¶â€åœ¨æ‰€æœ‰ç‰¹å¾å€¼ä¸­å‡ºç°çš„æ¦‚ç‡ã€‚</p> 
<p><img src="https://images2.imgbox.com/c6/14/t3jNuXjD_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="3__57"></a>3 æ•°æ®é›†ä»‹ç»</h2> 
<p>ä½¿ç”¨ä¸­æ–‡é‚®ä»¶æ•°æ®é›†ï¼šä¸¹æˆå­¦é•¿è‡ªå·±é‡‡é›†ï¼Œé€šè¿‡çˆ¬è™«ä»¥åŠäººå·¥ç­›é€‰ã€‚</p> 
<p>æ•°æ®é›†â€œdataâ€ æ–‡ä»¶å¤¹ä¸­ï¼ŒåŒ…å«ï¼Œâ€œfullâ€ æ–‡ä»¶å¤¹å’Œ â€œdelayâ€ æ–‡ä»¶å¤¹ã€‚</p> 
<p>â€œdataâ€ æ–‡ä»¶å¤¹é‡Œé¢åŒ…å«å¤šä¸ªäºŒçº§æ–‡ä»¶å¤¹ï¼ŒäºŒçº§æ–‡ä»¶å¤¹é‡Œé¢æ‰æ˜¯åƒåœ¾é‚®ä»¶æ–‡æœ¬ï¼Œä¸€ä¸ªæ–‡æœ¬ä»£è¡¨ä¸€ä»½é‚®ä»¶ã€‚â€œfullâ€ æ–‡ä»¶å¤¹é‡Œæœ‰ä¸€ä¸ª index<br> æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶è®°å½•çš„æ˜¯å„é‚®ä»¶æ–‡æœ¬çš„æ ‡ç­¾ã€‚</p> 
<p><img src="https://images2.imgbox.com/cb/aa/yk2LzbjO_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><strong>æ•°æ®é›†å¯è§†åŒ–ï¼š</strong></p> 
<p><img src="https://images2.imgbox.com/90/1b/M2jZMqGQ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="4__72"></a>4 æ•°æ®é¢„å¤„ç†</h2> 
<p>è¿™ä¸€æ­¥å°†åˆ†åˆ«æå–é‚®ä»¶æ ·æœ¬å’Œæ ·æœ¬æ ‡ç­¾åˆ°ä¸€ä¸ªå•ç‹¬æ–‡ä»¶ä¸­ï¼Œé¡ºä¾¿å»æ‰é‚®ä»¶çš„éä¸­æ–‡å­—ç¬¦ï¼Œå°†é‚®ä»¶åˆ†å¥½è¯ã€‚</p> 
<p>é‚®ä»¶å¤§è‡´å†…å®¹å¦‚ä¸‹å›¾ï¼š</p> 
<p><img src="https://images2.imgbox.com/23/02/j4lu3MoI_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æ¯ä¸€ä¸ªé‚®ä»¶æ ·æœ¬ï¼Œé™¤äº†é‚®ä»¶æ–‡æœ¬å¤–ï¼Œè¿˜åŒ…å«å…¶ä»–ä¿¡æ¯ï¼Œå¦‚å‘ä»¶äººé‚®ç®±ã€æ”¶ä»¶äººé‚®ç®±ç­‰ã€‚å› ä¸ºæˆ‘æ˜¯æƒ³æŠŠåƒåœ¾é‚®ä»¶åˆ†ç±»ç®€å•åœ°ä½œä¸ºä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ¥è§£å†³ï¼Œæ‰€ä»¥è¿™é‡Œå°±å¿½ç•¥äº†è¿™äº›ä¿¡æ¯ã€‚<br> ç”¨é€’å½’çš„æ–¹æ³•è¯»å–æ‰€æœ‰ç›®å½•é‡Œçš„é‚®ä»¶æ ·æœ¬ï¼Œç”¨ jieba åˆ†å¥½è¯åå†™å…¥åˆ°ä¸€ä¸ªæ–‡æœ¬ä¸­ï¼Œä¸€è¡Œæ–‡æœ¬ä»£è¡¨ä¸€ä¸ªé‚®ä»¶æ ·æœ¬ï¼š</p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> re
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> codecs
<span class="token keyword">import</span> os 
<span class="token comment"># å»æ‰éä¸­æ–‡å­—ç¬¦</span>
<span class="token keyword">def</span> <span class="token function">clean_str</span><span class="token punctuation">(</span>string<span class="token punctuation">)</span><span class="token punctuation">:</span>
    string <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^\u4e00-\u9fff]"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> string<span class="token punctuation">)</span>
    string <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"\s{2,}"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> string<span class="token punctuation">)</span>
    <span class="token keyword">return</span> string<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_data_in_a_file</span><span class="token punctuation">(</span>original_path<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">'all_email.txt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    files <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>original_path<span class="token punctuation">)</span>
    <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> files<span class="token punctuation">:</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>original_path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                get_data_in_a_file<span class="token punctuation">(</span>original_path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> <span class="token builtin">file</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span>save_path<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            email <span class="token operator">=</span> <span class="token string">''</span>
            <span class="token comment"># æ³¨æ„è¦ç”¨ 'ignore'ï¼Œä¸ç„¶ä¼šæŠ¥é”™</span>
            f <span class="token operator">=</span> codecs<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>original_path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> <span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'gbk'</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>
            <span class="token comment"># lines = f.readlines()</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
                line <span class="token operator">=</span> clean_str<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
                email <span class="token operator">+=</span> line
            f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token triple-quoted-string string">"""
            å‘ç°åœ¨é€’å½’è¿‡ç¨‹ä¸­ä½¿ç”¨ 'a' æ¨¡å¼ä¸€ä¸ªä¸ªå†™å…¥æ–‡ä»¶æ¯” åœ¨é€’å½’å®Œåä¸€æ¬¡æ€§ç”¨ 'w' æ¨¡å¼å†™å…¥æ–‡ä»¶å¿«å¾ˆå¤š
            """</span>
            f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>save_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span>
            email <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>email<span class="token punctuation">)</span> <span class="token keyword">if</span> word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">]</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>email<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Storing emails in a file ...'</span><span class="token punctuation">)</span>
get_data_in_a_file<span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">'all_email.txt'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Store emails finished !'</span><span class="token punctuation">)</span>
</code></pre> 
<p>ç„¶åå°†æ ·æœ¬æ ‡ç­¾å†™å…¥å•ç‹¬çš„æ–‡ä»¶ä¸­ï¼Œ0 ä»£è¡¨åƒåœ¾é‚®ä»¶ï¼Œ1 ä»£è¡¨éåƒåœ¾é‚®ä»¶ã€‚ä»£ç å¦‚ä¸‹ï¼š</p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_label_in_a_file</span><span class="token punctuation">(</span>original_path<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">'all_email.txt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>original_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
    label_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
        <span class="token comment"># spam</span>
        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'s'</span><span class="token punctuation">:</span>
            label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'0'</span><span class="token punctuation">)</span>
        <span class="token comment"># ham</span>
        <span class="token keyword">elif</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'h'</span><span class="token punctuation">:</span>
            label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'1'</span><span class="token punctuation">)</span>

    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>save_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>label_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Storing labels in a file ...'</span><span class="token punctuation">)</span>
get_label_in_a_file<span class="token punctuation">(</span><span class="token string">'index'</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">'label.txt'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Store labels finished !'</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="5__149"></a>5 ç‰¹å¾æå–</h2> 
<p>å°†æ–‡æœ¬å‹æ•°æ®è½¬åŒ–ä¸ºæ•°å€¼å‹æ•°æ®ï¼Œæœ¬æ–‡ä½¿ç”¨çš„æ˜¯ TF-IDF æ–¹æ³•ã€‚</p> 
<p>TF-IDF æ˜¯è¯é¢‘-é€†å‘æ–‡æ¡£é¢‘ç‡ï¼ˆTerm-Frequencyï¼ŒInverse Document Frequencyï¼‰ã€‚å…¬å¼å¦‚ä¸‹ï¼š</p> 
<p><img src="https://images2.imgbox.com/a3/85/JhIUbI7w_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­ï¼Œä¸€ä¸ªè¯çš„ IDF æ˜¯ä¸€æ ·çš„ï¼ŒTF æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨ä¸€ä¸ªæ–‡æ¡£ä¸­ï¼Œä¸€ä¸ªè¯çš„ TF å’Œ IDF<br> è¶Šé«˜ï¼Œè¯´æ˜è¯¥è¯åœ¨è¯¥æ–‡æ¡£ä¸­å‡ºç°å¾—å¤šï¼Œåœ¨å…¶ä»–æ–‡æ¡£ä¸­å‡ºç°å¾—å°‘ã€‚å› æ­¤ï¼Œè¯¥è¯å¯¹è¿™ä¸ªæ–‡æ¡£çš„é‡è¦æ€§è¾ƒé«˜ï¼Œå¯ä»¥ç”¨æ¥åŒºåˆ†è¿™ä¸ªæ–‡æ¡£ã€‚</p> 
<p><img src="https://images2.imgbox.com/34/f3/o6AKQWPG_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer

<span class="token keyword">def</span> <span class="token function">tokenizer_jieba</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ç»“å·´åˆ†è¯</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>li <span class="token keyword">for</span> li <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token keyword">if</span> li<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">tokenizer_space</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># æŒ‰ç©ºæ ¼åˆ†è¯</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>li <span class="token keyword">for</span> li <span class="token keyword">in</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> li<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">get_data_tf_idf</span><span class="token punctuation">(</span>email_file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># é‚®ä»¶æ ·æœ¬å·²ç»åˆ†å¥½äº†è¯ï¼Œè¯ä¹‹é—´ç”¨ç©ºæ ¼éš”å¼€ï¼Œæ‰€ä»¥ tokenizer=tokenizer_space</span>
    vectoring <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">'content'</span><span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer_space<span class="token punctuation">,</span> analyzer<span class="token operator">=</span><span class="token string">'word'</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>email_file_name<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> vectoring<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x<span class="token punctuation">,</span> vectoring
</code></pre> 
<h2><a id="6__185"></a>6 è®­ç»ƒåˆ†ç±»å™¨</h2> 
<p><strong>è¿™é‡Œå­¦é•¿ç®€å•çš„ç»™ä¸€ä¸ªé€»è¾‘å›å½’åˆ†ç±»å™¨çš„ä¾‹å­</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> svm<span class="token punctuation">,</span> ensemble<span class="token punctuation">,</span> naive_bayes
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    email_file_name <span class="token operator">=</span> <span class="token string">'all_email.txt'</span>
    label_file_name <span class="token operator">=</span> <span class="token string">'label.txt'</span>
    x<span class="token punctuation">,</span> vectoring <span class="token operator">=</span> get_data_tf_idf<span class="token punctuation">(</span>email_file_name<span class="token punctuation">)</span>
    y <span class="token operator">=</span> get_label_list<span class="token punctuation">(</span>label_file_name<span class="token punctuation">)</span>

    <span class="token comment"># print('x.shape : ', x.shape)</span>
    <span class="token comment"># print('y.shape : ', y.shape)</span>
    
    <span class="token comment"># éšæœºæ‰“ä¹±æ‰€æœ‰æ ·æœ¬</span>
    index <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>  
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>index<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
    y <span class="token operator">=</span> y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>

    <span class="token comment"># åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

    clf <span class="token operator">=</span> svm<span class="token punctuation">.</span>LinearSVC<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># clf = LogisticRegression()</span>
    <span class="token comment"># clf = ensemble.RandomForestClassifier()</span>
    clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
    y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'classification_report\n'</span><span class="token punctuation">,</span> metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> digits<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy:'</span><span class="token punctuation">,</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="7__227"></a>7 ç»¼åˆæµ‹è¯•ç»“æœ</h2> 
<p><strong>æµ‹è¯•äº†2000æ¡æ•°æ®ï¼Œä½¿ç”¨å¦‚ä¸‹æ–¹æ³•ï¼š</strong></p> 
<ul><li> <p>æ”¯æŒå‘é‡æœº SVM</p> </li><li> <p>éšæœºæ•°æ·±æ—</p> </li><li> <p>é€»è¾‘å›å½’<br> <img src="https://images2.imgbox.com/58/e4/eifyaQHs_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> </li></ul> 
<p>å¯ä»¥çœ‹åˆ°ï¼Œ2000æ¡æ•°æ®è®­ç»ƒç»“æœï¼Œ200æ¡æµ‹è¯•ç»“æœï¼Œç²¾åº¦è¿˜ç®—é«˜ï¼Œä¸è¿‡æ•°æ®è¾ƒå°‘å¾ˆéš¾è¯´æ˜é—®é¢˜ã€‚</p> 
<h2><a id="8__240"></a>8 å…¶ä»–æ¨¡å‹æ–¹æ³•</h2> 
<p><strong>è¿˜å¯ä»¥æ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹</strong></p> 
<p><img src="https://images2.imgbox.com/bf/dd/fMNYl18h_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ç½‘ç»œæ¶æ„ç¬¬ä¸€å±‚æ˜¯é¢„è®­ç»ƒçš„åµŒå…¥å±‚ï¼Œå®ƒå°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°å®æ•°çš„Nç»´å‘é‡ï¼ˆEMBEDDING_SIZEå¯¹åº”äºè¯¥å‘é‡çš„å¤§å°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ä¸º100ï¼‰ã€‚å…·æœ‰ç›¸ä¼¼å«ä¹‰çš„ä¸¤ä¸ªå•è¯å¾€å¾€å…·æœ‰éå¸¸æ¥è¿‘çš„å‘é‡ã€‚</p> 
<p>ç¬¬äºŒå±‚æ˜¯å¸¦æœ‰LSTMå•å…ƒçš„é€’å½’ç¥ç»ç½‘ç»œã€‚æœ€åï¼Œè¾“å‡ºå±‚æ˜¯2ä¸ªç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒå¯¹åº”äºå…·æœ‰softmaxæ¿€æ´»åŠŸèƒ½çš„â€œåƒåœ¾é‚®ä»¶â€æˆ–â€œæ­£å¸¸é‚®ä»¶â€ã€‚</p> 
<p>â€‹</p> 
<pre><code class="prism language-python">

    <span class="token keyword">def</span> <span class="token function">get_embedding_vectors</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embedding_index <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"data/glove.6B.</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dim<span class="token punctuation">}</span></span><span class="token string">d.txt"</span></span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token string">"Reading GloVe"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    values <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
    word <span class="token operator">=</span> values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    vectors <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
    embedding_index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> vectors
    
    word_index <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>word_index
    embedding_matrix <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>word_index<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> word<span class="token punctuation">,</span> i <span class="token keyword">in</span> word_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embedding_vector <span class="token operator">=</span> embedding_index<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    <span class="token keyword">if</span> embedding_vector <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token comment"># words not found will be 0s</span>
    embedding_matrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> embedding_vector
    
    <span class="token keyword">return</span> embedding_matrix


    <span class="token keyword">def</span> <span class="token function">get_model</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> lstm_units<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Constructs the model,
    Embedding vectors =&gt; LSTM =&gt; 2 output Fully-Connected neurons with softmax activation
    """</span>
    <span class="token comment"># get the GloVe embedding vectors</span>
    embedding_matrix <span class="token operator">=</span> get_embedding_vectors<span class="token punctuation">(</span>tokenizer<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>
    EMBEDDING_SIZE<span class="token punctuation">,</span>
    weights<span class="token operator">=</span><span class="token punctuation">[</span>embedding_matrix<span class="token punctuation">]</span><span class="token punctuation">,</span>
    trainable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    input_length<span class="token operator">=</span>SEQUENCE_LENGTH<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span>lstm_units<span class="token punctuation">,</span> recurrent_dropout<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># compile as rmsprop optimizer</span>
    <span class="token comment"># aswell as with recall metric</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"rmsprop"</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">"categorical_crossentropy"</span><span class="token punctuation">,</span>
    metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">,</span> keras_metrics<span class="token punctuation">.</span>precision<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keras_metrics<span class="token punctuation">.</span>recall<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

</code></pre> 
<p><strong>è®­ç»ƒç»“æœå¦‚ä¸‹ï¼š</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python">_________________________________________________________________
Layer <span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">)</span> Output Shape Param <span class="token comment">#</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
embedding_1 <span class="token punctuation">(</span>Embedding<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token number">901300</span>
_________________________________________________________________
lstm_1 <span class="token punctuation">(</span>LSTM<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span> <span class="token number">117248</span>
_________________________________________________________________
dropout_1 <span class="token punctuation">(</span>Dropout<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span> <span class="token number">0</span>
_________________________________________________________________
dense_1 <span class="token punctuation">(</span>Dense<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token number">258</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Total params<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">018</span><span class="token punctuation">,</span><span class="token number">806</span>
Trainable params<span class="token punctuation">:</span> <span class="token number">117</span><span class="token punctuation">,</span><span class="token number">506</span>
Non<span class="token operator">-</span>trainable params<span class="token punctuation">:</span> <span class="token number">901</span><span class="token punctuation">,</span><span class="token number">300</span>
_________________________________________________________________
X_train<span class="token punctuation">.</span>shape<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">4180</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
X_test<span class="token punctuation">.</span>shape<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">1394</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
y_train<span class="token punctuation">.</span>shape<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">4180</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
y_test<span class="token punctuation">.</span>shape<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">1394</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
Train on <span class="token number">4180</span> samples<span class="token punctuation">,</span> validate on <span class="token number">1394</span> samples
Epoch <span class="token number">1</span><span class="token operator">/</span><span class="token number">20</span>
<span class="token number">4180</span><span class="token operator">/</span><span class="token number">4180</span> <span class="token punctuation">[</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token punctuation">]</span> <span class="token operator">-</span> 9s 2ms<span class="token operator">/</span>step <span class="token operator">-</span> loss<span class="token punctuation">:</span> <span class="token number">0.1712</span> <span class="token operator">-</span> acc<span class="token punctuation">:</span> <span class="token number">0.9325</span> <span class="token operator">-</span> precision<span class="token punctuation">:</span> <span class="token number">0.9524</span> <span class="token operator">-</span> recall<span class="token punctuation">:</span> <span class="token number">0.9708</span> <span class="token operator">-</span> val_loss<span class="token punctuation">:</span> <span class="token number">0.1023</span> <span class="token operator">-</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.9656</span> <span class="token operator">-</span> val_precision<span class="token punctuation">:</span> <span class="token number">0.9840</span> <span class="token operator">-</span> val_recall<span class="token punctuation">:</span> <span class="token number">0.9758</span>

Epoch <span class="token number">00001</span><span class="token punctuation">:</span> val_loss improved <span class="token keyword">from</span> inf to <span class="token number">0.10233</span><span class="token punctuation">,</span> saving model to results<span class="token operator">/</span>spam_classifier_0<span class="token punctuation">.</span><span class="token number">10</span>
Epoch <span class="token number">2</span><span class="token operator">/</span><span class="token number">20</span>
<span class="token number">4180</span><span class="token operator">/</span><span class="token number">4180</span> <span class="token punctuation">[</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token punctuation">]</span> <span class="token operator">-</span> 8s 2ms<span class="token operator">/</span>step <span class="token operator">-</span> loss<span class="token punctuation">:</span> <span class="token number">0.0976</span> <span class="token operator">-</span> acc<span class="token punctuation">:</span> <span class="token number">0.9675</span> <span class="token operator">-</span> precision<span class="token punctuation">:</span> <span class="token number">0.9765</span> <span class="token operator">-</span> recall<span class="token punctuation">:</span> <span class="token number">0.9862</span> <span class="token operator">-</span> val_loss<span class="token punctuation">:</span> <span class="token number">0.0809</span> <span class="token operator">-</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.9720</span> <span class="token operator">-</span> val_precision<span class="token punctuation">:</span> <span class="token number">0.9793</span> <span class="token operator">-</span> val_recall<span class="token punctuation">:</span> <span class="token number">0.9883</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/88/b8/yglgzBUl_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="9__338"></a>9 æœ€å</h2> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/826a85973c5b0b1380c6573cd5b86fe6/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">Prometheus é‡‡é›†snmpç›‘æ§æ•°æ®</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/de346a184b443f6dc9050554efb81294/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€JSåŸºç¡€ã€‘DOMçš„ä¸€äº›åŸºç¡€æ“ä½œ</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>