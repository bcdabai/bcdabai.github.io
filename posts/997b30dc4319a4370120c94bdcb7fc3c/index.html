<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习PyTorch（二）卷积神经网络 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习PyTorch（二）卷积神经网络" />
<meta property="og:description" content="文章目录 背景及应用基础及计算卷积池化感受野 卷积神经网络的定义bvb CNN在pytorch中的实现**卷积**：**池化**: 标准化数据预处理Batch Normalization 有名的卷积网络结构AlexNetpytorch实现 **VGG**pytorch实现 GoogLeNetpytorch实现 ResNetpytorch实现 DenseNetpytorch实现 卷积神经网络训练技巧数据增强学习率衰减Dropout正则化微调进行迁移学习灵活的数据读取ImageFolderDatasetDataLoadercollate_fn 批标准化pytorch实现 TensorBoard可视化 背景及应用 基础及计算 因为是彩色图片，所以有RGB三个通道。
传统方法处理图像
卷积 引入卷积
十字架元素不等于零。
卷积运算
左边的矩阵是输入图像抽取的一部分，表示每一个像素点的像素值。
卷积运算
到
运算规则
卷积
扩充0来增加卷积输出的大小：
以上输出矩阵从4×4到6×6，还可以保留边缘信息。原本边缘信息只能用到一次，用这个方法可以用到很多次。
我们在矩阵外部补零的时候可以补很多层0，称这个层数为“padding”
卷积输出后矩阵大小的计算公式（以宽度为例）
W o u t = ( W − K &#43; 2 P ) / S &#43; 1 {W_{out}} = (W - K &#43; 2P)/S &#43; 1 Wout​=(W−K&#43;2P)/S&#43;1，有小数，则向下取整。
卷积层
比如：输入（32，32，3）的矩阵，有6个（5，5）卷积核。
那么我们就有5个（28，28）输出矩阵，连接起来就是（28，28，6）的输出
总结
池化 找最大值输出：最大值池化
统计平均值信息：均值池化
池化的作用
计算公式和卷积一样，但如果有小数，向上取整。
感受野 感受野计算时有下面几个知识点需要知道：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/997b30dc4319a4370120c94bdcb7fc3c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-05T18:17:49+08:00" />
<meta property="article:modified_time" content="2019-08-05T18:17:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习PyTorch（二）卷积神经网络</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_2" rel="nofollow">背景及应用</a></li><li><a href="#_9" rel="nofollow">基础及计算</a></li><li><ul><li><a href="#_18" rel="nofollow">卷积</a></li><li><a href="#_66" rel="nofollow">池化</a></li><li><ul><li><a href="#_77" rel="nofollow">感受野</a></li></ul> 
   </li><li><a href="#bvb_88" rel="nofollow">卷积神经网络的定义bvb</a></li></ul> 
  </li><li><a href="#CNNpytorch_93" rel="nofollow">CNN在pytorch中的实现</a></li><li><ul><li><a href="#_98" rel="nofollow">**卷积**：</a></li><li><a href="#_172" rel="nofollow">**池化**:</a></li></ul> 
  </li><li><a href="#_208" rel="nofollow">标准化</a></li><li><ul><li><a href="#_210" rel="nofollow">数据预处理</a></li><li><a href="#Batch__Normalization_224" rel="nofollow">Batch Normalization</a></li></ul> 
  </li><li><a href="#_238" rel="nofollow">有名的卷积网络结构</a></li><li><ul><li><a href="#AlexNet_245" rel="nofollow">AlexNet</a></li><li><ul><li><a href="#pytorch_266" rel="nofollow">pytorch实现</a></li></ul> 
   </li><li><a href="#VGG_356" rel="nofollow">**VGG**</a></li><li><ul><li><a href="#pytorch_373" rel="nofollow">pytorch实现</a></li></ul> 
   </li><li><a href="#GoogLeNet_501" rel="nofollow">GoogLeNet</a></li><li><ul><li><a href="#pytorch_531" rel="nofollow">pytorch实现</a></li></ul> 
   </li><li><a href="#ResNet_681" rel="nofollow">ResNet</a></li><li><ul><li><a href="#pytorch_707" rel="nofollow">pytorch实现</a></li></ul> 
   </li><li><a href="#DenseNet_827" rel="nofollow">DenseNet</a></li><li><ul><li><a href="#pytorch_850" rel="nofollow">pytorch实现</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_964" rel="nofollow">卷积神经网络训练技巧</a></li><li><ul><li><a href="#_970" rel="nofollow">数据增强</a></li><li><a href="#_1127" rel="nofollow">学习率衰减</a></li><li><a href="#Dropout_1253" rel="nofollow">Dropout</a></li><li><a href="#_1264" rel="nofollow">正则化</a></li><li><a href="#_1274" rel="nofollow">微调进行迁移学习</a></li><li><a href="#_1366" rel="nofollow">灵活的数据读取</a></li><li><ul><li><a href="#ImageFolder_1367" rel="nofollow">ImageFolder</a></li><li><a href="#Dataset_1425" rel="nofollow">Dataset</a></li><li><a href="#DataLoader_1465" rel="nofollow">DataLoader</a></li><li><a href="#collate_fn_1497" rel="nofollow">collate_fn</a></li></ul> 
   </li><li><a href="#_1517" rel="nofollow">批标准化</a></li><li><ul><li><a href="#pytorch_1582" rel="nofollow">pytorch实现</a></li></ul> 
  </li></ul> 
  </li><li><a href="#TensorBoard_1667" rel="nofollow">TensorBoard可视化</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>背景及应用</h2> 
<p><img src="https://images2.imgbox.com/b1/e1/CyjIYEVy_o.png" width="50%" alt=""></p> 
<p><img src="https://images2.imgbox.com/45/d5/f7XvHsKv_o.png" width="50%" alt=""></p> 
<h2><a id="_9"></a>基础及计算</h2> 
<p><img src="https://images2.imgbox.com/7c/25/owQiySn8_o.png" width="80%" alt=""><br> 因为是彩色图片，所以有RGB三个通道。<br> <img src="https://images2.imgbox.com/a1/b4/m20R0SC8_o.png" width="80%" alt=""><br> <strong>传统方法处理图像</strong><br> <img src="https://images2.imgbox.com/43/98/foLQB318_o.png" width="80%" alt=""></p> 
<h3><a id="_18"></a>卷积</h3> 
<p><strong>引入卷积</strong><br> 十字架元素不等于零。<br> <img src="https://images2.imgbox.com/05/02/g0Dhk7bH_o.png" width="60%" alt=""><br> <strong>卷积运算</strong><br> 左边的矩阵是输入图像抽取的一部分，表示每一个像素点的像素值。<br> <img src="https://images2.imgbox.com/9a/78/H4EdkBwK_o.png" width="60%" alt=""><br> <strong>卷积运算</strong><br> <img src="https://images2.imgbox.com/34/e6/ZZHVsLXn_o.png" width="50%" alt=""><strong>到</strong><img src="https://images2.imgbox.com/a6/f6/JTBuZxmt_o.png" width="50%" alt=""><br> <strong>运算规则</strong><br> <img src="https://images2.imgbox.com/48/6b/5I2m0ouH_o.png" width="50%" alt=""><br> <img src="https://images2.imgbox.com/70/91/6pL6HnAX_o.png" width="50%" alt=""><br> <strong>卷积</strong><br> <img src="https://images2.imgbox.com/0f/2e/HD5FWpJZ_o.png" width="50%" alt=""><br> <strong>扩充0来增加卷积输出的大小</strong>：<br> <img src="https://images2.imgbox.com/ba/5e/Ue5ffbUC_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/cf/77/K7SYrFHA_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/87/ac/ZnBbYkvv_o.png" width="60%" alt=""><br> 以上输出矩阵从4×4到6×6，还可以保留边缘信息。原本边缘信息只能用到一次，用这个方法可以用到很多次。<br> 我们在矩阵外部补零的时候可以补很多层0，称这个层数为“<strong>padding</strong>”<br> 卷积输出后矩阵大小的计算公式（以宽度为例）<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          W 
         
         
         
           o 
          
         
           u 
          
         
           t 
          
         
        
       
         = 
        
       
         ( 
        
       
         W 
        
       
         − 
        
       
         K 
        
       
         + 
        
       
         2 
        
       
         P 
        
       
         ) 
        
       
         / 
        
       
         S 
        
       
         + 
        
       
         1 
        
       
      
        {W_{out}} = (W - K + 2P)/S + 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">o</span><span class="mord mathit mtight">u</span><span class="mord mathit mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathit" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.76666em; vertical-align: -0.08333em;"></span><span class="mord mathit" style="margin-right: 0.07153em;">K</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">2</span><span class="mord mathit" style="margin-right: 0.13889em;">P</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathit" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span>，有小数，则向下取整。<br> <img src="https://images2.imgbox.com/5f/0f/dE7DOhxp_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/65/46/8yZxYToL_o.png" width="60%" alt=""><br> <strong>卷积层</strong><br> <img src="https://images2.imgbox.com/81/84/XoC6nbPB_o.png" width="60%" alt=""></p> 
<p><img src="https://images2.imgbox.com/46/ca/vJBv2UYB_o.png" width="60%" alt=""><br> 比如：输入（32，32，3）的矩阵，有6个（5，5）卷积核。<br> 那么我们就有5个（28，28）输出矩阵，连接起来就是（28，28，6）的输出<br> <strong>总结</strong><br> <img src="https://images2.imgbox.com/d9/1f/yGqQRwem_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/76/96/GhLi8yes_o.png" width="60%" alt=""></p> 
<h3><a id="_66"></a>池化</h3> 
<p><img src="https://images2.imgbox.com/3f/dc/bGE1J4N4_o.png" width="70%" alt=""><br> 找最大值输出：最大值池化<br> 统计平均值信息：均值池化<br> <img src="https://images2.imgbox.com/3f/ce/GGQ9ur7k_o.png" width="60%" alt=""><br> <strong>池化的作用</strong><br> <img src="https://images2.imgbox.com/fb/ef/zQ49lr8a_o.png" width="70%" alt=""><br> 计算公式和卷积一样，但如果有小数，向上取整。</p> 
<h4><a id="_77"></a>感受野</h4> 
<p>感受野计算时有下面几个知识点需要知道：</p> 
<p>. 最后一层（卷积层或池化层）输出特征图感受野的大小等于卷积核的大小。<br> . 第i层卷积层的感受野大小和第i层的卷积核大小和步长有关系，同时也与第（i+1）层感受野大小有关。<br> . 计算感受野的大小时忽略了图像边缘的影响，即不考虑padding的大小。<br> 关于感受野大小的计算方式是采用从最后一层往下计算的方法，即先计算最深层在前一层上的感受野，然后逐层传递到第一层，使用的公式可以表示如下：<br> <img src="https://images2.imgbox.com/9f/5d/lc3Y8IzX_o.png" alt="在这里插入图片描述"><br> 其中，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         R 
        
        
        
          F 
         
        
          i 
         
        
       
      
        R{F_i} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="mord"><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>是第i层卷积层的感受野，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         R 
        
        
        
          F 
         
         
         
           i 
          
         
           + 
          
         
           1 
          
         
        
       
      
        R{F_{i + 1}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.891661em; vertical-align: -0.208331em;"></span><span class="mord mathit" style="margin-right: 0.00773em;">R</span><span class="mord"><span class="mord"><span class="mord mathit" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>是（i+1）层上的感受野，stride是卷积的步长，Ksize是本层卷积核的大小。</p> 
<h3><a id="bvb_88"></a>卷积神经网络的定义bvb</h3> 
<p>是一个"卷积层"+“池化层”，<br> 作为神经网络的隐藏层反复出现的多层神经网络结构。<br> <img src="https://images2.imgbox.com/06/eb/Mk1uUoAG_o.png" width="80%" alt=""></p> 
<h2><a id="CNNpytorch_93"></a>CNN在pytorch中的实现</h2> 
<p>ReLU(inplace=True)<br> inplace=True<br> 计算结果不会有影响。利用in-place计算可以节省内（显）存，同时还可以省去反复申请和释放内存的时间。但是会对原变量覆盖，只要不带来错误就用。<br> inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出</p> 
<h3><a id="_98"></a><strong>卷积</strong>：</h3> 
<p>pytorch中有函数<code>torch.nn.Con2d()</code>来实现卷积<br> 和<code>torch.nn.functional.con2d()</code>两种实现方式<br> <img src="https://images2.imgbox.com/8f/79/eqz5oIrN_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/b3/84/D5SlcD5U_o.png" width="50%" alt=""><br> dilation(扩张)：控制kernel点（卷积核点）的间距; 也被称为 "à trous"算法. 可以在此github地址查看:Dilated convolution animations<br> groups(卷积核个数)：这个比较好理解，通常来说，卷积个数唯一，但是对某些情况，可以设置范围在1 —— in_channels中数目的卷积核</p> 
<pre><code>bias:默认为True，表示使用偏置
groups：groups=1表示所有输入输出是相关联的；groups=n表示输入输出通道数（深度）被分割为n份，并分别对应，且需要被groups整除
（dilation:卷积对输入的空间间隔，默认为dilation=1）
</code></pre> 
<p>卷积输入为<code>torch.autograd.Variable()</code>的类型，大小为<code>（batch，channel，H，W）</code></p> 
<p><strong>卷积实例</strong><br> 输入图片：<br> <img src="https://images2.imgbox.com/55/95/m1qx7fXv_o.png" width="50%" alt=""></p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
在Pytorch中定义一个能够检测边缘的卷积核
"""</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pt
<span class="token comment">#%matplotlib inline</span>

im<span class="token operator">=</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./cat.png'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span><span class="token comment">#转化为灰度图</span>
im<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>im<span class="token punctuation">,</span>dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>

<span class="token comment">#可视化图片</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>im<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'unit8'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">cmp</span><span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>

<span class="token comment">#将图片矩阵转化为pytorch tensor,并适配卷积输入的要求</span>
im<span class="token operator">=</span>im<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>im<span class="token punctuation">.</span>reshape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#in,out,H,W</span>
im<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>im<span class="token punctuation">)</span>

<span class="token comment">#定义一个算子对其进行轮廓检测</span>
<span class="token comment"># 使用nn.conv2f</span>
conv1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#定义卷积</span>

sobel_kernel<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">==</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token comment">#定义轮廓检测算子</span>
sobel_kernel<span class="token operator">=</span>sobel_kernel<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#适配卷积的输入输出</span>
conv1<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>sobel_kernel<span class="token punctuation">)</span><span class="token comment">#给卷积的kernel赋值</span>

edge1<span class="token operator">=</span>conv1<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#作用在图片上</span>
edge1<span class="token operator">=</span>edge1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将输出转换为图片的形式,删除所有单维度的条目</span>

plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>edge1<span class="token punctuation">,</span>cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>

<span class="token comment"># 使用nn.function.conv2d</span>
sobel_kernel<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">==</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token comment">#定义轮廓检测算子</span>
sobel_kernel<span class="token operator">=</span>sobel_kernel<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#适配卷积的输入输出</span>
weight<span class="token operator">=</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>sobel_kernel<span class="token punctuation">)</span><span class="token punctuation">)</span>

edge2<span class="token operator">=</span>F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token punctuation">,</span>weight<span class="token punctuation">)</span><span class="token comment">#作用在图片上</span>
edge2<span class="token operator">=</span>edge2<span class="token punctuation">.</span>data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将输出转化为图片的格式</span>

plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>edg2<span class="token punctuation">,</span><span class="token builtin">cmp</span><span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ca/6c/xGrR8bT9_o.png" width="80%" alt=""></p> 
<p>结果图：<br> <img src="https://images2.imgbox.com/e8/9d/p4yiO7FE_o.png" width="40%" alt=""></p> 
<h3><a id="_172"></a><strong>池化</strong>:</h3> 
<p>pytorch中有函数<code>torch.nn.MaxPool2d()</code>或者<code>torch.nn.functional.max_pool2d()</code>来实现最大值池化<br> <img src="https://images2.imgbox.com/b2/05/ONNX0wUn_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/e7/75/SZtQU3AX_o.png" width="50%" alt=""></p> 
<pre><code class="prism language-python"><span class="token comment">#使用nn.MaxPool2d</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'before max pool,image shape:{}*{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pool<span class="token operator">=</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#kernel_size=2*2，stride=2</span>
small_im1<span class="token operator">=</span>pool<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span>
small_im1<span class="token operator">=</span>small_im1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'after max pool,image shape:{}*{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>small_im1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>small_im1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>small_im1<span class="token punctuation">,</span>cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>

<span class="token comment">#使用F.max_pool2d()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'before max pool,image shape:{}*{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
smal2_im1<span class="token operator">=</span>F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
smal2_im1<span class="token operator">=</span>small_im1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'after max pool,image shape:{}*{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>small_im1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>small_im1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>small_im2<span class="token punctuation">,</span>cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：</p> 
<pre><code class="prism language-python">before <span class="token builtin">max</span> pool<span class="token punctuation">,</span> image shape<span class="token punctuation">:</span> <span class="token number">224</span> x <span class="token number">224</span>
after <span class="token builtin">max</span> pool<span class="token punctuation">,</span> image shape<span class="token punctuation">:</span> <span class="token number">112</span> x <span class="token number">112</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/a2/40/RGhoUx4w_o.png" width="80%" alt=""></p> 
<p>结果图：<br> <img src="https://images2.imgbox.com/4a/fd/fS0heXz5_o.png" width="40%" alt=""></p> 
<p><a href="https://blog.csdn.net/Da_wan/article/details/80518725">Numpy中ndim、shape、dtype、astype的用法</a></p> 
<h2><a id="_208"></a>标准化</h2> 
<p>对数据增加预处理，同时使用批标准化能够得到非常好的收敛结果，这也是卷积网络能够训练到非常深的层的一个重要原因。</p> 
<h3><a id="_210"></a>数据预处理</h3> 
<p>尽量输入特征不相关且满足一个标准的正态分布。<br> 最常见的方法是中心化和标准化。<br> <strong>中心化</strong><br> 修正数据的中心位置。<br> 实现方法：在每个特征维度上减去对应的均值，最后得到0均值的特征。<br> <strong>标准化</strong><br> 把数据变成0均值后，为了使得不同的特征维度有相同的规模，除以标准差近似为一个标准正态分布。<br> 也可以依据最大值和最小值将其转化为-1~1之间。<br> <img src="https://images2.imgbox.com/c8/88/WSedgeqy_o.png" width="80%" alt=""></p> 
<p>另外有些方法，比武PCA或者白噪声已经用的非常少了。</p> 
<h3><a id="Batch__Normalization_224"></a>Batch Normalization</h3> 
<p>对于很深的网路结构，<strong>网路的非线性层会使得输出的结果变得相关，且不再满足一个标准的B(0,1)分布，甚至输入的中心已经发生偏移</strong>，这对于训练深层模型是很不有利的。</p> 
<p>BN是对每一层网络的输出，做一个归一化，使其服从标准的正态分布。从而加快收敛。</p> 
<p><strong>实现</strong>：<br> 对于给定的一个batch的数据 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         B 
        
       
         = 
        
       
         { 
        
        
        
          x 
         
        
          1 
         
        
       
         , 
        
        
        
          x 
         
        
          2 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          x 
         
        
          m 
         
        
       
         } 
        
       
      
        {B =\{ {x_1},{x_2},...,{x_m}\}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.05017em;">B</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span></span>算法 的公式如下：<br> <img src="https://images2.imgbox.com/f0/05/Eff0uYij_o.png" width="28%" alt=""></p> 
<p>1.第一行和第二行是计算出一个batch中数据的均值和方差<br> 2.接着使用第三个公式对batch中的每个数据点做标准化，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">ε</span></span></span></span></span>是为了计算稳定引入的一个小的常数，通常取 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
        
        
          0 
         
         
         
           − 
          
         
           5 
          
         
        
       
      
        10^{ - 5} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.814108em; vertical-align: 0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span></span>。<br> 3.最后利用权重修正得到最后的输出结果</p> 
<h2><a id="_238"></a>有名的卷积网络结构</h2> 
<p>2010年ILSVRC 1000分类</p> 
<p>数据集：CIFAR 10<br> <img src="https://images2.imgbox.com/5b/85/LWleJcLx_o.png" width="60%" alt=""></p> 
<h3><a id="AlexNet_245"></a>AlexNet</h3> 
<p><strong>8层CNN</strong><br> <img src="https://images2.imgbox.com/be/29/QKqhLEAa_o.png" width="80%" alt=""><br> 几个卷积池化堆叠后连接几个全连接层<br> <strong>结构图</strong><br> <img src="https://images2.imgbox.com/80/e5/FbjPAv3U_o.png" width="80%" alt=""></p> 
<p><img src="https://images2.imgbox.com/3f/db/3DUN4BDE_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/7a/09/spPwLhVQ_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/67/ec/lvcDp8PR_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/75/7f/ISEMOEtg_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/e1/a0/oRHrVjZI_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/d3/fe/wFWoN88W_o.png" width="40%" alt=""></p> 
<h4><a id="pytorch_266"></a>pytorch实现</h4> 
<p>将矩阵拉平,torch中的view相当于numpy中的reshape<br> x=x.reshape((-1,))</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFIR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token keyword">class</span> <span class="token class-name">AlexNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Modele<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AlexNet<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#第一层是5*5的卷积，输入的channels是3，输出的channels是64，步长是1，没有padding</span>
        self<span class="token punctuation">.</span>conv1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#（32-5）+1=28(64,28,28)</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment">#第二层是3*3的池化，步长是2，没有padding</span>
        self<span class="token punctuation">.</span>max_pool1<span class="token operator">=</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#(28-3)/2+1=13 (64,13,13)</span>

        <span class="token comment">#第三层是5*5的卷积，输入的channel是64，输出的channel是64，步长为1，没有padding</span>
        self<span class="token punctuation">.</span>conv2<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#(13-5)+1=9,(64,9,9)</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment">#第四层是3*3的池化，步长是2，没有padding</span>
        self<span class="token punctuation">.</span>max_pool2<span class="token operator">=</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#(9-3)/2+1=4,(64,4,4)</span>

        <span class="token comment">#第五层是全连接层，输入是1204，输出是384</span>
        self<span class="token punctuation">.</span>fc1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span><span class="token number">384</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 第五层是全连接层，输入是384，输出是192</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 第六层是全连接层，输入是192，输出是10</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>max_pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>max_pool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment">#将矩阵拉平,torch中的view相当于numpy中的reshape</span>
        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

alexnet<span class="token operator">=</span>AlexNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#为验证网络结构是否正确，先输入一张32*32的图片，看看输出</span>
<span class="token comment">#定义输入为（1，3，32，32）</span>
input_demo<span class="token operator">=</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
out_demo<span class="token operator">=</span>alexnet<span class="token punctuation">(</span>input_demo<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>out_demo<span class="token punctuation">,</span>shape<span class="token punctuation">)</span><span class="token comment">#torch.size([1,10])</span>

<span class="token keyword">def</span> <span class="token function">data_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x<span class="token operator">=</span>np<span class="token punctuation">.</span>arrar<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
    x<span class="token operator">=</span><span class="token punctuation">(</span>x<span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">0.5</span><span class="token comment">#标准化</span>
    x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#将channel放到第一维，只是pytorch要求地输入方式</span>
    x<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set<span class="token operator">=</span>CIFIR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
test_set<span class="token operator">=</span>CIFIR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
train_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shufflr<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>shufflr<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

net<span class="token operator">=</span>AlexNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
criterion<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_data<span class="token punctuation">,</span>test_data<span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>criterion<span class="token punctuation">)</span><span class="token comment">#训练20次</span>
</code></pre> 
<h3><a id="VGG_356"></a><strong>VGG</strong></h3> 
<p>第一个真正意义上的深层神经网络结构，是ImageNet2014年的亚军。<br> 得益于python函数和循环，能方便地构建重复结构的深层网络。</p> 
<p>不断地堆叠卷积层和池化层。<br> 几乎全部使用3×3的卷积核和2×2的池化层 。<br> <strong>作用：使用小的卷积核进行多层的堆叠和一个大的卷积核的感受野是相同的，同时小的卷积核还能减少参数，同时可以有更深的结构。</strong><br> 关键：使用很多层的3×3的卷积核然后再使用一个最大池化层。这个模块使用很多次。<br> 第一层是11×11的卷积，96个核，步长stride=4,最大值池化，图像大小会减小一半。<br> <img src="https://images2.imgbox.com/33/49/aAmWQUYj_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/ff/06/ljb1WGFR_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/39/1a/33VLp1ku_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/2e/da/8sOWs0DT_o.png" width="80%" alt=""></p> 
<h4><a id="pytorch_373"></a>pytorch实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFIR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token keyword">def</span> <span class="token function">vgg_block</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net<span class="token operator">=</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#(300-3+2)/1+1=300</span>
         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment">#定义第一层</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_convs<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#定义后面的很多层</span>
        net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kenel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#(300-3+2)+1=300</span>
        net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                                  <span class="token comment">#(300-3+2)+1=300</span>
    net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#定义池化层(300-2)/2+1=150</span>
    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>net<span class="token punctuation">)</span>

<span class="token comment">#将模型打印出来看结构</span>
block_demo<span class="token operator">=</span>vgg_block<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>block_demo<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
结果;
Sequential(
(0): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(3): ReLU(inplace)
(4): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(5): ReLU(inplace) 
(6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
"""</span>
<span class="token comment">#首先定义输入为（1，64，300，300）</span>
input_demo<span class="token operator">=</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#（batch.out_channel,H,W）</span>
output_demo<span class="token operator">=</span>block_demo<span class="token punctuation">(</span>input_demo<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>out_demo<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment">#torch.Size([1, 128, 150, 150])?</span>

<span class="token comment">#定义一个函数对vgg bolck堆叠</span>
<span class="token keyword">def</span> <span class="token function">vgg_stack</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span>channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表</span>
    <span class="token keyword">for</span> n<span class="token punctuation">,</span>c <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span>channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        int_c<span class="token operator">=</span>c<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        out_c<span class="token operator">=</span>c<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>vgg_block<span class="token punctuation">(</span>n<span class="token punctuation">,</span>int_c<span class="token punctuation">,</span>out_c<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>net<span class="token punctuation">)</span>

<span class="token comment">#定义一个简单点的VGG结构，8个卷积层进行测试。</span>
vgg_net<span class="token operator">=</span>vgg_stack<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vgg_net<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
Sequential(
(0): Sequential(
(0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
(1): Sequential(
(0): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
(2): Sequential(
(0): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(3): ReLU(inplace)
(4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
(3): Sequential(
(0): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(3): ReLU(inplace)
(4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
(4): Sequential(
(0): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace)
(2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(3): ReLU(inplace)
(4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
)
"""</span>
<span class="token comment">#可以看出该网络有5个池化层，图片大小会减少2^5倍。测试：</span>
test_x<span class="token operator">=</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y<span class="token operator">=</span>vgg_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test_y<span class="token punctuation">,</span>shape<span class="token punctuation">)</span><span class="token comment"># torch.Size([1, 512, 8, 8])</span>

<span class="token keyword">class</span> <span class="token class-name">vgg</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Modele<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>vgg<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feature<span class="token operator">=</span>vgg_net
        self<span class="token punctuation">.</span>fc<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">,</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>feature<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment">#将矩阵拉平,torch中的view相当于numpy中的reshape</span>
        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token keyword">def</span> <span class="token function">data_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x<span class="token operator">=</span>np<span class="token punctuation">.</span>arrar<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
    x<span class="token operator">=</span><span class="token punctuation">(</span>x<span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">0.5</span><span class="token comment">#标准化</span>
    x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#将channel放到第一维，只是pytorch要求地输入方式</span>
    x<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set<span class="token operator">=</span>CIFIR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
test_set<span class="token operator">=</span>CIFIR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
train_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shufflr<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>shufflr<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

net<span class="token operator">=</span>net<span class="token operator">=</span>vgg<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
criterion<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_data<span class="token punctuation">,</span>test_data<span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>criterion<span class="token punctuation">)</span><span class="token comment">#训练20次</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e1/aa/ABc1iREd_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="GoogLeNet_501"></a>GoogLeNet</h3> 
<p>ImageNet2014年的冠军。<br> 颠覆了传统卷积网络的串联的印象和固定做法，采用了一种非常有效的inception模块，得到了比VGG更深的网络结构，却比 VGG的参数更少，因为<strong>去掉了后面的全连接层，所以参数大大减少，同时有了很高的计算效率</strong>。<br> <strong>加入了更加结构化的Inception块使得我们能够使用更大的通道，更多的层，同时控制了计算量。</strong><br> Inception模块:四个并行卷积的层。<br> <img src="https://images2.imgbox.com/9c/85/ny0ZSs67_o.png" width="80%" alt=""><br> 最后将四个并行线路得到的特征在通道这个维度上拼接在一起。<br> <img src="https://images2.imgbox.com/13/7a/eZ1rOz03_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/38/41/FRkc0yGs_o.png" width="80%" alt=""><br> 从左到右：<br> 第一分支：不同感受野<br> 第二分支：减少通道数，扩大感受野<br> ……<br> 得到四个不同的特征<br> <img src="https://images2.imgbox.com/08/64/ErBmHUUu_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/cb/e6/1dbu4fNu_o.png" width="40%" alt=""><br> <img src="https://images2.imgbox.com/10/52/WgBRLfQx_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/ae/b0/PaoejnGV_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/16/c3/jhPdr5VU_o.png" width="50%" alt=""></p> 
<p><img src="https://images2.imgbox.com/73/97/gYyGwRuy_o.png" width="30%" alt=""></p> 
<h4><a id="pytorch_531"></a>pytorch实现</h4> 
<p>原论文使用多个输出来解决梯度小时的问题，这里我们之定义一个简单版本的GooLeNet，简化一个输出。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token comment">#定义一个卷积加一个relu激活函数和一个batchnorm作为一个基本的层的结构</span>
<span class="token keyword">def</span> <span class="token function">conv_relu</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token punctuation">,</span>padding<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span>eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> layer

<span class="token keyword">class</span> <span class="token class-name">inception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channel<span class="token punctuation">,</span>out1_1<span class="token punctuation">,</span>out2_1<span class="token punctuation">,</span>out2_3<span class="token punctuation">,</span>out3_1<span class="token punctuation">,</span>out3_5<span class="token punctuation">,</span>out4_1<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>inception<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#第一条线路</span>
        self<span class="token punctuation">.</span>batch1x1<span class="token operator">=</span>conv_relu<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out1_1<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment">#第二条线路</span>
        self<span class="token punctuation">.</span>batch3x3<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            conv_relu<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out2_1<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            conv_relu<span class="token punctuation">(</span>out2_1<span class="token punctuation">,</span>out2_3<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 第三条线路</span>
        self<span class="token punctuation">.</span>batch5x5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            conv_relu<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> out3_1<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            conv_relu<span class="token punctuation">(</span>out2_1<span class="token punctuation">,</span> out3_5<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 第四条线路</span>
        self<span class="token punctuation">.</span>batch_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            conv_relu<span class="token punctuation">(</span>out2_1<span class="token punctuation">,</span> out4_1<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        f1<span class="token operator">=</span>self<span class="token punctuation">.</span>batch1x1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        f2<span class="token operator">=</span>self<span class="token punctuation">.</span>batch3x3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        f3<span class="token operator">=</span>self<span class="token punctuation">.</span>batch5x5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        f4<span class="token operator">=</span>self<span class="token punctuation">.</span>batch_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>f1<span class="token punctuation">,</span>f2<span class="token punctuation">,</span>f3<span class="token punctuation">,</span>f4<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#按行拼接在后面</span>
        <span class="token keyword">return</span> out
<span class="token comment">#测试：</span>
test_net<span class="token operator">=</span>inception<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">48</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">96</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
test_x<span class="token operator">=</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">96</span><span class="token punctuation">,</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
input shape: 3 x 96 x 96
output shape: 256 x 96 x 96
#大小没有发生变化，通道维数变多
"""</span>

<span class="token keyword">class</span> <span class="token class-name">googlenet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>googlenet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose

        self<span class="token punctuation">.</span>block1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        conv_relu<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> out_channel<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        conv_relu<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        conv_relu<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        inception<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        inception<span class="token punctuation">(</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">208</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">144</span><span class="token punctuation">,</span> <span class="token number">288</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">182</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 1 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 2 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>block3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 3 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>block4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 4 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>block5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 5 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">return</span> x

test_net <span class="token operator">=</span> googlenet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
block 1 output: torch.Size([1, 64, 23, 23])
block 2 output: torch.Size([1, 192, 11, 11])
block 3 output: torch.Size([1, 480, 5, 5])
block 4 output: torch.Size([1, 832, 2, 2])
block 5 output: torch.Size([1, 1024, 1, 1])
output: torch.Size([1, 10])
输入的尺寸不断减少，通道的维数不断增加
"""</span>

<span class="token keyword">def</span> <span class="token function">data_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 将图片放大到 96 x 96，resize(size,interpolation=2)</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">0.5</span> <span class="token comment"># 标准化</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 将channel放到第一维</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
train_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> googlenet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> test_data<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="ResNet_681"></a>ResNet</h3> 
<p>ImageNet2015年的冠军。<br> <strong>使用跨层通道使得训练非常深的卷积神经网络成为可能。同样它使用非常简单的卷积层配置，使得其拓展更加简单。</strong><br> <img src="https://images2.imgbox.com/d7/96/vzFRrr7Z_o.png" width="80%" alt=""></p> 
<p><img src="https://images2.imgbox.com/66/76/Cvu5Fggt_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/7f/df/5PjWwyNd_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/89/c2/QA4js5bD_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/28/da/oLxNNpPX_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/3e/11/K4ZQf8pG_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/05/cc/Vi4Qs7nu_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/d8/8e/2CmOodTu_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/8b/fc/yDcW7mdX_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/f0/42/LUjHe3K3_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/49/99/wr0RP9uJ_o.png" width="70%" alt=""></p> 
<h4><a id="pytorch_707"></a>pytorch实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token keyword">def</span> <span class="token function">conv3x3</span><span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">residual_block</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span>same_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>residual_block<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>same_shape<span class="token operator">=</span>same_shape
        stride<span class="token operator">=</span><span class="token number">1</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>same_shape <span class="token keyword">else</span> <span class="token number">2</span>

        self<span class="token punctuation">.</span>conv1<span class="token operator">=</span>conv3x3<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">)</span>
        stride <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>same_shape <span class="token keyword">else</span> <span class="token number">2</span>

        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> conv3x3<span class="token punctuation">(</span>out_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channel<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>same_shape<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conv3<span class="token operator">=</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>same_shape<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x <span class="token operator">+</span> out<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#测试输出</span>
<span class="token comment">#输入输出形状相同</span>
test_net <span class="token operator">=</span> residual_block<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
input: torch.Size([1, 32, 96, 96])
output: torch.Size([1, 32, 96, 96])
"""</span>

<span class="token comment">#输入输出形状不同</span>
test_net <span class="token operator">=</span> residual_block<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
input: torch.Size([1, 3, 96, 96])
output: torch.Size([1, 32, 48, 48])
"""</span>

<span class="token keyword">class</span> <span class="token class-name">resnet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>resnet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose
        self<span class="token punctuation">.</span>block1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        residual_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        residual_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        residual_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        residual_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        residual_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        residual_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        residual_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        residual_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 1 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 2 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 3 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 4 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>block5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'block 5 output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token comment">#测试</span>
test_net <span class="token operator">=</span> resnet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
block 1 output: torch.Size([1, 64, 45, 45])
block 2 output: torch.Size([1, 64, 22, 22])
block 3 output: torch.Size([1, 128, 11, 11])
block 4 output: torch.Size([1, 256, 6, 6])
block 5 output: torch.Size([1, 512, 1, 1])
output: torch.Size([1, 10])
"""</span>
</code></pre> 
<h3><a id="DenseNet_827"></a>DenseNet</h3> 
<p>cvpr2017 best paper<br> DenseNet将残差连接改为了特征拼接，使网络有了更稠密的连接<br> ResNet跨层连接的思想影响了后面很多网络。<br> <img src="https://images2.imgbox.com/e5/2f/a0U01aaC_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/b0/15/s9QWHWGo_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/88/92/WBjrTdVj_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/34/2f/7fVdRQH8_o.png" width="90%" alt=""><br> <img src="https://images2.imgbox.com/59/65/ORulySmK_o.png" width="90%" alt=""><br> <img src="https://images2.imgbox.com/4a/35/lC0DWuVb_o.png" width="90%" alt=""><br> <img src="https://images2.imgbox.com/1e/03/BMAiMLxu_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/5f/85/YbcjHpXA_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/67/e1/mWcgCyrJ_o.png" width="70%" alt=""><br> <img src="https://images2.imgbox.com/e1/af/slHTC1Xu_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="pytorch_850"></a>pytorch实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token triple-quoted-string string">"""
首先定义一个卷积快，卷积块的顺序为bn,relu,conv
"""</span>
<span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> layer

<span class="token triple-quoted-string string">"""
dense block将每次的卷积输出称为growth_rate，如果输入时in_channel，有n层，那么输出就是in_channel+n*growth_rate
"""</span>
<span class="token keyword">class</span> <span class="token class-name">dense_block</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channel<span class="token punctuation">,</span>growth_rate<span class="token punctuation">,</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        block<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        channel<span class="token operator">=</span>in_channel
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv_block<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>growth_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
            channel<span class="token operator">+=</span>growth_rate

        self<span class="token punctuation">.</span>net<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>block<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>net<span class="token punctuation">:</span>
            out<span class="token operator">=</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token comment">#验证输出的channel对不对</span>
test_net <span class="token operator">=</span> dense_block<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
input shape: 3 x 96 x 96
output shape: 39 x 96 x 96
"""</span>

<span class="token triple-quoted-string string">"""
因为DenseNet会不断对维数进行拼接，当层数越高时，输出通道数越来越大，参数和计算量也越来越大。
为了避免这个问题，需要引入过渡层将输出通道降低下来，同时将输入的长宽减半，这个过渡层可以使用1*1的卷积
transition block
"""</span>
<span class="token keyword">def</span> <span class="token function">transition_block</span><span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    trans_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>out_channel<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> trans_layer

<span class="token comment">#验证过渡层是否正确</span>
test_net <span class="token operator">=</span> transition_block<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output shape: {} x {} x {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
input shape: 3 x 96 x 96
output shape: 12 x 48 x 48
"""</span>

<span class="token keyword">class</span> <span class="token class-name">densenet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channel<span class="token punctuation">,</span>num_classes<span class="token punctuation">,</span>growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>block_layers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>densenet<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        channels<span class="token operator">=</span><span class="token number">64</span>
        block<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span>num_layers <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>block_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dense_block<span class="token punctuation">(</span>channels<span class="token punctuation">,</span>growth_rate<span class="token punctuation">,</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">)</span>
            channels<span class="token operator">+=</span>growth_rate
            <span class="token keyword">if</span> i<span class="token operator">!=</span>num_layers<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transition_block<span class="token punctuation">(</span>channels<span class="token punctuation">,</span>channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#大小减半，通道数减半</span>
                channels<span class="token operator">=</span>channels<span class="token operator">//</span><span class="token number">2</span>
        self<span class="token punctuation">.</span>block2<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>block<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block2<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'bn'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block2<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>block2<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'adg_pool'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>classifier<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>channels<span class="token punctuation">,</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>block1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>block2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span>  x

<span class="token comment">#测试</span>
test_net <span class="token operator">=</span> densenet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> test_net<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#output: torch.Size([1, 10])</span>
</code></pre> 
<h2><a id="_964"></a>卷积神经网络训练技巧</h2> 
<p>欠拟合：模型训练次数还不够或者模型太简单，没有拟合好真实的数据。<br> 解决办法:进行充分训练，或者增加模型的复杂度。</p> 
<p>过拟合：在训练集表现良好，但在测试集上表现不好。以下时减小过拟合的方法。</p> 
<h3><a id="_970"></a>数据增强</h3> 
<p>对训练数据进行扩充的方法，使模型具有不错的表达能力和泛化能力。<br> 当数据量不足时，模型陷入局部最优解、出现过拟合等现象。<br> <img src="https://images2.imgbox.com/38/9d/Wq7E1koP_o.png" width="30%" alt=""><br> <img src="https://images2.imgbox.com/df/81/dzsjj4KB_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/61/53/x5fkLbR5_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/27/94/gtLgpqjS_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/32/bd/3EEf2Anz_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/4a/49/ngl1WEWw_o.png" width="60%" alt=""></p> 
<p><img src="https://images2.imgbox.com/46/4a/ZkDFvzEO_o.png" width="60%" alt=""></p> 
<p><img src="https://images2.imgbox.com/6e/c5/bfki3dCe_o.png" width="60%" alt=""></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs

<span class="token comment">#读入一张图片</span>
im<span class="token operator">=</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./cat.png'</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
比例缩放 tfs.Resize(）
第一个参数可以是一个整数，图片会保存现在的宽和高的比例，并将更短的边缩放到这个整数的大小。
第一个参数可以是一个tuple(元组)，图片会直接把宽和高缩放到这个大小。
第二个参数表示放缩图片使用的方法，比如最近邻法，双线性差值。默认双线性差值，因其能保留图片更多信息
"""</span>
<span class="token comment">#比例缩放</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'before scale, shape: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
new_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'after scale, shape: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>new_im<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
before scale, shape: (224, 224)
after scale, shape: (200, 100)
"""</span>

<span class="token triple-quoted-string string">"""
随机位置截取 
tfs.RandomCrop() 传入参数是截取出的图片的长和宽，对图片在随机位置截取
tfs.CenterCrop() 传入截取出的图片的大小，再图片的中心进行截取
"""</span>
random_im1<span class="token operator">=</span>tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span>
random_im2<span class="token operator">=</span>tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机裁剪出150*100的区域</span>
center_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#中心裁剪出100*100的区域</span>

<span class="token triple-quoted-string string">"""
随机水平翻转
随机垂直翻转
"""</span>
h_flip<span class="token operator">=</span>tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机水平</span>
v_flip<span class="token operator">=</span>tfs<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机垂直</span>

<span class="token triple-quoted-string string">"""
随机角度翻转
第一个参数就是随机旋转的角度，-num~num
"""</span>
rot_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
亮度、对比度和颜色的变化
"""</span>
bright_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机从0~2之间亮度变化，1是原图</span>
contrast_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>contrast<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机从0~2之间对比度变化，1是原图</span>
color_im<span class="token operator">=</span>tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token comment">#随机从-0.5~0.5之间颜色变化，1是原图</span>

<span class="token triple-quoted-string string">"""
联合使用
"""</span>
im_aug<span class="token operator">=</span>tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment">#读入一张图片</span>
im<span class="token operator">=</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./cat.png'</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
联合使用
"""</span>
im_aug<span class="token operator">=</span>tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

nrows<span class="token operator">=</span><span class="token number">3</span>
ncols<span class="token operator">=</span><span class="token number">3</span>
figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span>figs<span class="token operator">=</span>plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token punctuation">,</span>ncols<span class="token punctuation">,</span>figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>im_aug<span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token punctuation">)</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_xaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#x轴标签不显示</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_yaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#y轴标签不显示</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#显示6张图</span>
</code></pre> 
<p>在Resnet进行训练</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train<span class="token punctuation">,</span> resnet
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs

<span class="token comment">#使用数据增强</span>
<span class="token keyword">def</span> <span class="token function">train_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug<span class="token operator">=</span>tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
        tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x<span class="token operator">=</span>im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

<span class="token keyword">def</span> <span class="token function">test_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
        tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>train_tf<span class="token punctuation">)</span>
train_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>test_tf<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> resnet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> test_data<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_1127"></a>学习率衰减</h3> 
<p><img src="https://images2.imgbox.com/3b/ef/odFHvKfK_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/13/d1/KrOE6Sp4_o.png" width="80%" alt=""><br> <img src="https://images2.imgbox.com/13/c4/Uiv63Bjk_o.png" width="50%" alt=""><br> 可以用<code>torch.optim.lr_scheduler</code><br> 更推荐以下这种</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> resnet
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs
<span class="token keyword">from</span> datetime <span class="token keyword">import</span> datetime
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#修改学习率</span>
<span class="token keyword">def</span> <span class="token function">set_learning_rate</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
        param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr

<span class="token comment">#使用数据增强</span>
<span class="token keyword">def</span> <span class="token function">train_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
<span class="token keyword">def</span> <span class="token function">test_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>train_tf<span class="token punctuation">)</span>
train_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
valid_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>test_tf<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>valid_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> resnet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

train_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
valid_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    net<span class="token operator">=</span>net<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

prev_time <span class="token operator">=</span> datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> epoch <span class="token operator">==</span> <span class="token number">20</span><span class="token punctuation">:</span>
        set_learning_rate<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span> <span class="token comment"># 20次之后学习率修改为0.01</span>

    net <span class="token operator">=</span> net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    train_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> im<span class="token punctuation">,</span> label <span class="token keyword">in</span> train_data<span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, 3, h, w)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, h, w)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">)</span>
        <span class="token comment"># forward</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        <span class="token comment"># backward</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    cur_time <span class="token operator">=</span> datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>
    h<span class="token punctuation">,</span> remainder <span class="token operator">=</span> <span class="token builtin">divmod</span><span class="token punctuation">(</span><span class="token punctuation">(</span>cur_time <span class="token operator">-</span> prev_time<span class="token punctuation">)</span><span class="token punctuation">.</span>seconds<span class="token punctuation">,</span> <span class="token number">3600</span><span class="token punctuation">)</span><span class="token comment">#商，余数</span>
    m<span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token builtin">divmod</span><span class="token punctuation">(</span>remainder<span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>
    time_str <span class="token operator">=</span> <span class="token string">"Time %02d:%02d:%02d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span> m<span class="token punctuation">,</span> s<span class="token punctuation">)</span>

    valid_loss <span class="token operator">=</span> <span class="token number">0</span>
    valid_acc <span class="token operator">=</span> <span class="token number">0</span>
    net <span class="token operator">=</span> net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> im<span class="token punctuation">,</span> label <span class="token keyword">in</span> valid_data<span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#volatile功能已被移除</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            output <span class="token operator">=</span> net<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        valid_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        epoch_str <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token string">"Epoch %d. Train Loss: %f, Valid Loss: %f, "</span>
            <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> train_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        prev_time <span class="token operator">=</span> cur_time

        train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
        valid_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>valid_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>epoch_str <span class="token operator">+</span> time_str<span class="token punctuation">)</span>

<span class="token comment">#画出loss曲线</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_losses<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>valid_losses<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
在第20次的时候，loss曲线陡降
"""</span>
</code></pre> 
<h3><a id="Dropout_1253"></a>Dropout</h3> 
<p><img src="https://images2.imgbox.com/4a/4f/MTY4qK1u_o.png" width="50%" alt=""><br> <img src="https://images2.imgbox.com/69/ab/s1K0f1td_o.png" width="50%" alt=""><br> <img src="https://images2.imgbox.com/2c/ed/FeQVE7BH_o.png" width="50%" alt=""><br> <img src="https://images2.imgbox.com/2f/9e/lAs86xqB_o.png" width="60%" alt=""></p> 
<h3><a id="_1264"></a>正则化</h3> 
<p><img src="https://images2.imgbox.com/f7/02/gCLMJeVP_o.png" width="60%" alt=""><br> <img src="https://images2.imgbox.com/5f/13/qcimGzjv_o.png" width="60%" alt=""></p> 
<pre><code class="prism language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre> 
<p>weight_decay是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         λ 
        
       
      
        \lambda 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">λ</span></span></span></span></span></p> 
<h3><a id="_1274"></a>微调进行迁移学习</h3> 
<p>fine_tuning<br> 把一个已经很厉害的模型再微调到我们自己的数据集。</p> 
<p>将与训练的模型导入，然后将最后的分类全连接层换成我们自己问题的全连接层，然后开始训练，<br> 可以固定卷积层的参数，也可以不固定进行训练，最后能够非常有效地得到结果。</p> 
<p>pytorch中内置了一些著名网络的预训练模型，模型都在<code>torchvision.models</code>里<br> 比如用预训练的50层resnet，可用<code>torchvision.models.resnet50[pretrained=True]</code><br> 因为对于图片识别分类任务，最底层的卷积识别的都是一些通用的特征，比如形状、纹理等，所以对于很多图像分类、识别任务，都可以用预训练的网络得到更好的结果。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> models
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> ImageFolder
<span class="token keyword">import</span> os
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token comment">#%matplotlib inline</span>

<span class="token triple-quoted-string string">"""
一个数据集，二分类问题,蚂蚁和蜜蜂
"""</span>
<span class="token comment">#可视化</span>
root_path <span class="token operator">=</span> <span class="token string">'./hymenoptera_data/train/'</span>
im_list<span class="token operator">=</span><span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span><span class="token string">'ant'</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>root_path<span class="token operator">+</span><span class="token string">'ant'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
im_list <span class="token operator">+=</span> <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'bees'</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>root_path <span class="token operator">+</span><span class="token string">'bees'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

nrows <span class="token operator">=</span> <span class="token number">3</span>
ncols <span class="token operator">=</span> <span class="token number">3</span>
figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span> figs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token punctuation">,</span> ncols<span class="token punctuation">,</span> figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>nrows<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ncols<span class="token punctuation">)</span><span class="token punctuation">:</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>im_list<span class="token punctuation">[</span>nrows<span class="token operator">*</span>i<span class="token operator">+</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_xaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        figs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_yaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#定义数据预处理</span>
train_tf <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
tfs<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 使用ImageNet的均值和方差</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

valid_tf <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 使用ImageFolder 定义数据集</span>
train_set <span class="token operator">=</span> ImageFolder<span class="token punctuation">(</span><span class="token string">'./hymenoptera_data/train/'</span><span class="token punctuation">,</span> train_tf<span class="token punctuation">)</span>
valid_set <span class="token operator">=</span> ImageFolder<span class="token punctuation">(</span><span class="token string">'./hymenoptera_data/val/'</span><span class="token punctuation">,</span> valid_tf<span class="token punctuation">)</span>
<span class="token comment"># 使用DataLoader 定义迭代器</span>
train_data <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token comment">#4个线程</span>
valid_data <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>valid_set<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment">#使用预训练的模型</span>
net <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet50<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

<span class="token comment">#打出第一层的权重</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>

<span class="token comment">#将最后的全连接层改为二分类</span>
net<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> valid_data<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>

<span class="token comment">#可视化预测的结果</span>
net<span class="token operator">=</span>net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将网络改为预测模式</span>

<span class="token comment">#读一张蚂蚁的图</span>
im1 <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./hymenoptera_data/train/ants/0013035.jpg'</span><span class="token punctuation">)</span>
im <span class="token operator">=</span> valid_tf<span class="token punctuation">(</span>im1<span class="token punctuation">)</span> <span class="token comment"># 做数据预处理</span>
out <span class="token operator">=</span> net<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>im<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred_label <span class="token operator">=</span> out<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment">#矩阵中最大的数对应的标签</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'predict label: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_set<span class="token punctuation">.</span>classes<span class="token punctuation">[</span>pred_label<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_1366"></a>灵活的数据读取</h3> 
<h4><a id="ImageFolder_1367"></a>ImageFolder</h4> 
<pre><code>torchvision.datasets.ImageFolder()
</code></pre> 
<p>按照分类将同一类的放到同一个文件夹中<br> 输入的是图片</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> ImageFolder
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> tfs

<span class="token comment">#三个文件夹，每个文件夹一个有3张图片作为例子</span>
folder_set<span class="token operator">=</span>ImageFolder<span class="token punctuation">(</span><span class="token string">'./example_data/image/'</span><span class="token punctuation">)</span>

<span class="token comment">#查看名称和类别下标的对应</span>
folder_set<span class="token punctuation">.</span>class_to_idx<span class="token comment">#{'class_1': 0, 'class_2': 1, 'class_3': 2}</span>

<span class="token comment">#得到所有的图片和标签</span>
folder_set<span class="token punctuation">.</span>images
<span class="token triple-quoted-string string">"""
[('./example_data/image/class_1/1.png', 0),
('./example_data/image/class_1/2.png', 0),
('./example_data/image/class_1/3.png', 0),
('./example_data/image/class_2/10.png', 1),
('./example_data/image/class_2/11.png', 1),
('./example_data/image/class_2/12.png', 1),
('./example_data/image/class_3/16.png', 2),
('./example_data/image/class_3/17.png', 2),
('./example_data/image/class_3/18.png', 2)]
"""</span>

<span class="token comment">#取出其中一个数据</span>
im<span class="token punctuation">,</span>label<span class="token operator">=</span>folder_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment">#传入数据预处理方式</span>
data_tf<span class="token operator">=</span>tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
folder_set<span class="token operator">=</span>ImageFolder<span class="token punctuation">(</span><span class="token string">'./example_data/image/'</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_tf<span class="token punctuation">)</span>
im<span class="token punctuation">,</span>label<span class="token operator">=</span>folder_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token triple-quoted-string string">"""
(0 ,.,.) =
0.2314 0.1686 0.1961 ... 0.6196 0.5961 0.5804
0.0627 0.0000 0.0706 ... 0.4824 0.4667 0.4784
0.0980 0.0627 0.1922 ... 0.4627 0.4706 0.4275
... ⋱ ...
0.8157 0.7882 0.7765 ... 0.6275 0.2196 0.2078
0.7059 0.6784 0.7294 ... 0.7216 0.3804 0.3255
0.6941 0.6588 0.7020 ... 0.8471 0.5922 0.4824
(1 ,.,.) =
0.2431 0.1804 0.1882 ... 0.5176 0.4902 0.4863
0.0784 0.0000 0.0314 ... 0.3451 0.3255 0.3412
0.0941 0.0275 0.1059 ... 0.3294 0.3294 0.2863
... ⋱ ...
0.6667 0.6000 0.6314 ... 0.5216 0.1216 0.1333
0.5451 0.4824 0.5647 ... 0.5804 0.2431 0.2078
0.5647 0.5059 0.5569 ... 0.7216 0.4627 0.3608
...
[torch.FloatTensor of size 3x32x32]
"""</span>
</code></pre> 
<h4><a id="Dataset_1425"></a>Dataset</h4> 
<p>输入的是txt</p> 
<pre><code>torch.utils.data.Dataset()
</code></pre> 
<p>其实<code>torchvision.datasets.ImageFolder()</code>是<code>torch.utils.data.Dataset()</code>的一个子类<br> 定义一个子类继承<code>Dataset</code>,重新定义<code>__getiems__()</code>和<code>__len__()</code>,前者表示按照下标取出其中一个数据，后者表示所有数据的总数。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset

<span class="token comment">#定义一个子类叫custom_dataset,继承Dataset</span>
<span class="token keyword">class</span> <span class="token class-name">custom_dataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>txt_path<span class="token punctuation">,</span>transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>transform<span class="token operator">=</span>transform <span class="token comment">#传入数据预处理</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>txt_path<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            lines<span class="token operator">=</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>img_list<span class="token operator">=</span><span class="token punctuation">[</span>i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>label_list<span class="token operator">=</span><span class="token punctuation">[</span>i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> lines<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>idx<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#根据idx取出其中一个</span>
        img<span class="token operator">=</span>self<span class="token punctuation">.</span>img_list<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        label<span class="token operator">=</span>self<span class="token punctuation">.</span>label_list<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            image<span class="token operator">=</span>self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        <span class="token keyword">return</span> img<span class="token punctuation">,</span>label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#总数有多少</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_list<span class="token punctuation">)</span>

txt_dataset<span class="token operator">=</span>custom_dataset<span class="token punctuation">(</span><span class="token string">'./example_data/train.txt'</span><span class="token punctuation">)</span><span class="token comment">#读入txt文件</span>

<span class="token comment">#取得其中一个数据</span>
data<span class="token punctuation">,</span>label<span class="token operator">=</span>txt_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
1009_2.png
YOU
"""</span>
</code></pre> 
<h4><a id="DataLoader_1465"></a>DataLoader</h4> 
<p>多线程迭代，batch<br> <img src="https://images2.imgbox.com/7c/11/ugj7qtnj_o.png" width="80%" alt=""></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_data1<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>folder_set<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#将2个数据作为一个batch</span>
<span class="token keyword">for</span> im<span class="token punctuation">,</span>label <span class="token keyword">in</span> train_data1<span class="token punctuation">:</span><span class="token comment">#访问迭代器</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
1
2
[torch.LongTensor of size 2]
0
1
[torch.LongTensor of size 2]
0
2
[torch.LongTensor of size 2]
0
2
[torch.LongTensor of size 2]
1
[torch.LongTensor of size 1]
一个9个数据，有5个batch，同时打乱顺序
"""</span>

<span class="token comment">#自定义数据</span>
train_data2<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>txt_dataset<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">## batch size 设置为 8</span>
im<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_data2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#使用这种方式来访问迭代器中第一个batch的数据</span>
</code></pre> 
<h4><a id="collate_fn_1497"></a>collate_fn</h4> 
<p>当需要将输出的label补成相同的长短，短的用0填充，就需要使用它来自定义batch的处理方式</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>reverse<span class="token operator">=</span><span class="token boolean">True</span> <span class="token punctuation">)</span><span class="token comment">#将数据集按照label的长度从大到小排序</span>
    img<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token comment">#将数据和label配对取出</span>
    <span class="token comment">#填充</span>
    pad_label<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    lens<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    max_len<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        temp_label<span class="token operator">=</span>label<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        temp_label<span class="token operator">+=</span><span class="token string">'0'</span><span class="token operator">*</span><span class="token punctuation">(</span>max_len<span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        pad_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_label<span class="token punctuation">)</span>
        lens<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> img<span class="token punctuation">,</span>pad_label<span class="token punctuation">,</span>lens<span class="token comment">#输出label的真实长度</span>

train_data3<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>txt_dataset<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">,</span>collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>
img<span class="token punctuation">,</span>label<span class="token punctuation">,</span>lens<span class="token operator">=</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_data3<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_1517"></a>批标准化</h3> 
<p><a href="https://blog.csdn.net/u010899985/article/details/82251932">BN详解</a></p> 
<p><img src="https://images2.imgbox.com/18/e0/kcvs3j3q_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bd/eb/n9ttj6zN_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/16/60/qO7dCwXC_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/76/6b/IlV4iNUo_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch

<span class="token keyword">def</span> <span class="token function">simple_batch_norm_1d</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>gamma<span class="token punctuation">,</span>beta<span class="token punctuation">)</span><span class="token punctuation">:</span>
    eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span>
    x_mean<span class="token operator">=</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#列向量，保留维度进行broadcast,均值</span>
    x_var<span class="token operator">=</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">-</span>x_mean<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    x_var<span class="token operator">=</span>torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>x_var<span class="token operator">+</span>eps<span class="token punctuation">)</span><span class="token comment">#标准差</span>
    x_hat<span class="token operator">=</span><span class="token punctuation">(</span>x<span class="token operator">-</span>x_mean<span class="token punctuation">)</span><span class="token operator">/</span>x_var
    <span class="token keyword">return</span> gamma<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span><span class="token operator">*</span>x_hat<span class="token operator">+</span>beta<span class="token punctuation">.</span>vie_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span><span class="token comment">#将gamma,beta变为和均值一个大小</span>

<span class="token comment">#验证对于任意输入，输出是否能标准化</span>
x<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
gamma<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
beta<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'before bn: '</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
y<span class="token operator">=</span>simple_batch_norm_1d<span class="token punctuation">(</span>x<span class="token punctuation">,</span>gamma<span class="token punctuation">,</span>beta<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'after bn: '</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
before bn:
0 1 2
3 4 5
6 7 8
9 10 11
12 13 14
[torch.FloatTensor of size 5x3]

after bn:
-1.4142 -1.4142 -1.4142
-0.7071 -0.7071 -0.7071
0.0000 0.0000 0.0000
0.7071 0.7071 0.7071
1.4142 1.4142 1.4142
[torch.FloatTensor of size 5x3]
5个数据点，三个特征，每一列表示一个特征 的不同数据点
"""</span>
</code></pre> 
<p>测试的适合该使用批标准化，否则会导致结果出现偏差。<br> 测试的时候不能用测试的数据集去算均值和方差，而是用训练时算出的移动平均均值和方差去代替<br> 用一下能区分训练状态和测试状态的批标准化方法</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token keyword">def</span> <span class="token function">batch_norm_1d</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> is_training<span class="token punctuation">,</span> moving_mean<span class="token punctuation">,</span> moving_var<span class="token punctuation">,</span>moving_momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span>
    x_mean<span class="token operator">=</span>torch<span class="token punctuation">.</span>means<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#保留维度进行broadcast</span>
    x_var<span class="token operator">=</span>torch<span class="token punctuation">.</span>means<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">-</span>x_mean<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> is_training<span class="token punctuation">:</span>
        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> x_mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>x_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        moving_mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>moving_momentum<span class="token operator">*</span>moving_mean<span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">-</span>moving_momentum<span class="token punctuation">)</span><span class="token operator">*</span>x_mean
        moving_var<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> moving_momentum <span class="token operator">*</span> moving_var <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">-</span> moving_momentum<span class="token punctuation">)</span> <span class="token operator">*</span> x_var
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> moving_mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>moving_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    <span class="token keyword">return</span> gamma<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span> <span class="token operator">*</span> x_hat <span class="token operator">+</span> beta<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="pytorch_1582"></a>pytorch实现</h4> 
<p>使用批标准化的情况能够更快地收敛。<br> mnist数据集</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist <span class="token comment"># 导入pytorch内置的mnist</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> utils <span class="token keyword">import</span> train

<span class="token keyword">def</span> <span class="token function">batch_norm_1d</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> is_training<span class="token punctuation">,</span> moving_mean<span class="token punctuation">,</span> moving_var<span class="token punctuation">,</span>moving_momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span>
    x_mean<span class="token operator">=</span>torch<span class="token punctuation">.</span>means<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#保留维度进行broadcast</span>
    x_var<span class="token operator">=</span>torch<span class="token punctuation">.</span>means<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">-</span>x_mean<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> is_training<span class="token punctuation">:</span>
        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> x_mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>x_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        moving_mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>moving_momentum<span class="token operator">*</span>moving_mean<span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">-</span>moving_momentum<span class="token punctuation">)</span><span class="token operator">*</span>x_mean
        moving_var<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> moving_momentum <span class="token operator">*</span> moving_var <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">-</span> moving_momentum<span class="token punctuation">)</span> <span class="token operator">*</span> x_var
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> moving_mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>moving_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    <span class="token keyword">return</span> gamma<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span> <span class="token operator">*</span> x_hat <span class="token operator">+</span> beta<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>x_mean<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">data_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">0.5</span> <span class="token comment">#</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#拉平</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

<span class="token comment">#使用内置函数下载mnist数据集</span>
train_set <span class="token operator">=</span> mnist<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>data_tf<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_set <span class="token operator">=</span> mnist<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>data_tf<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_data <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">multi_network</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>multi_network<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>gamma<span class="token operator">=</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>beta <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>moving_mean <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>moving_var <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> batch_norm_1d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gamma<span class="token punctuation">,</span> self<span class="token punctuation">.</span>beta<span class="token punctuation">,</span> is_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>moving_mean<span class="token punctuation">,</span>self<span class="token punctuation">.</span>moving_var<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


net<span class="token operator">=</span>multi_network<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> test_data<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
gamma和beta可以作为参数进行训练，初始化为随机的高斯分布
moving_mean和moving_var都初始化为0，并不是更新的参数，训练完后，它们的值会变
"""</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>moving_mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
Variable containing:
0.5505
2.0835
0.0794
-0.1991
-0.9822
-0.5820
0.6991
-0.1292
2.9608
1.0826
[torch.FloatTensor of size 10]
"""</span>
</code></pre> 
<p>还可以有内置函数<code>torch.nn.BatchNorm1d()</code>和<code>torch.nn.BatchNorm2d()</code>，pytorch中将gamma、beta、moving_mean和moving_var都作为参数进行训练。</p> 
<h2><a id="TensorBoard_1667"></a>TensorBoard可视化</h2> 
<p>是tensorflow中非常好用的可视化工具<br> pytorch中也可以用。</p> 
<p>安装 tensorflow 和 tensorboardX</p> 
<pre><code class="prism language-python">pip install tensorflow
pip install tensorboradX
</code></pre> 
<p>画计算图不大支持，但可以画出loss曲线</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> CIFAR10
<span class="token keyword">from</span> utils <span class="token keyword">import</span> resnet
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token keyword">as</span> tfs
<span class="token keyword">from</span> datetime <span class="token keyword">import</span> datetime
<span class="token keyword">from</span> tensorboardX <span class="token keyword">import</span> SummaryWriter

<span class="token comment">#使用数据增强</span>
<span class="token keyword">def</span> <span class="token function">train_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

<span class="token keyword">def</span> <span class="token function">test_tf</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_aug <span class="token operator">=</span> tfs<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tfs<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tfs<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> im_aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

train_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>train_tf<span class="token punctuation">)</span>
train_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
valid_set <span class="token operator">=</span> CIFAR10<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>test_tf<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>valid_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> resnet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

writer<span class="token operator">=</span>SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_acc</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    total<span class="token operator">=</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    _<span class="token punctuation">,</span>pred_label<span class="token operator">=</span>output<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    num_correct<span class="token operator">=</span><span class="token punctuation">(</span>pred_label<span class="token operator">==</span>label<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> num_correct<span class="token operator">/</span>total

<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    net<span class="token operator">=</span>net<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

prev_time<span class="token operator">=</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_loss<span class="token operator">=</span><span class="token number">0</span>
    train_acc<span class="token operator">=</span><span class="token number">0</span>
    net<span class="token operator">=</span>net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> im<span class="token punctuation">,</span>label <span class="token keyword">in</span> train_data<span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            im<span class="token operator">=</span>Variable<span class="token punctuation">(</span>im<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">## (bs, 3, h, w)</span>
            label<span class="token operator">=</span>Variable<span class="token punctuation">(</span>label<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#(bs,h,w)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">)</span>  <span class="token comment">## (bs, 3, h, w)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">)</span>  <span class="token comment"># (bs,h,w)</span>
        <span class="token comment">#forward</span>
        out<span class="token operator">=</span>net<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
        loss<span class="token operator">=</span>criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span>label<span class="token punctuation">)</span>
        <span class="token comment">#backward</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss<span class="token operator">+=</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        train_acc<span class="token operator">+=</span>get_acc<span class="token punctuation">(</span>out<span class="token punctuation">,</span>label<span class="token punctuation">)</span>

    cur_time<span class="token operator">=</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>
    h<span class="token punctuation">,</span> remainder <span class="token operator">=</span> <span class="token builtin">divmod</span><span class="token punctuation">(</span><span class="token punctuation">(</span>cur_time <span class="token operator">-</span> prev_time<span class="token punctuation">)</span><span class="token punctuation">.</span>seconds<span class="token punctuation">,</span> <span class="token number">3600</span><span class="token punctuation">)</span>
    m<span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token builtin">divmod</span><span class="token punctuation">(</span>remainder<span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>
    time_str <span class="token operator">=</span> <span class="token string">"Time %02d:%02d:%02d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span> m<span class="token punctuation">,</span> s<span class="token punctuation">)</span>

    valid_loss <span class="token operator">=</span> <span class="token number">0</span>
    valid_acc <span class="token operator">=</span> <span class="token number">0</span>
    net <span class="token operator">=</span> net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> im<span class="token punctuation">,</span> label <span class="token keyword">in</span> valid_data<span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            im <span class="token operator">=</span> Variable<span class="token punctuation">(</span>im<span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            label <span class="token operator">=</span> Variable<span class="token punctuation">(</span>label<span class="token punctuation">,</span> volatile<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        valid_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        valid_acc <span class="token operator">+=</span> get_acc<span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>

    epoch_str <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc:%f, "</span>
                 <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> train_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span>train_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    valid_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    prev_time <span class="token operator">=</span> cur_time



<span class="token comment">#========================使用tensorboard===============================</span>
writer<span class="token punctuation">.</span>add_scalars<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">,</span><span class="token punctuation">{<!-- --></span><span class="token string">'train'</span><span class="token punctuation">:</span>train_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                           <span class="token string">'valid'</span><span class="token punctuation">:</span>valid_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>epoch<span class="token punctuation">)</span>

writer<span class="token punctuation">.</span>add_scalars<span class="token punctuation">(</span><span class="token string">'acc'</span><span class="token punctuation">,</span><span class="token punctuation">{<!-- --></span><span class="token string">'train'</span><span class="token punctuation">:</span>train_acc<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span>
                           <span class="token string">'valid'</span><span class="token punctuation">:</span>valid_acc<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_data<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>epoch<span class="token punctuation">)</span>
<span class="token comment">#========================================================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>epoch_str<span class="token operator">+</span>time_str<span class="token punctuation">)</span>
</code></pre> 
<p>训练完成后，目录中会出现一个文件夹叫runs,在终端运行</p> 
<pre><code class="prism language-python">tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir runs
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/64697e6f28b0b245619918f1f3e6da4d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">狗追慢跑者</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7c13e4057eb0eeabf5ed179c8c65eff3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">CentOS7中离线安装MySQL5.7</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>