<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python毕设选题 - 机器学习新闻算法实现 - python机器学习 深度学习 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python毕设选题 - 机器学习新闻算法实现 - python机器学习 深度学习" />
<meta property="og:description" content="文章目录 0 前言简介本文章博主将介绍: 参与及比较算法先说结论实现过程数据爬取数据预处理 CNN文本分类其他分类方法更新中....... 最后 0 前言 🔥 这两年开始毕业设计和毕业答辩的要求和难度不断提升，传统的毕设题目缺少创新和亮点，往往达不到毕业答辩的要求，这两年不断有学弟学妹告诉学长自己做的项目系统达不到老师的要求。
为了大家能够顺利以及最少的精力通过毕设，学长分享优质毕业设计项目，今天要分享的是
🚩 机器学习新闻算法实现
🥇学长这里给一个题目综合评分(每项满分5分)
难度系数：3分工作量：3分创新点：3分 简介 新闻分类课题是在算法类毕业设计中比较热门的, 本质上是属于自然语言分类, 可以使用机器学习算法去处理, 也可以使用深度学习算法去处理.
基本步骤如下 :
文本数据采集 --&gt; 选择训练算法(机器学习/深度学习) --&gt; 进行训练 --&gt; 检效果.
本文章博主将介绍: 从头开始实践中文短文本分类运用多种机器学习（深度学习 &#43; 传统机器学习）方法比较短文本分类处理过程与结果差别 参与及比较算法 使用下面的算法来进行文本分类, 并对最后分类准确率进行比较
CNN 、 CNN &#43; word2vecLSTM 、 LSTM &#43; word2vecMLP（多层感知机）朴素贝叶斯KNNSVMSVM &#43; word2vec 、SVM &#43; doc2vec 先说结论 引入预训练的 word2vec 模型会给训练带来好处，具体来说：（1）间接引入外部训练数据，防止过拟合；（2）减少需要训练的参数个数，提高训练效率LSTM 需要训练的参数个数远小于 CNN，但训练时间大于 CNN。CNN 在分类问题的表现上一直很好，无论是图像还是文本；而想让 LSTM 优势得到发挥，首先让训练数据量得到保证将单词在 word2vec 中的词向量加和求平均获得整个句子的语义向量的方法看似 naive 有时真挺奏效，当然仅限于短句子，长度 100 以内应该问题不大机器学习方法万千，具体选择用什么样的方法还是要取决于数据集的规模以及问题本身的复杂度，对于复杂程度一般的问题，看似简单的方法有可能是坠吼地 实现过程 数据爬取 爬虫这里不公开提供, 爬取的是各大新闻网站数据, 需要的联系博主获取, 联系方式在文章最下方~" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b76ec61892a33cd109c267b0bd5f6fa9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-26T14:52:10+08:00" />
<meta property="article:modified_time" content="2024-01-26T14:52:10+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python毕设选题 - 机器学习新闻算法实现 - python机器学习 深度学习</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0__4" rel="nofollow">0 前言</a></li><li><ul><li><ul><li><ul><li><a href="#_24" rel="nofollow">简介</a></li><li><ul><li><ul><li><a href="#_32" rel="nofollow">本文章博主将介绍:</a></li></ul> 
     </li></ul> 
     </li><li><a href="#_39" rel="nofollow">参与及比较算法</a></li><li><a href="#_52" rel="nofollow">先说结论</a></li><li><a href="#_65" rel="nofollow">实现过程</a></li><li><ul><li><a href="#_67" rel="nofollow">数据爬取</a></li><li><a href="#_71" rel="nofollow">数据预处理</a></li></ul> 
     </li><li><a href="#CNN_98" rel="nofollow">CNN文本分类</a></li><li><a href="#_175" rel="nofollow">其他分类方法更新中.......</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#_180" rel="nofollow">最后</a></li></ul> 
</div> 
<p></p> 
<hr color="#000000" size='1"'> 
<h2><a id="0__4"></a>0 前言</h2> 
<p>🔥 这两年开始毕业设计和毕业答辩的要求和难度不断提升，传统的毕设题目缺少创新和亮点，往往达不到毕业答辩的要求，这两年不断有学弟学妹告诉学长自己做的项目系统达不到老师的要求。</p> 
<p>为了大家能够顺利以及最少的精力通过毕设，学长分享优质毕业设计项目，今天要分享的是</p> 
<p>🚩 <strong>机器学习新闻算法实现</strong></p> 
<p>🥇学长这里给一个题目综合评分(每项满分5分)</p> 
<ul><li>难度系数：3分</li><li>工作量：3分</li><li>创新点：3分</li></ul> 
<h5><a id="_24"></a>简介</h5> 
<p>新闻分类课题是在算法类毕业设计中比较热门的, 本质上是属于自然语言分类, 可以使用机器学习算法去处理, 也可以使用深度学习算法去处理.</p> 
<p>基本步骤如下 :</p> 
<p>文本数据采集 --&gt; 选择训练算法(机器学习/深度学习) --&gt; 进行训练 --&gt; 检效果.</p> 
<h6><a id="_32"></a>本文章博主将介绍:</h6> 
<ul><li>从头开始实践中文短文本分类</li><li>运用多种机器学习（深度学习 + 传统机器学习）方法比较短文本分类处理过程与结果差别</li></ul> 
<h5><a id="_39"></a>参与及比较算法</h5> 
<p>使用下面的算法来进行文本分类, 并对最后分类准确率进行比较</p> 
<ul><li>CNN 、 CNN + word2vec</li><li>LSTM 、 LSTM + word2vec</li><li>MLP（多层感知机）</li><li>朴素贝叶斯</li><li>KNN</li><li>SVM</li><li>SVM + word2vec 、SVM + doc2vec</li></ul> 
<h5><a id="_52"></a>先说结论</h5> 
<p><img src="https://images2.imgbox.com/7f/8e/0qTZYCQ5_o.png" alt="在这里插入图片描述"></p> 
<ul><li>引入预训练的 word2vec 模型会给训练带来好处，具体来说：（1）间接引入外部训练数据，防止过拟合；（2）减少需要训练的参数个数，提高训练效率</li><li>LSTM 需要训练的参数个数远小于 CNN，但训练时间大于 CNN。CNN 在分类问题的表现上一直很好，无论是图像还是文本；而想让 LSTM 优势得到发挥，首先让训练数据量得到保证</li><li>将单词在 word2vec 中的词向量加和求平均获得整个句子的语义向量的方法看似 naive 有时真挺奏效，当然仅限于短句子，长度 100 以内应该问题不大</li><li>机器学习方法万千，具体选择用什么样的方法还是要取决于数据集的规模以及问题本身的复杂度，对于复杂程度一般的问题，看似简单的方法有可能是坠吼地</li></ul> 
<h5><a id="_65"></a>实现过程</h5> 
<h6><a id="_67"></a>数据爬取</h6> 
<p>爬虫这里不公开提供, 爬取的是各大新闻网站数据, 需要的联系博主获取, 联系方式在文章最下方~</p> 
<h6><a id="_71"></a>数据预处理</h6> 
<p>将下载的原始数据进行转码，然后给文本标类别的标签，然后制作训练与测试数据，然后控制文本长度，分词，去标点符号</p> 
<p>哎，坑多，费事，比较麻烦</p> 
<p>首先，下载下来是 xml 格式，并且是 GBK （万恶之源）编码，需要转成 UTF8，并整理成 json 方便处理。原始数据长这个样：</p> 
<p><img src="https://images2.imgbox.com/c5/d5/HlRG2yPl_o.png" alt="在这里插入图片描述"></p> 
<p>对成功标出来的15个类的新闻，统计一下类别的分布，结果如下：<br> <img src="https://images2.imgbox.com/1a/31/d2nSSqoB_o.png" alt="在这里插入图片描述"></p> 
<p>分布比较不均，第 14 类和第 15 类的新闻很少，另外第 8 类和第 11 类一个新闻也没有</p> 
<p>所以最后选了剩下的11个类，每个类抽2000个新闻，按4：1分成训练与测试，如图</p> 
<p><img src="https://images2.imgbox.com/aa/2c/NvCvUReP_o.png" alt="在这里插入图片描述"><br> 上一步选出来的训练新闻长这样，因为考虑到新闻标题的意义重大，这里就将新闻标题和新闻内容接到一起，用空格隔开，然后截取每条新闻的前 100 个字</p> 
<p><img src="https://images2.imgbox.com/48/7e/HZ6FVoCD_o.png" alt="在这里插入图片描述"><br> 最后得到以下结果文件：（1）新闻文本数据，每行 1 条新闻，每条新闻由若干个词组成，词之间以空格隔开，训练文本 17600 行，测试文本 4324 行；（2）新闻标签数据，每行 1 个数字，对应这条新闻所属的类别编号，训练标签 17600行，测试标签 4324 行</p> 
<h5><a id="CNN_98"></a>CNN文本分类</h5> 
<p>深度学习用的 keras 工具，操作简单易懂，模型上手飞快，居家旅行必备。keras 后端用的 Tensorflow，虽然用什么都一样</p> 
<p>首先一些先设定一些会用到的参数</p> 
<pre><code class="prism language-python">MAX_SEQUENCE_LENGTH <span class="token operator">=</span> <span class="token number">100</span> <span class="token comment"># 每条新闻最大长度</span>
EMBEDDING_DIM <span class="token operator">=</span> <span class="token number">200</span> <span class="token comment"># 词向量空间维度</span>
VALIDATION_SPLIT <span class="token operator">=</span> <span class="token number">0.16</span> <span class="token comment"># 验证集比例</span>
TEST_SPLIT <span class="token operator">=</span> <span class="token number">0.2</span> <span class="token comment"># 测试集比例</span>
</code></pre> 
<p>第一步先把训练与测试数据放在一起提取特征，使用 keras 的 Tokenizer 来实现，将新闻文档处理成单词索引序列，单词与序号之间的对应关系靠单词的索引表 word_index 来记录，这里从所有新闻中提取到 65604 个单词，比如 [苟，国家，生死] 就变成了 [1024, 666, 233] ；然后将长度不足 100 的新闻用 0 填充（在前端填充），用 keras 的 pad_sequences 实现；最后将标签处理成 one-hot 向量，比如 6 变成了 [0,0,0,0,0,0,1,0,0,0,0,0,0]，用 keras 的 to_categorical 实现</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text <span class="token keyword">import</span> Tokenizer
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence <span class="token keyword">import</span> pad_sequences
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_categorical
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>all_texts<span class="token punctuation">)</span>
sequences <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>all_texts<span class="token punctuation">)</span>
word_index <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>word_index
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Found %s unique tokens.'</span> <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word_index<span class="token punctuation">)</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> maxlen<span class="token operator">=</span>MAX_SEQUENCE_LENGTH<span class="token punctuation">)</span>
labels <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>all_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Shape of data tensor:'</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Shape of label tensor:'</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p>再将处理后的新闻数据按 6.4：1.6：2 分为训练集，验证集，测试集</p> 
<pre><code class="prism language-python">p1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>VALIDATION_SPLIT<span class="token operator">-</span>TEST_SPLIT<span class="token punctuation">)</span><span class="token punctuation">)</span>
p2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>TEST_SPLIT<span class="token punctuation">)</span><span class="token punctuation">)</span>
x_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span>p1<span class="token punctuation">]</span>
y_train <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>p1<span class="token punctuation">]</span>
x_val <span class="token operator">=</span> data<span class="token punctuation">[</span>p1<span class="token punctuation">:</span>p2<span class="token punctuation">]</span>
y_val <span class="token operator">=</span> labels<span class="token punctuation">[</span>p1<span class="token punctuation">:</span>p2<span class="token punctuation">]</span>
x_test <span class="token operator">=</span> data<span class="token punctuation">[</span>p2<span class="token punctuation">:</span><span class="token punctuation">]</span>
y_test <span class="token operator">=</span> labels<span class="token punctuation">[</span>p2<span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token keyword">print</span> <span class="token string">'train docs: '</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token string">'val docs: '</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_val<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token string">'test docs: '</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>然后就是搭建模型，首先是一个将文本处理成向量的 embedding 层，这样每个新闻文档被处理成一个 100 x 200 的二维向量，100 是每条新闻的固定长度，每一行的长度为 200 的行向量代表这个单词在空间中的词向量。下面通过 1 层卷积层与池化层来缩小向量长度，再加一层 Flatten 层将 2 维向量压缩到 1 维，最后通过两层 Dense（全连接层）将向量长度收缩到 12 上，对应新闻分类的 12 个类（其实只有 11 个类，标签 0 没有用到）。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Input<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dropout
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv1D<span class="token punctuation">,</span> MaxPooling1D<span class="token punctuation">,</span> Embedding
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential

model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>word_index<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> EMBEDDING_DIM<span class="token punctuation">,</span> input_length<span class="token operator">=</span>MAX_SEQUENCE_LENGTH<span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv1D<span class="token punctuation">(</span><span class="token number">250</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling1D<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>EMBEDDING_DIM<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>网络模型如下</strong><br> <img src="https://images2.imgbox.com/5b/15/lMQOcN0F_o.png" alt="在这里插入图片描述"></p> 
<p><strong>实验结果如下</strong></p> 
<p><img src="https://images2.imgbox.com/41/57/lRpaFs7S_o.png" alt="在这里插入图片描述"><br> 准确度 0.81459521</p> 
<p>拥有11个分类的问题达到这个准确度，应该也不错（易满足）。并且搜狗给的数据本来也不是很好（甩锅）。可以看到在训练集上的准确度达到了 0.88，但是测试集上的准确度只有 0.81，说明还是有些过拟合。另外，整个模型需要训练的参数接近 1500 万，其中 1300 万都是 embedding 层的参数，说明如果利用 word2vec 模型替换 embedding 层，解放这 1300 万参数，肯定会让训练效率得到提高</p> 
<h5><a id="_175"></a>其他分类方法更新中…</h5> 
<h2><a id="_180"></a>最后</h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2d1298c10c206f19f961bc0cc98942cf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">75.导入报错:ORA-31644: 无法定位块编号 549045</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d81c4e2a5523693881948a302ad88238/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">纯血鸿蒙（HarmonyOS3.1）入门教程 未完待续......</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>