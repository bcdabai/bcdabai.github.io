<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>网络爬虫——urllib（4）文末好书推荐 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="网络爬虫——urllib（4）文末好书推荐" />
<meta property="og:description" content="前言🍭 ❤️❤️❤️网络爬虫专栏更新中，各位大佬觉得写得不错，支持一下，感谢了！❤️❤️❤️
Python网络爬虫_热爱编程的林兮的博客-CSDN博客
上篇我们讲解了百度详细翻译这个案例，这篇同样也是进行案例讲解。
9.ajax的get请求🍉 Ⅰ、ajax的get请求请求豆瓣电影第一页🍓 我们打开豆瓣电影，随便打开一个排行榜（电影-&gt;剧情）
豆瓣电影分类排行榜 - 剧情片 (douban.com)
​
我们F12，打开开发者工具
打开第一个接口，可以看到只有网页，没有数据，我们继续找
​
找到下面这个，发现了“肖申克的救赎” ，但是这个只有一个数据啊，继续找
​
我们又找到一个，有20个数据（都是json格式的，因为它给我们返回的就是json数据，前后端分离），我们打开来看看
​
前面两个是 肖申克的救赎 和 霸王别姬
​
最后一个（第二十个）是 海上钢琴师 ​
果然 第二十部电影是 海上钢琴师 ​
这个接口就是我们想要的数据，好下面我们来写代码：
​
这是get请求，我们就按get请求来做。
# get请求 # 获取豆瓣电影的第一页的数据 并且保存起来 import urllib.request # header中的url url = &#39;https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20&#39; headers = { &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36&#39; } # (1) 请求对象的定制 request = urllib." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/2c9fd2db9fd4974c5d2e46848ed603a7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-31T17:06:04+08:00" />
<meta property="article:modified_time" content="2023-10-31T17:06:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">网络爬虫——urllib（4）文末好书推荐</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E5%89%8D%E8%A8%80%F0%9F%8D%AD">前言🍭</h2> 
<blockquote> 
 <p style="text-align:center;"> ❤️❤️❤️网络爬虫专栏更新中，各位大佬觉得写得不错，支持一下，感谢了！❤️❤️❤️</p> 
 <p style="text-align:center;"><a href="https://blog.csdn.net/m0_63951142/category_12449453.html" title="Python网络爬虫_热爱编程的林兮的博客-CSDN博客">Python网络爬虫_热爱编程的林兮的博客-CSDN博客</a></p> 
</blockquote> 
<p> 上篇我们讲解了百度详细翻译这个案例，这篇同样也是进行案例讲解。</p> 
<h3 id="9.ajax%E7%9A%84get%E8%AF%B7%E6%B1%82%F0%9F%8D%89">9.ajax的get请求🍉</h3> 
<h4 id="%E2%85%A0%E3%80%81ajax%E7%9A%84get%E8%AF%B7%E6%B1%82%E8%AF%B7%E6%B1%82%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E7%AC%AC%E4%B8%80%E9%A1%B5%F0%9F%8D%93">Ⅰ、ajax的get请求请求豆瓣电影第一页🍓</h4> 
<p>我们打开豆瓣电影，随便打开一个排行榜（电影-&gt;剧情）</p> 
<p><a href="https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=" rel="nofollow" title="豆瓣电影分类排行榜 - 剧情片 (douban.com)">豆瓣电影分类排行榜 - 剧情片 (douban.com)</a></p> 
<div> 
 <p><img alt="" height="930" src="https://images2.imgbox.com/82/dc/qQ31o7Hg_o.png" width="1200">​</p> 
</div> 
<p>我们F12，打开开发者工具</p> 
<p>打开第一个接口，可以看到只有网页，没有数据，我们继续找</p> 
<p><img alt="" height="709" src="https://images2.imgbox.com/00/e5/iqO7BIS0_o.png" width="1200">​</p> 
<p>找到下面这个，发现了“肖申克的救赎” ，但是这个只有一个数据啊，继续找</p> 
<div> 
 <p><img alt="" height="475" src="https://images2.imgbox.com/e5/7d/XKfrmkgm_o.png" width="1194">​</p> 
</div> 
<p> 我们又找到一个，有20个数据（都是json格式的，因为它给我们返回的就是json数据，前后端分离），我们打开来看看</p> 
<div> 
 <p><img alt="" height="702" src="https://images2.imgbox.com/7d/0c/dAgxlAmp_o.png" width="1200">​</p> 
</div> 
<p> 前面两个是 <span style="color:#fe2c24;">肖申克的救赎</span> 和 <span style="color:#fe2c24;">霸王别姬</span></p> 
<div> 
 <p><img alt="" height="706" src="https://images2.imgbox.com/d7/35/2x2vFv3g_o.png" width="1200">​</p> 
</div> 
<p>最后一个（第二十个）是 <span style="color:#fe2c24;">海上钢琴师 </span></p> 
<div> 
 <p><img alt="" height="600" src="https://images2.imgbox.com/7c/1c/8WeslGRg_o.png" width="1200">​</p> 
</div> 
<p>果然 第二十部电影是 海上钢琴师 </p> 
<div> 
 <p><img alt="" height="930" src="https://images2.imgbox.com/1e/03/4ePsOfm3_o.png" width="1200">​</p> 
</div> 
<p>这个接口就是我们想要的数据，好下面我们来写代码：</p> 
<div> 
 <p><img alt="" height="930" src="https://images2.imgbox.com/53/2d/FqmtqbGv_o.png" width="1200">​</p> 
</div> 
<p> 这是get请求，我们就按get请求来做。</p> 
<div> 
 <pre><code class="language-python"># get请求
# 获取豆瓣电影的第一页的数据 并且保存起来

import urllib.request

# header中的url
url = 'https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
}

# (1) 请求对象的定制
request = urllib.request.Request(url=url, headers=headers)

# （2）获取响应的数据
response = urllib.request.urlopen(request)
content = response.read().decode('utf-8')

print(content)</code></pre> 
</div> 
<p>我们先打印出来，看看有什么问题</p> 
<div> 
 <p><img alt="" height="391" src="https://images2.imgbox.com/ce/f8/m6ouvDzT_o.png" width="1200">​</p> 
</div> 
<p>好像没问题，我们继续写代码，我们将json数据下载下来：</p> 
<div> 
 <pre><code class="language-python"># get请求
# 获取豆瓣电影的第一页的数据 并且保存起来

import urllib.request

# header中的url
url = 'https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
}

# (1) 请求对象的定制
request = urllib.request.Request(url=url, headers=headers)

# （2）获取响应的数据
response = urllib.request.urlopen(request)
content = response.read().decode('utf-8')

# print(content)
# (3) 数据下载到本地
# open方法默认情况下使用的是gbk的编码  如果我们要想保存汉字 那么需要在open方法中指定编码格式为utf-8

with open('douban1.json', 'w', encoding='utf-8') as fp:
    fp.write(content)
</code></pre> 
</div> 
<p> 运行代码，然后就下载好了，我们将前20条数据下载好了：</p> 
<div> 
 <p><img alt="" height="370" src="https://images2.imgbox.com/93/b8/Hhb5zHoA_o.png" width="1200">​</p> 
</div> 
<p> 下面我们来下载豆瓣电影的前十页</p> 
<h4 id="%C2%A0%E2%85%A1%E3%80%81ajax%E7%9A%84get%E8%AF%B7%E6%B1%82%E8%AF%B7%E6%B1%82%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E5%89%8D%E5%8D%81%E9%A1%B5%F0%9F%8D%93"> Ⅱ、ajax的get请求请求豆瓣电影前十页🍓</h4> 
<p> 我们在上面知道了，豆瓣电影中一组数据有20部电影，我们继续往下滑，它还有第21部，22部电影</p> 
<div> 
 <p><img alt="" height="839" src="https://images2.imgbox.com/89/17/oy5pG9Db_o.png" width="1200">​</p> 
</div> 
<p>同样的我们去 开发者工具中找到第二组数据：</p> 
<p><img alt="" height="445" src="https://images2.imgbox.com/37/a4/0s36gFJe_o.png" width="1200">​ 同样的我们去找第三组第四组数据：</p> 
<div> 
 <pre><code class="language-python"># https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=20&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=40&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=60&amp;limit=20
</code></pre> 
</div> 
<p>然后去观察规律</p> 
<p>我们发现只有start的键值对 的值不一样，很明显可以看出start值是（page-1）*20</p> 
<p>从这里我们就找到了start和page的关系</p> 
<p>下面我们来写代码</p> 
<div> 
 <pre><code class="language-python"># https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=20&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=40&amp;limit=20
# https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=60&amp;limit=20

# start （page - 1）*20

import urllib.parse
import urllib.request


def create_request(page):
    base_url = 'https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;'

    data = {
        'start': (page - 1) * 20,
        'limit': 20
    }

    data = urllib.parse.urlencode(data)

    url = base_url + data

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
    }

    request = urllib.request.Request(url=url, headers=headers)
    return request


def get_content(request):
    response = urllib.request.urlopen(request)
    content = response.read().decode('utf-8')
    return content

# page强制类型转换 否则拼接不上
def down_load(page, content):
    with open('douban_' + str(page) + '.json', 'w', encoding='utf-8') as fp:
        fp.write(content)


# 程序的入口
if __name__ == '__main__':
    start_page = int(input('请输入起始的页码'))
    end_page = int(input('请输入结束的页面'))

    for page in range(start_page, end_page + 1):
        #         每一页都有自己的请求对象的定制
        request = create_request(page)
        #         获取响应的数据
        content = get_content(request)
        #         下载
        down_load(page, content)
</code></pre> 
</div> 
<p>运行代码我们就将前十页json数据都下载好了 </p> 
<p><img alt="" height="285" src="https://images2.imgbox.com/ed/7b/KTfIu36h_o.png" width="1200">​</p> 
<h3 id="10.ajax%E7%9A%84post%E8%AF%B7%E6%B1%82%C2%A0%F0%9F%8D%89">10.ajax的post请求 🍉</h3> 
<p>下面我们来爬取一下KFC，查看一下北京这个城市哪个位置有KFC，并且保存数据。</p> 
<p><a href="http://www.kfc.com.cn/kfccda/storelist/index.aspx" rel="nofollow" title="肯德基餐厅信息查询 (kfc.com.cn)">肯德基餐厅信息查询 (kfc.com.cn)</a></p> 
<div> 
 <p><img alt="" height="930" src="https://images2.imgbox.com/2f/ad/oBlMQIPR_o.png" width="1200">​</p> 
</div> 
<p> 可以看到这里有很多KFC店</p> 
<div> 
 <p><img alt="" height="637" src="https://images2.imgbox.com/0d/8d/np8KZe94_o.png" width="1200">​</p> 
</div> 
<p>我们查看url，同时也可以看到这是POST请求</p> 
<div> 
 <p><img alt="" height="446" src="https://images2.imgbox.com/07/09/F1ADFPdH_o.png" width="1200">​</p> 
</div> 
<p> 一样的，我们观察不同页数的url区别 </p> 
<div> 
 <pre><code class="language-python"># 1页
# http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname
# post
表单数据
# cname: 北京
# pid:
# pageIndex: 1
# pageSize: 10


# 2页
# http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname
# post
表单数据
# cname: 北京
# pid:
# pageIndex: 2
# pageSize: 10</code></pre> 
</div> 
<p> 下面我们来写代码，去爬取北京KFC位置信息</p> 
<div> 
 <pre><code class="language-python"># 1页
# http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname
# post
# cname: 北京
# pid:
# pageIndex: 1
# pageSize: 10


# 2页
# http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname
# post
# cname: 北京
# pid:
# pageIndex: 2
# pageSize: 10

import urllib.request
import urllib.parse


def create_request(page):
    base_url = 'http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname'

    data = {
        'cname': '北京',
        'pid': '',
        'pageIndex': page,
        'pageSize': '10'
    }

    data = urllib.parse.urlencode(data).encode('utf-8')

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
    }

    request = urllib.request.Request(url=base_url, headers=headers, data=data)

    return request


def get_content(request):
    response = urllib.request.urlopen(request)
    content = response.read().decode('utf-8')
    return content


def down_load(page, content):
    with open('kfc_' + str(page) + '.json', 'w', encoding='utf-8') as fp:
        fp.write(content)


if __name__ == '__main__':
    start_page = int(input('请输入起始页码'))
    end_page = int(input('请输入结束页码'))

    for page in range(start_page, end_page + 1):
        # 请求对象的定制
        request = create_request(page)
        # 获取网页源码
        content = get_content(request)
        # 下载
        down_load(page, content)
</code></pre> 
</div> 
<p> 运行代码，我们就爬取好了，数据也能对上</p> 
<div> 
 <p><img alt="" height="280" src="https://images2.imgbox.com/e5/7f/thQuGKDd_o.png" width="1200">​</p> 
</div> 
<h2 id="%C2%A0%E6%96%87%E6%9C%AB%E9%80%81%E4%B9%A6ChatGPT%E8%BF%9B%E9%98%B6%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%85%A5%E9%97%A8"> 好书推荐：<strong><span style="color:#000000;"><strong>ChatGPT进阶：提示工程入门</strong></span></strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">爆火全网的原创提示词设计框架BROKE，带你5步掌握向人工智能提问的艺术，从小白变身ChatGPT应用专家，将AI转化为生产工具，重塑你的工作流！</p> 
<p class="img-center"><img alt="" height="542" src="https://images2.imgbox.com/40/29/NXjb96vP_o.jpg" width="542"></p> 
<h4 style="margin-left:.0001pt;text-align:center;"><strong><span style="color:#0070c0;"><strong>内容简介</strong></span></strong></h4> 
<p style="margin-left:.0001pt;text-align:left;"><span style="color:#221e1f;">本书是一本面向所有人的提示工程工具书，旨在帮助你掌握并有效利用以ChatGPT为代表的AI工具。学习完本书后，你将能够自如地将ChatGPT运用在生活和专业领域中，成为ChatGPT进阶玩家。</span></p> 
<p style="margin-left:.0001pt;text-align:left;"><span style="color:#221e1f;">本书共分为9章，内容涵盖三个层次：介绍与解读、入门学习、进阶提升。第1～2章深入介绍与剖析了ChatGPT与提示工程，并从多个学科的角度探讨了提示工程学科。第3～5章演示了ChatGPT的实际运用，教你如何使用ChatGPT解决自然语言处理问题，并为你提供了一套可操作、可重复的提示设计框架，让你能够熟练驾驭ChatGPT。第6～9章讲解了来自学术界的提示工程方法，以及如何围绕ChatGPT进行创新；此外，为希望ChatGPT进行应用开发的读者提供了实用的参考资料，并介绍了除ChatGPT之外的其他选择。</span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#221e1f;">本书聚焦ChatGPT的实际应用，可操作，可重复，轻松易读却不失深度。无论你是对ChatGPT及类似工具充满好奇，还是期待将其转化为生产力，本书都值得一读。此外，本书还可作为相关培训机构的教材。</span></p> 
<h4 style="margin-left:.0001pt;text-align:justify;"><span style="color:#221e1f;">购买链接</span></h4> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#221e1f;">京东购买链接：<a class="link-info" href="https://item.jd.com/14098844.html" rel="nofollow" title="https://item.jd.com/14098844.html">https://item.jd.com/14098844.html</a></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#221e1f;">当当购买链接：<a class="link-info" href="http://product.dangdang.com/29612772.html" rel="nofollow" title="http://product.dangdang.com/29612772.html">http://product.dangdang.com/29612772.html</a></span></p> 
<h4>参与方式</h4> 
<blockquote> 
 <p style="text-align:center;">关注博主、点赞、收藏、评论区任意评论（评论折叠无效）</p> 
 <p style="text-align:center;">即可参与送书活动！</p> 
 <p style="text-align:center;">开奖时间：2023-10-28 21:00:00</p> 
</blockquote> 
<div> 
 <p class="img-center"><img alt="" height="299" src="https://images2.imgbox.com/36/a8/hA7Ia1t5_o.gif" width="531"></p> 
 <p>​</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a512ab530e12fc9ad92e336cd612a512/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">加速软件开发和交付的革命性方法-DevOps</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7db49e615c19134a75fe31be352c073f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2023-2024-1高级语言程序设计第1次月考</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>