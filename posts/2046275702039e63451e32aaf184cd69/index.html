<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch学习笔记（17）———训练一个性别2分类网络 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch学习笔记（17）———训练一个性别2分类网络" />
<meta property="og:description" content="转载自https://www.jianshu.com/p/1ec6075c0ab6
性别识别是一个2分类问题，网上应该有不少的研究。比如商汤/旷世科技 早已经将人脸属性继承到SDK中，可以供API在线调用，还有针对Android, ios的SDK， 本人测试过，速度很精度都很不错。
简单起见，直接采用预训练模型微调的方式训练一个性别分类器。
网络模型选择 torchvision.models中集成了几个常见的网络模型，ResNet, AlexNet, VGG, DenseNet, SqueezeNet。 AlexNet和VGG模型文件都很大，AlexNet大约230M, VGG更大，下载特别慢，而且这么大的模型文件对于以后往移动平台移植很不利。
SqueezeNet有所了解，这是一个轻量化的网络，网络名称squeeze就是压缩的意思。作者文章介绍到SqueezeNet与AlexNet精度相当，模型参数大大降低。因此决定采用SqueezeNet进行实验，如果效果不错可以考虑Android端的移植。
SqueezeNet SqueezeNet是一个轻量化的网络 ,模型文件比较小，大约4M多，相比AlexNet 230M，算是非常轻量化。
采用pytorch 打印出的SqueezeNet的网络结构。
数据集制作 UTKFace数据集进行训练
https://susanqq.github.io/UTKFace/
训练集，验证集，测试集划分 UTKFace数据需要从Google Drive下载，链接包含2个压缩包。 采用第一个压缩包crop_part1.tar.gz的数据，规模稍微小，先看看效果。训练：验证：测试 = 6:2:2
总共9780张图像训练数据5000&#43;验证数据约2000测试数据约2000
由于UTKFace数据的按照年龄排序的，因此在划分数据时候全部采用随机采样。
划分结果：
使用pytorch加载数据 继承Dataset类， override __len()__, __getitem()__方法采用Dataloder包装，按照mini_batch方式读取 from torch.utils.data import Dataset import torch import torchvision.transforms as transforms import PIL.Image as Image import os import numpy import shutil import random class UTKFaceGenderDataset(Dataset): def __init__(self, root, txt_file, transform=None, target_transform=None): self.root = root self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/2046275702039e63451e32aaf184cd69/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-26T15:37:27+08:00" />
<meta property="article:modified_time" content="2022-04-26T15:37:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch学习笔记（17）———训练一个性别2分类网络</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><a href="https://www.jianshu.com/p/1ec6075c0ab6" rel="nofollow">转载自https://www.jianshu.com/p/1ec6075c0ab6</a><br> 性别识别是一个2分类问题，网上应该有不少的研究。比如商汤/旷世科技 早已经将人脸属性继承到SDK中，可以供API在线调用，还有针对Android, ios的SDK， 本人测试过，速度很精度都很不错。</p> 
<p>简单起见，直接采用预训练模型微调的方式训练一个性别分类器。</p> 
<h3><a id="_7"></a>网络模型选择</h3> 
<p><code>torchvision.models</code>中集成了几个常见的网络模型，ResNet, AlexNet, VGG, DenseNet, SqueezeNet。 AlexNet和VGG模型文件都很大，AlexNet大约230M, VGG更大，下载特别慢，而且这么大的模型文件对于以后往移动平台移植很不利。</p> 
<p><strong>SqueezeNet</strong>有所了解，这是一个轻量化的网络，网络名称squeeze就是压缩的意思。作者文章介绍到SqueezeNet与AlexNet精度相当，模型参数大大降低。因此决定采用SqueezeNet进行实验，如果效果不错可以考虑Android端的移植。</p> 
<h3><a id="SqueezeNet_13"></a>SqueezeNet</h3> 
<p>SqueezeNet是一个轻量化的网络 ,模型文件比较小，大约4M多，相比AlexNet 230M，算是非常轻量化。<br> <img src="https://images2.imgbox.com/99/2d/zzCUMKbi_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/88/2c/Wyjdx4fi_o.png" alt="在这里插入图片描述"><br> 采用pytorch 打印出的SqueezeNet的网络结构。<br> <img src="https://images2.imgbox.com/bd/e8/tZKbkNBV_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b7/df/EBOZn2Qa_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/53/8d/2eSZ5qiY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e4/80/pBqPTNTr_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_23"></a>数据集制作</h3> 
<p>UTKFace数据集进行训练<br> https://susanqq.github.io/UTKFace/</p> 
<p><img src="https://images2.imgbox.com/86/d2/WwV2S8NT_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/be/38/62SlnsZw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9f/a0/SSFDFgMv_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a7/4b/D9gTDe77_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_32"></a>训练集，验证集，测试集划分</h3> 
<p>UTKFace数据需要从Google Drive下载，链接包含2个压缩包。 采用第一个压缩包crop_part1.tar.gz的数据，规模稍微小，先看看效果。训练：验证：测试 = 6:2:2</p> 
<ul><li>总共9780张图像</li><li>训练数据5000+</li><li>验证数据约2000</li><li>测试数据约2000<br> 由于UTKFace数据的按照年龄排序的，因此在划分数据时候全部采用随机采样。<br> 划分结果：<br> <img src="https://images2.imgbox.com/16/13/DgTtYrSO_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="pytorch_43"></a>使用pytorch加载数据</h3> 
<ul><li>继承<code>Dataset</code>类， override <code>__len()__</code>, <code>__getitem()__</code>方法</li><li>采用<code>Dataloder</code>包装，按照mini_batch方式读取</li></ul> 
<pre><code class="prism language-bash">from torch.utils.data <span class="token function">import</span> Dataset
<span class="token function">import</span> torch
<span class="token function">import</span> torchvision.transforms as transforms
<span class="token function">import</span> PIL.Image as Image
<span class="token function">import</span> os
<span class="token function">import</span> numpy
<span class="token function">import</span> shutil
<span class="token function">import</span> random


class UTKFaceGenderDataset<span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span>:

    def __init__<span class="token punctuation">(</span>self, root, txt_file, <span class="token assign-left variable">transform</span><span class="token operator">=</span>None, <span class="token assign-left variable">target_transform</span><span class="token operator">=</span>None<span class="token punctuation">)</span>:
        self.root <span class="token operator">=</span> root
        self.transform <span class="token operator">=</span> transform
        self.target_transform <span class="token operator">=</span> target_transform
        self.class_name <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span>: <span class="token string">'male'</span>, <span class="token number">1</span>: <span class="token string">'female'</span><span class="token punctuation">}</span>
        self.txt_file <span class="token operator">=</span> txt_file
        self.length <span class="token operator">=</span> <span class="token number">0</span>
        self.images_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        f <span class="token operator">=</span> open<span class="token punctuation">(</span>txt_file, <span class="token string">'r'</span><span class="token punctuation">)</span>
        assert f is not None
        <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> f:
            self.length <span class="token operator">+=</span> <span class="token number">1</span>
            self.images_name.append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

    def __len__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:
        <span class="token builtin class-name">return</span> self.length

    def __getitem__<span class="token punctuation">(</span>self, index<span class="token punctuation">)</span>:
        image_name <span class="token operator">=</span> self.images_name<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># if not os.path.isfile(os.path.join(self.root, image_name)):</span>
        <span class="token comment">#     return None</span>
        image <span class="token operator">=</span> Image.open<span class="token punctuation">(</span>os.path.join<span class="token punctuation">(</span>self.root, image_name<span class="token punctuation">)</span>.rstrip<span class="token punctuation">(</span><span class="token punctuation">))</span>
        assert image is not None
        label <span class="token operator">=</span> int<span class="token punctuation">(</span>image_name.split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        image_transformed <span class="token operator">=</span> image
        label_transformed <span class="token operator">=</span> label
        <span class="token keyword">if</span> self.transform:
            image_transformed <span class="token operator">=</span> self.transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self.target_transform:
            label_transformed <span class="token operator">=</span> self.target_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>

        <span class="token builtin class-name">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">'image'</span><span class="token builtin class-name">:</span> image_transformed, <span class="token string">'label'</span><span class="token builtin class-name">:</span> label_transformed<span class="token punctuation">}</span>

</code></pre> 
<p>DataLoader包装</p> 
<pre><code class="prism language-bash"><span class="token comment"># ---------------------------数据集--------------------------------------------------</span>
batch_size <span class="token operator">=</span> <span class="token number">8</span>
data_root <span class="token operator">=</span> <span class="token string">'/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/'</span>
device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch.cuda.is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> transforms.Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>transforms.Resize<span class="token variable"><span class="token punctuation">((</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">))</span></span>,
     transforms.ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> dataset.UTKFaceGenderDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>os.path.join<span class="token punctuation">(</span>data_root, <span class="token string">'image'</span><span class="token punctuation">)</span>,
                                             <span class="token assign-left variable">txt_file</span><span class="token operator">=</span>os.path.join<span class="token punctuation">(</span>data_root, <span class="token string">'train.txt'</span><span class="token punctuation">)</span>,
                                             <span class="token assign-left variable">transform</span><span class="token operator">=</span>transform<span class="token punctuation">)</span>

print<span class="token punctuation">(</span><span class="token string">'train_dataset: {}'</span>.format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_dataset<span class="token punctuation">))</span><span class="token punctuation">)</span>

train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset,batch_size<span class="token operator">=</span>batch_size,shuffle<span class="token operator">=</span>True, <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="UTKFace_118"></a>UTKFace数据分布</h3> 
<p>train set only</p> 
<ul><li> <p>年龄分布<br> <img src="https://images2.imgbox.com/7f/d3/pCCzysYn_o.png" alt="在这里插入图片描述"></p> </li><li> <p>性别分布<br> <img src="https://images2.imgbox.com/03/a4/rtAZYHA4_o.png" alt="在这里插入图片描述"></p> </li><li> <p>人种肤色分布<br> <img src="https://images2.imgbox.com/76/d6/jUrkLkMZ_o.png" alt="在这里插入图片描述"><br> 根据数据库的分布的分布情况可知，UTKFace男女性别分布基本平衡，其中欧美白种人占据的比例比较大，亚洲人占据的比例约16%，从年龄分布来看，0~10岁的比较多。因此直接用此数据库训练性别分类模型，可能对亚洲人识别不一定很好(猜测)，作为实验，后续可以验证。</p> </li><li> <p>代码， 可视化数据分布：又重写写了一个UTKFaceDateset类，觉得之前的写法有不太好，容易造成BUG。</p> </li></ul> 
<pre><code class="prism language-bash">class UTKFaceDataset<span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span>:

    def __init__<span class="token punctuation">(</span>self, root, txt_file, <span class="token assign-left variable">transform</span><span class="token operator">=</span>None, <span class="token assign-left variable">target_transform</span><span class="token operator">=</span>None<span class="token punctuation">)</span>:
        self.root <span class="token operator">=</span> root
        self.transform <span class="token operator">=</span> transform
        self.target_transform <span class="token operator">=</span> target_transform
        self.txt_file <span class="token operator">=</span> txt_file

        self.lines <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        f <span class="token operator">=</span> open<span class="token punctuation">(</span>self.txt_file, <span class="token string">'r'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> f:
            self.lines.append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

    def __len__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:
        <span class="token builtin class-name">return</span> len<span class="token punctuation">(</span>self.lines<span class="token punctuation">)</span>

    def __getitem__<span class="token punctuation">(</span>self, index<span class="token punctuation">)</span>:
        attrs <span class="token operator">=</span> self.lines<span class="token punctuation">[</span>index<span class="token punctuation">]</span>.split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span>

        assert len<span class="token punctuation">(</span>attrs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span>

        age <span class="token operator">=</span> int<span class="token punctuation">(</span>attrs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        gender <span class="token operator">=</span> int<span class="token punctuation">(</span>attrs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        race <span class="token operator">=</span> int<span class="token punctuation">(</span>attrs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        date_time <span class="token operator">=</span> attrs<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>.split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment"># [age] is an integer from 0 to 116, indicating the age</span>
        <span class="token comment"># gender] is either 0 (male) or 1 (female)</span>
        <span class="token comment"># [race] is an integer from 0 to 4, denoting White, Black,</span>
        <span class="token comment"># Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern)</span>
        <span class="token comment"># [date&amp;time] is in the format of yyyymmddHHMMSSFFF,</span>
        <span class="token comment"># showing the date and time an image was collected to UTKFace</span>
        assert age <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">117</span><span class="token punctuation">)</span>
        assert gender <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>
        assert race <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">3</span>, <span class="token number">4</span><span class="token punctuation">]</span>
        label <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'age'</span><span class="token builtin class-name">:</span> age, <span class="token string">'gender'</span><span class="token builtin class-name">:</span> gender, <span class="token string">'race'</span><span class="token builtin class-name">:</span> race, <span class="token string">'data_time'</span><span class="token builtin class-name">:</span> date_time<span class="token punctuation">}</span>

        image_path <span class="token operator">=</span> os.path.join<span class="token punctuation">(</span>self.root, self.lines<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>.rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        assert os.path.isfile<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
        image <span class="token operator">=</span> Image.open<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>.convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>

        image_transformed <span class="token operator">=</span> image
        label_transformed <span class="token operator">=</span> label
        <span class="token keyword">if</span> self.transform:
            image_transformed <span class="token operator">=</span> self.transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self.target_transform:
            label_transformed<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self.target_transform<span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            label_transformed<span class="token punctuation">[</span><span class="token string">'gender'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self.target_transform<span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token string">'gender'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            label_transformed<span class="token punctuation">[</span><span class="token string">'race'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self.target_transform<span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token string">'race'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token builtin class-name">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">'image'</span><span class="token builtin class-name">:</span> image_transformed, <span class="token string">'label'</span><span class="token builtin class-name">:</span> label_transformed<span class="token punctuation">}</span>

</code></pre> 
<pre><code class="prism language-bash"><span class="token function">import</span> torch
<span class="token function">import</span> dataset
<span class="token function">import</span> matplotlib.pyplot as plt
<span class="token function">import</span> numpy as np


def main<span class="token punctuation">(</span><span class="token punctuation">)</span>:

    train_dataset <span class="token operator">=</span> dataset.UTKFaceDataset<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/image'</span>,
                                       <span class="token assign-left variable">txt_file</span><span class="token operator">=</span><span class="token string">'/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/train.txt'</span><span class="token punctuation">)</span>
    <span class="token comment"># 性别</span>
    gender_nums <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'male'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'female'</span><span class="token builtin class-name">:</span> <span class="token number">0</span><span class="token punctuation">}</span>

    <span class="token comment"># 年龄段</span>
    age_nums <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'age0_10'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age10_20'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age20_30'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age30_40'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
                 <span class="token string">'age40_50'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age50_60'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age60_70'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'age70_80'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
                 <span class="token string">'age80_90'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,  <span class="token string">'age90_100'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,  <span class="token string">'age100_120'</span><span class="token builtin class-name">:</span> <span class="token number">0</span><span class="token punctuation">}</span>

    age_hist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment"># 人种</span>
    race_nums <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'White'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'Black'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'Asian'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'Indian'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'Others'</span><span class="token builtin class-name">:</span> <span class="token number">0</span><span class="token punctuation">}</span>

    <span class="token keyword">for</span> i, sample <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>:

        print<span class="token punctuation">(</span>i, sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        age <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span>
        gender <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'gender'</span><span class="token punctuation">]</span>
        race <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'race'</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> gender <span class="token operator">==</span> <span class="token number">0</span>:
            gender_nums<span class="token punctuation">[</span><span class="token string">'male'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        else:
            gender_nums<span class="token punctuation">[</span><span class="token string">'female'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">if</span> race <span class="token operator">==</span> <span class="token number">0</span>:
            race_nums<span class="token punctuation">[</span><span class="token string">'White'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> race <span class="token operator">==</span> <span class="token number">1</span>:
            race_nums<span class="token punctuation">[</span><span class="token string">'Black'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> race <span class="token operator">==</span> <span class="token number">2</span>:
            race_nums<span class="token punctuation">[</span><span class="token string">'Asian'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> race <span class="token operator">==</span> <span class="token number">3</span>:
            race_nums<span class="token punctuation">[</span><span class="token string">'Indian'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        else:
            race_nums<span class="token punctuation">[</span><span class="token string">'Others'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

        age_hist.append<span class="token punctuation">(</span>age<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">10</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age0_10'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">10</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">20</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age10_20'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">20</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">30</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age20_30'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">30</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">40</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age30_40'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">40</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">50</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age40_50'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">50</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">60</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age50_60'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">60</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">70</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age60_70'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">70</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">80</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age70_80'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">80</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">90</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age80_90'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token number">90</span> <span class="token operator">&lt;=</span> age <span class="token operator">&lt;</span> <span class="token number">100</span>:
            age_nums<span class="token punctuation">[</span><span class="token string">'age90_100'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        else:
            age_nums<span class="token punctuation">[</span><span class="token string">'age100_120'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

    print<span class="token punctuation">(</span>age_nums, gender_nums, race_nums<span class="token punctuation">)</span>

    <span class="token comment"># 画图</span>
    plt.figure<span class="token punctuation">(</span><span class="token string">'age'</span><span class="token punctuation">)</span>
    plt.hist<span class="token punctuation">(</span>age_hist, <span class="token assign-left variable">bins</span><span class="token operator">=</span><span class="token number">10</span>, <span class="token assign-left variable">facecolor</span><span class="token operator">=</span><span class="token string">'blue'</span>, <span class="token assign-left variable">edgecolor</span><span class="token operator">=</span><span class="token string">'black'</span>, <span class="token assign-left variable">alpha</span><span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
    plt.title<span class="token punctuation">(</span><span class="token string">'UTKFace age'</span><span class="token punctuation">)</span>
    plt.xlabel<span class="token punctuation">(</span><span class="token string">'age'</span><span class="token punctuation">)</span>
    plt.ylabel<span class="token punctuation">(</span><span class="token string">'count'</span><span class="token punctuation">)</span>

    plt.figure<span class="token punctuation">(</span><span class="token string">'gender'</span><span class="token punctuation">)</span>
    plt.pie<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token punctuation">[</span>gender_nums<span class="token punctuation">[</span><span class="token string">'male'</span><span class="token punctuation">]</span>, gender_nums<span class="token punctuation">[</span><span class="token string">'female'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">colors</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'red'</span>, <span class="token string">'blue'</span><span class="token punctuation">]</span>, <span class="token assign-left variable">labels</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'male'</span>, <span class="token string">'female'</span><span class="token punctuation">]</span>,
            <span class="token assign-left variable">autopct</span><span class="token operator">=</span><span class="token string">'%1.1f%%'</span>, <span class="token assign-left variable">pctdistance</span><span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
    plt.axis<span class="token punctuation">(</span><span class="token string">'equal'</span><span class="token punctuation">)</span>
    plt.legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt.figure<span class="token punctuation">(</span><span class="token string">'race'</span><span class="token punctuation">)</span>
    plt.pie<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token punctuation">[</span>race_nums<span class="token punctuation">[</span><span class="token string">'White'</span><span class="token punctuation">]</span>, race_nums<span class="token punctuation">[</span><span class="token string">'Black'</span><span class="token punctuation">]</span>, race_nums<span class="token punctuation">[</span><span class="token string">'Asian'</span><span class="token punctuation">]</span>,  race_nums<span class="token punctuation">[</span><span class="token string">'Indian'</span><span class="token punctuation">]</span>, race_nums<span class="token punctuation">[</span><span class="token string">'Others'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>,
            <span class="token assign-left variable">colors</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'red'</span>, <span class="token string">'blue'</span>, <span class="token string">'green'</span>, <span class="token string">'yellow'</span>, <span class="token string">'purple'</span><span class="token punctuation">]</span>,
            <span class="token assign-left variable">labels</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'White'</span>, <span class="token string">'Black'</span>, <span class="token string">'Asian'</span>, <span class="token string">'Indian'</span>, <span class="token string">'Others'</span><span class="token punctuation">]</span>,
            <span class="token assign-left variable">labeldistance</span><span class="token operator">=</span><span class="token number">1.1</span>,
            <span class="token assign-left variable">shadow</span><span class="token operator">=</span>False,
            <span class="token assign-left variable">startangle</span><span class="token operator">=</span><span class="token number">90</span>,
            <span class="token assign-left variable">autopct</span><span class="token operator">=</span><span class="token string">'%1.1f%%'</span>, <span class="token assign-left variable">pctdistance</span><span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
    plt.axis<span class="token punctuation">(</span><span class="token string">'equal'</span><span class="token punctuation">)</span>
    plt.legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>



<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token builtin class-name">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="_297"></a>训练</h3> 
<p>训练采用GPU，下面有部分的loss, Acc曲线。</p> 
<h3><a id="_301"></a>测试</h3> 
<pre><code class="prism language-bash">viz <span class="token operator">=</span> visdom.Visdom<span class="token punctuation">(</span>env<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">)</span>
GENDER <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'male'</span>, <span class="token string">'female'</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i, sample <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span>:
    inputs, labels <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span>, sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>

    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

    _, prediction <span class="token operator">=</span> torch.max<span class="token punctuation">(</span>outputs, <span class="token number">1</span><span class="token punctuation">)</span>
    correct <span class="token operator">+=</span> <span class="token punctuation">(</span>labels <span class="token operator">==</span> prediction<span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total <span class="token operator">+=</span> labels.size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    inputs <span class="token operator">=</span> make_grid<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    viz.image<span class="token punctuation">(</span>inputs, <span class="token assign-left variable">opts</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'{},{},{},{}'</span>.format<span class="token punctuation">(</span>GENDER<span class="token punctuation">[</span>labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>,GENDER<span class="token punctuation">[</span>labels<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>,GENDER<span class="token punctuation">[</span>labels<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>,GENDER<span class="token punctuation">[</span>labels<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">))</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/42/bf/dyIOgq9e_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/81/c6/fRQuxlEW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/eb/cd/w1hZhN75_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/8c/lZLd7mcM_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/62/30/1tBnONgl_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_325"></a>输出</h3> 
<p><img src="https://images2.imgbox.com/12/57/oGR9Rd1n_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8b/6b/Sc6Zl6Dg_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_330"></a>完整工程</h2> 
<ul><li><strong>数据集</strong></li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> PIL<span class="token punctuation">.</span>Image <span class="token keyword">as</span> Image
<span class="token keyword">import</span> os
<span class="token keyword">import</span> numpy
<span class="token keyword">import</span> shutil
<span class="token keyword">import</span> random


<span class="token keyword">class</span> <span class="token class-name">UTKFaceGenderDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> txt_file<span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> target_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>root <span class="token operator">=</span> root
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform
        self<span class="token punctuation">.</span>target_transform <span class="token operator">=</span> target_transform
        self<span class="token punctuation">.</span>class_name <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'male'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'female'</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>txt_file <span class="token operator">=</span> txt_file
        self<span class="token punctuation">.</span>length <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>images_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>txt_file<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> f <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> f<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>length <span class="token operator">+=</span> <span class="token number">1</span>
            self<span class="token punctuation">.</span>images_name<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>length

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image_name <span class="token operator">=</span> self<span class="token punctuation">.</span>images_name<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># if not os.path.isfile(os.path.join(self.root, image_name)):</span>
        <span class="token comment">#     return None</span>
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root<span class="token punctuation">,</span> image_name<span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> image <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
        label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>image_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        image_transformed <span class="token operator">=</span> image
        label_transformed <span class="token operator">=</span> label
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>
            image_transformed <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">:</span>
            label_transformed <span class="token operator">=</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">'image'</span><span class="token punctuation">:</span> image_transformed<span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> label_transformed<span class="token punctuation">}</span>


<span class="token comment"># train_file = open('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/train.txt', 'w')</span>
<span class="token comment"># val_file = open('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/val.txt', 'w')</span>
<span class="token comment"># test_file = open('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/test.txt', 'w')</span>
<span class="token comment">#</span>
<span class="token comment"># image_idx = list(range(len(os.listdir('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/image'))))</span>
<span class="token comment"># images_name = os.listdir('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/image')</span>
<span class="token comment">#</span>
<span class="token comment"># for i in range(1956):</span>
<span class="token comment">#     num = 0</span>
<span class="token comment">#     while True:</span>
<span class="token comment">#         num = random.randint(a=image_idx[0], b=image_idx[len(image_idx)-1]-1)</span>
<span class="token comment">#         if num in image_idx:</span>
<span class="token comment">#             break</span>
<span class="token comment">#     image_name = images_name[num]</span>
<span class="token comment">#     test_file.write(image_name + '\n')</span>
<span class="token comment">#     image_idx.remove(num)</span>
<span class="token comment">#     print(i)</span>
<span class="token comment">#</span>
<span class="token comment"># test_file.close()</span>
<span class="token comment"># print('test.txt create finish!')</span>
<span class="token comment">#</span>
<span class="token comment"># for i in range(1956):</span>
<span class="token comment">#     num = 0</span>
<span class="token comment">#     while True:</span>
<span class="token comment">#         num = random.randint(a=image_idx[0], b=image_idx[len(image_idx)-1]-1)</span>
<span class="token comment">#         if num in image_idx:</span>
<span class="token comment">#             break</span>
<span class="token comment">#     image_name = images_name[num]</span>
<span class="token comment">#     val_file.write(image_name + '\n')</span>
<span class="token comment">#     image_idx.remove(num)</span>
<span class="token comment">#     print(i)</span>
<span class="token comment">#</span>
<span class="token comment"># test_file.close()</span>
<span class="token comment"># print('val.txt create finish!')</span>
<span class="token comment">#</span>
<span class="token comment"># for i in image_idx:</span>
<span class="token comment">#     train_file.write(images_name[i] + '\n')</span>
<span class="token comment"># print('train.txt create finish!')</span>


<span class="token comment"># ---------------------------测试--------------------------------------------------</span>
<span class="token comment"># length = len(os.listdir('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/image'))</span>
<span class="token comment">#</span>
<span class="token comment">#</span>
<span class="token comment">#</span>
<span class="token comment"># batch_size = 8</span>
<span class="token comment"># data_root = '/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/'</span>
<span class="token comment"># device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')</span>
<span class="token comment">#</span>
<span class="token comment"># transform = transforms.Compose(</span>
<span class="token comment">#     [transforms.Resize((224, 224)),</span>
<span class="token comment">#      transforms.ToTensor()</span>
<span class="token comment">#      ])</span>
<span class="token comment">#</span>
<span class="token comment"># train_dataset = UTKFaceGenderDataset(root=os.path.join(data_root, 'image'),</span>
<span class="token comment">#                                              txt_file=os.path.join(data_root, 'train.txt'),</span>
<span class="token comment">#                                              transform=transform,</span>
<span class="token comment">#                                              target_transform=ToTensor())</span>
<span class="token comment">#</span>
<span class="token comment"># print('train_dataset: {}'.format(len(train_dataset)))</span>
<span class="token comment">#</span>
<span class="token comment">#</span>
<span class="token comment"># val_dataset = UTKFaceGenderDataset(root=os.path.join(data_root, 'image'),</span>
<span class="token comment">#                                            txt_file=os.path.join(data_root, 'val.txt'),</span>
<span class="token comment">#                                            transform=transform,</span>
<span class="token comment">#                                            target_transform=ToTensor()</span>
<span class="token comment">#                                    )</span>
<span class="token comment"># print('val dataset: {}'.format(len(val_dataset)))</span>
<span class="token comment">#</span>
<span class="token comment"># datasets = [train_dataset, val_dataset]</span>
<span class="token comment"># for dataset in datasets:</span>
<span class="token comment">#     print('-'*20)</span>
<span class="token comment">#     for i, sample in enumerate(dataset):</span>
<span class="token comment">#         print('{}, {}, label={}'.format(dataset.images_name[i].rstrip(), i, sample['label'].item()))</span>
<span class="token comment">#         # if (sample['label'].item() == 0) or (sample['label'].item() == 1):</span>
<span class="token comment">#         #     continue</span>
<span class="token comment">#         # else:</span>
<span class="token comment">#         #     os.remove(os.path.join('/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/image',dataset.images_name[i].rstrip()))</span>
<span class="token comment">#         #     continue</span>
<span class="token comment">#         assert sample['label'].item() == 0 or sample['label'].item() == 1</span>


</code></pre> 
<ul><li><strong>训练+验证</strong></li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> ImageFolder
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> copy
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> dataset
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torchnet

<span class="token comment"># ---------------------------数据集--------------------------------------------------</span>
batch_size <span class="token operator">=</span> <span class="token number">8</span>
data_root <span class="token operator">=</span> <span class="token string">'/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/'</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>UTKFaceGenderDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'image'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             txt_file<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'train.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_dataset: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># plt.figure()</span>
<span class="token comment"># for i in train_dataset:</span>
<span class="token comment">#     plt.imshow(np.transpose(i['image'].numpy(), (1, 2, 0)))</span>
<span class="token comment">#     plt.title(train_dataset.class_name[i['label']])</span>
<span class="token comment">#     plt.show()</span>

val_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>UTKFaceGenderDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'image'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                           txt_file<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'val.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                           transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'val dataset: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

val_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># ------------------定义网络---------------------------------</span>
<span class="token comment"># 载入预训练的型</span>
model <span class="token operator">=</span> models<span class="token punctuation">.</span>squeezenet1_1<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> <span class="token number">2</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token comment"># print('Down finish')</span>
<span class="token comment"># model = models.alexnet(pretrained=True)</span>
<span class="token comment"># # 修改输出层，2分类</span>
<span class="token comment"># model.classifier[6] = nn.Linear(in_features=4096, out_features=2)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># ------------------优化方法，损失函数--------------------------------------------------</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
loss_fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
scheduler <span class="token operator">=</span> optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token comment"># ------------------训练--------------------------------------------------------------</span>
num_epoch <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 训练日志保存</span>
file_train_loss <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./log/train_loss.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>
file_train_acc <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./log/train_acc.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

file_val_loss <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./log/val_loss.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>
file_val_acc <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./log/val_acc.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

<span class="token comment"># loss可视化</span>
<span class="token comment"># win_loss = torchnet.logger.VisdomPlotLogger(plot_type='line',</span>
<span class="token comment">#                                             env='gender_classfiy',</span>
<span class="token comment">#                                             opts=dict(title='Train loss'),</span>
<span class="token comment">#                                             win='Train loss')</span>
<span class="token comment"># </span>
<span class="token comment"># # Accuracy可视化</span>
<span class="token comment"># win_acc = torchnet.logger.VisdomPlotLogger(plot_type='line',</span>
<span class="token comment">#                                            env='gender_classify',</span>
<span class="token comment">#                                            opts=dict(title='Val acc'),</span>
<span class="token comment">#                                            win='Val acc')</span>

acc_best_wts <span class="token operator">=</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
best_acc <span class="token operator">=</span> <span class="token number">0</span>
iter_count <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    train_acc <span class="token operator">=</span> <span class="token number">0.0</span>
    train_correct <span class="token operator">=</span> <span class="token number">0</span>
    train_total <span class="token operator">=</span> <span class="token number">0</span>

    val_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    val_acc <span class="token operator">=</span> <span class="token number">0.0</span>
    val_correct <span class="token operator">=</span> <span class="token number">0</span>
    val_total <span class="token operator">=</span> <span class="token number">0</span>

    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> sample_batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> sample_batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> sample_batch<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        <span class="token comment"># 模型设置为train</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># forward</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

        <span class="token comment"># print(labels)</span>
        <span class="token comment"># loss</span>
        loss <span class="token operator">=</span> loss_fc<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

        <span class="token comment"># forward update</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 统计</span>
        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_correct <span class="token operator">+=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">200</span> <span class="token operator">==</span> <span class="token number">199</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> sample_batch <span class="token keyword">in</span> val_dataloader<span class="token punctuation">:</span>
                inputs <span class="token operator">=</span> sample_batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                labels <span class="token operator">=</span> sample_batch<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

                model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> loss_fc<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
                _<span class="token punctuation">,</span> prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
                val_correct <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>labels <span class="token operator">==</span> prediction<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                val_total <span class="token operator">+=</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                val_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            val_acc <span class="token operator">=</span> val_correct <span class="token operator">/</span> val_total
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[{},{}] train_loss = {:.5f} train_acc = {:.5f} val_loss = {:.5f} val_acc = {:.5f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> train_loss <span class="token operator">/</span> <span class="token number">100</span><span class="token punctuation">,</span>train_correct <span class="token operator">/</span> train_total<span class="token punctuation">,</span> val_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>
                val_correct <span class="token operator">/</span> val_total<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> val_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>
                best_acc <span class="token operator">=</span> val_acc
                acc_best_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            file_train_loss<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>train_loss <span class="token operator">/</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
            file_train_acc<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>train_correct <span class="token operator">/</span> train_total<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
            file_val_loss<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>val_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>
            file_val_acc<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>val_correct <span class="token operator">/</span> val_total<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>

            iter_count <span class="token operator">+=</span> <span class="token number">200</span>

            <span class="token comment"># 可视化</span>
            <span class="token comment"># win_loss.log(iter_count, train_loss)</span>
            <span class="token comment"># win_acc.log(iter_count, val_acc)</span>

            train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
            train_total <span class="token operator">=</span> <span class="token number">0</span>
            train_correct <span class="token operator">=</span> <span class="token number">0</span>
            val_correct <span class="token operator">=</span> <span class="token number">0</span>
            val_total <span class="token operator">=</span> <span class="token number">0</span>
            val_loss <span class="token operator">=</span> <span class="token number">0</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train finish!'</span><span class="token punctuation">)</span>
<span class="token comment"># 保存模型</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>acc_best_wts<span class="token punctuation">,</span> <span class="token string">'./models/model_squeezenet_utk_face_1.pth'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Model save ok!'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li><strong>测试</strong></li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> ImageFolder
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> copy
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> dataset
<span class="token keyword">import</span> os


data_root <span class="token operator">=</span> <span class="token string">'/media/weipenghui/Extra/人脸属性识别/UTKFace/crop_part1/'</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">]</span><span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>UTKFaceGenderDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'image'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             txt_file<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">'test.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_dataset: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


model <span class="token operator">=</span> models<span class="token punctuation">.</span>squeezenet1_1<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> <span class="token number">2</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./models/model_squeezenet_utk_face_20.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

correct <span class="token operator">=</span> <span class="token number">0</span>
total <span class="token operator">=</span> <span class="token number">0</span>
acc <span class="token operator">=</span> <span class="token number">0.0</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> sample <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>

    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

    _<span class="token punctuation">,</span> prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    correct <span class="token operator">+=</span> <span class="token punctuation">(</span>labels <span class="token operator">==</span> prediction<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

acc <span class="token operator">=</span> correct <span class="token operator">/</span> total
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test finish, total:{}, correct:{}, acc:{:.3f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total<span class="token punctuation">,</span> correct<span class="token punctuation">,</span> acc<span class="token punctuation">)</span><span class="token punctuation">)</span>


</code></pre> 
<ul><li>解析log, 可视化Loss, Accuracy</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> visdom


train_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'./log/train_loss2.txt'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>
train_acc <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'./log/train_acc2.txt'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>
val_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'./log/val_loss2.txt'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>
val_acc <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'./log/val_acc2.txt'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span>


viz <span class="token operator">=</span> visdom<span class="token punctuation">.</span>Visdom<span class="token punctuation">(</span>env<span class="token operator">=</span><span class="token string">'gender_classifier'</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span>Y<span class="token operator">=</span>train_loss<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'train_loss'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'train_loss'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span>Y<span class="token operator">=</span>val_loss<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span>Y<span class="token operator">=</span>train_acc<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'train_acc'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'train_acc'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span>Y<span class="token operator">=</span>val_acc<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'val_acc'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p><a href="https://www.jianshu.com/p/1ec6075c0ab6" rel="nofollow">全部来自https://www.jianshu.com/p/1ec6075c0ab6</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ec49c05f9133be3330fffd8aa2f3fba6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">软考高级哪个更容易过</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5f9da35058d368a976f05cffb23da600/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【微信小程序】【项目实战】三、事件（点击事件）、路由跳转</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>