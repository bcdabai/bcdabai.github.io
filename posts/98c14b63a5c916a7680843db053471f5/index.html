<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用 LDA 方法进行数据分类的 Python 实现 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="用 LDA 方法进行数据分类的 Python 实现" />
<meta property="og:description" content="图片来源于网络，文末附本文源码下载方法
笔者之前写过一篇名为《用PCA方法进行数据降维》的文章，文章中主要讲述了如何用PCA（主成分分析）来对数据进行降维的方法。而今天笔者将介绍另一种常用的数据降维方法——LDA。
LDA的全称是linear discriminant analysis，即线性判别分析，LDA与PCA一样，都可用于数据降维，但二者既有相似也有区别，PCA主要是从特征/维度的协方差角度，去找到比较好的投影方式，即选择样本点投影具有最大方差的方向，而LDA则是寻找一个投影方向，让原先的数据在这个方向上投影后，不同类别之间数据点距离尽可能大，而同类别数据点距离尽可能小。此外PCA属于无监督式学习，很多情况下需要配合其他算法使用，而LDA属于监督式学习，本身除了可以用于降维外，还可以进行预测分析，说白了就是既可以“团战”，也可以单独打怪。而本文就主要讲述如何用LDA来进行数据分类，当然这里面肯定也会用到降维的原理。
LDA的大致原理如图1所示。图1中左图是按照常规坐标系来分析，这时可以看到数据有部分重叠，在分类时可能会有干扰，这时我们就要找到一个投影方向，让这些数据在这个方向上的投影，做到类之间距离尽可能大，类内数据尽可能聚集，如右图所示。
图1. LDA原理图
下面再简单介绍一下LDA的数学原理。
以最简单的两个类别为例，假设Xi、ui、Σi分别表示第i类样本点的集合、均值向量、协方差矩阵，若将数据投影到直线w上，则两类样本的中心在直线上的投影分别是w^Tu1和w^Tu2，在所有样本点都投影到直线上后，两类样本的协方差分别是w^TΣ1w和w^TΣ2w。我们要想让类别之间距离更大、类内距离更小，也就是要使图2中的（1）式最大。在这里我们再定义两个概念，一个是类内散度阵（within-class scatter matrix），即图2中（2）式，一个是类间散度阵（between-class scatter matrix），即图2中（3）式。那么这个让（1）式最大的问题就转化为最大化一个瑞利熵，即最大化（4）式。
图2. LDA部分推导公式
而求解（4）式也就是相当于求解图3中（5）式，用拉格朗日乘法求解，得到图3中（6）式，这就转化成了一个求特征方程的问题了，也就是求n-1个最大特征值所对应的特征向量（n是维度）。这个按照我们正常求解特征方程就可以了。
图3. LDA部分推导公式
在实际使用中，如果按照上述原理推导会非常麻烦，但是scikit-learn中已经为我们提供了现成的LDA方法，我们只要直接调用即可，下面就以scikit-learn为例，来看一下LDA在实际使用中的效果。
这次选用的数据集是鸢尾花数据集，来自seaborn库，大小为150行、5列，数据集样例如图4所示。
图4. 鸢尾花数据集样例
首先还是导入各种库。
import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from sklearn.metrics import classification_report from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA 然后是设置训练数据集和测试数据集。熟悉鸢尾花数据集的人都知道，这个数据集中150个样本点可以分为3个类别，每个类别各有50个样本点，这三个类别是&#39;setosa&#39;、&#39;versicolor&#39;和&#39;virginica&#39;，可以用代码set(data[&#39;species&#39;].values)来查看这三个值。我们在这里要设置训练集和测试集，就要在每个类别中都取得一定量的数据，笔者的方法是选取总数据集中60%的数据为训练集，即训练集一共是90个样本点，其中每个类别取前30个样本点，而测试集就是剩下的60个样本点，每个类别就是20个，代码如下。
data = sns.load_dataset(&#39;iris&#39;) #总数据集 data_train = data.iloc[np.r_[0:30, 50:80, 100:130]] #训练集 data_test = data.iloc[np.r_[30:50, 80:100, 130:150]] #测试集 train_x = data_train." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/98c14b63a5c916a7680843db053471f5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-12T08:30:00+08:00" />
<meta property="article:modified_time" content="2020-08-12T08:30:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用 LDA 方法进行数据分类的 Python 实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p><img src="https://images2.imgbox.com/cd/3e/hwuzbWfr_o.png"><br></p> 
 <p style="text-align: center">图片来源于网络，文末附本文源码下载方法</p> 
 <p>笔者之前写过一篇名为<a href="http://mp.weixin.qq.com/s?__biz=MzAxMjUyNDQ5OA%3D%3D&amp;chksm=806e05e3b7198cf50c95ed5edff7c2d927d4bcc3427e1fdaa1c897a612ba3cd4130dcb148773&amp;idx=1&amp;mid=2653563742&amp;scene=21&amp;sn=0c30499a4680bdf025d41feea6d04c83#wechat_redirect" rel="nofollow">《用PCA方法进行数据降维》</a>的文章，文章中主要讲述了如何用PCA（主成分分析）来对数据进行降维的方法。而今天笔者将介绍另一种常用的数据降维方法——LDA。</p> 
 <p>LDA的全称是<code>linear discriminant analysis</code>，即线性判别分析，LDA与PCA一样，都可用于数据降维，但二者既有相似也有区别，PCA主要是从特征/维度的协方差角度，去找到比较好的投影方式，即选择样本点投影具有最大方差的方向，而LDA则是寻找一个投影方向，让原先的数据在这个方向上投影后，不同类别之间数据点距离尽可能大，而同类别数据点距离尽可能小。此外PCA属于无监督式学习，很多情况下需要配合其他算法使用，而LDA属于监督式学习，本身除了可以用于降维外，还可以进行预测分析，说白了就是既可以“团战”，也可以单独打怪。而本文就主要讲述如何用LDA来进行数据分类，当然这里面肯定也会用到降维的原理。</p> 
 <p>LDA的大致原理如图1所示。图1中左图是按照常规坐标系来分析，这时可以看到数据有部分重叠，在分类时可能会有干扰，这时我们就要找到一个投影方向，让这些数据在这个方向上的投影，做到类之间距离尽可能大，类内数据尽可能聚集，如右图所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/87/a2/fh9ALDCn_o.png"></p> 
 <p style="text-align: center">图1. LDA原理图</p> 
 <p>下面再简单介绍一下LDA的数学原理。</p> 
 <p>以最简单的两个类别为例，假设<code>Xi</code>、<code>ui</code>、<code>Σi</code>分别表示第<code>i</code>类样本点的集合、均值向量、协方差矩阵，若将数据投影到直线w上，则两类样本的中心在直线上的投影分别是w^Tu1和w^Tu2，在所有样本点都投影到直线上后，两类样本的协方差分别是w^TΣ1w和w^TΣ2w。我们要想让类别之间距离更大、类内距离更小，也就是要使图2中的（1）式最大。在这里我们再定义两个概念，一个是类内散度阵（within-class scatter matrix），即图2中（2）式，一个是类间散度阵（between-class scatter matrix），即图2中（3）式。那么这个让（1）式最大的问题就转化为最大化一个瑞利熵，即最大化（4）式。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a8/61/aeq0sWTi_o.png"></p> 
 <p style="text-align: center">图2. LDA部分推导公式</p> 
 <p>而求解（4）式也就是相当于求解图3中（5）式，用拉格朗日乘法求解，得到图3中（6）式，这就转化成了一个求特征方程的问题了，也就是求n-1个最大特征值所对应的特征向量（n是维度）。这个按照我们正常求解特征方程就可以了。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/76/3c/QlmLPtBC_o.png"></p> 
 <p style="text-align: center">图3. LDA部分推导公式</p> 
 <p>在实际使用中，如果按照上述原理推导会非常麻烦，但是scikit-learn中已经为我们提供了现成的LDA方法，我们只要直接调用即可，下面就以scikit-learn为例，来看一下LDA在实际使用中的效果。</p> 
 <p>这次选用的数据集是鸢尾花数据集，来自seaborn库，大小为150行、5列，数据集样例如图4所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/62/83/D6lgI3Xr_o.png"></p> 
 <p style="text-align: center">图4. 鸢尾花数据集样例</p> 
 <p>首先还是导入各种库。</p> 
 <pre class="has"><code class="language-go">import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
</code></pre> 
 <p>然后是设置训练数据集和测试数据集。熟悉鸢尾花数据集的人都知道，这个数据集中150个样本点可以分为3个类别，每个类别各有50个样本点，这三个类别是'setosa'、'versicolor'和'virginica'，可以用代码set(data['species'].values)来查看这三个值。我们在这里要设置训练集和测试集，就要在每个类别中都取得一定量的数据，笔者的方法是选取总数据集中60%的数据为训练集，即训练集一共是90个样本点，其中每个类别取前30个样本点，而测试集就是剩下的60个样本点，每个类别就是20个，代码如下。</p> 
 <pre class="has"><code class="language-go">data = sns.load_dataset('iris') #总数据集
data_train = data.iloc[np.r_[0:30, 50:80, 100:130]] #训练集
data_test = data.iloc[np.r_[30:50, 80:100, 130:150]] #测试集
train_x = data_train.iloc[:,:4] #训练集数据
train_y = data_train.iloc[:,4] #训练集分类
test_x = data_test.iloc[:,:4] #测试集数据
test_y = data_test.iloc[:,4] #测试集分类
接下来就是设置分类器，并用分类器进行训练和预测，代码如下。
clf = LDA(n_components=2) #分类器
clf.fit(train_x, train_y) #用数据进行训练
pre_y = clf.predict(test_x) #对测试数据进行预测
</code></pre> 
 <p>这里<code>clf = LDA(n_components=2)</code>中，<code>n_components=2</code>就是我们最终要得到的数据维度数，原数据是4个维度，而这里我们要把它降维到2维，实际上这里我们只能选择2维和1维，因为<code>n_components</code>的默认值是数据集维度数和数据集分类数-1这两个中较小者，本例中维度数是4，数据集分类数-1是2（分类数是3），而这里<code>n_components</code>的值只能小于或等于2，所以我们选2。然后我们输出预测结果，结果如图5所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/f9/98/4ufSJwX5_o.png"></p> 
 <p style="text-align: center">图5. 60%情况下预测结果</p> 
 <p>从图中可以看到预测效果还是很好的，准确率在95%以上，为了更好地了解LDA的效果，笔者又分别作了两次测试，即分别取总数据集40%和80%的数据为训练集，这里40%的数据量就是60个样本点，每个类别取前20个样品，剩下的60%（也就是90个样本点）为测试集，而80%的情况也同理。这里笔者不再粘贴代码，代码只需对前面代码进行小的修改即可，只附上最终结果，预测的结果如图6和图7所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/44/92/BEHsSvn7_o.png"></p> 
 <p style="text-align: center">图6. 40%情况下预测结果</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/4f/1b/dhevBihP_o.png"></p> 
 <p style="text-align: center">图7. 80%情况下预测结果</p> 
 <p>从图中我们可以看到，在40%和80%训练量这两种情况下，最终预测的准确率都非常高，40%的条件下和60%的结果几乎一样，而80%的情况下三个类别的预测准确率竟然高达100%。这里笔者推测，准确率如此之高的原因，除了LDA方法的优势之外，可能和我们选用的鸢尾花数据集有关，这个数据集比较简单，其类别比较容易区分，即便选择其他的分类方法，也同样能取得好的效果。而这里还有一个小插曲，LDA方法的提出者Ronald Fisher，同时也是鸢尾花数据集的提出者，用他自己的方法来分析自己的数据集，结果肯定不会差。</p> 
 <p>本文用scikit-learn来对LDA方法进行了一个说明，并且在案例中也取得了不错的效果，但希望用户不要对LDA的使用过于盲目，其自身依然存在一些不足，比如当样本量远小于样本的特征数时，分类效果会很差，同时LDA不适合对非高斯分布的样本进行降维，LDA还可能过度拟合数据等等。<strong>本文源码下载方式请见文末，讨论本文内容可以添加文末“Python小助手”进入微信群交流！</strong></p> 
 <p>作者简介：Mort，数据分析爱好者，擅长数据可视化，比较关注机器学习领域，希望能和业内朋友多学习交流。</p> 
 <p style="text-align: center"><strong>赞 赏 作 者</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/cc/96/cjlHqIoo_o.png"></p> 
 <p>Python中文社区作为一个去中心化的全球技术社区，以成为全球20万Python中文开发者的精神部落为愿景，目前覆盖各大主流媒体和协作平台，与阿里、腾讯、百度、微软、亚马逊、开源中国、CSDN等业界知名公司和技术社区建立了广泛的联系，拥有来自十多个国家和地区数万名登记会员，会员来自以工信部、清华大学、北京大学、北京邮电大学、中国人民银行、中科院、中金、华为、BAT、谷歌、微软等为代表的政府机关、科研单位、金融机构以及海内外知名公司，全平台近20万开发者关注。</p> 
 <p style="text-align: center"><strong>长按扫码添加“Python小助手” </strong></p> 
 <p style="text-align: center"><strong>后回复</strong><strong>“LDA”</strong><strong>获取</strong><strong>本文源码</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/ca/39/bvY6ASqY_o.png"></p> 
 <p><strong>▼点击</strong>成为社区会员   喜欢就点个<strong>在看吧</strong><strong><strong><img src="https://images2.imgbox.com/1c/a1/DCtRxncO_o.png"></strong></strong></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/06582b932d9c243894a5069a978c416f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">element-ui_NavMenu-典型导航菜单</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6c2978a9267bc3edbb7c075646afb51b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">当在地址栏中输入内容回车时，浏览器干了啥？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>