<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Apache Impala介绍&amp;架构 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Apache Impala介绍&amp;架构" />
<meta property="og:description" content="Apache Impala 概述 Impala直接对存储在HDFS，HBase或Amazon Simple Storage Service（S3）中的Apache Hadoop数据提供快速，交互式SQL查询。除了使用相同的统一存储平台之外，Impala还使用与Apache Hive相同的元数据，SQL语法（Hive SQL），ODBC驱动程序和用户界面（Hue中的Impala查询UI）。这为实时或面向批处理的查询提供了一个熟悉且统一的平台。 Impala是可用于查询大数据的工具的补充。 Impala不会替代基于MapReduce构建的批处理框架，例如Hive。基于MapReduce构建的Hive和其他框架最适合长时间运行的批处理作业，例如涉及对Extract，Transform和Load（ETL）类型的作业进行批处理的框架。
Note： Impala于2017年11月15日从Apache Incubator毕业。在文档以前称为“ Cloudera Impala”的地方，现在的正式名称是“ Apache Impala”。
Impala优势 数据科学家和分析师已经知道的熟悉的SQL接口。能够查询Apache Hadoop中的大量数据（“大数据”）。集群环境中的分布式查询，可方便地扩展并利用具有成本效益的商品硬件。无需复制或导出/导入步骤即可在不同组件之间共享数据文件；例如，使用Pig编写，使用Hive进行转换以及使用Impala进行查询。 Impala可以读写Hive表，从而可以使用Impala对Hive生成的数据进行分析，从而实现简单的数据交换。用于大数据处理和分析的单一系统，因此客户可以避免仅用于分析的昂贵建模和ETL。 Impala执行原理 Impala服务器是一个分布式的大规模并行处理（MPP）数据库引擎。它由运行在群集内特定主机上的不同守护进程组成。Impala解决方案由以下组件组成：
Impala Daemon
Impala的核心组件是Impala守护程序，由impalad进程物理表示。Impala守护程序与StateStore保持持续通信，以确认哪些守护程序是健康的并且可以接受新工作。每当集群中的任何Impala守护程序创建，更改或删除任何类型的对象，或者通过Impala处理INSERT或LOAD DATA语句时，它们还从catalogd daemon（在Impala 1.2中引入）接收广播消息。这种后台通信最大程度地减少了在Impala 1.2之前的跨Impala守护程序协调元数据所需的REFRESH或INVALIDATE METADATA语句的需要。在Impala 2.9和更高版本中，您可以控制哪些主机充当查询协调器，哪些主机充当查询执行器，以提高大型集群上高并发工作负载的可伸缩性。 Impala守护程序执行的一些关键功能是：
Reads and writes to data files.Accepts queries transmitted from the impala-shell command, Hue, JDBC, or ODBC.Parallelizes the queries and distributes work across the cluster.Transmits intermediate query results back to the central coordinator. Impala Statestore" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/75db2f0b0787f7597b1e39f6508f969f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-13T14:02:31+08:00" />
<meta property="article:modified_time" content="2020-01-13T14:02:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Apache Impala介绍&amp;架构</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Apache_Impala_0"></a>Apache Impala</h2> 
<h3><a id="_2"></a>概述</h3> 
<p>Impala直接对存储在HDFS，HBase或Amazon Simple Storage Service（S3）中的Apache Hadoop数据提供快速，交互式SQL查询。除了使用相同的统一存储平台之外，Impala还使用与Apache Hive相同的元数据，SQL语法（Hive SQL），ODBC驱动程序和用户界面（Hue中的Impala查询UI）。这为实时或面向批处理的查询提供了一个熟悉且统一的平台。 Impala是可用于查询大数据的工具的补充。 Impala不会替代基于MapReduce构建的批处理框架，例如Hive。基于MapReduce构建的Hive和其他框架最适合长时间运行的批处理作业，例如涉及对Extract，Transform和Load（ETL）类型的作业进行批处理的框架。</p> 
<p><strong>Note：</strong> Impala于2017年11月15日从Apache Incubator毕业。在文档以前称为“ Cloudera Impala”的地方，现在的正式名称是“ Apache Impala”。</p> 
<h4><a id="Impala_8"></a>Impala优势</h4> 
<ul><li>数据科学家和分析师已经知道的熟悉的SQL接口。</li><li>能够查询Apache Hadoop中的大量数据（“大数据”）。</li><li>集群环境中的分布式查询，可方便地扩展并利用具有成本效益的商品硬件。</li><li>无需复制或导出/导入步骤即可在不同组件之间共享数据文件；例如，使用Pig编写，使用Hive进行转换以及使用Impala进行查询。 Impala可以读写Hive表，从而可以使用Impala对Hive生成的数据进行分析，从而实现简单的数据交换。</li><li>用于大数据处理和分析的单一系统，因此客户可以避免仅用于分析的昂贵建模和ETL。</li></ul> 
<h4><a id="Impala_16"></a>Impala执行原理</h4> 
<p>Impala服务器是一个分布式的大规模并行处理（MPP）数据库引擎。它由运行在群集内特定主机上的不同守护进程组成。Impala解决方案由以下组件组成：<br> <img src="https://images2.imgbox.com/10/e0/srn3eD6d_o.png" alt="在这里插入图片描述"><br> <strong>Impala Daemon</strong></p> 
<p>Impala的核心组件是Impala守护程序，由impalad进程物理表示。Impala守护程序与StateStore保持持续通信，以确认哪些守护程序是健康的并且可以接受新工作。每当集群中的任何Impala守护程序创建，更改或删除任何类型的对象，或者通过Impala处理INSERT或LOAD DATA语句时，它们还从catalogd daemon（在Impala 1.2中引入）接收广播消息。这种后台通信最大程度地减少了在Impala 1.2之前的跨Impala守护程序协调元数据所需的REFRESH或INVALIDATE METADATA语句的需要。在Impala 2.9和更高版本中，您可以控制哪些主机充当查询协调器，哪些主机充当查询执行器，以提高大型集群上高并发工作负载的可伸缩性。 Impala守护程序执行的一些关键功能是：</p> 
<blockquote> 
 <ul><li>Reads and writes to data files.</li><li>Accepts queries transmitted from the <code>impala-shell</code> command, Hue, JDBC, or ODBC.</li><li>Parallelizes the queries and distributes work across the cluster.</li><li>Transmits intermediate query results back to the central coordinator.</li></ul> 
</blockquote> 
<p><strong>Impala Statestore</strong></p> 
<p>称为StateStore的Impala组件会检查群集中所有Impala守护程序的运行状况，并将其发现结果不断传递给每个守护程序。它由名为statestored的守护进程物理表示。您只需要在群集中的一台主机上执行此过程。如果因硬件故障，网络错误，软件问题或其他原因而使Impala守护程序脱机，则StateStore会通知所有其他Impala守护程序，以便将来的查询可以避免向无法访问的Impala守护程序发出请求。</p> 
<p>因为StateStore的目的是在出现问题时提供帮助，并向Coordinators广播元数据，所以它对Impala群集的正常运行并不总是至关重要的。如果StateStore未运行或变得不可访问，则在处理Impala已知的数据时，Impala守护程序将继续运行并像往常一样在它们之间分配工作。如果其他Impala守护程序失败，则群集的健壮性就会降低，并且在StateStore脱机时，随着元数据的更改，元数据的一致性也会降低。当StateStore重新联机时，它将与Impala守护程序重新建立通信并恢复其监视和广播功能。</p> 
<p>如果在StateStore关闭时发出DDL语句，则访问DDL创建的新对象的查询将失败。</p> 
<p>负载平衡和高可用性的大多数注意事项都适用于impalad守护程序。Statestored 和 catalogd对高可用性没有特殊要求，因为这些守护程序的问题不会导致数据丢失。如果这些守护程序由于特定主机上的中断而变得不可用，则可以停止Impala服务，删除Impala StateStore和Impala Catalog Server角色，在其他主机上添加角色，然后重新启动Impala服务。</p> 
<p><strong>Impala Catalog Service</strong></p> 
<p>称为目录服务的Impala组件将元数据更改从Impala SQL语句中继到集群中的所有Impala守护程序。它由名为cataloged的守护进程物理表示。您只需要在群集中的一台主机上执行此过程。因为请求是通过StateStore守护程序传递的，所以在同一主机上运statestored和catalogd服务是有意义的。</p> 
<p>当元数据更改由通过Impala发出的语句执行时，Catalog Service避免了发出REFRESH和INVALIDATE METADATA语句的需要。当您通过Hive创建表，加载数据等时，您确实需要在Impala守护程序上发出REFRESH或INVALIDATE METADATA，然后在该处执行查询。</p> 
<h4><a id="ImpalaHadoop_46"></a>Impala&amp;Hadoop协作</h4> 
<p>mpala利用了Hadoop生态系统中许多熟悉的组件。 Impala可以将数据与其他Hadoop组件（作为使用者和生产者）互换，因此可以灵活地将其放入ETL和ELT管道中。</p> 
<p><strong>How Impala Works with Hive</strong></p> 
<p>Impala的主要目标是使SQL-on-Hadoop操作足够快速高效，以吸引新的用户类别，并向Hadoop开放新的用例类型。在可行的情况下，它利用许多Hadoop用户已经拥有的现有Apache Hive基础结构来执行长时间运行的，面向批处理的SQL查询。</p> 
<p>特别是，Impala将其表定义保存在称为元存储的传统MySQL或PostgreSQL数据库中，而Hive保留了这种类型的数据库。因此，只要所有列都使用Impala支持的数据类型，文件格式和压缩编解码器，Impala就可以访问Hive定义或加载的表。</p> 
<p>最初侧重于查询功能和性能意味着Impala与INSERT语句相比，可以使用SELECT语句读取更多类型的数据。要使用Avro，RCFile或SequenceFile文件格式查询数据，请使用Hive加载数据。</p> 
<p><strong>Metadata and the Metastore</strong></p> 
<p>对于具有大量数据和/或许多分区的表，检索表的所有元数据可能很耗时，在某些情况下会花费几分钟。因此，每个Impala节点都会缓存所有这些元数据，以供将来针对同一表的查询重用。</p> 
<p>如果表定义或表中的数据已更新，则在对该表发出查询之前，集群中的所有其他Impala守护程序必须接收最新的元数据，以替换过时的缓存元数据。在Impala 1.2及更高版本中，元数据更新是自动的，并通过catalogd 守护程序对通过Impala发布的所有DDL和DML语句进行协调。</p> 
<p>对于通过Hive发出的DDL和DML，或对HDFS中的文件进行手动更改，您仍然使用REFRESH语句（将新数据文件添加到现有表时）或INVALIDATE METADATA语句（对于全新表，或删除表，执行HDFS重新平衡操作或删除数据文件）。本身发出INVALIDATE METADATA即可检索元存储所跟踪的所有表的元数据。如果您知道在Impala之外仅更改了特定的表，则可以为每个受影响的表发出REFRESH table_name，以仅检索这些表的最新元数据。</p> 
<p><strong>How Impala Uses HDFS</strong></p> 
<p>Impala使用分布式文件系统HDFS作为其主要数据存储介质。 Impala依靠HDFS提供的冗余来防止单个节点上的硬件或网络中断。使用熟悉的HDFS文件格式和压缩编解码器，将Impala表数据物理上表示为HDFS中的数据文件。当新表的目录中存在数据文件时，Impala会全部读取它们，而不管文件名如何。新数据将添加到名称由Impala控制的文件中。</p> 
<p><strong>How Impala Uses HBase</strong></p> 
<p>HBase是HDFS的替代方案，可作为Impala数据的存储介质。它是建立在HDFS之上的数据库存储系统，没有内置的SQL支持。许多Hadoop用户已经对其进行了配置，并在其中存储了大型（通常是稀疏的）数据集。通过在Impala中定义表并将它们映射到HBase中的等效表，您可以通过Impala查询HBase表的内容，甚至可以执行包括Impala和HBase表在内的联接查询。</p> 
<h4><a id="_74"></a>总结</h4> 
<blockquote> 
 <p>Clients - 包括Hue，ODBC客户端，JDBC客户端和Impala Shell在内的实体都可以与Impala进行交互。这些接口通常用于发出查询或完成管理任务，例如连接到Impala。</p> 
 <p>Hive Metastore - 存储有关可用于Impala的数据的信息。例如，Metastore使Impala知道哪些数据库可用以及这些数据库的结构是什么。在创建，删除和更改Schema对象，通过Impala SQL语句将数据加载到表等时，相关的元数据更改将通过Impala 1.2中引入的专用目录服务（catalog service）自动广播到所有Impala节点。</p> 
 <p>Impala - 该过程在DataNodes上运行，可以协调并执行查询。 Impala的每个实例都可以接收，计划和协调来自Impala客户端的查询。查询分布在Impala节点之间，然后这些节点充当工作程序，执行并行查询片段。</p> 
 <p>HBase and HDFS - 存储要查询的数据</p> 
</blockquote> 
<p>使用Impala执行的查询的处理方式如下：</p> 
<blockquote> 
 <p>1、用户应用程序通过提供标准化查询接口的ODBC或JDBC将SQL查询发送到Impala。用户应用程序可以连接到群集中的任何impalad。该impalad成为查询的协调器。<br> 2、 Impala解析查询并对其进行分析，以确定跨集群的impalad实例需要执行哪些任务。执行计划是为了获得最佳效率。<br> 3、本地impalad实例访问诸如HDFS和HBase之类的服务以提供数据。<br> 4、每个impalad将数据返回到协调impalad，后者将这些结果发送到客户端。</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e4bf2f9c4c03913c5a609790e6944473/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">thymeleaf介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8fa0e707a0bc322eb3a5d30d35af6b5e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AUTOSAR Time Synchronization时间同步</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>