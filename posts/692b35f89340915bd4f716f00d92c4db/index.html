<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【深度学习注意力机制系列】—— SKNet注意力机制（附pytorch实现） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【深度学习注意力机制系列】—— SKNet注意力机制（附pytorch实现）" />
<meta property="og:description" content="SKNet（Selective Kernel Network）是一种用于图像分类和目标检测任务的深度神经网络架构，其核心创新是引入了选择性的多尺度卷积核（Selective Kernel）以及一种新颖的注意力机制，从而在不增加网络复杂性的情况下提升了特征提取的能力。SKNet的设计旨在解决多尺度信息融合的问题，使网络能够适应不同尺度的特征。
1. 核心思想 SKNet的核心思想是**通过选择性地应用不同尺度的卷积核，从而在不同层级上捕捉多尺度特征。**为了实现这一点，SKNet引入了一个选择模块，用于自适应地决定在每个通道上使用哪些尺度的卷积核。这种选择性的多尺度卷积核有助于提升特征表示的能力，使网络更具适应性和泛化能力。
2. 结构 SKNet的结构如下：
实现机制：
split：对特征图进行多分支分离卷积，各分支使用不同的卷积核（感受野不同）进行特征提取。（并未对原始特征图进行拆解分离，只是使用不同的卷积核对原始特征图进行卷积操作）。假设分支为n,则特征图维度变换为 (c, h, w) -&gt; (n, c, h, w)，原文中n=2。
Fuse：将多个分支的特征图提取结果相加。特征图维度变换为 (n, c, h, w) -&gt; (c, h, w)。再通过全局平均池，特征图维度变换为 (c, h, w) -&gt; (c, 1, 1)，然后利用全连接层进行降维（限制了最低维度，通过全连接层生成d×1的向量(图中的z)，公式如图中所示(δ表示ReLU激活函数，B表示Batch Noramlization,W是一个d×C的维的)。d的取值是由公式d = max(C/r,L)确定，r是一个缩小的比率(与SENet中相似)，L表示d的最小值，原文实验中L的值为32。），再利用两个（或多个，和分支数目相同，原论文中为两个）全连接层进行升维，得到两个（多个）维度同降维前相同的特征图（向量）。在对两个特征向量进行softmax处理。假设分支为n,则特征图维度为 n个(c, 1, 1) ，原文中n=2，即a-&gt;(c, 1, 1)， b-&gt;(c, 1, 1)。
select：利用softmax处理后的多个特征向量分别乘以第一步中的多分支提取的特征图结果。特征维度变化为n个(c, 1 ,1) * n 个(c, h ,w) = (n, c, h, w)。最后将n个特征图进行相加。
3. 优势 SKNet的设计在以下几个方面具有优势：
多尺度信息融合 通过选择性地应用不同尺度的卷积核，SKNet能够有效地融合多尺度的特征信息。这有助于网络捕捉不同层次的视觉特征，提高了特征的表征能力。
自适应性 选择模块使网络能够自适应地选择卷积核的尺度，从而适应不同任务和图像的特点。这种自适应性能够使网络在各种场景下都能表现出色。
减少计算成本 尽管引入了多尺度卷积核，但由于选择模块的存在，SKNet只会选择一部分卷积核进行计算，从而减少了计算成本，保持了网络的高效性。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/692b35f89340915bd4f716f00d92c4db/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-09T13:05:05+08:00" />
<meta property="article:modified_time" content="2023-08-09T13:05:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【深度学习注意力机制系列】—— SKNet注意力机制（附pytorch实现）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>SKNet（Selective Kernel Network）<strong>是一种用于图像分类和目标检测任务的深度神经网络架构，其核心创新是</strong>引入了选择性的多尺度卷积核（Selective Kernel）以及一种新颖的注意力机制</strong>，从而在不增加网络复杂性的情况下提升了特征提取的能力。SKNet的设计旨在<strong>解决多尺度信息融合的问题，使网络能够适应不同尺度的特征。</strong></p> 
<h4><a id="1__4"></a>1. 核心思想</h4> 
<p>SKNet的核心思想是**通过选择性地应用不同尺度的卷积核，从而在不同层级上捕捉多尺度特征。**为了实现这一点，SKNet引入了一个选择模块，用于自适应地决定在每个通道上使用哪些尺度的卷积核。这种选择性的多尺度卷积核有助于提升特征表示的能力，使网络更具适应性和泛化能力。</p> 
<h4><a id="2__10"></a>2. 结构</h4> 
<p>SKNet的结构如下：</p> 
<p><img src="https://images2.imgbox.com/a9/ae/Q6OOUeAB_o.png" alt="在这里插入图片描述"></p> 
<p><strong>实现机制：</strong></p> 
<ul><li> <p><strong>split</strong>：对特征图进行多分支分离卷积，各分支使用不同的卷积核（感受野不同）进行特征提取。（并未对原始特征图进行拆解分离，只是使用不同的卷积核对原始特征图进行卷积操作）。假设分支为n,则特征图维度变换为 (c, h, w) -&gt; (n, c, h, w)，原文中n=2。</p> </li><li> <p><strong>Fuse</strong>：将多个分支的特征图提取结果相加。特征图维度变换为 (n, c, h, w) -&gt; (c, h, w)。再通过全局平均池，特征图维度变换为 (c, h, w) -&gt; (c, 1, 1)，然后利用全连接层进行降维（限制了最低维度，通过全连接层生成d×1的向量(图中的z)，公式如图中所示(δ表示ReLU激活函数，B表示Batch Noramlization,W是一个d×C的维的)。d的取值是由公式d = max(C/r,L)确定，r是一个缩小的比率(与SENet中相似)，L表示d的最小值，原文实验中L的值为32。），再利用两个（或多个，和分支数目相同，原论文中为两个）全连接层进行升维，得到两个（多个）维度同降维前相同的特征图（向量）。在对两个特征向量进行softmax处理。假设分支为n,则特征图维度为 n个(c, 1, 1) ，原文中n=2，即a-&gt;(c, 1, 1)， b-&gt;(c, 1, 1)。</p> </li><li> <p><strong>select</strong>：利用softmax处理后的多个特征向量分别乘以第一步中的多分支提取的特征图结果。特征维度变化为n个(c, 1 ,1) * n 个(c, h ,w) = (n, c, h, w)。最后将n个特征图进行相加。</p> </li></ul> 
<h4><a id="3__30"></a>3. 优势</h4> 
<p>SKNet的设计在以下几个方面具有优势：</p> 
<ul><li><strong>多尺度信息融合</strong></li></ul> 
<p>通过选择性地应用不同尺度的卷积核，SKNet能够有效地融合多尺度的特征信息。这有助于网络捕捉不同层次的视觉特征，提高了特征的表征能力。</p> 
<ul><li><strong>自适应性</strong></li></ul> 
<p>选择模块使网络能够自适应地选择卷积核的尺度，从而适应不同任务和图像的特点。这种自适应性能够使网络在各种场景下都能表现出色。</p> 
<ul><li><strong>减少计算成本</strong></li></ul> 
<p>尽管引入了多尺度卷积核，但由于选择模块的存在，SKNet只会选择一部分卷积核进行计算，从而减少了计算成本，保持了网络的高效性。</p> 
<h4><a id="4_48"></a>4.代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">SKNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> L<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        :param in_channels:  输入通道维度
        :param out_channels: 输出通道维度   原论文中 输入输出通道维度相同
        :param stride:  步长，默认为1
        :param M:  分支数
        :param r: 特征Z的长度，计算其维度d 时所需的比率（论文中 特征S-&gt;Z 是降维，故需要规定 降维的下界）
        :param L:  论文中规定特征Z的下界，默认为32
        采用分组卷积： groups = 32,所以输入channel的数值必须是group的整数倍
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SKNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        d <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>in_channels <span class="token operator">//</span> r<span class="token punctuation">,</span> L<span class="token punctuation">)</span>  
        self<span class="token punctuation">.</span>M <span class="token operator">=</span> M
        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> out_channels
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">+</span> i<span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">+</span> i<span class="token punctuation">,</span> groups<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>global_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> d<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 降维</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>d<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> M<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> conv <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">)</span><span class="token punctuation">:</span>
            output<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        U <span class="token operator">=</span> <span class="token builtin">reduce</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x <span class="token operator">+</span> y<span class="token punctuation">,</span> output<span class="token punctuation">)</span>  
        s <span class="token operator">=</span> self<span class="token punctuation">.</span>global_pool<span class="token punctuation">(</span>U<span class="token punctuation">)</span>  
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
        a_b <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>z<span class="token punctuation">)</span> 
        a_b <span class="token operator">=</span> a_b<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>M<span class="token punctuation">,</span> self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> 
        a_b <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a_b<span class="token punctuation">)</span> 
        a_b <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>a_b<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        a_b <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       a_b<span class="token punctuation">)</span><span class="token punctuation">)</span>  
        V <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> output<span class="token punctuation">,</span>
                     a_b<span class="token punctuation">)</span><span class="token punctuation">)</span>  
        V <span class="token operator">=</span> <span class="token builtin">reduce</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x <span class="token operator">+</span> y<span class="token punctuation">,</span>
                   V<span class="token punctuation">)</span>  
        <span class="token keyword">return</span> V
</code></pre> 
<h4><a id="_105"></a>总结</h4> 
<p>SKNet是一种创新的深度神经网络架构，通过引入选择性的多尺度卷积核和注意力机制，提升了特征提取的能力。其核心结构包括选择模块和SK卷积层，能够有效地融合多尺度信息、自适应地调整卷积核的尺度，并减少计算成本。这使得SKNet在图像分类和目标检测等任务中取得了优越的性能。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/88ebd27d056b054b8d83ffe75b3075d9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">K8s常用命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6f0052f9b68f339be4b0d10d8c6e1e94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">IBM DB2 ODBC驱动包安装步骤（适用于zabbix环境调用）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>