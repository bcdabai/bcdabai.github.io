<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hive 调优 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hive 调优" />
<meta property="og:description" content="Hive 调优 一、SQL语句分析——EXPLAIN二、Fetch抓取三、本地模式四、表的优化1、小表大表JOIN2、大表JOIN大表3、Group by4、Count(Distinct) 去重统计5、笛卡尔积6、行列过滤7、分区分桶 五、合理设置Map及Reduce数1、复杂文件增加Map数2、小文件进行合并3、合理设置Reduce数 六、并行执行七、严格模式八、JVM重用九、压缩 一、SQL语句分析——EXPLAIN EXPLAIN不会执行该SQL，会分析出该SQL执行的步骤。
EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query 示例：
hive (default)&gt; explain select deptno, avg(sal) avg_sal from emp group by deptno; Explain STAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1 STAGE PLANS: Stage: Stage-1 Map Reduce Map Operator Tree: TableScan alias: emp Statistics: Num rows: 1 Data size: 7020 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: sal (type: double), deptno (type: int) outputColumnNames: sal, deptno Statistics: Num rows: 1 Data size: 7020 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: sum(sal), count(sal) keys: deptno (type: int) mode: hash outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 1 Data size: 7020 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: &#43; Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 1 Data size: 7020 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: double), _col2 (type: bigint) Execution mode: vectorized Reduce Operator Tree: Group By Operator aggregations: sum(VALUE." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/ae3c8b346726ac5e81977f3826c1d880/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T08:32:02+08:00" />
<meta property="article:modified_time" content="2023-04-05T08:32:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hive 调优</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Hive 调优</h4> 
 <ul><li><ul><li><ul><li><a href="#SQLEXPLAIN_2" rel="nofollow">一、SQL语句分析——EXPLAIN</a></li><li><a href="#Fetch_67" rel="nofollow">二、Fetch抓取</a></li><li><a href="#_97" rel="nofollow">三、本地模式</a></li><li><a href="#_112" rel="nofollow">四、表的优化</a></li><li><ul><li><a href="#1JOIN_113" rel="nofollow">1、小表大表JOIN</a></li><li><a href="#2JOIN_140" rel="nofollow">2、大表JOIN大表</a></li><li><a href="#3Group_by_183" rel="nofollow">3、Group by</a></li><li><a href="#4CountDistinct__211" rel="nofollow">4、Count(Distinct) 去重统计</a></li><li><a href="#5_217" rel="nofollow">5、笛卡尔积</a></li><li><a href="#6_220" rel="nofollow">6、行列过滤</a></li><li><a href="#7_231" rel="nofollow">7、分区分桶</a></li></ul> 
    </li><li><a href="#MapReduce_233" rel="nofollow">五、合理设置Map及Reduce数</a></li><li><ul><li><a href="#1Map_244" rel="nofollow">1、复杂文件增加Map数</a></li><li><a href="#2_255" rel="nofollow">2、小文件进行合并</a></li><li><a href="#3Reduce_287" rel="nofollow">3、合理设置Reduce数</a></li></ul> 
    </li><li><a href="#_319" rel="nofollow">六、并行执行</a></li><li><a href="#_338" rel="nofollow">七、严格模式</a></li><li><a href="#JVM_350" rel="nofollow">八、JVM重用</a></li><li><a href="#_352" rel="nofollow">九、压缩</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h4><a id="SQLEXPLAIN_2"></a>一、SQL语句分析——EXPLAIN</h4> 
<p>EXPLAIN不会执行该SQL，会分析出该SQL执行的步骤。</p> 
<pre><code class="prism language-sql"><span class="token keyword">EXPLAIN</span> <span class="token punctuation">[</span><span class="token keyword">EXTENDED</span> <span class="token operator">|</span> DEPENDENCY <span class="token operator">|</span> <span class="token keyword">AUTHORIZATION</span><span class="token punctuation">]</span> query 
</code></pre> 
<p>示例：</p> 
<pre><code class="prism language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">explain</span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
<span class="token keyword">Explain</span>
STAGE DEPENDENCIES:
  Stage<span class="token operator">-</span><span class="token number">1</span> <span class="token operator">is</span> a root stage
  Stage<span class="token operator">-</span><span class="token number">0</span> depends <span class="token keyword">on</span> stages: Stage<span class="token operator">-</span><span class="token number">1</span>

STAGE PLANS:
  Stage: Stage<span class="token operator">-</span><span class="token number">1</span> 
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: emp
            <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
            <span class="token keyword">Select</span> Operator
              expressions: sal <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> deptno <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span>
              outputColumnNames: sal<span class="token punctuation">,</span> deptno
              <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
              <span class="token keyword">Group</span> <span class="token keyword">By</span> Operator
                aggregations: <span class="token function">sum</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span>
                <span class="token keyword">keys</span>: deptno <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span>
                <span class="token keyword">mode</span>: <span class="token keyword">hash</span>
                outputColumnNames: _col0<span class="token punctuation">,</span> _col1<span class="token punctuation">,</span> _col2
                <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
                Reduce Output Operator
                  <span class="token keyword">key</span> expressions: _col0 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span>
                  sort <span class="token keyword">order</span>: <span class="token operator">+</span>
                  Map<span class="token operator">-</span>reduce <span class="token keyword">partition</span> <span class="token keyword">columns</span>: _col0 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span>
                  <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
                  <span class="token keyword">value</span> expressions: _col1 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> _col2 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">bigint</span><span class="token punctuation">)</span>
      Execution <span class="token keyword">mode</span>: vectorized
      Reduce Operator Tree:
        <span class="token keyword">Group</span> <span class="token keyword">By</span> Operator
          aggregations: <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">VALUE</span><span class="token punctuation">.</span>_col0<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">VALUE</span><span class="token punctuation">.</span>_col1<span class="token punctuation">)</span>
          <span class="token keyword">keys</span>: <span class="token keyword">KEY</span><span class="token punctuation">.</span>_col0 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span>
          <span class="token keyword">mode</span>: mergepartial
          outputColumnNames: _col0<span class="token punctuation">,</span> _col1<span class="token punctuation">,</span> _col2
          <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
          <span class="token keyword">Select</span> Operator
            expressions: _col0 <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>_col1 <span class="token operator">/</span> _col2<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">type</span>: <span class="token keyword">double</span><span class="token punctuation">)</span>
            outputColumnNames: _col0<span class="token punctuation">,</span> _col1
            <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
            <span class="token keyword">File</span> Output Operator
              compressed: <span class="token boolean">false</span>
              <span class="token keyword">Statistics</span>: Num <span class="token keyword">rows</span>: <span class="token number">1</span> <span class="token keyword">Data</span> size: <span class="token number">7020</span> Basic stats: COMPLETE <span class="token keyword">Column</span> stats: NONE
              <span class="token keyword">table</span>:
                  input format: org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span>SequenceFileInputFormat
                  output format: org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>HiveSequenceFileOutputFormat
                  serde: org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>lazy<span class="token punctuation">.</span>LazySimpleSerDe

  Stage: Stage<span class="token operator">-</span><span class="token number">0</span>
    <span class="token keyword">Fetch</span> Operator
      <span class="token keyword">limit</span>: <span class="token operator">-</span><span class="token number">1</span>
      Processor Tree:
        ListSink
</code></pre> 
<h4><a id="Fetch_67"></a>二、Fetch抓取</h4> 
<p>对于某些查询可以不用MapReduce计算。例如：<code>SELECT * FROM employees;</code>在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p> 
<pre><code class="prism language-sql">默认：<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion <span class="token operator">=</span> more<span class="token punctuation">;</span>
</code></pre> 
<ul><li><strong>none</strong> : disable hive.fetch.task.conversion</li><li><strong>minimal</strong> : SELECT STAR, FILTER on partition columns, LIMIT only</li><li><strong>more</strong> : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)</li></ul> 
<p>把hive.fetch.task.conversion设置成more，以下都不会执行mapreduce程序。</p> 
<pre><code class="prism language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>more<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<p>把hive.fetch.task.conversion设置成none，以下查询都会执行mapreduce程序。</p> 
<pre><code class="prism language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>none<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_97"></a>三、本地模式</h4> 
<p>有时Hive的输入数据量比较小，此时触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p> 
<p>用户可以通过设置<code>hive.exec.mode.local.auto</code>的值为true，让Hive在适当的时候自动启动这个优化。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token comment">//开启本地mr</span>
<span class="token comment">//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token punctuation">.</span>inputbytes<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">50000000</span><span class="token punctuation">;</span>
<span class="token comment">//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token punctuation">.</span>input<span class="token punctuation">.</span>files<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_112"></a>四、表的优化</h4> 
<h5><a id="1JOIN_113"></a>1、小表大表JOIN</h5> 
<p>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存，在map端完成join（MapJoin）。</p> 
<p>开启MapJoin参数设置<br> （1）设置自动选择Mapjoin (默认为true)</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> 
</code></pre> 
<p>（2）大表小表的阈值设置（默认25M以下认为是小表）：</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>smalltable<span class="token punctuation">.</span>filesize <span class="token operator">=</span> <span class="token number">25000000</span><span class="token punctuation">;</span>
</code></pre> 
<p>MapJoin的工作机制：小表直接进内存，只对大表进行MAP操作，省去了REDUCE操作。</p> 
<p><strong>注意：</strong></p> 
<ul><li>小表大表JOIN主要影响的是内连接的情况；</li><li>新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</li><li>map：做数据处理，（<strong>连表也是一种数据处理</strong>）</li><li>reduce：根据业务，对数据进行计算，获得我们想要的结果，比如统计，求和等。</li><li>MapJoin：利用cachefile接入数据 与map端接入的数据进行逻辑连接，不需要写reduce</li><li>ReduceJoin：map端只完成文件合并，利用相同的关联条件id作为key输出到reduce端，reduce端根据key聚合达到关联的效果</li></ul> 
<h5><a id="2JOIN_140"></a>2、大表JOIN大表</h5> 
<p><strong>（1）空KEY过滤</strong><br> 有时join超时是因为<strong>某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够，发生数据倾斜</strong>。此时我们应该仔细分析这些异常的key，如果这些key对应的数据是异常数据，那就需要进行过滤。例如key为空时，表示的是异常数据，需要进行剔除：</p> 
<pre><code class="prism language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable 
<span class="token keyword">select</span> n<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> nullidtable <span class="token keyword">where</span> id <span class="token operator">is</span> <span class="token operator">not</span> <span class="token boolean">null</span> <span class="token punctuation">)</span> n  
<span class="token keyword">left</span> <span class="token keyword">join</span> bigtable o <span class="token keyword">on</span> n<span class="token punctuation">.</span>id <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）空KEY转换</strong><br> 有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。例如：</p> 
<p>随机分布空null值<br> 1）设置5个reduce个数</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）JOIN两张表</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> n<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">from</span> nullidtable n <span class="token keyword">full</span> <span class="token keyword">join</span> bigtable o <span class="token keyword">on</span> 
nvl<span class="token punctuation">(</span>n<span class="token punctuation">.</span>id<span class="token punctuation">,</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p><strong>（3）SMB(Sort Merge Bucket join) 桶JOIN</strong><br> 先将每个表，进行分桶，分桶键相同，桶数相同。两个表分别针对ID（关联字段）进行分桶。<br> <img src="https://images2.imgbox.com/f6/c5/TIQObwER_o.png" alt="在这里插入图片描述"></p> 
<p>设置参数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin<span class="token punctuation">.</span>sortedmerge <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BucketizedHiveInputFormat<span class="token punctuation">;</span>
</code></pre> 
<p><strong>注意：</strong><br> 创建分桶表1,桶的个数不要超过可用CPU的核数。</p> 
<h5><a id="3Group_by_183"></a>3、Group by</h5> 
<p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。<br> <img src="https://images2.imgbox.com/60/71/B4rvc9cw_o.png" alt="在这里插入图片描述"><br> 并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p> 
<p><strong>(1）开启Map端聚合参数设置</strong><br> 1）是否在Map端进行聚合，默认为True</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p>2）在Map端进行聚合操作的条目数目</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>mapaggr<span class="token punctuation">.</span>checkinterval <span class="token operator">=</span> <span class="token number">100000</span>
</code></pre> 
<p>3）有数据倾斜的时候进行负载均衡（默认是false）</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p><strong>负载均衡：</strong><br> 当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</p> 
<p>先在第一个MR中局部汇总，再在一个MR中整体汇总，启用两个MR，耗时增长，但是，解决了数据倾斜问题。</p> 
<h5><a id="4CountDistinct__211"></a>4、Count(Distinct) 去重统计</h5> 
<p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,但是需要注意group by造成的数据倾斜问题.</p> 
<p><strong>虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</strong></p> 
<h5><a id="5_217"></a>5、笛卡尔积</h5> 
<p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p> 
<h5><a id="6_220"></a>6、行列过滤</h5> 
<p><strong>列处理</strong>：在SELECT中，只拿需要的列，如果有分区，尽量使用分区过滤，少用<code>SELECT *</code>。<br> <strong>行处理</strong>：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤。</p> 
<p>通过子查询后，再关联表：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> b<span class="token punctuation">.</span>id 
<span class="token keyword">from</span> bigtable b
<span class="token keyword">join</span> <span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> bigtable <span class="token keyword">where</span> id <span class="token operator">&lt;=</span> <span class="token number">10</span> <span class="token punctuation">)</span> o 
<span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7_231"></a>7、分区分桶</h5> 
<h4><a id="MapReduce_233"></a>五、合理设置Map及Reduce数</h4> 
<p><strong>1）通常情况下，作业会通过input的目录产生一个或者多个map任务。</strong><br> 主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p> 
<p><strong>2）是不是map数越多越好？</strong><br> 答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p> 
<p><strong>3）是不是保证每个map处理接近128m的文件块，就高枕无忧了？</strong><br> 答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。<br> <font color="blue"> 针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</font></p> 
<h5><a id="1Map_244"></a>1、复杂文件增加Map数</h5> 
<p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p> 
<p>增加map的方法为：根据<br> <code>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M</code>公式，调整maxSize最大值。<strong>让maxSize最大值低于blocksize就可以增加map的个数。</strong></p> 
<p>设置最大切片值为100个字节：</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>input<span class="token punctuation">.</span>fileinputformat<span class="token punctuation">.</span>split<span class="token punctuation">.</span>maxsize<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="2_255"></a>2、小文件进行合并</h5> 
<p><strong>1）在map执行前合并小文件，减少map数</strong><br> CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>CombineHiveInputFormat<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）在Map-Reduce的任务结束时合并小文件的设置</strong><br> 在map-only任务结束时合并小文件，默认true</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>在map-reduce任务结束时合并小文件，默认false</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapredfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>合并文件的大小，默认256M</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>task <span class="token operator">=</span> <span class="token number">268435456</span><span class="token punctuation">;</span>
</code></pre> 
<p>当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>smallfiles<span class="token punctuation">.</span>avgsize <span class="token operator">=</span> <span class="token number">16777216</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="3Reduce_287"></a>3、合理设置Reduce数</h5> 
<p><strong>（1）调整reduce个数方法一</strong><br> 1）每个Reduce处理的数据量默认是256MB</p> 
<pre><code class="prism language-sql">hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer<span class="token operator">=</span><span class="token number">256000000</span>
</code></pre> 
<p>2）每个任务最大的reduce数，默认为1009</p> 
<pre><code class="prism language-sql">hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">1009</span>
</code></pre> 
<p>3）计算reducer数的公式</p> 
<pre><code class="prism language-sql">N<span class="token operator">=</span><span class="token function">min</span><span class="token punctuation">(</span>参数<span class="token number">2</span>，总输入数据量<span class="token operator">/</span>参数<span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）调整reduce个数方法二</strong><br> 在hadoop的mapred-default.xml文件中修改<br> 设置每个job的Reduce个数</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（3）reduce个数并不是越多越好</strong><br> 1）过多的启动和初始化reduce也会消耗时间和资源；</p> 
<p>2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p> 
<p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p> 
<h4><a id="_319"></a>六、并行执行</h4> 
<ul><li>并行：真正意义上的并发执行；多线程同时执行；</li><li>并发： 多线程执行，但不是同时；多个线程抢占几个CPU资源；</li></ul> 
<p>执行SQL会分多个阶段，通过EXPLAIN可以查看具体阶段；各个阶段间有的有依赖关系，有的是比较独立的。互相独立的阶段，可以拿出来并行执行。</p> 
<p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。<br> 通过设置参数<code>hive.exec.parallel = true</code>，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>              <span class="token comment">//打开任务并行执行</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">;</span>  <span class="token comment">//同一个sql允许最大并行度，默认为8。</span>
</code></pre> 
<p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p> 
<h4><a id="_338"></a>七、严格模式</h4> 
<p>Hive可以通过设置防止一些危险操作（大数据量查询等耗费资源的操作）。</p> 
<p><strong>1、分区表不使用分区过滤</strong><br> <code>hive.strict.checks.no.partition.filter = true</code>时，对于分区表，如果过滤条件中不包含分区字段，就不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p> 
<p><strong>2、使用order by没有limit过滤</strong><br> <code>hive.strict.checks.orderby.no.limit = true</code>时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p> 
<p><strong>3、笛卡尔积</strong><br> <code>hive.strict.checks.cartesian.product = true</code>时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在 执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p> 
<h4><a id="JVM_350"></a>八、JVM重用</h4> 
<p>主要用在小文件场景，频繁建容器，销毁容器，占用时间超过计算时间。可以让多个TASK(MAP或REDUCE)，在同一个容器(JVM环境)中执行。</p> 
<h4><a id="_352"></a>九、压缩</h4> 
<p>减少磁盘使用空间；IO传输的数据量减低，传输速度就会变快；</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/68f28764f5a2882193c2989b43224961/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">通俗易懂的知识图谱（Knowledge Graph）简介</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b60a0fa7b807f99013e2597c03f71efa/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LeetCode刷题笔记（Top K Frequent Elements）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>