<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LGBM函数及参数详解 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LGBM函数及参数详解" />
<meta property="og:description" content="LGBM Python API Dataset class lightgbm.Dataset(data, label=None, max_bin=None, reference=None, weight=None, group=None, init_score=None, silent=False, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, params=None, free_raw_data=True)
创建一个带label的训练集和交叉验证集 trn_data = lgb.Dataset(X_tr, label=y_tr) val_data = lgb.Dataset(X_valid, label=y_valid) Booster class lightgbm.Booster(params=None, train_set=None, model_file=None, silent=False) #booster可用lgb来代替
params 字典形式的参数train_set Training dataset.model_file model文件的路径silent 构建模型时是否打印信息 只要有lgb实例，就可以调用下列函数 ，包括 predict，
lgb.add_valid 添加交叉训练集 lgb.attr(key) Get attribute string from the Booster.
lgb.current_iteration() Get the index of the current iteration.
lgb.dump_model(num_iteration=-1) Dump Booster to json format.
lgb.eval(data, name, feval=None) Evaluate for data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7a7e08036107d44e3ee4b7860af83e52/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-04-02T21:05:52+08:00" />
<meta property="article:modified_time" content="2019-04-02T21:05:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LGBM函数及参数详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="margin-left:0cm;"><strong>LGBM Python API</strong></h2> 
<h3 style="margin-left:0cm;"><span style="color:#6a737d;">Dataset</span></h3> 
<p style="margin-left:0cm;"><span style="color:#6a737d;">class lightgbm.Dataset(data, label=None, max_bin=None, reference=None, weight=None, group=None, init_score=None, silent=False, feature_name='auto', categorical_feature='auto', params=None, free_raw_data=True)</span></p> 
<h3 style="margin-left:0cm;"><span style="color:#000000;">创建一个带label的训练集和交叉验证集</span></h3> 
<pre class="has"><code>    trn_data = lgb.Dataset(X_tr, label=y_tr)
    val_data = lgb.Dataset(X_valid, label=y_valid)</code></pre> 
<h3>Booster </h3> 
<p>class lightgbm.Booster(params=None, train_set=None, model_file=None, silent=False)    #booster可用lgb来代替</p> 
<ul><li><strong>params</strong>   字典形式的参数</li><li><strong>train_set </strong>Training dataset.</li><li><strong>model_file </strong>model文件的路径</li><li><strong>silent </strong>构建模型时是否打印信息</li></ul> 
<p><strong>只要有lgb实例，就可以调用下列函数 ，包括</strong> predict，</p> 
<p>lgb.add_valid  添加交叉训练集 </p> 
<p>lgb.attr(key)  Get attribute string from the Booster.</p> 
<p>lgb.current_iteration()  Get the index of the current iteration.</p> 
<p>lgb.dump_model(num_iteration=-1)   Dump Booster to json format.</p> 
<p>lgb.eval(data, name, feval=None)    Evaluate for data.   <strong>Result</strong> – List with evaluation results.</p> 
<p>lgb.eval_train(feval=None)   Evaluate for training data.</p> 
<p>lgb.eval_valid(feval=None)    Evaluate for validation data.</p> 
<p>lgb.feature_importance(importance_type='split', iteration=-1)   Get feature importances.</p> 
<p>lgb.feature_name()   Get names of features.</p> 
<p>lgb.free_dataset()     Free Booster’s Datasets.</p> 
<p>lgb.free_network()    Free Network.</p> 
<p>lgb.get_leaf_output(tree_id, leaf_id)   Get the output of a leaf.</p> 
<p>lgb.num_feature()     Get number of features.</p> 
<p><strong>predict</strong>(data, num_iteration=-1, raw_score=False, pred_leaf=False, pred_contrib=False, data_has_header=False, is_reshape=True, pred_parameter=None)</p> 
<p>lgb.reset_parameter(params)</p> 
<p>lgb.rollback_one_iter()      Rollback one iteration.</p> 
<p>lgb.save_model(filename, num_iteration=-1)</p> 
<p>lgb.set_attr(**kwargs)      Set the attribute of the Booster.</p> 
<p>lgb.set_network(machines, local_listen_port=12400, listen_time_out=120, num_machines=1)    Set the network configuration.</p> 
<p>lgb.set_train_data_name(name)</p> 
<p>lgb.update(train_set=None, fobj=None)     Update for one iteration.</p> 
<h2>Train API</h2> 
<h3> lightgbm.train</h3> 
<p>lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', early_stopping_rounds=None, evals_result=None, verbose_eval=True, learning_rates=None, keep_training_booster=False, callbacks=None)</p> 
<ul><li><strong>params</strong> (<em>dict</em>) – Parameters for training.</li><li><strong>train_set</strong> (<a href="https://github.com/apachecn/lightgbm-doc-zh/blob/master/docs/8.md#lightgbm.Dataset"><em>Dataset</em></a>) – Data to be trained.</li><li><strong>num_boost_round</strong> (<em>int</em>_,_ <em>optional</em> <em>(<strong>default=100</strong>)</em>) – 迭代次数，也就是弱学习器的数量</li><li><strong>valid_sets </strong>– List of data to be evaluated during training.</li></ul> 
<p>训练参数中没有单个弱学习器的参数(即决策树的参数) ，<strong>params</strong>表示所有弱学习器的参数</p> 
<h4><strong>params参数包括：</strong></h4> 
<ul><li>"objective" : "regression", "binary",</li><li>"metric" : "rmse","auc"</li><li>"boosting": 'gbdt',</li><li> "max_depth": -1,</li><li>"min_child_samples": 20, </li><li>"num_leaves" : 31,</li><li>"learning_rate" : 0.1, </li><li>"subsample" : 0.8,</li><li>"colsample_bytree" : 0.8, </li><li>"verbosity": -1</li><li>"bagging_freq": 5,</li><li>"bagging_fraction" : 0.4,</li><li>"feature_fraction" : 0.05,</li><li>"min_data_in_leaf": 80,</li><li>"min_sum_heassian_in_leaf": 10,</li><li>"tree_learner": "serial",</li><li>"boost_from_average": "false",</li><li>"lambda_l1" : 5,</li><li>"lambda_l2" : 5</li><li>"bagging_seed" : random_state</li><li> "seed": random_state</li></ul> 
<p><strong><span style="color:#2c3e50;">boosting_type</span> </strong></p> 
<p>提升算法类型：‘gbdt’，‘dart’，‘goss’，‘rf’ 。默认算法为gbdt，一般用的最多。</p> 
<p>dart：Dropouts meet Multiple Additive Regression Trees，是利用dropout解决过拟合的Regression Trees，利用了深度神经网络中dropout设置的技巧，<strong>随机丢弃生成的决策树</strong>，然后再从剩下的决策树集中迭代优化提升树，特点是</p> 
<ul><li>因为随机dropout不使用用于保存预测结果的buffer所以训练会更慢</li><li>因为随机，早停可能不够稳定</li></ul> 
<p>    dart与gbdt的不同点：计算下一棵树要拟合的梯度的时候，仅仅随机从已经生成的树中选取一部分。 DART添加一棵树时需        要先归一化。</p> 
<p>goss ：基本思想是首先对训练集数据根据<strong>梯度排序</strong>，预设一个<strong>比例划分梯度大小</strong>，<strong>保留在所有样本中梯度大的数据样本</strong>；再设       置一个采样比例，<strong>从梯度小的样本中按比例抽取样本</strong>。为了弥补对样本分布造成的影响，GOSS算法在计算信息增益时，会       对较<strong>小梯度的数据集乘以一个系数</strong>，用来放大。这样，在计算信息增益时，算法可以更加关注“未被充分训练”的样本数据。         GOSS通过对较小的样本数据集估算增益，<strong>大大的减少了计算量</strong>。而且通过证明，<strong>GOSS算法不会过多的降低训练的精度</strong>。</p> 
<p>rf ：随机森林，很熟悉了。</p> 
<p><strong><span style="color:#2c3e50;">num_leaves</span></strong></p> 
<p>因为LightGBM使用的是leaf-wise的算法，因此在调节树的复杂程度时，使用的是num_leaves而不是max_depth。大致换算关系：num_leaves = 2^(max_depth)。它的值的设置应该小于2^(max_depth)，否则可能会导致过拟合。</p> 
<p><strong><span style="color:#2c3e50;">max_depth</span></strong></p> 
<p>每个弱学习器也就是决策树的最大深度，-1表示不限制，</p> 
<p>n_estimators</p> 
<p>弱学习器的数目，因为gbdt原理是利用通过梯度不断拟合新的弱学习器，直到达到设定的弱学习器的数量。</p> 
<p><strong><span style="color:#2c3e50;">learning_rate</span></strong> </p> 
<p>Boosting learning rate. </p> 
<p><strong><span style="color:#2c3e50;">max_bin</span></strong></p> 
<p><span style="color:#6a737d;">为直方图算法中特征值离散化的分段数量</span></p> 
<h3>lightgbm.cv</h3> 
<p>lightgbm.cv(params, train_set, num_boost_round=10, folds=None, nfold=5, stratified=True, shuffle=True, metrics=None, fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', early_stopping_rounds=None, fpreproc=None, verbose_eval=None, show_stdv=True, seed=0, callbacks=None)</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2c5d585c8018974edc0fc884263b713/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">php命令行（cli）模式下require引入错误解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/17f18b8a3a3de076a155aab21ea417e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue组件通信深入二: pubsub.js</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>