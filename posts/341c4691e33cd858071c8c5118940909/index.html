<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ES-分词器 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ES-分词器" />
<meta property="og:description" content="简介 分词器是es中的一个组件，通俗意义上理解，就是将一段文本按照一定的逻辑，分析成多个词语，同时对这些词语进行常规化的一种工具；ES会将text格式的字段按照分词器进行分词，并编排成倒排索引，正是因为如此，es的查询才如此之快。
一个analyzer即分析器，无论是内置的还是自定义的，只是一个包含character filters（字符过滤器）、 tokenizers（分词器）、token filters（令牌过滤器）三个细分模块的包。
看下这三个细分模块包的作用：
character filters（字符过滤器）：分词之前的预处理，过滤无用字符
token filters（令牌过滤器）：停用词、时态转换，大小写转换、同义词转换、语气词处理等。
tokenizers（分词器）：切词
自定义分词器 先来看个自定义分词器，了解整个分析器analyzer的构造
PUT custom_analysis { &#34;settings&#34;:{ &#34;analysis&#34;:{	#分析配置，可以设置char_filter(字符过滤器)、filter(令牌过滤器)、tokenizer(分词器)、analyzer(分析器) &#34;char_filter&#34;: { # 字符过滤器配置 &#34;my_char_filter&#34;:{ #定义一个字符过滤器：my_char_filter &#34;type&#34;:&#34;mapping&#34;, # 字符过滤器类型：主要有三种：html_strip(标签过滤)、mapping(字符替换)、pattern_replace(正则匹配替换) &#34;mappings&#34;:[	# mapping的参数:表示 &#39;&amp;&#39; 会被替换成 &#39;and&#39; &#34;&amp; =&gt; and&#34;, &#34;| =&gt; or&#34; ] }, &#34;html_strip_char_filter&#34;:{ &#34;type&#34;:&#34;html_strip&#34;, &#34;escaped_tags&#34;:[&#34;a&#34;] } }, &#34;filter&#34;: {	# 令牌过滤器配置 &#34;my_stopword&#34;:{ # 定义一个令牌过滤器：my_stopword &#34;type&#34;:&#34;stop&#34;, # 令牌过滤器类型：stop（停用（删除）词） &#34;stopwords&#34;:[	# stop的参数：表示这些词会被删除 &#34;is&#34;, &#34;in&#34;, &#34;the&#34;, &#34;a&#34;, &#34;at&#34;, &#34;for&#34; ] } }, &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/341c4691e33cd858071c8c5118940909/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-17T20:58:59+08:00" />
<meta property="article:modified_time" content="2022-11-17T20:58:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ES-分词器</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="YdJk2">简介</h2> 
<p id="u342cbc52">分词器是es中的一个组件，通俗意义上理解，就是将一段文本按照一定的逻辑，分析成多个词语，同时对这些词语进行常规化的一种工具；ES会将text格式的字段按照分词器进行分词，并编排成倒排索引，正是因为如此，es的查询才如此之快。</p> 
<p id="u1b794d23">一个analyzer即分析器，无论是内置的还是自定义的，只是一个包含character filters（字符过滤器）、 tokenizers（分词器）、token filters（令牌过滤器）三个细分模块的包。</p> 
<p id="u7bc96e5d">看下这三个细分模块包的作用：</p> 
<p id="u42957500"><strong>character filters（字符过滤器）</strong>：分词之前的预处理，过滤无用字符</p> 
<p id="u6cf1ec7d"><strong>token filters（令牌过滤器）</strong>：停用词、时态转换，大小写转换、同义词转换、语气词处理等。</p> 
<p id="u2a4a8c64"><strong>tokenizers（分词器）：</strong>切词</p> 
<h2 id="a4ViZ">自定义分词器</h2> 
<p id="ub79bb8a6">先来看个自定义分词器，了解整个分析器analyzer的构造</p> 
<pre id="qqQ3E">PUT custom_analysis
{
  "settings":{
    "analysis":{	#分析配置，可以设置char_filter(字符过滤器)、filter(令牌过滤器)、tokenizer(分词器)、analyzer(分析器)
      "char_filter": { # 字符过滤器配置
        "my_char_filter":{ #定义一个字符过滤器：my_char_filter
          "type":"mapping", # 字符过滤器类型：主要有三种：html_strip(标签过滤)、mapping(字符替换)、pattern_replace(正则匹配替换)
          "mappings":[	# mapping的参数:表示 '&amp;' 会被替换成 'and'
            "&amp; =&gt; and",
            "| =&gt; or"
          ]
        },
        "html_strip_char_filter":{
          "type":"html_strip",
          "escaped_tags":["a"]
        }
      },
      "filter": {	# 令牌过滤器配置
        "my_stopword":{ # 定义一个令牌过滤器：my_stopword
          "type":"stop", # 令牌过滤器类型：stop（停用（删除）词）
          "stopwords":[	# stop的参数：表示这些词会被删除
            "is",
            "in",
            "the",
            "a",
            "at",
            "for"
          ]
        }
      },
      "tokenizer": {	# 分词器配置
        "my_tokenizer":{ # 定义一个分词器my_tokenizer
          "type":"pattern", # 分词器类型：pattern 正则匹配
          "pattern":"[ ,.!?]" # pattern的参数：会根据这几个字符进行分割
        }
      },
      "analyzer": {	# 分析器：可以理解成组合了字符过滤器、令牌过滤器、分词器的一个整体。
        "my_analyzer":{ #定义一个分析器：my_analyzer
          "type":"custom", 
          "char_filter":["my_char_filter","html_strip_char_filter"], # 使用的字符过滤器
          "filter":["my_stopword"], # 使用的令牌过滤器
          "tokenizer":"my_tokenizer" # 使用的分词器
        }
      }
    }
  }
}</pre> 
<p id="u5deddc43"></p> 
<h2 id="RC2yB">字符过滤器（character filters）</h2> 
<p id="uf21c2669">字符过滤器是分词之前的预处理，过滤无用字符，主要有这三种：html_strip、mapping、pattern_replace</p> 
<h3 id="KKQgl">html_strip</h3> 
<p id="u362c4186">html_strip用于过滤html标签，它有个参数<strong>escaped_tags</strong>可以设置保留的标签</p> 
<p id="uf528a7c1">看下面例子</p> 
<pre id="Tbxe0">PUT index_html_strip
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter":{
          "type":"html_strip",
          "escaped_tags":["a"] 
        }
      },
      "analyzer": {
        "my_analyzer":{
          "tokenizer":"keyword",
          "char_filter":["my_char_filter"]
        }
      }
    }
  }
}
GET my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "&lt;p&gt;要的话就&lt;a&gt;点击&lt;/a&gt;&lt;/p&gt;"
}</pre> 
<p id="u5836ff9d">结果：p标签过滤掉了，而a标签保留了</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/24/80/CmVDokSA_o.png"></p> 
<h3 id="y5sRW">mapping</h3> 
<p id="ud0266e3f">mapping是字符替换</p> 
<p id="ue643f646">看下面例子，可以设置一些敏感词替换成*</p> 
<pre id="m5ZyM">PUT index_mapping
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter":{
          "type":"mapping",
          "mappings":[
            "滚 =&gt; *",
            "垃圾 =&gt; *",
            "手枪 =&gt; *",
            "你妈 =&gt; *"
            ] 
        }
      },
      "analyzer": {
        "my_analyzer":{
          "tokenizer":"keyword",
          "char_filter":["my_char_filter"]
        }
      }
    }
  }
}
GET index_mapping/_analyze
{
  "analyzer": "my_analyzer",
  "text": "你妈的，小垃圾，拿上你的手枪，滚远点！"
}</pre> 
<p id="ue2ff4e9a">结果：可以看到设置的敏感词被替换成*了</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/6a/e9/x43DCrqf_o.png"></p> 
<h3 id="g3Ezy">pattern_replace</h3> 
<p id="u204d3293">pattern_replace是正则匹配替换</p> 
<p id="u85f10ab5">可以匹配手机号码，将中间四个数字加密处理</p> 
<pre id="oElM6">PUT index_pattern_replace
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter":{
          "type":"pattern_replace",
          "pattern":"(\\d{3})\\d{4}(\\d{4})",
          "replacement":"$1****$2"
        }
      },
      "analyzer": {
        "my_analyzer":{
          "tokenizer":"keyword",
          "char_filter":["my_char_filter"]
        }
      }
    }
  }
}
GET index_pattern_replace/_analyze
{
  "analyzer": "my_analyzer",
  "text": "你的手机号是18814142694"
}</pre> 
<p id="u70306943">结果：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/73/49/wou4kWqD_o.png"></p> 
<h2 id="EL1KM">令牌过滤器（token filters）</h2> 
<p id="u465d8a3d">停用词（stop）、大小写转换（lowercase）、同义词转换（synonym）等。</p> 
<h3 id="yfeLy">stop-停用词</h3> 
<p id="u0265ffc2">停用词有个参数可以设置删除的词语：stopwords</p> 
<pre id="QZeLx">PUT /index_stop
{
  "settings": {
      "analysis": {
        "analyzer": {
          "my_stop": {
            "tokenizer": "whitespace",
            "filter": [ "my_stop" ]
          }
        },
        "filter": {
          "my_stop": {
            "type": "stop",
            "stopwords": [
            "is",
            "in",
            "the",
            "a",
            "at",
            "for"
          ]
          }
        }
      }
    }
}
GET index_stop/_analyze
{
  "analyzer": "my_stop",
  "text": ["What is a apple?"]
}</pre> 
<p id="u99a9fa56">结果：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/cb/44/kkLi8qT6_o.png"></p> 
<h3 id="jt1Me">synonym-同义词</h3> 
<p id="u0cb3281f">同义词过滤器需要配置同义词的文件路径synonyms_path，需要放在项目目录下的config文件目录里</p> 
<p id="u55ba8520">（本项目同义词文件完整路径：/app/elasticsearch-8.4.2/config/analysis/synonym.txt）</p> 
<pre id="kx7Vj">蒙丢丢 =&gt; 'DaB'</pre> 
<pre id="VNUFK">PUT /index_synonym
{
  "settings": {
      "analysis": {
        "analyzer": {
          "synonym": {
            "tokenizer": "whitespace",
            "filter": [ "synonym" ]
          }
        },
        "filter": {
          "synonym": {
            "type": "synonym",
            "synonyms_path": "analysis/synonym.txt"
          }
        }
      }
    }
}
GET index_synonym/_analyze
{
  "analyzer": "synonym",
  "text": ["蒙丢丢"]
}</pre> 
<p id="u39233655">结果：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/44/81/6VajWnlo_o.png"></p> 
<h2 id="P45kT">分词器（tokenizer）</h2> 
<p id="u33bbbac2">分词器的作用就是用来切词的。</p> 
<p id="ue5cb4424">常见的分词器有：</p> 
<p id="u5192fa7f">standard：默认分词器，中文支持的不理想，会逐字拆分</p> 
<p id="u85786153">pattern：以正则匹配分隔符，把文本拆分成若干词项</p> 
<p id="u3019b40c">simple pattern：以正则匹配词项，速度比pattern tokenizer快</p> 
<p id="ueaa27ecc">whitespace：以空白符分割</p> 
<pre id="cmluy">GET _analyze
{
  "analyzer": "whitespace",
  "text": ["What is a apple?"]
}</pre> 
<p id="ue7d4dca8">结果</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/3c/8a/gOFPILnt_o.png"></p> 
<h3 id="STfR3">中文分词器</h3> 
<p id="ua8216167">ES的中文分词器需要下载插件安装使用的。</p> 
<h4 id="DYdSy">安装&amp;部署</h4> 
<p id="u5def4aef">ik下载地址：<a href="https://github.com/medcl/elasticsearch-analysis-ik" title="GitHub - medcl/elasticsearch-analysis-ik: The IK Analysis plugin integrates Lucene IK analyzer into elasticsearch, support customized dictionary.">GitHub - medcl/elasticsearch-analysis-ik: The IK Analysis plugin integrates Lucene IK analyzer into elasticsearch, support customized dictionary.</a></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/85/aa/frOMGYdk_o.png"></p> 
<p id="uc8a127a4"><br> 点击Releases，选择版本下载</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f8/8c/eAUsEXSn_o.png"></p> 
<p id="uc8a127a4"><br> 在根目录下的plugins文件夹下，创建ik文件目录，将下载的插件解压到ik目录下</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/fd/93/GRElA8cy_o.png"></p> 
<h4 id="azmwo">ik配置文件说明</h4> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/62/53/CCO5lNRt_o.png"></p> 
<p id="u0024f4c5">IKAnalyzer.cfg.xml:IK分词配置文件<br> main.dic：主词库:<br> stopword.dic：英文停用词，不会建立在倒排索引中<br> quantifier.dic：特殊词库:计量单位等<br> suffix.dic：特殊词库: 后级名<br> surname.dic： 特殊词库: 百家姓<br> preposition：特殊词库: 语气词<br> 自定义词库:网络词汇、流行词、自造词等</p> 
<h4 id="I9cEq">重启ES</h4> 
<pre id="CsWvw">/app/elasticsearch-8.4.2/bin/elasticsearch -d
/app/kibana-8.4.2/bin/kibana &amp;</pre> 
<h4 id="yIbbp">使用</h4> 
<pre id="F8MpK">GET _analyze
{
  "analyzer": "ik_max_word",  #中文分词器：ik_max_word
  "text": ["今天真是美好的一天"]
}</pre> 
<p id="u7a2ed70b">结果</p> 
<pre id="blNIt">{
  "tokens": [
    {
      "token": "今天",
      "start_offset": 0,
      "end_offset": 2,
      "type": "CN_WORD",
      "position": 0
    },
    {
      "token": "天真",
      "start_offset": 1,
      "end_offset": 3,
      "type": "CN_WORD",
      "position": 1
    },
    {
      "token": "真是",
      "start_offset": 2,
      "end_offset": 4,
      "type": "CN_WORD",
      "position": 2
    },
    {
      "token": "美好",
      "start_offset": 4,
      "end_offset": 6,
      "type": "CN_WORD",
      "position": 3
    },
    {
      "token": "的",
      "start_offset": 6,
      "end_offset": 7,
      "type": "CN_CHAR",
      "position": 4
    },
    {
      "token": "一天",
      "start_offset": 7,
      "end_offset": 9,
      "type": "CN_WORD",
      "position": 5
    },
    {
      "token": "一",
      "start_offset": 7,
      "end_offset": 8,
      "type": "TYPE_CNUM",
      "position": 6
    },
    {
      "token": "天",
      "start_offset": 8,
      "end_offset": 9,
      "type": "COUNT",
      "position": 7
    }
  ]
}</pre> 
<p id="ub4ed150e"></p> 
<p id="ub4ed150e"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d59c577479c79d20c85ff6a5c170e0e3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ES增删改查入门</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5d268c1bde50e802b97563c5f3d37e00/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">嵌入式笔记一——代码编辑工具：Vim</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>