<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>文本数据预处理:可能需要关注这些点 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="文本数据预处理:可能需要关注这些点" />
<meta property="og:description" content="文章目录 1、文本数据获取2、常规文本数据预处理2.1 将文本数据清洗干净2.2 将文本数据格式化 3、任务相关的文本数据预处理3.1 不平衡问题3.2 数据增强问题3.3 数据标注问题 4、一些可用的文本预处理工具5、总结 本文关键词： 文本数据预处理、中文文本预处理、自然语言处理
摘要： 要进行自然语言处理相关工作，文本数据预处理是个必不可少的过程。本文将对文本数据预处理相关的内容进行归纳整理，主要包括以下4个方面内容：
文本数据获取常规文本数据预处理任务相关的文本数据预处理文本预处理工具 1、文本数据获取 “巧妇难为无米之炊”，要做文本数据处理，首先需要获得文本数据。对于此问题，大家可以“八仙过海，各显神通”，借助一切合法、合理方式收集数据集。一般的，可以通过：自有数据整理、公开数据爬取和开源数据引用三个渠道获取数据。
自有数据：收集整理自有或者组织内部的可用数据集。
爬取数据：爬虫是获取数据的重要手段，但是在执行该操作前需遵守相关法规和Robots协议，在爬取数据后合法应用数据。通常，可以通过requests、BeautifulSoup4和Selenium等python工具完成绝大多数爬取任务。
图片豆瓣电影评论爬取可参考：
https://www.cnblogs.com/fengxi177/p/16939376.html
开源数据：当前已有很多公开的NLP数据集支撑相关的研究和应用分析，如github项目： 项目名项目链接项目概述CLUEDatasetSearchhttps://github.com/CLUEbenchmark/CLUEDatasetSearch收集了众多中英文NLP数据集funNLPhttps://github.com/fighting41love/funNLP分门别类的组织了众多的NLP数据集和项目awesome-chinese-nlphttps://github.com/crownpku/Awesome-Chinese-NLP收集了中文自然语言处理相关资料Chinese_medical_NLPhttps://github.com/lrs1353281004/Chinese_medical_NLP收集了医疗NLP领域（主要关注中文）评测数据集与论文相关资源 由此，在收集好原始数据集后便可进行后续相关的NLP分析了。
特别的，数据集可以保存为txt、json、csv、tsv、sql表等等格式，只要你喜欢，都可以（哈哈哈，有些格式可能会比较占用内存，较大数据集时需要留意）。
图片此处分享一个csv超大文件数据读取技巧，即利用pandas的chunksize分块读取。
import pandas as pd df = pd.read_csv(&#34;data.csv&#34;, chunksize=10000) # 每次读取1w行数据 for df_chunk in df: print(df_chunk) 2、常规文本数据预处理 文本数据作为一种非结构化数据，除了特别处理过的数据集，大多数直接收集的文本数据会掺杂或多或少的无用信息，如果直接将其进行相关的文本分析于建模是无益的。通常，需要先对文本数据进行预处理操作。
文本数据预处理的主要目的一般有两个，即：
（1）将文本数据清洗干净（标准自定）
（2）将文本数据格式化（需求自定）
2.1 将文本数据清洗干净 空格换行符，利用replace操作将原始文本中的空格、tab键、换行符\n、\r等与文本无关的字符直接替换为空。
无用信息剔除，如：停用词表构建。
标点符号去除，利用正则表达式去除标点符号，中英文标点符号可以通过如下两个方式获取。
中文标点符号：from zhon.hanzi import punctuation （需要安装包：pip install zhon）
英文标点符号：from string import punctuation
特别的，文本情感分析中，可保留有情感倾向的标点符号，如：？和！
在噪声数据中提取需要数据，利用正则表达式完成数据提取。如：只需要提取汉字时可以利用正则[\u4e00-\u9fa5]
简体繁体转换，可安装包：pip install opencc
英文数据：词形还原、大小写转换等 （推荐python包：NLTK）
2.2 将文本数据格式化 文本分句，根据标点符号分句。文本分段，根据换行符或其他数据规律分段。文本根据字段存储：半结构化文本数据存储excel数据提取，推荐安装python包pandas，pip install pandas" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/bb8cceb40eadebdbff20ce5704533c7f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-02T11:58:04+08:00" />
<meta property="article:modified_time" content="2023-02-02T11:58:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">文本数据预处理:可能需要关注这些点</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><ul><li><a href="#1_11" rel="nofollow">1、文本数据获取</a></li><li><a href="#2_49" rel="nofollow">2、常规文本数据预处理</a></li><li><ul><li><a href="#21__54" rel="nofollow">2.1 将文本数据清洗干净</a></li><li><a href="#22__65" rel="nofollow">2.2 将文本数据格式化</a></li></ul> 
    </li><li><a href="#3_76" rel="nofollow">3、任务相关的文本数据预处理</a></li><li><ul><li><a href="#31__78" rel="nofollow">3.1 不平衡问题</a></li><li><a href="#32__85" rel="nofollow">3.2 数据增强问题</a></li><li><a href="#33__88" rel="nofollow">3.3 数据标注问题</a></li></ul> 
    </li><li><a href="#4_93" rel="nofollow">4、一些可用的文本预处理工具</a></li><li><a href="#5_99" rel="nofollow">5、总结</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<p><strong>本文关键词：</strong> 文本数据预处理、中文文本预处理、自然语言处理</p> 
<p><strong>摘要：</strong> 要进行自然语言处理相关工作，文本数据预处理是个必不可少的过程。本文将对文本数据预处理相关的内容进行归纳整理，主要包括以下4个方面内容：</p> 
<ul><li>文本数据获取</li><li>常规文本数据预处理</li><li>任务相关的文本数据预处理</li><li>文本预处理工具</li></ul> 
<h4><a id="1_11"></a>1、文本数据获取</h4> 
<p>“巧妇难为无米之炊”，要做文本数据处理，首先需要获得文本数据。对于此问题，大家可以“八仙过海，各显神通”，借助一切合法、合理方式收集数据集。一般的，可以通过：自有数据整理、公开数据爬取和开源数据引用三个渠道获取数据。</p> 
<ul><li> <p>自有数据：收集整理自有或者组织内部的可用数据集。</p> </li><li> <p>爬取数据：爬虫是获取数据的重要手段，但是在执行该操作前需遵守相关法规和Robots协议，在爬取数据后合法应用数据。通常，可以通过requests、BeautifulSoup4和Selenium等python工具完成绝大多数爬取任务。</p> </li></ul> 
<hr> 
<p>图片豆瓣电影评论爬取可参考：<br> https://www.cnblogs.com/fengxi177/p/16939376.html</p> 
<hr> 
<ul><li>开源数据：当前已有很多公开的NLP数据集支撑相关的研究和应用分析，如github项目：</li></ul> 
<font size="0.2"> </font> 
<table><thead><tr><th>项目名</th><th>项目链接</th><th>项目概述</th></tr></thead><tbody><tr><td>CLUEDatasetSearch</td><td>https://github.com/CLUEbenchmark/CLUEDatasetSearch</td><td>收集了众多中英文NLP数据集</td></tr><tr><td>funNLP</td><td>https://github.com/fighting41love/funNLP</td><td>分门别类的组织了众多的NLP数据集和项目</td></tr><tr><td>awesome-chinese-nlp</td><td>https://github.com/crownpku/Awesome-Chinese-NLP</td><td>收集了中文自然语言处理相关资料</td></tr><tr><td>Chinese_medical_NLP</td><td>https://github.com/lrs1353281004/Chinese_medical_NLP</td><td>收集了医疗NLP领域（主要关注中文）评测数据集与论文相关资源</td></tr></tbody></table> 
<p>由此，在收集好原始数据集后便可进行后续相关的NLP分析了。</p> 
<p>特别的，数据集可以保存为txt、json、csv、tsv、sql表等等格式，只要你喜欢，都可以（哈哈哈，有些格式可能会比较占用内存，较大数据集时需要留意）。<br> 图片此处分享一个csv超大文件数据读取技巧，即利用pandas的chunksize分块读取。</p> 
<pre><code>import pandas as pd

df = pd.read_csv("data.csv", chunksize=10000)  # 每次读取1w行数据
for df_chunk in df:
    print(df_chunk)
</code></pre> 
<h4><a id="2_49"></a>2、常规文本数据预处理</h4> 
<p>文本数据作为一种非结构化数据，除了特别处理过的数据集，大多数直接收集的文本数据会掺杂或多或少的无用信息，如果直接将其进行相关的文本分析于建模是无益的。通常，需要先对文本数据进行预处理操作。<br> 文本数据预处理的主要目的一般有两个，即：<br> （1）将文本数据清洗干净（标准自定）<br> （2）将文本数据格式化（需求自定）</p> 
<h5><a id="21__54"></a>2.1 将文本数据清洗干净</h5> 
<ul><li> <p>空格换行符，利用replace操作将原始文本中的空格、tab键、换行符\n、\r等与文本无关的字符直接替换为空。</p> </li><li> <p>无用信息剔除，如：停用词表构建。</p> </li><li> <p>标点符号去除，利用正则表达式去除标点符号，中英文标点符号可以通过如下两个方式获取。<br> 中文标点符号：from zhon.hanzi import punctuation （需要安装包：pip install zhon）<br> 英文标点符号：from string import punctuation<br> 特别的，文本情感分析中，可保留有情感倾向的标点符号，如：？和！</p> </li><li> <p>在噪声数据中提取需要数据，利用正则表达式完成数据提取。如：只需要提取汉字时可以利用正则[\u4e00-\u9fa5]</p> </li><li> <p>简体繁体转换，可安装包：pip install opencc</p> </li><li> <p>英文数据：词形还原、大小写转换等 （推荐python包：NLTK）</p> </li></ul> 
<h5><a id="22__65"></a>2.2 将文本数据格式化</h5> 
<ul><li>文本分句，根据标点符号分句。</li><li>文本分段，根据换行符或其他数据规律分段。</li><li>文本根据字段存储：半结构化文本数据存储</li><li>excel数据提取，推荐安装python包pandas，pip install pandas<br> docx格式数据提取，推荐安装python包python-docx，pip install python-docx</li><li>pdf数据提取，可安装包pdfminer.six，pip install pdfminer.six</li></ul> 
<p>至此，经过常规预处理后，文本数据会变的比较干净与规整，可以用于后续nlp研究与应用。（说明，适用于自己任务的操作才是必须的，其他的参照奥卡姆剃刀“如无必要，勿增实体”）。</p> 
<h4><a id="3_76"></a>3、任务相关的文本数据预处理</h4> 
<p>前面介绍了通常情况下文本预处理可能涉及的注意点，但是要真正的做好数据预处理，应该与具体的任务相结合起来。比如：数据不平衡问题，数据增强问题、数据标注问题等等。</p> 
<h5><a id="31__78"></a>3.1 不平衡问题</h5> 
<ul><li>不平衡分类问题：实际应用中数据存在长尾分布现象，需要注意处理不平衡分类问题。python包imbalanced-learn提供了几个不错的过采样和欠采样方法，可以试用。</li><li>不平衡回归问题，一篇好文链接：https://zhuanlan.zhihu.com/p/369627086</li></ul> 
<p>特别的，如需获得泛化性能好的模型，首先需要关注解决不平衡问题。</p> 
<h5><a id="32__85"></a>3.2 数据增强问题</h5> 
<p>数据太少，那就需要利用规则和算法增强数据，使数据多样化。</p> 
<h5><a id="33__88"></a>3.3 数据标注问题</h5> 
<ul><li>人工标注，好处：毕竟人多力量大，有多少人工有多少智能。坏处：成本昂贵。</li><li>主动学习标注，目的：通过一定的技术手段和方法降低标注成本。具体的，可利用单个机器学习模型或集成学习的思想，提取需要人工审核标注的数据。</li><li>标注平台与工具：可开发相应的自动化预标注平台，通过人工审核获得标注后的高质量数据集。</li></ul> 
<h4><a id="4_93"></a>4、一些可用的文本预处理工具</h4> 
<p>对于文本预处理工作，目前已有一些专门的工具包，功能比较多样，大家可以试用一下，提升自己处理数据的效率和质量。</p> 
<ul><li>数据预处理<br> https://github.com/dongrixinyu/JioNLP</li><li>数据增强<br> https://github.com/425776024/nlpcda</li></ul> 
<h4><a id="5_99"></a>5、总结</h4> 
<p>本文对文本预处理，特别是中文文本预处理做了一个简要的概述，希望于相关的nlper有所帮助。后续，将依次递进分享相应的NLP文章，敬请关注。</p> 
<hr> 
<p><strong>你是如何看待“文本预处理”的呢？ 欢迎关注留言讨论</strong></p> 
<hr> 
<p>此处本来有一张二维码，哈哈哈</p> 
<hr> 
<p><strong>特别的，如本文有疏漏，麻烦留言指出，以期校正提升。<br> 如看到文章的小伙伴有感兴趣的nlp主题，欢迎留言交流讨论，共同撰文分享。</strong></p> 
<hr> 
<p>原文首发于：实用自然语言处理</p> 
<hr>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/84c5cbc11b9af935dc01c22f5e0bd826/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">HDFS通过WEB UI操作文件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8c7219f177c471788ab57953e7ea40be/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">win10系统远程连接桌面窗口太小怎么调大</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>