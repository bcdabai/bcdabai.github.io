<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python爬虫基础与初识scrapy - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python爬虫基础与初识scrapy" />
<meta property="og:description" content="数据获取方法与实践 数据的价值爬虫基础实战案例思路启发 1. 数据的价值 数据分析推荐系统人工智能、深度学习 Garbage in, garbage out! 2. 爬虫基础 2.1 HTTP URI ：Uniform Resource Identifier，统一资源标志符，类似于人的指纹，用于唯一标识某一资源。
URL ：Uniform Resource Locator，统一资源定位符，是URI的一种，它指定了资源的位置，通过URL就可以访问该资源。
URN：Uniform Resource Name，统一资源名称，如某一本书的ISBN号，只知道这是哪本书，不知道书在哪里。 HTTP: 超文本传输协议（Hyper Text Transfer Protocol）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。
HTTPS: HTTP的加密版本，更安全。Secure Socket Layer
请求：包含请求URL、请求方法、请求头、请求体。浏览器打开任一网址，鼠标右键，选择”检查“打开浏览器调试模式，就可以看到网页源码。调试模式-网络选项卡可以查看各个请求的详情，如请求头中的User-Agent和Cookie
请求方法：GET 与 POST
GET请求中的参数包含在URL中，POST请求则通过表单形式传输，存放在请求体中。GET请求提交数据最多只有1024个字节，而POST没有限制。 Cookie: 服务器端生成的并发送给用户的特殊字符串，用于辨别用户。客户端会在本地存储服务器发送的Cookie，每次请求时又会将Cookie发送到服务器，以便服务器校对身份。例如当你第一次登录某网站，随后再次访问的时候不需要再输入账号密码就已经是登录状态，这正是Cookie在发挥作用。
User-Agent: 标识客户端的操作系统、浏览器、内核版本等信息。编写爬虫时加上该字段，可以伪装成浏览器进行请求。
响应: 响应状态码、响应头、响应体
状态码: 标识此次通信的状态，是成功还是失败，以及失败的原因。
200，请求成功，无异常。
302，临时重定向。
404，Not found，哦豁，请求的页面不见了。请求的资源不存在。
状态码详解参考文章：https://www.cnblogs.com/xflonga/p/9368993.html
响应体: 请求到的资源，如HTML文档、JSON文档、图片的二进制数据等等。爬虫正是通过解析响应体，获取所需要的内容。
2.2 网页基础 一个网页由HTML、CSS、JavaScript三部分组成。如果把网页比作一个人，HTML相当于骨架，JavaScript相当于肌肉，CSS相当于皮肤，三者结合形成一个完善的网页。
HTML：超文本标记语言（Hyper Text Markup Language），其使用不同的标签代表网页中不同的元素，如文字、按钮、图片。在HTML中所有标签定义的内容都是节点，它们构成一个HTML DOM树，即Doctument Object Model 文档对象）
示例：http://example.com/
&lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example Domain&lt;/title&gt; &lt;meta charset=&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b8fb8cc01bf1f8c9fe2598226c03c386/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-01-28T20:05:28+08:00" />
<meta property="article:modified_time" content="2022-01-28T20:05:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python爬虫基础与初识scrapy</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>数据获取方法与实践</h2> 
<ul><li>数据的价值</li><li>爬虫基础</li><li>实战案例</li><li>思路启发</li></ul> 
<h3><a id="1__7"></a>1. 数据的价值</h3> 
<ul><li>数据分析</li><li>推荐系统</li><li>人工智能、深度学习 Garbage in, garbage out!</li></ul> 
<h3><a id="2__13"></a>2. 爬虫基础</h3> 
<h5><a id="21__HTTP_15"></a>2.1 HTTP</h5> 
<p><strong>URI</strong> ：Uniform Resource Identifier，统一资源标志符，类似于人的指纹，用于唯一标识某一资源。</p> 
<p><strong>URL</strong> ：Uniform Resource Locator，统一资源定位符，是URI的一种，它指定了资源的位置，通过URL就可以访问该资源。</p> 
<p><strong>URN</strong>：Uniform Resource Name，统一资源名称，如某一本书的ISBN号，只知道这是哪本书，不知道书在哪里。 <br> <img src="https://images2.imgbox.com/77/82/5jVaXZvS_o.png" alt="在这里插入图片描述"><br> <strong>HTTP:</strong> 超文本传输协议（Hyper Text Transfer Protocol）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。</p> 
<p><strong>HTTPS:</strong> HTTP的加密版本，更安全。Secure Socket Layer<br> <img src="https://images2.imgbox.com/d3/cd/5ZzC5nvj_o.png" alt="在这里插入图片描述"><br> <strong>请求</strong>：包含请求URL、请求方法、请求头、请求体。浏览器打开任一网址，鼠标右键，选择”检查“打开浏览器调试模式，就可以看到网页源码。调试模式-网络选项卡可以查看各个请求的详情，如请求头中的User-Agent和Cookie</p> 
<p><strong>请求方法：</strong><code>GET</code> 与 <code>POST</code></p> 
<ul><li>GET请求中的参数包含在URL中，POST请求则通过表单形式传输，存放在请求体中。</li><li>GET请求提交数据最多只有1024个字节，而POST没有限制。</li></ul> 
<p><strong>Cookie</strong>: 服务器端生成的并发送给用户的特殊字符串，用于辨别用户。客户端会在本地存储服务器发送的Cookie，每次请求时又会将Cookie发送到服务器，以便服务器校对身份。例如当你第一次登录某网站，随后再次访问的时候不需要再输入账号密码就已经是登录状态，这正是Cookie在发挥作用。</p> 
<p><strong>User-Agent</strong>: 标识客户端的操作系统、浏览器、内核版本等信息。编写爬虫时加上该字段，可以伪装成浏览器进行请求。</p> 
<p><strong>响应</strong>: 响应状态码、响应头、响应体</p> 
<p><strong>状态码</strong>: 标识此次通信的状态，是成功还是失败，以及失败的原因。</p> 
<ul><li> <p><code>200</code>，请求成功，无异常。</p> </li><li> <p><code>302</code>，临时重定向。</p> </li><li> <p><code>404</code>，Not found，哦豁，请求的页面不见了。请求的资源不存在。</p> <p>状态码详解参考文章：https://www.cnblogs.com/xflonga/p/9368993.html</p> </li></ul> 
<p><strong>响应体</strong>: 请求到的资源，如HTML文档、JSON文档、图片的二进制数据等等。爬虫正是通过解析响应体，获取所需要的内容。</p> 
<h5><a id="22___56"></a>2.2 网页基础</h5> 
<p>一个网页由HTML、CSS、JavaScript三部分组成。如果把网页比作一个人，HTML相当于骨架，JavaScript相当于肌肉，CSS相当于皮肤，三者结合形成一个完善的网页。</p> 
<p><strong>HTML：<strong>超文本标记语言（Hyper Text Markup Language），其使用不同的标签代表网页中不同的元素，如文字、按钮、图片。在HTML中所有标签定义的内容都是节点，它们构成一个</strong>HTML DOM</strong>树，即<strong>Doctument Object Model 文档对象</strong>）</p> 
<p>示例：http://example.com/</p> 
<pre><code class="prism language-html"><span class="token doctype"><span class="token punctuation">&lt;!</span><span class="token name">doctype</span> <span class="token name">html</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">&gt;</span></span>Example Domain<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>utf-8<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Content-type<span class="token punctuation">"</span></span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/html; charset=utf-8<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>viewport<span class="token punctuation">"</span></span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>width=device-width, initial-scale=1<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/css<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token style"><span class="token language-css">
    </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">&gt;</span></span>    
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">&gt;</span></span>Example Domain<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">&gt;</span></span>This domain is for use in illustrative examples in documents. You may use this
    domain in literature without prior coordination or asking for permission.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://www.iana.org/domains/example<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>More information...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p><img src="https://images2.imgbox.com/0a/74/OS6cIoH8_o.png" alt="在这里插入图片描述"></p> 
<center> 
 <b><font size="3">HTML文档节点树示例</font></b> 
</center> 
<h5><a id="23_requests_91"></a>2.3 requests的使用</h5> 
<p>​ python标准库提供了urllib3、httplib等模块以供Http请求，但是API复杂，使用不便。而requests第三方库解决了标准库的痛点，成为了python流行的HTTP请求库。Requests官方中文文档地址：https://docs.python-requests.org/zh_CN/latest/</p> 
<p>​ <strong>基本用法</strong>：使用<code>requests.get()</code>方法发起<code>GET</code>请求，代码如下。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
baidu <span class="token operator">=</span> <span class="token string">'https://www.baidu.com'</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>baidu<span class="token punctuation">)</span>           <span class="token comment"># 发起get请求，获得一个Response对象</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'response类型：'</span><span class="token punctuation">,</span><span class="token builtin">type</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'状态码：'</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>    <span class="token comment"># 通过Response对象的status_code属性，获取响应状态码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'url：'</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>              <span class="token comment"># 获取请求url</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'请求头'</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>request<span class="token punctuation">.</span>headers<span class="token punctuation">)</span>  <span class="token comment"># 获取发起请求时request的headers，即请求头</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'html：'</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>            <span class="token comment"># 通过Response对象的text属性，获取html</span>
</code></pre> 
<p>​ <strong>添加User-Agent</strong>: 有时候，由于网站的限制，通过简单的requests.get方法并不能得到我们想要的结果。这时需要添加User-Agent伪装成浏览器才能正常访问网站，因此添加在请求头中添加User-Agent是爬虫的一种基本操作。</p> 
<pre><code class="prism language-python">amazon <span class="token operator">=</span> <span class="token string">'https://www.amazon.cn/'</span>
<span class="token comment"># 不加User-Agent</span>
amazon_response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>amazon<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Before：'</span><span class="token punctuation">,</span> amazon_response<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span> <span class="token comment"># 结果是503</span>
<span class="token comment"># 添加User-Agent</span>
headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'User-Agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36'</span><span class="token punctuation">}</span>
amazon_response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>amazon<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'After：'</span><span class="token punctuation">,</span>amazon_response<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>  <span class="token comment"># 结果是200</span>
</code></pre> 
<p>​ <strong>添加Cookie</strong>: 有的网页需要登录才能访问，因此使用requests发起请求是需要添加cookie，否则请求会被重定向到登录页。</p> 
<pre><code class="prism language-python">weibo <span class="token operator">=</span> <span class="token string">'https://weibo.com/u/7361031918?refer_flag=0000015010_&amp;from=feed&amp;loc=avatar&amp;is_all=1'</span>
<span class="token comment"># 默认允许重定向</span>
weibo_response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token operator">=</span>weibo<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span>weibo_response<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>weibo_response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>  <span class="token comment"># 此时response对应的url发生改变，已不是原来的url。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'禁止重定向======='</span><span class="token punctuation">)</span>
<span class="token comment"># allow_redirects 默认为True，即允许重定向，若求情发生重定向，则会自动请求重定向连接。</span>
<span class="token comment"># 这里手动设置为Flase，查看其状态码</span>
weibo_response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token operator">=</span>weibo<span class="token punctuation">,</span> allow_redirects<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span>weibo_response<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>  <span class="token comment"># 此使状态码为302， 临时重定向</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>weibo_response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>  <span class="token comment"># url未发生改变</span>
</code></pre> 
<h5><a id="24_CSS_137"></a>2.4 CSS选择器的使用</h5> 
<p>​ 针对响应正文为HTML文档的请求，Python中有许多与HTML相关的解析库，比如<code>lxml</code>、<code>BeautifulSoup</code>、<code>PyQuery</code>等，这些库使得我们能够使用XPATH语法或CSS语法对HTML文档中对任一地方进行定位，并提取其中的内容。</p> 
<p>​ CSS选择器分为类别选择器、ID选择器、标签选择器、属性选择器等等，具体语法规则如下表。</p> 
<p>​ 加一个<strong>比较重要的规则</strong>"div.quote", 这个需要逆序看，即选择class=“quote”的div标签。与实战案例中的".quote"等效，因为案例中的html页面class=“quote”的标签只有div标签。<strong>等看完实战后，再返回来看这里，应该就懂了。</strong></p> 
<p><img src="https://images2.imgbox.com/f7/49/PJTU75hu_o.png" alt="在这里插入图片描述"></p> 
<p>示例：example.com</p> 
<pre><code class="prism language-html"><span class="token doctype"><span class="token punctuation">&lt;!</span><span class="token name">doctype</span> <span class="token name">html</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">&gt;</span></span>Example Domain<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">&gt;</span></span>Example Domain<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">&gt;</span></span>This domain is for use in illustrative examples in documents. You may use this
    domain in literature without prior coordination or asking for permission.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://www.iana.org/domains/example<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>More information...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">from</span> parsel <span class="token keyword">import</span> Selector
url <span class="token operator">=</span> <span class="token string">'http://example.com/'</span>
response <span class="token operator">=</span> requsets<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>text
sel <span class="token operator">=</span> Selector<span class="token punctuation">(</span>html<span class="token punctuation">)</span>  
<span class="token comment"># 提取title</span>
title <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"title"</span><span class="token punctuation">)</span>
<span class="token comment"># 提取h1</span>
title <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">)</span>
<span class="token comment"># 提取p标签</span>
p <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">)</span>
<span class="token comment"># 提取第一个p标签</span>
p1 <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment"># "::text"，剔除html&lt;/&gt;标签，提取其中的文本</span>
title <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"title::text"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'类型：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">type</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>  <span class="token comment"># 查看类型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span>
<span class="token comment"># extract()，提取选择器中的内容，并以列表形式返回，与getall()等效</span>
title_extract <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"title::text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'类型：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">type</span><span class="token punctuation">(</span>title_extract<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span>title_extract<span class="token punctuation">)</span>
<span class="token comment"># extract_first()提取选择器内容中的第一个元素，与get()等效</span>
title_extract_first <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"title::text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'类型：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">type</span><span class="token punctuation">(</span>title_extract_first<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span>title_extract_first<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="3__194"></a>3. 实战案例</h3> 
<p>​ 编写一个爬虫程序的基本步骤包括：</p> 
<p>​ （1）确定目标网站。</p> 
<p>​ （2）明确要爬取的内容，分析网页结构以确定爬取逻辑。</p> 
<p>​ （3）编写目标内容解析规则（CSS,Xpath, 正则均可）</p> 
<p>​ （4）编写程序</p> 
<h4><a id="1_206"></a>案例1：爬取名言警句</h4> 
<p><strong>目标网站</strong>： http://quotes.toscrape.com/</p> 
<p><strong>爬取内容：</strong> 名言、作者、标签<br> <img src="https://images2.imgbox.com/b5/b1/82JFSJiT_o.png" alt="在这里插入图片描述"></p> 
<p><strong>解析规则</strong>： 编写并检验CSS表达式。</p> 
<pre><code class="prism language-python"><span class="token comment"># quotes列表</span>
quotes <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.quote'</span><span class="token punctuation">)</span> <span class="token comment"># 返回SelectorList</span>
<span class="token keyword">for</span> quote <span class="token keyword">in</span> quotes<span class="token punctuation">:</span> <span class="token comment"># 遍历SelectorList中的Selector，进一步解析。</span>
    text <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    author <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    tags <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.tags .tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 注意.tags 与.tag之间有个空格</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/99/a7/8Ry3O5vx_o.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-McNfXyxT-1643369934553)(C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20220117221317623.png)]"></p> 
<p><strong>编写程序：</strong></p> 
<p><em>quotes.py</em></p> 
<pre><code class="prism language-python">base_url <span class="token operator">=</span> <span class="token string">'http://quotes.toscrape.com/'</span>
<span class="token comment"># page = 2</span>
<span class="token comment"># 构造请求头字典，这里只添加了User-Agent，没设置Cookie</span>
headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Edg/97.0.1072.55'</span><span class="token punctuation">}</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token operator">=</span>base_url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
<span class="token comment"># 将html传入Selector类，生成选择器对象sel</span>
sel <span class="token operator">=</span> Selector<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
<span class="token comment"># 获取所有的名言”块“</span>
quotes <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.quote'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> quote <span class="token keyword">in</span> quotes<span class="token punctuation">:</span>
    text <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    author <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    tags <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.tags .tag'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 转为字符串,用/拼接各个标签</span>
    tags <span class="token operator">=</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tags<span class="token punctuation">)</span>
    result <span class="token operator">=</span> <span class="token punctuation">[</span>author<span class="token punctuation">,</span> tags<span class="token punctuation">,</span> text<span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre> 
<p><em>quotes1.py</em></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">from</span> parsel <span class="token keyword">import</span> Selector

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>html<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    解析html，提取想要的数据
    """</span>
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    sel <span class="token operator">=</span> Selector<span class="token punctuation">(</span>html<span class="token punctuation">)</span>
    quotes <span class="token operator">=</span> sel<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.quote'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> quote <span class="token keyword">in</span> quotes<span class="token punctuation">:</span>
        text <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        author <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        tags <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.tags .tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 转为字符串,用/拼接各个标签</span>
        tags <span class="token operator">=</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tags<span class="token punctuation">)</span>
        result <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>author<span class="token punctuation">,</span> text<span class="token punctuation">,</span> tags<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>result<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results

<span class="token keyword">def</span> <span class="token function">save_results</span><span class="token punctuation">(</span>results<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    保存parse函数解析出来的results至csv文件中
    """</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>writelines<span class="token punctuation">(</span>results<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    base_url <span class="token operator">=</span> <span class="token string">'http://quotes.toscrape.com/'</span>
    headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Edg/97.0.1072.55'</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> page_index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 该网站最多只有10页</span>
        <span class="token comment"># 第一页没有page路径后缀</span>
        <span class="token keyword">if</span> page_index <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            url <span class="token operator">=</span> base_url
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            url <span class="token operator">=</span> base_url <span class="token operator">+</span> <span class="token string">'page/'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>page_index<span class="token punctuation">)</span>  <span class="token comment"># 末尾的斜杠/不加也不影响</span>
        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token operator">=</span>base_url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'抓取第 </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>page_index<span class="token punctuation">}</span></span><span class="token string"> 页的内容'</span></span><span class="token punctuation">)</span>
        results <span class="token operator">=</span> parse<span class="token punctuation">(</span>html<span class="token operator">=</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>  <span class="token comment"># results：["quote1", "quote2",... ""]</span>
        save_results<span class="token punctuation">(</span>results<span class="token punctuation">,</span> path<span class="token operator">=</span><span class="token string">'results.csv'</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="2Scrapy_296"></a>案例2：Scrapy初体验</h4> 
<h5><a id="Scrapy_298"></a><strong>为什么要用Scrapy？</strong></h5> 
<p>​ <strong>（1）爬虫框架化</strong>：借助案例1，我们将一个爬虫程序的四个基本部分——请求，响应，解析，存储都走了一遍，形成了一个小爬虫，爬虫虽小但五脏俱全。但是这只小爬虫只是在比较理想的情况下，它能顺利爬取数据，如果发生异常，则程序停止。下图中①②③④任意一个过程都可能发生异常情况。<u>爬虫框架化后能够很方便的处理各部分的问题，并且易于扩展实现自定义功能。</u><br> <img src="https://images2.imgbox.com/ba/f2/aNCJyL1y_o.png" alt="在这里插入图片描述"></p> 
<p>①：比如网络有问题时，爬虫程序不能成功发起请求</p> 
<p>②：比如服务器端识别你为爬虫，响应状态码不为200，返回的页面不是我们所预期的。</p> 
<p>③：解析规则不能成功解析页面，报错。</p> 
<p>④：存储过程发生错误。</p> 
<p>​ **（2）提高爬取速度：**借助scrapy可以轻松实现高并发，以及分布式爬虫</p> 
<h5><a id="Scrapy_315"></a>Scrapy是什么</h5> 
<p>​ 一个用于从网站提取所需数据的开源协作框架。它快速、简单、可扩展。基于twitsted，Scrapy使用了一种非阻塞（又名异步）的编程思想，实现高并发高效率。</p> 
<p><strong>Scrapy数据流</strong>（架构概览）</p> 
<p><img src="https://images2.imgbox.com/d6/9f/jq1S0cHJ_o.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-G1ZAOxqN-1643369361473)(C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20220118134112169.png)]"></p> 
<ul><li><code>Scrapy Engine</code>：核心引擎，负责控制和调度各个组件，保证数据流转；</li><li><code>Scheduler</code>：负责管理请求、过滤请求、输出请求的调度器。1. 指定请求输出顺序；2. 过滤可能存在的重复请求</li><li><code>Downloader</code>：下载器，负责在网络上下载数据，输入待下载的 URL，输出下载结果；</li><li><code>Spiders</code>：一个编写自己的爬虫逻辑，定义抓取意图的类；</li><li><code>Item Pipeline</code>：负责输出结构化数据，可自定义格式和输出的位置；</li></ul> 
<p>如果你观察地比较仔细的话，可以看到还有两个模块：</p> 
<ul><li><code>Downloader middlewares</code>：介于引擎和下载器之间，可以在网页在下载前、后进行相应处理，比如下载前给Request添加请求头，cookie，代理等；</li><li><code>Spider middlewares</code>：介于引擎和爬虫之间，在向爬虫输入下载结果前，和爬虫输出请求 / 数据后进行逻辑处理；</li></ul> 
<p><strong>用scrapy实现案例1</strong></p> 
<ul><li> <p>创建scrapy工程</p> <pre><code class="prism language-bash">scrapy startproject tutorial
</code></pre> <p>工程文件目录结构如图，scrapy.cfg是</p> <pre><code>tutorial
|
|---scrapy.cfg             # 部署配置文件
|---tutorial               # python模块，所需要的__init__.py，有它才能正常import
    |--- __init__.py
    |--- items.py          # 定义数据结构的文件
    |--- middlewares.py    # 定义爬虫中间件的文件
    |--- pipelines.py      # 定义处理数据的管道的文件
    |--- settings.py       # 工程设置文件
    |--- spiders           # 在改文件夹下，编写自己的爬虫名.py文件，该爬虫名.py文件定义爬取逻辑和解析规则
         |--- __init__.py
</code></pre> </li><li> <p>进入工程目录第一个tutorial，创建爬虫程序, <code>quotes</code>是爬虫名，<code>quotes.toscrape.com</code>要爬取链接的域名。命令行运行这两条指令后，<code>spiders</code>文件夹下会自动生成一个<code>quotes.py</code>文件，如下图，QuotesSpider类则正是我们编写爬虫逻辑和解析规则的地方。</p> <pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> tutorial 
scrapy genspider quotes quotes.toscrape.com
</code></pre> </li></ul> 
<p><img src="https://images2.imgbox.com/c3/77/5NQXRnNj_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p><code>name</code>: 爬虫名称，同一个工程下，爬虫名称唯一。</p> </li><li> <p><code>allow_domains</code>: 准许的域名列表，属于这个列表内域名下的链接会被丢忽略。</p> </li><li> <p><code>start_urls</code>: 设置起始连接，即爬虫的入口，从哪些网页开始爬。</p> </li><li> <p><code>parse()</code>: 解析规则就写在这个函数里，用于解析响应，Response对象。</p> </li><li> <p>在<code>item.py</code>文件定义<code>Items</code>类，添加我们想要提取数据的字段，规范数据格式。</p> <pre><code class="prism language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QuoteItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    tags <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>编写<code>parse()</code>解析函数，使用Item</p> <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        quotes <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.quote'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> quote <span class="token keyword">in</span> quotes<span class="token punctuation">:</span>
            item <span class="token operator">=</span> QuoteItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># ::text 代表获取正文（去除标签），返回值是选择器对象</span>
            text <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># extract_first() 提取选择器对象中的第一个数据。</span>
            author <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 一个tags下有多个tag， extract()返回全部tag组成的列表。</span>
            tags <span class="token operator">=</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.tags .tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>  
            tags <span class="token operator">=</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tags<span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span> <span class="token operator">=</span> text
            item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span> <span class="token operator">=</span> author
            item<span class="token punctuation">[</span><span class="token string">'tags'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tags
            <span class="token keyword">yield</span> item
        <span class="token comment"># 这里.pager .next 中间有个空格， 讲课时候的程序因为没有空格，</span>
        <span class="token comment"># 所以没有匹配到下一页链接的后缀，即/page/2/ 这样的后缀，导致只爬取了第一页</span>
        <span class="token builtin">next</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.pager .next a::attr("href")'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 这里将提取到的下一页后缀'/page/2/'与当前页url融合，组成下页请求连接，</span>
        url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">)</span>
        <span class="token comment"># callback指定这个请求用哪个函数来解析</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> </li><li> <p>命令行运行爬虫</p> <pre><code class="prism language-bashn">scrapy crawl quotes
</code></pre> </li><li> <p>命令行运行爬虫，并将记过保存到csv文件</p> <pre><code>scrapy crawl quotes -o quotes.csv
</code></pre> <p><img src="https://images2.imgbox.com/2d/1d/tFNDUqyi_o.png" alt=""></p> </li></ul> 
<h3><a id="4__425"></a>4. 思路启发</h3> 
<p>​ 你能否做一个程序，甚至是带GUI的应用或者微信小程序后搭建一个网页，输入商品名字（如某某型号的手机），得到该各大电商平台的价格，并给出给用户一个最低价商品的的链接。感兴趣的同学可以试试看，用scrapy实现。</p> 
<h3><a id="5__429"></a>5. 参考资料</h3> 
<p>​ 优质学习资料的重要性不言而喻，现在做如下推荐，我基本都看过，都很棒。</p> 
<p><strong>推荐书籍</strong></p> 
<ul><li> <p>《Python3网络爬虫开发实战》，崔庆才著，2018</p> <pre><code>#这本比较详细和全面，通俗易懂，培训笔记也主要参考了这本书籍，跟着案例一个个都走一遍.
这篇文章大多数内容都参考了这本书。
</code></pre> </li><li> <p>《精通Python爬虫框架Scrapy》，迪米特里奥斯著，李斌译，2018</p> <pre><code>#和第一本结合着看，这本主要讲scrapy，掌握scrapy常用指令
</code></pre> </li><li> <p>《Python3反爬虫原理与绕过实战》，韦世东，2020</p> <pre><code>#全面讲解了常见与不常见的反爬虫手段以及如何绕过反爬，快速过完后，做到心中有数，方便回头查阅
</code></pre> </li><li> <p>《实战Python网络爬虫》，黄永祥著，2019</p> <pre><code>#前面的书看了，基本就掌握得从差不多了，这本主要是练习后面几章的实战案例，
加深理解和提高代码能力。总之，实践为王。
</code></pre> </li></ul> 
<p>**备注：**前三本我都提供了电子版，最后一本没有，但是在手机APP<font color="red">微信读书</font>能搜到电子版免费阅读</p> 
<p><strong>推荐专栏</strong>：下面是别的大佬的源码解析，滤清了各个流程的细节，挺好。但是需要有一定scrapy实践经验，基本掌握scrapy架构，才能看懂，了解细节实现，学习别人的源码时怎么写的。</p> 
<ul><li> <p><a href="https://zhuanlan.zhihu.com/p/272367027" rel="nofollow">Scrapy 源码剖析（一）架构概览 - 知乎 (zhihu.com)</a></p> </li><li> <p><a href="https://zhuanlan.zhihu.com/p/272370864" rel="nofollow">Scrapy源码剖析（二）Scrapy是如何运行起来的？ - 知乎 (zhihu.com)</a></p> </li><li> <p><a href="https://zhuanlan.zhihu.com/p/272376444" rel="nofollow">Scrapy源码剖析（三）Scrapy有哪些核心组件？ - 知乎 (zhihu.com)</a></p> </li><li> <p><a href="https://zhuanlan.zhihu.com/p/272381374" rel="nofollow">Scrapy源码剖析（四）Scrapy如何完成抓取任务？ - 知乎 (zhihu.com)</a></p> </li><li> <p>Scarpy官方指南：https://docs.scrapy.org/en/latest/intro/tutorial.html</p> </li></ul> 
<p>​ <br> ​ <br> ​</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8b0d354a5ca51c376c807b18fd09d928/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;入门基础 逻辑运算符</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f52ea4180f59d9d68cd5df9d40beed3f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MySQL 8.0 Command Line Client打开时闪退的问题解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>