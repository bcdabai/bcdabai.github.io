<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[转]YOLOv8-Cls推理详解及部署实现 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[转]YOLOv8-Cls推理详解及部署实现" />
<meta property="og:description" content="目录 前言一、YOLOv8-Cls推理(Python) 1. YOLOv8-Cls预测2. YOLOv8-Cls预处理3. YOLOv8-Cls推理二、YOLOv8-Cls推理(C&#43;&#43;) 1. ONNX导出2. YOLOv8-Cls预处理3. YOLOv8-Cls推理三、YOLOv8-Cls部署 1. 源码下载2. 环境配置 2.1 配置CMakeLists.txt2.2 配置Makefile3. ONNX导出4. 源码修改结语下载链接参考 前言 梳理下 YOLOv8-Cls 的预处理流程，顺便让 tensorRT_Pro 支持 YOLOv8-Cls
参考：https://github.com/shouxieai/tensorRT_Pro
实现：https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8
一、YOLOv8-Cls推理(Python) 1. YOLOv8-Cls预测 我们先尝试利用官方预训练权重来推理一张图片，看能否成功
在 YOLOv8 主目录下新建 predict-cls.py 预测文件，其内容如下：
import cv2 from ultralytics import YOLO if __name__ == &#34;__main__&#34;: model = YOLO(&#34;yolov8s-cls.pt&#34;) img = cv2.imread(&#34;ultralytics/assets/bus.jpg&#34;) result = model(img)[0] names = result.names top1_label = result.probs.top1 top5_label = result.probs.top5 top1_conf = result.probs.top1conf top5_conf = result." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b9eac1fec5d7cb31758f98a2e860da6d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-04T11:33:34+08:00" />
<meta property="article:modified_time" content="2024-01-04T11:33:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[转]YOLOv8-Cls推理详解及部署实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p></p> 
<p></p> 
<div class="toc"> 
 <h5><a name="t0"></a>目录</h5> 
 <ul><li> 
   <ul><li><a href="#_1" rel="nofollow">前言</a></li><li><a href="#YOLOv8ClsPython_9" rel="nofollow">一、YOLOv8-Cls推理(Python)</a></li><li> 
     <ul><li><a href="#1_YOLOv8Cls_11" rel="nofollow">1. YOLOv8-Cls预测</a></li><li><a href="#2_YOLOv8Cls_45" rel="nofollow">2. YOLOv8-Cls预处理</a></li><li><a href="#3_YOLOv8Cls_133" rel="nofollow">3. YOLOv8-Cls推理</a></li></ul></li><li><a href="#YOLOv8ClsC_186" rel="nofollow">二、YOLOv8-Cls推理(C++)</a></li><li> 
     <ul><li><a href="#1_ONNX_190" rel="nofollow">1. ONNX导出</a></li><li><a href="#2_YOLOv8Cls_262" rel="nofollow">2. YOLOv8-Cls预处理</a></li><li><a href="#3_YOLOv8Cls_331" rel="nofollow">3. YOLOv8-Cls推理</a></li></ul></li><li><a href="#YOLOv8Cls_348" rel="nofollow">三、YOLOv8-Cls部署</a></li><li> 
     <ul><li><a href="#1__354" rel="nofollow">1. 源码下载</a></li><li><a href="#2__364" rel="nofollow">2. 环境配置</a></li><li> 
       <ul><li><a href="#21_CMakeListstxt_370" rel="nofollow">2.1 配置CMakeLists.txt</a></li><li><a href="#22_Makefile_404" rel="nofollow">2.2 配置Makefile</a></li></ul></li><li><a href="#3_ONNX_438" rel="nofollow">3. ONNX导出</a></li><li><a href="#4__442" rel="nofollow">4. 源码修改</a></li></ul></li><li><a href="#_472" rel="nofollow">结语</a></li><li><a href="#_478" rel="nofollow">下载链接</a></li><li><a href="#_483" rel="nofollow">参考</a></li></ul></li></ul> 
</div> 
<p></p> 
<p></p> 
<p></p> 
<h4><a name="t1"></a><a id="_1"></a>前言</h4> 
<p></p> 
<blockquote> 
 <p>梳理下 YOLOv8-Cls 的预处理流程，顺便让 tensorRT_Pro 支持 YOLOv8-Cls</p> 
 <p>参考：<a href="https://github.com/shouxieai/tensorRT_Pro">https://github.com/shouxieai/tensorRT_Pro</a></p> 
 <p>实现：<a href="https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8">https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8</a></p> 
</blockquote> 
<p></p> 
<h4><a name="t2"></a><a id="YOLOv8ClsPython_9"></a>一、YOLOv8-Cls推理(Python)</h4> 
<p></p> 
<h5><a name="t3"></a><a id="1_YOLOv8Cls_11"></a>1. YOLOv8-Cls预测</h5> 
<p></p> 
<blockquote> 
 <p>我们先尝试利用官方<a class="hl hl-1" href="https://so.csdn.net/so/search?q=%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D&amp;spm=1001.2101.3001.7020">预训练权重</a>来推理一张图片，看能否成功</p> 
</blockquote> 
<p></p> 
<p>在 YOLOv8 主目录下新建 <strong>predict-cls.py</strong> 预测文件，其内容如下：</p> 
<p></p> 
<pre><code class="hljs">import cv2
from ultralytics import YOLO

if __name__ == "__main__":

    model = YOLO("yolov8s-cls.pt")

    img = cv2.imread("ultralytics/assets/bus.jpg")

    result = model(img)[0]
    names  = result.names

    top1_label = result.probs.top1
    top5_label = result.probs.top5
    top1_conf  = result.probs.top1conf
    top5_conf  = result.probs.top5conf
    top1_name  = names[top1_label]

    print(f"The model predicted category is {top1_name}, label = {top1_label}, confidence = {top1_conf:.4f}")
</code></pre> 
<p></p> 
<p>在上述代码中我们通过 opencv 读取了一张图像，并送入模型中推理得到 results，results 中保存着不同任务的结果，我们这里是分类任务，因此只需要拿到对应 1000 个类别中最高置信度的类别标签即可。</p> 
<p></p> 
<p>模型推理的结果如下所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/6b/70/5T8iYre6_o.png"></p> 
<p></p> 
<h5><a name="t4"></a><a id="2_YOLOv8Cls_45"></a>2. YOLOv8-Cls预处理</h5> 
<p></p> 
<blockquote> 
 <p>模型预测成功后我们就需要自己动手来写下 YOLOv8-Cls 的预处理，方便后续在 C++ 上的实现</p> 
</blockquote> 
<p></p> 
<p>经过我们的调试分析可知 YOLOv8-Cls 的预处理过程在 <strong>ultralytics/data/augment.py</strong> 文件中，可以参考：<a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/data/augment.py#L1059">augment.py#L1059</a></p> 
<p></p> 
<pre><code class="hljs">class CenterCrop:
    """YOLOv8 CenterCrop class for image preprocessing, designed to be part of a transformation pipeline, e.g.,
    T.Compose([CenterCrop(size), ToTensor()]).
    """

    def __init__(self, size=640):
        """Converts an image from numpy array to PyTorch tensor."""
        super().__init__()
        self.h, self.w = (size, size) if isinstance(size, int) else size

    def __call__(self, im):
        """
        Resizes and crops the center of the image using a letterbox method.

        Args:
            im (numpy.ndarray): The input image as a numpy array of shape HWC.

        Returns:
            (numpy.ndarray): The center-cropped and resized image as a numpy array.
        """
        imh, imw = im.shape[:2]
        m = min(imh, imw)  # min dimension
        top, left = (imh - m) // 2, (imw - m) // 2
        return cv2.resize(im[top:top + m, left:left + m], (self.w, self.h), interpolation=cv2.INTER_LINEAR)


class ToTensor:
    """YOLOv8 ToTensor class for image preprocessing, i.e., T.Compose([LetterBox(size), ToTensor()])."""

    def __init__(self, half=False):
        """Initialize YOLOv8 ToTensor object with optional half-precision support."""
        super().__init__()
        self.half = half

    def __call__(self, im):
        """
        Transforms an image from a numpy array to a PyTorch tensor, applying optional half-precision and normalization.

        Args:
            im (numpy.ndarray): Input image as a numpy array with shape (H, W, C) in BGR order.

        Returns:
            (torch.Tensor): The transformed image as a PyTorch tensor in float32 or float16, normalized to [0, 1].
        """
        im = np.ascontiguousarray(im.transpose((2, 0, 1))[::-1])  # HWC to CHW -&gt; BGR to RGB -&gt; contiguous
        im = torch.from_numpy(im)  # to torch
        im = im.half() if self.half else im.float()  # uint8 to fp16/32
        im /= 255.0  # 0-255 to 0.0-1.0
        return im
</code></pre> 
<p></p> 
<p>它包含如下步骤：</p> 
<p></p> 
<ul><li><strong>im[top:top +m, left:left + m]</strong>：中心裁剪</li><li><strong>cv2.resize</strong>：缩放到 224x224</li><li><strong>transpose(2, 0, 1)[::-1]</strong>：HWC → CHW，BGR → RGB</li><li><strong>torch.from_numpy</strong>：to Tensor</li><li><strong>im /= 255.0</strong>：除以 255.0，归一化</li></ul> 
<p></p> 
<p>因此我们不难写出对应的预处理代码，如下所示：</p> 
<p></p> 
<pre><code class="hljs">def preprocess(img, dst_width=224, dst_height=224):

    imh, imw = img.shape[:2]
    m = min(imh, imw)
    top, left = (imh - m) // 2, (imw - m) // 2
    img_pre = img[top:top+m, left:left+m]
    img_pre = cv2.resize(img_pre, (dst_width, dst_height), interpolation=cv2.INTER_LINEAR)
    
    img_pre = (img_pre[...,::-1] / 255.0).astype(np.float32)
    img_pre = img_pre.transpose(2, 0, 1)[None]
    img_pre = torch.from_numpy(img_pre)

    return img_pre
</code></pre> 
<p></p> 
<p>经过中心裁剪并 resize 后的图片如下所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/15/e7/JXHOUJiY_o.jpg"></p> 
<p></p> 
<h5><a name="t5"></a><a id="3_YOLOv8Cls_133"></a>3. YOLOv8-Cls推理</h5> 
<p></p> 
<blockquote> 
 <p>由于我们经过 softmax 后直接得到的是每个类别的概率值，因此没有后处理一说，YOLOv8-Cls 的推理包括<a class="hl hl-1" href="https://so.csdn.net/so/search?q=%E5%9B%BE%E5%83%8F%E9%A2%84%E5%A4%84%E7%90%86&amp;spm=1001.2101.3001.7020">图像预处理</a>、模型推理，其中预处理主要是 <strong>中心裁剪和缩放</strong>。</p> 
</blockquote> 
<p></p> 
<p>完整的推理代码如下：</p> 
<p></p> 
<pre><code class="hljs">import cv2
import torch
import numpy as np
from ultralytics.nn.autobackend import AutoBackend

def preprocess(img, dst_width=224, dst_height=224):

    imh, imw = img.shape[:2]
    m = min(imh, imw)
    top, left = (imh - m) // 2, (imw - m) // 2
    img_pre = img[top:top+m, left:left+m]
    img_pre = cv2.resize(img_pre, (dst_width, dst_height), interpolation=cv2.INTER_LINEAR)
    
    img_pre = (img_pre[...,::-1] / 255.0).astype(np.float32)
    img_pre = img_pre.transpose(2, 0, 1)[None]
    img_pre = torch.from_numpy(img_pre)

    return img_pre

if __name__ == "__main__":

    img = cv2.imread("ultralytics/assets/bus.jpg")

    img_pre = preprocess(img)

    model = AutoBackend(weights="yolov8s-cls.pt")
    names = model.names
    probs = model(img_pre)[0]

    top1_label = int(probs.argmax())
    top5_label = (-probs).argsort(0)[:5].tolist()
    top1_conf  = probs[top1_label]
    top5_conf  = probs[top5_label]

    top1name = names[top1_label]

    print(f"The model predicted category is {top1name}, label = {top1_label}, confidence = {top1_conf:.4f}")
</code></pre> 
<p></p> 
<p>推理结果如下所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/73/79/bOyc98nb_o.png"></p> 
<p></p> 
<p>至此，我们在 Python 上面完成了 YOLOv8-Cls 的整个推理过程，下面我们去 C++ 上实现。</p> 
<p></p> 
<h4><a name="t6"></a><a id="YOLOv8ClsC_186"></a>二、YOLOv8-Cls推理(C++)</h4> 
<p></p> 
<blockquote> 
 <p>C++ 上的实现我们使用的 repo 依旧是 tensorRT_Pro，现在我们就基于 tensorRT_Pro 完成 YOLOv8-Cls 在 C++ 上的推理。</p> 
</blockquote> 
<p></p> 
<h5><a name="t7"></a><a id="1_ONNX_190"></a>1. ONNX导出</h5> 
<p></p> 
<p>首先我们需要将 YOLOv8-Cls 模型导出为 ONNX，为了适配 tensorRT_Pro 我们需要做一些修改，主要有以下几点：</p> 
<p></p> 
<ul><li>修改输出节点名 <strong>output</strong></li><li>输入输出只让 batch 维度动态，宽高不动态</li></ul> 
<p></p> 
<p>具体修改如下：</p> 
<p></p> 
<p><strong>1.</strong> <strong>在 ultralytics/engine/exporter.py 文件中改动一处</strong></p> 
<p></p> 
<ul><li><strong>323 行</strong>：输出节点名修改为 <strong>output</strong></li><li><strong>326 行</strong>：输入只让 batch 维度动态，宽高不动态</li><li><strong>331 行</strong>：输出只让 batch 维度动态，宽高不动态</li></ul> 
<p></p> 
<pre><code class="hljs"># ========== exporter.py ==========

# ultralytics/engine/exporter.py第323行
# output_names = ['output0', 'output1'] if isinstance(self.model, SegmentationModel) else ['output0']
# dynamic = self.args.dynamic
# if dynamic:
#     dynamic = {'images': {0: 'batch', 2: 'height', 3: 'width'}}  # shape(1,3,640,640)
#     if isinstance(self.model, SegmentationModel):
#         dynamic['output0'] = {0: 'batch', 2: 'anchors'}  # shape(1, 116, 8400)
#         dynamic['output1'] = {0: 'batch', 2: 'mask_height', 3: 'mask_width'}  # shape(1,32,160,160)
#     elif isinstance(self.model, DetectionModel):
#         dynamic['output0'] = {0: 'batch', 2: 'anchors'}  # shape(1, 84, 8400)
# 修改为：

output_names = ['output0', 'output1'] if isinstance(self.model, SegmentationModel) else ['output']
dynamic = self.args.dynamic
if dynamic:
    dynamic = {'images': {0: 'batch'}}  # shape(1,3,640,640)
    dynamic['output'] = {0: 'batch'}
    if isinstance(self.model, SegmentationModel):
        dynamic['output0'] = {0: 'batch', 2: 'anchors'}  # shape(1, 116, 8400)
        dynamic['output1'] = {0: 'batch', 2: 'mask_height', 3: 'mask_width'}  # shape(1,32,160,160)
    elif isinstance(self.model, DetectionModel):
        dynamic['output'] = {0: 'batch'}  # shape(1, 84, 8400)
</code></pre> 
<p></p> 
<p>以上就是为了适配 tensorRT_Pro 而做出的代码修改，修改好以后，将预训练权重 <strong>yolov8-cls.pt</strong> 放在 ultralytics-main 主目录下，新建导出文件 <strong>export.py</strong>，内容如下：</p> 
<p></p> 
<pre><code class="hljs">from ultralytics import YOLO

model = YOLO("yolov8s-cls.pt")

success = model.export(format="onnx", dynamic=True, simplify=True)
</code></pre> 
<p></p> 
<p>在终端执行如下指令即可完成 onnx 导出：</p> 
<p></p> 
<pre><code class="hljs">python export.py
</code></pre> 
<p></p> 
<p>导出过程如下图所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/66/9d/dWjTgpQV_o.png"></p> 
<p></p> 
<p>可以看到导出的 pytorch 模型的输入 shape 是 1x3x224x224，输出 shape 是 1x1000，符合我们的预期。</p> 
<p></p> 
<p>导出成功后会在当前目录下生成 yolov8s-cls.onnx 模型，我们可以使用 <a href="https://netron.app/" rel="nofollow">Netron</a> 可视化工具查看，如下图所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/f8/e4/A0Dq88JM_o.png"></p> 
<p></p> 
<p>可以看到输入节点名是 <strong>images</strong>，维度是 batchx3x224x224，保证只有 batch 维度动态，输出节点名是 <strong>output</strong>，维度是 batchx1000，保证只有 batch 维度动态，符合 tensorRT_Pro 的格式。</p> 
<p></p> 
<h5><a name="t8"></a><a id="2_YOLOv8Cls_262"></a>2. YOLOv8-Cls预处理</h5> 
<p></p> 
<blockquote> 
 <p>之前有提到过 YOLOv8-Cls 的预处理部分主要是中心裁剪加缩放，而在 tensorRT_Pro 中有提供 resize 的实现，我们只需要添加中心裁剪即可。</p> 
</blockquote> 
<p></p> 
<p>因此我们不难写出 YOLOv8-Cls 的预处理代码，如下所示：</p> 
<p></p> 
<pre><code class="hljs">__global__ void crop_resize_bilinear_and_normalize_kernel(
	uint8_t* src, int src_line_size, int src_width, int src_height, float* dst, int dst_width, int dst_height,
	int crop_x, int crop_y, float sx, float sy, Norm norm, int edge
){
	int position = blockDim.x * blockIdx.x + threadIdx.x;
	if (position &gt;= edge) return;

	int dx      = position % dst_width;
	int dy      = position / dst_width;
	float src_x = (dx + 0.5f) * sx - 0.5f + crop_x;
	float src_y = (dy + 0.5f) * sy - 0.5f + crop_y;
	float c0, c1, c2;

	int y_low = floorf(src_y);
	int x_low = floorf(src_x);
	int y_high = limit(y_low + 1, 0, src_height - 1);
	int x_high = limit(x_low + 1, 0, src_width - 1);
	y_low = limit(y_low, 0, src_height - 1);
	x_low = limit(x_low, 0, src_width - 1);

	int ly    = rint((src_y - y_low) * INTER_RESIZE_COEF_SCALE);
	int lx    = rint((src_x - x_low) * INTER_RESIZE_COEF_SCALE);
	int hy    = INTER_RESIZE_COEF_SCALE - ly;
	int hx    = INTER_RESIZE_COEF_SCALE - lx;
	int w1    = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;
	float* pdst = dst + dy * dst_width + dx * 3;
	uint8_t* v1 = src + y_low * src_line_size + x_low * 3;
	uint8_t* v2 = src + y_low * src_line_size + x_high * 3;
	uint8_t* v3 = src + y_high * src_line_size + x_low * 3;
	uint8_t* v4 = src + y_high * src_line_size + x_high * 3;

	c0 = resize_cast(w1 * v1[0] + w2 * v2[0] + w3 * v3[0] + w4 * v4[0]);
	c1 = resize_cast(w1 * v1[1] + w2 * v2[1] + w3 * v3[1] + w4 * v4[1]);
	c2 = resize_cast(w1 * v1[2] + w2 * v2[2] + w3 * v3[2] + w4 * v4[2]);

	if(norm.channel_type == ChannelType::Invert){
		float t = c2;
		c2 = c0;  c0 = t;
	}

	if(norm.type == NormType::MeanStd){
		c0 = (c0 * norm.alpha - norm.mean[0]) / norm.std[0];
		c1 = (c1 * norm.alpha - norm.mean[1]) / norm.std[1];
		c2 = (c2 * norm.alpha - norm.mean[2]) / norm.std[2];
	}else if(norm.type == NormType::AlphaBeta){
		c0 = c0 * norm.alpha + norm.beta;
		c1 = c1 * norm.alpha + norm.beta;
		c2 = c2 * norm.alpha + norm.beta;
	}

	int area = dst_width * dst_height;
	float* pdst_c0 = dst + dy * dst_width + dx;
	float* pdst_c1 = pdst_c0 + area;
	float* pdst_c2 = pdst_c1 + area;
	*pdst_c0 = c0;
	*pdst_c1 = c1;
	*pdst_c2 = c2;
}
</code></pre> 
<p></p> 
<p>相比于 resize 的实现就多了一个偏移，主要是为了做中心裁剪，具体代码可以参考：<a href="https://github.com/shouxieai/tensorRT_Pro/blob/main/src/tensorRT/common/preprocess_kernel.cu#L49">preprocess_kernel.cu#L49</a></p> 
<p></p> 
<h5><a name="t9"></a><a id="3_YOLOv8Cls_331"></a>3. YOLOv8-Cls推理</h5> 
<p></p> 
<blockquote> 
 <p>通过上面对 YOLOv8-Cls 的预处理分析之后，整个推理过程就显而易见了。C++ 上 YOLOv8-Cls 的预处理部分将 resize 简单修改即可。</p> 
</blockquote> 
<p></p> 
<p>我们在终端执行如下指令即可完成推理（<strong>注意！完整流程博主会在后续内容介绍，这边只是简单演示</strong>）</p> 
<p></p> 
<pre><code class="hljs">make yolo_cls
</code></pre> 
<p></p> 
<p>编译图解如下所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/f1/42/ARmOt93J_o.png"></p> 
<p></p> 
<p>至此，我们在 C++ 上面完成了 YOLOv8-Cls 的整个推理过程，下面我们将完整的走一遍流程。</p> 
<p></p> 
<h4><a name="t10"></a><a id="YOLOv8Cls_348"></a>三、YOLOv8-Cls部署</h4> 
<p></p> 
<blockquote> 
 <p>博主新建了一个仓库 <a href="https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8">tensorRT_Pro-YOLOv8</a>，该仓库基于 <a href="https://github.com/shouxieai/tensorRT_Pro">shouxieai/tensorRT_Pro</a>，并进行了调整以支持 YOLOv8 的各项任务，目前已支持分类、检测、分割、姿态点估计任务。</p> 
 <p>下面我们就来具体看看如何利用 tensorRT_Pro-YOLOv8 这个 repo 完成 YOLOv8-Cls 的推理。</p> 
</blockquote> 
<p></p> 
<h5><a name="t11"></a><a id="1__354"></a>1. 源码下载</h5> 
<p></p> 
<p>tensorRT_Pro-YOLOv8 的代码可以直接从 GitHub 官网上下载，源码下载地址是 <a href="https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8">https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8</a>，Linux 下代码克隆指令如下：</p> 
<p></p> 
<pre><code class="hljs">git clone https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8.git
</code></pre> 
<p></p> 
<p>也可手动点击下载，点击右上角的 <code>Code</code> 按键，将代码下载下来。至此整个项目就已经准备好了。也可以点击 <a href="https://pan.baidu.com/s/1yn8rdGVruCkhfHuVhTr8_w" rel="nofollow">here</a> 下载博主准备好的源代码（<strong>注意代码下载于 2023/11/7 日，若有改动请参考最新</strong>）</p> 
<p></p> 
<h5><a name="t12"></a><a id="2__364"></a>2. 环境配置</h5> 
<p></p> 
<blockquote> 
 <p>需要使用的软件环境有 <strong>TensorRT、CUDA、cuDNN、OpenCV、Protobuf</strong>，所有软件环境的安装可以参考 <a href="https://blog.csdn.net/qq_40672115/article/details/130255299">Ubuntu20.04软件安装大全</a>，这里不再赘述，需要各位看官自行配置好相关环境😄，外网访问较慢，这里提供下博主安装过程中的软件安装包下载链接 <a href="https://pan.baidu.com/s/1XPe6xd6q1TLDMlVO-84KXA" rel="nofollow">Baidu Drive【pwd:yolo】</a>🚀🚀🚀</p> 
 <p>tensorRT_Pro-YOLOv8 提供 CMakeLists.txt 和 Makefile 两种方式编译，<strong>二者选一即可</strong></p> 
</blockquote> 
<p></p> 
<h6><a id="21_CMakeListstxt_370"></a>2.1 配置CMakeLists.txt</h6> 
<p></p> 
<p>主要修改五处</p> 
<p></p> 
<p><strong>1.</strong> 修改第 13 行，修改 OpenCV 路径</p> 
<p></p> 
<pre><code class="hljs">set(OpenCV_DIR   "/usr/local/include/opencv4/")
</code></pre> 
<p></p> 
<p><strong>2.</strong> 修改第 15 行，修改 CUDA 路径</p> 
<p></p> 
<pre><code class="hljs">set(CUDA_TOOLKIT_ROOT_DIR     "/usr/local/cuda-11.6")
</code></pre> 
<p></p> 
<p><strong>3.</strong> 修改第 16 行，修改 cuDNN 路径</p> 
<p></p> 
<pre><code class="hljs">set(CUDNN_DIR    "/usr/local/cudnn8.4.0.27-cuda11.6")
</code></pre> 
<p></p> 
<p><strong>4.</strong> 修改第 17 行，修改 <a class="hl hl-1" href="https://so.csdn.net/so/search?q=tensorRT&amp;spm=1001.2101.3001.7020">tensorRT</a> 路径</p> 
<p></p> 
<pre><code class="hljs">set(TENSORRT_DIR "/opt/TensorRT-8.4.1.5")
</code></pre> 
<p></p> 
<p><strong>5.</strong> 修改第 20 行，修改 protobuf 路径</p> 
<p></p> 
<pre><code class="hljs">set(PROTOBUF_DIR "/home/jarvis/protobuf")
</code></pre> 
<p></p> 
<h6><a id="22_Makefile_404"></a>2.2 配置Makefile</h6> 
<p></p> 
<p>主要修改五处</p> 
<p></p> 
<p><strong>1.</strong> 修改第 4 行，修改 protobuf 路径</p> 
<p></p> 
<pre><code class="hljs">lean_protobuf  := /home/jarvis/protobuf
</code></pre> 
<p></p> 
<p><strong>2.</strong> 修改第 5 行，修改 tensorRT 路径</p> 
<p></p> 
<pre><code class="hljs">lean_tensor_rt := /opt/TensorRT-8.4.1.5
</code></pre> 
<p></p> 
<p><strong>3.</strong> 修改第 6 行，修改 cuDNN 路径</p> 
<p></p> 
<pre><code class="hljs">lean_cudnn     := /usr/local/cudnn8.4.0.27-cuda11.6
</code></pre> 
<p></p> 
<p><strong>4.</strong> 修改第 7 行，修改 OpenCV 路径</p> 
<p></p> 
<pre><code class="hljs">lean_opencv    := /usr/local
</code></pre> 
<p></p> 
<p><strong>5.</strong> 修改第 8 行，修改 CUDA 路径</p> 
<p></p> 
<pre><code class="hljs">lean_cuda      := /usr/local/cuda-11.6
</code></pre> 
<p></p> 
<h5><a name="t13"></a><a id="3_ONNX_438"></a>3. ONNX导出</h5> 
<p></p> 
<p>导出细节可以查看之前的内容，这边不再赘述。记得将导出的 ONNX 模型放在 tensorRT_Pro-YOLOv8/workspace 文件夹下。</p> 
<p></p> 
<h5><a name="t14"></a><a id="4__442"></a>4. 源码修改</h5> 
<p></p> 
<blockquote> 
 <p>如果你想推理自己训练的模型还需要修改下源代码，YOLOv8-Cls 模型的推理代码主要在 <strong>app_yolo_cls.cpp</strong> 文件中，我们就只需要修改这一个文件中的内容即可，源码修改较简单主要有以下几点：</p> 
</blockquote> 
<p></p> 
<ul><li><strong>1.</strong> <strong>app_yolo_cls.cpp 187行，“yolov8s-cls” 修改为你导出的 ONNX 模型名</strong></li><li><strong>2.</strong> <strong>app_yolo_cls.cpp 105行，“imagenet.txt” 修改为你自训练分类模型的类别 txt 文件</strong></li></ul> 
<p></p> 
<p>具体修改示例如下：</p> 
<p></p> 
<pre><code class="hljs">test(TRT::Model::FP32, "best")	// 修改1 187行"yolov8s-cls"改成"best"

auto labels = iLogger::split_string(iLogger::load_text_file("custom.txt"), "\n");	// 修改2 105行修改检测类别，为自训练模型的类别名称
</code></pre> 
<p></p> 
<p>OK！源码修改好了，Makefile 编译文件也搞定了，ONNX 模型也准备好了，现在可以编译运行了，直接在终端执行如下指令即可：</p> 
<p></p> 
<pre><code class="hljs">make yolo_cls
</code></pre> 
<p></p> 
<p>编译过程如下所示：</p> 
<p></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/d1/7d/EdqWENSI_o.png"></p> 
<p></p> 
<p>编译运行成功后在 workspace 文件夹下会生成 engine 文件 <strong>yolov8s-cls.FP32.trtmodel</strong> 用于模型推理，同时在终端还可以看见模型预测的结果。</p> 
<p></p> 
<p>OK！以上就是使用 tensorRT_Pro-YOLOv8 推理 YOLOv8-Cls 的大致流程，若有问题，欢迎各位看官批评指正。</p> 
<p></p> 
<h4><a name="t15"></a><a id="_472"></a>结语</h4> 
<p></p> 
<blockquote> 
 <p>博主在这里针对 YOLOv8-Cls 的预处理和后处理做了简单分析，同时与大家分享了 C++ 上的实现流程，目的是帮大家理清思路，更好的完成后续的部署工作😄。感谢各位看到最后，创作不易，读后有收获的看官请帮忙点个👍⭐️</p> 
 <p>最后大家如果觉得 <a href="https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8">tensorRT_Pro-YOLOv8</a> 这个 repo 对你有帮助的话，不妨点个 ⭐️ 支持一波，这对博主来说非常重要，感谢各位🙏。</p> 
</blockquote> 
<p></p> 
<h4><a name="t16"></a><a id="_478"></a>下载链接</h4> 
<p></p> 
<ul><li><a href="https://pan.baidu.com/s/1XPe6xd6q1TLDMlVO-84KXA" rel="nofollow">软件安装包下载链接【提取码:yolo】</a>🚀🚀🚀</li><li><a href="https://pan.baidu.com/s/1yn8rdGVruCkhfHuVhTr8_w" rel="nofollow">源代码、权重下载链接【提取码:yolo】</a></li></ul> 
<p></p> 
<h4><a name="t17"></a><a id="_483"></a>参考</h4> 
<p></p> 
<ul><li><a href="https://github.com/shouxieai/infer">https://github.com/shouxieai/infer</a></li><li><a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a></li><li><a href="https://github.com/shouxieai/tensorRT_Pro">https://github.com/shouxieai/tensorRT_Pro</a></li><li><a href="https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8">https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8</a></li><li><a href="https://blog.csdn.net/qq_40672115/article/details/127012332">YOLOv5推理详解及预处理高性能实现</a></li></ul> 
<p><br> ---------------------<br> 作者：爱听歌的周童鞋<br> 来源：CSDN<br> 原文：https://blog.csdn.net/qq_40672115/article/details/134277392<br> 版权声明：本文为作者原创文章，转载请附上博文链接！<br> 内容解析By：<a href="https://greasyfork.org/zh-CN/scripts/381053-csdn-cnblog%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E4%B8%80%E9%94%AE%E8%BD%AC%E8%BD%BD%E6%8F%92%E4%BB%B6" rel="nofollow">CSDN,CNBLOG博客文章一键转载插件</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/28e51ddd1447acaa568087c1dd815ce2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深入了解Python中的进程控制和监控技巧，提高系统稳定性</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1697822969dc734519b93d07586b6660/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">xshell配色</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>