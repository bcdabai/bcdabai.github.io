<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TVM学习（三）编译流程 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TVM学习（三）编译流程" />
<meta property="og:description" content="VM主要的编译过程如下图：
Import：将tensorflow，onnx，pytorch等构建的深度学习模型导入，转化成TVM的中间层表示IR。
Lower：将高层IR表示转化成低阶TIR表示。
Codegen：内存分配和硬件可执行程序生成。
图导入
通过一个tensorflow的reception网络来熟悉编译过程，其它深度学习框架也具有类似过程。从TVM官网可以下载tensorflow的编译程序
https://tvm.apache.org/docs/tutorials/frontend/from_tensorflow.html#sphx-glr-tutorials-frontend-from-tensorflow-py。
主要代码如下：
模型的输入是一个后缀为pb的文件，它是神经网络模型图的protobuf格式存储文件。Pb是二进制形式，pbtxt是文本形式。Import_graph_def函数是导入pb，graph是tensorflow的图结构。
From_tensorflow是将tensorflow的图结构转化成TVM的IR。这个函数在文件relay/frontend/tensorflow.py中。函数的调用关系为：
From_tensorflow -&gt; GraphProto.from_tensorflow -&gt; self._get_relay_func。
在get_relay_func中会遍历每个tensorflow的节点，转换成tvm的IR表示。重点关注_backtrack_construct函数。
继续深入和算子转化有关的函数调用为：_convert_operator -&gt; convert_map。Convert_map中对应了可支持tensorflow算子到tvm算子的转换关系。
完成了tensorflow到TVM算子转化后，我们就得到了一个IRModule。我们可以利用tvm的可视化来打印出转化后的图：
Main是主函数入口，在TVM中以函数形式反应了tensorflow的图结构。函数的调用关系反应了图的依赖关系。
编译
Python中主要代码位于relay/build_module.py文件中，调用关系为build -&gt; BuildModule -&gt; build。在build中通过字典获得了C&#43;&#43;中的相应函数。
这里不明白如何通过self.mod[“build”]得到C&#43;&#43;中函数的。_BuildModule()是C&#43;&#43;中注册到环境中的一个函数。在src/relay/backend/http://build_module.cc中，
TVM_REGISTER_GLOBAL是将C&#43;&#43;函数注册到一个全局map中。当python加载编译好的动态库时，会自动查询map中静态注册的函数，并添加到python模块当中。
真正build操作位于RelayBuildModule类中，在其中有一个GetFunction函数，会通过名字查询要使用的函数，打包成PackedFunc返回，这个函数可能和self.mod[“build”]有关。PackedFunc是TVM中提供的python的一个接口，任何函数都可以封装成PackedFunc，并给python调用。更详细介绍可看：https://hjchen2.github.io/2020/01/10/TVMPackedFunc%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/
继续深入代码，Build -&gt; BuildRelay。这是编译的主要代码。其过程包括optimize，codgen。
Optimize就是执行一些优化passes，这些passes包括常数折叠，算符融合等。之后会调用graph_codegen-&gt;Codegen。Codegen中实现了内存分配和硬件代码生成。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/48f05eea4971e1941710d0a85a4ffdad/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-23T23:56:38+08:00" />
<meta property="article:modified_time" content="2021-02-23T23:56:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TVM学习（三）编译流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>VM主要的编译过程如下图：<br> <img src="https://images2.imgbox.com/9d/e7/QTKTF80r_o.png" alt="在这里插入图片描述"></p> 
<p>Import：将tensorflow，onnx，pytorch等构建的深度学习模型导入，转化成TVM的中间层表示IR。<br> Lower：将高层IR表示转化成低阶TIR表示。<br> Codegen：内存分配和硬件可执行程序生成。</p> 
<p><strong>图导入</strong></p> 
<p>通过一个tensorflow的reception网络来熟悉编译过程，其它深度学习框架也具有类似过程。从TVM官网可以下载tensorflow的编译程序</p> 
<p><a href="https://tvm.apache.org/docs/tutorials/frontend/from_tensorflow.html#sphx-glr-tutorials-frontend-from-tensorflow-py" rel="nofollow">https://tvm.apache.org/docs/tutorials/frontend/from_tensorflow.html#sphx-glr-tutorials-frontend-from-tensorflow-py</a>。<br> 主要代码如下：<br> <img src="https://images2.imgbox.com/f9/4d/ojpOXDyw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/85/1e/PuLvzJRc_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/07/b2/yhqB8Ema_o.png" alt="在这里插入图片描述"></p> 
<p>模型的输入是一个后缀为pb的文件，它是神经网络模型图的protobuf格式存储文件。Pb是二进制形式，pbtxt是文本形式。Import_graph_def函数是导入pb，graph是tensorflow的图结构。</p> 
<p>From_tensorflow是将tensorflow的图结构转化成TVM的IR。这个函数在文件relay/frontend/tensorflow.py中。函数的调用关系为：</p> 
<p>From_tensorflow -&gt; GraphProto.from_tensorflow -&gt; self._get_relay_func。</p> 
<p>在get_relay_func中会遍历每个tensorflow的节点，转换成tvm的IR表示。重点关注_backtrack_construct函数。<br> <img src="https://images2.imgbox.com/b5/cd/CeNg8Ib0_o.png" alt="在这里插入图片描述"></p> 
<p>继续深入和算子转化有关的函数调用为：_convert_operator -&gt; convert_map。Convert_map中对应了可支持tensorflow算子到tvm算子的转换关系。<br> <img src="https://images2.imgbox.com/f6/97/kX1DBoRt_o.png" alt="在这里插入图片描述"></p> 
<p>完成了tensorflow到TVM算子转化后，我们就得到了一个IRModule。我们可以利用tvm的可视化来打印出转化后的图：<br> <img src="https://images2.imgbox.com/21/f7/sBuVvi4v_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/27/80/1p2SBkni_o.png" alt="在这里插入图片描述"></p> 
<p>Main是主函数入口，在TVM中以函数形式反应了tensorflow的图结构。函数的调用关系反应了图的依赖关系。</p> 
<p><strong>编译</strong><br> Python中主要代码位于relay/build_module.py文件中，调用关系为build -&gt; BuildModule -&gt; build。在build中通过字典获得了C++中的相应函数。<br> <img src="https://images2.imgbox.com/38/20/KsAApkY8_o.png" alt="在这里插入图片描述"></p> 
<p>这里不明白如何通过self.mod[“build”]得到C++中函数的。_BuildModule()是C++中注册到环境中的一个函数。在src/relay/backend/http://build_module.cc中，<br> <img src="https://images2.imgbox.com/89/48/GbY8qgGD_o.png" alt="在这里插入图片描述"></p> 
<p>TVM_REGISTER_GLOBAL是将C++函数注册到一个全局map中。当python加载编译好的动态库时，会自动查询map中静态注册的函数，并添加到python模块当中。</p> 
<p>真正build操作位于RelayBuildModule类中，在其中有一个GetFunction函数，会通过名字查询要使用的函数，打包成PackedFunc返回，这个函数可能和self.mod[“build”]有关。PackedFunc是TVM中提供的python的一个接口，任何函数都可以封装成PackedFunc，并给python调用。更详细介绍可看：<a href="https://link.zhihu.com/?target=https://hjchen2.github.io/2020/01/10/TVM-PackedFunc%25E5%25AE%259E%25E7%258E%25B0%25E6%259C%25BA%25E5%2588%25B6/" rel="nofollow">https://hjchen2.github.io/2020/01/10/TVMPackedFunc%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</a></p> 
<p>继续深入代码，Build -&gt; BuildRelay。这是编译的主要代码。其过程包括optimize，codgen。<br> <img src="https://images2.imgbox.com/0b/da/XBKitsgb_o.png" alt="在这里插入图片描述"></p> 
<p>Optimize就是执行一些优化passes，这些passes包括常数折叠，算符融合等。之后会调用graph_codegen-&gt;Codegen。Codegen中实现了内存分配和硬件代码生成。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b29c499a2dc3d0808af7df89dc99c723/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Ubuntu打开ssh，可以远程登陆自己的电脑</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ef761841187510822e4d35b82d6193a0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java jdbctemplate赋值_给dao层注入jdbcTemplate时的一个强行bug(jdbcDaoSupport不要随便用!用了要记得!)...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>