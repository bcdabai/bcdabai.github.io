<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>爬虫进阶之scrapy项目实战 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="爬虫进阶之scrapy项目实战" />
<meta property="og:description" content="爬虫进阶之scrapy项目实战 前言 觉得Scrapy确实挺强大的，并且要想更加熟悉和了解这个框架，应该要多做一些项目来强化对Scrapy的理解，本次的项目是针对Boss直聘，想要爬取boss直聘根据关键词（地点和工作）的工作岗位的详细情况，包括薪资、学历要求、地点、工作描述等等…此次设置的爬虫规则是通过CSS选择器进行的，因此说明时也会介绍CSS选择
正文 初始化爬虫项目 scrapy startproject zhipin_com #后面是项目的名字 从得到的文件架构中也能清楚知道整个Scrapy的框架，具体我们在上一章博客中也介绍了
scrapt genspider zhipin #创建一个名为zhipin的爬虫 当初始化完成后，接下来我们就应该设置item，其实item很好理解，就是我们所要爬取的参数，我们需要爬取多少参数，就可以设置多少个items,这里我们需要设置如下items:
如上，这些都是我们需要爬取的，我们在items.py先将他们说明，接下来就是设置爬虫规则了，在这里先说明一下CSS选择器
http://www.scrapyd.cn/doc/185.html
现附上scrapy对于CSS选择器的官方文档，个人感觉讲的很详细了，下面举一些例子来说明:
&lt;ol class=&#34;page-navigator&#34;&gt; &lt;li class=&#34;current&#34;&gt;&lt;a href=&#34;http://lab.scrapyd.cn/page/1/&#34;&gt;1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;http://lab.scrapyd.cn/page/2/&#34;&gt;2&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;http://lab.scrapyd.cn/page/3/&#34;&gt;3&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;http://lab.scrapyd.cn/page/4/&#34;&gt;4&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; 如果我们想提取该html中的URL，我们应该如何提取呢？
这里列举了一些重要的匹配，如果我们是要选择class中的元素，我们只需要在response.css(&#34;.class&#34;)，其实在设置匹配规则时，我们要操作的无非是这三个，response.css(“css表达式”)、extract()、extract_first()
提取属性我们是用：“标签名::attr(属性名)”，因此在上面html中，匹配URL应该是
url = response.css(&#34;.page-navigator a::attr(href)&#34;).extract() 在使用scrapy匹配时返回的都是selectorList的对象实例，而extract()可以看成是将对象实例变成列表的形式
再比如这个例子：
&lt;div class=&#34;left&#34;&gt; scrapy中文网左边 &lt;/div&gt; &lt;div class=&#34;center&#34;&gt; scrapy中文网中部 &lt;/div&gt; &lt;div class=&#34;right&#34;&gt; scrapy中文网右侧 &lt;/div&gt; 我们想要第二段文字，应该如何匹配？这时::text能够匹配标签中的内容，因此我们应该这样匹配
text = response.css(&#34;.center::text&#34;).extract() 这里需要注意的是，CSS高级用法中，response.css(&#34;.div1 .div2&#34;)表示的是选择div1中的所有div2元素，不一定是父子关系，而response.css(&#34;.div1&gt;.div2&#34;)则这俩者一定是父子关系的，那如果&lt;div&gt;标签中的class属性的值本来就含有空格，例如
这里本来就含有空格，但是我们是相匹配的这个&lt;div&gt;标签的话，此时就应该把空格当成.处理：
div = response.css(&#34;div.wrapper_new.wrapper_s&#34;)#这样进行匹配 CSS选择器说明完之后，接下来我们就来配置规则了：
先设置开始的url和当前页数
设置好请求头(注意：请求头的设置尤为重要，现在很多网页都有反爬取措施，不设置请求头很可能不会有response)
具体的job参数对应html哪个位置，我们可以将鼠标移动到job参数右击检查，即可在开发者工具中看到对应的位置，因此我们只需要一个一个进行查找即可，每一个工作都是放在&lt;ul&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;下，for循环即可
这里还需要动态爬取页面，当第一页爬取完后主动爬取第二页，因此还要构造一个方法
def next_request(self): return scrapy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/72c764fcd80d2aa8f550ae3e9a811d42/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-26T22:37:38+08:00" />
<meta property="article:modified_time" content="2020-07-26T22:37:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">爬虫进阶之scrapy项目实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="scrapy_0"></a>爬虫进阶之scrapy项目实战</h2> 
<h3><a id="_1"></a>前言</h3> 
<p>觉得<code>Scrapy</code>确实挺强大的，并且要想更加熟悉和了解这个框架，应该要多做一些项目来强化对<code>Scrapy</code>的理解，本次的项目是针对<strong>Boss直聘</strong>，想要爬取<strong>boss直聘</strong>根据关键词（地点和工作）的工作岗位的详细情况，包括薪资、学历要求、地点、工作描述等等…此次设置的爬虫规则是通过<code>CSS选择器</code>进行的，因此说明时也会介绍CSS选择</p> 
<h3><a id="_3"></a>正文</h3> 
<h4><a id="_4"></a>初始化爬虫项目</h4> 
<pre><code class="prism language-bash">scrapy startproject zhipin_com <span class="token comment">#后面是项目的名字</span>
</code></pre> 
<p>从得到的文件架构中也能清楚知道整个<code>Scrapy</code>的框架，具体我们在上一章博客中也介绍了</p> 
<pre><code class="prism language-bash">scrapt genspider zhipin <span class="token comment">#创建一个名为zhipin的爬虫</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/24/c1/z8dCdhOY_o.png" alt="在这里插入图片描述"><br> 当初始化完成后，接下来我们就应该设置<code>item</code>，其实<code>item</code>很好理解，就是我们所要爬取的参数，我们需要爬取多少参数，就可以设置多少个<code>items</code>,这里我们需要设置如下<code>items</code>:<br> <img src="https://images2.imgbox.com/94/4a/5VO4ULPb_o.png" alt="在这里插入图片描述"><br> 如上，这些都是我们需要爬取的，我们在<code>items.py</code>先将他们说明，接下来就是设置爬虫规则了，在这里先说明一下<code>CSS选择器</code><br> <a href="http://www.scrapyd.cn/doc/185.html" rel="nofollow">http://www.scrapyd.cn/doc/185.html</a><br> 现附上scrapy对于<code>CSS选择器</code>的官方文档，个人感觉讲的很详细了，下面举一些例子来说明:</p> 
<pre><code class="prism language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ol</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>page-navigator<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>current<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://lab.scrapyd.cn/page/1/<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://lab.scrapyd.cn/page/2/<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://lab.scrapyd.cn/page/3/<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://lab.scrapyd.cn/page/4/<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ol</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>如果我们想提取该<code>html</code>中的URL，我们应该如何提取呢？<br> <img src="https://images2.imgbox.com/f4/40/kqw1bDPJ_o.png" alt="在这里插入图片描述"><br> 这里列举了一些重要的匹配，如果我们是要选择<code>class中</code>的元素，我们只需要在<code>response.css(".class")</code>，其实在设置匹配规则时，我们要操作的无非是这三个，<strong>response.css(“css表达式”)、extract()、extract_first()</strong><br> 提取属性我们是用：<code>“标签名::attr(属性名)”</code>，因此在上面<code>html</code>中，匹配URL应该是</p> 
<pre><code class="prism language-python">url <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">".page-navigator a::attr(href)"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>在使用scrapy匹配时返回的都是selectorList的对象实例，而extract()可以看成是将对象实例变成列表的形式</p> 
</blockquote> 
<p>再比如这个例子：</p> 
<pre><code class="prism language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>left<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
  scrapy中文网左边
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>center<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
  scrapy中文网中部
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>right<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
  scrapy中文网右侧
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>我们想要第二段文字，应该如何匹配？这时<code>::text</code>能够匹配标签中的内容，因此我们应该这样匹配</p> 
<pre><code class="prism language-python">text <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">".center::text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这里需要注意的是，CSS高级用法中，<code>response.css(".div1 .div2")</code>表示的是选择<code>div1</code>中的所有<code>div2</code>元素，不一定是父子关系，而<code>response.css(".div1&gt;.div2")</code>则这俩者一定是父子关系的，那如果<code>&lt;div&gt;</code>标签中的class属性的值本来就含有空格，例如<br> <img src="https://images2.imgbox.com/72/12/LLwH2LlG_o.png" alt="在这里插入图片描述"><br> 这里本来就含有空格，但是我们是相匹配的这个<code>&lt;div&gt;</code>标签的话，此时就应该把空格当成<code>.</code>处理：</p> 
<pre><code class="prism language-python">div <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">"div.wrapper_new.wrapper_s"</span><span class="token punctuation">)</span><span class="token comment">#这样进行匹配</span>
</code></pre> 
<p>CSS选择器说明完之后，接下来我们就来配置规则了：<br> <img src="https://images2.imgbox.com/8e/1b/MNHJMoPd_o.png" alt="在这里插入图片描述"><br> 先设置开始的<code>url</code>和当前页数<br> <img src="https://images2.imgbox.com/6c/0e/WYLQrR2m_o.png" alt="在这里插入图片描述"><br> 设置好请求头(注意：请求头的设置尤为重要，现在很多网页都有反爬取措施，不设置请求头很可能不会有<code>response</code>)</p> 
<p>具体的job参数对应<code>html</code>哪个位置，我们可以将鼠标移动到job参数右击检查，即可在开发者工具中看到对应的位置，因此我们只需要一个一个进行查找即可，每一个工作都是放在<code>&lt;ul&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;</code>下，for循环即可</p> 
<p>这里还需要动态爬取页面，当第一页爬取完后主动爬取第二页，因此还要构造一个方法</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">next_request</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> scrapy<span class="token punctuation">.</span>http<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>self<span class="token punctuation">.</span>position_url<span class="token operator">+</span><span class="token string">"&amp;page={}&amp;ka=page-{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>cur_page<span class="token punctuation">,</span>self<span class="token punctuation">.</span>cur_page<span class="token punctuation">)</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>self<span class="token punctuation">.</span>headers<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
        <span class="token keyword">pass</span>
</code></pre> 
<p>爬取完一页后<code>cur_page+=1</code>然后调用<code>next_request()</code>这样继续爬取第二页的数据<br> <img src="https://images2.imgbox.com/32/95/sRzVgfcX_o.png" alt="在这里插入图片描述"><br> 当写完项目后，在命令行中<code>scrapy crawl zhipin -o data.json</code>便能生成data的<code>json</code>数据，看一眼效果图<br> <img src="https://images2.imgbox.com/2b/44/UQclwmsU_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_79"></a>写到最后</h3> 
<p>然后前几次可以，多爬取几次后就翻车了…<br> <img src="https://images2.imgbox.com/4d/71/fIz2Glpt_o.png" alt="在这里插入图片描述"><br> 应该是<code>boss直聘</code>有反爬措施，并且我设置的<code>time.sleep()</code>是一个定值，可能也被检测出了，在这里我尝试了一种新的思路，随着爬虫项目的变大应该也很常见，就是设置代理，通过<strong>不断随机的代理和UA头</strong>来骗取服务器的信任，认为这是一个合法的用户，那么如何设置代理呢？</p> 
<h5><a id="settingpy_84"></a>setting.py</h5> 
<p>在<code>settings.py</code>中设置好相应的代理参数和UA头：<br> <img src="https://images2.imgbox.com/02/3d/bs610NtT_o.png" alt="在这里插入图片描述"><br> 免费代理可以去<code>google</code>上找找</p> 
<h5><a id="middlewarespy_88"></a>middlewares.py</h5> 
<p>这其实是<code>scrapy</code>的一个中间件，scrapy的下载器中间件位于调度器和下载器之间，<strong>可用于给请求头中添加user-agent等应用</strong><br> <img src="https://images2.imgbox.com/6d/39/Te01z7gg_o.png" alt="在这里插入图片描述">这就是这个中间件的大致作用，当然还有其他的作用，如添加cookie等<br> <img src="https://images2.imgbox.com/84/ae/dxQzuUDv_o.png" alt="在这里插入图片描述"><br> 我们设置好相应的代理和随机UA头的处理，注意设置好后需要在<code>settings.py</code>中配置好中间件，即<code>DOWNLOADER_MIDDLEWARES</code><br> <img src="https://images2.imgbox.com/fd/c1/yLt0O5je_o.png" alt="在这里插入图片描述"><br> 这样自建中间件才会发挥作用，配置好后我们重新进行</p> 
<pre><code class="prism language-python">scrapy crawl zhipin <span class="token operator">-</span>o data<span class="token punctuation">.</span>json
</code></pre> 
<p>…很不幸的是，我找到的代理都挂了，反正一直请求不了，显示目标计算机积极拒绝之类的，大概率是免费代理太辣鸡了，这里留个坑以后明白了再来玩一玩代理池这些。之前成功的图忘记截了，然后第二次爬取就被<code>ban</code>了IP，这里就附上设置代理挂了的截图吧…<br> <img src="https://images2.imgbox.com/a4/43/BJ9a1WAY_o.png" alt="在这里插入图片描述"></p> 
<p>好在是爬到了一些数据，为了避开反爬取，我想的是应该设置<code>time.sleep()</code>为随机值，并且时间要足够的长，这样才会让我的IP变得像是合法用户而不是spiders</p> 
<p>第二天顺着思路设置了随机的<code>time.sleep()</code>后发现能爬四页左右，然后需要重新爬取，但是IP不会被封了。附上截图吧<br> <img src="https://images2.imgbox.com/56/c3/UcIi2iIN_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ce5756919b9d3317a7d31ea758dabcae/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;面向对象（三）：类和对象</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4f3ad39bb17a9dac7d4871e78c193b0a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">代码实现LRU最近很少使用算法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>