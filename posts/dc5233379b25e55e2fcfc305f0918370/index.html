<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【高级人工智能】国科大《高级人工智能》联结主义 笔记 &#43; 考试回忆 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【高级人工智能】国科大《高级人工智能》联结主义 笔记 &#43; 考试回忆" />
<meta property="og:description" content="国科大《高级人工智能》吴老师部分——联结主义笔记
吴老师上课dddd，上课东西太多太杂，听不太懂比较煎熬，但是课后花点时间理解理解，还是挺有帮助的考试按照重点复习即可，虽然答疑时提到的传教士野人没考😅，但是知识点基本都在最后一节ppt里听说下一届就不会用原题了 文章目录 一、搜索1.概念形式化描述野人与传教士问题搜索算法特性 2.树搜索深度优先DFS广度优先BFS3.启发式搜索4.图搜索5.局部搜索 二、人工神经网络1.神经网络2.感知机3.深度神经网络4.CNN卷积网络5.RNN6.GAN生成式对抗网络 考试回忆 一、搜索 1.概念 形式化描述 搜索问题的形式化描述：
状态空间后继函数初始状态目标测试=&gt; 解：一个行动序列，将初始状态转换成目标状态 野人与传教士问题 状态空间：{(左岸传教士数量, 左岸野人数量, 船状态[1在左岸，0在右岸])}后继函数：{ P01, P10, P02, P20, P11, Q01, Q10,Q02, Q20, Q11}（船向左/右, 船上传教士数量, 船上野人数量）耗散函数：当前状态下船从一侧划到另外一侧耗散值为1个单位初始状态：(3, 3, 1)目标状态：(0, 0, 0)
搜索算法特性 完备性(问题有解且能找到一个)最优性(保证找到最优解[最小损耗])时间、空间复杂度 2.树搜索 扩展出潜在行动，维护行动的边缘节点，扩展尽可能少的树节点。
深度优先DFS 描述：回溯，每次从边缘集合选最深的[栈]不保证完备性(有环层数无限大)与最优性(无视深度损失)m层b叉：时O(bm) 空O(bm)迭代深入搜索：结合DFS空间优势&#43;BFS时间优势 广度优先BFS 描述：对每个相邻节点再访问其相邻但是未被访问过的节点[队列]保证完备性&#43;最优性m层b叉：时O(bm) 空O(bm)代价一致搜索：总是扩展路径消耗最小的节点 3.启发式搜索 描述：利用问题拥有的启发信息引导搜索启发策略：估计一个状态到目标距离的函数贪婪搜索：扩展离目标最近的节点，不具完备性、最优性 评价节点：启发函数f(n)=h(n)(当前节点到终点的开销) A*搜索：代价一致搜索 &#43; Greedy， 评价：f(n)=代价函数g(n) &#43;启发函数h(n) 启发函数可采纳-&gt;最优性 4.图搜索 描述：避免重复状态，不扩展一个状态两次：树搜索&#43;扩展过的状态集(closed set)A*图搜索：启发式的一致性 =&gt; A*图最优 一致性：沿路径的节点估计耗散 f 值单调递增：h(A) ≤ cost(A to C) &#43; h© 5.局部搜索 描述：改进单一选项直到不能再改善为止；新的后继函数: 局部改变；不完备，不最优爬山法：任意位置起始，重复直到移动到最好的相邻状态（可能局部最优解）模拟退火搜索：引入随机因素，避免局部极大（允许向山下移动）遗传算法：适应度函数，每步保留N个最好状态 二、人工神经网络 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/dc5233379b25e55e2fcfc305f0918370/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-11T17:11:22+08:00" />
<meta property="article:modified_time" content="2023-01-11T17:11:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【高级人工智能】国科大《高级人工智能》联结主义 笔记 &#43; 考试回忆</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>国科大《高级人工智能》吴老师部分——联结主义笔记</p> 
 <ul><li>吴老师上课dddd，上课东西太多太杂，听不太懂比较煎熬，但是课后花点时间理解理解，还是挺有帮助的</li><li>考试按照重点复习即可，虽然答疑时提到的传教士野人没考😅，但是知识点基本都在最后一节ppt里</li><li>听说下一届就不会用原题了</li></ul> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_7" rel="nofollow">一、搜索</a></li><li><ul><li><a href="#1_8" rel="nofollow">1.概念</a></li><li><ul><li><a href="#_9" rel="nofollow">形式化描述</a></li><li><a href="#_16" rel="nofollow">野人与传教士问题</a></li><li><a href="#_24" rel="nofollow">搜索算法特性</a></li></ul> 
   </li><li><a href="#2_28" rel="nofollow">2.树搜索</a></li><li><a href="#DFS_30" rel="nofollow">深度优先DFS</a></li><li><a href="#BFS_35" rel="nofollow">广度优先BFS</a></li><li><a href="#3_40" rel="nofollow">3.启发式搜索</a></li><li><a href="#4_47" rel="nofollow">4.图搜索</a></li><li><a href="#5_51" rel="nofollow">5.局部搜索</a></li></ul> 
  </li><li><a href="#_56" rel="nofollow">二、人工神经网络</a></li><li><ul><li><a href="#1_57" rel="nofollow">1.神经网络</a></li><li><a href="#2_61" rel="nofollow">2.感知机</a></li><li><a href="#3_70" rel="nofollow">3.深度神经网络</a></li><li><a href="#4CNN_79" rel="nofollow">4.CNN卷积网络</a></li><li><a href="#5RNN_91" rel="nofollow">5.RNN</a></li><li><a href="#6GAN_110" rel="nofollow">6.GAN生成式对抗网络</a></li></ul> 
  </li><li><a href="#_127" rel="nofollow">考试回忆</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_7"></a>一、搜索</h2> 
<h3><a id="1_8"></a>1.概念</h3> 
<h4><a id="_9"></a>形式化描述</h4> 
<p>搜索问题的形式化描述：</p> 
<ul><li>状态空间</li><li>后继函数</li><li>初始状态</li><li>目标测试</li><li>=&gt; 解：一个行动序列，将初始状态转换成目标状态</li></ul> 
<h4><a id="_16"></a>野人与传教士问题</h4> 
<ul><li>状态空间：{(左岸传教士数量, 左岸野人数量, 船状态[1在左岸，0在右岸])}</li><li>后继函数：{ P01, P10, P02, P20, P11, Q01, Q10,Q02, Q20, Q11}（船向左/右, 船上传教士数量, 船上野人数量）</li><li>耗散函数：当前状态下船从一侧划到另外一侧耗散值为1个单位</li><li>初始状态：(3, 3, 1)</li><li>目标状态：(0, 0, 0)<br> <img src="https://images2.imgbox.com/08/23/0Pu70Efm_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="_24"></a>搜索算法特性</h4> 
<ul><li>完备性(问题有解且能找到一个)</li><li>最优性(保证找到最优解[最小损耗])</li><li>时间、空间复杂度</li></ul> 
<h3><a id="2_28"></a>2.树搜索</h3> 
<p>扩展出潜在行动，维护行动的边缘节点，扩展尽可能少的树节点。</p> 
<h3><a id="DFS_30"></a>深度优先DFS</h3> 
<ul><li>描述：回溯，每次从边缘集合选最深的[栈]</li><li>不保证完备性(有环层数无限大)与最优性(无视深度损失)</li><li>m层b叉：时O(b<sup>m</sup>) 空O(b<sup>m</sup>)</li><li><strong>迭代深入搜索</strong>：结合DFS空间优势+BFS时间优势</li></ul> 
<h3><a id="BFS_35"></a>广度优先BFS</h3> 
<ul><li>描述：对每个相邻节点再访问其相邻但是未被访问过的节点[队列]</li><li>保证完备性+最优性</li><li>m层b叉：时O(bm) 空O(bm)</li><li><strong>代价一致搜索</strong>：总是扩展路径消耗最小的节点</li></ul> 
<h3><a id="3_40"></a>3.启发式搜索</h3> 
<ul><li>描述：利用问题拥有的启发信息引导搜索</li><li>启发策略：估计一个状态到目标距离的函数</li><li><strong>贪婪搜索</strong>：扩展离目标最近的节点，不具完备性、最优性 
  <ul><li>评价节点：启发函数f(n)=h(n)(当前节点到终点的开销)</li></ul> </li><li><strong>A*搜索</strong>：代价一致搜索 + Greedy， 
  <ul><li>评价：f(n)=代价函数g(n) +启发函数h(n) 启发函数可采纳-&gt;最优性</li></ul> </li></ul> 
<h3><a id="4_47"></a>4.图搜索</h3> 
<ul><li>描述：避免重复状态，不扩展一个状态两次：树搜索+扩展过的状态集(closed set)</li><li><strong>A*图搜索</strong>：启发式的一致性 =&gt; A*图最优 
  <ul><li>一致性：沿路径的节点估计耗散 f 值单调递增：h(A) ≤ cost(A to C) + h©</li></ul> </li></ul> 
<h3><a id="5_51"></a>5.局部搜索</h3> 
<ul><li>描述：改进单一选项直到不能再改善为止；新的后继函数: 局部改变；不完备，不最优</li><li>爬山法：任意位置起始，重复直到移动到最好的相邻状态（可能局部最优解）</li><li>模拟退火搜索：引入随机因素，避免局部极大（允许向山下移动）</li><li>遗传算法：适应度函数，每步保留N个最好状态</li></ul> 
<h2><a id="_56"></a>二、人工神经网络</h2> 
<h3><a id="1_57"></a>1.神经网络</h3> 
<ul><li>神经元模型：二值神经元模型、模拟神经元模型、二值随机神经元</li><li>网络结构：前馈结构、反馈/循环结构</li><li>学习方法：通过神经网络所在环境的模拟过程，调整网络中的自由参数</li></ul> 
<h3><a id="2_61"></a>2.感知机</h3> 
<p>单层感知机：</p> 
<ul><li>二值神经元模型+单神经元网络</li><li>基于超平面判别分类，不能处理非线性分类问题</li></ul> 
<p>多层感知机：</p> 
<ul><li>模拟神经元模型+三层前馈网络</li><li>BP算法：链式规则，从前往后计算结果，从后往前误差反传调整参数（梯度求导），结果评价：最小二乘法</li><li><strong>梯度消失</strong>：BP网络中，由于激活函数的原因，误差反向传播时，样本梯度越来越小，基本上接近于0，意味着初始层的权重和偏差不会在训练中得到有效更新，可能导致网络整体不准确，得不到良好的解</li></ul> 
<h3><a id="3_70"></a>3.深度神经网络</h3> 
<ul><li>学习方法：自下向上的非监督学习 or 自顶向下的监督学习</li><li>自动编码器：非监督方法得到每层神经元的结果累加，通过端对端的训练调参</li><li>深度玻尔兹曼机DBM：浅层网络是双向的，最小化能量函数</li><li>受限玻尔兹曼机RBM：层间全连接，层内无连接，随机神经元，限定模型为二分图，学习目标是极大似然</li><li>深度置信网络DBN：非监督的预学习+监督微调，多个RBM堆叠<br> <img src="https://images2.imgbox.com/df/a9/TTC348dU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c6/b1/VqPLCfyC_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/32/52/GqRCt45K_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="4CNN_79"></a>4.CNN卷积网络</h3> 
<ul><li>特点：局部链接、参数共享、子采样（选择题）</li><li>BP算法 
  <ul><li>输出层：代价函数的确定及求导</li><li>Pooling：数据的下采样及残差的上采样，降低数据空间尺寸，减少网络参数</li><li>卷积层：数据的卷积运算及残差的反卷积运算，对输入图像降维和特征抽取</li><li>全连接层：整个网络分类器的作用</li></ul> </li><li>举例： 
  <ul><li>GoogleLeNet：模块叠加实现深层网络搭建</li><li>残差网络：解决深度网络退化问题，深层网络的后面若干层学习成恒等映射，模型就退化成浅层网络</li></ul> </li><li>图像数据应用 
  <ul><li>目标检测：卷积的滑动窗口实现+人像识别</li></ul> </li></ul> 
<h3><a id="5RNN_91"></a>5.RNN</h3> 
<ul><li>描述：对序列数据建模，存储过去信息+非线性动态更新隐藏状态</li><li>结构：隐层有时回有连向下一时间Hidden Layer的边</li><li>学习算法BPTT：实现权值一致，前向网络，所有时刻损失相加=总损失</li><li>长序列神经网络：解决梯度膨胀或消散问题 
  <ul><li>GRU：重置门、更新门(计算速度快、容易创建较大的网络)</li><li>LSTM：遗忘门、信息增加门和输出门</li><li>BRNN：双向</li><li>DRNN：深层循环神经网络<br> <img src="https://images2.imgbox.com/27/02/CRHF0ahb_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d0/83/HrbNRv0b_o.png" alt="在这里插入图片描述"><br> 序列模型：</li></ul> </li><li>机器翻译：条件语言模型 — 集束搜索 
  <ul><li>例子：Encoder、Decoder为RNN： 
    <ul><li>Encoder：每个输入的词向量会经过线性变换</li><li>Decoder：可以是预先训练好的语言模型，能预测合理的English短语</li><li>训练encoder、decoder的weights，使所有单词的交叉熵达到最小，每次得到一个最有可能的翻译结果</li></ul> </li></ul> </li><li>注意力模型：在生成每个翻译结果时只考虑部分提取到的特征<br> <img src="https://images2.imgbox.com/2a/59/eBp8XtYM_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="6GAN_110"></a>6.GAN生成式对抗网络</h3> 
<ul><li> <p>描述：生成器C(生成一个数据，会被判定结果优化)+判别器(判断是否是生成器生成的)</p> </li><li> <p>核心思想：纳什均衡<br> - 生成器：尽量学习真实的数据分布。把噪声数据Z通过生成模型G，伪装成真实数据x<br> - 判别器：尽量正确判别输入数据是真实数据还是来自生成器数据<br> - 各自提高自己生成能力和判别能力，这个学习优化的过程是寻找生成器和判别器之间的纳什均衡<br> <img src="https://images2.imgbox.com/04/e4/ybJ7DbEF_o.png" alt="在这里插入图片描述"></p> </li><li> <p>训练过程：</p> 
  <ul><li> 
    <ol><li>固定G，训练D，D希望V(G,D)越大越好，所以需要加上梯度（判断能力越来越好）</li></ol> </li><li> 
    <ol start="2"><li>固定D，训练G，G希望V(G,D)越小越好，所以要减去梯度（让判别模糊，生成欺骗能力越来越好)</li></ol> </li><li> 
    <ol start="3"><li>整个训练过程由上面两步交替进行，直至两者平衡</li></ol> </li></ul> </li><li> <p>类型：</p> 
  <ul><li>普通GAN：生成real的图像</li><li>条件GAN：生成符合条件的数据/图像，判断是否real + match</li><li>非监督条件GAN：产生相同风格的图像</li></ul> </li></ul> 
<h2><a id="_127"></a>考试回忆</h2> 
<ul><li>选择题： 
  <ul><li>A*树搜索最优条件</li><li>tanh函数图像</li><li>CNN特点</li><li>神经网络在哪一项引入非线性</li><li>感知机特点</li><li>GAN特点</li></ul> </li><li>简答题： 
  <ul><li>启发式算法：什么时候算法保证完备 or 保证最优？</li></ul> </li><li>应用题： 
  <ul><li>感知机实现布尔函数</li><li>卷积神经网络的各层神经元数量和可训练参数数量</li><li>RNN设计翻译器</li></ul> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/51a5caa5759cfe5eba299641c52e6216/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">人大金仓KingbaseES 中truncate和oracle中truncate区别</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9089af9ecea07d982d91ce9e643e1a2a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">git仓库清理瘦身解决 .git文件夹过大的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>