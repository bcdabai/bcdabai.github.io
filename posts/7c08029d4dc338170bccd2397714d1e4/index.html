<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>yolo理论合集 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="yolo理论合集" />
<meta property="og:description" content="文章目录 yolo1yolo2yolov3yolov3 spp （包括CIoU 和Focal Loss） https://github.com/WZMIAOMIAO/deep-learning-for-image-processing yolo1 xy是小网格中的，(0,1)
w,h是整个图像中的 ，(0,1)
confidence=bounding box是否含有object×预测的与gt之间的iou。
为每个目标的概率&#43;预测的目标边界框和真实的目标边界框的重合程度。
为什么w和h要根号？
假设蓝色为预测的边界框，绿色为真实边界框。
假设目标越小 ，预测的边界框与真实边界框偏移相同的情况下 ，IOU就越大，检测效果越差。
所以应该要让小目标的偏差设的更大一些。
confidence损失的前一项是正样本（C=1）的损失计算，后者是负样本的（ C=0）。
YOLOv1存在的问题：
1.因为每个cell只预测一组类别 ，所以对群体聚集的小目标检测结果较差。
2.输入尺寸变化时，检测效果较差；
3.定位不准确。（因为直接预测坐标信息）
yolo2 class大于9000
采用anchor偏移的方式，recall提升较高，map略微上升
t_0是confidence，也受到sigmoid限制。
高层和底层信息融合，为了更好提取细节信息。
每10个batch，就随机输入网络的图片尺寸（32的倍数）。
用224是为了方便对比。
yolov3 用了新的backbone，效果持平同时fps也比较高。和resnet相比，没有最大池化层，而是用了卷积。
http://blog.csdn.net/qq_37541097/article/details/81214953
yolov3 spp （包括CIoU 和Focal Loss） A^c是蓝色框，u是并集。GIoU在两者不相交时也可提供损失。
CIoU(D)是将C计算IoU时把其换成DIoU
负样本挖掘没focal loss好。
正负样本。
难易样本。
右边曲线表示:
p_t越大，就表示越容易分类。这部分就降低其权重。
越小，表示越难分类，这部分就提高其权重。
这里的α是用来平衡γ的（平衡套娃）。
前两者都是易分样本，所以权重降低比较好。
前提：数据标注要正确。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7c08029d4dc338170bccd2397714d1e4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-27T23:59:57+08:00" />
<meta property="article:modified_time" content="2022-02-27T23:59:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">yolo理论合集</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#yolo1_2" rel="nofollow">yolo1</a></li><li><a href="#yolo2_27" rel="nofollow">yolo2</a></li><li><a href="#yolov3_55" rel="nofollow">yolov3</a></li><li><a href="#yolov3_spp_CIoU__Focal_Loss_76" rel="nofollow">yolov3 spp （包括CIoU 和Focal Loss）</a></li></ul> 
</div> 
<br> https://github.com/WZMIAOMIAO/deep-learning-for-image-processing 
<p></p> 
<h2><a id="yolo1_2"></a>yolo1</h2> 
<p><img src="https://images2.imgbox.com/4f/c0/7yPDc7BZ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/62/14/jObHaevg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7d/69/v9vqyzQj_o.png" alt="在这里插入图片描述"><br> xy是小网格中的，(0,1)<br> w,h是整个图像中的 ，(0,1)<br> confidence=bounding box是否含有object×预测的与gt之间的iou。</p> 
<p>为每个目标的概率+预测的目标边界框和真实的目标边界框的重合程度。<br> <img src="https://images2.imgbox.com/59/e0/ILvrKXMA_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/96/cTUZoJQp_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/83/4b/Q496Lncc_o.png" alt="在这里插入图片描述"><br> 为什么w和h要根号？<br> 假设蓝色为预测的边界框，绿色为真实边界框。<br> 假设目标越小 ，预测的边界框与真实边界框偏移相同的情况下 ，IOU就越大，检测效果越差。<br> 所以应该要让小目标的偏差设的更大一些。<br> <img src="https://images2.imgbox.com/8e/39/OKfcux9z_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c9/da/YruYubyA_o.png" alt="在这里插入图片描述"><br> confidence损失的前一项是正样本（C=1）的损失计算，后者是负样本的（ C=0）。</p> 
<p>YOLOv1存在的问题：<br> 1.因为每个cell只预测一组类别 ，所以对群体聚集的小目标检测结果较差。<br> 2.输入尺寸变化时，检测效果较差；<br> 3.定位不准确。（因为直接预测坐标信息）<br> <img src="https://images2.imgbox.com/98/4a/vnH6ebnX_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="yolo2_27"></a>yolo2</h2> 
<p><img src="https://images2.imgbox.com/28/3d/A0RAxg4E_o.png" alt="在这里插入图片描述"><br> class大于9000<br> <img src="https://images2.imgbox.com/fd/f5/8cPCxudh_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/27/03/bFw9EcfB_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d4/96/CWMhjh4G_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/21/1d/EyBJrI0y_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d4/9e/swrGoVwN_o.png" alt="在这里插入图片描述"><br> 采用anchor偏移的方式，recall提升较高，map略微上升<br> <img src="https://images2.imgbox.com/a2/5d/ezGuNS3T_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/3e/18/Bpie2bTM_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/89/a1/mi11gyvY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c0/00/ATJBCWVs_o.png" alt="在这里插入图片描述"><br> t_0是confidence，也受到sigmoid限制。<br> <img src="https://images2.imgbox.com/39/54/rrw1LR8r_o.png" alt="在这里插入图片描述"><br> 高层和底层信息融合，为了更好提取细节信息。<br> <img src="https://images2.imgbox.com/06/5d/aU52wTkL_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/16/93/mJPEjBjz_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c1/ef/cVaizoUZ_o.png" alt="在这里插入图片描述"><br> 每10个batch，就随机输入网络的图片尺寸（32的倍数）。<br> <img src="https://images2.imgbox.com/a5/60/ry5H7eni_o.png" alt="在这里插入图片描述"><br> 用224是为了方便对比。<br> <img src="https://images2.imgbox.com/1a/e7/KeJkqj8e_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bf/4a/PE52yfZ6_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f3/4c/UyyVcrZX_o.png" alt=" "></p> 
<h2><a id="yolov3_55"></a>yolov3</h2> 
<p><img src="https://images2.imgbox.com/b8/f3/uJyX5aV7_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/ae/f6/Hi1AveIq_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/b4/1rSt9F9Q_o.png" alt="在这里插入图片描述"><br> 用了新的backbone，效果持平同时fps也比较高。和resnet相比，没有最大池化层，而是用了卷积。<br> <img src="https://images2.imgbox.com/5a/94/TKJ6uAy5_o.png" alt="在这里插入图片描述"><br> http://blog.csdn.net/qq_37541097/article/details/81214953<br> <img src="https://images2.imgbox.com/a2/bc/djJq4iiJ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/95/cf/SCc0RBaT_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/39/f9/BHxV0dOs_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/23/f6/hSijTuDz_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/61/38/iOUiZ7YJ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/81/ec/pm47Re5M_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/97/2f/195T1eja_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/65/6c/wpZPps3e_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/20/16/zKvo2abU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/49/8f/SAdZ5ouK_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/90/75/E9RTewxI_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/32/a8/eKYPqEwe_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="yolov3_spp_CIoU__Focal_Loss_76"></a>yolov3 spp （包括CIoU 和Focal Loss）</h2> 
<p><img src="https://images2.imgbox.com/a5/8a/ZHFuoEis_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/e7/86/1We8yVDZ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c0/f3/WxiPZwfG_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/63/d7/DzY1TxX4_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8b/12/n8QaseY4_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/9e/80/zsm4uH4Z_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c4/08/rrpaBWap_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/53/68/TKUlkcTk_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c9/bc/9UmGwdZj_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/de/51/jzbiTr5Z_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6f/59/lQpe2Zaj_o.png" alt="在这里插入图片描述"><br> A^c是蓝色框，u是并集。GIoU在两者不相交时也可提供损失。<br> <img src="https://images2.imgbox.com/17/f6/DyW1YCOu_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6c/8c/YevqeqAp_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/cd/ae/rHdImZuh_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/89/8f/JmIwvM0h_o.png" alt="在这里插入图片描述"><br> CIoU(D)是将C计算IoU时把其换成DIoU<br> <img src="https://images2.imgbox.com/f1/f6/UrBaklNL_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b2/5c/Q5tzzxu8_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/19/00/FKZVFDrL_o.png" alt="在这里插入图片描述"><br> 负样本挖掘没focal loss好。<br> <img src="https://images2.imgbox.com/95/9b/hlRQyy9P_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/ce/16/hRW9t2J5_o.png" alt="在这里插入图片描述"><br> 正负样本。<br> <img src="https://images2.imgbox.com/ea/dc/VDgi2eMW_o.png" alt="在这里插入图片描述"><br> 难易样本。<br> 右边曲线表示:<br> p_t越大，就表示越容易分类。这部分就降低其权重。<br> 越小，表示越难分类，这部分就提高其权重。<br> <img src="https://images2.imgbox.com/92/dc/YQDLdOiy_o.png" alt="在这里插入图片描述"><br> 这里的α是用来平衡γ的（平衡套娃）。<br> <img src="https://images2.imgbox.com/90/3c/efrl1vZ1_o.png" alt="在这里插入图片描述"><br> 前两者都是易分样本，所以权重降低比较好。</p> 
<p>前提：数据标注要正确。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f40ded30b3ee4aca2717e7601b8d9096/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">动态规划（js版）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c5dbb6b51e52b1dd7e0f7f48b5750654/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Visual Studio2017源码编译libzip源码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>