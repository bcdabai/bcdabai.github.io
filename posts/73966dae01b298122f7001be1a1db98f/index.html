<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>COCO 数据集的使用，以及下载链接 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="COCO 数据集的使用，以及下载链接" />
<meta property="og:description" content="转于：https://www.cnblogs.com/q735613050/p/8969452.html
Windows 10 编译 Pycocotools 踩坑记
COCO数据库简介
一、下载链接 [1] - train2014 images: (13GB)
http://images.cocodataset.org/zips/train2014.zip
[2] - val2014 images:(6GB)
http://images.cocodataset.org/zips/val2014.zip
[3] - train2014/val2014 annotations:(241MB)
http://images.cocodataset.org/annotations/annotations_trainval2014.zip
[4] - test2014 images: (12GB)
http://images.cocodataset.org/zips/test2014.zip
[5] - test2015 images: (12GB)
http://images.cocodataset.org/zips/test2015.zip
[6] - train2017 images: (18GB)
http://images.cocodataset.org/zips/train2017.zip
[7] - val2017 images: (1GB)
http://images.cocodataset.org/zips/val2017.zip
[8] - train2017/val2017 annotations: (241MB)
http://images.cocodataset.org/annotations/annotations_trainval2017.zip
[9] - stuff train2017/val2017 annotations: (1.1GB)
http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip
[10] - test2017 images: (6GB)
http://images.cocodataset.org/zips/test2017.zip
[11] - Panoptic train2017/val2017 annotations: (821MB)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/73966dae01b298122f7001be1a1db98f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-07-03T10:04:10+08:00" />
<meta property="article:modified_time" content="2019-07-03T10:04:10+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">COCO 数据集的使用，以及下载链接</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>转于：<a href="https://www.cnblogs.com/q735613050/p/8969452.html" rel="nofollow">https://www.cnblogs.com/q735613050/p/8969452.html</a></p> 
<ul><li> <p><a href="https://www.jianshu.com/p/de455d653301" rel="nofollow">Windows 10 编译 Pycocotools 踩坑记</a></p> </li><li> <p><a href="https://blog.csdn.net/happyhorizion/article/details/77894205#coco">COCO数据库简介</a></p> </li></ul> 
<h2>一、下载链接</h2> 
<p>[1] - <strong>train2014 images:</strong> (13GB)</p> 
<p><a href="http://images.cocodataset.org/zips/train2014.zip" rel="nofollow">http://images.cocodataset.org/zips/train2014.zip</a></p> 
<p>[2] - <strong>val2014 images:</strong>(6GB)</p> 
<p><a href="http://images.cocodataset.org/zips/val2014.zip" rel="nofollow">http://images.cocodataset.org/zips/val2014.zip</a></p> 
<p>[3] - <strong>train2014/val2014 annotations:</strong>(241MB)</p> 
<p><a href="http://images.cocodataset.org/annotations/annotations_trainval2014.zip" rel="nofollow">http://images.cocodataset.org/annotations/annotations_trainval2014.zip</a></p> 
<p>[4] - <strong>test2014 images:</strong> (12GB)</p> 
<p><a href="http://images.cocodataset.org/zips/test2014.zip" rel="nofollow">http://images.cocodataset.org/zips/test2014.zip</a></p> 
<p>[5] - <strong>test2015 images:</strong> (12GB)</p> 
<p><a href="http://images.cocodataset.org/zips/test2015.zip" rel="nofollow">http://images.cocodataset.org/zips/test2015.zip</a></p> 
<p>[6] - <strong>train2017 images:</strong> (18GB)</p> 
<p><a href="http://images.cocodataset.org/zips/train2017.zip" rel="nofollow">http://images.cocodataset.org/zips/train2017.zip</a></p> 
<p>[7] - <strong>val2017 images:</strong> (1GB)</p> 
<p><a href="http://images.cocodataset.org/zips/val2017.zip" rel="nofollow">http://images.cocodataset.org/zips/val2017.zip</a></p> 
<p>[8] - <strong>train2017/val2017 annotations:</strong> (241MB)</p> 
<p><a href="http://images.cocodataset.org/annotations/annotations_trainval2017.zip" rel="nofollow">http://images.cocodataset.org/annotations/annotations_trainval2017.zip</a></p> 
<p>[9] - <strong>stuff train2017/val2017 annotations:</strong> (1.1GB)</p> 
<p><a href="http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip" rel="nofollow">http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip</a></p> 
<p>[10] - <strong>test2017 images:</strong> (6GB)</p> 
<p><a href="http://images.cocodataset.org/zips/test2017.zip" rel="nofollow">http://images.cocodataset.org/zips/test2017.zip</a></p> 
<p>[11] - <strong>Panoptic train2017/val2017 annotations: </strong>(821MB)</p> 
<p><a href="http://images.cocodataset.org/annotations/panoptic_annotations_trainval2017.zip" rel="nofollow">http://images.cocodataset.org/annotations/panoptic_annotations_trainval2017.zip</a></p> 
<p>[12] - <strong>test2017 images:</strong> (6GB)</p> 
<p><a href="http://images.cocodataset.org/zips/test2017.zip" rel="nofollow">http://images.cocodataset.org/zips/test2017.zip</a></p> 
<p>[13] - <strong>Unlabeled2017 images:</strong> (19GB)</p> 
<p><a href="http://images.cocodataset.org/zips/unlabeled2017.zip" rel="nofollow">http://images.cocodataset.org/zips/unlabeled2017.zip</a></p> 
<p>[14]-<strong>info_test image:</strong>(1MB)</p> 
<p>http://images.cocodataset.org/annotations/image_info_test2017.zip</p> 
<h2>二、使用</h2> 
<h4><strong>１．Note</strong>：</h4> 
<ul><li>在COCO数据集评价指标中，所有的AP <strong>默认为mAP</strong> 。即，AP50=mAP50，AP75=mAP75，以此类推。</li><li>AP50一定大于AP75</li><li>在更早期的数据集VOC上，数据量更少，评价指标也更简单，为 <strong>mAP</strong> ，即相当于COCO数据集上的 AP50这一单项指标。</li><li>COCO数据集出来后，对检测算法性能的评价指标变得多样化，也更加客观全面了。</li></ul> 
<p> </p> 
<p>２．微软发布的COCO数据库, 除了图片以外还提供物体检测, 分割(segmentation)和对图像的语义文本描述信息.<br> COCO数据库的网址是:</p> 
<ul><li>MS COCO API - http://mscoco.org/</li><li>Github网址 - https://github.com/pdollar/coco</li><li>关于API更多的细节在网站: http://mscoco.org/dataset/#download</li></ul> 
<p> </p> 
<p>数据库提供 Matlab, Python 和 Lua 的 API 接口. 其中 matlab 和 python 的 API 接口可以提供完整的图像标签数据的加载, parsing 和可视化.此外,网站还提供了数据相关的文章, 教程等.</p> 
<p>在使用 COCO 数据库提供的 API 和 demo 时, 需要首先下载 COCO 的图像和标签数据.</p> 
<ul><li>安装: 
  <ol><li>首先解压数据文件: 
    <ul><li>图像数据下载到 <code>coco/images/</code> 文件夹中</li><li>标签数据下载到 <code>coco/</code> 文件夹中.</li></ul></li><li>matlab, 在 matlab 的默认路径中添加 <code>coco/MatlabApi</code></li><li>Python. 打开终端,将路径切换到 <code>coco/PythonAPI</code>下,输入 <code>make</code></li></ol></li><li>COCO数据集的标注信息</li></ul> 
<p>COCO的数据标注信息包括:</p> 
<ul><li>类别标志</li><li>类别数量区分</li><li>像素级的分割</li></ul> 
<pre class="has"><code>import sys
sys.path.append('E:/xinlib')
from data import cocox
import zipfile</code></pre> 
<p>查看 <code>coco/images/</code> 文件夹下的数据：</p> 
<pre class="has"><code>image_names = cocox.get_image_names()
image_names</code></pre> 
<pre class="has"><code>['E:/Data/coco/images/test2017.zip',
 'E:/Data/coco/images/train2017.zip',
 'E:/Data/coco/images/unlabeled2017.zip',
 'E:/Data/coco/images/val2017.zip']</code></pre> 
<p>查看 <code>coco/</code> 文件夹的文件：</p> 
<pre class="has"><code>import os
dataDir = cocox.root</code></pre> 
<pre class="has"><code>os.listdir(dataDir)</code></pre> 
<pre class="has"><code>['annotations',
 'annotations_trainval2017.zip',
 'cocoapi',
 'images',
 'image_info_test2017.zip',
 'image_info_unlabeled2017.zip',
 'stuff_annotations_trainval2017.zip']</code></pre> 
<p>我们只需要获取 annotations 的信息（这里都是以 <code>.zip</code> 结尾）：</p> 
<pre class="has"><code>annDir = [z_name for z_name in os.listdir(dataDir) if z_name.endswith('.zip')]
annDir</code></pre> 
<pre class="has"><code>['annotations_trainval2017.zip',
 'image_info_test2017.zip',
 'image_info_unlabeled2017.zip',
 'stuff_annotations_trainval2017.zip']</code></pre> 
<p>解压 annotations 的文件：</p> 
<pre class="has"><code>for ann_name in annDir:
    z = zipfile.ZipFile(dataDir + '/' + ann_name)
    # 全部解压
    z.extractall(dataDir)</code></pre> 
<pre class="has"><code># 封装为函数
cocox.unzip_annotations()</code></pre> 
<pre class="has"><code># 删除标签的压缩文件
cocox.del_annotations()</code></pre> 
<p>由于图片数据比较大，我就不解压了，不过可以通过 <code>MXNet + zipfile</code> 来直接获取图片信息。</p> 
<h2 id="获取图片数据">获取图片数据</h2> 
<p>我以 <code>test2017.zip</code> 为例：</p> 
<pre class="has"><code>image_names</code></pre> 
<pre class="has"><code>['E:/Data/coco/images/test2017.zip',
 'E:/Data/coco/images/train2017.zip',
 'E:/Data/coco/images/unlabeled2017.zip',
 'E:/Data/coco/images/val2017.zip']</code></pre> 
<pre class="has"><code>z = zipfile.ZipFile(image_names[0])</code></pre> 
<pre class="has"><code># 测试集的图片名称列表
z.namelist()</code></pre> 
<pre class="has"><code>['test2017/',
 'test2017/000000259564.jpg',
 'test2017/000000344475.jpg',
 ...]</code></pre> 
<p>我们可以看出，第一个是目录名，之后的才是图片。下面我们来看看第一张图片：</p> 
<pre class="has"><code>from mxnet import image</code></pre> 
<pre class="has"><code>r = z.read(z.namelist()[1])    # bytes
data = image.imdecode(r)       # 转换为 NDArray 数组，可以做数值运算
data</code></pre> 
<pre class="has"><code>[[[ 87  94  78]
  [ 85  94  77]
  [ 87  96  79]
  ..., 
  [108  63  44]
  [252 244 233]
  [253 253 253]]

 [[ 86  95  76]
  [ 88  97  78]
  [ 85  94  75]
  ..., 
  [ 55  14   0]
  [150  94  81]
  [252 245 216]]

 [[ 90  99  78]
  [ 89  98  77]
  [ 89  98  77]
  ..., 
  [ 63  37  12]
  [ 90  30   6]
  [149  83  61]]

 ..., 
 [[ 86 104  82]
  [ 89 102  82]
  [ 84 102  80]
  ..., 
  [ 50  62  40]
  [ 50  61  45]
  [ 51  58  50]]

 [[ 89 101  77]
  [ 87  96  75]
  [ 89 104  83]
  ..., 
  [ 54  63  42]
  [ 49  53  39]
  [ 53  54  48]]

 [[ 96 100  77]
  [ 94  97  76]
  [ 88 103  82]
  ..., 
  [ 44  58  32]
  [ 45  57  37]
  [ 49  57  42]]]
&lt;NDArray 480x640x3 @cpu(0)&gt;</code></pre> 
<pre class="has"><code>x = data.asnumpy()   # 转换为 array</code></pre> 
<pre class="has"><code># 显示图片
%pylab inline 
plt.imshow(x)</code></pre> 
<p><img alt="output_21_3.png-125.1kB" class="has" src="https://images2.imgbox.com/37/e5/voD5wQyp_o.png"></p> 
<p>为此，我们可以将其封装为一个迭代器：<code>cocox.data_iter(dataType)</code></p> 
<h2 id="获取标签信息利用官方给定教程">获取标签信息（利用官方给定教程）</h2> 
<ul><li>安装 python API：</li></ul> 
<pre class="has"><code>pip install -U pycocotools</code></pre> 
<p>Windows （一般需要安装 visual studio）下有许多的坑：<a href="https://www.jianshu.com/p/de455d653301" rel="nofollow">Windows 10 编译 Pycocotools 踩坑记</a></p> 
<pre class="has"><code>%pylab inline
from pycocotools.coco import COCO
import numpy as np
import skimage.io as io
import matplotlib.pyplot as plt
import pylab
pylab.rcParams['figure.figsize'] = (8.0, 10.0)</code></pre> 
<p>这里有一个坑 (由 PIL 引发) <code>import skimage.io as io</code> 在 Windows 下可能会报错，我的解决办法是：</p> 
<ul><li> <p>先卸载 Pillow，然后重新安装即可。</p> </li><li> <p>插曲：PIL(Python Imaging Library)是Python一个强大方便的图像处理库，名气也比较大。Pillow 是 PIL 的一个派生分支，但如今已经发展成为比 PIL 本身更具活力的图像处理库。</p> </li></ul> 
<pre class="has"><code>dataDir = cocox.root
dataType = 'val2017'
annFile = '{}/annotations/instances_{}.json'.format(dataDir, dataType)</code></pre> 
<pre class="has"><code># initialize COCO api for instance annotations
coco=COCO(annFile)</code></pre> 
<pre class="has"><code>loading annotations into memory...
Done (t=0.93s)
creating index...
index created!</code></pre> 
<pre class="has"><code>COCO??</code></pre> 
<p><code>COCO</code> 是一个类：</p> 
<pre class="has"><code>Constructor of Microsoft COCO helper class for reading and visualizing annotations.
:param annotation_file (str): location of annotation file
:param image_folder (str): location to the folder that hosts images.</code></pre> 
<h3 id="display-coco-categories-and-supercategories">display COCO categories and supercategories</h3> 
<pre class="has"><code>cats = coco.loadCats(coco.getCatIds())
nms = [cat['name'] for cat in cats]
print('COCO categories: \n{}\n'.format(' '.join(nms)))

nms = set([cat['supercategory'] for cat in cats])
print('COCO supercategories: \n{}'.format(' '.join(nms)))</code></pre> 
<pre class="has"><code>COCO categories: 
person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush

COCO supercategories: 
appliance sports person indoor vehicle food electronic furniture animal outdoor accessory kitchen</code></pre> 
<pre class="has"><code># get all images containing given categories, select one at random
catIds = coco.getCatIds(catNms=['person', 'dog', 'skateboard'])
imgIds = coco.getImgIds(catIds=catIds)
imgIds = coco.getImgIds(imgIds=[335328])
img = coco.loadImgs(imgIds[np.random.randint(0, len(imgIds))])[0]</code></pre> 
<pre class="has"><code>img</code></pre> 
<pre class="has"><code>{'license': 4,
 'file_name': '000000335328.jpg',
 'coco_url': 'http://images.cocodataset.org/val2017/000000335328.jpg',
 'height': 640,
 'width': 512,
 'date_captured': '2013-11-20 19:29:37',
 'flickr_url': 'http://farm3.staticflickr.com/2079/2128089396_ddd988a59a_z.jpg',
 'id': 335328}</code></pre> 
<p>官方给的这个代码需要将图片数据集解压：</p> 
<pre class="has"><code># load and display image
# use url to load image
# I = io.imread(img['coco_url'])
I = io.imread('%s/images/%s/%s' % (dataDir, dataType, img['file_name']))
plt.axis('off')
plt.imshow(I)
plt.show()</code></pre> 
<p>我们可以使用 <code>zipfile</code> 模块直接读取图片，而无须解压：</p> 
<pre class="has"><code>image_names[-1]</code></pre> 
<pre class="has"><code>'E:/Data/coco/images/val2017.zip'</code></pre> 
<pre class="has"><code>val_z = zipfile.ZipFile(image_names[-1])
I = image.imdecode(val_z.read('%s/%s' % (dataType, img['file_name']))).asnumpy()
plt.axis('off')
plt.imshow(I)
plt.show()</code></pre> 
<p><img alt="output_36_0.png-493.1kB" class="has" src="https://images2.imgbox.com/13/33/vEXY51yz_o.png"></p> 
<h3 id="load-and-display-instance-annotations">load and display instance annotations</h3> 
<pre class="has"><code>plt.imshow(I)
plt.axis('off')
annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)
anns = coco.loadAnns(annIds)
coco.showAnns(anns)</code></pre> 
<p><img alt="output_38_0.png-491.6kB" class="has" src="https://images2.imgbox.com/01/61/Mo8Btltn_o.png"></p> 
<h3 id="initialize-coco-api-for-person-keypoints-annotations">initialize COCO api for person keypoints annotations</h3> 
<pre class="has"><code>annFile = '{}/annotations/person_keypoints_{}.json'.format(dataDir, dataType)
coco_kps = COCO(annFile)</code></pre> 
<pre class="has"><code>loading annotations into memory...
Done (t=0.43s)
creating index...
index created!</code></pre> 
<h3 id="load-and-display-keypoints-annotations">load and display keypoints annotations</h3> 
<pre class="has"><code>plt.imshow(I)
plt.axis('off')
ax = plt.gca()
annIds = coco_kps.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)
anns = coco_kps.loadAnns(annIds)
coco_kps.showAnns(anns)</code></pre> 
<p><img alt="output_42_0.png-491kB" class="has" src="https://images2.imgbox.com/bc/9d/KBOEJ7ld_o.png"></p> 
<h3 id="initialize-coco-api-for-caption-annotations">initialize COCO api for caption annotations</h3> 
<pre class="has"><code>annFile = '{}/annotations/captions_{}.json'.format(dataDir, dataType)
coco_caps = COCO(annFile)</code></pre> 
<pre class="has"><code>loading annotations into memory...
Done (t=0.06s)
creating index...
index created!</code></pre> 
<h3 id="load-and-display-caption-annotations">load and display caption annotations</h3> 
<pre class="has"><code>annIds = coco_caps.getAnnIds(imgIds=img['id'])
anns = coco_caps.loadAnns(annIds)
coco_caps.showAnns(anns)
plt.imshow(I)
plt.axis('off')
plt.show()</code></pre> 
<pre class="has"><code>A couple of people riding waves on top of boards.
a couple of people that are surfing in water
A man and a young child in wet suits surfing in the ocean.
a man and small child standing on a surf board  and riding some waves
A young boy on a surfboard being taught to surf.</code></pre> 
<p><img alt="output_46_1.png-493.1kB" class="has" src="https://images2.imgbox.com/c4/26/goB90nh6_o.png"></p> 
<ul><li><a href="https://nbviewer.jupyter.org/github/q735613050/dataLoader/blob/master/COCO/coco%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86.ipynb" rel="nofollow">GitHub 展示</a></li></ul> 
<p>你也可以在线编辑：https://mybinder.org/v2/gh/q735613050/dataLoader/master</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/016b3fefbc5da6c954d5f80b2c0ac4a8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Daily Scrum: 2012/11/12</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/de6f16ef0811f2a124deb2de112d7e9c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">前端请求后端接口出现Waiting(TTFB)耗时很长的解决方案</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>