<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>tensorflow学习笔记（五）：模型参数的保存和读取saver - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="tensorflow学习笔记（五）：模型参数的保存和读取saver" />
<meta property="og:description" content="文章目录 一、Tensorflow模型二、保存模型三、模型数据的读取四、其他保存和读取方法 在深度学习中，经常会听到”预训练“、”保存模型“、”加载模型“等词，实际上就是在模型训练完成之后，将模型及其训练得到的参数保存下来，下次再来直接调用，或者上次得到的数据上再次训练（预训练)。
一、Tensorflow模型 所谓的Tensorflow模型，是指训练得到的网络参数的网络设计或图形和值。因此，Tensorflow模型有两个主要的文件:
Meta graph：这是一个协议缓冲区，它保存了完整的Tensorflow图形;即所有变量、操作、集合等。该文件以.meta作为扩展名，如下： model.ckpt.meta Checkpoint file:：这个文件是以.ckpt为后缀的,是个二进制的文件，里面保存了.meta文件中对应变量或者tensor或者操作等等的值。但是现在变成了三个文件，分别是以.index 和.data为后缀的两个文件加上一个checkpoint文件。其中.data文件保存了我们训练的变量的值;checkpoint 文件仅仅记录最新保存的模型是哪个，如下： checkpoint model.ckpt.data-00000-of-00001 model.ckpt.index 二、保存模型 在深度学习中，往往训练需要很长的时间，而每次要用模型的时候不可能重新在训练一次，所以要把模型保存起来。在tensorflow中如果想保存graph和参数的值，我们需要用到tf.train.Saver() ，演示代码如下：
#################保存模型################ # 执行本段程序时注意当前的工作路径 import tensorflow as tf v1 = tf.Variable(tf.constant(1.0, shape=[1]), name=&#34;v1&#34;) v2 = tf.Variable(tf.constant(2.0, shape=[1]), name=&#34;v2&#34;) result = v1 &#43; v2 saver = tf.train.Saver() with tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver.save(sess, &#34;Model/model.ckpt&#34;) 将定义的float32型的2*3的矩阵保存在当前路径的&#34;Model&#34;文件夹中，4个文件如下：
三、模型数据的读取 现在开始读取上一步保存的模型参数。有两种方法：
1）、自己写一个一模一样的网络出来，如下：
#########加载方法一： #重新定义相同的dtype和shape import tensorflow as tf v1 = tf.Variable(tf.constant(1.0, shape=[1]), name=&#34;v1&#34;) v2 = tf.Variable(tf.constant(1.0, shape=[1]), name=&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/37f5d0342657fc53b1445fb3ce8d7bbb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-02T21:50:44+08:00" />
<meta property="article:modified_time" content="2019-08-02T21:50:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">tensorflow学习笔记（五）：模型参数的保存和读取saver</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Tensorflow_6" rel="nofollow">一、Tensorflow模型</a></li><li><a href="#_19" rel="nofollow">二、保存模型</a></li><li><a href="#_41" rel="nofollow">三、模型数据的读取</a></li><li><a href="#_83" rel="nofollow">四、其他保存和读取方法</a></li></ul> 
</div> 
<p></p> 
<hr> 
<p>在深度学习中，经常会听到”预训练“、”保存模型“、”加载模型“等词，实际上就是在模型训练完成之后，将模型及其训练得到的参数保存下来，下次再来直接调用，或者上次得到的数据上再次训练（预训练)。</p> 
<h2><a id="Tensorflow_6"></a>一、Tensorflow模型</h2> 
<p>所谓的Tensorflow模型，是指训练得到的网络参数的网络设计或图形和值。因此，Tensorflow模型有两个主要的文件:</p> 
<ul><li><strong>Meta graph</strong>：这是一个协议缓冲区，它保存了完整的Tensorflow图形;即所有变量、操作、集合等。该文件以.meta作为扩展名，如下：</li></ul> 
<pre><code>model.ckpt.meta
</code></pre> 
<ul><li><strong>Checkpoint file:</strong>：这个文件是以.ckpt为后缀的,是个二进制的文件，里面保存了.meta文件中对应变量或者tensor或者操作等等的值。但是现在变成了三个文件，分别是以.index 和.data为后缀的两个文件加上一个checkpoint文件。其中.data文件保存了我们训练的变量的值;checkpoint 文件仅仅记录最新保存的模型是哪个，如下：</li></ul> 
<pre><code>checkpoint
model.ckpt.data-00000-of-00001
model.ckpt.index
</code></pre> 
<h2><a id="_19"></a>二、保存模型</h2> 
<p>在深度学习中，往往训练需要很长的时间，而每次要用模型的时候不可能重新在训练一次，所以要把模型保存起来。在tensorflow中如果想保存graph和参数的值，我们需要用到tf.train.Saver() ，演示代码如下：</p> 
<pre><code>#################保存模型################ 

# 执行本段程序时注意当前的工作路径
import tensorflow as tf

v1 = tf.Variable(tf.constant(1.0, shape=[1]), name="v1")
v2 = tf.Variable(tf.constant(2.0, shape=[1]), name="v2")
result = v1 + v2

saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    saver.save(sess, "Model/model.ckpt")
    
</code></pre> 
<p>将定义的float32型的2*3的矩阵保存在当前路径的"Model"文件夹中，4个文件如下：<br> <img src="https://images2.imgbox.com/dd/8d/H64wpOzc_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_41"></a>三、模型数据的读取</h2> 
<p>现在开始读取上一步保存的模型参数。有两种方法：<br> <strong>1）、自己写一个一模一样的网络出来</strong>，如下：</p> 
<pre><code>#########加载方法一：

#重新定义相同的dtype和shape
import tensorflow as tf

v1 = tf.Variable(tf.constant(1.0, shape=[1]), name="v1")
v2 = tf.Variable(tf.constant(1.0, shape=[1]), name="v2")
result = v1 + v2

saver = tf.train.Saver()

with tf.Session() as sess:
    saver.restore(sess, "./Model/model.ckpt")  # 注意此处路径前添加"./"
    print(sess.run(result))
    
#输出：
[3.]
</code></pre> 
<p>这里的输出，并不是自己生产的[2.0]，所以是加载的上一步保存的结果[3.0]。并且，定义的W和b的名称name=“v1”，name="v2"必须和之前保持一致，否则无法读取。</p> 
<p><strong>2）、直接引入meta文件中保存的网络graph</strong>，如下：</p> 
<pre><code>#加载方法二：若不希望重复定义计算图上的运算，可直接加载已经持久化的图

import tensorflow as tf

saver = tf.train.import_meta_graph("Model/model.ckpt.meta")

with tf.Session() as sess:
    saver.restore(sess, "./Model/model.ckpt")  # 注意路径写法
    print(sess.run(tf.get_default_graph().get_tensor_by_name("add:0")))

#输出：
[3.]
</code></pre> 
<h2><a id="_83"></a>四、其他保存和读取方法</h2> 
<p>1）、<strong>tf.train.Saver类也支持在保存和加载时给变量重命名</strong>，如下：</p> 
<pre><code>
import tensorflow as tf
 
# 声明的变量名称name与已保存的模型中的变量名称name不一致
u1 = tf.Variable(tf.constant(1.0, shape=[1]), name="other-v1")
u2 = tf.Variable(tf.constant(2.0, shape=[1]), name="other-v2")
result = u1 + u2
 
# 若直接声明Saver类对象，会报错变量找不到
# 使用一个字典dict重命名变量即可，{"已保存的变量的名称name": 重命名变量名}
# 原来名称name为v1的变量现在加载到变量u1（名称name为other-v1）中
saver = tf.train.Saver({"v1": u1, "v2": u2})
 
with tf.Session() as sess:
    saver.restore(sess, "./Model/model.ckpt")
    print(sess.run(result)) 

#输出：
[3.]
</code></pre> 
<p><strong>2）、保存滑动平均模型</strong>，如下：</p> 
<pre><code>
import tensorflow as tf
 
v = tf.Variable(0, dtype=tf.float32, name="v")
for variables in tf.global_variables():
    print(variables.name)         #输出：   v:0
 
ema = tf.train.ExponentialMovingAverage(0.99)
maintain_averages_op = ema.apply(tf.global_variables())
for variables in tf.global_variables():
    print(variables.name)    # 输出：     v:0
                             #输出：      v/ExponentialMovingAverage:0
 
saver = tf.train.Saver()
 
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(tf.assign(v, 10))
    sess.run(maintain_averages_op)
    saver.save(sess, "Model/model_ema.ckpt")
    print(sess.run([v, ema.average(v)]))     #输出：  [10.0, 0.099999905]

</code></pre> 
<p>然后<strong>通过变量重命名直接读取变量的滑动平均值</strong>，如下：</p> 
<pre><code>
import tensorflow as tf
 
v = tf.Variable(0, dtype=tf.float32, name="v")
saver = tf.train.Saver({"v/ExponentialMovingAverage": v})
 
with tf.Session() as sess:
    saver.restore(sess, "./Model/model_ema.ckpt")
    print(sess.run(v))     # 输出：    0.0999999
    
</code></pre> 
<p>3）、<strong>通过tf.train.ExponentialMovingAverage的variables_to_restore()函数获取变量重命名字典</strong>，如下：</p> 
<pre><code>
import tensorflow as tf

v = tf.Variable(0, dtype=tf.float32, name="v")
# 注意此处的变量名称name一定要与已保存的变量名称一致
ema = tf.train.ExponentialMovingAverage(0.99)
print(ema.variables_to_restore())
# {'v/ExponentialMovingAverage': &lt;tf.Variable 'v:0' shape=() dtype=float32_ref&gt;}
# 此处的v取自上面变量v的名称name="v"

saver = tf.train.Saver(ema.variables_to_restore())

with tf.Session() as sess:
    saver.restore(sess, "./Model/model_ema.ckpt")
    print(sess.run(v))       #输出     0.0999999

</code></pre> 
<p><strong>4）、通过convert_variables_to_constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中</strong></p> 
<pre><code>
import tensorflow as tf
from tensorflow.python.framework import graph_util

v1 = tf.Variable(tf.constant(1.0, shape=[1]), name="v1")
v2 = tf.Variable(tf.constant(2.0, shape=[1]), name="v2")
result = v1 + v2

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    # 导出当前计算图的GraphDef部分，即从输入层到输出层的计算过程部分
    graph_def = tf.get_default_graph().as_graph_def()
    output_graph_def = graph_util.convert_variables_to_constants(sess,graph_def, ['add'])

    with tf.gfile.GFile("Model/combined_model.pb", 'wb') as f:
        f.write(output_graph_def.SerializeToString())
        
</code></pre> 
<p><strong>5）、载入包含变量及其取值的模型</strong></p> 
<pre><code>
import tensorflow as tf
from tensorflow.python.platform import gfile

with tf.Session() as sess:
    model_filename = "Model/combined_model.pb"
    with gfile.FastGFile(model_filename, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())

    result = tf.import_graph_def(graph_def, return_elements=["add:0"])
    print(sess.run(result))     #输出：    [array([ 3.], dtype=float32)]
    
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/974c07c0b9245a7b60fb9b3af0b17606/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">系统一键还原后发现无法激活windows解决方案</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a419de20ae5c18abbeb638da378c8d28/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">烽火HG261GS——获取超级管理员密码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>