<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CUDA流（Stream） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CUDA流（Stream）" />
<meta property="og:description" content="CUDA流表示一个GPU操作队列，该队列中的操作将以添加到流中的先后顺序而依次执行。可以将一个流看做是GPU上的一个任务，不同任务可以并行执行。使用CUDA流，首先要选择一个支持设备重叠（Device Overlap）功能的设备，支持设备重叠功能的GPU能够在执行一个CUDA核函数的同时，还能在主机和设备之间执行复制数据操作。
支持重叠功能的设备的这一特性很重要，可以在一定程度上提升GPU程序的执行效率。一般情况下，CPU内存远大于GPU内存，对于数据量比较大的情况，不可能把CPU缓冲区中的数据一次性传输给GPU，需要分块传输，如果能够在分块传输的同时，GPU也在执行核函数运算，这样的异步操作，就用到设备的重叠功能，能够提高运算性能。
以下程序演示单个流的使用步骤，对比使用流操作的性能提升，不使用流的情况：
#include &#34;cuda_runtime.h&#34; #include &lt;iostream&gt; #include &lt;stdio.h&gt; #include &lt;math.h&gt; #define N (1024*1024) #define FULL_DATA_SIZE N*20 __global__ void kernel(int* a, int *b, int*c) { int threadID = blockIdx.x * blockDim.x &#43; threadIdx.x; if (threadID &lt; N) { c[threadID] = (a[threadID] &#43; b[threadID]) / 2; } } int main() { //启动计时器 cudaEvent_t start, stop; float elapsedTime; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); cudaEventRecord(start, 0); int *host_a, *host_b, *host_c; int *dev_a, *dev_b, *dev_c; //在GPU上分配内存 cudaMalloc((void**)&amp;dev_a, FULL_DATA_SIZE * sizeof(int)); cudaMalloc((void**)&amp;dev_b, FULL_DATA_SIZE * sizeof(int)); cudaMalloc((void**)&amp;dev_c, FULL_DATA_SIZE * sizeof(int)); //在CPU上分配可分页内存 host_a = (int*)malloc(FULL_DATA_SIZE * sizeof(int)); host_b = (int*)malloc(FULL_DATA_SIZE * sizeof(int)); host_c = (int*)malloc(FULL_DATA_SIZE * sizeof(int)); //主机上的内存赋值 for (int i = 0; i &lt; FULL_DATA_SIZE; i&#43;&#43;) { host_a[i] = i; host_b[i] = FULL_DATA_SIZE - i; } //从主机到设备复制数据 cudaMemcpy(dev_a, host_a, FULL_DATA_SIZE * sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, host_b, FULL_DATA_SIZE * sizeof(int), cudaMemcpyHostToDevice); kernel &lt;&lt; &lt;FULL_DATA_SIZE / 1024, 1024 &gt;&gt; &gt; (dev_a, dev_b, dev_c); //数据拷贝回主机 cudaMemcpy(host_c, dev_c, FULL_DATA_SIZE * sizeof(int), cudaMemcpyDeviceToHost); //计时结束 cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;elapsedTime, start, stop); std::cout &lt;&lt; &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7913d1860abf5c22138094467aaf1bee/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-02-14T22:56:49+08:00" />
<meta property="article:modified_time" content="2017-02-14T22:56:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CUDA流（Stream）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="font-size:18px"><strong>CUDA流表示一个GPU操作队列，该队列中的操作将以添加到流中的先后顺序而依次执行</strong>。可以将一个流看做是GPU上的一个任务，不同任务可以并行执行。使用CUDA流，首先要选择一个支持设备重叠（Device Overlap）功能的设备，支持设备重叠功能的GPU能够在执行一个CUDA核函数的同时，还能在主机和设备之间执行复制数据操作。</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">支持重叠功能的设备的这一特性很重要，可以在一定程度上提升GPU程序的执行效率。一般情况下，CPU内存远大于GPU内存，对于数据量比较大的情况，不可能把CPU缓冲区中的数据一次性传输给GPU，需要分块传输，如果能够在分块传输的同时，GPU也在执行核函数运算，这样的异步操作，就用到设备的重叠功能，能够提高运算性能。</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">以下程序演示单个流的使用步骤，对比使用流操作的性能提升，不使用流的情况：</span></p> 
<p><span style="font-size:18px"></span></p> 
<pre><code class="language-cpp">#include "cuda_runtime.h"  
#include &lt;iostream&gt;
#include &lt;stdio.h&gt;  
#include &lt;math.h&gt;  

#define N (1024*1024)  
#define FULL_DATA_SIZE N*20  

__global__ void kernel(int* a, int *b, int*c)
{
	int threadID = blockIdx.x * blockDim.x + threadIdx.x;

	if (threadID &lt; N)
	{
		c[threadID] = (a[threadID] + b[threadID]) / 2;
	}
}

int main()
{
	//启动计时器
	cudaEvent_t start, stop;
	float elapsedTime;
	cudaEventCreate(&amp;start);
	cudaEventCreate(&amp;stop);
	cudaEventRecord(start, 0);

	int *host_a, *host_b, *host_c;
	int *dev_a, *dev_b, *dev_c;

	//在GPU上分配内存
	cudaMalloc((void**)&amp;dev_a, FULL_DATA_SIZE * sizeof(int));
	cudaMalloc((void**)&amp;dev_b, FULL_DATA_SIZE * sizeof(int));
	cudaMalloc((void**)&amp;dev_c, FULL_DATA_SIZE * sizeof(int));

	//在CPU上分配可分页内存
	host_a = (int*)malloc(FULL_DATA_SIZE * sizeof(int));
	host_b = (int*)malloc(FULL_DATA_SIZE * sizeof(int));
	host_c = (int*)malloc(FULL_DATA_SIZE * sizeof(int));

	//主机上的内存赋值
	for (int i = 0; i &lt; FULL_DATA_SIZE; i++)
	{
		host_a[i] = i;
		host_b[i] = FULL_DATA_SIZE - i;
	}

	//从主机到设备复制数据
	cudaMemcpy(dev_a, host_a, FULL_DATA_SIZE * sizeof(int), cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, host_b, FULL_DATA_SIZE * sizeof(int), cudaMemcpyHostToDevice);

	kernel &lt;&lt; &lt;FULL_DATA_SIZE / 1024, 1024 &gt;&gt; &gt; (dev_a, dev_b, dev_c);

	//数据拷贝回主机
	cudaMemcpy(host_c, dev_c, FULL_DATA_SIZE * sizeof(int), cudaMemcpyDeviceToHost);

	//计时结束
	cudaEventRecord(stop, 0);
	cudaEventSynchronize(stop);
	cudaEventElapsedTime(&amp;elapsedTime, start, stop);

	std::cout &lt;&lt; "消耗时间： " &lt;&lt; elapsedTime &lt;&lt; std::endl;

	//输出前10个结果
	for (int i = 0; i &lt; 10; i++)
	{
		std::cout &lt;&lt; host_c[i] &lt;&lt; std::endl;
	}

	getchar();

	cudaFreeHost(host_a);
	cudaFreeHost(host_b);
	cudaFreeHost(host_c);

	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);

	return 0;
}</code></pre> 
<p><br> </p> 
<p><span style="font-size:18px">使用流：</span></p> 
<p><span style="font-size:18px"></span></p> 
<pre><code class="language-cpp">#include "cuda_runtime.h"  
#include &lt;iostream&gt;
#include &lt;stdio.h&gt;  
#include &lt;math.h&gt;  

#define N (1024*1024)  
#define FULL_DATA_SIZE N*20  

__global__ void kernel(int* a, int *b, int*c)
{
	int threadID = blockIdx.x * blockDim.x + threadIdx.x;

	if (threadID &lt; N)
	{
		c[threadID] = (a[threadID] + b[threadID]) / 2;
	}
}

int main()
{
	//获取设备属性
	cudaDeviceProp prop;
	int deviceID;
	cudaGetDevice(&amp;deviceID);
	cudaGetDeviceProperties(&amp;prop, deviceID);

	//检查设备是否支持重叠功能
	if (!prop.deviceOverlap)
	{
		printf("No device will handle overlaps. so no speed up from stream.\n");
		return 0;
	}

	//启动计时器
	cudaEvent_t start, stop;
	float elapsedTime;
	cudaEventCreate(&amp;start);
	cudaEventCreate(&amp;stop);
	cudaEventRecord(start, 0);

	//创建一个CUDA流
	cudaStream_t stream;
	cudaStreamCreate(&amp;stream);

	int *host_a, *host_b, *host_c;
	int *dev_a, *dev_b, *dev_c;

	//在GPU上分配内存
	cudaMalloc((void**)&amp;dev_a, N * sizeof(int));
	cudaMalloc((void**)&amp;dev_b, N * sizeof(int));
	cudaMalloc((void**)&amp;dev_c, N * sizeof(int));

	//在CPU上分配页锁定内存
	cudaHostAlloc((void**)&amp;host_a, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault);
	cudaHostAlloc((void**)&amp;host_b, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault);
	cudaHostAlloc((void**)&amp;host_c, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault);

	//主机上的内存赋值
	for (int i = 0; i &lt; FULL_DATA_SIZE; i++)
	{
		host_a[i] = i;
		host_b[i] = FULL_DATA_SIZE - i;
	}

	for (int i = 0; i &lt; FULL_DATA_SIZE; i += N)
	{
		cudaMemcpyAsync(dev_a, host_a + i, N * sizeof(int), cudaMemcpyHostToDevice, stream);
		cudaMemcpyAsync(dev_b, host_b + i, N * sizeof(int), cudaMemcpyHostToDevice, stream);

		kernel &lt;&lt; &lt;N / 1024, 1024, 0, stream &gt;&gt; &gt; (dev_a, dev_b, dev_c);

		cudaMemcpyAsync(host_c + i, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost, stream);
	}

	// wait until gpu execution finish  
	cudaStreamSynchronize(stream);

	cudaEventRecord(stop, 0);
	cudaEventSynchronize(stop);
	cudaEventElapsedTime(&amp;elapsedTime, start, stop);

	std::cout &lt;&lt; "消耗时间： " &lt;&lt; elapsedTime &lt;&lt; std::endl;

	//输出前10个结果
	for (int i = 0; i &lt; 10; i++)
	{
		std::cout &lt;&lt; host_c[i] &lt;&lt; std::endl;
	}

	getchar();

	// free stream and mem  
	cudaFreeHost(host_a);
	cudaFreeHost(host_b);
	cudaFreeHost(host_c);

	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);

	cudaStreamDestroy(stream);
	return 0;
}</code></pre> 
<br> 
<span style="font-size:18px">首先声明一个Stream，可以把不同的操作放到Stream内，按照放入的先后顺序执行。</span> 
<p></p> 
<p><span style="font-size:18px">cudaMemcpyAsync操作只是一个请求，表示在流中执行一次内存复制操作，并不能确保cudaMemcpyAsync函数返回时已经启动了复制动作，更不能确定复制操作是否已经执行完成，可以确定的是放入流中的这个复制动作一定是在其后 放入流中的其他动作之前完成的。</span><span style="font-size:18px">使用流（同时要使用页锁定内存）和不使用流的结果一致，运算时间分别是30ms和50ms。</span></p> 
<p><span style="font-size:18px"><br> </span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/db9667109ea2ec9dff4f80955aa89c9e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">NIO-直接内存</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0bb80498bd946de49a6f6d5ba236cb37/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">mysql中char,varchar以及nchar的区别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>