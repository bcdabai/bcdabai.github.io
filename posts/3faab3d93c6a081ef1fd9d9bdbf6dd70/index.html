<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>自定义ES分词器 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="自定义ES分词器" />
<meta property="og:description" content="1 分词器的组成 ES的分词器主要由三部分组成：
（1）原始文本处理-charactor filters
对原始文本进行处理。
（2）切词-tokenizer
按照规则进行切词。
（3）单词处理-token filters
将切词获取的单词进行加工。如大小写转化，删除stopwords,增加同义词等。
2 自定义分词 下面是一个自定义分词器的案例，自定义分词器的以上三部分内容。
# custom_analyzer - 自定义分词器的名称 # char_filter - 原始文本预处理 # tokenizer - 按照指定的规则切词 # filter - 将切词后的结果进行加工 # _english_ 英文停用词，如 a,an,the PUT /test_analyzer_index_001 { &#34;settings&#34;: { &#34;analysis&#34;: { &#34;analyzer&#34;: { &#34;custom_analyzer&#34;:{ &#34;type&#34;:&#34;custom&#34;, &#34;char_filter&#34;:[&#34;emoticons&#34;], &#34;tokenizer&#34;: &#34;threeVerticalLine&#34;, &#34;filter&#34;:[&#34;english_stop&#34;] } }, &#34;char_filter&#34;: { &#34;emoticons&#34;:{ &#34;type&#34; : &#34;mapping&#34;, &#34;mappings&#34; : [ &#34;:) =&gt; _happy_&#34;, &#34;:( =&gt; _sad_&#34; ] } }, &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3faab3d93c6a081ef1fd9d9bdbf6dd70/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-25T09:11:13+08:00" />
<meta property="article:modified_time" content="2023-11-25T09:11:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">自定义ES分词器</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1 分词器的组成</h2> 
<p>ES的分词器主要由三部分组成：</p> 
<p><strong>（1）原始文本处理-charactor filters</strong></p> 
<p>对原始文本进行处理。</p> 
<p><strong>（2）切词-tokenizer</strong></p> 
<p>按照规则进行切词。</p> 
<p><strong>（3）单词处理-token filters</strong></p> 
<p>将切词获取的单词进行加工。如大小写转化，删除stopwords,增加同义词等。</p> 
<p></p> 
<h2>2 自定义分词</h2> 
<p>下面是一个自定义分词器的案例，自定义分词器的以上三部分内容。</p> 
<pre><code class="language-bash"># custom_analyzer - 自定义分词器的名称
# char_filter - 原始文本预处理
# tokenizer - 按照指定的规则切词
# filter - 将切词后的结果进行加工

# _english_ 英文停用词，如 a,an,the

PUT /test_analyzer_index_001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_analyzer":{ 
          "type":"custom", 
          "char_filter":["emoticons"],
          "tokenizer": "threeVerticalLine",
          "filter":["english_stop"]
        }
      },
      "char_filter": {
        "emoticons":{ 
          "type" : "mapping",
          "mappings" : [
            ":) =&gt; _happy_",
            ":( =&gt; _sad_"
          ]
        }
      },
      "tokenizer": {
        "threeVerticalLine":{
          "type":"pattern",
          "pattern":"(\\|\\|\\|)"
        }
      },
      "filter": {
        "english_stop":{
          "type":"stop",
          "stopwords":"_english_"
        }
      }
    }
  },
  "mappings": {
    "dynamic": "strict",
    "properties": {
      "remark": {
        "type": "text",
        "analyzer": "custom_analyzer",
        "search_analyzer": "custom_analyzer"
      }
    }
  }
}</code></pre> 
<p>analyzer 用于指定对插入ES中的数据使用的分词器</p> 
<p>search_analyzer 用于指定查询入参使用的分词器</p> 
<h2></h2> 
<h2>3 测试分词效果</h2> 
<h3>3.1 测试分词</h3> 
<pre><code class="language-bash">POST test_analyzer_index_001/_analyze
{
  "analyzer": "custom_analyzer",
  "text": "进口药品|注册证H20130650|||进口药品注册证h20130650|||h20130650_haha_a_the|||tom :)|||jack :(|||a|||an|||the"
}

或者
POST test_analyzer_index_001/_analyze
{
  "field":"remark",
  "text": "进口药品|注册证H20130650|||进口药品注册证h20130650|||h20130650_haha_a_the|||tom :)|||jack :(|||a|||an|||the"
}</code></pre> 
<p>分词结果如下所示。</p> 
<pre><code class="language-bash">{
  "tokens" : [
    {
      "token" : "进口药品|注册证H20130650",
      "start_offset" : 0,
      "end_offset" : 17,
      "type" : "word",
      "position" : 0
    },
    {
      "token" : "进口药品注册证h20130650",
      "start_offset" : 20,
      "end_offset" : 36,
      "type" : "word",
      "position" : 1
    },
    {
      "token" : "h20130650_haha_a_the",
      "start_offset" : 39,
      "end_offset" : 59,
      "type" : "word",
      "position" : 2
    },
    {
      "token" : "tom _happy_",
      "start_offset" : 62,
      "end_offset" : 68,
      "type" : "word",
      "position" : 3
    },
    {
      "token" : "jack _sad_",
      "start_offset" : 71,
      "end_offset" : 78,
      "type" : "word",
      "position" : 4
    }
  ]
}</code></pre> 
<p>由结果可知，分词时，先按照emoticons规则进行了原始文本处理，然后根据threeVerticalLine规则进行分词（即使用"|||"分词），最后根据english_stop规则对英文停用词进行去除。</p> 
<h3>3.2 测试查询</h3> 
<p>下面来测试下查询效果。</p> 
<h4>3.2.1 插入数据</h4> 
<pre><code class="language-bash">PUT /test_analyzer_index_001/_doc/1
{
  "remark": "进口药品|注册证H20130650|||进口药品注册证h20130650|||h20130650_haha_a_the|||tom :)|||jack :(|||a|||an|||the"
}</code></pre> 
<h4>3.2.2 查询所有数据</h4> 
<pre><code class="language-bash">GET /test_analyzer_index_001/_search
{
  "query": {
    "match_all": {}
  }
}</code></pre> 
<p>结果如下</p> 
<pre><code class="language-bash">{
  
    "hits" : [
      {
        "_index" : "test_analyzer_index_001",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "remark" : "进口药品|注册证H20130650|||进口药品注册证h20130650|||h20130650_haha_a_the|||tom :)|||jack :(|||a|||an|||the"
        }
      }
    ]
  }
}</code></pre> 
<h4>3.2.3 term查询</h4> 
<p>term 查询对输入不做分词，会将输入作为一个整体，到倒排索引中查找准确的词项。</p> 
<p><strong>（1）场景1-可召回插入的数据</strong></p> 
<pre><code class="language-bash">GET /test_analyzer_index_001/_search
{
  "query": {
    "term": {
      "remark": "进口药品注册证h20130650"
    }
  }
}</code></pre> 
<p><strong>（2）场景2-查询结果为空</strong></p> 
<p>以下查询结果为空，因为”进口药品|注册证H20130650|||进口药品注册证h20130650|||h20130650_haha_a_the|||tom :)|||jack :(|||a|||an|||the“在新增ES倒排索引时会进行分词，将”tom :)“转化为了”tom _happy_“，因此在倒排索引中存储的值为分词后的值：”tom _happy_“，因此使用”tom :)“查询不到数据。</p> 
<pre><code class="language-bash">GET /test_analyzer_index_001/_search
{
  "query": {
    "term": {
      "remark": "tom :)"
    }
  }
}</code></pre> 
<h4>3.2.4 match查询</h4> 
<p>match 查询对输入的查询条件进行分词，生成一个供查询的词项列表，然后每个词项逐个进行底层的查询，最终将结果进行合并。</p> 
<p><strong>（1）场景1-可召回插入的数据</strong></p> 
<p>分词后的入参为 ”进口药品|注册证H20130650“、”tom _happy_“ 和 ”jack _sad_“。</p> 
<pre><code class="language-bash">GET /test_analyzer_index_001/_search
{
  "query": {
    "match": {
      "remark": "进口药品|注册证H20130650|||tom :)|||jack :("
    }
  }
}</code></pre> 
<p><strong>（2）场景2-可召回插入的数据</strong></p> 
<p>分词后的入参为”tom _happy_“ 。</p> 
<pre><code class="language-bash">GET /test_analyzer_index_001/_search
{
  "query": {
    "match": {
      "remark": "tom :)"
    }
  }
}</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b0611e911f7dec76008d8574b4b81814/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Vue.js devtools插件：超实用的浏览器扩展，使项目更容易地调试和优化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a28eceece0e534e39696a937753ae518/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">滚雪球学Java(09-10)：Java中的Lambda运算符，你真的掌握了吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>