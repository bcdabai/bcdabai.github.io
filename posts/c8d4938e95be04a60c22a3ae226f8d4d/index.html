<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>动态实例分割SOLOv2，更快更强更精准！ - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="动态实例分割SOLOv2，更快更强更精准！" />
<meta property="og:description" content="今天跟大家分享下前天新出的论文 SOLOv2: Dynamic, Faster and Stronger，一看这名字就知道很霸气！SOLO 超越自己，在原有架构基础上引入动态卷积和发明了Matrix NMS，再次刷新COCO 实例分割数据集的最高精度（41.7 AP），而且其轻量级版本精度与Mask RCNN相近（37.1 AP vs 37.8），而速度能达到 31.3 fps（GPU V100）！
下图中红色标出的即为SOLOv2的结果：
可谓在实时轻量级和高精度两个战场都很抢眼！
该文作者信息：
论文出自沈春华老师组，作者单位澳大利亚阿德莱德大学、同济大学、字节跳动公司。
作者是在自己之前的工作SOLO基础上做的改进，所以我们有必要看看SOLO的架构：
SOLO架构
长久以来实例分割都是在目标检测给出框的情况下再进行目标mask分割，而这种思路和人类的视觉感知是不同的，人眼是可以直接定位到目标的轮廓的。SOLO的本意为 Segmenting Objects by Locations，即根据位置分割目标。
SOLO的预测头
SOLO将图像划分为SxS个网格，认为每个网格都是一个潜在的目标实例。
具体实现上，图像经过全卷积网络（FCN）后进入两个分支的预测。一个类别分支，预测每个网格所处的物体类别，每个网格对应一个C维类别向量（C为类别数），总的类别矩阵大小为S x S x C；一个mask分支预测每个网格所属的物体mask，总的mask矩阵大小为H x W x （S x S）。
请注意：mask是不关乎类别的，无论是什么物体，只要该物体落入了这个网格，mask 分支都预测它的mask。
mask分支预测得到的每个网格的mask的大小是和原图大小相等，每个网格只对应落入此网格的物体的mask。
这样来自相同位置（网格）的物体类别和相应mask就出来了，每个网格完成了单个目标实例的分割。
由于一个物体可能落在不同的相邻网格里，所以以上过程得到的肯定是多个网格含有相同的物体的mask。故最后必须进行NMS（非极大抑制），以消除重复的分割结果。
从作者的可视化图：
可以很明显的看出这个问题，NMS是必须的。
现实图片中，由于目标实例并不会很密集，所以计算SxS个网格的mask会有大量的计算冗余，作者在SOLOv1中给出的解决方案是对mask预测分支进行分解，分别为预测 x-分支和y-分支，以降低计算量和内存占用，如下图b中所示。
这样mask的预测就从S x S 个变为预测 S &#43; S 个。
作者在SOLOv2中一项重要改进是引入动态卷积。因为在mask预测时每个网格使用的特征是固定的，输出的Mask是冗余的，可以直接从网络的类别分类结果过滤掉那些不含目标的，同时使用动态卷积，也可以降低模型参数。
所谓动态滤波，即滤波核的参数是通过网络预测出来的，这样网络自适应调整的能力也增强了。
如上图中的（c）。模型在mask预测分支时动态进行卷积核学习和特征学习，最后将此二者卷积得到最终的mask。
从FPN中构造mask分支预测前的特征：
作者的另一个重要更新是发明了Matrix NMS方法。
其启发自soft NMS，soft NMS 是每次选择置信度最高的候选mask（或框）降低与其存在重叠的候选mask（或框）的置信度。这个过程是迭代的、顺序的，没法并行。
作者反其道而行之，既然是降低每个mask的置信度，那我就干脆想办法按照一定规则对所有mask挨个降低置信度。而某一候选mask j 置信度被降低，和两方面因素有关：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c8d4938e95be04a60c22a3ae226f8d4d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-03-26T23:53:01+08:00" />
<meta property="article:modified_time" content="2020-03-26T23:53:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">动态实例分割SOLOv2，更快更强更精准！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/e7/78/46ksL36X_o.png"></p> 
 <p style="text-align: left">今天跟大家分享下前天新出的论文 SOLOv2: Dynamic, Faster and Stronger，一看这名字就知道很霸气！SOLO 超越自己，在原有架构基础上引入动态卷积和发明了Matrix NMS，再次刷新COCO 实例分割数据集的最高精度（41.7 AP），而且其轻量级版本精度与Mask RCNN相近（37.1 AP vs 37.8），而速度能达到 31.3 fps（GPU V100）！</p> 
 <p style="text-align: left">下图中红色标出的即为SOLOv2的结果：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/4d/9e/Oqt0Ksfz_o.png"></p> 
 <p style="text-align: left">可谓在实时轻量级和高精度两个战场都很抢眼！<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/42/10/cXu3bYiK_o.png"></p> 
 <p style="text-align: left">该文作者信息：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a6/d4/ZWU4cX2O_o.png"></p> 
 <p style="text-align: left">论文出自沈春华老师组，作者单位澳大利亚阿德莱德大学、同济大学、字节跳动公司。</p> 
 <p style="text-align: left">作者是在自己之前的工作SOLO基础上做的改进，所以我们有必要看看SOLO的架构：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/30/10/zEo6ebzv_o.png"></p> 
 <p style="text-align: center">SOLO架构</p> 
 <p style="text-align: left">长久以来实例分割都是在目标检测给出框的情况下再进行目标mask分割，而这种思路和人类的视觉感知是不同的，人眼是可以直接定位到目标的轮廓的。SOLO的本意为 Segmenting Objects by Locations，即根据位置分割目标。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/6c/43/52YRq9yC_o.png"></p> 
 <p style="text-align: center">SOLO的预测头</p> 
 <p style="text-align: left">SOLO将图像划分为SxS个网格，认为每个网格都是一个潜在的目标实例。</p> 
 <p style="text-align: left">具体实现上，图像经过全卷积网络（FCN）后进入两个分支的预测。一个类别分支，预测每个网格所处的物体类别，每个网格对应一个C维类别向量（C为类别数），总的类别矩阵大小为S x S x C；一个mask分支预测每个网格所属的物体mask，总的mask矩阵大小为H x W x （S x S）。</p> 
 <p style="text-align: left">请注意：mask是不关乎类别的，无论是什么物体，只要该物体落入了这个网格，mask 分支都预测它的mask。</p> 
 <p style="text-align: left">mask分支预测得到的每个网格的mask的大小是和原图大小相等，每个网格只对应落入此网格的物体的mask。</p> 
 <p style="text-align: left">这样来自相同位置（网格）的物体类别和相应mask就出来了，每个网格完成了单个目标实例的分割。</p> 
 <p style="text-align: left">由于一个物体可能落在不同的相邻网格里，所以以上过程得到的肯定是多个网格含有相同的物体的mask。故最后必须进行NMS（非极大抑制），以消除重复的分割结果。<br></p> 
 <p style="text-align: left">从作者的可视化图：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/23/62/r2fq86KO_o.png"></p> 
 <p style="text-align: left">可以很明显的看出这个问题，NMS是必须的。<br></p> 
 <p style="text-align: left">现实图片中，由于目标实例并不会很密集，所以计算SxS个网格的mask会有大量的计算冗余，作者在SOLOv1中给出的解决方案是对mask预测分支进行分解，分别为预测 x-分支和y-分支，以降低计算量和内存占用，如下图b中所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/48/8b/PBV26yFd_o.png"></p> 
 <p style="text-align: left">这样mask的预测就从S x S 个变为预测 S + S 个。<br></p> 
 <p>作者在SOLOv2中一项重要改进是引入动态卷积。因为在mask预测时每个网格使用的特征是固定的，输出的Mask是冗余的，可以直接从网络的类别分类结果过滤掉那些不含目标的，同时使用动态卷积，也可以降低模型参数。<br></p> 
 <p>所谓动态滤波，即滤波核的参数是通过网络预测出来的，这样网络自适应调整的能力也增强了。</p> 
 <p>如上图中的（c）。模型在mask预测分支时动态进行卷积核学习和特征学习，最后将此二者卷积得到最终的mask。<br></p> 
 <p style="text-align: left">从FPN中构造mask分支预测前的特征：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/c9/60/Muj4p97N_o.png"></p> 
 <p style="text-align: left">作者的另一个重要更新是发明了Matrix NMS方法。</p> 
 <p style="text-align: left">其启发自soft NMS，soft NMS 是每次选择置信度最高的候选mask（或框）降低与其存在重叠的候选mask（或框）的置信度。这个过程是迭代的、顺序的，没法并行。</p> 
 <p style="text-align: left">作者反其道而行之，既然是降低每个mask的置信度，那我就干脆想办法按照一定规则对所有mask挨个降低置信度。而某一候选mask j 置信度被降低，和两方面因素有关：<br></p> 
 <p style="text-align: left">1）与其存在重叠的置信度比起其高的mask i，迫使mask j置信度衰减；<br></p> 
 <p style="text-align: left">2）mask i 本身也有一定概率置信度被其它候选mask k 降低，mask i 置信度降低的概率。</p> 
 <p style="text-align: left">当然你也可以说mask k的置信度还有可能被其他mask 迫使衰减，如果考虑到完整链条，那这个过程就复杂了，作者以上面的过程作为计算衰减因子的近似，不追求完美的数学表达。而且实际计算时仅考虑最大重叠的置信度高的mask的带来的衰减。</p> 
 <p style="text-align: left">mask i 置信度被降低的概率：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/13/c1/L8NDjc0v_o.png"></p> 
 <p style="text-align: left">mask j 置信度衰减因子：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/c1/4a/mgIGTd0J_o.png"></p> 
 <p style="text-align: left">事实证明，这样的近似已经够用了。</p> 
 <p style="text-align: left">以上每个mask置信度衰减的过程是可并行计算的，计算速度也很快。</p> 
 <p style="text-align: left">作者甚至在论文中给出了Matrix NMS的Python代码：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/d2/e8/DQufkK6A_o.png"></p> 
 <p style="text-align: left">这个Matrix NMS不仅适用于SOLO，也可以用于其他目标检测和实例分割算法需要NMS的场合中。<br></p> 
 <p style="text-align: center">实验结果</p> 
 <p style="text-align: left">作者在COCO test-dev数据集上进行了实例分割实验：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/c1/22/Skjbk3WM_o.png"></p> 
 <p style="text-align: left">SOLOv2达得了新的SOTA，使用Res-DCN-101-FPN，AP 达到41.7！比Mask RCNN 高近 4 个百分点。<br></p> 
 <p style="text-align: left">作者在生成的mask 上直接生成目标框，得到同样在COCO test-dev数据集上目标检测的结果，同样达到了主流算法水平：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/84/ef/0Ewzydk4_o.png"></p> 
 <p style="text-align: left">超越著名的单阶段目标检测器FCOS、CenterNet。<br></p> 
 <p style="text-align: left">下图为与Mask R-CNN分割结果的比较：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/dc/e8/E2Cv2cIw_o.png"></p> 
 <p style="text-align: left">可见在物体边缘上得到的结果更好。<br></p> 
 <p style="text-align: left">除了精度高，速度也是SOLOv2的一点亮点，精度与Mask R-CNN相近的SOLO-512 在V100的GPU上可达31.3 fps！<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/cf/fb/e7MyfCu4_o.png"></p> 
 <p style="text-align: left">下图为作为目标检测算法使用时，与其他算法的精度和推断时间比较的散点图：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/e2/65/2FDtGn0L_o.png"></p> 
 <p style="text-align: left">SPLOv2的几个版本在速度与其他相近时，精度大幅超越对手。从图中可见，相比经常被谈起的YOLOv3，SOLOv2 精度提升巨大。<br></p> 
 <p style="text-align: left">作者在新出的LVIS实例分割数据集上与Mask R-CNN也进行了对比：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/67/21/VRf42UAR_o.png"></p> 
 <p style="text-align: left">大多数情况下好于Mask R-CNN，平均精度更高，唯有在小目标分割上低于Mask R-CNN，这可能与网格的划分有关系（当然划分密集有助于检测到小目标，但计算代价更大）。</p> 
 <p style="text-align: left">将SOLOv2用于全景分割，在COCO val2017数据集上的结果：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/32/36/s3ePrQwg_o.png"></p> 
 <p style="text-align: left">SOLOv2取得了与之前最高精度的UPSNet相近的精度！<br></p> 
 <p style="text-align: left">精度高、速度快、代码还将开源！相信SOLO系列算法必将在实例分割、目标检测、全景分割领域留下浓墨重彩的一笔！<br></p> 
 <p style="text-align: left">论文地址：<br></p> 
 <p>https://arxiv.org/pdf/2003.10152.pdf</p> 
 <p>代码地址：</p> 
 <p>https://github.com/WXinlong/SOLO</p> 
 <p>（目前还未开源）</p> 
 <p>在我爱计算机视觉公众号后台回复“SOLO”，即可收到这两篇论文的下载。</p> 
 <p>END</p> 
 <p style="text-align: right"><img src="https://images2.imgbox.com/47/55/cvUAYbvc_o.png"></p> 
 <p><strong>备注：分割</strong></p> 
 <p><img src="https://images2.imgbox.com/e3/0b/IAbmUovr_o.png"></p> 
 <p><strong>图像分割交流群</strong></p> 
 <p>语义分割、实例分割、全景分割、抠图等技术，若已为CV君其他账号好友请直接私信。</p> 
 <p style="text-align: left">我爱计算机视觉<br></p> 
 <p>微信号 : aicvml</p> 
 <p>QQ群：805388940</p> 
 <p>微博/知乎：@我爱计算机视觉</p> 
 <p>投稿：amos@52cv.net<br></p> 
 <p>网站：www.52cv.net</p> 
 <p><img src="https://images2.imgbox.com/d0/1e/2caxFqQF_o.png"></p> 
 <p style="text-align: right">在看，让更多人看到  <img src="https://images2.imgbox.com/0b/7b/G2UqVjco_o.png"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/df65b1820d45ebb86b1ae660abd377f5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vuex state及mapState的基础用法详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ee05df81cd48d19ddb7786378f48b97f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">3.自动任务和JasperReport</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>