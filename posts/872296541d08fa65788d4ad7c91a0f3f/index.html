<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Elasticsearch 分词器切词器分析器 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Elasticsearch 分词器切词器分析器" />
<meta property="og:description" content="normalization : 文档规范化 先切词,然后规范化.
规范化要规范哪些内容?
大小写; 标点符号; 时态; 复数;
规范化主要是为了匹配更精准
character filter : 字符过滤器. 标点符号 分词之前的预处理，过滤无用字符 HTML Strip Character Filter
：html_strip
参数：escaped_tags 需要保留的html标签 Mapping Character Filter：type mapping
Pattern Replace Character Filter：type pattern_replace
&gt; normalization 通过分词器把单词分词然后规范化 查看具体分词器效果 ​```json GET _analyze { &#34;text&#34;: &#34;the computer Apple is the best Tools, Teacher&#39;s notebood&#34;, &#34;analyzer&#34;: &#34;english&#34; } GET _analyze { &#34;text&#34;: &#34;the computer Apple is the best Tools&#34;, &#34;analyzer&#34;: &#34;standard&#34; } ​``` - HTML strip 过滤html标签 - mapping 映射替换的标点符号等 - pattern Replace 正则替换 - 分词器在创建时指定 DELETE test_idx_analyzer1 PUT test_idx_analyzer1 { &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/872296541d08fa65788d4ad7c91a0f3f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-02T19:54:29+08:00" />
<meta property="article:modified_time" content="2023-07-02T19:54:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Elasticsearch 分词器切词器分析器</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="normalization___0"></a>normalization : 文档规范化</h4> 
<p>先切词,然后规范化.</p> 
<p><strong>规范化要规范哪些内容?</strong></p> 
<p>大小写; 标点符号; 时态; 复数;</p> 
<p>规范化主要是为了匹配更精准</p> 
<h4><a id="character_filter____10"></a>character filter : 字符过滤器. 标点符号</h4> 
<h4><a id="_12"></a>分词之前的预处理，过滤无用字符</h4> 
<ul><li> <p>HTML Strip Character Filter</p> <p>：html_strip</p> 
  <ul><li>参数：escaped_tags 需要保留的html标签</li></ul> </li><li> <p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-mapping-charfilter.html" rel="nofollow">Mapping Character Filter</a>：type mapping</p> </li><li> <p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-replace-charfilter.html" rel="nofollow">Pattern Replace Character Filter</a>：type pattern_replace</p> </li></ul> 
<pre><code class="prism language-json">

<span class="token operator">&gt;</span> normalization 通过分词器把单词分词然后规范化  查看具体分词器效果
​<span class="token template-string"><span class="token template-punctuation string">`</span><span class="token template-punctuation string">`</span></span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">json
GET _analyze
{
  "text": "the computer Apple is the best Tools, Teacher's notebood",
  "analyzer": "english"
}
GET _analyze
{
  "text": "the computer Apple is the best Tools",
  "analyzer": "standard"
}
​</span><span class="token template-punctuation string">`</span></span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token template-punctuation string">`</span></span>

<span class="token operator">-</span> <span class="token constant">HTML</span> strip 过滤html标签
<span class="token operator">-</span> mapping 映射替换的标点符号等
<span class="token operator">-</span> pattern Replace 正则替换
<span class="token operator">-</span> 分词器在创建时指定
<span class="token constant">DELETE</span> test_idx_analyzer1
<span class="token constant">PUT</span> test_idx_analyzer1
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"settings"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 这里是分析器 不是分词器; 分词器可以包含设置过滤器和分词器</span>
    <span class="token string-property property">"analysis"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">// 这个有四种类型具体看官方文档</span>
      <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 分词器名称</span>
        <span class="token string-property property">"test_char_filter1"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token comment">// 指定具体的类型, 具体类型看官方文档, </span>
          <span class="token string-property property">"type"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"html_strip"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token string-property property">"escaped_tags"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"a"</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string-property property">"test_analyzer1"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string-property property">"tokenizer"</span><span class="token operator">:</span> <span class="token string">"keyword"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token string">"test_char_filter1"</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
​<span class="token template-string"><span class="token template-punctuation string">`</span><span class="token template-punctuation string">`</span></span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">html
&lt;p&gt; I&amp;apos;m so &lt;a&gt;Happy&lt;/a&gt;&lt;/p&gt;
​</span><span class="token template-punctuation string">`</span></span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token template-punctuation string">`</span></span>
<span class="token constant">GET</span> test_idx_analyzer1<span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token string">"test_analyzer1"</span>
  <span class="token punctuation">,</span> <span class="token string-property property">"text"</span><span class="token operator">:</span> <span class="token string">"&lt;p&gt; I&amp;apos;m so &lt;a&gt;Happy&lt;/a&gt;&lt;/p&gt;"</span>
<span class="token punctuation">}</span>

### mapping
<span class="token constant">DELETE</span> test_idx_analyzer3
<span class="token constant">PUT</span> test_idx_analyzer3
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"settings"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 这里是分析器 不是分词器; 分词器可以包含设置过滤器和分词器</span>
    <span class="token string-property property">"analysis"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">// 这个有四种类型具体看官方文档</span>
      <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string-property property">"test_mapping_filter1"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string-property property">"type"</span><span class="token operator">:</span> <span class="token string">"mapping"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"mappings"</span><span class="token operator">:</span><span class="token punctuation">[</span>
            <span class="token string">"滚 =&gt; *"</span><span class="token punctuation">,</span>
            <span class="token string">"蛋 =&gt; x"</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string-property property">"test_analyzer2"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string-property property">"tokenizer"</span><span class="token operator">:</span> <span class="token string">"keyword"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"test_mapping_filter1"</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token constant">GET</span> test_idx_analyzer3<span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token string">"test_analyzer2"</span>
  <span class="token punctuation">,</span> <span class="token string-property property">"text"</span><span class="token operator">:</span> <span class="token string">"滚蛋球"</span>
<span class="token punctuation">}</span>

### Pattern replace


### pattern replace
<span class="token constant">DELETE</span> test_idx_analyzer3
<span class="token constant">PUT</span> test_idx_analyzer3
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"settings"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 这里是分析器 不是分词器; 分词器可以包含设置过滤器和分词器</span>
    <span class="token string-property property">"analysis"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">// 这个有四种类型具体看官方文档</span>
      <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string-property property">"test_mapping_filter1"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string-property property">"type"</span><span class="token operator">:</span> <span class="token string">"pattern_replace"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"pattern"</span><span class="token operator">:</span> <span class="token string">"(\\d{3})(\\d{4})(\\d{4})"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"replacement"</span><span class="token operator">:</span> <span class="token string">"$1***$2"</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string-property property">"test_analyzer2"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string-property property">"tokenizer"</span><span class="token operator">:</span> <span class="token string">"keyword"</span><span class="token punctuation">,</span>
          <span class="token string-property property">"char_filter"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"test_mapping_filter1"</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token constant">GET</span> test_idx_analyzer3<span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"analyzer"</span><span class="token operator">:</span> <span class="token string">"test_analyzer2"</span>
  <span class="token punctuation">,</span> <span class="token string-property property">"text"</span><span class="token operator">:</span> <span class="token string">"12345677890"</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="tokenizer___148"></a>tokenizer : 分词器</h4> 
<h5><a id="IK_150"></a>安装IK分词器</h5> 
<p>IK地址:</p> 
<p>https://github.com/medcl/elasticsearch-analysis-ik/blob/master/README.md</p> 
<h5><a id="_156"></a>分词器安装目录</h5> 
<pre><code class="prism language-shell">es_home/plugins/ik
</code></pre> 
<h5><a id="_164"></a>分词器安装方式</h5> 
<p>// 此例子可能需要安装插件, 插件安装有单独一节进行讲解见后<br> <strong>每个节点同义词文件都要同步吗?是的</strong><br> // ik每个node都要安装; 如果版本不对有两种办法</p> 
<blockquote> 
 <ol><li>手动编译安装</li><li>相近的版本可以直接修改版本</li></ol> 
</blockquote> 
<p><strong>如何手动安装？</strong></p> 
<pre><code class="prism language-json">git clone https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>medcl<span class="token operator">/</span>elasticsearch<span class="token operator">-</span>analysis<span class="token operator">-</span>ik
cd elasticsearch<span class="token operator">-</span>analysis<span class="token operator">-</span>ik
git checkout tags<span class="token operator">/</span><span class="token punctuation">{<!-- --></span>version<span class="token punctuation">}</span>
mvn clean
mvn compile
mvn <span class="token keyword">package</span>
<span class="token literal-property property">拷贝和解压release下的文件</span><span class="token operator">:</span> #<span class="token punctuation">{<!-- --></span>project_path<span class="token punctuation">}</span><span class="token operator">/</span>elasticsearch<span class="token operator">-</span>analysis<span class="token operator">-</span>ik<span class="token operator">/</span>target<span class="token operator">/</span>releases<span class="token operator">/</span>elasticsearch<span class="token operator">-</span>analysis<span class="token operator">-</span>ik<span class="token operator">-</span><span class="token operator">*</span><span class="token punctuation">.</span>zip 到你的 elasticsearch 插件目录<span class="token punctuation">,</span> <span class="token literal-property property">如</span><span class="token operator">:</span> plugins<span class="token operator">/</span>ik 重启elasticsearch

</code></pre> 
<p><strong>相近的版本可以直接修改版本</strong></p> 
<pre><code class="prism language-json">vim plugin<span class="token operator">-</span>descriptor<span class="token punctuation">.</span>properties
修改
elasticsearch<span class="token punctuation">.</span>version<span class="token operator">=</span>your_version

<span class="token operator">&gt;</span> 如果修改plugin<span class="token operator">-</span>descriptor<span class="token punctuation">.</span>properties里的版本号不行的话，还有elasticsearch<span class="token operator">-</span>analysis<span class="token operator">-</span>ik<span class="token operator">-</span>xxx<span class="token punctuation">.</span>jar内pom<span class="token punctuation">.</span>properties里的版本号。
</code></pre> 
<h5><a id="_202"></a>常见分词器</h5> 
<ul><li>standard analyzer：默认分词器，中文支持的不理想，会逐字拆分。</li><li>pattern tokenizer：以正则匹配分隔符，把文本拆分成若干词项。</li><li>simple pattern tokenizer：以正则匹配词项，速度比pattern tokenizer快。</li><li>whitespace analyzer：以空白符分隔 Tim_cookie</li></ul> 
<h4><a id="custom_analyzer_209"></a>自定义分词器：custom analyzer</h4> 
<p>char_filter：内置或自定义字符过滤器 。</p> 
<p>token filter：内置或自定义token filter 。</p> 
<p>tokenizer：内置或自定义分词器。</p> 
<h4><a id="IK_217"></a>中文分词器IK</h4> 
<p>IK分词器</p> 
<h5><a id="_221"></a>安装和部署</h5> 
<ul><li>ik下载地址：https://github.com/medcl/elasticsearch-analysis-ik</li><li>Github加速器：https://github.com/fhefh2015/Fast-GitHub</li><li>创建插件文件夹 cd your-es-root/plugins/ &amp;&amp; mkdir ik</li><li>将插件解压缩到文件夹 your-es-root/plugins/ik</li><li>重新启动es</li></ul> 
<blockquote> 
 <ol><li> <h5><a id="IK_229"></a>IK文件描述</h5> 
   <ul><li>IKAnalyzer.cfg.xml：IK分词配置文件</li></ul> </li></ol> 
 <ul><li>主词库：main.dic 
   <ul><li>英文停用词：stopword.dic，不会建立在倒排索引中</li><li>特殊词库： 
     <ul><li>quantifier.dic：特殊词库：计量单位等</li><li>suffix.dic：特殊词库：行政单位</li><li>surname.dic：特殊词库：百家姓</li><li>preposition：特殊词库：语气词</li></ul> </li><li>自定义词库：网络词汇、流行词、自造词等</li></ul> </li></ul> 
 <ol><li> <h5><a id="ikanalyzer_242"></a>ik提供的两种analyzer:</h5> 
   <ol><li>ik_max_word会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query；</li><li>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase 查询。</li></ol> </li></ol> 
</blockquote> 
<h4><a id="IK_249"></a>扩展IK词库</h4> 
<p>修改IKAnalyzer.cfg.xml中自定义词库的路径,路径原则上可以随便放,管理是跟ik放一起,建一个custome目录</p> 
<p><img src="https://images2.imgbox.com/3c/f9/bdi6VySD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="token_filter___254"></a>token filter : 令牌过滤器</h4> 
<p>停用词、时态转换、大小写转换、同义词转换、语气词处理等。比如：has=&gt;have him=&gt;he apples=&gt;apple the/oh/a=&gt;干掉</p> 
<h5><a id="_260"></a>处理大小写</h5> 
<pre><code class="prism language-shell">
// why get not PUT
// I miss the keyword _analyze,why? cannot understand better?
// this way is operate exists index to <span class="token keyword">do</span> query
GET /test_index02/_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"tokenizer"</span><span class="token builtin class-name">:</span> <span class="token string">"standard"</span>,
  <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"condition"</span>,
    <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token string">"uppercase"</span>,
    <span class="token string">"script"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token string">"source"</span><span class="token builtin class-name">:</span> <span class="token string">"token.getTerm().length() &lt; 5"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>,
  <span class="token string">"text"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"abdsfs sdf dsfdsf dsf dsfdsf sd fds fds f dsf sd f dsf sd fs df sdf dsfdsfdsfs dfdsfds"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<h5><a id="token_filter_283"></a>token_filter同义词替换</h5> 
<ul><li> <p>定义同义词词典文件 格式 <code>src1,src2 =&gt; target</code></p> </li><li> <pre><code class="prism language-shell"><span class="token function">vim</span> analysis/synonyms.txt
Mengdiudiu,mengdiudiu <span class="token operator">=</span><span class="token operator">&gt;</span> MDO
</code></pre> </li><li> <p>同步到目录 es_home/config/analysis/your_dict.txt</p> </li><li> <p>如何验证是否生效:</p> </li><li> <pre><code class="prism language-shell">DELETE test_index01
PUT /test_index01
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"settings"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"index"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token string">"analysis"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string">"test_index01_synonym"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"tokenizer"</span><span class="token builtin class-name">:</span> <span class="token string">"whitespace"</span>,
            <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span> <span class="token string">"test_index01_synonym"</span> <span class="token punctuation">]</span>
          <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>,
        <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string">"test_index01_synonym"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"synonym"</span>,
            <span class="token string">"synonyms_path"</span><span class="token builtin class-name">:</span> <span class="token string">"analysis/synonyms.txt"</span>
          <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
GET /test_index01/_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"text"</span><span class="token builtin class-name">:</span> <span class="token string">"Mengdiudiu"</span>,
  <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token string">"test_index01_synonym"</span>
<span class="token punctuation">}</span>
</code></pre> </li></ul> 
<p><strong>第二种方式</strong></p> 
<pre><code class="prism language-shell">DELETE test_index02
PUT /test_index02
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"settings"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"index"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token string">"analysis"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string">"test_index02_search_synonyms"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"tokenizer"</span><span class="token builtin class-name">:</span> <span class="token string">"whitespace"</span>,
            <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span> <span class="token string">"test_index02_graph_synonyms"</span> <span class="token punctuation">]</span>
          <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>,
        <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string">"test_index02_graph_synonyms"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"synonym_graph"</span>,
            <span class="token string">"synonyms_path"</span><span class="token builtin class-name">:</span> <span class="token string">"analysis/synonyms.txt"</span>
          <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
GET /test_index02/_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"text"</span><span class="token builtin class-name">:</span> <span class="token string">"Mengdiudiu"</span>,
  <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token string">"test_index02_search_synonyms"</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_364"></a>自定义切词器,分析器</h4> 
<pre><code class="prism language-shell">DELETE test_index03
PUT /test_index03
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"settings"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"analysis"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
      <span class="token string">"char_filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        // 自定义char_filter: 转换单词
        <span class="token string">"test_myfilter03"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"mapping"</span>,
          <span class="token string">"mappings"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"&amp; =&gt; and"</span>, <span class="token string">"| =&gt; or"</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
        // 可以定义多个char_filter,其余的是否可以定义多个可以尝试
      <span class="token punctuation">}</span>,
      <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        // 自定义过滤器: 过滤停用词
        <span class="token string">"test_mystop01"</span>:<span class="token punctuation">{<!-- --></span>
          <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"stop"</span>,
          <span class="token string">"stopwords"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"is"</span>, <span class="token string">"the"</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>,
      <span class="token string">"tokenizer"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        // 自定义切词器
        <span class="token string">"test_mytokenizer01"</span>:<span class="token punctuation">{<!-- --></span>
          <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"pattern"</span>,
          <span class="token string">"pattern"</span><span class="token builtin class-name">:</span> <span class="token string">"[.,!? ]"</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>,
      <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
        // 自定义分析器
        <span class="token string">"test_myanalyzer01"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>
          // 分词器类型,自定义
          <span class="token string">"type"</span><span class="token builtin class-name">:</span> <span class="token string">"custom"</span>,
          <span class="token string">"char_filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"test_myfilter03"</span><span class="token punctuation">]</span>,
          <span class="token string">"tokenizer"</span><span class="token builtin class-name">:</span> <span class="token string">"test_mytokenizer01"</span>,
          <span class="token string">"filter"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"test_mystop01"</span>,<span class="token string">"lowercase"</span><span class="token punctuation">]</span>
          
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
GET test_index03/_analyze
<span class="token punctuation">{<!-- --></span>
  // 使用自定义的analyzer
  <span class="token string">"analyzer"</span><span class="token builtin class-name">:</span> <span class="token string">"test_myanalyzer01"</span>,
  <span class="token string">"text"</span><span class="token builtin class-name">:</span> <span class="token string">"is,the.New? Apple! &amp; |"</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_422"></a>常用分词器</h4> 
<h4><a id="_424"></a>中文分词器</h4> 
<h4><a id="_426"></a>已定义分词器</h4> 
<h4><a id="_428"></a>词库热更新</h4> 
<p>如果每次更新词库都要重启服务这是生产环境无法忍受的.</p> 
<p>所以现在支持热更新;</p> 
<p>使用方式就是配置IK config文件的remote_ext_dict的url地址进行热更新(默认是location)</p> 
<p>具体的热更新见IK github说明</p> 
<p>https://github.com/medcl/elasticsearch-analysis-ik</p> 
<h5><a id="_442"></a>热更新的坑</h5> 
<ul><li>你本地启动的服务只是告诉es要不要更新,并不是由这个服务返回最新内容,即最终reload操作还是es node从自己本地目录去加载</li><li>node 对应的停用词文件, 分词文件必须有,理由见第一条.</li><li>停用词和分词文件目录一定要放对plugins/ik/config/custome, 一定要在ik的config内,它是相对这里的, 其他地方不生效,除非配置绝对路径</li><li>正更新流程是这样的: 修改各个node本地文件-&gt; 三方服务告诉es需要更新-&gt;es reload本地文件</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/115ab38abead2a6d84fe111a70e7009e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">leetcode-060-排列序列</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5f06f8167b7eb127edbbf1ea5dbc485e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pyqt类继承实现自定义界面类的需求</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>