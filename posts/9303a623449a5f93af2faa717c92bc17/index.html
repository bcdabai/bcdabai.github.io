<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>InfoNCE Loss公式及源码理解 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="InfoNCE Loss公式及源码理解" />
<meta property="og:description" content="InfoNCE Loss公式及源码理解–从交叉熵损失谈起 当谈论到信息论中的损失函数时，InfoNCE（Noise Contrastive Estimation）和交叉熵损失都是两个关键的概念。它们不仅在衡量概率分布之间的差异方面发挥着重要作用，而且在深度学习的自监督学习领域扮演着重要角色。虽然它们的形式和应用环境有所不同，但是我们可以发现它们之间存在着微妙的联系。
交叉熵损失作为衡量两个概率分布之间距离的指标，在分类任务和神经网络训练中广泛使用。而InfoNCE Loss，则是针对自监督学习任务中特征学习的一种损失函数。它通过比较正样本和负样本的相似性来学习模型参数，从而提高特征的区分度。
在这篇博客中，我们将深入探讨交叉熵损失和InfoNCE之间的联系，探究它们在信息论和深度学习中的联系与异同。我们将分析两者的数学形式、应用领域以及它们之间可能的内在关系，以期对这两个重要概念有更深入的理解。
InfoNCE InfoNCE Loss（Noise Contrastive Estimation Loss）是一种用于自监督学习的损失函数，通常用于学习特征表示或者表征学习。它基于信息论的思想，通过对比正样本和负样本的相似性来学习模型参数。
公式介绍 InfoNCE Loss的公式如下：
InfoNCE Loss = − 1 N ∑ i = 1 N log ⁡ ( exp ⁡ ( q i ⋅ k i &#43; τ ) ∑ j = 1 N exp ⁡ ( q i ⋅ k j − τ ) ) \text{InfoNCE Loss} = -\frac{1}{N} \sum_{i=1}^{N} \log \left( \frac{\exp \left( \frac{q_i \cdot k_{i^&#43;}}{\tau} \right)}{\sum_{j=1}^{N} \exp \left( \frac{q_i \cdot k_{j^-}}{\tau} \right)} \right) InfoNCE Loss=−N1​i=1∑N​log ​∑j=1N​exp(τqi​⋅kj−​​)exp(τqi​⋅ki&#43;​​)​ ​" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9303a623449a5f93af2faa717c92bc17/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-21T21:58:46+08:00" />
<meta property="article:modified_time" content="2023-11-21T21:58:46+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">InfoNCE Loss公式及源码理解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="InfoNCE_Loss_0"></a>InfoNCE Loss公式及源码理解–从交叉熵损失谈起</h2> 
<p>当谈论到信息论中的损失函数时，InfoNCE（Noise Contrastive Estimation）和交叉熵损失都是两个关键的概念。它们不仅在衡量概率分布之间的差异方面发挥着重要作用，而且在深度学习的自监督学习领域扮演着重要角色。虽然它们的形式和应用环境有所不同，但是我们可以发现它们之间存在着微妙的联系。</p> 
<p>交叉熵损失作为衡量两个概率分布之间距离的指标，在分类任务和神经网络训练中广泛使用。而InfoNCE Loss，则是针对自监督学习任务中特征学习的一种损失函数。它通过比较正样本和负样本的相似性来学习模型参数，从而提高特征的区分度。</p> 
<p>在这篇博客中，我们将深入探讨交叉熵损失和InfoNCE之间的联系，探究它们在信息论和深度学习中的联系与异同。我们将分析两者的数学形式、应用领域以及它们之间可能的内在关系，以期对这两个重要概念有更深入的理解。</p> 
<h3><a id="InfoNCE_7"></a>InfoNCE</h3> 
<p>InfoNCE Loss（Noise Contrastive Estimation Loss）是一种用于自监督学习的损失函数，通常用于学习特征表示或者表征学习。它基于信息论的思想，通过对比正样本和负样本的相似性来学习模型参数。</p> 
<h4><a id="_9"></a>公式介绍</h4> 
<p>InfoNCE Loss的公式如下：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          InfoNCE Loss 
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           N 
          
         
        
          log 
         
        
          ⁡ 
         
         
         
           ( 
          
          
           
           
             exp 
            
           
             ⁡ 
            
            
            
              ( 
             
             
              
               
               
                 q 
                
               
                 i 
                
               
              
                ⋅ 
               
               
               
                 k 
                
                
                
                  i 
                 
                
                  + 
                 
                
               
              
             
               τ 
              
             
            
              ) 
             
            
           
           
            
            
              ∑ 
             
             
             
               j 
              
             
               = 
              
             
               1 
              
             
            
              N 
             
            
           
             exp 
            
           
             ⁡ 
            
            
            
              ( 
             
             
              
               
               
                 q 
                
               
                 i 
                
               
              
                ⋅ 
               
               
               
                 k 
                
                
                
                  j 
                 
                
                  − 
                 
                
               
              
             
               τ 
              
             
            
              ) 
             
            
           
          
         
           ) 
          
         
        
       
         \text{InfoNCE Loss} = -\frac{1}{N} \sum_{i=1}^{N} \log \left( \frac{\exp \left( \frac{q_i \cdot k_{i^+}}{\tau} \right)}{\sum_{j=1}^{N} \exp \left( \frac{q_i \cdot k_{j^-}}{\tau} \right)} \right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord text"><span class="mord">InfoNCE Loss</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.88em; vertical-align: -1.69em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 2.05em;"><span class="" style="top: -4.05em;"><span class="pstrut" style="height: 5.6em;"></span><span class="" style="width: 0.875em; height: 3.6em;"> 
              <svg width="0.875em" height="3.600em" viewbox="0 0 875 3600"> 
               <path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1
c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,
-36,557 l0,84c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,
949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9
c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,
-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189
l0,-92c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,
-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"></path> 
              </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.55em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 2.19em;"><span class="" style="top: -2.11em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4358em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0906em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1132em;">τ</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.6045em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: -0.0359em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3448em; margin-left: -0.0315em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.6267em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8773em;"><span class="" style="top: -2.8773em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.5833em;"></span><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4207em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span></span></span><span class="" style="top: -3.38em;"><span class="pstrut" style="height: 3.15em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -4.19em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mop">exp</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9934em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1132em;">τ</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.5073em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: -0.0359em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3448em; margin-left: -0.0315em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.6267em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8773em;"><span class="" style="top: -2.8773em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.5833em;"></span><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.69em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 2.05em;"><span class="" style="top: -4.05em;"><span class="pstrut" style="height: 5.6em;"></span><span class="" style="width: 0.875em; height: 3.6em;"> 
              <svg width="0.875em" height="3.600em" viewbox="0 0 875 3600"> 
               <path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,
63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5
c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,9
c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664
c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11
c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17
c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558
l0,-144c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,
-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"></path> 
              </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.55em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span><br> 其中：</p> 
<ul><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          N 
         
        
       
         N 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span></span></span>是样本的数量</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           q 
          
         
           i 
          
         
        
       
         q_i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是查询样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的编码向量</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           k 
          
          
          
            i 
           
          
            + 
           
          
         
        
       
         k_{i+} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是与查询样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><strong>相对应的正样本</strong>的编码向量</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           k 
          
          
          
            i 
           
          
            − 
           
          
         
        
       
         k_{i-} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是与查询样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><strong>不对应的负样本</strong>的编码向量</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          τ 
         
        
       
         \tau 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span></span></span></span></span>是温度系数，用于调节相似度得分的分布，后面会详细讨论</li></ul> 
<h4><a id="_23"></a>算法思想</h4> 
<p>从INfoNCE的公式中我们可以发现，分子只包含一对正样本，分母则包含一个batch下的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
      
        N 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span></span></span>个所有样本，即1个与<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          q 
         
        
          i 
         
        
       
      
        q_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>对应的正样本和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         N 
        
       
         − 
        
       
         1 
        
       
         ) 
        
       
      
        (N-1) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>个负样本，那么上述公式我们也可以简化为下述形式：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          InfoNCE Loss 
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           N 
          
         
        
          log 
         
        
          ⁡ 
         
         
          
          
            A 
           
          
            + 
           
          
          
           
           
             A 
            
           
             + 
            
           
          
            + 
           
           
           
             B 
            
           
             − 
            
           
          
         
        
       
         \text{InfoNCE Loss} = -\frac{1}{N} \sum_{i=1}^{N} \log\frac{A_+}{A_++B_-} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord text"><span class="mord">InfoNCE Loss</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.106em; vertical-align: -1.2777em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3603em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0502em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: -0.0502em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8943em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 首先，分式部分一定是介于(0,1)之间的，而log在（0，1）之间是单增的且函数值小于0<br> 在损失优化过程中，我们希望达成的结果是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          A 
         
        
          + 
         
        
       
      
        A_+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>尽可能大，也就是正样本之间的距离尽可能尽，其实也隐含着与负样本之间的相似度尽可能低，距离尽可能远。从公式上来看，我们在最小化loss的过程中，需要让公式接近0，也就是让log内部的分式接近1，要达到这个效果，应该使<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         A 
        
       
         &gt; 
        
       
         &gt; 
        
       
         B 
        
       
      
        A&gt;&gt;B 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7224em; vertical-align: -0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0502em;">B</span></span></span></span></span>，可以发现跟我们的训练思路是吻合的，这就达到了对于查询向量而言，推近它和正样本之间的距离，拉远它和负样本的距离</p> 
<p>写到这里，基本上把InfoNCE的公式以及公式背后的主要思想讲清楚了，下面就要说Cross Entropy Loss跟它的关系了，其实主要还是InfoNCELoss代码是基于交叉熵损失实现的，看不明白交叉熵损失的代码逻辑也看不懂InfoNCELoss了</p> 
<h3><a id="Cross_Entropy_Loss_32"></a>Cross Entropy Loss</h3> 
<p>交叉熵损失是衡量两个概率分布之间差异的一种指标。在分类问题中，我们通常有一个真实的概率分布 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
      
        P 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span></span></span></span></span>（通常是一个独热编码向量，代表了样本的真实标签分布），和一个模型预测的概率分布 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Q 
        
       
      
        Q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>。交叉熵损失用于衡量这两个概率分布之间的差异。</p> 
<p>其数学公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          CrossEntropy 
         
        
          ( 
         
        
          P 
         
        
          , 
         
        
          Q 
         
        
          ) 
         
        
          = 
         
        
          − 
         
         
         
           ∑ 
          
         
           i 
          
         
        
          P 
         
        
          ( 
         
        
          i 
         
        
          ) 
         
        
          ⋅ 
         
        
          log 
         
        
          ⁡ 
         
        
          ( 
         
        
          Q 
         
        
          ( 
         
        
          i 
         
        
          ) 
         
        
          ) 
         
        
       
         \text{CrossEntropy}(P, Q) = - \sum_i P(i) \cdot \log(Q(i)) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">CrossEntropy</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.3277em; vertical-align: -1.2777em;"></span><span class="mord">−</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">))</span></span></span></span></span></span></p> 
<ul><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
        
          i 
         
        
          ) 
         
        
       
         P(i) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span> 是真实标签的概率分布，代表了样本属于类别<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的概率</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Q 
         
        
          ( 
         
        
          i 
         
        
          ) 
         
        
       
         Q(i) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span>是模型预测的概率分布，代表了模型对样本属于类别<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的预测概率</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          l 
         
        
          o 
         
        
          g 
         
        
       
         log 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span></span></span></span></span> 是自然对数函数。</li></ul> 
<p>交叉熵损失的含义和主要思想是在真实分布和模型预测分布之间衡量误差。当模型的预测与真实情况相符时，交叉熵损失会趋近于0。换句话说，交叉熵损失函数的优化目标是使得模型的预测概率分布尽可能地接近真实标签的概率分布，以最小化误差。</p> 
<p>在深度学习中，交叉熵损失通常用作分类任务中的损失函数，在训练过程中用来衡量模型预测与真实标签之间的差异，并通过反向传播来优化模型参数。</p> 
<p>结合上述解释，下面来看一下交叉熵损失的代码</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''

创建原始数据样例
x:3row x 4col的张量，表示数据中包含三条数据，每条数据预测四个类别
y:3d张量，与三条数据对应；每个元素属于0-3，与四个类别对应

'''</span>

<span class="token comment"># 1.创建原始数据</span>
x<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 2.计算x_sfm=softmax(x)，求出归一化后的每个类别概率值</span>
softmax_func<span class="token operator">=</span>nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_sfm<span class="token operator">=</span>softmax_func<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 3.计算log(x_sfm)，由于原来的概率值位于0-1，取对数后一定是负值</span>
<span class="token comment"># 概率值越大，取对数后的绝对值越小，符合我们的损失目标</span>
x_log<span class="token operator">=</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>x_sfm<span class="token punctuation">)</span>

<span class="token comment"># ls = nn.LogSoftmax(dim=1)# 也可以使用nn.LogSoftmax()进行测试，二者结果一致</span>
<span class="token comment"># print(ls(x))</span>

<span class="token comment"># 4.最后使用nn.NLLLoss求损失</span>
<span class="token comment"># 思路，按照交叉熵的计算过程，将真值与经过LogSoftmax后的预测值求和取平均</span>
index<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
loss<span class="token operator">=</span>x_log<span class="token punctuation">[</span>index<span class="token punctuation">,</span>y<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token builtin">sum</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>从代码中可以很好理解交叉熵如何发挥作用，并且也能理解交叉熵的真值标签为啥只是一维张量</p> 
<h3><a id="InfoNCE_loss__82"></a>InfoNCE loss 代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">def</span> <span class="token function">approx_infoNCE_loss</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 计算query和key的相似度得分</span>
    similarity_scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 矩阵乘法计算相似度得分</span>

    <span class="token comment"># 计算相似度得分的温度参数</span>
    temperature <span class="token operator">=</span> <span class="token number">0.07</span>

    <span class="token comment"># 计算logits</span>
    logits <span class="token operator">=</span> similarity_scores <span class="token operator">/</span> temperature

    <span class="token comment"># 构建labels（假设有N个样本）</span>
    N <span class="token operator">=</span> q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>logits<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 计算交叉熵损失</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> loss

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6f70b9d292c8031dc2d0cd339759150e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">百川2-大模型-论文笔记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d85ca299182cdfd5842527856ece2de2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Nginx采集日志的几种方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>