<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深入浅出LLamaSharp：打造智能.NET应用，不需GPU也能玩转LLaMA模型 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深入浅出LLamaSharp：打造智能.NET应用，不需GPU也能玩转LLaMA模型" />
<meta property="og:description" content="在如今的.NET社区中，机器学习和人工智能的应用越来越普遍。今天我要给大家推荐一个名叫LLamaSharp的开源项目。这是llama.cpp的C#/.NET绑定，提供了高级的API，使得我们能在本地设备上使用C#/.NET 推理LLaMA模型，并且部署它。
LLamaSharp支持在Windows、Linux和Mac上运行，无需自己编译llama.cpp。即便在没有GPU或者GPU内存不足的情况下，也能够使用LLaMA模型，这是非常让人兴奋的一点!
此外，LLamaSharp还提供了与其他项目如semantic-kernel、kernel-memory和BotSharp的集成，以提供更高层次的应用程序。
安装步骤 首先，在NuGet中安装LLamaSharp包：
PM&gt; Install-Package LLamaSharp 然后，根据您的需要安装以下后端之一：
LLamaSharp.Backend.Cpu：适用于Windows和Linux的纯CPU，以及适用于Mac的Metal。
LLamaSharp.Backend.Cuda11：适用于Windows和Linux的CUDA11。
LLamaSharp.Backend.Cuda12：适用于Windows和Linux的CUDA12。
如果这些后端都不适合您的需求，您可以自己编译llama.cpp。在这种情况下，请不要安装后端包！而是将您编译的DLL添加到您的项目中，并确保在编译项目时能够将其复制到输出目录。如果要这样做，您必须使用正确的llama.cpp提交版本，请参考下方的版本表格。
（可选）对于Microsoft semantic-kernel集成，请安装LLamaSharp.semantic-kernel包。
PM&gt; Install-Package LLamaSharp.semantic-kernel （可选）对于Microsoft kernel-memory集成，请安装LLamaSharp.kernel-memory包（这个包当前只支持net6.0）。
PM&gt; Install-Package LLamaSharp.kernel-memory 选择版本的建议 由于llama.cpp是一个变动频繁并且常有重大变更的项目，因此LLamaSharp也经常会有突破性的更改。LLamaSharp遵循语义化版本控制，并且不会在补丁版本中引入API的重大变更。
建议尽快更新到最新的补丁版本，同时也尽快更新到新的主版本。
快速开始-模型推理和聊天会话 LLamaSharp提供了两种运行推理的方式：LLamaExecutor和ChatSession。ChatSession是对executor和模型的更高级别的封装。下面是一个使用chat session的简单示例。
using LLama.Common; using LLama; string modelPath = &#34;&lt;Your model path&gt;&#34;; // 请更改为您自己的模型路径 var prompt = &#34;Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User&#39;s requests immediately and with precision." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6b2fa4db103c9d39105c76586c5ba599/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-23T08:00:21+08:00" />
<meta property="article:modified_time" content="2024-01-23T08:00:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深入浅出LLamaSharp：打造智能.NET应用，不需GPU也能玩转LLaMA模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:left;">        在如今的.NET社区中，机器学习和人工智能的应用越来越普遍。今天我要给大家推荐一个名叫<strong>LLamaSharp</strong>的开源项目。这是<strong>llama.cpp</strong>的<strong>C#/.NET</strong>绑定，提供了高级的API，使得我们能在本地设备上使用<strong>C#/.NET 推理LLaMA模型</strong>，并且部署它。</p> 
 <p style="text-align:left;">        <strong>LLamaSharp</strong>支持在Windows、Linux和Mac上运行，无需自己编译llama.cpp。<strong>即便在没有GPU或者GPU内存不足的情况下，也能够使用LLaMA模型，这是非常让人兴奋的一点!</strong></p> 
 <p style="text-align:left;">        此外，<strong>LLamaSharp</strong>还提供了与其他项目如<strong>semantic-kernel、kernel-memory</strong>和<strong>BotSharp</strong>的集成，以提供更高层次的应用程序。</p> 
 <h3><strong>安装步骤</strong></h3> 
 <p style="text-align:left;">首先，在NuGet中安装LLamaSharp包：</p> 
 <pre class="has"><code class="language-shell">PM&gt; Install-Package LLamaSharp</code></pre> 
 <p style="text-align:left;">然后，根据您的需要安装以下后端之一：</p> 
 <ul><li><p><strong>LLamaSharp.Backend.Cpu</strong>：适用于Windows和Linux的纯CPU，以及适用于Mac的Metal。</p></li><li><p><strong>LLamaSharp.Backend.Cuda11</strong>：适用于Windows和Linux的CUDA11。</p></li><li><p><strong>LLamaSharp.Backend.Cuda12</strong>：适用于Windows和Linux的CUDA12。</p></li></ul> 
 <p style="text-align:left;">如果这些后端都不适合您的需求，您可以自己编译llama.cpp。在这种情况下，请不要安装后端包！而是将您编译的DLL添加到您的项目中，并确保在编译项目时能够将其复制到输出目录。如果要这样做，您必须使用正确的llama.cpp提交版本，请参考下方的版本表格。</p> 
 <p style="text-align:left;">（可选）对于Microsoft semantic-kernel集成，请安装LLamaSharp.semantic-kernel包。</p> 
 <pre class="has"><code class="language-shell">PM&gt; Install-Package LLamaSharp.semantic-kernel</code></pre> 
 <p>（可选）对于Microsoft kernel-memory集成，请安装LLamaSharp.kernel-memory包（这个包当前只支持net6.0）。</p> 
 <pre class="has"><code class="language-shell">PM&gt; Install-Package LLamaSharp.kernel-memory</code></pre> 
 <h3><br></h3> 
 <h3><strong>选择版本的建议</strong></h3> 
 <p style="text-align:left;">        由于<strong>llama.cpp</strong>是一个变动频繁并且常有重大变更的项目，因此LLamaSharp也经常会有突破性的更改。<strong>LLamaSharp</strong>遵循语义化版本控制，并且不会在补丁版本中引入API的重大变更。</p> 
 <p style="text-align:left;">建议尽快更新到最新的补丁版本，同时也尽快更新到新的主版本。</p> 
 <h4><strong><br></strong></h4> 
 <h3><strong>快速开始-</strong><strong>模型推理和聊天会话</strong></h3> 
 <p style="text-align:left;">        LLamaSharp提供了两种运行推理的方式：<strong>LLamaExecutor和ChatSession</strong>。ChatSession是对executor和模型的更高级别的封装。下面是一个使用chat session的简单示例。</p> 
 <pre class="has"><code class="language-cs">using LLama.Common;
using LLama;


string modelPath = "&lt;Your model path&gt;"; // 请更改为您自己的模型路径
var prompt = "Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User's requests immediately and with precision.\r\n\r\nUser: Hello, Bob.\r\nBob: Hello. How may I help you today?\r\nUser: Please tell me the largest city in Europe.\r\nBob: Sure. The largest city in Europe is Moscow, the capital of Russia.\r\nUser:"; // 这里使用“chat-with-bob”提示。


// 加载模型
var parameters = new ModelParams(modelPath)
{
    ContextSize = 1024,
    Seed = 1337,
    GpuLayerCount = 5
};
using var model = LLamaWeights.LoadFromFile(parameters);


// 初始化一个聊天会话
using var context = model.CreateContext(parameters);
var ex = new InteractiveExecutor(context);
ChatSession session = new ChatSession(ex);


// 展示提示内容
Console.WriteLine();
Console.Write(prompt);


// 循环运行推理，与LLM聊天
while (prompt != "stop")
{
    await foreach (var text in session.ChatAsync(new ChatHistory.Message(AuthorRole.User, prompt), new InferenceParams { Temperature = 0.6f, AntiPrompts = [ "User:" ] }))
    {
        Console.Write(text);
    }
    prompt = Console.ReadLine() ?? "";
}


// 保存会话
session.SaveSession("SavedSessionPath");</code></pre> 
 <h4><strong><br></strong></h4> 
 <h4><strong>模型量化</strong></h4> 
 <p style="text-align:left;">以下示例展示了如何量化模型：</p> 
 <pre class="has"><code class="language-cs">string srcFilename = "&lt;Your source path&gt;";
string dstFilename = "&lt;Your destination path&gt;";
string ftype = "q4_0";
if(Quantizer.Quantize(srcFileName, dstFilename, ftype))
{
    Console.WriteLine("Quantization succeed!");
}
else
{
    Console.WriteLine("Quantization failed!");
}</code></pre> 
 <p style="text-align:left;">想了解更多使用方法，请参考示例代码。</p> 
 <h3><br></h3> 
 <h3><strong>Web API</strong></h3> 
 <p style="text-align:left;"><strong>        LLamaSharp</strong>提供了ASP.NET core集成以及一个Web应用演示。因为人手不足，如果您熟悉ASP.NET core，将非常感激你能帮助升级Web API集成。</p> 
 <h3><strong>特性</strong></h3> 
 <p style="text-align:left;">以下是项目中的特性清单：</p> 
 <p style="text-align:left;">✅ LLaMA模型推理</p> 
 <p style="text-align:left;">✅ 生成嵌入、分词和去分词 </p> 
 <p style="text-align:left;">✅ 聊天会话 </p> 
 <p style="text-align:left;">✅ 模型量化</p> 
 <p style="text-align:left;">✅ 语法 </p> 
 <p style="text-align:left;">✅ 状态保存与加载 </p> 
 <p style="text-align:left;">✅ BotSharp集成在线演示 </p> 
 <p style="text-align:left;">✅ ASP.NET core集成 </p> 
 <p style="text-align:left;">✅ Semantic-kernel集成 </p> 
 <p style="text-align:left;">🔳 微调 </p> 
 <p style="text-align:left;">✅ 本地文档搜索（由kernel-memory启用） </p> 
 <p style="text-align:left;">🔳 MAUI集成</p> 
 <h3><br></h3> 
 <h3><strong>Console示例</strong></h3> 
 <p style="text-align:left;">演示程序：demo-console</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/52/05/56wYkmPp_o.gif" alt="4d1ca4204aa01a94aa9fb609248589b9.gif"></p> 
 <h3><br></h3> 
 <h3><strong>常见问题</strong></h3> 
 <ul><li><p><strong>GPU内存不足</strong>：请尝试将n_gpu_layers设置为一个较小的数字。</p></li><li><p><strong>不支持的模型</strong>：llama.cpp正在快速开发中，经常会有重大更改。请检查模型的发布日期，并找到一个合适的LLamaSharp版本进行安装，或者自己生成gguf格式的权重。</p></li><li><p><strong>无法载入本机库</strong>：</p> 
   <ul><li><p>确保您已经安装了一个后端包。</p></li><li><p>在代码最开始处运行NativeLibraryConfig.WithLogs()以打印更多信息。</p></li></ul></li><li><p><strong>GGUF格式的模型与LLamaSharp兼容</strong>。在huggingface上搜索gguf是一个好主意，以找到一个模型。另一个选择是自己生成GGUF格式文件，请参考convert.py获取更多信息。</p></li></ul> 
 <h3><br></h3> 
 <h3><strong>贡献</strong></h3> 
 <p style="text-align:left;">        任何贡献都是受欢迎的！在LLamaSharp Dev项目中有一个TODO列表，你可以挑选一个有趣的任务开始。请阅读贡献指南了解更多信息。</p> 
 <p style="text-align:left;">        您还可以做以下事情之一，帮助社区改进LLamaSharp：</p> 
 <ul><li><p>提交功能请求。</p></li><li><p>star并分享LLamaSharp让更多人知道它。</p></li><li><p>关于LLamaSharp写博客或演示。</p></li><li><p>帮助开发Web API和UI集成。</p></li><li><p>只要打开一个问题，报告你遇到的问题！</p></li></ul> 
 <p>        最后，该项目的开源地址是：</p> 
 <pre class="has"><code class="language-javascript">https://github.com/SciSharp/LLamaSharp</code></pre> 
 <p>        大家可以去github上获取该项目更详细的信息。<br></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/310c9b7d16c2066b0962a707ef971d16/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">私有镜像仓库 Harbor 安装和使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a8815050dc12e07994f3284eda107cd3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">一个PDF处理利器的.Net开源项目</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>