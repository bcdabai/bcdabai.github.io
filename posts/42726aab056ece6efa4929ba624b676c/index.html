<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习之物体检测算法yolov3 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习之物体检测算法yolov3" />
<meta property="og:description" content="一 yolov3网络结构
首先回顾下激活函数Relu
Relu函数将输入矩阵x内所有负值都设置为0，其余值不变
在Relu的基础上，引入LeakyRelu
对比Relu，LeakyRelu将负值以一个较小斜率保留下来了
再了解上采样(upsampling)的概念
简单的说就是把图片进行放大了，图片放大一般采用内插值方法，即在原有图像像素点之间采用合适的算法插入新的元素。
对应Pytorch函数，
torch.nn.Upsample(size, # 指定输出tensor大小
scale_factor, # 输出放大的倍数
mode, # 上采样算法，‘nearest’ 最近邻点插值法，‘linear’, ‘bilinear’,’trilinear’ 线性，双线性，三线性，插值法
align_corners # 如果为True表示输出tensor和原有tensor边角是对齐相等的)
使用方式，
import torch.nn as nn
m = nn.Upsample(scaler_factor=2, model=‘bilinear’, align_corners=True)
m(input)
yolov3完整网络结构图如下，结构图来源网上
从上图可以看出，
yolo系列的模型将(卷积&#43;BN&#43;LeakyRelu激活函数)一起作为单元组件CBL
class Conv(nn.Module):
def __int__(self, c1, c2, k=1, s=1):
super(Conv, self).__int__()
self.conv = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=k, stride=s)
self.bn = nn.BatchNorm2d(num_features=c2)
self.act = nn.LeakyRelu(0.1)
def forward(self, x):
return self.act(self.bn(self.conv(x)))
yolov3借鉴Resnet的残差结构，由(2个单元组件&#43;残差)构成基础组件ResUnit
class Bottleneck(nn.Module):
def __int__(self, c1, c2, shortcut=True, e=0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/42726aab056ece6efa4929ba624b676c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-22T12:10:40+08:00" />
<meta property="article:modified_time" content="2022-10-22T12:10:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习之物体检测算法yolov3</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:.0001pt;text-align:justify;">一 yolov3网络结构</p> 
<p style="margin-left:.0001pt;text-align:justify;">首先回顾下激活函数Relu</p> 
<p style="margin-left:.0001pt;text-align:justify;">Relu函数将输入矩阵x内所有负值都设置为0，其余值不变</p> 
<p style="margin-left:.0001pt;text-align:justify;">在Relu的基础上，引入LeakyRelu</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="65" src="https://images2.imgbox.com/09/af/nPOkBl3y_o.png" width="303"></p> 
<p style="margin-left:.0001pt;text-align:justify;">对比Relu，LeakyRelu将负值以一个较小斜率保留下来了</p> 
<p style="margin-left:.0001pt;text-align:justify;">再了解上采样(upsampling)的概念</p> 
<p style="margin-left:.0001pt;text-align:justify;">简单的说就是把图片进行放大了，图片放大一般采用内插值方法，即在原有图像像素点之间采用合适的算法插入新的元素。</p> 
<p style="margin-left:.0001pt;text-align:justify;">对应Pytorch函数，</p> 
<p style="margin-left:.0001pt;text-align:justify;">torch.nn.Upsample(size, # 指定输出tensor大小</p> 
<p style="margin-left:.0001pt;text-align:justify;">scale_factor, # 输出放大的倍数</p> 
<p style="margin-left:.0001pt;text-align:justify;">mode, # 上采样算法，‘nearest’ 最近邻点插值法，‘linear’, ‘bilinear’,’trilinear’ 线性，双线性，三线性，插值法</p> 
<p style="margin-left:.0001pt;text-align:justify;">align_corners # 如果为True表示输出tensor和原有tensor边角是对齐相等的)</p> 
<p style="margin-left:.0001pt;text-align:justify;">使用方式，</p> 
<p style="margin-left:.0001pt;text-align:justify;">import torch.nn as nn</p> 
<p style="margin-left:.0001pt;text-align:justify;">m = nn.Upsample(scaler_factor=2, model=‘bilinear’, align_corners=True)</p> 
<p style="margin-left:.0001pt;text-align:justify;">m(input)</p> 
<p style="margin-left:.0001pt;text-align:justify;">yolov3完整网络结构图如下，结构图来源网上</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="228" src="https://images2.imgbox.com/68/16/cQ3Z1CpT_o.png" width="462"></p> 
<p style="margin-left:.0001pt;text-align:justify;">从上图可以看出，</p> 
<p style="margin-left:.0001pt;text-align:justify;">yolo系列的模型将(卷积+BN+LeakyRelu激活函数)一起作为<strong><strong>单元组件CBL</strong></strong></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">class</span> <span style="color:#000000;">Conv</span><span style="color:#000000;">(nn.Module):</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   def __int__(self</span><span style="color:#000000;">, c1, c2, k=1, s=1</span><span style="color:#000000;">):</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      super(</span><span style="color:#000000;">Conv</span><span style="color:#000000;">, self).__int__()</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      self.conv = nn.Conv2d(in_channels=</span><span style="color:#000000;">c1</span><span style="color:#000000;">,</span> <span style="color:#000000;">out_channels=</span><span style="color:#000000;">c</span><span style="color:#000000;">2, kernel_size=</span><span style="color:#000000;">k</span><span style="color:#000000;">, stride=</span><span style="color:#000000;">s</span><span style="color:#000000;">)</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      self.bn = nn.BatchNorm2d(num_features=</span><span style="color:#000000;">c2</span><span style="color:#000000;">)</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   self.act = nn.LeakyRelu(0.1)</span></p> 
<p style="margin-left:0pt;text-align:left;"></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   def forward(self, x):</span></p> 
<p style="margin-left:0pt;text-align:left;">      <span style="color:#000000;">return self.act(self.bn(</span><span style="color:#000000;">self.conv(x)</span><span style="color:#000000;">))</span></p> 
<p style="margin-left:.0001pt;text-align:justify;">yolov3借鉴Resnet的残差结构，由(2个单元组件+残差)构成<strong><strong>基础组件ResUnit</strong></strong></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">class</span> <span style="color:#000000;">Bottleneck</span><span style="color:#000000;">(nn.Module):</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   def __int__(self</span><span style="color:#000000;">, c1, c2, shortcut=True, e=0.5</span><span style="color:#000000;">):</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      super(</span><span style="color:#000000;">Bottleneck</span><span style="color:#000000;">, self).__int__()</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   c_ = int(c2 * e)</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      self.c</span><span style="color:#000000;">v1 = Conv(c1, c_, 1, 1)</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">      self.</span><span style="color:#000000;">cv2 = Conv(c_, c2, 3, 1)</span></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   self.shortcut = shortcut and c1==c2</span></p> 
<p style="margin-left:0pt;text-align:left;"></p> 
<p style="margin-left:0pt;text-align:left;"><span style="color:#000000;">   def forward(self, x):</span></p> 
<p style="margin-left:.0001pt;text-align:justify;">      <span style="color:#000000;">return x + self.cv2(self.cv1(x)) if self.shortcut else self.cv2(self.cv1(x)) </span></p> 
<p style="margin-left:.0001pt;text-align:justify;">注意，基础组件ResUnit的输入和输出tensor的大小不变，只是内部两个卷积计算的channels个数变动了下</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>重要组件ResX</strong></strong>包含一个(CBL单元组件+X个基础组件ResUnit)</p> 
<p style="margin-left:.0001pt;text-align:justify;">其中CBL单元组件中的卷积窗口移动步长stride为(2, 2), 因此每经过一个ResX组件，feature map大小缩小一倍，输出tensor的channels也会扩大一倍</p> 
<p style="margin-left:.0001pt;text-align:justify;">X个ResUnit首尾串联在一起</p> 
<p style="margin-left:.0001pt;text-align:justify;">再回到上图，</p> 
<p style="margin-left:.0001pt;text-align:justify;">输入图片大小为608*608，chanles为3</p> 
<p style="margin-left:.0001pt;text-align:justify;">经过第一个CBL，tensor大小为[608, 608, 32], 通过一次卷积实现channels从3到32</p> 
<p style="margin-left:.0001pt;text-align:justify;">经过Res1，tensor大小变为[304, 304, 64]</p> 
<p style="margin-left:.0001pt;text-align:justify;">经过Res2，tensor大小变为[152, 152, 128]</p> 
<p style="margin-left:.0001pt;text-align:justify;">经过Res8，tensor大小变为[76, 76, 256]</p> 
<p style="margin-left:.0001pt;text-align:justify;">到这里为止，</p> 
<p style="margin-left:.0001pt;text-align:justify;">图像的特征图大小已经由最初的608*608缩小到76*76，因此也叫<strong><strong>8倍下采样，</strong></strong>作为模型第三个输出y3的一部分</p> 
<p style="margin-left:.0001pt;text-align:justify;">再经过一个Res8，tensor大小为[38, 38, 512]</p> 
<p style="margin-left:.0001pt;text-align:justify;">图像特征图大小继续缩小一倍，也叫<strong><strong>16倍下采样，</strong></strong>作为模型第二个输出y2的一部分</p> 
<p style="margin-left:.0001pt;text-align:justify;">经过最后一个Res4，tensor大小为[19, 19, 1024]</p> 
<p style="margin-left:.0001pt;text-align:justify;">图像特征图进行了<strong><strong>32倍下采样</strong></strong>，是模型第一个输出y1的一部分</p> 
<p style="margin-left:.0001pt;text-align:justify;">可以看出的是，</p> 
<p style="margin-left:.0001pt;text-align:justify;">yolov3模型网络不存在全连接层，图像特征图的大小缩小由设置卷积参数stride实现，需要对齐大小时，采用<strong><strong>上采样Upsample</strong></strong>实现</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>Concat操作</strong></strong>作用在channels维度上，将宽和高一致的图像拼接起来</p> 
<p style="margin-left:.0001pt;text-align:justify;">模型输出y1，y2，y3的channels维度都是255，都是由前一个卷积<strong><strong>Conv</strong></strong>(如图上)将输出channels设置为255实现的</p> 
<p style="margin-left:.0001pt;text-align:justify;">前面介绍了yolov3的网络结构</p> 
<p style="margin-left:.0001pt;text-align:justify;">那么，yolov3是如何实现准确检测不同大小的物体边框呢？</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">二 Yolov3物体检测原理</p> 
<p style="margin-left:.0001pt;text-align:justify;">首先对训练数据集采用聚类算法，将物体大小聚类到K个框内，这些框称为anchor</p> 
<p style="margin-left:.0001pt;text-align:justify;">yolov3采用COCO数据集，能够检测80种不同物体，物体大小聚类到K=9个anchors</p> 
<p style="margin-left:.0001pt;text-align:justify;">以3个为一组，分别是，</p> 
<p style="margin-left:.0001pt;text-align:justify;">[10,13, 16,30, 33,23]</p> 
<p style="margin-left:.0001pt;text-align:justify;">[30,61, 62,45, 59,119]</p> 
<p style="margin-left:.0001pt;text-align:justify;">[116,90, 156,198, 373,326]</p> 
<p style="margin-left:.0001pt;text-align:justify;">这三组anchors分别分配给yolov3的三层输出y3，y2，y1</p> 
<p style="margin-left:.0001pt;text-align:justify;">即输出tensor的特征图(feature map)越小，每个网格单元(grid cell)的感受野越大，越能对应大物体的检测</p> 
<p style="margin-left:.0001pt;text-align:justify;">以y1为例，19*19为特征图大小，在三层输出中最小，对应anchors为[116,90, 156,198, 373,326]，用来检测大物体</p> 
<p style="margin-left:.0001pt;text-align:justify;">y2用来检测中等大小物体</p> 
<p style="margin-left:.0001pt;text-align:justify;">y1用来检测小物体</p> 
<p style="margin-left:.0001pt;text-align:justify;">输出中的255可以拆分为3*(4+1+80)，</p> 
<p style="margin-left:.0001pt;text-align:justify;">3表示分配给该层输出的3个anchor，每个网格单元都对应3个anchor</p> 
<p style="margin-left:.0001pt;text-align:justify;">4表示相对所在网格单元左上角坐标的偏移，包含(x, y, w, h)</p> 
<p style="margin-left:.0001pt;text-align:justify;">如何将(x, y, w, h)映射到真正的预测框(px, py, pw, ph)，并和预测图片的标签数据计算损失函数，将在下一节详细给出</p> 
<p style="margin-left:.0001pt;text-align:justify;">1表示当前预测框正好包含预测目标的置信度</p> 
<p style="margin-left:.0001pt;text-align:justify;">80表示COCO数据集80个物体的置信度</p> 
<p style="margin-left:.0001pt;text-align:justify;">yolov3 模型拥有三层输出，分别对应大中小三种物体大小的目标检测，将实际目标的中心坐标和目标的宽和高映射到每层输出的网格上，使得yolov3的输出具备预测图片上各种大小，各个位置的目标物体</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">三 Yolov3 损失函数计算</p> 
<p style="margin-left:.0001pt;text-align:justify;">首先给出训练数据的标签数据格式，每一行表示图片上的一个目标，</p> 
<p style="margin-left:.0001pt;text-align:justify;"><em><em>class </em></em><em><em>x</em></em><em><em>_center</em></em><em><em>, y_center, width, height</em></em></p> 
<p style="margin-left:.0001pt;text-align:justify;">这里x_center，y_center为目标实际中心坐标除以宽/高，取值范围为0～1</p> 
<p style="margin-left:.0001pt;text-align:justify;">width和height计算方式同上，取值范围也是0～1</p> 
<p style="margin-left:.0001pt;text-align:justify;">为了描述方便，假定训练的Batch_size为1，即每次从训练集中取一张图片输入模型进行预测，且每张图片都只有一个检测目标，并在此过程中完成一次损失函数的计算</p> 
<p style="margin-left:.0001pt;text-align:justify;">因此问题变为，给定一张图片的标签数据t，和这张图片的预测结果p，计算一次损失函数的值L</p> 
<p style="margin-left:.0001pt;text-align:justify;">L由三部分组成，</p> 
<p style="margin-left:.0001pt;text-align:justify;">lbox 计算p中预测框和t中标签物体框的差异</p> 
<p style="margin-left:.0001pt;text-align:justify;">lobj 计算p中预测框置信度和根据p中预测框与t中物体框计算的实际置信度的差异</p> 
<p style="margin-left:.0001pt;text-align:justify;">lcls 计算p中class与t中class的差异</p> 
<p style="margin-left:.0001pt;text-align:justify;">L = lbox + lobj + lcls</p> 
<p style="margin-left:.0001pt;text-align:justify;">针对模型的三层输出，损失函数值的计算是独立的</p> 
<p style="margin-left:.0001pt;text-align:justify;">为了方便描述，以第一层y1为例，</p> 
<p style="margin-left:.0001pt;text-align:justify;">预测结果为p[0]，格式为(anchors, grid, grid, xywh+conf+classes)</p> 
<p style="margin-left:.0001pt;text-align:justify;">标签t的格式为(class, x, y, w, h)</p> 
<p style="margin-left:.0001pt;text-align:justify;">ng代表网格19*19的大小，用元组来表示，为(19,19)</p> 
<p style="margin-left:.0001pt;text-align:justify;">anchor_vec表示anchor适配到当前网格上的大小，就是将原有anchor缩小32倍后的值，为[3.6,2.8], [4.875,6.18], [11.6,10.1]</p> 
<p style="margin-left:.0001pt;text-align:justify;">原有anchor为[116,90, 156,198, 373,326]</p> 
<p style="margin-left:.0001pt;text-align:justify;">将标签数据适配到当前网格的大小</p> 
<p style="margin-left:.0001pt;text-align:justify;">class = t[0]</p> 
<p style="margin-left:.0001pt;text-align:justify;">gxy = t[1:3] * ng[0]</p> 
<p style="margin-left:.0001pt;text-align:justify;">gwh = t[3:5] * ng[1]</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算标签数据中心点所在网格左上角坐标</p> 
<p style="margin-left:.0001pt;text-align:justify;">long()函数返回取整</p> 
<p style="margin-left:.0001pt;text-align:justify;">gi, gj = gxy.long()</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算标签数据中心点相对网格左上角坐标的偏移</p> 
<p style="margin-left:.0001pt;text-align:justify;">floor()函数返回数字的下舍整数</p> 
<p style="margin-left:.0001pt;text-align:justify;">gxy -= gxy.floor()</p> 
<p style="margin-left:.0001pt;text-align:justify;">得到标签数据的网格偏移坐标和映射到网格的宽高</p> 
<p style="margin-left:.0001pt;text-align:justify;">tbox = (gxy, gwh)</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算gwh和anchor_vec的最大IoU(两个面积的交集/并集)</p> 
<p style="margin-left:.0001pt;text-align:justify;">得到IoU最大值对应的anchor下标</p> 
<p style="margin-left:.0001pt;text-align:justify;">iou = wh_iou(anchor_vec, gwh)</p> 
<p style="margin-left:.0001pt;text-align:justify;">a = np.argmax(iou)</p> 
<p style="margin-left:.0001pt;text-align:justify;">根据正样本所在位置索引到预测结果值</p> 
<p style="margin-left:.0001pt;text-align:justify;">ps = p[0][a, gi, gj]</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算ps的预测框并与tbox计算GIoU, Ac为两个框的最小闭包面积</p> 
<p style="margin-left:.0001pt;text-align:justify;">clamp有将数据夹紧到某个区间的功能，这里是为了防止溢出</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="82" src="https://images2.imgbox.com/b6/a8/H7XZnOAC_o.png" width="270"></p> 
<p style="margin-left:.0001pt;text-align:justify;">pxy = torch.sigmoid(ps[0:2])</p> 
<p style="margin-left:.0001pt;text-align:justify;">pwh = torch.exp(ps[2:4]).clamp(max=1E3) * anchor_vec[a]</p> 
<p style="margin-left:.0001pt;text-align:justify;">pbox = (pxy, pwh)</p> 
<p style="margin-left:.0001pt;text-align:justify;">giou = bbox_iou(pbox, tbox, GIoU=True)</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算损失函数值的第一部分lbox</p> 
<p style="margin-left:.0001pt;text-align:justify;">lbox += (1.0 - giou)</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算损失函数的第二部分lobj</p> 
<p style="margin-left:.0001pt;text-align:justify;">pytorch中使用detarch表示返回一个新的变量，从当前计算图中分离，不计算梯度</p> 
<p style="margin-left:.0001pt;text-align:justify;">这一部分正负样本都参与了计算</p> 
<p style="margin-left:.0001pt;text-align:justify;">采用的BCEWithLogitsLoss损失函数</p> 
<p style="margin-left:.0001pt;text-align:justify;">tobj[a, gi, gj] = giou.detach().type(tobj.dtype)</p> 
<p style="margin-left:.0001pt;text-align:justify;">lobj += BCEobj(p[0][..., 4], tobj)</p> 
<p style="margin-left:.0001pt;text-align:justify;">计算损失函数的第三部分lcls</p> 
<p style="margin-left:.0001pt;text-align:justify;">设置正样本class处置信度为1</p> 
<p style="margin-left:.0001pt;text-align:justify;">也采用的BCEWithLogitsLoss损失函数</p> 
<p style="margin-left:.0001pt;text-align:justify;">t = torch.zeros_like(ps[5:])</p> 
<p style="margin-left:.0001pt;text-align:justify;">t[class] = 1.0</p> 
<p style="margin-left:.0001pt;text-align:justify;">lcls = BCEcls(ps[5:], t)</p> 
<p style="margin-left:.0001pt;text-align:justify;">到这里为止，在前面假设的训练Batch_size为1，且图片预测物体个数为1的简单情形下，损失函数值计算的全部过程已经介绍了一遍</p> 
<p style="margin-left:.0001pt;text-align:justify;">实际情形下，Batch_size的大小不会是1，上面很多变量都需要增加一个维度images，这里就不累述了</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fe38f873b27d72fc00de8a3fd729eff4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">达梦DBLINK之DM访问Oracle配置步骤</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/38d2e2ef25260306784942cda01f4ad0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">centos安装hadoop环境（编写中）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>