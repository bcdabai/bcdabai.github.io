<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【文本预处理】 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【文本预处理】" />
<meta property="og:description" content="文本预处理的核心思想是如何将文本中转化成能够训练的样本，而且通常情况下是转化成序列数据。通常有以下几个步骤：
通常英文和中文的处理会有些差别，我们分别举例讲解
处理英文文本 加载原始文本（一般我们按行来进行处理，因此一行一行的读） import collections import re from d2l import torch as d2l # 这里主要是懒得再去下载英文文章了，就直接copy的李沐老师的代码 d2l.DATA_HUB[&#39;time_machine&#39;] = (d2l.DATA_URL &#43; &#39;timemachine.txt&#39;, &#39;090b5e7e70c295757f55df93cb0a180b9691891a&#39;) def read_time_machine(): &#34;&#34;&#34;将时间机器数据集加载到文本行的列表中&#34;&#34;&#34; with open(d2l.download(&#39;time_machine&#39;), &#39;r&#39;) as f: lines = f.readlines() return [re.sub(&#39;[^A-Za-z]&#43;&#39;, &#39; &#39;, line).strip().lower() for line in lines] # 这一步是暴力将所有非英文字符全部替换并转换成小写 # 可能会有一些问题，但是无伤大雅 lines = read_time_machine() print(lines[0]) print(lines[10]) the time machine by h g wells twinkled and his usually pale face was flushed and animated the 获得每一行句子的token（可以理解为词汇表） # 这里由于是英文，都是空格分割，相对好处理，中英文的处理差别就在这儿 def tokenize(lines, token=&#39;word&#39;): &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/66f1165738eede05de9b7653809c0946/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-29T16:46:39+08:00" />
<meta property="article:modified_time" content="2022-06-29T16:46:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【文本预处理】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>  文本预处理的核心思想是如何将文本中转化成能够训练的样本，而且通常情况下是转化成序列数据。通常有以下几个步骤：</p> 
<p><strong>通常英文和中文的处理会有些差别，我们分别举例讲解</strong></p> 
<h3><a id="_4"></a>处理英文文本</h3> 
<ul><li>加载原始文本（一般我们按行来进行处理，因此一行一行的读）</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> collections
<span class="token keyword">import</span> re
<span class="token keyword">from</span> d2l <span class="token keyword">import</span> torch <span class="token keyword">as</span> d2l
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 这里主要是懒得再去下载英文文章了，就直接copy的李沐老师的代码</span>
d2l<span class="token punctuation">.</span>DATA_HUB<span class="token punctuation">[</span><span class="token string">'time_machine'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>DATA_URL <span class="token operator">+</span> <span class="token string">'timemachine.txt'</span><span class="token punctuation">,</span>
                                <span class="token string">'090b5e7e70c295757f55df93cb0a180b9691891a'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">read_time_machine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""将时间机器数据集加载到文本行的列表中"""</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'time_machine'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'[^A-Za-z]+'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
    <span class="token comment"># 这一步是暴力将所有非英文字符全部替换并转换成小写</span>
    <span class="token comment"># 可能会有一些问题，但是无伤大雅</span>

lines <span class="token operator">=</span> read_time_machine<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lines<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>lines<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>the time machine by h g wells
twinkled and his usually pale face was flushed and animated the
</code></pre> 
<ul><li>获得每一行句子的token（可以理解为词汇表）</li></ul> 
<pre><code class="prism language-python"><span class="token comment"># 这里由于是英文，都是空格分割，相对好处理，中英文的处理差别就在这儿</span>
<span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>lines<span class="token punctuation">,</span> token<span class="token operator">=</span><span class="token string">'word'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""将文本行拆分为单词或字符词元"""</span>
    <span class="token keyword">if</span> token <span class="token operator">==</span> <span class="token string">'word'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
    <span class="token keyword">elif</span> token <span class="token operator">==</span> <span class="token string">'char'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'错误：未知词元类型：'</span> <span class="token operator">+</span> token<span class="token punctuation">)</span>

tokens <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>['the', 'time', 'machine', 'by', 'h', 'g', 'wells']
[]
[]
[]
[]
['i']
[]
[]
['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']
['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']
['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']
</code></pre> 
<ul><li>构建一个字典，通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从 0 开始的数字索引中（可以理解为LabelEncoder）</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Vocab</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""文本词表"""</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_freq<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> reserved_tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># reserved_tokens主要用来保存一些特殊的符号，比如起始符、间隔符等</span>
        <span class="token keyword">if</span> reserved_tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            reserved_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        
        <span class="token comment"># 获取所有单词的词频并将其按照出现频率从高到低排序</span>
        <span class="token comment"># 这么做的原因是频率高的词索引次数也就越多，放在前面从计算机内存角度方便索引，减少复杂度</span>
        counter <span class="token operator">=</span> count_corpus<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_token_freqs <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>counter<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        
        <span class="token comment"># &lt;unk&gt; 表示空，即没有出现过的词，我们把它放在0位置</span>
        self<span class="token punctuation">.</span>idx_to_token <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> reserved_tokens
        self<span class="token punctuation">.</span>token_to_idx <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>token<span class="token punctuation">:</span> idx
                             <span class="token keyword">for</span> idx<span class="token punctuation">,</span> token <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> token<span class="token punctuation">,</span> freq <span class="token keyword">in</span> self<span class="token punctuation">.</span>_token_freqs<span class="token punctuation">:</span>
            <span class="token keyword">if</span> freq <span class="token operator">&lt;</span> min_freq<span class="token punctuation">:</span>
                <span class="token keyword">break</span>
            <span class="token keyword">if</span> token <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span>
	
	<span class="token comment"># 给定单词，查找期所对应的索引</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unk<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span>
	
	<span class="token comment"># 给定索引值，查找对应的单词</span>
    <span class="token keyword">def</span> <span class="token function">to_tokens</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>indices<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> indices<span class="token punctuation">]</span>

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">token_freqs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_token_freqs
    
    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">unk</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">0</span>

<span class="token keyword">def</span> <span class="token function">count_corpus</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""统计词元的频率"""</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> line <span class="token keyword">in</span> tokens <span class="token keyword">for</span> token <span class="token keyword">in</span> line<span class="token punctuation">]</span>
    <span class="token keyword">return</span> collections<span class="token punctuation">.</span>Counter<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">vocab <span class="token operator">=</span> Vocab<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
vocab<span class="token punctuation">.</span>to_tokens<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> vocab<span class="token punctuation">[</span><span class="token string">'the'</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code>('the', 1)
</code></pre> 
<h2><a id="_132"></a>处理中文文本</h2> 
<ul><li>处理中文文本主要是牵扯到分词，一般我们使用jieba分词</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> collections
<span class="token keyword">import</span> jieba
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">load_text</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>src<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 获取原始文本</span>
lines <span class="token operator">=</span> load_text<span class="token punctuation">(</span><span class="token string">'D:/Pytorch/mine/nlp/word2vec/data/sexy.txt'</span><span class="token punctuation">)</span>
lines<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code>'男性和女性的性观念是否存在差异？平均来看，的确存在差异：男性在性的价值取向和态度体验上更为宽容，虽然随着时代的进步这种差异会越来越小，但差别大小取决于所要测量的具体态度（Petersen &amp; Hyde，2010）。男女两性在性观念上的最大的差异是对待婚前随意性行为的态度；男性比女性更可能认为没有爱情的性也可接受。这种差异毫无疑问会影响男女两性对过去性行为的反思：女性更可能后悔自己过去的行为（如发生一夜情），而男性更可能悔不当初（如有人追求自己时没有发生性关系）。谈到随意性行为时，女性往往后悔自己的行为，而男性则后悔自己没有行动（Galperin et al.，2011）。'
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 读取停用词（即一些语气助词、特殊符号等对我们训练没用的词）</span>
stop_words <span class="token operator">=</span> load_text<span class="token punctuation">(</span><span class="token string">'D:/Pytorch/mine/nlp/word2vec/data/stop_words.txt'</span><span class="token punctuation">)</span>
stop_words<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code>['嗳', '会', '人', '使', '不', '更', '越', '都', '最']
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 使用jieba进行切词</span>
sentence_cut <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>
sentence_cut<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code>'男性 和 女性 的 性观念 是否 存在 差异 ？ 平均 来看 ， 的确 存在 差异 ： 男性 在 性 的 价值 取向 和 态度 体验 上 更为 宽容 ， 虽然 随着 时代 的 进步 这种 差异 会 越来越 小 ， 但 差别 大小 取决于 所 要 测量 的 具体 态度 （ Petersen   &amp;   Hyde ， 2010 ） 。 男女 两性 在 性观念 上 的 最大 的 差异 是 对待 婚前 随意性 行为 的 态度 ； 男性 比 女性 更 可能 认为 没有 爱情 的 性 也 可 接受 。 这种 差异 毫无疑问 会 影响 男女 两性 对 过去 性行为 的 反思 ： 女性 更 可能 后悔 自己 过去 的 行为 （ 如 发生 一夜情 ） ， 而 男性 更 可能 悔不当初 （ 如 有人 追求 自己 时 没有 发生 性关系 ） 。 谈到 随意性 行为 时 ， 女性 往往 后悔 自己 的 行为 ， 而 男性 则 后悔 自己 没有 行动 （ Galperin   et   al . ， 2011 ） 。'
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 去除停用词</span>
sentence_no_stopwords <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> sentence_cut<span class="token punctuation">]</span>
sentence_no_stopwords<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code>['男性', '女性', '性观念', '是否', '存在', '差异', '平均', '来看', '的确', '存在']
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Vocab</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""文本词表"""</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_freq<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> reserved_tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> reserved_tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            reserved_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        counter <span class="token operator">=</span> count_corpus<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_token_freqs <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>counter<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>idx_to_token <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> reserved_tokens
        self<span class="token punctuation">.</span>token_to_idx <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>token<span class="token punctuation">:</span> idx
                             <span class="token keyword">for</span> idx<span class="token punctuation">,</span> token <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> token<span class="token punctuation">,</span> freq <span class="token keyword">in</span> self<span class="token punctuation">.</span>_token_freqs<span class="token punctuation">:</span>
            <span class="token keyword">if</span> freq <span class="token operator">&lt;</span> min_freq<span class="token punctuation">:</span>
                <span class="token keyword">break</span>
            <span class="token keyword">if</span> token <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unk<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">to_tokens</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>indices<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> indices<span class="token punctuation">]</span>

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">unk</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">0</span>

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">token_freqs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_token_freqs

<span class="token keyword">def</span> <span class="token function">count_corpus</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""统计词元的频率"""</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> line <span class="token keyword">in</span> tokens <span class="token keyword">for</span> token <span class="token keyword">in</span> line<span class="token punctuation">]</span>
    <span class="token keyword">return</span> collections<span class="token punctuation">.</span>Counter<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">vocab <span class="token operator">=</span> Vocab<span class="token punctuation">(</span>sentence_no_stopwords<span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span>
</code></pre> 
<pre><code>2250
</code></pre> 
<pre><code class="prism language-python">vocab<span class="token punctuation">[</span><span class="token string">'追求'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> vocab<span class="token punctuation">.</span>to_tokens<span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>(112, '追求')
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ce265260fd05eeb155cf9deb26d5bb72/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">#define定义常量和宏，指针和结构体初了解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4884a0f7a8699a8317d412a19a64e320/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何彻底禁止win10家庭版系统自动更新-2021跟新</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>