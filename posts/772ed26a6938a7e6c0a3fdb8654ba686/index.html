<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>java提交spark submit_spark-submit提交方式测试Demo - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="java提交spark submit_spark-submit提交方式测试Demo" />
<meta property="og:description" content="写一个小小的Demo测试一下Spark提交程序的流程
Maven的pom文件
1.7
1.7
UTF-8
1.6.1
org.apache.spark
spark-core_2.10
${spark.version}
redis.clients
jedis
2.7.1
org.apache.maven.plugins
maven-compiler-plugin
1.7
1.7
org.apache.maven.plugins
maven-shade-plugin
2.4.3
package
shade
*:*
META-INF/*.SF
META-INF/*.DSA
META-INF/*.RSA
编写一个蒙特卡罗求PI的代码
importjava.util.ArrayList;importjava.util.List;importorg.apache.spark.SparkConf;importorg.apache.spark.api.java.JavaRDD;importorg.apache.spark.api.java.JavaSparkContext;importorg.apache.spark.api.java.function.Function;importorg.apache.spark.api.java.function.Function2;importredis.clients.jedis.Jedis;/*** Computes an approximation to pi
* Usage: JavaSparkPi [slices]*/
public final classJavaSparkPi {public static void main(String[] args) throwsException {
SparkConf sparkConf= new SparkConf().setAppName(&#34;JavaSparkPi&#34;)/*.setMaster(&#34;local[2]&#34;)*/;
JavaSparkContext jsc= newJavaSparkContext(sparkConf);
Jedis jedis= new Jedis(&#34;192.168.49.151&#34;,19000);int slices = (args.length == 1) ? Integer.parseInt(args[0]) : 2;int n = 100000 *slices;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/772ed26a6938a7e6c0a3fdb8654ba686/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-28T01:55:19+08:00" />
<meta property="article:modified_time" content="2021-02-28T01:55:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">java提交spark submit_spark-submit提交方式测试Demo</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>写一个小小的Demo测试一下Spark提交程序的流程</p> 
 <p>Maven的pom文件</p> 
 <p>1.7</p> 
 <p>1.7</p> 
 <p>UTF-8</p> 
 <p>1.6.1</p> 
 <p>org.apache.spark</p> 
 <p>spark-core_2.10</p> 
 <p>${spark.version}</p> 
 <p>redis.clients</p> 
 <p>jedis</p> 
 <p>2.7.1</p> 
 <p>org.apache.maven.plugins</p> 
 <p>maven-compiler-plugin</p> 
 <p>1.7</p> 
 <p>1.7</p> 
 <p>org.apache.maven.plugins</p> 
 <p>maven-shade-plugin</p> 
 <p>2.4.3</p> 
 <p>package</p> 
 <p>shade</p> 
 <p>*:*</p> 
 <p>META-INF/*.SF</p> 
 <p>META-INF/*.DSA</p> 
 <p>META-INF/*.RSA</p> 
 <p>编写一个蒙特卡罗求PI的代码</p> 
 <p>importjava.util.ArrayList;importjava.util.List;importorg.apache.spark.SparkConf;importorg.apache.spark.api.java.JavaRDD;importorg.apache.spark.api.java.JavaSparkContext;importorg.apache.spark.api.java.function.Function;importorg.apache.spark.api.java.function.Function2;importredis.clients.jedis.Jedis;/*** Computes an approximation to pi</p> 
 <p>* Usage: JavaSparkPi [slices]*/</p> 
 <p>public final classJavaSparkPi {public static void main(String[] args) throwsException {<!-- --></p> 
 <p>SparkConf sparkConf= new SparkConf().setAppName("JavaSparkPi")/*.setMaster("local[2]")*/;</p> 
 <p>JavaSparkContext jsc= newJavaSparkContext(sparkConf);</p> 
 <p>Jedis jedis= new Jedis("192.168.49.151",19000);int slices = (args.length == 1) ? Integer.parseInt(args[0]) : 2;int n = 100000 *slices;</p> 
 <p>List l = new ArrayList(n);for (int i = 0; i &lt; n; i++) {<!-- --></p> 
 <p>l.add(i);</p> 
 <p>}</p> 
 <p>JavaRDD dataSet =jsc.parallelize(l, slices);int count = dataSet.map(new Function() {<!-- --></p> 
 <p>@OverridepublicInteger call(Integer integer) {double x = Math.random() * 2 - 1;double y = Math.random() * 2 - 1;return (x * x + y * y &lt; 1) ? 1 : 0;</p> 
 <p>}</p> 
 <p>}).reduce(new Function2() {<!-- --></p> 
 <p>@OverridepublicInteger call(Integer integer, Integer integer2) {return integer +integer2;</p> 
 <p>}</p> 
 <p>});</p> 
 <p>jedis.set("Pi", String.valueOf(4.0 * count /n));</p> 
 <p>System.out.println("Pi is roughly " + 4.0 * count /n);</p> 
 <p>jsc.stop();</p> 
 <p>}</p> 
 <p>}</p> 
 <p>前提条件的setMaster("local[2]") 没有在代码中hard code</p> 
 <p>本地模式测试情况：# Run application locally on 8 cores</p> 
 <p>spark-submit \</p> 
 <p>--master local[8] \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--executor-memory 4g \</p> 
 <p>--executor-cores 4 \</p> 
 <p>/home/dinpay/test/Spark-SubmitTest.jar 100</p> 
 <p>运行结果在本地：运行在本地一起提交8个Task，不会在WebUI的8080端口上看见提交的任务</p> 
 <p align="center"><img src="https://images2.imgbox.com/c7/fe/gA0IKh4H_o.png" alt="af70b13d7f0a2a9a0e271db6b0f515aa.png"></p> 
 <p>-------------------------------------</p> 
 <p>spark-submit \</p> 
 <p>--master local[8] \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--executor-memory 8G \</p> 
 <p>--total-executor-cores 8 \</p> 
 <p>hdfs://192.168.46.163:9000/home/test/Spark-SubmitTest.jar 100</p> 
 <p>运行报错：java.lang.ClassNotFoundException: com.spark.test.JavaSparkPi</p> 
 <p>------------------------------------</p> 
 <p>spark-submit \</p> 
 <p>--master local[8] \</p> 
 <p>--deploy-mode cluster \</p> 
 <p>--supervise \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--executor-memory 8G \</p> 
 <p>--total-executor-cores 8 \</p> 
 <p>/home/dinpay/test/Spark-SubmitTest.jar 100</p> 
 <p>运行报错:Error: Cluster deploy mode is not compatible with master "local"</p> 
 <p>====================================================================</p> 
 <p>Standalone模式client模式 # Run on a Spark standalone cluster in client deploy mode</p> 
 <p>spark-submit \</p> 
 <p>--master spark://hadoop-namenode-02:7077 \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--executor-memory 8g \</p> 
 <p>--tital-executor-cores 8 \</p> 
 <p>/home/dinpay/test/Spark-SubmitTest.jar 100</p> 
 <p>运行结果如下：</p> 
 <p align="center"><img src="https://images2.imgbox.com/36/76/LcLedHiD_o.png" alt="4bff19b24a60d5bc8b1877d6de17b9c3.png"></p> 
 <p align="center"><img src="https://images2.imgbox.com/ec/1f/2ewZg6cU_o.png" alt="2c27810d4de740d233660e59c7c735f5.png"></p> 
 <p align="center"><img src="https://images2.imgbox.com/ca/bd/q6m7LfjY_o.png" alt="188ea6bba67d9c9ca3c77d5b6ef6c8cb.png"></p> 
 <p>-------------------------------------------</p> 
 <p>spark-submit \</p> 
 <p>--master spark://hadoop-namenode-02:7077 \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--executor-memory 4g \</p> 
 <p>--executor-cores 4g \</p> 
 <p>hdfs://192.168.46.163:9000/home/test/Spark-SubmitTest.jar 100</p> 
 <p>运行报错:java.lang.ClassNotFoundException: com.spark.test.JavaSparkPi</p> 
 <p>=======================================================================</p> 
 <p>standalone模式下的cluster模式 # Run on a Spark standalone cluster in cluster deploy mode with supervise</p> 
 <p>spark-submit \</p> 
 <p>--master spark://hadoop-namenode-02:7077 \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--deploy-mode cluster \</p> 
 <p>--supervise \</p> 
 <p>--executor-memory 4g \</p> 
 <p>--executor-cores 4 \</p> 
 <p>/home/dinpay/test/Spark-SubmitTest.jar 100</p> 
 <p>运行报错：java.io.FileNotFoundException: /home/dinpay/test/Spark-SubmitTest.jar (No such file or directory)</p> 
 <p>-------------------------------------------</p> 
 <p>spark-submit \</p> 
 <p>--master spark://hadoop-namenode-02:7077 \</p> 
 <p>--class com.spark.test.JavaSparkPi \</p> 
 <p>--deploy-mode cluster \</p> 
 <p>--supervise \</p> 
 <p>--driver-memory 4g \</p> 
 <p>--driver-cores 4 \</p> 
 <p>--executor-memory 2g \</p> 
 <p>--total-executor-cores 4 \</p> 
 <p>hdfs://192.168.46.163:9000/home/test/Spark-SubmitTest.jar 100</p> 
 <p>运行结果如下：</p> 
 <p align="center"><img src="https://images2.imgbox.com/d2/20/slS86pqF_o.png" alt="77637c11e66216f827ede63b58b64186.png"></p> 
 <p align="center"><img src="https://images2.imgbox.com/40/1f/1muyxPh0_o.png" alt="e40a547cf5ac2c1ed5bfad57069c3396.png"></p> 
 <p align="center"><img src="https://images2.imgbox.com/ed/36/HIojAnsj_o.png" alt="d7146b488513bb6e89c15c7669a6c433.png"></p> 
 <p>=============================================</p> 
 <p>如果代码中写定了.setMaster("local[2]");</p> 
 <p>则提交的集群模式也会运行driver，但是不会有对应的application并行运行</p> 
 <p>spark-submit --deploy-mode cluster \</p> 
 <p>--master spark://hadoop-namenode-02:6066 \</p> 
 <p>--class com.dinpay.bdp.rcp.service.Window12HzStat \</p> 
 <p>--driver-memory 2g \</p> 
 <p>--driver-cores 2 \</p> 
 <p>--executor-memory 1g \</p> 
 <p>--total-executor-cores 2 \</p> 
 <p>hdfs://192.168.46.163:9000/home/dinpay/RCP-HZ-TASK-0.0.1-SNAPSHOT.jar</p> 
 <p>如果代码中限定了.setMaster("local[2]");</p> 
 <p>则提交方式还是本地模式，会找一台worker进行本地化运行任务</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bc872ce0864d4587c0cd6b7c059daf1e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SpringMVC应用在jetty容器中启动，如何引用其他路径下的配置文件？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8b7c5538bf97020b8009f156530aa045/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java接收js excel_通过Javascript读取本地Excel文件内容的代码示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>