<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLM之幻觉（二）：大语言模型LLM幻觉缓减技术综述 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LLM之幻觉（二）：大语言模型LLM幻觉缓减技术综述" />
<meta property="og:description" content="LLM幻觉缓减技术分为两大主流，梯度方法和非梯度方法。梯度方法是指对基本LLM进行微调；而非梯度方法主要是在推理时使用Prompt工程技术。LLM幻觉缓减技术，如下图所示：
LLM幻觉缓减技术值得注意的是：
检索增强生成（RAG）知识检索（https://arxiv.org/abs/2307.03987）CoNLI（https://arxiv.org/abs/2310.03951）CoVe（https://cobusgreyling.medium.com/chain-of-verification-reduces-hallucination-in-llms-20af5ea67672） 与专注于有限任务的传统人工智能系统不同，LLM在训练过程中使用了大量的在线文本数据。当大模型语言生成功能应用在要求严格的应用程序时，LLM幻觉就变得非常令人担忧，例如：
总结医疗记录；
客户支持对话;
财务分析报告，并提供错误的法律建议。
一、幻觉缓解分类法 这项研究对LLM幻觉缓解技术进行了总结，分类为：梯度方法和非梯度方法。
梯度方法包括复杂和不透明的解码策略、知识图谱、微调策略等。
非梯度方法包括RAG、自我优化和Prompt微调。
值得注意的是，RAG方法分为四个部分；
生成之前；生成期间；生成后；端到端 Prompt工程缓解幻觉的原理在于定义：
特殊上下文&amp;；预期输出 二、最佳预防幻觉 预防幻觉的最佳方法不是单一的方法，需要综合多种方法。
缓减幻觉需要考虑以下因素：
在多大程度上依赖标签数据？
引入无监督或弱监督学习技术以提高可扩展性和灵活性的可能性是什么？
考虑梯度和非梯度方法，以产生连贯和上下文相关的信息。
收集到的缓解幻觉的工作揭示了一系列不同的策略，每种策略都有助于解决LLM中幻觉的细微差别。
通过反馈和推理的自我完善会产生有影响力的策略。
结构化比较推理引入了一种结构化的文本偏好预测方法，增强了连贯性，减少了幻觉。
监督微调可以通过知识注入和师生方法进行探索。
特定领域的知识被注入到较弱的LLM和使用反事实数据集来提高真实性的方法中。
参考文献： [1] https://cobusgreyling.medium.com/large-language-model-hallucination-mitigation-techniques-a75b6f873318" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/a6bf77117240b600c7cd25c619e2d96d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-15T17:26:56+08:00" />
<meta property="article:modified_time" content="2024-01-15T17:26:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLM之幻觉（二）：大语言模型LLM幻觉缓减技术综述</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p class="img-center"><img alt="" height="556" src="https://images2.imgbox.com/80/b7/vLrexLfJ_o.png" width="1080"></p> 
<p>       LLM幻觉缓减技术分为两大主流，<strong>梯度方法</strong>和<strong>非梯度方法</strong>。梯度方法是指对基本LLM进行微调；而非梯度方法主要是在推理时使用Prompt工程技术。LLM幻觉缓减技术，如下图所示：</p> 
<p></p> 
<p class="img-center"><img alt="" height="722" src="https://images2.imgbox.com/28/9a/9haOyg09_o.jpg" width="1080"></p> 
<p><strong>LLM幻觉缓减技术值得注意的是：</strong></p> 
<ul><li>检索增强生成（RAG）</li><li>知识检索（https://arxiv.org/abs/2307.03987）</li><li>CoNLI（https://arxiv.org/abs/2310.03951）</li><li>CoVe（https://cobusgreyling.medium.com/chain-of-verification-reduces-hallucination-in-llms-20af5ea67672）</li></ul> 
<p>      与专注于有限任务的传统人工智能系统不同，LLM在训练过程中使用了大量的在线文本数据。当大模型语言生成功能应用在要求严格的应用程序时，LLM幻觉就变得非常令人担忧，例如：</p> 
<ol><li> <p>总结医疗记录；</p> </li><li> <p>客户支持对话;</p> </li><li> <p>财务分析报告，并提供错误的法律建议。</p> </li></ol> 
<h2><strong>一、幻觉缓解分类法</strong></h2> 
<p>       这项研究对LLM幻觉缓解技术进行了总结，分类为：<strong>梯度方法</strong>和<strong>非梯度方法</strong>。</p> 
<p><strong>梯度方法</strong>包括<strong>复杂和不透明的解码策略</strong>、<strong>知识图谱</strong>、<strong>微调策略</strong>等。</p> 
<p><strong>非梯度方法</strong>包括<strong>RAG</strong>、<strong>自我优化</strong>和<strong>Prompt微调</strong>。</p> 
<p>值得注意的是，RAG方法分为四个部分；</p> 
<ul><li>生成之前；</li><li>生成期间；</li><li>生成后；</li><li>端到端</li></ul> 
<p>Prompt工程缓解幻觉的原理在于定义：</p> 
<ul><li>特殊上下文&amp;；</li><li>预期输出</li></ul> 
<h2><strong>二、最佳预防幻觉</strong></h2> 
<p>预防幻觉的最佳方法不是单一的方法，需要综合多种方法。</p> 
<p><strong>缓减幻觉需要考虑以下因素：</strong></p> 
<ol><li> <p>在多大程度上依赖标签数据？</p> </li><li> <p>引入无监督或弱监督学习技术以提高可扩展性和灵活性的可能性是什么？</p> </li><li> <p>考虑梯度和非梯度方法，以产生连贯和上下文相关的信息。</p> </li><li> <p>收集到的缓解幻觉的工作揭示了一系列不同的策略，每种策略都有助于解决LLM中幻觉的细微差别。</p> </li><li> <p>通过反馈和推理的自我完善会产生有影响力的策略。</p> </li><li> <p>结构化比较推理引入了一种结构化的文本偏好预测方法，增强了连贯性，减少了幻觉。</p> </li><li> <p>监督微调可以通过知识注入和师生方法进行探索。</p> </li><li> <p>特定领域的知识被注入到较弱的LLM和使用反事实数据集来提高真实性的方法中。</p> </li></ol> 
<h2><strong>参考文献：</strong></h2> 
<p>[1] https://cobusgreyling.medium.com/large-language-model-hallucination-mitigation-techniques-a75b6f873318</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1ace1738c41f98b71f35216ab9c74799/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">uniapp使用camera完成指定区域大小扫描拍照功能--自定义拍照区域，相册选择剪裁 打开闪光灯</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fb6d210b330c687dc46208be446f6dfd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【FPGA &amp; Modsim】数字频率计</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>