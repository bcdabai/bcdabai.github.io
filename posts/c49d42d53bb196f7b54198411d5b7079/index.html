<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多页爬取数据 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多页爬取数据" />
<meta property="og:description" content="BeautifulSoup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，BeautifulSoup就不能自动识别编码方式。这时，你只需要说明一下原始编码方式就ok。参数用lxml就可以，需要另行安装并载入。BeautifulSoup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。
爬取一网站多个网页数据：
from bs4 import BeautifulSoup import requests import lxml import time url=&#39;https://www.tripadvisor.cn/Attractions-g60763-Activities-New_York_City_New_York.html&#39; urls = [&#39;https://www.tripadvisor.cn/Attractions-g60763-Activities-oa{}-New_York_City_New_York.html#ATTRACTION_LIST&#39;.format(str(i)) for i in range(30,1110,30)] def get_attractions(url): web_data = requests.get(url) time.sleep(2) soup = BeautifulSoup(web_data.text,&#39;lxml&#39;) imgs = soup.select(&#39;img[width=&#34;180&#34;]&#39;) titles = soup.select(&#39;#ATTR_ENTRY_ &gt; div.attraction_clarity_cell &gt; div &gt; div &gt; div.listing_info &gt; div.listing_title &gt; a&#39;) scores = soup.select(&#39;#ATTR_ENTRY_ &gt; div.attraction_clarity_cell &gt; div &gt; div &gt; div.listing_info &gt; div.listing_rating &gt; div &gt; div &gt; span[alt]&#39;) comments = soup.select(&#39;#ATTR_ENTRY_ &gt; div." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c49d42d53bb196f7b54198411d5b7079/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-07-30T12:33:40+08:00" />
<meta property="article:modified_time" content="2017-07-30T12:33:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多页爬取数据</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>BeautifulSoup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，BeautifulSoup就不能自动识别编码方式。这时，你只需要说明一下原始编码方式就ok。参数用lxml就可以，需要另行安装并载入。BeautifulSoup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。</p> 
<hr> 
<p>爬取一网站多个网页数据：</p> 
<pre class="prettyprint"><code class="language-Python hljs python"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> lxml
<span class="hljs-keyword">import</span> time
url=<span class="hljs-string">'https://www.tripadvisor.cn/Attractions-g60763-Activities-New_York_City_New_York.html'</span>
urls = [<span class="hljs-string">'https://www.tripadvisor.cn/Attractions-g60763-Activities-oa{}-New_York_City_New_York.html#ATTRACTION_LIST'</span>.format(str(i)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>,<span class="hljs-number">1110</span>,<span class="hljs-number">30</span>)]  
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_attractions</span><span class="hljs-params">(url)</span>:</span>
    web_data = requests.get(url)
    time.sleep(<span class="hljs-number">2</span>)
    soup = BeautifulSoup(web_data.text,<span class="hljs-string">'lxml'</span>)
    imgs = soup.select(<span class="hljs-string">'img[width="180"]'</span>)
    titles = soup.select(<span class="hljs-string">'#ATTR_ENTRY_ &gt; div.attraction_clarity_cell &gt; div &gt; div &gt; div.listing_info &gt; div.listing_title &gt; a'</span>)
    scores = soup.select(<span class="hljs-string">'#ATTR_ENTRY_ &gt; div.attraction_clarity_cell &gt; div &gt; div &gt; div.listing_info &gt; div.listing_rating &gt; div &gt; div &gt; span[alt]'</span>)
    comments = soup.select(<span class="hljs-string">'#ATTR_ENTRY_ &gt; div.attraction_clarity_cell &gt; div &gt; div &gt; div.listing_info &gt; div.listing_rating &gt; div &gt; div &gt; span.more &gt; a'</span>)
    cates = soup.select(<span class="hljs-string">'div.p13n_reasoning_v2'</span>)
    <span class="hljs-keyword">for</span> img,title,score,comment,cate <span class="hljs-keyword">in</span> zip(imgs,titles,scores,comments,cates):
        data = {
                <span class="hljs-string">'img'</span>:img.get(<span class="hljs-string">'src'</span>),
                <span class="hljs-string">'title'</span>:title.get_text(),
                <span class="hljs-string">'score'</span>:score.get(<span class="hljs-string">'alt'</span>),
                <span class="hljs-string">'comment'</span>:comment.get_text(),
                <span class="hljs-string">'cate'</span>:list(cate.stripped_strings)          
                }
        print(data)
<span class="hljs-keyword">for</span> single_url <span class="hljs-keyword">in</span> urls:
    get_attractions(single_url)</code></pre> 
<p>爬取数据如下</p> 
<p><img src="https://images2.imgbox.com/3d/10/YLOLddU2_o.jpg" alt="爬取数据如下" title=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/385d962b99f7e7dcef1c56d8024f93fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">VMware vSphere Web Services SDK编程指南（四）- vSphere API 编程模型（一）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9a3472e830b3c8b2a450f9f0e1840eff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">podspec 简单用法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>