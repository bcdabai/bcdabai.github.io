<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch 中所有样本对的余弦相似度快速计算 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch 中所有样本对的余弦相似度快速计算" />
<meta property="og:description" content="PyTorch 定义了 cosine_similarity 函数来计算向量对之间的余弦相似度。但是，目前还没有方法可以计算列表中每对向量之间的余弦相似度。我们将探索一种非常简单且有效的方法来在 PyTorch 中执行此操作。
我们先来看一个公式，这是计算余弦相似度的数学计算公式：
cosine similarity = S C ( A , B ) : = cos ⁡ ( θ ) = A ⋅ B ∥ A ∥ ∥ B ∥ = ∑ i = 1 n A i B i ∑ i = 1 n A i 2 ∑ i = 1 n B i 2 \text{cosine similarity}=S_C(A,B):=\cos(\theta)=\frac{\mathbf{A}\cdot\mathbf{B}}{\|\mathbf{A}\|\|\mathbf{B}\|}=\frac{\sum_{i=1}^nA_iB_i}{\sqrt{\sum_{i=1}^nA_i^2}\sqrt{\sum_{i=1}^nB_i^2}} cosine similarity=SC​(A,B):=cos(θ)=∥A∥∥B∥A⋅B​=∑i=1n​Ai2​ ​∑i=1n​Bi2​ ​∑i=1n​Ai​Bi​​
现在开始系统介绍如何在pytorch中高效计算多对向量之间的余弦相似度（多对向量组成矩阵形式，这在对比学习中经常使用到）
介绍 来自维基百科:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/f5e2acaf5b6276272a0c026982c536e2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-17T11:34:14+08:00" />
<meta property="article:modified_time" content="2023-10-17T11:34:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch 中所有样本对的余弦相似度快速计算</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>  PyTorch 定义了 cosine_similarity 函数来计算向量对之间的余弦相似度。但是，目前还没有方法可以计算列表中每对向量之间的余弦相似度。我们将探索一种非常简单且有效的方法来在 PyTorch 中执行此操作。</p> 
<p>  我们先来看一个公式，这是计算余弦相似度的数学计算公式：<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         cosine similarity 
        
       
         = 
        
        
        
          S 
         
        
          C 
         
        
       
         ( 
        
       
         A 
        
       
         , 
        
       
         B 
        
       
         ) 
        
       
         : 
        
       
         = 
        
       
         cos 
        
       
         ⁡ 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
         = 
        
        
         
         
           A 
          
         
           ⋅ 
          
         
           B 
          
         
         
         
           ∥ 
          
         
           A 
          
         
           ∥ 
          
         
           ∥ 
          
         
           B 
          
         
           ∥ 
          
         
        
       
         = 
        
        
         
          
          
            ∑ 
           
           
           
             i 
            
           
             = 
            
           
             1 
            
           
          
            n 
           
          
          
          
            A 
           
          
            i 
           
          
          
          
            B 
           
          
            i 
           
          
         
         
          
           
            
            
              ∑ 
             
             
             
               i 
              
             
               = 
              
             
               1 
              
             
            
              n 
             
            
            
            
              A 
             
            
              i 
             
            
              2 
             
            
           
          
          
           
            
            
              ∑ 
             
             
             
               i 
              
             
               = 
              
             
               1 
              
             
            
              n 
             
            
            
            
              B 
             
            
              i 
             
            
              2 
             
            
           
          
         
        
       
      
        \text{cosine similarity}=S_C(A,B):=\cos(\theta)=\frac{\mathbf{A}\cdot\mathbf{B}}{\|\mathbf{A}\|\|\mathbf{B}\|}=\frac{\sum_{i=1}^nA_iB_i}{\sqrt{\sum_{i=1}^nA_i^2}\sqrt{\sum_{i=1}^nB_i^2}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord text"><span class="mord">cosine similarity</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0502em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.3943em; vertical-align: -0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8743em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∥</span><span class="mord mathbf mtight">A</span><span class="mord mtight">∥∥</span><span class="mord mathbf mtight">B</span><span class="mord mtight">∥</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">A</span><span class="mbin mtight">⋅</span><span class="mord mathbf mtight">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.52em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.8896em; vertical-align: -0.8296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.06em;"><span class="" style="top: -2.4702em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0283em;"><span class="svg-align" style="top: -3.4286em;"><span class="pstrut" style="height: 3.4286em;"></span><span class="mord mtight" style="padding-left: 1.19em;"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7047em;"><span class="" style="top: -2.1786em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -2.8971em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3214em;"><span class=""></span></span></span></span></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8051em;"><span class="" style="top: -2.1777em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -2.8448em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3223em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -3.0003em;"><span class="pstrut" style="height: 3.4286em;"></span><span class="hide-tail mtight" style="min-width: 0.853em; height: 1.5429em;"> 
                   <svg width="400em" height="1.5429em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
                    <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
                   </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4282em;"><span class=""></span></span></span></span></span><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0283em;"><span class="svg-align" style="top: -3.4286em;"><span class="pstrut" style="height: 3.4286em;"></span><span class="mord mtight" style="padding-left: 1.19em;"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7047em;"><span class="" style="top: -2.1786em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -2.8971em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3214em;"><span class=""></span></span></span></span></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0502em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8051em;"><span class="" style="top: -2.1777em; margin-left: -0.0502em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -2.8448em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3223em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -3.0003em;"><span class="pstrut" style="height: 3.4286em;"></span><span class="hide-tail mtight" style="min-width: 0.853em; height: 1.5429em;"> 
                   <svg width="400em" height="1.5429em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
                    <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
                   </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4282em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.535em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7385em;"><span class="" style="top: -2.1786em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -2.931em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3214em;"><span class=""></span></span></span></span></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0502em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: -0.0502em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8296em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><br> 现在开始系统介绍如何在pytorch中高效计算多对向量之间的余弦相似度（多对向量组成矩阵形式，这在对比学习中经常使用到）</p> 
<h3><a id="_5"></a>介绍</h3> 
<p>  来自维基百科:</p> 
<blockquote> 
 <p>在数据分析中，余弦相似度是在内积空间中定义的两个非零向量之间的相似度的度量。余弦相似度是向量之间角度的余弦；也就是说，它是向量的点积除以向量长度的乘积。由此可见，余弦相似度不取决于向量的大小，而仅取决于它们的角度。余弦相似度始终属于区间 [−1,1]。</p> 
</blockquote> 
<p>  用于余弦相似度的 PyTorch API</p> 
<blockquote> 
 <p>torch.nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8) -&gt; Tensor</p> 
</blockquote> 
<p>  这将计算 x1 和 x2 之间沿指定维度的成对余弦相似度。即，如果 x1 和 x2 的形状均为 (10, 4, 5)，并且我们希望计算沿最后一个维度的余弦相似度，则结果形状为(10, 4)。<br> 例如：</p> 
<pre><code class="prism language-python">x<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>F<span class="token punctuation">.</span>cosine_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#torch.Size([10, 4])</span>
</code></pre> 
<p>  这是因为当我们向 cosine_similarity 提供一个 3d 张量并要求它在第三维（维度索引=2）上运行余弦相似度时，它会将该索引折叠为单个值。</p> 
<h3><a id="_PyTorch__22"></a>在 PyTorch 中计算所有对的余弦相似度</h3> 
<p>  互联网现有的查询结果表明，人们一直很难找到一种简洁有效的方法来执行全对余弦相似性运算。事实上，这个问题被认为非常复杂，以至于torchmetrics 页面上有一个专门针对该主题的指标。<br>   幸运的是，这个问题有一个可行解决方案（<a href="https://github.com/pytorch/pytorch/issues/48306">此 PyTorch GitHub 问题中提到了</a>)。让我们一起先看看它长什么样子吧！<br> <code>cosine_similarity(x[None,:,:], x[:,None,:], dim=-1)</code><br>   里面发生了很多事情，而且它的真正工作原理可能并不明显，因此本文的其余部分将重点通过从头开始构建解决方案来剖析这个方法的各个子部分到底发生了什么。在下面的小节中，我们将了解以下内容，因为它适用于简洁地计算所有对余弦相似度。</p> 
<ol><li>用“None”索引张量</li><li>使用tensor.expand()沿单维展开张量</li><li>利用 PyTorch 广播语义沿单维隐式扩展张量</li></ol> 
<h4><a id="None_32"></a>用“None”索引张量</h4> 
<p>  我们需要了解的第一件事是，当您使用 None 索引 PyTorch 张量时会发生什么?</p> 
<blockquote> 
 <p>与 NumPy 类似，您可以通过使用 None 索引该维度来插入单个维度（“解压缩”维度）。反过来，n[:, None] 将具有在 dim=1 上插入新维度的效果。这相当于 n.unsqueeze(dim=1)</p> 
</blockquote> 
<pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># Indexing with None does the same thing as unsqueezing the tensor</span>
<span class="token comment"># at that dimension. After this indexing operation, the tensors</span>
<span class="token comment"># x_row_dup and x_col_dup will have 1 additional dimension at</span>
<span class="token comment"># dimensions 0 and 1 respectively.</span>
x_row_dup<span class="token punctuation">,</span> x_col_dup <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_row_dup<span class="token punctuation">,</span> x_row_dup<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_col_dup<span class="token punctuation">,</span> x_col_dup<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#tensor([-1.2756, 1.1559, -0.0660]) torch.Size([3])</span>
<span class="token comment">#tensor([[-1.2756, 1.1559, -0.0660]]) torch.Size([1, 3])</span>
<span class="token comment">#tensor([[-1.2756],</span>
<span class="token comment">#        [ 1.1559],</span>
<span class="token comment">#        [-0.0660]]) torch.Size([3, 1])</span>

</code></pre> 
<h4><a id="_expand__54"></a>使用 .expand(…) 扩展张量</h4> 
<p>  PyTorch Expand(…) API 用于通过重复某些维度的值来扩展某些维度的值。请注意，只有值为 1 的维度才能扩展。让我们看下面的示例。</p> 
<pre><code>x_row_dup, x_col_dup = x_row_dup.expand(3, 3), x_col_dup.expand(3, 3)
print("x stretched across rows")
print(" - - - - - - - - - - - -")
print(x_row_dup, x_row_dup.shape)
print("")
print("x stretched across columns")
print(" - - - - - - - - - - - - - ")
print(x_col_dup, x_col_dup.shape)

# 打印内容
x stretched across rows
- - - - - - - - - - - -
tensor([[-1.2756, 1.1559, -0.0660],
        [-1.2756, 1.1559, -0.0660],
        [-1.2756, 1.1559, -0.0660]]) torch.Size([3, 3])

x stretched across columns
- - - - - - - - - - - - - 
tensor([[-1.2756, -1.2756, -1.2756],
        [ 1.1559, 1.1559, 1.1559],
        [-0.0660, -0.0660, -0.0660]]) torch.Size([3, 3])
</code></pre> 
<p>  假设我们的输入张量有 3 个元素，即 (A, B, C)。为了计算所有对的余弦相似度，我们首先将这个张量沿 3 行和 3 列展开。具体过程如下：</p> 
<p><strong>Unsqueeze</strong>：第一步，我们的输入张量 (A, B, C) 大小为3。我们首先沿第0和第1维度将其展开，具体方法就是刚刚介绍过的插入None，使其如下所示：<br> (A, B, C) 沿维度 0 展开将看起来像 ((A, B, C)) 并具有形状 (1, 3)。<br> (A, C, C) 沿维度 1 展开将看起来像 ((A), (B), ( C)) 并具有形状 (3, 1)。</p> 
<p><strong>Expand</strong>：然后，我们将沿着这些张量的单一维度（值为 1 的维度）展开这些张量，使两个张量都成为平方。<br> ((A, B, C)) 扩展为形状 (3, 3) 将如下所示：</p> 
<pre><code>((A, B, C),
 (A, B, C),
 (A, B, C))
</code></pre> 
<p>((A), (B), ©) 展开为形状 (3, 3) 将如下所示：</p> 
<pre><code>((A, A, A),
 (B, B ,B),
 (C, C, C))
</code></pre> 
<p>  上面这部分如果看不懂的话建议看看numpy的广播操作，这里推荐一篇文章：<a href="https://blog.csdn.net/qq_51352578/article/details/125074264">numpy广播机制</a>，这里面介绍的非常详细。</p> 
<p>  如果我们执行成对余弦相似度（PyTorch API 已经可以做到），那么我们将得到全对余弦相似度，如下图所示。<br> <img src="https://images2.imgbox.com/ab/28/LTVpbfYS_o.png" alt="在这里插入图片描述"><br> 就是这样！下面是一个示例，展示了我们迄今为止使用的张量。</p> 
<pre><code class="prism language-python"><span class="token comment"># Add a dummy dimension at the end so that we can perform cosine</span>
<span class="token comment"># similarity on that last dimension.</span>
x_row_dup <span class="token operator">=</span> x_row_dup<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
x_col_dup <span class="token operator">=</span> x_col_dup<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
x_cosine_similarity <span class="token operator">=</span> F<span class="token punctuation">.</span>cosine_similarity<span class="token punctuation">(</span>x_row_dup<span class="token punctuation">,</span> x_col_dup<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_cosine_similarity<span class="token punctuation">)</span>

<span class="token comment">#tensor([[ 1., -1., 1.],</span>
<span class="token comment">#        [-1., 1., -1.],</span>
<span class="token comment">#        [ 1., -1., 1.]])</span>
</code></pre> 
<p>可是等等！为什么所有的值都是 1 或 -1？！很容易理解，这是因为单个元素向量的角度为 0 度或 180 度，具体取决于它们指向相同方向还是相反方向。不明白可以看下面的推演过程：<br> <img src="https://images2.imgbox.com/7f/a3/ZwUZTFf0_o.png" alt="在这里插入图片描述"></p> 
<p>让我们用二维的矩阵而不是 一维 的向量尝试同样的事情。</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
x_row_dup<span class="token punctuation">,</span> x_col_dup <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
x_row_dup<span class="token punctuation">,</span> x_col_dup <span class="token operator">=</span> x_row_dup<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x_col_dup<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
x_cosine_similarity <span class="token operator">=</span> F<span class="token punctuation">.</span>cosine_similarity<span class="token punctuation">(</span>x_row_dup<span class="token punctuation">,</span> x_col_dup<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_cosine_similarity<span class="token punctuation">)</span>

<span class="token comment">#tensor([[1.0000, 0.9512, 0.9826],</span>
       <span class="token punctuation">[</span><span class="token number">0.9512</span><span class="token punctuation">,</span> <span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">0.9920</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0.9826</span><span class="token punctuation">,</span> <span class="token number">0.9920</span><span class="token punctuation">,</span> <span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>这看起来就会容易明白了！</p> 
<h4><a id="_132"></a>最后一招：广播</h4> 
<p>  虽然我们在前面使用了 .expand(…) ，但我们想提一下，这完全没有必要，因为 PyTorch 中定义的大多数操作都支持称为维度广播的概念。从文档来看，如果 PyTorch 操作支持广播，则其 Tensor 参数可以自动扩展为相同大小（无需复制数据）。</p> 
<p>  因此，当输入形状为 (1, 3) 和 (3, 1) 的 2 个张量时，余弦相似性运算会将它们广播到 (3, 3)，并本质上隐式执行我们上面显式执行的张量扩展步骤。</p> 
<p>  当我们运行下面的代码时。</p> 
<pre><code class="prism language-python">x_cosine_similarity <span class="token operator">=</span> F<span class="token punctuation">.</span>cosine_similarity<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># This should print the same matrix as above.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_cosine_similarity<span class="token punctuation">)</span>

<span class="token comment">#tensor([[1.0000, 0.9512, 0.9826],</span>
 <span class="token comment">#      [0.9512, 1.0000, 0.9920],</span>
 <span class="token comment">#      [0.9826, 0.9920, 1.0000]])</span>
</code></pre> 
<p>这实际上与我们上面得到的相同。</p> 
<h3><a id="_148"></a>关于效率的注释</h3> 
<p>与本讨论中提到的许多解决方案相比，此解决方案不使用任何显式的 for 循环。每次编写显式 for 循环时，都会遇到以下问题：</p> 
<ol><li>发生了一些重要的 CPU 计算，可能会导致 GPU 饥饿</li><li>如果您使用 for 循环，则可能会留下一些 GPU 并行执行的机会。这将影响您的整体 GPU 利用率，从而影响运行计算所需的时间</li></ol> 
<p>以上文章主要翻译自：<a href="https://medium.com/@dhruvbird/all-pairs-cosine-similarity-in-pytorch-867e722c8572" rel="nofollow">All Pairs Cosine Similarity in PyTorch</a> 感兴趣的可以看看原文，绝对精彩！</p> 
<p>参考资料：<br> 1.All Pairs Cosine Similarity in PyTorch,https://medium.om/@dhruvbird/all-pairs-cosine-similarity-in-pytorch-867e722c8572<br> 2.numpy广播机制,https://blog.csdn.net/qq_51352578/article/details/125074264</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/90a239aa910023da2f72a3899375e0de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">别人ping不通我的ip解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fa3ef4ad59a19345b24f6be9fe239d5c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">excel导出-将后端返回的文件流导出为excel</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>