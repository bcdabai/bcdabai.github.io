<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>alsa 驱动介绍 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="alsa 驱动介绍" />
<meta property="og:description" content="Machine 以装配有CS4270的一款android 智能电视的为例 /sound/soc/samsung/exynos.c Platform 以Samsung cpu exynos4412为例 /sound/soc/samsung/ Codec 以wolfson的Codec芯片cs4270为例 /sound/soc/codecs/cs4270.c ALSA 框架介绍 Alsa 太多太杂，很难整理的规整，只能看到哪里写到哪里 ASoC被分为Machine，Platform和Codec三大部件，
Platform驱动的主要作用是完成音频数据的管理，最终通过CPU的数字音频接口（DAI）把音频数据传送给Codec进行处理，最终由Codec输出驱动耳机或者是喇叭的音信信号。在具体实现上，ASoC有把Platform驱动分为两个部分：snd_soc_platform_driver和snd_soc_dai_driver。其中，platform_driver负责管理音频数据，把音频数据通过dma或其他操作传送至cpu dai中，dai_driver则主要完成cpu一侧的dai的参数配置，同时也会通过一定的途径把必要的dma等参数与snd_soc_platform_driver进行交互。
Machine 是指某一款机器，可以是某款设备，某款开发板，又或者是某款智能手机，由此可以看出Machine几乎是不可重用的，每个Machine上的硬件实现可能都不一样，CPU不一样，Codec不一样，音频的输入、输出设备也不一样，Machine为CPU、Codec、输入输出设备提供了一个载体。
Platform 一般是指某一个SoC平台，比如pxaxxx,s3cxxxx,omapxxx等等，与音频相关的通常包含该SoC中的时钟、DMA、I2S、PCM等等，只要指定了SoC，那么我们可以认为它会有一个对应的Platform，它只与SoC相关，与Machine无关，这样我们就可以把Platform抽象出来，使得同一款SoC不用做任何的改动，就可以用在不同的Machine中。实际上，把Platform认为是某个SoC更好理解。 Codec 字面上的意思就是编解码器，Codec里面包含了I2S接口、D/A、A/D、Mixer、PA（功放），通常包含多种输入（Mic、Line-in、I2S、PCM）和多个输出（耳机、喇叭、听筒，Line-out），Codec和Platform一样，是可重用的部件，同一个Codec可以被不同的Machine使用。嵌入式Codec通常通过I2C对内部的寄存器进行控制。 Machine驱动的初始化，codec和dai的注册，都会调用snd_soc_instantiate_cards()进行一次声卡和codec，dai，platform的匹配绑定过程，这里所说的绑定，正如Machine驱动一文中所描述，就是通过3个全局链表，按名字进行匹配，把匹配的codec，dai和platform实例赋值给声卡每对dai的snd_soc_pcm_runtime变量中。一旦绑定成功，将会使得codec和dai驱动的probe回调被调用 alsa架构的数据交互，是通过对PCM设备的操作来完成的， PCM设备分成playback和capture两个stream, 每个stream底下有N个substream。 alsa驱动最底层需要调试的有三块： DMA部分，IIS驱动部分，codec部分 IIS介绍 A）I2S有四根线， 1.串行时钟SCLK，也叫位时钟（BCLK），即对应数字音频的每一位数据，SCLK都有1个脉冲。SCLK的频率=2×采样频率×采样位数。 2. 帧时钟LRCK，(也称WS)，用于切换左右声道的数据。LRCK为“1”表示正在传输的是右声道的数据，为“0”则表示正在传输的是左声道的数据。LRCK的频率等于采样频率。 3.串行数据SDATA，就是用二进制补码表示的音频数据。 4.有时为了使系统间能够更好地同步，还需要另外传输一个信号MCLK，称为主时钟，也叫系统时钟（Sys Clock），是采样频率的256倍或384倍。 B）声音数据DAT一般在CLK的上升沿进行采样，有些DAC也是可以调的。每个声道里面可以容纳的CLK数必须多于数据的位数，多出来的时钟和数据DAC会丢弃不用，比如16bit采样的声音数据当一个声道是32个CLK且left-justify的时候，后面十六个时钟的数据会被DAC丢掉，不影响的。
C）I2S数据的格式分I2S， Left-justify， Right-justify。三种格式的区别在于声音数据与WS的对应关系： 1 . I2S模式DAT的MSB在WS变化后的第二个上升沿开始传输 2. Left-justify模式DAT的MSB在WS变化后的第一个上升沿开始传输 3. Right-justify模式DAT的LSB在WS即将变换到下一声道前的最后一个时钟传输 I2S部分涉及的几个频率: * 输出采样频率 fs = 44.1KHz. (也有其它fs的音源, 但加了resampler后, 都变成44.1KHz输出了). 这是个关键频率. * LRCLK, 就等于fs. (L/R声道信号) * BCLK = 32倍fs = 1411." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3e78ecbf9720619d85db736061afd2a9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-06-26T22:27:22+08:00" />
<meta property="article:modified_time" content="2016-06-26T22:27:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">alsa 驱动介绍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    Machine 
<br> 以装配有CS4270的一款android 智能电视的为例 
<br> /sound/soc/samsung/exynos.c 
<br> 
<br> 
<br> Platform 
<br> 以Samsung cpu exynos4412为例 
<br> /sound/soc/samsung/ 
<br> 
<br> 
<br> Codec 
<br> 以wolfson的Codec芯片cs4270为例 
<br> /sound/soc/codecs/cs4270.c 
<br> 
<br> 
<span style="font-size:32px"><br> ALSA 框架介绍</span> 
<br> 
<br> 
<br> Alsa 太多太杂，很难整理的规整，只能看到哪里写到哪里 
<br> 
<br> 
<p>ASoC被分为Machine，Platform和Codec三大部件，</p> 
<p><br> </p> 
<p><span style="font-size:12px">Platform驱动的主要作用是完成音频数据的管理，最终通过CPU的数字音频接口（DAI）把音频数据传送</span>给Codec进行处理，最终由Codec输出驱动耳机或者是喇叭的音信信号。在具体实现上，ASoC有把Platform驱动分为两个部分：snd_soc_platform_driver和snd_soc_dai_driver。其中，platform_driver负责管理音频数据，把音频数据通过dma或其他操作传送至cpu dai中，dai_driver则主要完成cpu一侧的dai的参数配置，同时也会通过一定的途径把必要的dma等参数与snd_soc_platform_driver进行交互。</p> 
<p><br> </p> 
<p>Machine  是指某一款机器，可以是某款设备，某款开发板，又或者是某款智能手机，由此可以看出Machine几乎是不可重用的，每个Machine上的硬件实现可能都不一样，CPU不一样，Codec不一样，音频的输入、输出设备也不一样，Machine为CPU、Codec、输入输出设备提供了一个载体。</p> Platform  一般是指某一个SoC平台，比如pxaxxx,s3cxxxx,omapxxx等等，与音频相关的通常包含该SoC中的时钟、DMA、I2S、PCM等等，只要指定了SoC，那么我们可以认为它会有一个对应的Platform，它只与SoC相关，与Machine无关，这样我们就可以把Platform抽象出来，使得同一款SoC不用做任何的改动，就可以用在不同的Machine中。实际上，把Platform认为是某个SoC更好理解。 
<br> 
<p><br> </p> 
<p>Codec  字面上的意思就是编解码器，Codec里面包含了I2S接口、D/A、A/D、Mixer、PA（功放），通常包含多种输入（Mic、Line-in、I2S、PCM）和多个输出（耳机、喇叭、听筒，Line-out），Codec和Platform一样，是可重用的部件，同一个Codec可以被不同的Machine使用。嵌入式Codec通常通过I2C对内部的寄存器进行控制。 </p> 
<br> Machine驱动的初始化，codec和dai的注册，都会调用snd_soc_instantiate_cards()进行一次声卡和codec，dai，platform的匹配绑定过程，这里所说的绑定，正如Machine驱动一文中所描述，就是通过3个全局链表，按名字进行匹配，把匹配的codec，dai和platform实例赋值给声卡每对dai的snd_soc_pcm_runtime变量中。一旦绑定成功，将会使得codec和dai驱动的probe回调被调用 
<br> 
<br> alsa架构的数据交互，是通过对PCM设备的操作来完成的， PCM设备分成playback和capture两个stream, 每个stream底下有N个substream。 
<br> 
<br> alsa驱动最底层需要调试的有三块： DMA部分，IIS驱动部分，codec部分 
<br> 
<p><br> </p> 
<p><img src="https://images2.imgbox.com/e7/55/T0ttnqe9_o.png" alt=""><br> </p> 
<p><br> </p> 
<p><br> </p> 
<p><br> </p> 
<p><img src="https://images2.imgbox.com/8c/94/y1SsF3Y7_o.png" alt=""><br> </p> 
<p><br> </p> 
<p><img src="https://images2.imgbox.com/5e/4e/UIxIwhI2_o.png" alt=""><br> </p> 
<p><br> </p> 
<span style="font-size:32px">IIS介绍</span> 
<br> 
<br> A）I2S有四根线， 
<br> 
<span style="white-space:pre"></span>1.串行时钟SCLK，也叫位时钟（BCLK），即对应数字音频的每一位数据，SCLK都有1个脉冲。SCLK的频率=2×采样频率×采样位数。 
<br> 
<span style="white-space:pre"></span>2. 帧时钟LRCK，(也称WS)，用于切换左右声道的数据。LRCK为“1”表示正在传输的是右声道的数据，为“0”则表示正在传输的是左声道的数据。LRCK的频率等于采样频率。 
<br> 
<span style="white-space:pre"></span>3.串行数据SDATA，就是用二进制补码表示的音频数据。 
<br> 
<span style="white-space:pre"></span>4.有时为了使系统间能够更好地同步，还需要另外传输一个信号MCLK，称为主时钟，也叫系统时钟（Sys Clock），是采样频率的256倍或384倍。 
<br> 
<p><br> </p> 
<p>B）声音数据DAT一般在CLK的上升沿进行采样，有些DAC也是可以调的。每个声道里面可以容纳的CLK数必须多于数据的位数，多出来的时钟和数据DAC会丢<span style="font-size:12px">弃不用，比如16bit采样的声音数据当一个声道是32个CLK且left-justify的时候，后面十六个时钟的数据会被DAC丢掉，不影响的。</span></p> 
<br> 
<br> C）I2S数据的格式分I2S， Left-justify， Right-justify。三种格式的区别在于声音数据与WS的对应关系： 
<br> 
<span style="white-space:pre"></span>1 .  I2S模式DAT的MSB在WS变化后的第二个上升沿开始传输 
<br> 
<span style="white-space:pre"></span>2.  Left-justify模式DAT的MSB在WS变化后的第一个上升沿开始传输 
<br> 
<span style="white-space:pre"></span>3.   Right-justify模式DAT的LSB在WS即将变换到下一声道前的最后一个时钟传输 
<br> 
<br> 
<br> I2S部分涉及的几个频率: 
<br>   * 输出采样频率 fs = 44.1KHz.  (也有其它fs的音源, 但加了resampler后, 都变成44.1KHz输出了). 这是个关键频率. 
<br>   * LRCLK, 就等于fs. (L/R声道信号) 
<br>   * BCLK = 32倍fs = 1411.2KHz = 1.4112MHz. (bit clock). 2声道16bit, 故32倍fs. 若2声道24bit, 则48倍fs. 
<br>   * MCLK是整个audio模块的工作频率, 通常选fs的256, 384, 512倍. 比如: 256倍fs = 11289.6KHz = 11.2896MHz. 
<br> 
<br> 从频率设置来说, MCLK是个主要频率, 它是整个audio模块的工作频率. 
<br> 
<br> 那么, 从软件来说要设置两个方面的寄存器: 一是该PLL从晶振频率如何得到PLLout频率(比如P/M/S/k). 二是PLLout如何分频得到audio部分的MCLK. 
<br> 
<br> 
<br> IIS驱动部分最重要的就是注册以下钩子函数，挂到了alsa驱动上 
<br> 
<pre><code class="language-cpp">static const struct snd_soc_dai_ops samsung_i2s_dai_ops = {
	.trigger = i2s_trigger,
	.hw_params = i2s_hw_params,
	.set_fmt = i2s_set_fmt,
	.set_clkdiv = i2s_set_clkdiv,
	.set_sysclk = i2s_set_sysclk,
	.startup = i2s_startup,
	.shutdown = i2s_shutdown,
	.delay = i2s_delay,
};</code></pre> 
<br> 
<br> 
<br> 
<span style="font-size:32px">codec芯片介绍</span> 
<br> cs4270的驱动要设置的参数有： 
<br> 
<span style="white-space:pre"></span> 
<span style="white-space:pre"></span>静音，传输模式，比特位长度，时钟主从模式，音量大小 
<br> cs4270驱动里面定义了snd_soc_dai_driver结构成员，里面定义了playback和capture两个substream，同事也挂了一个snd_soc_dai_ops结构体，里面全是操作函数指针。 
<br> alsa上面一层层的最终会调用到这些指针 
<br> 
<br> 
<pre><code class="language-cpp">static const struct snd_soc_dai_ops cs4270_dai_ops = {
	.hw_params	= cs4270_hw_params,
	.set_sysclk	= cs4270_set_dai_sysclk,
	.set_fmt	= cs4270_set_dai_fmt,
	.digital_mute	= cs4270_dai_mute,
};


static struct snd_soc_dai_driver cs4270_dai = {
	.name = "cs4270-hifi",
	.playback = {
		.stream_name = "Playback",
		.channels_min = 1,
		.channels_max = 2,
		.rates = SNDRV_PCM_RATE_CONTINUOUS,
		.rate_min = 4000,
		.rate_max = 216000,
		.formats = CS4270_FORMATS,
	},
	.capture = {
		.stream_name = "Capture",
		.channels_min = 1,
		.channels_max = 2,
		.rates = SNDRV_PCM_RATE_CONTINUOUS,
		.rate_min = 4000,
		.rate_max = 216000,
		.formats = CS4270_FORMATS,
	},
	.ops = &amp;cs4270_dai_ops,
};</code></pre> 
<br> 
<br> 
<br> 
<span style="font-size:32px"><br> DMA介绍<br> </span> 
<br> IIS总线是慢速总线，相对于CPU来说，太慢。所以采用DMA的方式最能节省CPU性能。 
<br> PCM playback的时候，DMA目的地址是IIS FIFO寄存器。源地址是存放PCM数据的内存。 
<br> DMA的驱动采用了linux pl330的驱动架构，采用中断的方式来触发后续DMA。 
<br> 
<p>IIS中通过DMA的方式写入FIFO寄存器，在DMA的驱动中挂接了一个回调函数audio_buffdone。DMA完成后，回函数调用，刷新alsa的环，便于下一次DMA。</p> 
<p>DMA的目的地址，就是IIS发送寄存器的地址。源地址，就是申请的DMA buffer，只不过DMAbuffer被映射成了一个环</p> 
<br> 
<pre><code class="language-cpp">static void dma_enqueue(struct snd_pcm_substream *substream)
{
	struct runtime_data *prtd = substream-&gt;runtime-&gt;private_data;
	dma_addr_t pos = prtd-&gt;dma_pos;
	unsigned int limit;
	struct samsung_dma_prep dma_info;


	pr_debug("Entered %s\n", __func__);


	limit = (prtd-&gt;dma_end - prtd-&gt;dma_start) / prtd-&gt;dma_period;


	pr_debug("%s: loaded %d, limit %d\n",
				__func__, prtd-&gt;dma_loaded, limit);


	dma_info.cap = (samsung_dma_has_circular() ? DMA_CYCLIC : DMA_SLAVE);
	dma_info.direction =
		(substream-&gt;stream == SNDRV_PCM_STREAM_PLAYBACK
		? DMA_MEM_TO_DEV : DMA_DEV_TO_MEM);
	dma_info.fp = audio_buffdone;   //回调函数
	dma_info.fp_param = substream;
	dma_info.period = prtd-&gt;dma_period;
	dma_info.len = prtd-&gt;dma_period*limit;


	while (prtd-&gt;dma_loaded &lt; limit) {
		pr_debug("dma_loaded: %d\n", prtd-&gt;dma_loaded);


		if ((pos + dma_info.period) &gt; prtd-&gt;dma_end) {
			dma_info.period  = prtd-&gt;dma_end - pos;
			pr_debug("%s: corrected dma len %ld\n",
					__func__, dma_info.period);
		}


		dma_info.buf = pos;
		prtd-&gt;params-&gt;ops-&gt;prepare(prtd-&gt;params-&gt;ch, &amp;dma_info); //DMA注册


		prtd-&gt;dma_loaded++;
		pos += prtd-&gt;dma_period;
		if (pos &gt;= prtd-&gt;dma_end)
			pos = prtd-&gt;dma_start;
	}


	prtd-&gt;dma_pos = pos;
}
static void audio_buffdone(void *data)
{
	struct snd_pcm_substream *substream = data;
	struct runtime_data *prtd = substream-&gt;runtime-&gt;private_data;


	pr_debug("Entered %s\n", __func__);


	if (prtd-&gt;state &amp; ST_RUNNING) {
		prtd-&gt;dma_pos += prtd-&gt;dma_period;
		if (prtd-&gt;dma_pos &gt;= prtd-&gt;dma_end)
			prtd-&gt;dma_pos = prtd-&gt;dma_start;


		if (substream)
			snd_pcm_period_elapsed(substream);


		spin_lock(&amp;prtd-&gt;lock);
		if (!samsung_dma_has_circular()) {
			prtd-&gt;dma_loaded--;
			dma_enqueue(substream);
		}
		spin_unlock(&amp;prtd-&gt;lock);
	}
}
</code></pre> 
<br> 
<br> 
<br> DMA部分主要通过注册以下钩子函数来挂到alsa驱动里面 
<br> 
<br> 
<pre><code class="language-cpp">static struct snd_pcm_ops dma_ops = {
	.open		= dma_open,
	.close		= dma_close,
	.ioctl		= snd_pcm_lib_ioctl,
	.hw_params	= dma_hw_params,
	.hw_free	= dma_hw_free,
	.prepare	= dma_prepare,
	.trigger	= dma_trigger,
	.pointer	= dma_pointer,
	.mmap		= dma_mmap,
};
</code></pre> 
<br> 
<br> 
<span style="font-size:32px">alsa数据读写简介</span> 
<br> 
<br> 播放时，应用程序把音频数据源源不断地写入dma buffer中，然后相应platform的dma操作则不停地从该buffer中取出数据，经dai送往codec中。录音时则正好相反，codec源源不断地把A/D转换好的音频数据经过dai送入dma buffer中，而应用程序则不断地从该buffer中读走音频数据。 
<br> 
<br> 以播放(playback)为例，我现在知道至少有3个途径可以完成对dma buffer的写入： 
<br> 应用程序调用alsa-lib的snd_pcm_writei、snd_pcm_writen函数； 
<br> 应用程序使用ioctl：SNDRV_PCM_IOCTL_WRITEI_FRAMES或SNDRV_PCM_IOCTL_WRITEN_FRAMES； 
<br> 应用程序使用alsa-lib的snd_pcm_mmap_begin/snd_pcm_mmap_commit; 
<br> 
<br> 以上几种方式最终把数据写入dma buffer中，然后修改runtime-&gt;control-&gt;appl_ptr的值。 
<br> 播放过程中，通常会配置成每一个period size生成一个dma中断，中断处理函数最重要的任务就是： 
<br> 更新dma的硬件的当前位置，该数值通常保存在runtime-&gt;private_data中； 
<br> 调用snd_pcm_period_elapsed函数，该函数会进一步调用snd_pcm_update_hw_ptr0函数更新上述所说的4个缓冲区管理字段，然后唤醒相应的等待进程； 
<br> 这个中断实际上在DMA驱动内部，给DMA驱动一个回调函数就可以了。就是我们前面说的audio_buffdone 
<br> 
<br> Playback时数据流向 
<br> 
<br> /sound/soc/samsung/里面，写入到DMA源buffer时， 
<br> 用的是mmap的写入方式，不是采用的snd_pcm_hw_writei 
<br> 
<br> 几个关键点： 
<br> 1，Pos计算方式 
<br> dma_pointer里面， res = prtd-&gt;dma_pos - prtd-&gt;dma_start; 
<br> 此pos就是在DMA 源buffer中的位置 
<br> 2，dma的初始化 
<br> dma_enqueue里面，把DMA源buffer切成period_size大小，挂到DMA队列里 
<br> 每次period_size传输完了，就会调用audio_buffdone终端处理函数，更新dma_pos 
<br> 同时audio_buffdone也会调用snd_pcm_update_hw_ptr0重新计算hw_ptr,从而计算是不是有足够的可用空间，来唤醒等待的poll 
<br> 
<br> 从alsalib来看，要先调用snd_pcm_start，触发DMA操作开始 
<br> snd_pcm_start---SNDRV_PCM_IOCTL_START---snd_pcm_action_lock_irq--snd_pcm_do_start----dma_trigger 
<br> 每次写入mmap buffer之前,要先snd_pcm_wait,等待有足够可用的空间. 
<br> snd_pcm_wait----snd_pcm_wait_nocheck----poll-----snd_pcm_playback_poll---poll_wait 
<br> 然后调用snd_pcm_mmap_begin获取mmap 内存 
<br> 然后写入,然后调用snd_pcm_mmap_commit做一下alsalib和驱动里面的环同步 
<br> 
<br> DMA实际上是在不停的DMA的。有空闲的了，上层就不用wait了，就会写入了 
<br> 
<p><span style="font-size:32px"><img src="https://images2.imgbox.com/7e/68/r6ZRJGki_o.png" alt=""><br> </span></p> 
<p><span style="font-size:32px">几个典型调用流程</span></p> 
<pre><code class="language-cpp">设置hw_param参数时，调用流程
snd_pcm_hw_params
_snd_pcm_hw_params
pcm-&gt;ops-&gt;hw_params----snd_pcm_hw_hw_params
SNDRV_PCM_IOCTL_HW_PARAMS


snd_pcm_common_ioctl1
snd_pcm_hw_params_user
snd_pcm_hw_params
substream-&gt;ops-&gt;hw_params
soc_pcm_hw_params
codec_dai-&gt;driver-&gt;ops-&gt;hw_params
cpu_dai-&gt;driver-&gt;ops-&gt;hw_params
cs4270_hw_params



设置mixer 参数时，volume为例，调用流程
snd_mixer_selem_set_playback_volume_all				
snd_mixer_selem_set_playback_volume
set_volume_ops
_snd_mixer_selem_set_volume---selem_write
selem_write_main
elem_write_volume
snd_hctl_elem_write
snd_ctl_elem_write
snd_ctl_hw_elem_write


snd_ctl_elem_write_user
snd_ctl_elem_write
snd_soc_put_volsw
snd_soc_update_bits_locked
regmap_update_bits_check


IIS clk 设置流程


snd_pcm_common_ioctl1
snd_pcm_hw_params_user
snd_pcm_hw_params 
substream-&gt;ops-&gt;hw_params
soc_pcm_hw_params
rtd-&gt;dai_link-&gt;ops-&gt;hw_params
smdk_wm8994_pcm_hw_params
snd_soc_dai_set_sysclk
dai-&gt;driver-&gt;ops-&gt;set_sysclk
i2s_set_sysclk


















</code></pre> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br> 
<br>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/df937586f3a00cd449c4ddc0d608ef7c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">gdb 查看当前位置的指令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0a59bc6a888c98f07da93f0e6fa10d88/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">com.alibaba.dubbo.rpc.RpcException的解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>