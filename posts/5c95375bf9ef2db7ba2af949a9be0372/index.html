<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>detr训练代码解析，训练自己的数据集 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="detr训练代码解析，训练自己的数据集" />
<meta property="og:description" content="原始代码：21个小时/epoch
前置resieze（最大边长1333）：17个小时/epoch
数据前处理:
train：
1.随机水平翻转
def __call__(self, img, target): if random.random() &lt; self.p: return hflip(img, target) return img, target 2.随机进行两种方式的处理
def __init__(self, transforms1, transforms2, p=0.5): self.transforms1 = transforms1 self.transforms2 = transforms2 self.p = p def __call__(self, img, target): if random.random() &lt; self.p: return self.transforms1(img, target) return self.transforms2(img, target) self.transforms1(img, target) :运行 5-6，直接resize和归一化。先根据最小边长进行resize，如果最大边长小于1333，进行下一步。否则按最大边长进行resize。最小边长为[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]，最大边长为1333。
self.transforms2(img, target) :运行 3-6，进行resize、crop、resize、归一化
3.resize
def __init__(self, sizes, max_size=None): assert isinstance(sizes, (list, tuple)) self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/5c95375bf9ef2db7ba2af949a9be0372/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-30T10:36:30+08:00" />
<meta property="article:modified_time" content="2023-08-30T10:36:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">detr训练代码解析，训练自己的数据集</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>原始代码：21个小时/epoch<br> 前置resieze（最大边长1333）：17个小时/epoch<br> 数据前处理:<br> train：<br> 1.随机水平翻转</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>p<span class="token punctuation">:</span>
        <span class="token keyword">return</span> hflip<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
    <span class="token keyword">return</span> img<span class="token punctuation">,</span> target
</code></pre> 
<p>2.随机进行两种方式的处理</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> transforms1<span class="token punctuation">,</span> transforms2<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>transforms1 <span class="token operator">=</span> transforms1
    self<span class="token punctuation">.</span>transforms2 <span class="token operator">=</span> transforms2
    self<span class="token punctuation">.</span>p <span class="token operator">=</span> p

<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>p<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>transforms1<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>transforms2<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">)</span>  
</code></pre> 
<p>self.transforms1(img, target) :运行 5-6，直接resize和归一化。先根据最小边长进行resize，如果最大边长小于1333，进行下一步。否则按最大边长进行resize。最小边长为[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]，最大边长为1333。<br> self.transforms2(img, target) :运行 3-6，进行resize、crop、resize、归一化<br> 3.resize</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sizes<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>sizes<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>sizes <span class="token operator">=</span> sizes
    self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size

<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sizes<span class="token punctuation">)</span>    <span class="token comment">##(400,500,600)</span>
    <span class="token keyword">return</span> resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">,</span> size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_size<span class="token punctuation">)</span>  dengbiliresieze<span class="token punctuation">,</span>zuixiaobiaochangshi size 
</code></pre> 
<p>4.crop</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> min_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> max_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>min_size <span class="token operator">=</span> min_size
    self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size

<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">:</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>min_size<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>width<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    h <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>min_size<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>height<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    region <span class="token operator">=</span> T<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">.</span>get_params<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token punctuation">[</span>h<span class="token punctuation">,</span> w<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> crop<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">,</span> region<span class="token punctuation">)</span>
</code></pre> 
<p>5.resize</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sizes<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>sizes<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>sizes <span class="token operator">=</span> sizes
    self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size

<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sizes<span class="token punctuation">)</span>   <span class="token comment">##[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]</span>
    <span class="token keyword">return</span> resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> target<span class="token punctuation">,</span> size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_size<span class="token punctuation">)</span>   <span class="token comment">###max_sizeshi 1333</span>
</code></pre> 
<p>6.Normalize</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>mean <span class="token operator">=</span> mean
    self<span class="token punctuation">.</span>std <span class="token operator">=</span> std

<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> target<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    image <span class="token operator">=</span> F<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> mean<span class="token operator">=</span>self<span class="token punctuation">.</span>mean<span class="token punctuation">,</span> std<span class="token operator">=</span>self<span class="token punctuation">.</span>std<span class="token punctuation">)</span>
    <span class="token keyword">if</span> target <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> image<span class="token punctuation">,</span> <span class="token boolean">None</span>
    target <span class="token operator">=</span> target<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    h<span class="token punctuation">,</span> w <span class="token operator">=</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token string">"boxes"</span> <span class="token keyword">in</span> target<span class="token punctuation">:</span>
        boxes <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token string">"boxes"</span><span class="token punctuation">]</span>
        boxes <span class="token operator">=</span> box_xyxy_to_cxcywh<span class="token punctuation">(</span>boxes<span class="token punctuation">)</span>
        boxes <span class="token operator">=</span> boxes <span class="token operator">/</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        target<span class="token punctuation">[</span><span class="token string">"boxes"</span><span class="token punctuation">]</span> <span class="token operator">=</span> boxes
    <span class="token keyword">return</span> image<span class="token punctuation">,</span> target
</code></pre> 
<p>总的处理前处理:</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">make_coco_transforms</span><span class="token punctuation">(</span>image_set<span class="token punctuation">)</span><span class="token punctuation">:</span>
    normalize <span class="token operator">=</span> T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
        T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        T<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>

    scales <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">544</span><span class="token punctuation">,</span> <span class="token number">576</span><span class="token punctuation">,</span> <span class="token number">608</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">672</span><span class="token punctuation">,</span> <span class="token number">704</span><span class="token punctuation">,</span> <span class="token number">736</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">]</span>

    <span class="token keyword">if</span> image_set <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
            T<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            T<span class="token punctuation">.</span>RandomSelect<span class="token punctuation">(</span>
                T<span class="token punctuation">.</span>RandomResize<span class="token punctuation">(</span>scales<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">1333</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">##等比例resize,随机选择尺寸，最大1333</span>
                T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                    T<span class="token punctuation">.</span>RandomResize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    
                    T<span class="token punctuation">.</span>RandomSizeCrop<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    T<span class="token punctuation">.</span>RandomResize<span class="token punctuation">(</span>scales<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">1333</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            normalize<span class="token punctuation">,</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> image_set <span class="token operator">==</span> <span class="token string">'val'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
            T<span class="token punctuation">.</span>RandomResize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">800</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">1333</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            normalize<span class="token punctuation">,</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'unknown </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>image_set<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>加快训练速度，又不影响模型精度。不能统一进行前置预处理，只能先进行一步操作。提前resize到max_size=1333。数据集中大部分都是1920<em>1080和2560</em>1440的，提前resize成小图减少io和数据处理时间，验证训练速度。</p> 
<p>参考链接：<br> https://zhuanlan.zhihu.com/p/490042821?utm_id=0<br> transform结构：<br> <img src="https://images2.imgbox.com/4a/f6/y6yAEFqm_o.png" alt="在这里插入图片描述"></p> 
<p>原理：https://blog.csdn.net/weixin_44649780/article/details/126808881?spm=1001.2014.3001.5501<br> <img src="https://images2.imgbox.com/01/a4/o4eWlL7N_o.png" alt="在这里插入图片描述"><br> 图2： DETR使用一个传统的CNN主干来学习一个输入图像的二维表示。该模型对其进行扁平化处理，并在将其传递给变换器编码器之前用位置编码进行补充。将其传递给一个transformer编码器。然后，transformer解码器将学习到的少量位置嵌入作为输入。我们称其为对象查询，并在解码器中输入少量固定数量的位置嵌入。另外还关注编码器的输出。我们将解码器的每个输出嵌入传递给一个共享的前馈网络（FFN），该网络预测一个检测（类别和边界框）或 "无物体 "类。</p> 
<p><strong>主干网络</strong>。从初始图像Ximg∈R 3×H0×W0（有3个色通道)，一个传统的CNN骨干网会生成一个较低分辨率的激活图f∈R C×H×W。我们使用的典型值是C = 2048，H, W =H0/32 ,W0/32 .</p> 
<p><strong>Transformer编码器</strong>。编码器希望有一个序列作为输入，因此我们将z0的空间维度折叠成一个维度，从而得到一个d×HW的特征图。每个编码器层都有一个标准的结构，由一个多头的自我注意模块和一个前馈网络（FFN）。<br> encoder的输入包含三部分，</p> 
<p>（1）由图像生成的序列：src (HW, N , 256),</p> 
<p>（2）掩码信息：mask (N, HW),</p> 
<p>（3）位置信息：pos_embed(HW, N ,256)<br> 参考：https://blog.csdn.net/sazass/article/details/118329320<br> <img src="https://images2.imgbox.com/ad/fa/fJyZRaKV_o.png" alt="在这里插入图片描述"></p> 
<p><strong>Transformer解码器</strong>。解码器遵循转化器的标准结构。transformer的标准结构，使用多头的自和<br> 编码器-解码器注意机制。与原始转化器的区别是，我们的模型在每个解码器层对N个对象进行并行解码。而Vaswani等人[47]使用一个自回归模型(autoregressive model)，每次预测输出的顺序一次预测一个元素。我们请不熟悉这些概念的读者参考补充材料。考补充由于解码器也是互换不变的。N个输入嵌入必须是不同的，以产生不同的结果。这些输入嵌入是学习到的位置编码，我们将其称为对象查询。与编码器类似，我们将它们添加到每个注意力层的输入中。N个对象查询被解码器转化为输出嵌入。然后，它们被一个前馈网络独立地解码为盒子坐标和类别标签。一个前馈网络（在下一小节中描述），产生N个最终的预测。使用自我和编码器-解码器对这些嵌入的关注。该模型使用成对的关系对所有物体进行全局推理之间的关系，同时能够使用整个图像作为背景。</p> 
<p><strong>归纳预测前馈网络（FFNs）</strong>。最终的预测是由一个具有ReLU激活函数和隐藏维度d的3层感知器和一个线性投影层计算的。FFN预测的是归一化的中心坐标、预测框的高度和宽度（相对于输入图像），而线性层则使用softmax函数预测类别标签。由于我们预测的是一个固定大小的N个边界框，而N通常比图像中感兴趣的物体的实际数量要大得多，所以一个额外的特殊类标签∅被用来表示在一个槽内没有检测到任何物体。这个类别扮演着与标准物体检测方法中的 "背景 "类类似的角色。</p> 
<p>**辅助解码损失。**我们发现在训练过程中使用辅助损失[1]对解码器很有帮助，特别是帮助模型输出每个类别的正确数量的对象。我们在每个解码层之后添加预测的FFN和匈牙利损失。解码器层之后。所有的预测FFNs共享它们的参数。我们使用一个额外的共享层规范来规范来自不同解码层的预测FFN的输入。<br> 流程：主干网络（resnet50）------位置编码器-----transformer编码器-----transformer解码器----FFN预测—计算loss</p> 
<pre><code class="prism language-python">self<span class="token punctuation">.</span>self_attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>    <span class="token comment">##256,8</span>
_hidden_dim<span class="token operator">=</span><span class="token number">256</span>
_num_queries<span class="token operator">=</span><span class="token number">100</span>
self<span class="token punctuation">.</span>query_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_queries<span class="token punctuation">,</span> _hidden_dim<span class="token punctuation">)</span>
features<span class="token punctuation">,</span> pos <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">(</span>samples<span class="token punctuation">)</span>    <span class="token comment">##src是backbone的输出；pos是backbone+位置编码后的输出</span>
src<span class="token punctuation">,</span> mask <span class="token operator">=</span> features<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decompose<span class="token punctuation">(</span><span class="token punctuation">)</span>
hs <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_proj<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> self<span class="token punctuation">.</span>query_embed<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
encoder的forward：
			 q <span class="token operator">=</span> k <span class="token operator">=</span> self<span class="token punctuation">.</span>with_pos_embed<span class="token punctuation">(</span>src<span class="token punctuation">,</span> pos<span class="token punctuation">)</span>
        src2 <span class="token operator">=</span> self<span class="token punctuation">.</span>self_attn<span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> value<span class="token operator">=</span>src<span class="token punctuation">,</span> attn_mask<span class="token operator">=</span>src_mask<span class="token punctuation">,</span>
                              key_padding_mask<span class="token operator">=</span>src_key_padding_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        src <span class="token operator">=</span> src <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>src2<span class="token punctuation">)</span>
        src <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>src<span class="token punctuation">)</span>
        src2 <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        src <span class="token operator">=</span> src <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>src2<span class="token punctuation">)</span>
        src <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>src<span class="token punctuation">)</span>
        <span class="token keyword">return</span> src
transformer的forward：
        memory <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>src<span class="token punctuation">,</span> src_key_padding_mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos_embed<span class="token punctuation">)</span>
        hs <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> memory_key_padding_mask<span class="token operator">=</span>mask<span class="token punctuation">,</span>
                          pos<span class="token operator">=</span>pos_embed<span class="token punctuation">,</span> query_pos<span class="token operator">=</span>query_embed<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">TransformerDecoderLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dim_feedforward<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                 activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> normalize_before<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>self_attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>multihead_attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>
        <span class="token comment"># Implementation of Feedforward model</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim_feedforward<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> _get_activation_fn<span class="token punctuation">(</span>activation<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>normalize_before <span class="token operator">=</span> normalize_before
</code></pre> 
<p>Q 的 shape 就是 n*dmodel， K、V 也是一样<br> out = {‘pred_logits’: outputs_class[-1], ‘pred_boxes’: outputs_coord[-1]}<br> if self.aux_loss:<br> out[‘aux_outputs’] = self._set_aux_loss(outputs_class, outputs_coord)</p> 
<p>batchx3x768x992-----batchx2048x24x31------卷积得到src=batchx_hidden_dimx24x31-----变换到744xbatchx _hidden_dim（q，k，v的维度）-----编码完还是744xbatchx _hidden_dim-----解码得到6x2x100x256-----分别计算类别全连接outputs_class：6x2x100x（num_cls+1）和位置MLP层outputs_coord：6x2x100x4</p> 
<pre><code class="prism language-python">out <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'pred_logits'</span><span class="token punctuation">:</span> outputs_class<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'pred_boxes'</span><span class="token punctuation">:</span> outputs_coord<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>  <span class="token comment">##pred_logits是（2,100,6），pred_boxes是（2,100,4）</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>aux_loss<span class="token punctuation">:</span>
            out<span class="token punctuation">[</span><span class="token string">'aux_outputs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_set_aux_loss<span class="token punctuation">(</span>outputs_class<span class="token punctuation">,</span> outputs_coord<span class="token punctuation">)</span>
</code></pre> 
<p><strong>位置编码器</strong>参考：https://blog.csdn.net/weixin_44649780/article/details/127162890<br> 作用：对backbone输出的二维特征添加上位置信息（b,c,h/32,w/32）.<br> DETR中提供了两种编码方式，一种是正弦编码（PositionEmbeddingSine），一种是可以学习的编码(PositionEmbeddingLearned)，默认为正弦编码。<br> 对x或y，计算奇数位置的正弦，计算偶数位置的余弦，然后将pos_x和pos_y拼接起来得到一个NHWD的数组，再经过permute(0,3,1,2)，形状变为NDHW，其中D等于hidden_dim。这个hidden_dim是Transformer输入向量的维度，在实现上，要等于CNN backbone输出的特征图的维度。所以pos code和CNN输出特征的形状是完全一样的。</p> 
<p>使用：https://zhuanlan.zhihu.com/p/566438910<br> 1.数据集yolo转coco<br> “”"<br> YOLO 格式的数据集转化为 COCO 格式的数据集<br> –root_dir 输入根路径<br> –save_path 保存文件的名字(没有random_split时使用)<br> –random_split 有则会随机划分数据集，然后再分别保存为3个文件。<br> –split_by_file 按照 ./train.txt ./val.txt ./test.txt 来对数据集进行划分。</p> 
<pre><code class="prism language-python"><span class="token string">""</span>"

<span class="token keyword">import</span> os
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> json
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> argparse

parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--root_dir'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'./val'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span>
                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"root path of images and labels, include ./images and ./labels and classes.txt"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--save_path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'./val.json'</span><span class="token punctuation">,</span>
                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"if not split the dataset, give a path to a json file"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--random_split'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"random split the dataset, default ratio is 8:1:1"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--split_by_file'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span>
                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"define how to split the dataset, include ./train.txt ./val.txt ./test.txt "</span><span class="token punctuation">)</span>

arg <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train_test_val_split_random</span><span class="token punctuation">(</span>img_paths<span class="token punctuation">,</span> ratio_train<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> ratio_test<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> ratio_val<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 这里可以修改数据集划分的比例。</span>
    <span class="token keyword">assert</span> <span class="token builtin">int</span><span class="token punctuation">(</span>ratio_train <span class="token operator">+</span> ratio_test <span class="token operator">+</span> ratio_val<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
    train_img<span class="token punctuation">,</span> middle_img <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>img_paths<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> ratio_train<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">233</span><span class="token punctuation">)</span>
    ratio <span class="token operator">=</span> ratio_val <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> ratio_train<span class="token punctuation">)</span>
    val_img<span class="token punctuation">,</span> test_img <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>middle_img<span class="token punctuation">,</span> test_size<span class="token operator">=</span>ratio<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">233</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"NUMS of train:val:test = {}:{}:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_img<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>val_img<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_img<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> train_img<span class="token punctuation">,</span> val_img<span class="token punctuation">,</span> test_img


<span class="token keyword">def</span> <span class="token function">train_test_val_split_by_files</span><span class="token punctuation">(</span>img_paths<span class="token punctuation">,</span> root_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 根据文件 train.txt, val.txt, test.txt（里面写的都是对应集合的图片名字） 来定义训练集、验证集和测试集</span>
    phases <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span>
    img_split <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> phases<span class="token punctuation">:</span>
        define_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>p<span class="token punctuation">}</span></span><span class="token string">.txt'</span></span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Read </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>p<span class="token punctuation">}</span></span><span class="token string"> dataset definition from </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>define_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>define_path<span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>define_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            img_paths <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># img_paths = [os.path.split(img_path.strip())[1] for img_path in img_paths]  # NOTE 取消这句备注可以读取绝对地址。</span>
            img_split<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img_paths<span class="token punctuation">)</span>
    <span class="token keyword">return</span> img_split<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> img_split<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> img_split<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">yolo2coco</span><span class="token punctuation">(</span>arg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    root_path <span class="token operator">=</span> arg<span class="token punctuation">.</span>root_dir
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading data from "</span><span class="token punctuation">,</span> root_path<span class="token punctuation">)</span>

    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>root_path<span class="token punctuation">)</span>
    originLabelsDir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">)</span>
    originImagesDir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'images'</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'classes.txt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        classes <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># images dir name</span>
    indexes <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>originImagesDir<span class="token punctuation">)</span>

    <span class="token keyword">if</span> arg<span class="token punctuation">.</span>random_split <span class="token keyword">or</span> arg<span class="token punctuation">.</span>split_by_file<span class="token punctuation">:</span>
        <span class="token comment"># 用于保存所有数据的图片信息和标注信息</span>
        train_dataset <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'categories'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'annotations'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        val_dataset <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'categories'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'annotations'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        test_dataset <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'categories'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'annotations'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

        <span class="token comment"># 建立类别标签和数字id的对应关系, 类别id从0开始。</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> cls <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>classes<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            train_dataset<span class="token punctuation">[</span><span class="token string">'categories'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'id'</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">:</span> cls<span class="token punctuation">,</span> <span class="token string">'supercategory'</span><span class="token punctuation">:</span> <span class="token string">'mark'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
            val_dataset<span class="token punctuation">[</span><span class="token string">'categories'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'id'</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">:</span> cls<span class="token punctuation">,</span> <span class="token string">'supercategory'</span><span class="token punctuation">:</span> <span class="token string">'mark'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
            test_dataset<span class="token punctuation">[</span><span class="token string">'categories'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'id'</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">:</span> cls<span class="token punctuation">,</span> <span class="token string">'supercategory'</span><span class="token punctuation">:</span> <span class="token string">'mark'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> arg<span class="token punctuation">.</span>random_split<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"spliting mode: random split"</span><span class="token punctuation">)</span>
            train_img<span class="token punctuation">,</span> val_img<span class="token punctuation">,</span> test_img <span class="token operator">=</span> train_test_val_split_random<span class="token punctuation">(</span>indexes<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> arg<span class="token punctuation">.</span>split_by_file<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"spliting mode: split by files"</span><span class="token punctuation">)</span>
            train_img<span class="token punctuation">,</span> val_img<span class="token punctuation">,</span> test_img <span class="token operator">=</span> train_test_val_split_by_files<span class="token punctuation">(</span>indexes<span class="token punctuation">,</span> root_path<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        dataset <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'categories'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'annotations'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> cls <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>classes<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dataset<span class="token punctuation">[</span><span class="token string">'categories'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'id'</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">:</span> cls<span class="token punctuation">,</span> <span class="token string">'supercategory'</span><span class="token punctuation">:</span> <span class="token string">'mark'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment"># 标注的id</span>
    ann_id_cnt <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> k<span class="token punctuation">,</span> index <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>indexes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 支持 png jpg 格式的图片。</span>
        txtFile <span class="token operator">=</span> index<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'images'</span><span class="token punctuation">,</span> <span class="token string">'txt'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'.jpg'</span><span class="token punctuation">,</span> <span class="token string">'.txt'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'.png'</span><span class="token punctuation">,</span> <span class="token string">'.txt'</span><span class="token punctuation">)</span>
        <span class="token comment"># 读取图像的宽和高</span>
        im <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'images/'</span><span class="token punctuation">)</span> <span class="token operator">+</span> index<span class="token punctuation">)</span>
        height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> _ <span class="token operator">=</span> im<span class="token punctuation">.</span>shape
        <span class="token keyword">if</span> arg<span class="token punctuation">.</span>random_split <span class="token keyword">or</span> arg<span class="token punctuation">.</span>split_by_file<span class="token punctuation">:</span>
            <span class="token comment"># 切换dataset的引用对象，从而划分数据集</span>
            <span class="token keyword">if</span> index <span class="token keyword">in</span> train_img<span class="token punctuation">:</span>
                dataset <span class="token operator">=</span> train_dataset
            <span class="token keyword">elif</span> index <span class="token keyword">in</span> val_img<span class="token punctuation">:</span>
                dataset <span class="token operator">=</span> val_dataset
            <span class="token keyword">elif</span> index <span class="token keyword">in</span> test_img<span class="token punctuation">:</span>
                dataset <span class="token operator">=</span> test_dataset
        <span class="token comment"># 添加图像的信息</span>
        dataset<span class="token punctuation">[</span><span class="token string">'images'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'file_name'</span><span class="token punctuation">:</span> index<span class="token punctuation">,</span>
                                  <span class="token string">'id'</span><span class="token punctuation">:</span> k<span class="token punctuation">,</span>
                                  <span class="token string">'width'</span><span class="token punctuation">:</span> width<span class="token punctuation">,</span>
                                  <span class="token string">'height'</span><span class="token punctuation">:</span> height<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>originLabelsDir<span class="token punctuation">,</span> txtFile<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 如没标签，跳过，只保留图片信息。</span>
            <span class="token keyword">continue</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>originLabelsDir<span class="token punctuation">,</span> txtFile<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>
            labelList <span class="token operator">=</span> fr<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> label <span class="token keyword">in</span> labelList<span class="token punctuation">:</span>
                label <span class="token operator">=</span> label<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
                x <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                y <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                w <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                h <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

                <span class="token comment"># convert x,y,w,h to x1,y1,x2,y2</span>
                H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> _ <span class="token operator">=</span> im<span class="token punctuation">.</span>shape
                x1 <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> w <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> W
                y1 <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> h <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> H
                x2 <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">+</span> w <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> W
                y2 <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">+</span> h <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> H
                <span class="token comment"># 标签序号从0开始计算, coco2017数据集标号混乱，不管它了。</span>
                cls_id <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                width <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> x2 <span class="token operator">-</span> x1<span class="token punctuation">)</span>
                height <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> y2 <span class="token operator">-</span> y1<span class="token punctuation">)</span>
                dataset<span class="token punctuation">[</span><span class="token string">'annotations'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
                    <span class="token string">'area'</span><span class="token punctuation">:</span> width <span class="token operator">*</span> height<span class="token punctuation">,</span>
                    <span class="token string">'bbox'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token string">'category_id'</span><span class="token punctuation">:</span> cls_id<span class="token punctuation">,</span>
                    <span class="token string">'id'</span><span class="token punctuation">:</span> ann_id_cnt<span class="token punctuation">,</span>
                    <span class="token string">'image_id'</span><span class="token punctuation">:</span> k<span class="token punctuation">,</span>
                    <span class="token string">'iscrowd'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                    <span class="token comment"># mask, 矩形是从左上角点按顺时针的四个顶点</span>
                    <span class="token string">'segmentation'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> y2<span class="token punctuation">]</span><span class="token punctuation">]</span>
                <span class="token punctuation">}</span><span class="token punctuation">)</span>
                ann_id_cnt <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token comment"># 保存结果</span>
    folder <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'annotations'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>folder<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>folder<span class="token punctuation">)</span>
    <span class="token keyword">if</span> arg<span class="token punctuation">.</span>random_split <span class="token keyword">or</span> arg<span class="token punctuation">.</span>split_by_file<span class="token punctuation">:</span>
        <span class="token keyword">for</span> phase <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            json_name <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'annotations/{}.json'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>phase<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>json_name<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
                <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
                    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> phase <span class="token operator">==</span> <span class="token string">'val'</span><span class="token punctuation">:</span>
                    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> phase <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>
                    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Save annotation to {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>json_name<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        json_name <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_path<span class="token punctuation">,</span> <span class="token string">'annotations/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>arg<span class="token punctuation">.</span>save_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>json_name<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Save annotation to {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>json_name<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    yolo2coco<span class="token punctuation">(</span>arg<span class="token punctuation">)</span>
</code></pre> 
<p>2.下载代码</p> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/facebookresearch/detr.git
</code></pre> 
<p>然后修改几个东西</p> 
<p>首先去官方github上下载权重，修改需训练权重文件，新建一个change.py</p> 
<p>注意num_class要是类别数加1，例如你是2类，就改为3</p> 
<p>import torch<br> pretrained_weights = torch.load(‘detr-r50-e632da11.pth’)</p> 
<p>num_class = 3 # 这里是你自己数据集的类别数量 + 1</p> 
<pre><code class="prism language-python">pretrained_weights<span class="token punctuation">[</span><span class="token string">"model"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"class_embed.weight"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>resize_<span class="token punctuation">(</span>num_class<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
pretrained_weights<span class="token punctuation">[</span><span class="token string">"model"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"class_embed.bias"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>resize_<span class="token punctuation">(</span>num_class<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>pretrained_weights<span class="token punctuation">,</span> <span class="token string">"detr-r50_%d.pth"</span><span class="token operator">%</span>num_class<span class="token punctuation">)</span>
</code></pre> 
<p>然后执行 python change.py 得到 detr-r50-3.pth 这个权重</p> 
<p>接下来修改./models/detr.py</p> 
<p>305行的 num_classes = 类别数 + 1</p> 
<p>如果就可以训练了</p> 
<p>参数想改哪个就改哪个<br> 3.训练</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_backbone</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    position_embedding <span class="token operator">=</span> build_position_encoding<span class="token punctuation">(</span>args<span class="token punctuation">)</span>  <span class="token comment">##正余弦位置编码/</span>
    train_backbone <span class="token operator">=</span> args<span class="token punctuation">.</span>lr_backbone <span class="token operator">&gt;</span> <span class="token number">0</span>
    return_interm_layers <span class="token operator">=</span> args<span class="token punctuation">.</span>masks
    backbone <span class="token operator">=</span> Backbone<span class="token punctuation">(</span>args<span class="token punctuation">.</span>backbone<span class="token punctuation">,</span> train_backbone<span class="token punctuation">,</span> return_interm_layers<span class="token punctuation">,</span> args<span class="token punctuation">.</span>dilation<span class="token punctuation">)</span>   <span class="token comment">##resnet50</span>
    model <span class="token operator">=</span> Joiner<span class="token punctuation">(</span>backbone<span class="token punctuation">,</span> position_embedding<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>num_channels <span class="token operator">=</span> backbone<span class="token punctuation">.</span>num_channels
    <span class="token keyword">return</span> model
</code></pre> 
<pre><code class="prism language-bash">python main.py <span class="token parameter variable">--dataset_file</span> <span class="token string">"coco"</span> <span class="token parameter variable">--coco_path</span> coco_data <span class="token parameter variable">--epochs</span> <span class="token number">100</span> <span class="token parameter variable">--lr</span><span class="token operator">=</span>1e-4 <span class="token parameter variable">--batch_size</span><span class="token operator">=</span><span class="token number">2</span> <span class="token parameter variable">--num_workers</span><span class="token operator">=</span><span class="token number">4</span> <span class="token parameter variable">--output_dir</span><span class="token operator">=</span><span class="token string">"outputs"</span> <span class="token parameter variable">--resume</span><span class="token operator">=</span><span class="token string">"detr-r50_3.pth"</span>
</code></pre> 
<p>4.代码解读<br> 模型构建：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_classes <span class="token operator">=</span> <span class="token number">5</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset_file <span class="token operator">==</span> <span class="token string">"coco_panoptic"</span><span class="token punctuation">:</span>
        <span class="token comment"># for panoptic, we just add a num_classes that is large enough to hold</span>
        <span class="token comment"># max_obj_id + 1, but the exact value doesn't really matter</span>
        num_classes <span class="token operator">=</span> <span class="token number">250</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

    backbone <span class="token operator">=</span> build_backbone<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    transformer <span class="token operator">=</span> build_transformer<span class="token punctuation">(</span>args<span class="token punctuation">)</span>

    model <span class="token operator">=</span> DETR<span class="token punctuation">(</span>
        backbone<span class="token punctuation">,</span>
        transformer<span class="token punctuation">,</span>
        num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
        num_queries<span class="token operator">=</span>args<span class="token punctuation">.</span>num_queries<span class="token punctuation">,</span>
        aux_loss<span class="token operator">=</span>args<span class="token punctuation">.</span>aux_loss<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>masks<span class="token punctuation">:</span>
        model <span class="token operator">=</span> DETRsegm<span class="token punctuation">(</span>model<span class="token punctuation">,</span> freeze_detr<span class="token operator">=</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>frozen_weights <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    matcher <span class="token operator">=</span> build_matcher<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    weight_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'loss_ce'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'loss_bbox'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>bbox_loss_coef<span class="token punctuation">}</span>
    weight_dict<span class="token punctuation">[</span><span class="token string">'loss_giou'</span><span class="token punctuation">]</span> <span class="token operator">=</span> args<span class="token punctuation">.</span>giou_loss_coef
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>masks<span class="token punctuation">:</span>
        weight_dict<span class="token punctuation">[</span><span class="token string">"loss_mask"</span><span class="token punctuation">]</span> <span class="token operator">=</span> args<span class="token punctuation">.</span>mask_loss_coef
        weight_dict<span class="token punctuation">[</span><span class="token string">"loss_dice"</span><span class="token punctuation">]</span> <span class="token operator">=</span> args<span class="token punctuation">.</span>dice_loss_coef
    <span class="token comment"># TODO this is a hack</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>aux_loss<span class="token punctuation">:</span>
        aux_weight_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dec_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            aux_weight_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>k <span class="token operator">+</span> <span class="token string-interpolation"><span class="token string">f'_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> weight_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        weight_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>aux_weight_dict<span class="token punctuation">)</span>

    losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">,</span> <span class="token string">'boxes'</span><span class="token punctuation">,</span> <span class="token string">'cardinality'</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>masks<span class="token punctuation">:</span>
        losses <span class="token operator">+=</span> <span class="token punctuation">[</span><span class="token string">"masks"</span><span class="token punctuation">]</span>
    criterion <span class="token operator">=</span> SetCriterion<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> matcher<span class="token operator">=</span>matcher<span class="token punctuation">,</span> weight_dict<span class="token operator">=</span>weight_dict<span class="token punctuation">,</span>
                             eos_coef<span class="token operator">=</span>args<span class="token punctuation">.</span>eos_coef<span class="token punctuation">,</span> losses<span class="token operator">=</span>losses<span class="token punctuation">)</span>
    criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    postprocessors <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'bbox'</span><span class="token punctuation">:</span> PostProcess<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>masks<span class="token punctuation">:</span>
        postprocessors<span class="token punctuation">[</span><span class="token string">'segm'</span><span class="token punctuation">]</span> <span class="token operator">=</span> PostProcessSegm<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset_file <span class="token operator">==</span> <span class="token string">"coco_panoptic"</span><span class="token punctuation">:</span>
            is_thing_map <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>i<span class="token punctuation">:</span> i <span class="token operator">&lt;=</span> <span class="token number">90</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            postprocessors<span class="token punctuation">[</span><span class="token string">"panoptic"</span><span class="token punctuation">]</span> <span class="token operator">=</span> PostProcessPanoptic<span class="token punctuation">(</span>is_thing_map<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">0.85</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> postprocessors
</code></pre> 
<p>匈牙利匹配</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HungarianMatcher</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cost_class<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> cost_bbox<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> cost_giou<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cost_class <span class="token operator">=</span> cost_class
        self<span class="token punctuation">.</span>cost_bbox <span class="token operator">=</span> cost_bbox
        self<span class="token punctuation">.</span>cost_giou <span class="token operator">=</span> cost_giou
        <span class="token keyword">assert</span> cost_class <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">or</span> cost_bbox <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">or</span> cost_giou <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"all costs cant be 0"</span>

    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
        bs<span class="token punctuation">,</span> num_queries <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">"pred_logits"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>

        <span class="token comment"># We flatten to compute the cost matrices in a batch</span>
        out_prob <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">"pred_logits"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [batch_size * num_queries, num_classes]</span>
        out_bbox <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">"pred_boxes"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [batch_size * num_queries, 4]</span>

        <span class="token comment"># Also concat the target labels and boxes</span>
        tgt_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>v<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span>
        tgt_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>v<span class="token punctuation">[</span><span class="token string">"boxes"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span>
        cost_class <span class="token operator">=</span> <span class="token operator">-</span>out_prob<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> tgt_ids<span class="token punctuation">]</span>  <span class="token comment"># tgt_ids是[1,2,1,0，...]，该batch中所有的目标类别</span>

        <span class="token comment"># Compute the L1 cost between boxes</span>
        cost_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>cdist<span class="token punctuation">(</span>out_bbox<span class="token punctuation">,</span> tgt_bbox<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># tgt_ids该batch中所有的目标的位置[总目标数，4]</span>

        <span class="token comment"># Compute the giou cost betwen boxes</span>
        cost_giou <span class="token operator">=</span> <span class="token operator">-</span>generalized_box_iou<span class="token punctuation">(</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>out_bbox<span class="token punctuation">)</span><span class="token punctuation">,</span> box_cxcywh_to_xyxy<span class="token punctuation">(</span>tgt_bbox<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Final cost matrix</span>
        C <span class="token operator">=</span> self<span class="token punctuation">.</span>cost_bbox <span class="token operator">*</span> cost_bbox <span class="token operator">+</span> self<span class="token punctuation">.</span>cost_class <span class="token operator">*</span> cost_class <span class="token operator">+</span> self<span class="token punctuation">.</span>cost_giou <span class="token operator">*</span> cost_giou     <span class="token comment">##类别损失+bbox的l1损失+bbox的giou损失</span>
        C <span class="token operator">=</span> C<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_queries<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>

        sizes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>v<span class="token punctuation">[</span><span class="token string">"boxes"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span>
        indices <span class="token operator">=</span> <span class="token punctuation">[</span>linear_sum_assignment<span class="token punctuation">(</span>c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>C<span class="token punctuation">.</span>split<span class="token punctuation">(</span>sizes<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>i<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>j<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> indices<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">build_matcher</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> HungarianMatcher<span class="token punctuation">(</span>cost_class<span class="token operator">=</span>args<span class="token punctuation">.</span>set_cost_class<span class="token punctuation">,</span> cost_bbox<span class="token operator">=</span>args<span class="token punctuation">.</span>set_cost_bbox<span class="token punctuation">,</span> cost_giou<span class="token operator">=</span>args<span class="token punctuation">.</span>set_cost_giou<span class="token punctuation">)</span>
</code></pre> 
<p>用自己的数据集训练完，测试结果：</p> 
<pre><code class="prism language-bash">IoU metric: bbox
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.712</span>
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>      <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.911</span>
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.75</span>      <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.779</span>
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span> small <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.049</span>
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>medium <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.443</span>
 Average Precision  <span class="token punctuation">(</span>AP<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span> large <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.752</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span>  <span class="token number">1</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.452</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span> <span class="token number">10</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.814</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>   all <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.846</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span> small <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.189</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span>medium <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.645</span>
 Average Recall     <span class="token punctuation">(</span>AR<span class="token punctuation">)</span> @<span class="token punctuation">[</span> <span class="token assign-left variable">IoU</span><span class="token operator">=</span><span class="token number">0.50</span>:0.95 <span class="token operator">|</span> <span class="token assign-left variable">area</span><span class="token operator">=</span> large <span class="token operator">|</span> <span class="token assign-left variable">maxDets</span><span class="token operator">=</span><span class="token number">100</span> <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.878</span>
</code></pre> 
<p>比yolov5s P=0.96，R=0.90精度低一些。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/041094f3247d34a63f219049c5fc1df2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">常见nginx管理及配置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5c0be9bcd712a4ab3786783202762ded/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Quartus FPGA工程创建流程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>