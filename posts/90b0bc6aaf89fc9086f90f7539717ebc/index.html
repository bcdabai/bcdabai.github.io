<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【研一小白论文精读】《MoCo》 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【研一小白论文精读】《MoCo》" />
<meta property="og:description" content="其实之前读simclr那篇论文的时候已经涉及到一些moco的内容，现在的moco已经更新到了v3。
moco是一种典型的contrastive unsupervised learning。
Momentum Contrast for Unsupervised Visual Representation Learning 在moco提出的时候现有的contrastive learning有两种手段：
第一种是end to end，就是一个sample经过不同的图像增强作为querry和key，放到两个encoder里面，然后算相似程度，同一个样本产生的querry和key相似程度是高的，不同样本产生的相似程度是低的，这种方法对两边的encoder都做传递，这一点和attention很像，互搏。
第二种呢则是memory bank，memory bank就是锁住一边的key，其实就相当于把所有的key存在一个bank里，那么每次一个新图像进来过encoder得到一个querry的时候，从bank中sample出一些representation和这个querry来做比较，那么显然这一部分是不需要传递梯度的。
那么最后就是moco
moco的原理其实非常简单，就是一个batch的图像仍然经过不同的图像增强策略，左边这支叫querry，右边这支叫key，querry过一个encoder，key也过一个encoder，不过这个encoder是momentum ecdoer。然后呢我们就得到了他们的represention，但是key的represention不仅有这个batch的represention，还有之前batch保存下来的represention，所以我们看到这里其实是维护了一个队列。这样做的好处就是比起之前的simclr一个batch内相互做contrastive learning，现在一个batch通过很少的代价获得了更多的negative samples，那么还是两个represention之间计算相似度来得到这个contrastive loss。
而这个contrastive loss如上图就是我们很熟悉的NCE，分子部分就是querry和对应的key的相似程度，分母就是querry和其他所有的key他们对应的相似程度的和，这里的“套”就是temperature，用来控制loss的分布，这就是contrastive loss的部分。
momentum ecdoer部分就是我在更新了querry的encoder之后呢，并不是直接复制到key的encoder里面，而是我已一定的比例更新这个key。
Methodology 接下来结合作者提供的伪代码来看一下：
代码一开始momentum encoder和encoder的参数是相等的已经初始化好了，然后对于一个sample来说，做不同的两种图像增强策略，得到querry的sample和key的sample，分别送到两个encoder里面。因为key是不需要计算梯度的，所以detach一下。先把q的vetor和k的vetocr做一个变形，然后两个做内积，就产生positive loss了。那么negaive loss就是所有的q和之前维护的队列中的key一起做个矩阵乘法。然后把得到的positive loss和negaive loss做串起来，传入这个形如softmax加CrossEntropy的loss中计算。这里非常巧妙的一点就是这里的logits有n行k&#43;1列，第一列是positive sample，其余的key列都是样本和negaive的相关程度。告诉CrossEntropy index为0的这一列是positive sample。然后再做传递，更新一下encoder network的参数，然后再用momentum更新一下momentum encoder，到此网络就结束了。最后维护一下key的队列，然后把最早的一个bacth的样本弹出来。
以上就是moco的实现方法。
Resuluts：Linear Classification 实验结果也是对比了之前end to end还有memory bank，随着negative sample的增加，模型的效果肯定也越来越好。
作者也测试了不同的momentum，应该以怎样的速率更新这个momentum encoder呢，可以看到这些结果。
这里其实是一个非常有意思的实验，shufflinfg batch normalization，作者说其实包括之前的论文也有汇报，我们的batch normalization其实会阻碍unsupervised learning的，阻碍我们的模型学到好的representation，那么可能的原因就是network在做batch normalization时应用到了一个batch中所有样本的信息，那么在这个normalization的过程中，不同不同样本之间的信息可能就泄露给对方了，这样呢就会使contrastive loss更容易达成，为了克服这个困难作者就使用了shufflinfg batch normalization，具体来说就是作者在多块GPU上训练了这个模型，他就是在每一个GPU上做 batch normalization，同时因为有两支，一支是key，一支是query，query又是打乱顺序之后送到GPU里的，也就说到最后对应的query和key不是从同一个batch normalization里出来的，这个技巧就称之为shufflinfg batch normalization。并且可以看到使用linear layer，也就是虚线，可以看到区别不是很明显，linear layer毕竟还是很强的模型，但是如果用KNN作为分类器，有没有shufflinfg batch normalization还是有影响的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/90b0bc6aaf89fc9086f90f7539717ebc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-13T09:57:12+08:00" />
<meta property="article:modified_time" content="2022-04-13T09:57:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【研一小白论文精读】《MoCo》</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>其实之前读simclr那篇论文的时候已经涉及到一些moco的内容，现在的moco已经更新到了v3。<br> moco是一种典型的contrastive unsupervised learning。</p> 
<h2><a id="Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_2"></a>Momentum Contrast for Unsupervised Visual Representation Learning</h2> 
<p>在moco提出的时候现有的contrastive learning有两种手段：<br> <img src="https://images2.imgbox.com/ba/1e/ZPVF7Wua_o.png" alt="在这里插入图片描述"><br> 第一种是end to end，就是一个sample经过不同的图像增强作为querry和key，放到两个encoder里面，然后算相似程度，同一个样本产生的querry和key相似程度是高的，不同样本产生的相似程度是低的，这种方法对两边的encoder都做传递，这一点和attention很像，互搏。<br> 第二种呢则是memory bank，memory bank就是锁住一边的key，其实就相当于把所有的key存在一个bank里，那么每次一个新图像进来过encoder得到一个querry的时候，从bank中sample出一些representation和这个querry来做比较，那么显然这一部分是不需要传递梯度的。<br> 那么最后就是moco<br> <img src="https://images2.imgbox.com/8e/5d/EujOqnAT_o.png" alt="在这里插入图片描述"><br> moco的原理其实非常简单，就是一个batch的图像仍然经过不同的图像增强策略，左边这支叫querry，右边这支叫key，querry过一个encoder，key也过一个encoder，不过这个encoder是momentum ecdoer。然后呢我们就得到了他们的represention，但是key的represention不仅有这个batch的represention，还有之前batch保存下来的represention，所以我们看到这里其实是维护了一个队列。这样做的好处就是比起之前的simclr一个batch内相互做contrastive learning，现在一个batch通过很少的代价获得了更多的negative samples，那么还是两个represention之间计算相似度来得到这个contrastive loss。<br> <img src="https://images2.imgbox.com/a2/e9/i4ZOu3Zg_o.png" alt="在这里插入图片描述"><br> 而这个contrastive loss如上图就是我们很熟悉的NCE，分子部分就是querry和对应的key的相似程度，分母就是querry和其他所有的key他们对应的相似程度的和，这里的“套”就是temperature，用来控制loss的分布，这就是contrastive loss的部分。<br> <img src="https://images2.imgbox.com/38/25/ULH4uuyl_o.png" alt="在这里插入图片描述"><br> momentum ecdoer部分就是我在更新了querry的encoder之后呢，并不是直接复制到key的encoder里面，而是我已一定的比例更新这个key。</p> 
<h3><a id="Methodology_14"></a>Methodology</h3> 
<p>接下来结合作者提供的伪代码来看一下：<br> <img src="https://images2.imgbox.com/32/cd/AiS4Prb9_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/dc/a1/YD7qKgAx_o.png" alt="在这里插入图片描述"><br> 代码一开始momentum encoder和encoder的参数是相等的已经初始化好了，然后对于一个sample来说，做不同的两种图像增强策略，得到querry的sample和key的sample，分别送到两个encoder里面。因为key是不需要计算梯度的，所以detach一下。先把q的vetor和k的vetocr做一个变形，然后两个做内积，就产生positive loss了。那么negaive loss就是所有的q和之前维护的队列中的key一起做个矩阵乘法。然后把得到的positive loss和negaive loss做串起来，传入这个形如softmax加CrossEntropy的loss中计算。这里非常巧妙的一点就是这里的logits有n行k+1列，第一列是positive sample，其余的key列都是样本和negaive的相关程度。告诉CrossEntropy index为0的这一列是positive sample。然后再做传递，更新一下encoder network的参数，然后再用momentum更新一下momentum encoder，到此网络就结束了。最后维护一下key的队列，然后把最早的一个bacth的样本弹出来。<br> 以上就是moco的实现方法。</p> 
<h3><a id="ResulutsLinear_Classification_21"></a>Resuluts：Linear Classification</h3> 
<p><img src="https://images2.imgbox.com/db/cf/7K1uUQqW_o.png" alt="在这里插入图片描述"><br> 实验结果也是对比了之前end to end还有memory bank，随着negative sample的增加，模型的效果肯定也越来越好。<br> <img src="https://images2.imgbox.com/84/09/zrbKhH3L_o.png" alt="在这里插入图片描述"></p> 
<p>作者也测试了不同的momentum，应该以怎样的速率更新这个momentum encoder呢，可以看到这些结果。<img src="https://images2.imgbox.com/9f/4c/VdbDRlyM_o.png" alt="在这里插入图片描述"><br> 这里其实是一个非常有意思的实验，shufflinfg batch normalization，作者说其实包括之前的论文也有汇报，我们的batch normalization其实会阻碍unsupervised learning的，阻碍我们的模型学到好的representation，那么可能的原因就是network在做batch normalization时应用到了一个batch中所有样本的信息，那么在这个normalization的过程中，不同不同样本之间的信息可能就泄露给对方了，这样呢就会使contrastive loss更容易达成，为了克服这个困难作者就使用了shufflinfg batch normalization，具体来说就是作者在多块GPU上训练了这个模型，他就是在每一个GPU上做 batch normalization，同时因为有两支，一支是key，一支是query，query又是打乱顺序之后送到GPU里的，也就说到最后对应的query和key不是从同一个batch normalization里出来的，这个技巧就称之为shufflinfg batch normalization。并且可以看到使用linear layer，也就是虚线，可以看到区别不是很明显，linear layer毕竟还是很强的模型，但是如果用KNN作为分类器，有没有shufflinfg batch normalization还是有影响的。<br> 再接下来就是吊打前任工作的环节：<br> <img src="https://images2.imgbox.com/68/22/7xvnstRR_o.png" alt="在这里插入图片描述"><br> 从模型复杂度和性能表现来看还是不错的，对比当时之前的方法也是最好的。</p> 
<h3><a id="ResultsTransferring_31"></a>Results：Transferring</h3> 
<p><img src="https://images2.imgbox.com/09/49/DHFzQtTy_o.png" alt="在这里插入图片描述"><br> 除了分类还有Transferring，作者在PASCAL VOC上做目标检测和在COCO数据集上做目标检测语义分割等，从不同的模型培训出来的moco，再对比之前的方法，就是好啊。<br> <img src="https://images2.imgbox.com/97/98/oeAIBFju_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Improved_Baselines_with_Momentum_Contrastive_Learning_35"></a>Improved Baselines with Momentum Contrastive Learning</h2> 
<p>随着simclr的提出，作者对moco又做了小部分的改进，也就是MoCo v2。<br> 这其中包含三条改进：<br> 1.An MLP head<br> 原来的query encoder和momentum encoder加上一层什么什么layer？把后面的head变成MLP<br> 2.Extra blur augmentation<br> 图像增强方面额外增加了模糊这种增强<br> 3.Cosine learning rate schedule<br> 把学习率改成一个余弦函数<br> <img src="https://images2.imgbox.com/01/93/zv8Z411r_o.png" alt="在这里插入图片描述"><br> 以mocov1作为一个baseline，加上这些东西性能表现就是好。<br> <img src="https://images2.imgbox.com/d2/f0/ZwNxi5No_o.png" alt="在这里插入图片描述"><br> 并对比同样使用这些trick策略的simclr，mocoV2的优势就是batch_size小，因为在本文中维护了一个队列，并且在队列中只存放了key representation，那显然这样又节省了内存，而且还可增加很多negative samples，这是一个非常好的方法。<br> <img src="https://images2.imgbox.com/c2/37/nhhY4ypn_o.png" alt="在这里插入图片描述"><br> 最后还有对比之前的end to end，本文使用的内存也好，训练的时间也好还是有很大的优势的。</p> 
<h2><a id="An_Empirical_Study_of_Training_SelfSupervised_Vision_Transformers_50"></a>An Empirical Study of Training Self-Supervised Vision Transformers</h2> 
<p>之前不管是moco v1还是moco v2之前都是用resnet作为backbone的，这篇论文主要就是把resnet换成vision transformers。最大的改动了就是取消了原来的队列，之前这个队列存储了计算的所有key，帮助我们在不扩大batch_size的情况下提供更多的negative samples，而作者现在说已经没有必要了，现在已经可以训练很大的batch_size了，无语了哈哈。第二点改动就是原来的不管是query encoder还是momentum encoder使用的都是backbone加pred mlp这种结构，那么在这篇论文中呢，作者把BYOL的东西搬进来了就是加了两层proj mlp。<br> <img src="https://images2.imgbox.com/3d/ee/vxjA9qKO_o.png" alt="在这里插入图片描述"><br> 那么在应用以上两项的改进下，用ResNet-50作为backbone的情况下，对比相对于之前版本的moco，性能是有提升的。做好这些准备之后就要开始真正面对transformer encoder了。</p> 
<h3><a id="Stability_54"></a>Stability</h3> 
<p>虽然我们再训练transformer的时候能够得到一个训练不错的模型，但是在这个不错的模型基础上隐藏了很多不稳定的因素，影响了训练的过程，作者为了揭示这个不稳定性，使用了这个kNN curves。kNN就是在训练完一个epoch之后，或者是几个循环迭代之后呢加入几个有标记的样本，然后用kNN测试这个representation他的表现。<br> 1.bacth_size<br> 在bacth_size相对较少的情况比如2048，曲线相对比较平稳，随着batch_size增大，虽然能够享受到大的bacth_size所带来的contrastive loss，但是模型变得更加不稳定了，经常会出现断崖式的下降。<br> <img src="https://images2.imgbox.com/bf/38/h8LqlAWL_o.png" alt="在这里插入图片描述"><br> 2.learning rate<br> 同样呢，learning rate也是，我们再选择相对较低的learning rate还是很平稳的，但是随着learning rate的提升，不稳定性也随之凸显出来。<br> <img src="https://images2.imgbox.com/8d/4d/bKQVAlxW_o.png" alt="在这里插入图片描述"><br> 3.optimizer<br> <img src="https://images2.imgbox.com/18/fb/dX024hxM_o.png" alt="在这里插入图片描述"><br> 我们看到不管是哪种curve，都会在准确率上大幅下降，然后再缓缓地提升回来。为什么我们训练transformer模型会有这样的问题呢？以及这样的问题我们是否有办法先去克服它呢？</p> 
<h2><a id="A_Trick_for_Improving_Stability_65"></a>A Trick for Improving Stability</h2> 
<h4><a id="Why_66"></a>Why?</h4> 
<p><img src="https://images2.imgbox.com/d4/34/Sonin60F_o.png" alt="在这里插入图片描述"></p> 
<p>通过观察发现呢，在我们的性能出现下降的时候，因为我们突然产生一个非常大的Gradinet，然后这个Gradinet先从第一层出现，在后面几个Iteration之后到了最后一层。也就是说这个大的Gradinet的尖刺是从浅的一层传到深的一层。那么更进一步的研究表明这个尖刺来自于从image patch到patch embedding的时候，我们训练MLP所产生大的梯度尖刺。</p> 
<h4><a id="How_wo_fix_71"></a>How wo fix?</h4> 
<p>那么怎么样规避这个问题呢？直接在这个patch projection也就是patch embedding之后把这个梯度停掉，前面的MLP就保持随机的初始化状态。于是使用随机初始化的MLP作为patch embedding，甚至比训练这个MLP效果还要好，训练过程中也更加的稳定。<br> <img src="https://images2.imgbox.com/45/7c/uPRYwIUL_o.png" alt="在这里插入图片描述"><br> 而且同样的特性，不仅在moco观察到，如果在SimCLR，BYOL,或者是SwAV这些模型中都是用vision transformer这个model，这些算法也都会出现性能的突然的下降这个问题，但是只要把前面的Gradient停掉，使用随机初始化MLP直接作为modle embedding，训练就会变得稳定。<br> 这真是一个很有意思的发现，作者还尝试了BatchNorm，WeightNorm但是这些都不能改变上面遇到的这些问题。作者还试了Grandient clip，相当于把Grandient限制到一定程度，作者发现把这个Grandient 限制的足够小，也能达到平稳训练的效果，但是本质和stop Grandient 是一样的。虽然是个治标不治本的方法，从原理上解决还有待进一步的研究。如果前面用resnet-50来提取image embedding，用VGG这样的网络或者用卷积神经网络提取embedding，如果将这种embedding作为transformer的input作为token效果会怎么样呢？</p> 
<h3><a id="Result_76"></a>Result</h3> 
<p><img src="https://images2.imgbox.com/f8/d1/Oi6YVytg_o.png" alt="在这里插入图片描述"><br> 这里是几种transformer的配置，他们的计算量相对于resnet-50的对比，还有TPU，训练的时间，这都是钱啊。</p> 
<p><img src="https://images2.imgbox.com/dd/0d/DinmZblW_o.png" alt="在这里插入图片描述"><br> 这里是对比的不同的backbone model，和不同的learning frameworks的对比，可以看到再借鉴了BYOL里面的projection之后呢，moco的方法在之前的几个backbone都取得了最好的效果。<br> 下面的图，横轴使用resnet-50，纵轴使用ViT，做出来的准确率，可以看出SimClR和moco都比较偏向于vision transformer作为backbone，但是SwAV和BYOL对什么作为backbone没有有太大区别。</p> 
<h3><a id="Ablations_83"></a>Ablations</h3> 
<p>再此基础上作者又汇报了一些玻璃实验：<br> <img src="https://images2.imgbox.com/90/c7/hbND7m0k_o.png" alt="在这里插入图片描述"><br> position embedding还是使用现成的sin-cos最好，不加position embedding当然是不可以的。<br> <img src="https://images2.imgbox.com/5b/ed/bqG4tsco_o.png" alt="在这里插入图片描述"><br> class token也就是CLS，如果没有class token行不行呢？显然是不行的，性能是大幅度下降的。即便把所有的token集合起来，性能的表现也是不如单独说一个class tolen来的好。</p> 
<p><img src="https://images2.imgbox.com/c9/71/MCe19B1f_o.png" alt="在这里插入图片描述"><br> 还有MLP head里面的BatchNormalization。<br> <img src="https://images2.imgbox.com/ed/d6/caLV9CMW_o.png" alt="在这里插入图片描述"><br> prediction head的影响就是从BYOL上借鉴过来的，性能还是有些提升的。<br> <img src="https://images2.imgbox.com/92/63/E9eVXm9o_o.png" alt="在这里插入图片描述"><br> 模型更新的多快<br> <img src="https://images2.imgbox.com/90/d3/QzDcjhR4_o.png" alt="在这里插入图片描述"><br> 训练的时长，等等。</p> 
<h3><a id="More_results_98"></a>More results</h3> 
<p>最后使用了transformer，不免和resnet在<strong>参数量</strong>和<strong>准确率</strong>上比较，参考下图：<br> <img src="https://images2.imgbox.com/5d/06/LfN3lUkt_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Transfer_learning_101"></a>Transfer learning</h3> 
<p>最后作者也是测试了迁移学习，就是现在image net上pretraining，在拿到别的数据集上fine-turn，可以看到大部分情况下使用self-supervised上做pretraining，然后再另一个数据集上做fine-turn，大部分情况下是有改善的，除了再宠物数据集上性能有所降低。<br> <img src="https://images2.imgbox.com/ed/27/MsOCY10J_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/402128fa9ab31c0a6dbfad2276d61c6e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于访问对象存储中的影像</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f35ac95d0c57dd6409553e41655c36b8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Photoshop简介</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>