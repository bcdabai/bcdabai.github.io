<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Centos7&#43;Hadoop3.1.2&#43;HBase2.2.0搭建过程 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Centos7&#43;Hadoop3.1.2&#43;HBase2.2.0搭建过程" />
<meta property="og:description" content="centos7系统安装 光盘驱动外接服务器,服务器开机F12进BISO安装系统,选择any other systyem,其他默认即可,一直点finish,服务器最终重启进入安装程序.
系统安装时，系统盘的分区如下：
/home 50G(51200M) /var 2G(2048M) /boot 1G(1024M) swap 20G(20480M) / 剩下的容量 服务器基础配置 注意:配置之前先熟悉linux基本命令 cd vi cat 1. 网卡bonding 注意:配置之前先熟悉网卡bond的作用 查看 /etc/sysconfig/network-scripts 目录可以看到服务器自带的四个网卡文件
ifcfg-em1,ifcfg-em2,ifcfg-p2p1,ifcfg-p2p2(名字可能有稍微差别),
em为普通网卡,pxpx为光纤网卡.
我们需要使用光纤网卡并且对其做bond0操作
首先编辑 ifcfg-p2p1 文件 修改成:
DEVICE=p2p1 ONBOOT=yes BOOTPROTO=none MASTER=bond0 SLAVE=yes 再编辑ifcfg-p2p2 文件 修改成:
DEVICE=p2p2 ONBOOT=yes BOOTPROTO=none MASTER=bond0 SLAVE=yes 在同目录下创建ifcfg-bond0文件,编辑文件添加内容(这里的IPADDR是bond0的IP地址,根据机器的实际情况修改):
DEVICE=bond0 BOOTPROTO=static TYPE=bond ONBOOT=yes IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 BONDING_OPTS=&#34;mode=0 miimon=100&#34; DNS1=202.118.1.29 DNS2=202.118.1.53 编辑/etc/resolv.conf,修改成如下:
nameserver 202.118.1.29 nameserver 202.118.1.53 执行命令systemctl stop firewalld.service关闭防火墙,执行systemctl disable firewalld.service禁止防火墙开机自启
然后执行下面的命令重启网络" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/cdb05c4f8c2e384a06a8e2ceb5fc667b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-09-12T17:41:38+08:00" />
<meta property="article:modified_time" content="2019-09-12T17:41:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Centos7&#43;Hadoop3.1.2&#43;HBase2.2.0搭建过程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="centos7_1"></a>centos7系统安装</h2> 
<p>光盘驱动外接服务器,服务器开机F12进BISO安装系统,选择any other systyem,其他默认即可,一直点finish,服务器最终重启进入安装程序.</p> 
<p>系统安装时，系统盘的分区如下：</p> 
<pre><code>/home     50G(51200M)
/var      2G(2048M)
/boot     1G(1024M)
swap      20G(20480M)
/         剩下的容量
</code></pre> 
<h2><a id="_15"></a>服务器基础配置</h2> 
<p><font size="4"><mark>注意:配置之前先熟悉linux基本命令 cd vi cat</mark> </font></p> 
<p><font size="6">1. 网卡bonding </font></p> 
<p><font size="3"><mark>注意:配置之前先熟悉网卡bond的作用</mark> </font></p> 
<p>查看 /etc/sysconfig/network-scripts 目录可以看到服务器自带的四个网卡文件<br> ifcfg-em1,ifcfg-em2,ifcfg-p2p1,ifcfg-p2p2(名字可能有稍微差别),<br> em为普通网卡,pxpx为光纤网卡.</p> 
<p>我们需要使用光纤网卡并且对其做<mark>bond0操作</mark></p> 
<blockquote> 
 <p>首先编辑 ifcfg-p2p1 文件 修改成:</p> 
</blockquote> 
<pre><code>DEVICE=p2p1
ONBOOT=yes
BOOTPROTO=none
MASTER=bond0
SLAVE=yes
</code></pre> 
<blockquote> 
 <p>再编辑ifcfg-p2p2 文件 修改成:</p> 
</blockquote> 
<pre><code>DEVICE=p2p2
ONBOOT=yes
BOOTPROTO=none
MASTER=bond0
SLAVE=yes
</code></pre> 
<blockquote> 
 <p>在同目录下创建ifcfg-bond0文件,编辑文件添加内容(这里的IPADDR是bond0的IP地址,根据机器的实际情况修改):</p> 
</blockquote> 
<pre><code>DEVICE=bond0
BOOTPROTO=static
TYPE=bond
ONBOOT=yes
IPADDR=192.168.1.10
NETMASK=255.255.255.0
GATEWAY=192.168.1.254
BONDING_OPTS="mode=0 miimon=100"
DNS1=202.118.1.29
DNS2=202.118.1.53

</code></pre> 
<blockquote> 
 <p>编辑/etc/resolv.conf,修改成如下:</p> 
</blockquote> 
<pre><code>nameserver 202.118.1.29
nameserver 202.118.1.53
</code></pre> 
<blockquote> 
 <p>执行命令<code>systemctl stop firewalld.service</code>关闭防火墙,执行<code>systemctl disable firewalld.service</code>禁止防火墙开机自启</p> 
</blockquote> 
<blockquote> 
 <p>然后执行下面的命令重启网络<br> (如果重启报错,尝试检查前面修改的文件是否有改错的,还不行的话执行service NetworkManager stop后再次执行下面命令)</p> 
</blockquote> 
<pre><code>service network restart
</code></pre> 
<p>遇到的问题：</p> 
<ol><li>在生成ifcfg-bond0文件时，将bond0的ipaddr改错了，然后配置完重启网络后发现不对，在重新修改bond0文件，再次重启网络发现bond0不再生效。</li></ol> 
<p>解决办法：<mark>删除bonding设备</mark> 执行<code>rm -f ifcfg-bond0</code>删除bond0文件，然后注释掉ifcfg-p2p1,ifcfg-p2p2最后几行，如下</p> 
<pre><code>DEVICE=p2p2
ONBOOT=yes
BOOTPROTO=none
#MASTER=bond0
#SLAVE=yes
</code></pre> 
<p>然后重启网络，这时bond0不存在了，再从头开始配置即可。</p> 
<hr> 
<p><font size="6">2. SSH免密登录 </font></p> 
<p><font size="3"><mark>注意:先了解SSH基本原理</mark></font></p> 
<p>以两台服务器之间的SSH配置为例,首先分别对两台机器的系统文件修改:</p> 
<ul><li> <p>第一台执行<code>vi /etc/hostname</code>修改主机名,将文件内容改为s6<br> <mark>(这个是对应的主机名,不同主机改成自己对应名字)</mark>,对第二台进行相应操作改成s7,</p> </li><li> <p>两台机器都执行<code>vi /etc/hosts</code>在文件中添加ip映射:</p> </li></ul> 
<pre><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.60 s6
192.168.1.70 s7
192.168.1.80 s8
</code></pre> 
<ul><li> <p>两台机器都执行<code>ssh-keygen -t rsa</code>生成公钥和私钥文件(公钥文件用于登录别的机器,A机器上有B机器的公钥,则B可以登录A),生成的文件在/root/.ssh目录下.</p> </li><li> <p>在s9上执行<code>ssh-copy-id -i s7</code>将s6公钥拷贝到s7机器上</p> </li><li> <p>在/root/.ssh目录下执行cat id_rsa.pub &gt;&gt; authorized_keys<br> (<mark>authorized_keys是存放所有公钥的文件,包括本机和别的机器</mark>)</p> </li><li> <p>有多台机器配置ssh时,每台机器都需要有包含所有公钥的文件authorized_keys,可使用scp命令进行拷贝,如下</p> </li></ul> 
<pre><code>scp /.ssh/authorized_keys root@s7:/.ssh/ 
</code></pre> 
<pre><code>scp /.ssh/authorized_keys root@s8:/.ssh/
</code></pre> 
<p>配置完成之后,即可使用ssh免密登录其他机器(第一次登陆时可能要输入密码,第二次登陆就不需要了)</p> 
<hr> 
<p><font size="6">3. 硬盘 </font></p> 
<p><font size="3"><mark>注意:先了解linux硬盘分区挂载基本命令,linux 的dev目录是什么（如果在安装系统时已经预先进行了硬盘分区可省略此步骤，但是预先分区并没有格式化硬盘，仍需要手动格式化）</mark> </font></p> 
<p>每台服务器一共安装了4块4T机械硬盘（实际容量3.6T），在使用硬盘之前需要对硬盘进行格式化和分区，我们对每块硬盘分一个区，挂载在提前创建好的文件夹目录下。</p> 
<blockquote> 
 <p>执行命令查看四块硬盘的名称,找到容量为4000G的硬盘，名字一般为sda,sdb,sdc,sdd</p> 
</blockquote> 
<pre><code>fdisk -l 
</code></pre> 
<h2><a id="font_size5__font_148"></a><font size="5"> 分区 </font></h2> 
<blockquote> 
 <p>以其中一块硬盘为例进行格式化和分区操作，执行命令进入分区工具</p> 
</blockquote> 
<pre><code>parted /dev/sda 
</code></pre> 
<p>执行命令将分区格式改为gpt</p> 
<pre><code>mklabel gpt
</code></pre> 
<p>然后执行<code>print</code>命令可以看到sda硬盘分区状态，执行<code>mkpart primary 0 4001gb</code>创建一个分区，容量从0开始到4001G全部空间，有提示请忽略，再次<code>print</code>可以看到分区已经建立,执行<code>quit</code>退出分区工具。</p> 
<h2><a id="font_size5_font_159"></a><font size="5">格式化和挂载 </font></h2> 
<p>执行<code>mkfs.ext4 -F /dev/sda1</code>对硬盘进行格式化，由于硬盘较大，等待命令执行完成。<br> 在根目录/下创建文件夹，用于挂载硬盘，执行<code>mkdir -p hddata/1/dfs</code>创建文件夹，执行<code>mount /dev/sda1 /hddata/1/dfs</code>将硬盘挂在在对应目录下。</p> 
<p>编辑/etc/fstab,最后四行为我们添加的内容,修改完后,每次开机硬盘就会自动挂载.</p> 
<pre><code># /etc/fstab
# Created by anaconda on Fri Jul 26 10:07:51 2019
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/centos-root /                       xfs     defaults        0 0
UUID=76428df8-0818-469e-ab82-8dc6f9a11a93 /boot                   xfs     defaults        0 0
UUID=076D-C578          /boot/efi               vfat    umask=0077,shortname=winnt 0 0
/dev/mapper/centos-home /home                   xfs     defaults        0 0
/dev/mapper/centos-var  /var                    xfs     defaults        0 0
/dev/mapper/centos-swap swap                    swap    defaults        0 0
/dev/sda1 /hddata/1/dfs   ext4 defaults 0 0
/dev/sdb1 /hddata/2/dfs   ext4 defaults 0 0
/dev/sdc1 /hddata/3/dfs   ext4 defaults 0 0
/dev/sdd1 /hddata/4/dfs   ext4 defaults 0 0
</code></pre> 
<hr> 
<p><font size="6">4. ntp时间同步</font></p> 
<ul><li> <p>对每台服务器执行<code>yum install -y ntp</code>安装ntp,并且执行<code>systemctl start ntpd</code>启动ntp服务,执行<code>systemctl enable ntpd</code>开机自启ntp.</p> </li><li> <p>对主服务器(<mark>这里我是s10</mark>)/etc/ntp.conf文件进行修改,在原有的基础上添加如下,并且注释掉了4行,<br> 倒数第二行是设置本机为时间服务器.</p> </li></ul> 
<pre><code>#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst
server 127.127.1.0
fudge  127.127.1.0 stratum 10
</code></pre> 
<ul><li> <p>保存修改后执行<code>systemctl restart ntpd</code>重启ntp,执行<code>ntpstat</code>可以发现已经向本地同步时间.有时执行过后依然没向本地同步时间，可以稍微等一会儿再执行一次，需要一点时间，也可执行如下命令进行查看：<code>watch ntpq -p</code></p> </li><li> <p>对从服务器(<mark>我这里是s9</mark>)/etc/ntp.conf文件修改,</p> </li></ul> 
<pre><code>#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst
server s10
</code></pre> 
<ul><li> <p>保存修改后执行<code>systemctl restart ntpd</code>重启ntp,执行<code>ntpstat</code>可以发现已经向s10同步时间(这个过程需要等待15分钟左右),如果一直没同步,执行<code>ntpdate -u s10</code>可向s10手动同步时间,若此命令成功应该没有问题.</p> </li><li> <p>执行<code>hwclock -w</code>将系统时间同步到BIOS硬件时间,若执行<code>date</code>查看发现系统时间是EDT，依次执行下面两个命令修改linux系统的时间EDT为CST.</p> </li></ul> 
<pre><code>mv /etc/localtime /etc/localtime.bak
ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</code></pre> 
<pre><code>EDT：指美国东部夏令时间，波士顿、纽约市、华盛顿哥伦比亚特区，都在这个时区内，跟北京时间有12小时的时差，晚12小时。

CST：可以指下面两种：

1. 美国中部标准时间(西六区，-6:00)，中国是东八区(+8:00)，北京时间比美国中部标准时间早14个小时。3:45 PM CST 是北京时间凌晨1：45。
2. 中澳大利亚标准时间(+10:30)，中国是东八区(+8:00)，北京时间比中澳大利亚标准时间晚2个半小时。3:45 PM CST 是北京时间下午上午5:45。
</code></pre> 
<p><font size="6">5. 基本软件安装配置 </font></p> 
<p><font size="3"><mark>注意:要安装的有jdk1.8,hadoop,hbase,zookeeper,spark</mark> </font></p> 
<p>jdk下载地址:<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" rel="nofollow">点击</a></p> 
<p>hadoop下载地址:<a href="" rel="nofollow"></a></p> 
<p>hbase下载地址:<a href="" rel="nofollow"></a></p> 
<p>zookeeper下载地址:<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.5.5/" rel="nofollow">点击</a></p> 
<p>spark下载地址:<a href="" rel="nofollow"></a></p> 
<h5><a id="_245"></a>软件安装</h5> 
<ul><li>将安装包下载到/software下,执行命令进行解压可以得到解压后的文件夹</li></ul> 
<pre><code>tar -zxvf (压缩包名) 
</code></pre> 
<ul><li>编辑/etc/profile文件,添加环境变量:</li></ul> 
<pre><code class="prism language-sh">export JAVA_HOME=/root/software/jdk1.8.0_221
export HADOOP_HOME=/root/software/hadoop-3.1.2
export ZOOKEEPER_HOME=/root/software/apache-zookeeper-3.5.5-bin
export HBASE_HOME=/root/software/hbase-2.2.0
export HBASE_CONF_DIR=/root/software/hbase-2.2.0/conf
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$HBASE_HOME/bin
</code></pre> 
<ul><li>执行<code>source /etc/profile</code>使配置文件立即生效.</li></ul> 
<p>nodemanager did not stop gracefully after 5 seconds: Trying to kill with kill -9</p> 
<h5><a id="_266"></a>配置文件</h5> 
<h6><a id="1_Hadoop_267"></a>1. Hadoop</h6> 
<p>在Hadoop安装目录</p> 
<blockquote> 
 <p><code>/software/hadoop-3.1.2/etc/hadoop</code>下修改配置文件<code>hadoop-env.sh``````core-site.xml``````hdfs-site.xml``````yarn-site.xml``````mapred-site.xml</code></p> 
</blockquote> 
<blockquote> 
 <p><code>/software/hadoop-3.1.2/sbin</code>下修改启动停止脚本文件<code>start-dfs.sh``````stop-dfs.sh``````start-yarn.sh``````stop-yarn.sh</code></p> 
</blockquote> 
<ul><li>hadoop-env.sh文件配置Java路径</li></ul> 
<pre><code>JAVA_HOME=/software/jdk1.8.0_221
</code></pre> 
<ul><li>core-site.xml文件主要用于配置namenode地址和tmp文件地址,内容如下:(<mark>这里先建立hadoop临时文件夹/hddata/temp</mark>)</li></ul> 
<pre><code>&lt;configuration&gt;

    &lt;!-- 指定HDFS namenode的通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://s6:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/hddata/tmp&lt;/value&gt;
    &lt;/property&gt;

&lt;/configuration&gt;
</code></pre> 
<ul><li>hdfs-site.xml用于设置namenode datanode，hdfs备份份数 默认是3<br> dfs.permissionsdfs权限是否打开 ，通过idea远程操作的时候提示没有权限访问不了 因此设置为false 默认值是true</li></ul> 
<pre><code>&lt;configuration&gt;
        &lt;property&gt;
        &lt;name&gt;dfs.name.dir&lt;/name&gt;
        &lt;value&gt;/hddata/1/dfs,/hddata/2/dfs,/hddata/3/dfs,/hddata/4/dfs&lt;/value&gt;
        &lt;description&gt;namenode上存储hdfs名字空间元数据 &lt;/description&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;dfs.data.dir&lt;/name&gt;
        &lt;value&gt;/hddata/1/dfs,/hddata/2/dfs,/hddata/3/dfs,/hddata/4/dfs&lt;/value&gt;
        &lt;description&gt;datanode上数据块的物理存储位置&lt;/description&gt;
    &lt;/property&gt;


    &lt;!-- 设置hdfs副本数量 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

</code></pre> 
<ul><li>mapred-site.xml</li></ul> 
<pre><code>&lt;configuration&gt;
   &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--&lt;property&gt;--&gt;
    &lt;!--    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;--&gt;
    &lt;!--    &lt;value&gt;master:10020&lt;/value&gt;--&gt;
    &lt;!--&lt;/property&gt;--&gt;
    &lt;!--&lt;property&gt;--&gt;
    &lt;!--  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;--&gt;
    &lt;!--    &lt;value&gt;master:19888&lt;/value&gt;--&gt;
    &lt;!--&lt;/property&gt;--&gt;
    &lt;!--&lt;property&gt;--&gt;
    &lt;!--    &lt;name&gt;mapred.job.tracker&lt;/name&gt;--&gt;
    &lt;!--    &lt;value&gt;http://master:9001&lt;/value&gt;--&gt;
    &lt;!--&lt;/property&gt;--&gt;

&lt;/configuration&gt;
</code></pre> 
<ul><li>yarn-site.xml</li></ul> 
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
          &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
          &lt;value&gt;s6&lt;/value&gt;
  &lt;/property&gt;
&lt;!-- Configurations for NodeManager: --&gt;
  &lt;property&gt;
          &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
          &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;

   
&lt;/configuration&gt;
</code></pre> 
<ul><li>start-dfs.sh和stop-dfs.sh的开头空白处添加:</li></ul> 
<pre><code>HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
</code></pre> 
<ul><li>start-yarn.sh和stop-yarn.sh的开头空白处添加:</li></ul> 
<pre><code>YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
</code></pre> 
<ul><li>在配置完成后(<mark>确认每台服务器都已经修改,并且配置文件已生效,防火墙已关闭,ntp时间同步,以及ssh均配置完成</mark>),在<mark>主节点</mark>上执行命令<code>start-all.sh</code>,下面给出终端输出结果.</li></ul> 
<pre><code>[root@s6 conf]# start-all.sh
WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.
Starting namenodes on [s6]
Last login: Thu Aug  1 19:19:01 CST 2019 on pts/6
Starting datanodes
Last login: Thu Aug  1 19:22:11 CST 2019 on pts/6
Starting secondary namenodes [s6]
Last login: Thu Aug  1 19:22:14 CST 2019 on pts/6
Starting resourcemanager
Last login: Thu Aug  1 19:22:17 CST 2019 on pts/6
Starting nodemanagers
Last login: Thu Aug  1 19:22:22 CST 2019 on pts/6

[root@s6 conf]# jps
257424 NodeManager
256500 SecondaryNameNode
255691 NameNode
257097 ResourceManager
258172 Jps

[root@s7 conf]# jps
170248 NodeManager
174969 Jps
169516 DataNode

[root@s8 logs]# jps
64875 DataNode
162126 Jps
71468 NodeManager

</code></pre> 
<p>如果进程和上面显示一致,则运行没有问题,在<mark>主节点</mark>执行<code>stop-all.sh</code>停止hadoop,在执行<code>jps</code>可看到hadoop进程都成功关闭.</p> 
<pre><code>[root@s6 conf]# stop-all.sh
WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.
Stopping namenodes on [s6]
Last login: Thu Aug  1 19:22:24 CST 2019 on pts/6
Stopping datanodes
Last login: Thu Aug  1 19:26:16 CST 2019 on pts/6
Stopping secondary namenodes [s6]
Last login: Thu Aug  1 19:26:17 CST 2019 on pts/6
Stopping nodemanagers
Last login: Thu Aug  1 19:26:19 CST 2019 on pts/6
Stopping resourcemanager
Last login: Thu Aug  1 19:26:22 CST 2019 on pts/6

</code></pre> 
<p>如果遇到错误,查看<code>/software/hadoop-3.1.2/logs</code>下的日志文件寻找错误原因,可复制错误提示百度寻找.</p> 
<hr> 
<h6><a id="2_Zookeeper_443"></a>2. Zookeeper</h6> 
<ul><li>每台服务器系统建立zookeeper数据和日志文件夹:<code>mkdir -p zookeeper/{data,log}</code></li><li>每台服务器修改配置文件/etc/profile,在原来修改的基础上添加ZOOKEEPER_HOME,修改PATH,然后执行<code>source /etc/profile</code>使配置文件生效</li></ul> 
<pre><code>export JAVA_HOME=/software/jdk1.8.0_221
export HADOOP_HOME=/software/hadoop-3.1.2
export ZOOKEEPER_HOME=/software/apache-zookeeper-3.5.5
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin
</code></pre> 
<ul><li>编辑/software/apache-zookeeper-3.5.5/conf/zoo.cfg(如果没有,vi编辑新建一个)</li></ul> 
<pre><code>tickTime=2000
dataDir=/hddata/zookeeper/data
dataLogDir=/hddata/zookeeper/logs
clientPort=2181
initLimit=5
syncLimit=2
server.1=s6:2888:3888
server.2=s7:2888:3888
server.3=s8:2888:3888
</code></pre> 
<ul><li>在每台服务器建立myid文件,s6上执行</li></ul> 
<pre><code>echo '1' &gt; /hddata/zookeeper/data/myid
</code></pre> 
<p>s7执行</p> 
<pre><code>echo '2' &gt; /hddata/zookeeper/data/myid
</code></pre> 
<p>s8执行</p> 
<pre><code>echo '3' &gt; /hddata/zookeeper/data/myid
</code></pre> 
<p>创建的myid文件里面内容为一个数字，用来标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字。（zookeeper启动时会读取这个文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。）</p> 
<ul><li>执行<code>zkServer.sh start</code>启动zookeeper集群，启动顺序随意没要求。执行<code>jps</code>可以看到zookeeper进程存在,执行<code>zkServer.sh status</code>查看每个节点zookeeper状态.</li></ul> 
<pre><code>[root@s6 ~]# jps
102793 QuorumPeerMain
374559 Jps

[root@s6 conf]# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /software/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: follower

</code></pre> 
<pre><code>[root@s7 conf]# jps
4262 QuorumPeerMain

[root@s7 conf]# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /software/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: follower
</code></pre> 
<pre><code>[root@s8 logs]# jps
279469 QuorumPeerMain

[root@s8 logs]# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /software/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: leader
</code></pre> 
<hr> 
<h6><a id="3_HBase_519"></a>3. HBase</h6> 
<ul><li><code>tar -zxvf hbase-1.2.6-bin.tar -C /software/</code>解压HBase到指定安装目录<code>/software</code>下,修改<code>vi /etc/profile</code>,并且添加HBASE_HOME,修改PATH,执行<code>source /etc/profile</code>使配置文件立即生效,<code>scp /etc/profile root@s7:/etc</code>将配置文件分发到其他机器同时在执行<code>source</code>命令</li></ul> 
<pre><code>export JAVA_HOME=/software/jdk1.8.0_221
export HADOOP_HOME=/software/hadoop-3.1.2
export HBASE_HOME=/software/hbase-2.2.0
export ZOOKEEPER_HOME=/software/apache-zookeeper-3.5.5-bin
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$HBASE_HOME/bin
</code></pre> 
<ul><li>hbase-env.sh主要用配置HBase的工作环境<br> 在文件空白处添加java环境变量,并且设置使用独立的zookeeper，如果想让HBase来管理zookeeper，设置export HBASE_MANAGES_ZK=true。不让HBase管理zookeeper,安装独立的zookeeper则设置为false。</li></ul> 
<pre><code>export JAVA_HOME=/software/jdk1.8.0_221
export HBASE_MANAGES_ZK=false
</code></pre> 
<ul><li>修改配置文件hbase-site.xml,</li></ul> 
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt;
        &lt;value&gt;hdfs://s6:8020/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
     &lt;property&gt;
   		&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;
    	&lt;value&gt;2181&lt;/value&gt;
   &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;s6,s7,s8&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--下面这一项必须有,不然启动HBase时HMASTER进程无法启动--&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<ul><li>修改文件regionservers,添加regionserver主机名</li></ul> 
<pre><code>s7
s8
</code></pre> 
<ul><li>执行远程拷贝命令,将文件分发到其他服务器</li></ul> 
<pre><code>scp -r /software/hbase-2.2.0 root@s7:/software/ 
</code></pre> 
<pre><code>scp -r /software/hbase-2.2.0 root@s8:/software/ 
</code></pre> 
<ul><li>配置完后,在主节点执行命令<code>start-all.sh</code>,启动hadoop,再执行<code>zkServer.sh start</code>启动zookeeper,最后执行start-hbase.sh启动hbase(<mark>注意:启动顺序为hadoop-&gt;zookeeper-&gt;hbase,停止顺序为hbase-&gt;zookeeper-&gt;hadoop</mark>)</li></ul> 
<p>主节点</p> 
<pre><code>[root@s6 logs]# start-hbase.sh
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/software/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/software/hbase-2.2.0/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
running master, logging to /software/hbase-2.2.0/logs/hbase-root-master-s6.out
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/software/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/software/hbase-2.2.0/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
s8: running regionserver, logging to /software/hbase-2.2.0/bin/../logs/hbase-root-regionserver-s8.out
s7: running regionserver, logging to /software/hbase-2.2.0/bin/../logs/hbase-root-regionserver-s7.out
[root@s6 logs]# jps
301942 SecondaryNameNode
302867 NodeManager
102793 QuorumPeerMain
308828 Jps
302526 ResourceManager
308062 HMaster
301113 NameNode
</code></pre> 
<p>从节点</p> 
<pre><code>[root@s7 conf]# jps
221234 Jps
4262 QuorumPeerMain
212773 DataNode
218376 HRegionServer
213484 NodeManager

[root@s8 logs]# jps
330656 NodeManager
279469 QuorumPeerMain
318237 DataNode
408975 HRegionServer
10668 Jps

</code></pre> 
<hr> 
<p>以下内容与搭建无关</p> 
<h2><a id="bug_633"></a>前端数据清洗界面工作及bug记录</h2> 
<h3><a id="201964_636"></a>2019.6.4</h3> 
<h5><a id="handsontable_637"></a>handsontable使用</h5> 
<p><a href="https://handsontable.com/docs/7.1.0/Core.html" rel="nofollow">handsontable开源框架的api参考网址(点击访问)</a></p> 
<pre><code>handsontable加载数据时 settings中给定的data格式有两种,

一种是json对象型的,即[{k1:v1,k2:v2,k3:v3},{k1:v1,k2:v2,k3:v3},...],

另一种是数组型的,即[[v1,v2,v3,v4],[v1,v2,v3,v4],....].

当使用第一种时,不能对列进行删除
即js不能调用hot.alter('remove_col',index,amout)或者hot.removeCol(index)函数对列进行删除操作,
因为json格式的数据固定了字段.
非要这样用的话,删除列只能使用updateSettings({ColHeaders:xxx})的方法来更新字段.

所以使用第二种方式进行表格数据的渲染
</code></pre> 
<h6><a id="hellohandsontablecom_655"></a>这是我向hello@handsontable.com发送问题的邮件回复,成功的解决了问题.</h6> 
<p><img src="https://images2.imgbox.com/6e/a3/L9HWhe6x_o.png" alt="image"></p> 
<h5><a id="font_size6_2019621font_660"></a><font size="6"> 2019.6.21-清洗界面程序介绍</font></h5> 
<font size="4"> 主要的文件构成: </font> 
<ul><li>static/js/myJS/handsontable_generate.js</li><li>static/js/myJS/handsontable_operation.js</li></ul> 
<p>第一个文件handsontable_generate.js:</p> 
<p>主要是数据选择,隐藏显示逻辑和表的初始化,由于需要初始化多个table,因此采取tab标签的形式展示table,可生成多个table同时进行处理.</p> 
<pre><code class="prism language-javascript"><span class="token comment">/**
*   全局变量解释:
*  table_index-----&gt;记录清洗界面生成的表的个数,用户每选择一个表计数+1,删除一个表-1
*  table_list -----&gt;用于保存生成的自定义表对象
*          每个对象包含属性:
*              hot:当前表对象,可用于调用表的各种方法属性
*              Ccol:当前选中的列
*              Crow:当前选中的行
*              style_yichang:当前对象中  表格的异常变色数据
*              style_danyi:当前对象中  表格的单一变色数据
*              style_queshi:当前对象中  表格的缺失变色数据
*              name:在数据库中该表的名称
 *      this_table_index----&gt;当前表的索引
 */</span>
</code></pre> 
<p>第二个文件handsontable_operation.js:</p> 
<p>主要是顶部功能栏的功能实现:</p> 
<ul><li>删除行,列</li><li>下载到本地,保存到数据库</li><li>单一值展示</li><li>异常值展示</li><li>缺失值展示</li><li>相关性展示</li><li>变化趋势展示(针对连续数据) 曲线图</li><li>数值分布展示(针对离散数据) 饼图或者柱状图(++获取到数据类型后即可完成++)</li></ul> 
<pre><code class="prism language-javascript">
<span class="token comment">/**
* 对整个表格的所有操作函数 写在这里
* function:
*       1.行,列删除函数
*       2.下载功能
*       3.保存到数据库
*       4.跳转到数据分析 (待完成)
*       5.单一值响应 handson_danyi_detail()
*         缺失值响应 handson_queshi_detail()
*         异常值响应 handson_yichang_detail()
*       6.相关性响应 handson_relation_rate()
*         变化趋势响应 handson_change_trend()
*/</span>
</code></pre> 
<hr> 
<h3><a id="imagehttpsimgconvertcsdnimgcnaHR0cHM6Ly9ub3RlLnlvdWRhby5jb20veXdzL3B1YmxpYy9yZXNvdXJjZS8yZDY5NDY2MTk5MTVhMWNhNjRmYjYwMjc0MDYyYjI5ZS94bWxub3RlL0RDQjlFQkRBN0NEQTRBNzJCMzY5Mzg4RTU3NEM3MzlGLzQwMgxossprocessimageformatpng_721"></a><img src="https://images2.imgbox.com/fd/d2/91aZA5xT_o.png" alt="image"></h3> 
<h3><a id="font_size6_font_725"></a><font size="6"> 下一步计划</font></h3> 
<p>1.完成导数据的任务</p> 
<h3><a id="font_size6_2019620_font_730"></a><font size="6"> 2019.6.20-问题 </font></h3> 
<p><font size="4"> 相关性条状图宽度固定 做成下拉条</font></p> 
<p>外接硬盘需要做的配置:https://www.cnblogs.com/fiberhome/p/8458783.html</p> 
<h3><a id="font_size6_2019724_font_744"></a><font size="6"> 2019.7.24 </font></h3> 
<ol><li>计划重装Linux,重新搭系统.将服务器集群分成两半.</li><li>考虑到数据量巨大,导入HBase困难,直接使用.csv格式存储在HDFS上,届时再直接进行读取.</li></ol> 
<h2><a id="201976_750"></a>2019.7.6</h2> 
<p>0xAA55A55A在C#中和在java中是不一样的，因为java中的int类型是有符号4字节，可以表示-2<sup>31~2</sup>31-1所以</p> 
<pre><code class="prism language-java"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">0xAA55A55A</span>
<span class="token punctuation">(</span>这里自动识别第一位为负号标志位，a<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1437227686</span><span class="token punctuation">)</span>
</code></pre> 
<p>在C#中int是有符号4字节，可以表示-2<sup>31~2</sup>31-1，</p> 
<pre><code class="prism language-C#">int a = 0xAA55A55 
(这里编译错误，编译器认为0xAA55A55是‭2857739610,而int的位数不足以表达，所以报错‬‬)
</code></pre> 
<p>要表示成java中的数，应该</p> 
<pre><code class="prism language-C#">uint a =0xAA55A55A
a = (int)a
(此时是告知编译器第一位是负号标志位，强转)
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5a3441e11832228cec7f474b8101477d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">git项目的完整迁移</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9c16f6f46a410ef38ecec327e2e8ed99/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">centos7安装docker并配置php运行环境</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>