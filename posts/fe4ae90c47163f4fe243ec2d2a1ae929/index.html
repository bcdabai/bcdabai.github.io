<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于Docker搭建Hadoop集群 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于Docker搭建Hadoop集群" />
<meta property="og:description" content="一、准备工作 下载VMware、Xshell、Xftp、centos7映像文件、hadoop和jdk的压缩包。
二、配置虚拟机 1.创建虚拟机 使用VMware新建虚拟机，同时安装centos7系统，命名为master。
2.给虚拟机配置IP、网关等 vi /etc/sysconfig/network-scripts/ifcfg-ens33 修改BOOTPROTO为static,并在最后添加虚拟机的IP地址，子网掩码、网关和DNS等，如下图。
保存后退出。
重启网络服务，测试能否ping通百度，可以则配置成功，如下图。
3.关闭防火墙 查看此时防火墙的状态。
systemctl status firewalld 发现此时防火墙开启，所以将其关闭，并设置永久关闭。
systemctl stop firewalld systemctl disable firewalld 此时再查看防火墙的状态，发现已关闭。（若要测试是否永久关闭可以重启后查看）
4.补充：找不到ifconfig命令（可用于查看IP） 进行如下操作即可。
5.使用xshell连接虚拟机 选择“接受并保存”，然后输入用户名和密码即可。
6.修改主机名 若第一步未命名虚拟机，可通过如下命令。
vi /etc/hostname 输入名字，保存后退出。然后重启，命名生效。
三、安装docker服务 1.自动安装docker curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 2.查看docker的版本 3.启动docker，并设置开机自启动 4.配置docker镜像加速器 vi /etc/docker/daemon.json 添加如下内容
保存后退出。
5.重启docker服务 systemctl daemon-reload systemctl restart docker 输入docker info，最下方显示我们配置的地址时即为成功配置镜像加速器，如下图。
四、安装pipework和bridge-utils 1.新建文件夹software mkdir software cd software 2.安装git yum install -y git 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/fe4ae90c47163f4fe243ec2d2a1ae929/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-02T14:23:07+08:00" />
<meta property="article:modified_time" content="2023-04-02T14:23:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于Docker搭建Hadoop集群</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>一、准备工作</h2> 
<p>  <span style="color:#6eaad7;">下载VMware、Xshell、Xftp、centos7映像文件、hadoop和jdk的压缩包。</span></p> 
<h2>二、配置虚拟机</h2> 
<h3>1.创建虚拟机</h3> 
<p>  使用VMware新建虚拟机，同时安装centos7系统，命名为master。</p> 
<h3>2.给虚拟机配置IP、网关等</h3> 
<pre><code>vi /etc/sysconfig/network-scripts/ifcfg-ens33</code></pre> 
<p>修改BOOTPROTO为static,并在最后添加虚拟机的IP地址，子网掩码、网关和DNS等，如下图。</p> 
<p><img alt="" height="383" src="https://images2.imgbox.com/2c/59/NVdU6u97_o.png" width="395"></p> 
<p>保存后退出。</p> 
<p>重启网络服务，测试能否ping通百度，可以则配置成功，如下图。</p> 
<p><img alt="" height="178" src="https://images2.imgbox.com/e1/57/hNDW3dIf_o.png" width="688"></p> 
<h3>3.关闭防火墙</h3> 
<p>查看此时防火墙的状态。</p> 
<pre><code>systemctl status firewalld</code></pre> 
<p><img alt="" height="212" src="https://images2.imgbox.com/ab/ff/dE9mnLlY_o.png" width="839"></p> 
<p>发现此时防火墙开启，所以将其关闭，并设置永久关闭。</p> 
<pre><code>systemctl stop firewalld
systemctl disable firewalld</code></pre> 
<p>此时再查看防火墙的状态，发现已关闭。（若要测试是否永久关闭可以重启后查看）</p> 
<p><img alt="" height="87" src="https://images2.imgbox.com/c5/27/mJ9b1l40_o.png" width="801"></p> 
<h3>4.补充：找不到ifconfig命令（可用于查看IP）</h3> 
<p>进行如下操作即可。</p> 
<p><img alt="" height="207" src="https://images2.imgbox.com/02/55/0WbMpEj3_o.png" width="838"></p> 
<h3>5.使用xshell连接虚拟机</h3> 
<p><img alt="" height="984" src="https://images2.imgbox.com/e8/70/FBn0d8Fu_o.png" width="1042"></p> 
<p> 选择“接受并保存”，然后输入用户名和密码即可。</p> 
<p><img alt="" height="803" src="https://images2.imgbox.com/34/a0/luQENxpn_o.png" width="829"></p> 
<h3>6.修改主机名</h3> 
<p>若第一步未命名虚拟机，可通过如下命令。</p> 
<pre><code>vi /etc/hostname</code></pre> 
<p> 输入名字，保存后退出。然后重启，命名生效。</p> 
<h3>三、安装docker服务</h3> 
<h4>1.自动安装docker</h4> 
<pre><code>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</code></pre> 
<h3>2.查看docker的版本</h3> 
<p><img alt="" height="97" src="https://images2.imgbox.com/c5/07/gkhIPFB5_o.png" width="506"></p> 
<h3>3.启动docker，并设置开机自启动</h3> 
<p><img alt="" height="514" src="https://images2.imgbox.com/2c/0f/oRpOesV6_o.png" width="1200"></p> 
<h3>4.配置docker镜像加速器</h3> 
<pre><code>vi /etc/docker/daemon.json</code></pre> 
<p>添加如下内容</p> 
<p><img alt="" height="208" src="https://images2.imgbox.com/ed/c1/p9tT1mia_o.png" width="505"></p> 
<p>保存后退出。</p> 
<h3>5.重启docker服务</h3> 
<pre><code>systemctl daemon-reload
systemctl restart docker</code></pre> 
<p>输入docker info，最下方显示我们配置的地址时即为成功配置镜像加速器，如下图。</p> 
<p><img alt="" height="320" src="https://images2.imgbox.com/45/1a/SkOcp7xM_o.png" width="496"></p> 
<h3>四、安装pipework和bridge-utils</h3> 
<h4>1.新建文件夹software</h4> 
<pre><code>mkdir software
cd software</code></pre> 
<h4>2.安装git</h4> 
<pre><code>yum install -y git</code></pre> 
<h4>3.下载pipework</h4> 
<pre><code>git clone https://github.com/jpetazzo/pipework.git</code></pre> 
<p>下载完成。</p> 
<p><img alt="" height="186" src="https://images2.imgbox.com/39/62/usAJoKlu_o.png" width="907"></p> 
<h4>4.把pipework脚本添加到path中</h4> 
<pre><code>cp pipework/pipework /usr/bin/</code></pre> 
<h4>5.安装bridge-utils</h4> 
<pre><code>yum install bridge-utils</code></pre> 
<h3>五、搭建集群（一）</h3> 
<h4>1.集群规划</h4> 
<table align="center" border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td></td><td>hadoop01</td><td>hadoop02</td><td>hadoop03</td></tr><tr><td>IP</td><td>192.168.19.201</td><td>192.168.19.202</td><td>192.168.19.203</td></tr><tr><td>HDFS</td><td>NameNode、DataNode</td><td>DataNode</td><td>SecondaryNode、DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager、NodeManager</td><td>NodeManager</td></tr></tbody></table> 
<h4>2.拉取centos镜像</h4> 
<pre><code>cd ~
docker pull centos:7.5.1804</code></pre> 
<p>查看镜像</p> 
<p><img alt="" height="69" src="https://images2.imgbox.com/30/e8/QzXphNV0_o.png" width="723"></p> 
<h4>3.创建文件夹docker-hadoop</h4> 
<pre><code>mkdir docker-hadoop
</code></pre> 
<h4>4.使用xftp连接master，并传输jdk安装包到文件夹docker-hadoop</h4> 
<p><img alt="" height="897" src="https://images2.imgbox.com/aa/ad/9yoTb84G_o.png" width="1200"></p> 
<p>选中jdk压缩包，直接拖拽过去即可。</p> 
<h4>5.编辑Dockerfile，通过其生成带有jdk、ssh服务的镜像</h4> 
<pre><code>cd docker-hadoop
vi Dockerfile</code></pre> 
<p>添加如下内容。</p> 
<pre><code>FROM centos
MAINTAINER master
 
#安装JDK
RUN mkdir -p /opt/software &amp;&amp; mkdir -p /opt/service
ADD jdk1.8.0_221.tar.gz /opt/service

RUN cd /etc/yum.repos.d/
RUN sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
RUN sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
RUN yum makecache
RUN yum update -y
RUN yum install -y openssh-server sudo
RUN sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config
RUN yum install -y openssh-clients
 
RUN echo "root:1" | chpasswd
RUN echo "root   ALL=(ALL)       ALL" &gt;&gt; /etc/sudoers
RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key
RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
 
RUN mkdir /var/run/sshd
EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]</code></pre> 
<p><span style="color:#fe2c24;">注：MAINTAINER+空格+作者的信息，用于指定镜像作者的信息，根据自身实际修改。“root:1”的冒号后改成自己的密码。</span></p> 
<h4>6.生成基础镜像</h4> 
<pre><code>docker build -t hadoopbase:1.0 ./
</code></pre> 
<p>查看镜像是否创建成功。</p> 
<p><img alt="" height="98" src="https://images2.imgbox.com/56/07/0r3q6lPA_o.png" width="708"></p> 
<h3> 六、搭建集群（二）</h3> 
<h4>1.创建三个容器</h4> 
<pre><code>docker create -it --name hadoop01 -h hadoop01 hadoopbase:1.0
docker create -it --name hadoop02 -h hadoop02 hadoopbase:1.0
docker create -it --name hadoop03 -h hadoop03 hadoopbase:1.0</code></pre> 
<h4>2.pipework配置网络</h4> 
<pre><code>cd /usr/local/bin
vi docker.sh
chmod 777 docker.sh</code></pre> 
<p>脚本内容如下</p> 
<pre><code>#!/bin/bash

# 启动容器
docker start hadoop01
docker start hadoop02
docker start hadoop03

# 搭建网桥
brctl addbr br0; \
ip link set dev br0 up;
ip addr del 192.168.19.144/24 dev ens33;\
ip addr add 192.168.19.144/24 dev br0; \
brctl addif br0 ens33;\
ip route add default via 192.168.19.1 dev br0 

#睡5秒钟
sleep 5

#给容器配置ip和网关
pipework br0 hadoop01 192.168.19.201/24@192.168.19.1
pipework br0 hadoop02 192.168.19.202/24@192.168.19.1
pipework br0 hadoop03 192.168.19.203/24@192.168.19.1
</code></pre> 
<h4>3.执行脚本</h4> 
<p><img alt="" height="91" src="https://images2.imgbox.com/14/2e/eLlqit1c_o.png" width="344"></p> 
<p>显示如上则说明容器启动成功。</p> 
<h4>4.使用xshell连接三个容器</h4> 
<p><img alt="" height="790" src="https://images2.imgbox.com/92/4e/qpJtfdsW_o.png" width="1200"></p> 
<p>编辑容器的hosts文件，配置主机映射。</p> 
<pre><code>vi /etc/hosts</code></pre> 
<p>删除最后一行，添加以下内容。</p> 
<pre><code>192.168.19.201 hadoop01
192.168.19.202 hadoop02
192.168.19.203 hadoop03</code></pre> 
<p>保存后退出。可测试能否通过主机名ping通，从而判断配置是否生效。</p> 
<h4>5.配置三个容器之间的免密登录</h4> 
<p>此时仅在hadoop01上操作。</p> 
<pre><code>ssh-keygen -t rsa</code></pre> 
<p>三次回车。</p> 
<pre><code>ssh-copy-id hadoop01
ssh-copy-id hadoop02
ssh-copy-id hadoop03</code></pre> 
<p>依次执行，需要输入“yes”和自己设置的密码。</p> 
<p><span style="color:#fe2c24;">然后在hadoop02和hadoop03上执行相同的操作。</span></p> 
<h3>七、搭建集群（三）</h3> 
<h4>1.使用xftp连接hadoop01，上传hadoop安装包，放在/opt/software下</h4> 
<p><img alt="" height="902" src="https://images2.imgbox.com/79/46/zwc6qfyA_o.png" width="1200"></p> 
<h4>2.解压hadoop的安装包到/opt/service下</h4> 
<pre><code>tar -zxvf hadoop-2.7.7.tar.gz -C /opt/service</code></pre> 
<h4>3.配置jdk和hadoop的环境变量</h4> 
<pre><code>vi /etc/profile</code></pre> 
<p>添加以下内容</p> 
<pre><code>#JAVE_HOME
export JAVA_HOME=/opt/service/jdk1.8.0_221
export PATH=$PATH:$JAVA_HOME/bin

#HADOOP_HOME
export HADOOP_HOME=/opt/service/hadoop-2.7.7
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin</code></pre> 
<p>使文件生效</p> 
<pre><code>source /etc/profile</code></pre> 
<p>查看jdk和hadoop的版本</p> 
<p><img alt="" height="273" src="https://images2.imgbox.com/2d/d3/hYFj99n7_o.png" width="809"></p> 
<h4>4.修改hadoop的配置文件</h4> 
<p>进入对应的文件夹</p> 
<pre><code>cd /opt/service/hadoop-2.7.7/etc/hadoop/</code></pre> 
<p>（1）修改core-site.xml</p> 
<pre><code>vi core-site.xml</code></pre> 
<p>在&lt;configuration&gt;&lt;/configuration&gt;间添加以下内容，保存后退出。</p> 
<pre><code>&lt;!--指定NameNode的地址--&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;
  &lt;/property&gt;
 
  &lt;!--指定hadoop存放数据的目录--&gt;
  &lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    
    &lt;value&gt;/opt/service/hadoop-2.7.7/data&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--配置HDFS网页登录使用的静态用户为root--&gt;
  &lt;property&gt;
    &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
    &lt;value&gt;root&lt;/value&gt;
  &lt;/property&gt;</code></pre> 
<p>（2）修改hdfs-site.xml</p> 
<p>在&lt;configuration&gt;&lt;/configuration&gt;间添加以下内容，保存后退出。</p> 
<pre><code>&lt;!--nn web端访问地址--&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
    &lt;value&gt;hadoop01:9001&lt;/value&gt;
  &lt;/property&gt;

  &lt;!-- 2nn web端访问地址--&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
    &lt;value&gt;hadoop03:9002&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--指定HDFS副本的数量--&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--指定NN存放元数据信息的位置--&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:/opt/service/hadoop-2.7.7/hdfs/name&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--指定DN存放元数据信息的位置--&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:/opt/service/hadoop-2.7.7/hdfs/data&lt;/value&gt;
  &lt;/property&gt;
</code></pre> 
<p>（3）修改mapred-site.xml</p> 
<p>该文件夹下没有mapred-site.xml这个文件，所以需要执行以下操作。</p> 
<pre><code>cp mapred-site.xml.template mapred-site.xml
</code></pre> 
<p>然后在&lt;configuration&gt;&lt;/configuration&gt;间添加以下内容，保存后退出。</p> 
<pre><code>&lt;!--指定MR运行在yarn上--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
  
  &lt;!--历史服务器端地址--&gt;
  &lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;hadoop01:10020&lt;/value&gt;
  &lt;/property&gt;
 
  &lt;!--历史服务器web端地址--&gt;
  &lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;hadoop01:19888&lt;/value&gt;
  &lt;/property&gt;</code></pre> 
<p>（4）编辑yarn-site.xml</p> 
<p>在&lt;configuration&gt;&lt;/configuration&gt;间添加以下内容，保存后退出。</p> 
<pre><code>&lt;!--指定MR走shuffle--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--指定ResourceManager的地址--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;hadoop02&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--yarn容器允许分配的最大最小内存--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
    &lt;value&gt;512&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
    &lt;value&gt;2048&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--yarn容器允许管理的物理内存大小--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
    &lt;value&gt;2048&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--关闭yarn对虚拟内存的限制检查--&gt;
  &lt;property&gt; 
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;
&lt;!--开启日志聚集功能--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
 
  &lt;!--设置日志聚集服务器地址--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.log.server.url&lt;/name&gt;
    &lt;value&gt;http://hadoop01:19888/jobhistory/logs&lt;/value&gt;
  &lt;/property&gt;

  &lt;!--设置日志保留时间为7天--&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
    &lt;value&gt;604800&lt;/value&gt;
  &lt;/property&gt;</code></pre> 
<p>（5）编辑hadoop_env.sh</p> 
<p>改动这个地方即可。</p> 
<p><img alt="" height="73" src="https://images2.imgbox.com/71/a9/bSukXq95_o.png" width="544"></p> 
<p>（6）编辑slaves</p> 
<p>把原有内容删除，添加三个容器的名字，如下。</p> 
<p><img alt="" height="105" src="https://images2.imgbox.com/e9/f7/kvj8kRBE_o.png" width="173"></p> 
<p><span style="color:#fe2c24;">注：不要有空格或者空行！ </span></p> 
<p> （7）配置环境变量</p> 
<pre><code>vi /etc/profile</code></pre> 
<p> 在最后添加如下内容。</p> 
<pre><code>export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
</code></pre> 
<p>使环境变量生效。</p> 
<pre><code>source /etc/profile</code></pre> 
<h4>5.分发hadoop到其余两个容器</h4> 
<pre><code>scp -r /opt/service/hadoop-2.7.7 hadoop02:/opt/service
scp -r /opt/service/hadoop-2.7.7 hadoop03:/opt/service</code></pre> 
<h4>6.分发配置文件</h4> 
<pre><code>scp -r /etc/profile hadoop02:/etc/profile
scp -r /etc/profile hadoop03:/etc/profile</code></pre> 
<p>在hadoop02和hadoop03上分别执行以下命令，使环境变量生效。</p> 
<pre><code>source /etc/profile</code></pre> 
<h4>7.启动集群</h4> 
<p>（1）格式化hdfs</p> 
<p>在hadoop01上执行以下命令。</p> 
<pre><code>cd /opt/service/hadoop-2.7.7
bin/hdfs namenode -format</code></pre> 
<p>格式化成功，结束状态为0</p> 
<p><img alt="" height="140" src="https://images2.imgbox.com/2a/f6/wEKVhszu_o.png" width="742"></p> 
<p>（2）启动hdfs和yarn</p> 
<pre><code class="hljs">start-dfs.sh
start-yarn.sh</code></pre> 
<p>注：在hadoop01上启动dfs，在hadoop02上启动yarn</p> 
<p> （3）查看集群状态</p> 
<p><img alt="" height="112" src="https://images2.imgbox.com/84/33/EfWWVie8_o.png" width="433"></p> 
<p><img alt="" height="112" src="https://images2.imgbox.com/a7/96/pIort8Mr_o.png" width="283"> </p> 
<p><img alt="" height="116" src="https://images2.imgbox.com/65/74/IEoxB4KU_o.png" width="324"> </p> 
<p> 使用jps查看各容器的进程，和上三图一致即为成功。</p> 
<p>（4）在web端查看</p> 
<p><img alt="" height="972" src="https://images2.imgbox.com/bf/0d/cr5WTPya_o.png" width="1200"></p> 
<p><img alt="" height="970" src="https://images2.imgbox.com/f0/81/qwMxXoqd_o.png" width="1200"> </p> 
<p><img alt="" height="976" src="https://images2.imgbox.com/9e/8d/fP2soDjI_o.png" width="1200"> </p> 
<p>搭建并启动成功，感谢浏览！如有问题，欢迎指正和讨论</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0294f49a84fc8001190466905c7e5b8d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">秒懂SpringBoot之参数验证全解析(@Validated与@Valid)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7eeea83c4a2743c83c68a274ac66ad39/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">免费可商用开源GPT模型问世，50G权重直接下载，性能不输GPT-3</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>