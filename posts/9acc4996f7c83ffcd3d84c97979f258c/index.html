<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ç«èµ›ä¿ç ” åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©è¯†åˆ«ç®—æ³• - cnn opencv python - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ç«èµ›ä¿ç ” åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©è¯†åˆ«ç®—æ³• - cnn opencv python" />
<meta property="og:description" content="æ–‡ç« ç›®å½• 0 å‰è¨€1 è¯¾é¢˜èƒŒæ™¯2 å…·ä½“å®ç°3 æ•°æ®æ”¶é›†å’Œå¤„ç†3 MobileNetV2ç½‘ç»œ4 æŸå¤±å‡½æ•°softmax äº¤å‰ç†µ4.1 softmaxå‡½æ•°4.2 äº¤å‰ç†µæŸå¤±å‡½æ•° 5 ä¼˜åŒ–å™¨SGD6 æœ€å 0 å‰è¨€ ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯
ğŸš© **åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©è¯†åˆ«ç®—æ³• **
è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼
ğŸ¥‡å­¦é•¿è¿™é‡Œç»™ä¸€ä¸ªé¢˜ç›®ç»¼åˆè¯„åˆ†(æ¯é¡¹æ»¡åˆ†5åˆ†)
éš¾åº¦ç³»æ•°ï¼š3åˆ†å·¥ä½œé‡ï¼š4åˆ†åˆ›æ–°ç‚¹ï¼š4åˆ† ğŸ§¿ æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š
https://gitee.com/dancheng-senior/postgraduate
1 è¯¾é¢˜èƒŒæ™¯ æ¤ç‰©åœ¨åœ°çƒä¸Šæ˜¯ä¸€ç§éå¸¸å¹¿æ³›çš„ç”Ÿå‘½å½¢å¼ï¼Œç›´æ¥å…³ç³»åˆ°äººç±»çš„ç”Ÿæ´»ç¯å¢ƒï¼Œç›®å‰ï¼Œæ¤ç‰©è¯†åˆ«ä¸»è¦ä¾é ç›¸å…³è¡Œä¸šä»ä¸šäººå‘˜åŠæœ‰ç»éªŒä¸“å®¶å®è·µç»éªŒï¼Œå·¥ä½œé‡å¤§ã€æ•ˆç‡ä½ã€‚è¿‘å¹´æ¥ï¼Œéšç€ç¤¾ä¼šç§‘æŠ€åŠç»æµå‘å±•è¶Šæ¥è¶Šå¿«ï¼Œè®¡ç®—æœºç¡¬ä»¶è¿›ä¸€æ­¥æ›´æ–°ï¼Œæ€§èƒ½ä¹Ÿæ—¥æ¸æé«˜ï¼Œæ•°å­—å›¾åƒé‡‡é›†è®¾å¤‡åº”ç”¨å¹¿æ³›ï¼Œè®¾å¤‡å­˜å‚¨ç©ºé—´ä¸æ–­å¢å¤§ï¼Œè¿™æ ·å¤§é‡æ¤ç‰©ä¿¡æ¯å¯è¢«æ•°å­—åŒ–ã€‚åŒæ—¶ï¼ŒåŸºäºè§†é¢‘çš„ç›®æ ‡æ£€æµ‹åœ¨æ¨¡å¼è¯†åˆ«ã€æœºå™¨å­¦ä¹ ç­‰é¢†åŸŸå¾—åˆ°å¿«é€Ÿå‘å±•ï¼Œè¿›è€ŒåŸºäºå›¾åƒé›†åˆ†ç±»æ–¹æ³•ç ”ç©¶å¾—åˆ°å‘å±•ã€‚
æœ¬é¡¹ç›®åŸºäºæ·±åº¦å­¦ä¹ å®ç°å›¾åƒæ¤ç‰©è¯†åˆ«ã€‚
2 å…·ä½“å®ç° 3 æ•°æ®æ”¶é›†å’Œå¤„ç† æ•°æ®æ˜¯æ·±åº¦å­¦ä¹ çš„åŸºçŸ³
æ•°æ®çš„ä¸»è¦æ¥æºæœ‰: ç™¾åº¦å›¾ç‰‡, å¿…åº”å›¾ç‰‡, æ–°æµªå¾®åš, ç™¾åº¦è´´å§, æ–°æµªåšå®¢å’Œä¸€äº›ä¸“ä¸šçš„æ¤ç‰©ç½‘ç«™ç­‰
çˆ¬è™«çˆ¬å–çš„å›¾åƒçš„è´¨é‡å‚å·®ä¸é½, æ ‡ç­¾å¯èƒ½æœ‰è¯¯, ä¸”å­˜åœ¨é‡å¤æ–‡ä»¶, å› æ­¤å¿…é¡»æ¸…æ´—ã€‚æ¸…æ´—æ–¹æ³•åŒ…æ‹¬è‡ªåŠ¨åŒ–æ¸…æ´—, åŠè‡ªåŠ¨åŒ–æ¸…æ´—å’Œæ‰‹å·¥æ¸…æ´—ã€‚
è‡ªåŠ¨åŒ–æ¸…æ´—åŒ…æ‹¬:
æ»¤é™¤å°å°ºå¯¸å›¾åƒ.æ»¤é™¤å®½é«˜æ¯”å¾ˆå¤§æˆ–å¾ˆå°çš„å›¾åƒ.æ»¤é™¤ç°åº¦å›¾åƒ.å›¾åƒå»é‡: æ ¹æ®å›¾åƒæ„ŸçŸ¥å“ˆå¸Œ. åŠè‡ªåŠ¨åŒ–æ¸…æ´—åŒ…æ‹¬:
å›¾åƒçº§åˆ«çš„æ¸…æ´—: åˆ©ç”¨é¢„å…ˆè®­ç»ƒçš„æ¤ç‰©/éæ¤ç‰©å›¾åƒåˆ†ç±»å™¨å¯¹å›¾åƒæ–‡ä»¶è¿›è¡Œæ‰“åˆ†, éæ¤ç‰©å›¾åƒåº”è¯¥æœ‰è¾ƒä½çš„å¾—åˆ†; åˆ©ç”¨å‰ä¸€é˜¶æ®µçš„æ¤ç‰©åˆ†ç±»å™¨å¯¹å›¾åƒæ–‡ä»¶ (æ¯ä¸ªæ–‡ä»¶éƒ½æœ‰ä¸€ä¸ªé¢„æ ‡ç±»åˆ«) è¿›è¡Œé¢„æµ‹, å–é¢„æ ‡ç±»åˆ«çš„æ¦‚ç‡å€¼ä¸ºå¾—åˆ†, ä¸å±äºåŸé¢„æ ‡ç±»åˆ«çš„å›¾åƒåº”è¯¥æœ‰è¾ƒä½çš„å¾—åˆ†. å¯ä»¥è®¾ç½®é˜ˆå€¼, æ»¤é™¤å¾ˆä½å¾—åˆ†çš„æ–‡ä»¶; å¦å¤–åˆ©ç”¨å¾—åˆ†å¯¹å›¾åƒæ–‡ä»¶è¿›è¡Œé‡å‘½å, å¹¶åœ¨èµ„æºç®¡ç†å™¨é€‰æ‹©æŒ‰æ–‡ä»¶åæ’åº, ä»¥ä¾¿äºåç»­æ‰‹å·¥æ¸…æ´—æ‰éæ¤ç‰©å›¾åƒå’Œä¸æ˜¯é¢„æ ‡ç±»åˆ«çš„å›¾åƒ.ç±»çº§åˆ«çš„æ¸…æ´— æ‰‹å·¥æ¸…æ´—: äººå·¥åˆ¤æ–­æ–‡ä»¶å¤¹ä¸‹å›¾åƒæ˜¯å¦å±äºæ–‡ä»¶å¤¹åæ‰€æ ‡ç§°çš„ç‰©ç§, è¿™éœ€è¦ç›¸å…³çš„æ¤ç‰©å­¦ä¸“ä¸šçŸ¥è¯†, æ˜¯æœ€è€—æ—¶ä¸”æ¯ç‡¥çš„ç¯èŠ‚, ä½†ä¹Ÿå‡­æ­¤è®¤è¯†äº†ä¸å°‘çš„æ¤ç‰©." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9acc4996f7c83ffcd3d84c97979f258c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T17:59:06+08:00" />
<meta property="article:modified_time" content="2024-01-10T17:59:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ç«èµ›ä¿ç ” åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©è¯†åˆ«ç®—æ³• - cnn opencv python</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>æ–‡ç« ç›®å½•</h4> 
 <ul><li><a href="#0__3" rel="nofollow">0 å‰è¨€</a></li><li><a href="#1__21" rel="nofollow">1 è¯¾é¢˜èƒŒæ™¯</a></li><li><a href="#2__26" rel="nofollow">2 å…·ä½“å®ç°</a></li><li><a href="#3__32" rel="nofollow">3 æ•°æ®æ”¶é›†å’Œå¤„ç†</a></li><li><a href="#3_MobileNetV2_51" rel="nofollow">3 MobileNetV2ç½‘ç»œ</a></li><li><a href="#4_softmax__149" rel="nofollow">4 æŸå¤±å‡½æ•°softmax äº¤å‰ç†µ</a></li><li><ul><li><a href="#41_softmax_151" rel="nofollow">4.1 softmaxå‡½æ•°</a></li><li><a href="#42__196" rel="nofollow">4.2 äº¤å‰ç†µæŸå¤±å‡½æ•°</a></li></ul> 
  </li><li><a href="#5_SGD_234" rel="nofollow">5 ä¼˜åŒ–å™¨SGD</a></li><li><a href="#6__301" rel="nofollow">6 æœ€å</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0__3"></a>0 å‰è¨€</h2> 
<p>ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯</p> 
<p>ğŸš© **åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©è¯†åˆ«ç®—æ³• **</p> 
<p>è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼</p> 
<p>ğŸ¥‡å­¦é•¿è¿™é‡Œç»™ä¸€ä¸ªé¢˜ç›®ç»¼åˆè¯„åˆ†(æ¯é¡¹æ»¡åˆ†5åˆ†)</p> 
<ul><li>éš¾åº¦ç³»æ•°ï¼š3åˆ†</li><li>å·¥ä½œé‡ï¼š4åˆ†</li><li>åˆ›æ–°ç‚¹ï¼š4åˆ†</li></ul> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h2><a id="1__21"></a>1 è¯¾é¢˜èƒŒæ™¯</h2> 
<p>æ¤ç‰©åœ¨åœ°çƒä¸Šæ˜¯ä¸€ç§éå¸¸å¹¿æ³›çš„ç”Ÿå‘½å½¢å¼ï¼Œç›´æ¥å…³ç³»åˆ°äººç±»çš„ç”Ÿæ´»ç¯å¢ƒï¼Œç›®å‰ï¼Œæ¤ç‰©è¯†åˆ«ä¸»è¦ä¾é ç›¸å…³è¡Œä¸šä»ä¸šäººå‘˜åŠæœ‰ç»éªŒä¸“å®¶å®è·µç»éªŒï¼Œå·¥ä½œé‡å¤§ã€æ•ˆç‡ä½ã€‚è¿‘å¹´æ¥ï¼Œéšç€ç¤¾ä¼šç§‘æŠ€åŠç»æµå‘å±•è¶Šæ¥è¶Šå¿«ï¼Œè®¡ç®—æœºç¡¬ä»¶è¿›ä¸€æ­¥æ›´æ–°ï¼Œæ€§èƒ½ä¹Ÿæ—¥æ¸æé«˜ï¼Œæ•°å­—å›¾åƒé‡‡é›†è®¾å¤‡åº”ç”¨å¹¿æ³›ï¼Œè®¾å¤‡å­˜å‚¨ç©ºé—´ä¸æ–­å¢å¤§ï¼Œè¿™æ ·å¤§é‡æ¤ç‰©ä¿¡æ¯å¯è¢«æ•°å­—åŒ–ã€‚åŒæ—¶ï¼ŒåŸºäºè§†é¢‘çš„ç›®æ ‡æ£€æµ‹åœ¨æ¨¡å¼è¯†åˆ«ã€æœºå™¨å­¦ä¹ ç­‰é¢†åŸŸå¾—åˆ°å¿«é€Ÿå‘å±•ï¼Œè¿›è€ŒåŸºäºå›¾åƒé›†åˆ†ç±»æ–¹æ³•ç ”ç©¶å¾—åˆ°å‘å±•ã€‚<br> æœ¬é¡¹ç›®åŸºäºæ·±åº¦å­¦ä¹ å®ç°å›¾åƒæ¤ç‰©è¯†åˆ«ã€‚</p> 
<h2><a id="2__26"></a>2 å…·ä½“å®ç°</h2> 
<p><img src="https://images2.imgbox.com/c3/f5/JNST3wSA_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/53/27/vuaMtDjS_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/de/b2/N4SELpr0_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="3__32"></a>3 æ•°æ®æ”¶é›†å’Œå¤„ç†</h2> 
<p>æ•°æ®æ˜¯æ·±åº¦å­¦ä¹ çš„åŸºçŸ³<br> æ•°æ®çš„ä¸»è¦æ¥æºæœ‰: ç™¾åº¦å›¾ç‰‡, å¿…åº”å›¾ç‰‡, æ–°æµªå¾®åš, ç™¾åº¦è´´å§, æ–°æµªåšå®¢å’Œä¸€äº›ä¸“ä¸šçš„æ¤ç‰©ç½‘ç«™ç­‰<br> çˆ¬è™«çˆ¬å–çš„å›¾åƒçš„è´¨é‡å‚å·®ä¸é½, æ ‡ç­¾å¯èƒ½æœ‰è¯¯, ä¸”å­˜åœ¨é‡å¤æ–‡ä»¶, å› æ­¤å¿…é¡»æ¸…æ´—ã€‚æ¸…æ´—æ–¹æ³•åŒ…æ‹¬è‡ªåŠ¨åŒ–æ¸…æ´—, åŠè‡ªåŠ¨åŒ–æ¸…æ´—å’Œæ‰‹å·¥æ¸…æ´—ã€‚<br> è‡ªåŠ¨åŒ–æ¸…æ´—åŒ…æ‹¬:</p> 
<ul><li>æ»¤é™¤å°å°ºå¯¸å›¾åƒ.</li><li>æ»¤é™¤å®½é«˜æ¯”å¾ˆå¤§æˆ–å¾ˆå°çš„å›¾åƒ.</li><li>æ»¤é™¤ç°åº¦å›¾åƒ.</li><li>å›¾åƒå»é‡: æ ¹æ®å›¾åƒæ„ŸçŸ¥å“ˆå¸Œ.</li></ul> 
<p>åŠè‡ªåŠ¨åŒ–æ¸…æ´—åŒ…æ‹¬:</p> 
<ul><li>å›¾åƒçº§åˆ«çš„æ¸…æ´—: åˆ©ç”¨é¢„å…ˆè®­ç»ƒçš„æ¤ç‰©/éæ¤ç‰©å›¾åƒåˆ†ç±»å™¨å¯¹å›¾åƒæ–‡ä»¶è¿›è¡Œæ‰“åˆ†, éæ¤ç‰©å›¾åƒåº”è¯¥æœ‰è¾ƒä½çš„å¾—åˆ†; åˆ©ç”¨å‰ä¸€é˜¶æ®µçš„æ¤ç‰©åˆ†ç±»å™¨å¯¹å›¾åƒæ–‡ä»¶ (æ¯ä¸ªæ–‡ä»¶éƒ½æœ‰ä¸€ä¸ªé¢„æ ‡ç±»åˆ«) è¿›è¡Œé¢„æµ‹, å–é¢„æ ‡ç±»åˆ«çš„æ¦‚ç‡å€¼ä¸ºå¾—åˆ†, ä¸å±äºåŸé¢„æ ‡ç±»åˆ«çš„å›¾åƒåº”è¯¥æœ‰è¾ƒä½çš„å¾—åˆ†. å¯ä»¥è®¾ç½®é˜ˆå€¼, æ»¤é™¤å¾ˆä½å¾—åˆ†çš„æ–‡ä»¶; å¦å¤–åˆ©ç”¨å¾—åˆ†å¯¹å›¾åƒæ–‡ä»¶è¿›è¡Œé‡å‘½å, å¹¶åœ¨èµ„æºç®¡ç†å™¨é€‰æ‹©æŒ‰æ–‡ä»¶åæ’åº, ä»¥ä¾¿äºåç»­æ‰‹å·¥æ¸…æ´—æ‰éæ¤ç‰©å›¾åƒå’Œä¸æ˜¯é¢„æ ‡ç±»åˆ«çš„å›¾åƒ.</li><li>ç±»çº§åˆ«çš„æ¸…æ´—</li></ul> 
<p>æ‰‹å·¥æ¸…æ´—: äººå·¥åˆ¤æ–­æ–‡ä»¶å¤¹ä¸‹å›¾åƒæ˜¯å¦å±äºæ–‡ä»¶å¤¹åæ‰€æ ‡ç§°çš„ç‰©ç§, è¿™éœ€è¦ç›¸å…³çš„æ¤ç‰©å­¦ä¸“ä¸šçŸ¥è¯†, æ˜¯æœ€è€—æ—¶ä¸”æ¯ç‡¥çš„ç¯èŠ‚, ä½†ä¹Ÿå‡­æ­¤è®¤è¯†äº†ä¸å°‘çš„æ¤ç‰©.</p> 
<h2><a id="3_MobileNetV2_51"></a>3 MobileNetV2ç½‘ç»œ</h2> 
<p><strong>ç®€ä»‹</strong></p> 
<p>MobileNetç½‘ç»œæ˜¯Googleæœ€è¿‘æå‡ºçš„ä¸€ç§å°å·§è€Œé«˜æ•ˆçš„CNNæ¨¡å‹ï¼Œå…¶åœ¨accuracyå’Œlatencyä¹‹é—´åšäº†æŠ˜ä¸­ã€‚</p> 
<p><strong>ä¸»è¦æ”¹è¿›ç‚¹</strong></p> 
<p>ç›¸å¯¹äºMobileNetV1ï¼ŒMobileNetV2 ä¸»è¦æ”¹è¿›ç‚¹ï¼š</p> 
<ul><li>å¼•å…¥å€’æ®‹å·®ç»“æ„ï¼Œå…ˆå‡ç»´å†é™ç»´ï¼Œå¢å¼ºæ¢¯åº¦çš„ä¼ æ’­ï¼Œæ˜¾è‘—å‡å°‘æ¨ç†æœŸé—´æ‰€éœ€çš„å†…å­˜å ç”¨ï¼ˆInverted Residualsï¼‰</li><li>å»æ‰ Narrow layer(low dimension or depth) åçš„ ReLUï¼Œä¿ç•™ç‰¹å¾å¤šæ ·æ€§ï¼Œå¢å¼ºç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ï¼ˆLinear Bottlenecksï¼‰</li><li>ç½‘ç»œä¸ºå…¨å·ç§¯ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥é€‚åº”ä¸åŒå°ºå¯¸çš„å›¾åƒï¼›ä½¿ç”¨ RELU6ï¼ˆæœ€é«˜è¾“å‡ºä¸º 6ï¼‰æ¿€æ´»å‡½æ•°ï¼Œä½¿å¾—æ¨¡å‹åœ¨ä½ç²¾åº¦è®¡ç®—ä¸‹å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§</li><li>MobileNetV2 Inverted residual block å¦‚ä¸‹æ‰€ç¤ºï¼Œè‹¥éœ€è¦ä¸‹é‡‡æ ·ï¼Œå¯åœ¨ DW æ—¶é‡‡ç”¨æ­¥é•¿ä¸º 2 çš„å·ç§¯</li><li>å°ç½‘ç»œä½¿ç”¨å°çš„æ‰©å¼ ç³»æ•°ï¼ˆexpansion factorï¼‰ï¼Œå¤§ç½‘ç»œä½¿ç”¨å¤§ä¸€ç‚¹çš„æ‰©å¼ ç³»æ•°ï¼ˆexpansion factorï¼‰ï¼Œæ¨èæ˜¯5~10ï¼Œè®ºæ–‡ä¸­ t = 6 t = 6t=6</li></ul> 
<p><strong>å€’æ®‹å·®ç»“æ„ï¼ˆInverted residual block</strong> ï¼‰</p> 
<p>ResNetçš„Bottleneckç»“æ„æ˜¯é™ç»´-&gt;å·ç§¯-&gt;å‡ç»´ï¼Œæ˜¯ä¸¤è¾¹ç»†ä¸­é—´ç²—</p> 
<p>è€ŒMobileNetV2æ˜¯å…ˆå‡ç»´ï¼ˆ6å€ï¼‰-&gt; å·ç§¯ -&gt; é™ç»´ï¼Œæ˜¯æ²™æ¼å½¢ã€‚<br> <img src="https://images2.imgbox.com/65/1b/QoQkFlxg_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°">åŒºåˆ«äºMobileNetV1,<br> MobileNetV2çš„å·ç§¯ç»“æ„å¦‚ä¸‹ï¼š<br> <img src="https://images2.imgbox.com/c4/5a/LW9IzqCE_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> å› ä¸ºDWå·ç§¯ä¸æ”¹å˜é€šé“æ•°ï¼Œæ‰€ä»¥å¦‚æœä¸Šä¸€å±‚çš„é€šé“æ•°å¾ˆä½æ—¶ï¼ŒDWåªèƒ½åœ¨ä½ç»´ç©ºé—´æå–ç‰¹å¾ï¼Œæ•ˆæœä¸å¥½ã€‚æ‰€ä»¥V2ç‰ˆæœ¬åœ¨DWå‰é¢åŠ äº†ä¸€å±‚PWç”¨æ¥å‡ç»´ã€‚</p> 
<p>åŒæ—¶V2å»é™¤äº†ç¬¬äºŒä¸ªPWçš„æ¿€æ´»å‡½æ•°æ”¹ç”¨çº¿æ€§æ¿€æ´»ï¼Œå› ä¸ºæ¿€æ´»å‡½æ•°åœ¨é«˜ç»´ç©ºé—´èƒ½å¤Ÿæœ‰æ•ˆåœ°å¢åŠ éçº¿æ€§ï¼Œä½†åœ¨ä½ç»´ç©ºé—´æ—¶ä¼šç ´åç‰¹å¾ã€‚ç”±äºç¬¬äºŒä¸ªPWä¸»è¦çš„åŠŸèƒ½æ˜¯é™ç»´ï¼Œæ‰€ä»¥ä¸å®œå†åŠ ReLU6ã€‚<br> <img src="https://images2.imgbox.com/28/dd/vWS9ayNy_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <strong>tensorflowç›¸å…³å®ç°ä»£ç </strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python">

    <span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
    <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
    <span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> Sequential<span class="token punctuation">,</span> Model
    
    <span class="token keyword">class</span> <span class="token class-name">ConvBNReLU</span><span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>conv <span class="token operator">=</span> layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> 
                                      kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> 
                                      strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> 
                                      padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> 
                                      use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                      name<span class="token operator">=</span><span class="token string">'Conv2d'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>bn <span class="token operator">=</span> layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'BatchNorm'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>activation <span class="token operator">=</span> layers<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>max_value<span class="token operator">=</span><span class="token number">6.0</span><span class="token punctuation">)</span>   <span class="token comment"># ReLU6</span>
            
        <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>training<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> x


    <span class="token keyword">class</span> <span class="token class-name">InvertedResidualBlock</span><span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> strides<span class="token punctuation">,</span> expand_ratio<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>InvertedResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>hidden_channel <span class="token operator">=</span> in_channel <span class="token operator">*</span> expand_ratio
            self<span class="token punctuation">.</span>use_shortcut <span class="token operator">=</span> <span class="token punctuation">(</span>strides <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token punctuation">(</span>in_channel <span class="token operator">==</span> out_channel<span class="token punctuation">)</span>
            
            layer_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token comment"># first bottleneck does not need 1*1 conv</span>
            <span class="token keyword">if</span> expand_ratio <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token comment"># 1x1 pointwise conv</span>
                layer_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">(</span>out_channel<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'expand'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layer_list<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
                
                <span class="token comment"># 3x3 depthwise conv </span>
                layers<span class="token punctuation">.</span>DepthwiseConv2D<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'depthwise'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'depthwise/BatchNorm'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>max_value<span class="token operator">=</span><span class="token number">6.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                
                <span class="token comment">#1x1 pointwise conv(linear) </span>
                <span class="token comment"># linear activation y = x -&gt; no activation function</span>
                layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'project'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'project/BatchNorm'</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            self<span class="token punctuation">.</span>main_branch <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>layer_list<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'expanded_conv'</span><span class="token punctuation">)</span>
        
        <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_shortcut<span class="token punctuation">:</span>
                <span class="token keyword">return</span> inputs <span class="token operator">+</span> self<span class="token punctuation">.</span>main_branch<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span> self<span class="token punctuation">.</span>main_branch<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>  



</code></pre> 
<p>â€‹<br> â€‹</p> 
<h2><a id="4_softmax__149"></a>4 æŸå¤±å‡½æ•°softmax äº¤å‰ç†µ</h2> 
<h3><a id="41_softmax_151"></a>4.1 softmaxå‡½æ•°</h3> 
<p>Softmaxå‡½æ•°ç”±ä¸‹åˆ—å…¬å¼å®šä¹‰<br> <img src="https://images2.imgbox.com/8c/5f/UWfX2PNr_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> softmax çš„ä½œç”¨æ˜¯æŠŠ ä¸€ä¸ªåºåˆ—ï¼Œå˜æˆæ¦‚ç‡ã€‚</p> 
<p><img src="https://images2.imgbox.com/32/f6/Rup9TxGD_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>softmaxç”¨äºå¤šåˆ†ç±»è¿‡ç¨‹ä¸­ï¼Œå®ƒå°†å¤šä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼Œæ˜ å°„åˆ°ï¼ˆ0,1ï¼‰åŒºé—´å†…ï¼Œæ‰€æœ‰æ¦‚ç‡çš„å’Œå°†ç­‰äº1ã€‚</p> 
<p><strong>pythonå®ç°</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    shift_x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token comment"># é˜²æ­¢è¾“å…¥å¢å¤§æ—¶è¾“å‡ºä¸ºnan</span>
    exp_x <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>shift_x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_x <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>exp_x<span class="token punctuation">)</span>
</code></pre> 
<p><strong>PyTorchå°è£…çš„Softmax()å‡½æ•°</strong></p> 
<p>dimå‚æ•°ï¼š</p> 
<ul><li> <p>dimä¸º0æ—¶ï¼Œå¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œsoftmaxè®¡ç®—</p> </li><li> <p>dimä¸º1æ—¶ï¼Œå¯¹æŸä¸€ä¸ªç»´åº¦çš„åˆ—è¿›è¡Œsoftmaxè®¡ç®—</p> </li><li> <p>dimä¸º-1 æˆ–è€…2 æ—¶ï¼Œå¯¹æŸä¸€ä¸ªç»´åº¦çš„è¡Œè¿›è¡Œsoftmaxè®¡ç®—</p> <pre><code class="prism language-python"><span class="token keyword">import</span> torch
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"è¾“å…¥ï¼š"</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"è¾“å‡ºï¼š"</span><span class="token punctuation">,</span>outputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"è¾“å‡ºä¹‹å’Œï¼š"</span><span class="token punctuation">,</span>outputs<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> </li></ul> 
<h3><a id="42__196"></a>4.2 äº¤å‰ç†µæŸå¤±å‡½æ•°</h3> 
<p><strong>å®šä¹‰å¦‚ä¸‹:</strong><br> <img src="https://images2.imgbox.com/27/7e/fDG7tqxB_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <strong>pythonå®ç°</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>nan_to_num<span class="token punctuation">(</span><span class="token operator">-</span>y<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment"># tensorflow version</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span><span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>y_<span class="token operator">*</span>tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> reduction_indices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment"># numpy version</span>
loss <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>PyTorchå®ç°</strong><br> äº¤å‰ç†µå‡½æ•°åˆ†ä¸ºäºŒåˆ†ç±»(torch.nn.BCELoss())å’Œå¤šåˆ†ç±»å‡½æ•°(torch.nn.CrossEntropyLoss()</p> 
<p>â€‹</p> 
<pre><code class="prism language-python">
    <span class="token comment"># äºŒåˆ†ç±» æŸå¤±å‡½æ•°</span>
    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    l <span class="token operator">=</span> loss<span class="token punctuation">(</span>predï¼Œreal<span class="token punctuation">)</span>


    <span class="token comment"># å¤šåˆ†ç±»æŸå¤±å‡½æ•°</span>
    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>â€‹</p> 
<h2><a id="5_SGD_234"></a>5 ä¼˜åŒ–å™¨SGD</h2> 
<p><strong>ç®€ä»‹</strong><br> SGDå…¨ç§°Stochastic Gradient Descentï¼Œéšæœºæ¢¯åº¦ä¸‹é™ï¼Œ1847å¹´æå‡ºã€‚æ¯æ¬¡é€‰æ‹©ä¸€ä¸ªmini-<br> batchï¼Œè€Œä¸æ˜¯å…¨éƒ¨æ ·æœ¬ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚å®ƒè§£å†³äº†éšæœºå°æ‰¹é‡æ ·æœ¬çš„é—®é¢˜ï¼Œä½†ä»ç„¶æœ‰è‡ªé€‚åº”å­¦ä¹ ç‡ã€å®¹æ˜“å¡åœ¨æ¢¯åº¦è¾ƒå°ç‚¹ç­‰é—®é¢˜ã€‚<br> <img src="https://images2.imgbox.com/cb/35/7cNSEuDp_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <strong>pytorchè°ƒç”¨æ–¹æ³•ï¼š</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token operator">&lt;</span>required parameter<span class="token operator">&gt;</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dampening<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> nesterov<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>ç›¸å…³ä»£ç ï¼š</strong></p> 
<p>â€‹</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> closure<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Performs a single optimization step.

        Arguments:
            closure (callable, optional): A closure that reevaluates the model
                and returns the loss.
        """</span>
        loss <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> closure <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            loss <span class="token operator">=</span> closure<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> group <span class="token keyword">in</span> self<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
            weight_decay <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span> <span class="token comment"># æƒé‡è¡°å‡ç³»æ•°</span>
            momentum <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'momentum'</span><span class="token punctuation">]</span> <span class="token comment"># åŠ¨é‡å› å­ï¼Œ0.9æˆ–0.8</span>
            dampening <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'dampening'</span><span class="token punctuation">]</span> <span class="token comment"># æ¢¯åº¦æŠ‘åˆ¶å› å­</span>
            nesterov <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'nesterov'</span><span class="token punctuation">]</span> <span class="token comment"># æ˜¯å¦ä½¿ç”¨nesterovåŠ¨é‡</span>

            <span class="token keyword">for</span> p <span class="token keyword">in</span> group<span class="token punctuation">[</span><span class="token string">'params'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> p<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                d_p <span class="token operator">=</span> p<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
                <span class="token keyword">if</span> weight_decay <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># è¿›è¡Œæ­£åˆ™åŒ–</span>
                	<span class="token comment"># add_è¡¨ç¤ºåŸå¤„æ”¹å˜ï¼Œd_p = d_p + weight_decay*p.data</span>
                    d_p<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>weight_decay<span class="token punctuation">,</span> p<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
                <span class="token keyword">if</span> momentum <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    param_state <span class="token operator">=</span> self<span class="token punctuation">.</span>state<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token comment"># ä¹‹å‰çš„ç´¯è®¡çš„æ•°æ®ï¼Œv(t-1)</span>
                    <span class="token comment"># è¿›è¡ŒåŠ¨é‡ç´¯è®¡è®¡ç®—</span>
                    <span class="token keyword">if</span> <span class="token string">'momentum_buffer'</span> <span class="token keyword">not</span> <span class="token keyword">in</span> param_state<span class="token punctuation">:</span>
                        buf <span class="token operator">=</span> param_state<span class="token punctuation">[</span><span class="token string">'momentum_buffer'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>clone<span class="token punctuation">(</span>d_p<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                    	<span class="token comment"># ä¹‹å‰çš„åŠ¨é‡</span>
                        buf <span class="token operator">=</span> param_state<span class="token punctuation">[</span><span class="token string">'momentum_buffer'</span><span class="token punctuation">]</span>
                        <span class="token comment"># buf= buf*momentum + ï¼ˆ1-dampeningï¼‰*d_p</span>
                        buf<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>momentum<span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> dampening<span class="token punctuation">,</span> d_p<span class="token punctuation">)</span>
                    <span class="token keyword">if</span> nesterov<span class="token punctuation">:</span> <span class="token comment"># ä½¿ç”¨neterovåŠ¨é‡</span>
                    	<span class="token comment"># d_p= d_p + momentum*buf</span>
                        d_p <span class="token operator">=</span> d_p<span class="token punctuation">.</span>add<span class="token punctuation">(</span>momentum<span class="token punctuation">,</span> buf<span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        d_p <span class="token operator">=</span> buf
				<span class="token comment"># p = p - lr*d_p</span>
                p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token operator">-</span>group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> d_p<span class="token punctuation">)</span>

        <span class="token keyword">return</span> loss
</code></pre> 
<p>â€‹</p> 
<h2><a id="6__301"></a>6 æœ€å</h2> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4f42f14236ef096af7c4a532072292c4/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">PythonåŸºç¡€æ•™ç¨‹â€”â€”ç”¨Pythonå¤„ç†Excelï¼</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dd1a688d661132f278ad4714cf33beab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€è½¯ä»¶é¡¹ç›®ç®¡ç†_è½¯ä»¶å·¥ç¨‹ã€‘è½¯ä»¶é¡¹ç›®ç®¡ç†è¯¾åç›¸å…³ä¹ é¢˜</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>