<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>竞赛保研 基于深度学习的植物识别算法 - cnn opencv python - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="竞赛保研 基于深度学习的植物识别算法 - cnn opencv python" />
<meta property="og:description" content="文章目录 0 前言1 课题背景2 具体实现3 数据收集和处理3 MobileNetV2网络4 损失函数softmax 交叉熵4.1 softmax函数4.2 交叉熵损失函数 5 优化器SGD6 最后 0 前言 🔥 优质竞赛项目系列，今天要分享的是
🚩 **基于深度学习的植物识别算法 **
该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！
🥇学长这里给一个题目综合评分(每项满分5分)
难度系数：3分工作量：4分创新点：4分 🧿 更多资料, 项目分享：
https://gitee.com/dancheng-senior/postgraduate
1 课题背景 植物在地球上是一种非常广泛的生命形式，直接关系到人类的生活环境，目前，植物识别主要依靠相关行业从业人员及有经验专家实践经验，工作量大、效率低。近年来，随着社会科技及经济发展越来越快，计算机硬件进一步更新，性能也日渐提高，数字图像采集设备应用广泛，设备存储空间不断增大，这样大量植物信息可被数字化。同时，基于视频的目标检测在模式识别、机器学习等领域得到快速发展，进而基于图像集分类方法研究得到发展。
本项目基于深度学习实现图像植物识别。
2 具体实现 3 数据收集和处理 数据是深度学习的基石
数据的主要来源有: 百度图片, 必应图片, 新浪微博, 百度贴吧, 新浪博客和一些专业的植物网站等
爬虫爬取的图像的质量参差不齐, 标签可能有误, 且存在重复文件, 因此必须清洗。清洗方法包括自动化清洗, 半自动化清洗和手工清洗。
自动化清洗包括:
滤除小尺寸图像.滤除宽高比很大或很小的图像.滤除灰度图像.图像去重: 根据图像感知哈希. 半自动化清洗包括:
图像级别的清洗: 利用预先训练的植物/非植物图像分类器对图像文件进行打分, 非植物图像应该有较低的得分; 利用前一阶段的植物分类器对图像文件 (每个文件都有一个预标类别) 进行预测, 取预标类别的概率值为得分, 不属于原预标类别的图像应该有较低的得分. 可以设置阈值, 滤除很低得分的文件; 另外利用得分对图像文件进行重命名, 并在资源管理器选择按文件名排序, 以便于后续手工清洗掉非植物图像和不是预标类别的图像.类级别的清洗 手工清洗: 人工判断文件夹下图像是否属于文件夹名所标称的物种, 这需要相关的植物学专业知识, 是最耗时且枯燥的环节, 但也凭此认识了不少的植物." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9acc4996f7c83ffcd3d84c97979f258c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T17:59:06+08:00" />
<meta property="article:modified_time" content="2024-01-10T17:59:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">竞赛保研 基于深度学习的植物识别算法 - cnn opencv python</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0__3" rel="nofollow">0 前言</a></li><li><a href="#1__21" rel="nofollow">1 课题背景</a></li><li><a href="#2__26" rel="nofollow">2 具体实现</a></li><li><a href="#3__32" rel="nofollow">3 数据收集和处理</a></li><li><a href="#3_MobileNetV2_51" rel="nofollow">3 MobileNetV2网络</a></li><li><a href="#4_softmax__149" rel="nofollow">4 损失函数softmax 交叉熵</a></li><li><ul><li><a href="#41_softmax_151" rel="nofollow">4.1 softmax函数</a></li><li><a href="#42__196" rel="nofollow">4.2 交叉熵损失函数</a></li></ul> 
  </li><li><a href="#5_SGD_234" rel="nofollow">5 优化器SGD</a></li><li><a href="#6__301" rel="nofollow">6 最后</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0__3"></a>0 前言</h2> 
<p>🔥 优质竞赛项目系列，今天要分享的是</p> 
<p>🚩 **基于深度学习的植物识别算法 **</p> 
<p>该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！</p> 
<p>🥇学长这里给一个题目综合评分(每项满分5分)</p> 
<ul><li>难度系数：3分</li><li>工作量：4分</li><li>创新点：4分</li></ul> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h2><a id="1__21"></a>1 课题背景</h2> 
<p>植物在地球上是一种非常广泛的生命形式，直接关系到人类的生活环境，目前，植物识别主要依靠相关行业从业人员及有经验专家实践经验，工作量大、效率低。近年来，随着社会科技及经济发展越来越快，计算机硬件进一步更新，性能也日渐提高，数字图像采集设备应用广泛，设备存储空间不断增大，这样大量植物信息可被数字化。同时，基于视频的目标检测在模式识别、机器学习等领域得到快速发展，进而基于图像集分类方法研究得到发展。<br> 本项目基于深度学习实现图像植物识别。</p> 
<h2><a id="2__26"></a>2 具体实现</h2> 
<p><img src="https://images2.imgbox.com/c3/f5/JNST3wSA_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/53/27/vuaMtDjS_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/de/b2/N4SELpr0_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3__32"></a>3 数据收集和处理</h2> 
<p>数据是深度学习的基石<br> 数据的主要来源有: 百度图片, 必应图片, 新浪微博, 百度贴吧, 新浪博客和一些专业的植物网站等<br> 爬虫爬取的图像的质量参差不齐, 标签可能有误, 且存在重复文件, 因此必须清洗。清洗方法包括自动化清洗, 半自动化清洗和手工清洗。<br> 自动化清洗包括:</p> 
<ul><li>滤除小尺寸图像.</li><li>滤除宽高比很大或很小的图像.</li><li>滤除灰度图像.</li><li>图像去重: 根据图像感知哈希.</li></ul> 
<p>半自动化清洗包括:</p> 
<ul><li>图像级别的清洗: 利用预先训练的植物/非植物图像分类器对图像文件进行打分, 非植物图像应该有较低的得分; 利用前一阶段的植物分类器对图像文件 (每个文件都有一个预标类别) 进行预测, 取预标类别的概率值为得分, 不属于原预标类别的图像应该有较低的得分. 可以设置阈值, 滤除很低得分的文件; 另外利用得分对图像文件进行重命名, 并在资源管理器选择按文件名排序, 以便于后续手工清洗掉非植物图像和不是预标类别的图像.</li><li>类级别的清洗</li></ul> 
<p>手工清洗: 人工判断文件夹下图像是否属于文件夹名所标称的物种, 这需要相关的植物学专业知识, 是最耗时且枯燥的环节, 但也凭此认识了不少的植物.</p> 
<h2><a id="3_MobileNetV2_51"></a>3 MobileNetV2网络</h2> 
<p><strong>简介</strong></p> 
<p>MobileNet网络是Google最近提出的一种小巧而高效的CNN模型，其在accuracy和latency之间做了折中。</p> 
<p><strong>主要改进点</strong></p> 
<p>相对于MobileNetV1，MobileNetV2 主要改进点：</p> 
<ul><li>引入倒残差结构，先升维再降维，增强梯度的传播，显著减少推理期间所需的内存占用（Inverted Residuals）</li><li>去掉 Narrow layer(low dimension or depth) 后的 ReLU，保留特征多样性，增强网络的表达能力（Linear Bottlenecks）</li><li>网络为全卷积，使得模型可以适应不同尺寸的图像；使用 RELU6（最高输出为 6）激活函数，使得模型在低精度计算下具有更强的鲁棒性</li><li>MobileNetV2 Inverted residual block 如下所示，若需要下采样，可在 DW 时采用步长为 2 的卷积</li><li>小网络使用小的扩张系数（expansion factor），大网络使用大一点的扩张系数（expansion factor），推荐是5~10，论文中 t = 6 t = 6t=6</li></ul> 
<p><strong>倒残差结构（Inverted residual block</strong> ）</p> 
<p>ResNet的Bottleneck结构是降维-&gt;卷积-&gt;升维，是两边细中间粗</p> 
<p>而MobileNetV2是先升维（6倍）-&gt; 卷积 -&gt; 降维，是沙漏形。<br> <img src="https://images2.imgbox.com/65/1b/QoQkFlxg_o.png" alt="在这里插入图片描述">区别于MobileNetV1,<br> MobileNetV2的卷积结构如下：<br> <img src="https://images2.imgbox.com/c4/5a/LW9IzqCE_o.png" alt="在这里插入图片描述"><br> 因为DW卷积不改变通道数，所以如果上一层的通道数很低时，DW只能在低维空间提取特征，效果不好。所以V2版本在DW前面加了一层PW用来升维。</p> 
<p>同时V2去除了第二个PW的激活函数改用线性激活，因为激活函数在高维空间能够有效地增加非线性，但在低维空间时会破坏特征。由于第二个PW主要的功能是降维，所以不宜再加ReLU6。<br> <img src="https://images2.imgbox.com/28/dd/vWS9ayNy_o.png" alt="在这里插入图片描述"><br> <strong>tensorflow相关实现代码</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">

    <span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
    <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
    <span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> Sequential<span class="token punctuation">,</span> Model
    
    <span class="token keyword">class</span> <span class="token class-name">ConvBNReLU</span><span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>conv <span class="token operator">=</span> layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> 
                                      kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> 
                                      strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> 
                                      padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> 
                                      use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                      name<span class="token operator">=</span><span class="token string">'Conv2d'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>bn <span class="token operator">=</span> layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'BatchNorm'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>activation <span class="token operator">=</span> layers<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>max_value<span class="token operator">=</span><span class="token number">6.0</span><span class="token punctuation">)</span>   <span class="token comment"># ReLU6</span>
            
        <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>training<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> x


    <span class="token keyword">class</span> <span class="token class-name">InvertedResidualBlock</span><span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">,</span> out_channel<span class="token punctuation">,</span> strides<span class="token punctuation">,</span> expand_ratio<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>InvertedResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>hidden_channel <span class="token operator">=</span> in_channel <span class="token operator">*</span> expand_ratio
            self<span class="token punctuation">.</span>use_shortcut <span class="token operator">=</span> <span class="token punctuation">(</span>strides <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token punctuation">(</span>in_channel <span class="token operator">==</span> out_channel<span class="token punctuation">)</span>
            
            layer_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token comment"># first bottleneck does not need 1*1 conv</span>
            <span class="token keyword">if</span> expand_ratio <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token comment"># 1x1 pointwise conv</span>
                layer_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">(</span>out_channel<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'expand'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layer_list<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
                
                <span class="token comment"># 3x3 depthwise conv </span>
                layers<span class="token punctuation">.</span>DepthwiseConv2D<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'depthwise'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'depthwise/BatchNorm'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>max_value<span class="token operator">=</span><span class="token number">6.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                
                <span class="token comment">#1x1 pointwise conv(linear) </span>
                <span class="token comment"># linear activation y = x -&gt; no activation function</span>
                layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span>out_channel<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'project'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'project/BatchNorm'</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            self<span class="token punctuation">.</span>main_branch <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>layer_list<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'expanded_conv'</span><span class="token punctuation">)</span>
        
        <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_shortcut<span class="token punctuation">:</span>
                <span class="token keyword">return</span> inputs <span class="token operator">+</span> self<span class="token punctuation">.</span>main_branch<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span> self<span class="token punctuation">.</span>main_branch<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>  



</code></pre> 
<p>​<br> ​</p> 
<h2><a id="4_softmax__149"></a>4 损失函数softmax 交叉熵</h2> 
<h3><a id="41_softmax_151"></a>4.1 softmax函数</h3> 
<p>Softmax函数由下列公式定义<br> <img src="https://images2.imgbox.com/8c/5f/UWfX2PNr_o.png" alt="在这里插入图片描述"><br> softmax 的作用是把 一个序列，变成概率。</p> 
<p><img src="https://images2.imgbox.com/32/f6/Rup9TxGD_o.png" alt="在这里插入图片描述"></p> 
<p>softmax用于多分类过程中，它将多个神经元的输出，映射到（0,1）区间内，所有概率的和将等于1。</p> 
<p><strong>python实现</strong></p> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    shift_x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token comment"># 防止输入增大时输出为nan</span>
    exp_x <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>shift_x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_x <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>exp_x<span class="token punctuation">)</span>
</code></pre> 
<p><strong>PyTorch封装的Softmax()函数</strong></p> 
<p>dim参数：</p> 
<ul><li> <p>dim为0时，对所有数据进行softmax计算</p> </li><li> <p>dim为1时，对某一个维度的列进行softmax计算</p> </li><li> <p>dim为-1 或者2 时，对某一个维度的行进行softmax计算</p> <pre><code class="prism language-python"><span class="token keyword">import</span> torch
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输入："</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输出："</span><span class="token punctuation">,</span>outputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输出之和："</span><span class="token punctuation">,</span>outputs<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> </li></ul> 
<h3><a id="42__196"></a>4.2 交叉熵损失函数</h3> 
<p><strong>定义如下:</strong><br> <img src="https://images2.imgbox.com/27/7e/fDG7tqxB_o.png" alt="在这里插入图片描述"><br> <strong>python实现</strong></p> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>nan_to_num<span class="token punctuation">(</span><span class="token operator">-</span>y<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment"># tensorflow version</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span><span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>y_<span class="token operator">*</span>tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> reduction_indices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment"># numpy version</span>
loss <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>PyTorch实现</strong><br> 交叉熵函数分为二分类(torch.nn.BCELoss())和多分类函数(torch.nn.CrossEntropyLoss()</p> 
<p>​</p> 
<pre><code class="prism language-python">
    <span class="token comment"># 二分类 损失函数</span>
    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    l <span class="token operator">=</span> loss<span class="token punctuation">(</span>pred，real<span class="token punctuation">)</span>


    <span class="token comment"># 多分类损失函数</span>
    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>​</p> 
<h2><a id="5_SGD_234"></a>5 优化器SGD</h2> 
<p><strong>简介</strong><br> SGD全称Stochastic Gradient Descent，随机梯度下降，1847年提出。每次选择一个mini-<br> batch，而不是全部样本，使用梯度下降来更新模型参数。它解决了随机小批量样本的问题，但仍然有自适应学习率、容易卡在梯度较小点等问题。<br> <img src="https://images2.imgbox.com/cb/35/7cNSEuDp_o.png" alt="在这里插入图片描述"><br> <strong>pytorch调用方法：</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token operator">&lt;</span>required parameter<span class="token operator">&gt;</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dampening<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> nesterov<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>相关代码：</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> closure<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Performs a single optimization step.

        Arguments:
            closure (callable, optional): A closure that reevaluates the model
                and returns the loss.
        """</span>
        loss <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> closure <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            loss <span class="token operator">=</span> closure<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> group <span class="token keyword">in</span> self<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
            weight_decay <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span> <span class="token comment"># 权重衰减系数</span>
            momentum <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'momentum'</span><span class="token punctuation">]</span> <span class="token comment"># 动量因子，0.9或0.8</span>
            dampening <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'dampening'</span><span class="token punctuation">]</span> <span class="token comment"># 梯度抑制因子</span>
            nesterov <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'nesterov'</span><span class="token punctuation">]</span> <span class="token comment"># 是否使用nesterov动量</span>

            <span class="token keyword">for</span> p <span class="token keyword">in</span> group<span class="token punctuation">[</span><span class="token string">'params'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> p<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                d_p <span class="token operator">=</span> p<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
                <span class="token keyword">if</span> weight_decay <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># 进行正则化</span>
                	<span class="token comment"># add_表示原处改变，d_p = d_p + weight_decay*p.data</span>
                    d_p<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>weight_decay<span class="token punctuation">,</span> p<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
                <span class="token keyword">if</span> momentum <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    param_state <span class="token operator">=</span> self<span class="token punctuation">.</span>state<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token comment"># 之前的累计的数据，v(t-1)</span>
                    <span class="token comment"># 进行动量累计计算</span>
                    <span class="token keyword">if</span> <span class="token string">'momentum_buffer'</span> <span class="token keyword">not</span> <span class="token keyword">in</span> param_state<span class="token punctuation">:</span>
                        buf <span class="token operator">=</span> param_state<span class="token punctuation">[</span><span class="token string">'momentum_buffer'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>clone<span class="token punctuation">(</span>d_p<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                    	<span class="token comment"># 之前的动量</span>
                        buf <span class="token operator">=</span> param_state<span class="token punctuation">[</span><span class="token string">'momentum_buffer'</span><span class="token punctuation">]</span>
                        <span class="token comment"># buf= buf*momentum + （1-dampening）*d_p</span>
                        buf<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>momentum<span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> dampening<span class="token punctuation">,</span> d_p<span class="token punctuation">)</span>
                    <span class="token keyword">if</span> nesterov<span class="token punctuation">:</span> <span class="token comment"># 使用neterov动量</span>
                    	<span class="token comment"># d_p= d_p + momentum*buf</span>
                        d_p <span class="token operator">=</span> d_p<span class="token punctuation">.</span>add<span class="token punctuation">(</span>momentum<span class="token punctuation">,</span> buf<span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        d_p <span class="token operator">=</span> buf
				<span class="token comment"># p = p - lr*d_p</span>
                p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token operator">-</span>group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> d_p<span class="token punctuation">)</span>

        <span class="token keyword">return</span> loss
</code></pre> 
<p>​</p> 
<h2><a id="6__301"></a>6 最后</h2> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4f42f14236ef096af7c4a532072292c4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python基础教程——用Python处理Excel！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dd1a688d661132f278ad4714cf33beab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【软件项目管理_软件工程】软件项目管理课后相关习题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>