<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>4、迁移学习和预训练模型 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="4、迁移学习和预训练模型" />
<meta property="og:description" content="注：迁移学习内容来自于王晋东老师的《迁移学习简明手册》
1、什么是迁移学习 迁移学习，顾名思义，就是要进行迁移。放到人工智能和机器学习的学科里，迁移学习是一种学习的思想和模式。
首先机器学习是人工智能的一大类重要方法，也是目前发展最迅速、效果最显著的方法。机器学习解决的是让机器自主地从数据中获取知识，从而应用于新的问题中。迁移学习作为机器学习的一个重要分支，侧重于将已经学习过的知识迁移应用于新的问题中。
迁移学习的核心问题是，找到新问题和原问题之间的相似性，才可顺利地实现知识的迁移。
例子：
在我们一开始说的天气问题中，那些北半球的天气之所以相似，是因为它们的地理位置相似；
而南北半球的天气之所以有差异，也是因为地理位置有根本不同。
其实我们人类对于迁移学习这种能力，是与生俱来的。
比如，我们如果已经会打乒乓球，就可以类比着学习打网球。再比如，我们如果已经会下中国象棋，就可以类比着下国际象棋。
因为这些活动之间，往往有着极高的相似性。生活中常用的“举一反三”、“照猫画虎”就很好地体现了迁移学习的思想。
迁移学习的定义：
迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。
1.1、为什么需要迁移学习 1. 大数据与少标注之间的矛盾。 我们正处在一个大数据时代，每天每时，社交网络、智能交通、视频监控、行业物流等，都产生着海量的图像、文本、语音等各类数据。数据的增多，使得机器学习和深度学习模型可以依赖于如此海量的数据，持续不断地训练和更新相应的模型，使得模型的性能越来越好，越来越适合特定场景的应用。然而，这些大数据带来了严重的问题：总是缺乏完善的数据标注。 2. 大数据与弱计算之间的矛盾。 大数据，就需要大设备、强计算能力的设备来进行存储和计算。然而，大数据的大计算能力，是” 有钱人” 才能玩得起的游戏。比如Google，Facebook，Microsoft，这些巨无霸公司有着雄厚的计算能力去利用这些数据训练模型。例如，ResNet 需要很长的时间进行训练。Google TPU 也都是有钱人的才可以用得起的。绝大多数普通用户是不可能具有这些强计算能力的。这就引发了大数据和弱计算之间的矛盾。在这种情况下，普通人想要利用这些海量的大数据去训练模型完成自己的任务，基本上不太可能。那么如何让普通人也能利用这些数据和模型？ 3. 普适化模型与个性化需求之间的矛盾。 机器学习的目标是构建一个尽可能通用的模型，使得这个模型对于不同用户、不同设备、不同环境、不同需求，都可以很好地进行满足。这是我们的美好愿景。这就是要尽可能地提高机器学习模型的泛化能力，使之适应不同的数据情形。基于这样的愿望，我们构建了多种多样的普适化模型，来服务于现实应用。比如导航模型，可以定位及导航所有的路线。但是不同的人有不同的需求。比如有的人喜欢走高速，有的人喜欢走偏僻小路，这就是个性化需求。并且，不同的用户，通常都有不同的隐私需求。这也是构建应用需要着重考虑的。所以目前的情况是，我们对于每一个通用的任务都构建了一个通用的模型。这个模型可以解决绝大多数的公共问题。但是具体到每个个体、每个需求，都存在其唯一性和特异性，一个普适化的通用模型根本无法满足。那么，能否将这个通用的模型加以改造和适配，使其更好地服务于人们的个性化需求？ 4. 特定应用的需求。 机器学习已经被广泛应用于现实生活中。在这些应用中，也存在着一些特定的应用，它们面临着一些现实存在的问题。比如推荐系统的冷启动问题。一个新的推荐系统，没有足够的用户数据，如何进行精准的推荐? 一个崭新的图片标注系统，没有足够的标签，如何进行精准的服务？现实世界中的应用驱动着我们去开发更加便捷更加高效的机器学习方法来加以解决。 上述存在的几个重要问题，使得传统的机器学习方法疲于应对。迁移学习则可以很好地进行解决。那么，迁移学习是如何进行解决的呢?
1. 大数据与少标注：迁移数据标注 单凭借少量的标注数据，无法准确地训练高可用度的模型。为了解决这个问题，直观的想法是：多增加一些标注数据。但是不依赖于人工，如何增加标注数据？利用迁移学习的思想，我们可以寻找一些与目标数据相近的有标注的数据，从而利用这些数据来构建模型，增加我们目标数据的标注。 2、大数据与弱计算：模型迁移 不可能所有人都有能力利用大数据快速进行模型的训练。利用迁移学习的思想，我们可以将那些大公司在大数据上训练好的模型，迁移到我们的任务中。针对于我们的任务进行微调，从而我们也可以拥有在大数据上训练好的模型。更进一步，我们可以将这些模型针对我们的任务进行自适应更新，从而取得更好的效果。
3、普适化模型与个性化需求：自适应学习 为了解决个性化需求的挑战，我们利用迁移学习的思想，进行自适应的学习。考虑到不同用户之间的相似性和差异性，我们对普适化模型进行灵活的调整，以便完成我们的任务。
4、特定应用的需求：相似领域知识迁移 为了满足特定领域应用的需求，我们可以利用上述介绍过的手段，从数据和模型方法上进行迁移学习。
以上用表格概括入下：
2、预训练模型 采用链接：https://www.zhihu.com/question/327642286/answer/1465037757
预训练模型可以把迁移学习很好地用起来。这和小孩读书一样，一开始语文、数学、化学都学，读书、网上游戏等，在脑子里积攒了很多。当他学习计算机时，实际上把他以前学到的所有知识都带进去了。如果他以前没上过中学，没上过小学，突然学计算机就不懂这里有什么道理。这和我们预训练模型一样，预训练模型就意味着把人类的语言知识，先学了一个东西，然后再代入到某个具体任务，就顺手了，就是这么一个简单的道理。
为什么要做预训练模型 自然语言处理（NLP），目的是使得计算机具备人类的听、说、读、写、译、问、答、搜索、摘要、对话和聊天等能力，并可利用知识和常识进行推理和决策，并支持客服、诊断、法律、教学等场景。
预训练模型，则是使自然语言处理由原来的手工调参、依靠 ML 专家的阶段，进入到可以大规模、可复制的大工业施展的阶段。而且预训练模型从单语言、扩展到多语言、多模态任务。
预训练通过自监督学习从大规模数据中获得与具体任务无关的预训练模型。体现某一个词在一个特定上下文中的语义表征。第二个步骤是微调，针对具体的任务修正网络。训练数据可以是文本、文本-图像对、文本-视频对。预训练模型的训练方法可使用自监督学习技术（如自回归的语言模型和自编码技术）。可训练单语言、多语言和多模态的模型。此类模型可经过微调之后，用于支持分类、序列标记、结构预测和序列生成等各项技术，并构建文摘、机器翻译、图片检索、视频注释等应用。
为什么我们要做预训练模型？
首先，预训练模型是一种迁移学习的应用，利用几乎无限的文本，学习输入句子的每一个成员的上下文相关的表示，它隐式地学习到了通用的语法语义知识。第二，它可以将从开放领域学到的知识迁移到下游任务，以改善低资源任务，对低资源语言处理也非常有利。第三，预训练模型在几乎所有NLP任务中都取得了目前最佳的成果。最后，这个预训练模型&#43;微调机制具备很好的可扩展性，在支持一个新任务时，只需要利用该任务的标注数据进行微调即可，一般工程师就可以实现。 不管是图片识别还是自然语言处理，模型都朝着越来越臃肿，越来越大的方向发展。 每训练一个大的模型，都会消耗掉数小时甚至数天的时间。我们并不希望浪费太多的时间在训练上，所以拿到一个预训练模型就十分重要了。 基于预训练模型，我们能够用较少的模型，较快的速度得到一个适合于我们自己数据的新模型，而且这个模型效果也不会很差。
所以预训练的核心价值就是：
手头只有小数据集，也能得到一个好模型； 训练速度大大提升，不用从零开始训练。
预训练模型的三个关键技术 第一个关键技术是 Transformer
它在 NLP 各个任务中都取得了优异的性能，它是预训练语言模型的核心网络。给定一句话或是一个段落作为输入，首先将输入序列中各个词转换为其对应的词向量，同时加上每一个词的位置向量，体现词在序列的位置。然后将这些词向量输入到多层 Transformer 网络中，通过自注意力（self-attention）机制来学习词与词之间的关系，编码其上下文信息，再通过一个前馈网络经过非线性变化，输出综合了上下文特征的各个词的向量表示。每一层 Transformer 网络主要由 Multi-head self-attention 层（多头自注意力机制）和前馈网络层两个子层构成。Multi-head self-attention 会并行地执行多个不同参数的 self-attention，并将各个 self-attention 的结果拼接作为后续网络的输入，self-attention 机制会在后面中做详细介绍。此后，我们得到了蕴含当前上下文信息的各个词的表示，然后网络会将其输入到前馈网络层以计算非线性层次的特征。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/bed2841d411c104fe1722c5b3d3a1fdc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-25T00:27:23+08:00" />
<meta property="article:modified_time" content="2021-06-25T00:27:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">4、迁移学习和预训练模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><sub>注：迁移学习内容来自于王晋东老师的《迁移学习简明手册》</sub></p> 
</blockquote> 
<h2><a id="1_2"></a>1、什么是迁移学习</h2> 
<p>迁移学习，顾名思义，就是要进行迁移。放到人工智能和机器学习的学科里，迁移学习是一种<mark>学习的思想和模式</mark>。<br> 首先机器学习是人工智能的一大类重要方法，也是目前发展最迅速、效果最显著的方法。机器学习解决的是让机器自主地从数据中获取知识，从而应用于新的问题中。迁移学习作为机器学习的一个重要分支，<mark>侧重于将已经学习过的知识迁移应用于新的问题中</mark>。<br> 迁移学习的核心问题是，<mark>找到新问题和原问题之间的相似性</mark>，才可顺利地实现知识的迁移。<br> 例子：</p> 
<blockquote> 
 <p>在我们一开始说的天气问题中，那些北半球的天气之所以相似，是因为它们的地理位置相似；<br> 而南北半球的天气之所以有差异，也是因为地理位置有根本不同。<br> 其实我们人类对于迁移学习这种能力，是与生俱来的。<br> 比如，我们如果已经会打乒乓球，就可以类比着学习打网球。再比如，我们如果已经会下中国象棋，就可以类比着下国际象棋。<br> 因为这些活动之间，往往有着极高的相似性。生活中常用的“举一反三”、“照猫画虎”就很好地体现了迁移学习的思想。</p> 
</blockquote> 
<p>迁移学习的定义：<br> <mark><strong>迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。</strong></mark></p> 
<h2><a id="11_17"></a>1.1、为什么需要迁移学习</h2> 
<h5><a id="1__18"></a>1. 大数据与少标注之间的矛盾。</h5> 
<ul><li>我们正处在一个大数据时代，每天每时，社交网络、智能交通、视频监控、行业物流等，都产生着海量的图像、文本、语音等各类数据。数据的增多，使得机器学习和深度学习模型可以依赖于如此海量的数据，持续不断地训练和更新相应的模型，使得模型的性能越来越好，越来越适合特定场景的应用。然而，这些大数据带来了严重的问题：<strong>总是缺乏完善的数据标注</strong>。</li></ul> 
<h5><a id="2__22"></a>2. 大数据与弱计算之间的矛盾。</h5> 
<ul><li>大数据，就需要大设备、强计算能力的设备来进行存储和计算。然而，大数据的大计算能力，是” 有钱人” 才能玩得起的游戏。比如Google，Facebook，Microsoft，这些巨无霸公司有着雄厚的计算能力去利用这些数据训练模型。</li><li>例如，ResNet 需要很长的时间进行训练。Google TPU 也都是有钱人的才可以用得起的。绝大多数普通用户是不可能具有这些强计算能力的。这就引发了大数据和弱计算之间的矛盾。在这种情况下，普通人想要利用这些海量的大数据去训练模型完成自己的任务，基本上不太可能。那么如何让普通人也能利用这些数据和模型？</li></ul> 
<h5><a id="3__27"></a>3. 普适化模型与个性化需求之间的矛盾。</h5> 
<ul><li>机器学习的目标是构建一个尽可能通用的模型，使得这个模型对于不同用户、不同设备、不同环境、不同需求，都可以很好地进行满足。这是我们的美好愿景。这就是要尽可能地提高机器学习模型的泛化能力，使之适应不同的数据情形。基于这样的愿望，我们构建了多种多样的普适化模型，来服务于现实应用。</li><li>比如导航模型，可以定位及导航所有的路线。但是不同的人有不同的需求。比如有的人喜欢走高速，有的人喜欢走偏僻小路，这就是个性化需求。并且，不同的用户，通常都有不同的隐私需求。这也是构建应用需要着重考虑的。</li><li>所以目前的情况是，我们对于每一个通用的任务都构建了一个通用的模型。这个模型可以解决绝大多数的公共问题。但是具体到每个个体、每个需求，都存在其唯一性和特异性，一个普适化的通用模型根本无法满足。那么，能否将这个通用的模型加以改造和适配，使其更好地服务于人们的个性化需求？</li></ul> 
<h5><a id="4__32"></a>4. 特定应用的需求。</h5> 
<ul><li>机器学习已经被广泛应用于现实生活中。在这些应用中，也存在着一些特定的应用，它们面临着一些现实存在的问题。</li><li>比如推荐系统的冷启动问题。一个新的推荐系统，没有足够的用户数据，如何进行精准的推荐? 一个崭新的图片标注系统，没有足够的标签，如何进行精准的服务？</li><li>现实世界中的应用驱动着我们去开发更加便捷更加高效的机器学习方法来加以解决。</li></ul> 
<p>上述存在的几个重要问题，使得传统的机器学习方法疲于应对。迁移学习则可以很好地进行解决。那么，迁移学习是如何进行解决的呢?</p> 
<h5><a id="1__38"></a>1. 大数据与少标注：迁移数据标注</h5> 
<ul><li>单凭借少量的标注数据，无法准确地训练高可用度的模型。为了解决这个问题，直观的想法是：多增加一些标注数据。但是不依赖于人工，如何增加标注数据？利用迁移学习的思想，我们可以寻找一些<mark>与目标数据相近的有标注的数据</mark>，从而利用这些数据来构建模型，增加我们目标数据的标注。</li></ul> 
<h5><a id="2_41"></a>2、大数据与弱计算：模型迁移</h5> 
<p>不可能所有人都有能力利用大数据快速进行模型的训练。利用迁移学习的思想，我们可以将那些大公司在大数据上训练好的模型，迁移到我们的任务中。针对于我们的任务进行微调，从而我们也可以拥有在大数据上训练好的模型。更进一步，我们可以将这些模型针对我们的任务进行自适应更新，从而取得更好的效果。</p> 
<h5><a id="3_43"></a>3、普适化模型与个性化需求：自适应学习</h5> 
<p>为了解决个性化需求的挑战，我们利用迁移学习的思想，进行自适应的学习。考虑到不同用户之间的相似性和差异性，我们对普适化模型进行灵活的调整，以便完成我们的任务。</p> 
<h5><a id="4_45"></a>4、特定应用的需求：相似领域知识迁移</h5> 
<p>为了满足特定领域应用的需求，我们可以利用上述介绍过的手段，从数据和模型方法上进行迁移学习。<br> 以上用表格概括入下：<br> <img src="https://images2.imgbox.com/e7/33/JbNikuWv_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2_49"></a>2、预训练模型</h2> 
<blockquote> 
 <p>采用链接：https://www.zhihu.com/question/327642286/answer/1465037757</p> 
</blockquote> 
<p>预训练模型可以把迁移学习很好地用起来。这和小孩读书一样，一开始语文、数学、化学都学，读书、网上游戏等，在脑子里积攒了很多。当他学习计算机时，实际上把他以前学到的所有知识都带进去了。如果他以前没上过中学，没上过小学，突然学计算机就不懂这里有什么道理。这和我们预训练模型一样，<strong>预训练模型就意味着把人类的语言知识，先学了一个东西，然后再代入到某个具体任务，就顺手了，就是这么一个简单的道理。</strong></p> 
<h4><a id="_53"></a>为什么要做预训练模型</h4> 
<p>自然语言处理（NLP），目的是使得计算机具备人类的听、说、读、写、译、问、答、搜索、摘要、对话和聊天等能力，并可利用知识和常识进行推理和决策，并支持客服、诊断、法律、教学等场景。</p> 
<p>预训练模型，则是使自然语言处理由原来的手工调参、依靠 ML 专家的阶段，进入到可以大规模、可复制的大工业施展的阶段。而且预训练模型从单语言、扩展到多语言、多模态任务。</p> 
<p>预训练通过自监督学习从大规模数据中获得与具体任务无关的预训练模型。体现某一个词在一个特定上下文中的语义表征。第二个步骤是微调，针对具体的任务修正网络。训练数据可以是文本、文本-图像对、文本-视频对。预训练模型的训练方法可使用自监督学习技术（如自回归的语言模型和自编码技术）。可训练单语言、多语言和多模态的模型。此类模型可经过微调之后，用于支持分类、序列标记、结构预测和序列生成等各项技术，并构建文摘、机器翻译、图片检索、视频注释等应用。</p> 
<p>为什么我们要做预训练模型？</p> 
<ul><li>首先，预训练模型是一种迁移学习的应用，利用几乎无限的文本，学习输入句子的每一个成员的上下文相关的表示，它隐式地学习到了通用的语法语义知识。</li><li>第二，它可以将从开放领域学到的知识迁移到下游任务，以改善低资源任务，对低资源语言处理也非常有利。</li><li>第三，预训练模型在几乎所有NLP任务中都取得了目前最佳的成果。</li><li>最后，这个预训练模型+微调机制具备很好的可扩展性，在支持一个新任务时，只需要利用该任务的标注数据进行微调即可，一般工程师就可以实现。</li></ul> 
<p>不管是图片识别还是自然语言处理，模型都朝着越来越臃肿，越来越大的方向发展。 每训练一个大的模型，都会消耗掉数小时甚至数天的时间。我们并不希望浪费太多的时间在训练上，所以拿到一个预训练模型就十分重要了。 基于预训练模型，我们能够用较少的模型，较快的速度得到一个适合于我们自己数据的新模型，而且这个模型效果也不会很差。</p> 
<p>所以预训练的核心价值就是：</p> 
<blockquote> 
 <p>手头只有小数据集，也能得到一个好模型； 训练速度大大提升，不用从零开始训练。</p> 
</blockquote> 
<h5><a id="_73"></a>预训练模型的三个关键技术</h5> 
<p><img src="https://images2.imgbox.com/57/fd/9e0WugEx_o.png" alt="在这里插入图片描述"><br> <strong>第一个关键技术是 Transformer</strong><br> 它在 NLP 各个任务中都取得了优异的性能，它是预训练语言模型的核心网络。给定一句话或是一个段落作为输入，首先将输入序列中各个词转换为其对应的词向量，同时加上每一个词的位置向量，体现词在序列的位置。然后将这些词向量输入到多层 Transformer 网络中，通过自注意力（self-attention）机制来学习词与词之间的关系，编码其上下文信息，再通过一个前馈网络经过非线性变化，输出综合了上下文特征的各个词的向量表示。每一层 Transformer 网络主要由 Multi-head self-attention 层（多头自注意力机制）和前馈网络层两个子层构成。Multi-head self-attention 会并行地执行多个不同参数的 self-attention，并将各个 self-attention 的结果拼接作为后续网络的输入，self-attention 机制会在后面中做详细介绍。此后，我们得到了蕴含当前上下文信息的各个词的表示，然后网络会将其输入到前馈网络层以计算非线性层次的特征。</p> 
<p>在每一层 Transformer 网络中，会将残差连接（residual connection）把自注意力机制前或者前馈神经网络之前的向量引入进来，以增强自注意力机制或者前馈网络的输出结果向量。并且还做一个 layer normalization，也就是通过归一化把同层的各个节点的多维向量映射到一个区间里面，这样各层节点的向量在一个区间里面。这两个操作加入在每个子层后，可更加平滑地训练深层次网络。</p> 
<p>Transformer 可以用于编码，也可以用于解码。所谓解码就是根据一个句子的输入得到一个预想的结果，比如机器翻译（输入源语言句子，输出目标语言句子），或者阅读理解（输入文档和问题，输出答案）。解码时，已经解码出来的词要做一个自注意力机制，之后和编码得到的隐状态的序列再做一个注意力机制。这样可以做 N 层，然后通过一个线性层映射到词表的大小的一个向量。每个向量代表一个词表词的输出可能性，经过一个softmax 层得到每个词的输出概率。</p> 
<p>接下来介绍一下 self-attention 机制，以一个 head 作为示例。假定当前输入包含三个词，给定其输入词向量或是其上一层 Transformer 网络的输出，将其通过三组线性变换，转换得到三组 queries、keys 和 values 向量。Query 和 key 向量用来计算两两词之间的得分，也就是其依赖关系，这个得分会同其对应的 value 向量做加权和，以得到每个词综合上下文信息的表示。给定当前第一个词的 query 向量，其首先同各个词的 key 向量通过点积操作得到这两个词的得分，这些得分用来表示这两个词的依赖或是相关程度。这些得分之后会根据 query 等向量的维度做一定比例的缩放，并将这些得分通过 softmax 操作做归一化。之后，各个得分会同其相对应的 value 向量相乘得到针对第一个词加权的各个 value 向量，这些加权的 value 向量最终相加以得到当前第一个词的上下文表示。</p> 
<p>得到第一个词的上下文表示后，给定第二个词的 query 向量，我们会重复之前的操作，计算当前 query 向量同各个词 key 向量的得分，对这些得分做 softmax 归一化处理，并将这些得分同其对应的 value 向量做加权和，以得到其编码上下文信息的表示。</p> 
<p><strong>第二个关键技术是自监督学习</strong><br> 在预训练的模型中，AR（自回归）LM 和 AE（自动编码器）是最常用的自监督学习方法，其中，自回归 LM 旨在利用前面的词序列预测下个词的出现概率（语言模型）。自动编码器旨在对损坏的输入句子，比如遮掩了句子某个词、或者打乱了词序等，重建原始数据。通过这些自监督学习手段来学习单词的上下文相关表示。</p> 
<p><strong>第三个关键技术就是微调</strong><br> 在做具体任务时，微调旨在利用其标注样本对预训练网络的参数进行调整。以我们使用基于 BERT（一种流行的预训练模型）为例来判断两个句子是否语义相同。输入是两个句子，经过 BERT 得到每个句子的对应编码表示，我们可以简单地用预训练模型的第一个隐节点预测分类标记判断两个句子是同义句子的概率，同时需要额外加一个线性层和 softmax 计算得到分类标签的分布。预测损失可以反传给 BERT 再对网络进行微调。当然也可以针对具体任务设计一个新网络，把预训练的结果作为其输入。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2c6c8d5783cfeaf82b6b082cb61284c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">QT：.DLL库的封装和调用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ffd3bdd7b2b08a0e4ed7a1f8970af481/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">html中插入for循环,如何在html文档中使用for循环</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>