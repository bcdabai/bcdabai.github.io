<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习（1）RGB-D数据集：ScanNet - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习（1）RGB-D数据集：ScanNet" />
<meta property="og:description" content="本文主要介绍相关的RGB-D数据集，并完成其搬运工作。
目录 1. ScanNet数据集1.1 获取数据集1.2 解析数据集1.2.1 2D数据1.2.2 scannet_frames_25k 数据 1.3 数据集分割 [2. SUN RGB-D 数据集](http://rgbd.cs.princeton.edu/)2.1 获取数据集2.2 解析数据集 [3. NYU-Depth V2数据集](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)3.1 获取数据集3.2 解析数据集 4.TUM数据集[5. SceneNet RGB-D数据集](https://robotvault.bitbucket.io/scenenet-rgbd.html)参考资料 1. ScanNet数据集 1513个采集场景数据，21个类别的对象，其中，1201个场景用于训练，312个场景用于测试。
该数据集有四个评测任务：3D语义分割、3D实例分割、2D语义分割和2D实例分割。
ScanNet is an RGB-D video dataset containing 2.5 million views in more than 1500 scans, annotated with 3D camera poses, surface reconstructions, and instance-level semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowdsourced semantic annotation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3862e378efa727783169a45100ea236c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-22T17:59:45+08:00" />
<meta property="article:modified_time" content="2021-06-22T17:59:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习（1）RGB-D数据集：ScanNet</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><font face="华文中宋"></font><br> <font face="华文中宋" size="4" color="B"><br>  本文主要介绍相关的RGB-D数据集，并完成其<code>搬运工作</code>。</font></p> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#1_ScanNet_5" rel="nofollow">1. ScanNet数据集</a></li><li><ul><li><a href="#11__15" rel="nofollow">1.1 获取数据集</a></li><li><a href="#12__37" rel="nofollow">1.2 解析数据集</a></li><li><ul><li><a href="#121_2D_69" rel="nofollow">1.2.1 2D数据</a></li><li><a href="#122_scannet_frames_25k__115" rel="nofollow">1.2.2 scannet_frames_25k 数据</a></li></ul> 
   </li><li><a href="#13__124" rel="nofollow">1.3 数据集分割</a></li></ul> 
  </li><li><a href="#2_SUN_RGBD_httprgbdcsprincetonedu_129" rel="nofollow">[2. SUN RGB-D 数据集](http://rgbd.cs.princeton.edu/)</a></li><li><ul><li><a href="#21__135" rel="nofollow">2.1 获取数据集</a></li><li><a href="#22__144" rel="nofollow">2.2 解析数据集</a></li></ul> 
  </li><li><a href="#3_NYUDepth_V2httpscsnyuedusilbermandatasetsnyu_depth_v2html_223" rel="nofollow">[3. NYU-Depth V2数据集](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)</a></li><li><ul><li><a href="#31__232" rel="nofollow">3.1 获取数据集</a></li><li><a href="#32__236" rel="nofollow">3.2 解析数据集</a></li></ul> 
  </li><li><a href="#4TUMhttpsvisionintumdedatadatasetsrgbddatasetdownload_258" rel="nofollow">4.TUM数据集</a></li><li><a href="#5_SceneNet_RGBDhttpsrobotvaultbitbucketioscenenetrgbdhtml_264" rel="nofollow">[5. SceneNet RGB-D数据集](https://robotvault.bitbucket.io/scenenet-rgbd.html)</a></li><li><a href="#_269" rel="nofollow">参考资料</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1_ScanNet_5"></a>1. ScanNet数据集</h2> 
<p>1513个采集场景数据，21个类别的对象，其中，1201个场景用于训练，312个场景用于测试。<br> 该数据集有四个评测任务：3D语义分割、3D实例分割、2D语义分割和2D实例分割。</p> 
<p> ScanNet is an RGB-D video dataset containing 2.5 million views in more than 1500 scans, annotated with 3D camera poses, surface reconstructions, and instance-level semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowdsourced semantic annotation. We show that using this data helps achieve state-of-the-art performance on several 3D scene understanding tasks, including 3D object classification, semantic voxel labeling, and CAD model retrieval. More information can be found in our <a href="https://arxiv.org/abs/1702.04405" rel="nofollow">paper</a>.</p> 
<p><a href="http://www.scan-net.org/" rel="nofollow">官方链接</a></p> 
<p><a href="https://github.com/ScanNet/ScanNet">官方GitHub</a></p> 
<h3><a id="11__15"></a>1.1 获取数据集</h3> 
<ol><li> <p>申请数据集：<a href="http://kaldir.vc.in.tum.de/scannet/ScanNet_TOS.pdf" rel="nofollow">ScanNet Terms of Use</a> to scannet@googlegroups.com <img src="https://images2.imgbox.com/08/3d/QKMbkHzy_o.png" alt="2."></p> </li><li> <p>下载数据集</p> <pre><code class="prism language-bash"><span class="token comment">#-o 保存文件路径</span>
python download_scannet.py -o data
</code></pre> <p>由于2DRGB-D帧的数据量特别大，作者提供了下载较小子集的选项scannet_frames_25k（约25,000帧，从完整数据集中大约每100帧进行二次采样）通过ScanNet数据下载，有5.6G，还有基准评估scannet_frames_test。<strong>#TODO 更多细节待补</strong></p> <pre><code class="prism language-bash">PREPROCESSED_FRAMES_FILE <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'scannet_frames_25k.zip'</span>, <span class="token string">'5.6GB'</span><span class="token punctuation">]</span>
TEST_FRAMES_FILE <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'scannet_frames_test.zip'</span>, <span class="token string">'610MB'</span><span class="token punctuation">]</span>
</code></pre> <p>下载scannet_frames_25k</p> <pre><code class="prism language-bash">python download-scannet.py -o data --preprocessed_frames 
</code></pre> <p>一般会出现<code>urllib.error.HTTPError: HTTP Error 404: Not Found</code>,笔者的解决方法是将下图中马赛克的下的网页链接复制到浏览器，直接用浏览器或迅雷下载。笔者测试的是迅雷不能下载，浏览器需要科学上网，下载速度还是很可观的，8MB/S左右。<br> <img src="https://images2.imgbox.com/ff/ce/uErLnypZ_o.png" alt="在这里插入图片描述"></p> </li></ol> 
<h3><a id="12__37"></a>1.2 解析数据集</h3> 
<pre><code class="prism language-bash"><span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>.sens
	RGB-D传感器流（*sens）：压缩二进制格式，
	包含每帧的颜色、深度、相机姿势和其他数据。
	其中RGB图像大小为1296×968，深度图像大小为640×480
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_vh_clean.ply
	高质量重建后的surface mesh 文件（.ply）：
    <span class="token punctuation">(</span>Updated <span class="token keyword">if</span> had remove annotations<span class="token punctuation">)</span>
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_vh_clean_2.ply
    <span class="token punctuation">(</span>Updated <span class="token keyword">if</span> had remove annotations<span class="token punctuation">)</span>
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>.aggregation.json, <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_vh_clean.aggregation.json
    曲面网格分割文件（.segs.json）：记录了场景中物体分割的详细信息
    Updated aggregated instance-level semantic annotations on lo-res, hi-res meshes, respectively
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_vh_clean_2.labels.ply
    Updated visualization of aggregated semantic segmentation<span class="token punctuation">;</span> colored by nyu40 labels <span class="token punctuation">(</span>see legend referenced above<span class="token punctuation">;</span> ply property <span class="token string">'label'</span> denotes the ScanNet label <span class="token function">id</span><span class="token punctuation">)</span>
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_2d-label.zip
    Updated raw 2d projections of aggregated annotation labels as <span class="token number">16</span>-bit pngs with ScanNet label ids
    原始16位png标签标注信息，图像大小为1296×968，带有ScanNet的标签id
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_2d-instance.zip
    Updated raw 2d projections of aggregated annotation instances as <span class="token number">8</span>-bit pngs
    原始16位png实例标注信息，图像大小为1296×968
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_2d-label-filt.zip
    Updated filtered 2d projections of aggregated annotation labels as <span class="token number">16</span>-bit pngs with ScanNet label ids
    经过滤波的8位png标签标注信息，图像大小为1296×968，带有ScanNet的标签id
<span class="token operator">|</span>-- <span class="token operator">&lt;</span>scanId<span class="token operator">&gt;</span>_2d-instance-filt.zip
    Updated filtered 2d projections of aggregated annotation instances as <span class="token number">8</span>-bit pngs
    经过滤波的8位png实例标注信息，图像大小为1296×968
</code></pre> 
<p><code>目前还不清楚，label和instance的区别。</code></p> 
<h4><a id="121_2D_69"></a>1.2.1 2D数据</h4> 
<p>包括每一个场景下的N个帧（为了避免帧之间的重叠信息一般取的时候隔50取一帧）2D标签和实例数据提供为.png图像文件。彩色图像以8位RGB的形式提供.jpg，深度图片为16位 .png（除以1000可获得以米为单位的深度）。<font face="楷体">详细信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料1.</a></font></p> 
<p><img src="https://images2.imgbox.com/5d/f8/SRVwsGaq_o.png" alt="在这里插入图片描述"></p> 
<p><strong>2D图像数据解析</strong></p> 
<p><a href="https://github.com/ScanNet/ScanNet/tree/master/SensReader/python">解析代码链接</a></p> 
<ol><li> <p>安装依赖包imageio</p> <pre><code class="prism language-bash">pip <span class="token function">install</span> <span class="token assign-left variable">imageio</span><span class="token operator">==</span><span class="token number">1.1</span>
</code></pre> <p><code>Imageio: 'freeimage-3.15.1-win64.dll' was not found on your computer; downloading it now.</code><font face="楷体">详细信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料2.</a></font></p> <p>笔者的python2.7环境：<br> <img src="https://images2.imgbox.com/1e/de/jv5s7IVk_o.png" alt="在这里插入图片描述"></p> </li><li> <p>解析图像数据，推荐python2.7，python3存在struct.unpack str到bayes转换为题。</p> <pre><code class="prism language-bash">python reader.py --filename scene0000_00.sens --output_path image 
<span class="token comment">#python reader.py --filename [.sens file to export data from] --output_path [output directory to export data to]</span>
<span class="token comment">#Options:</span>
<span class="token comment">#--export_depth_images: export all depth frames as 16-bit pngs (depth shift 1000)</span>
<span class="token comment">#--export_color_images: export all color frames as 8-bit rgb jpgs</span>
<span class="token comment">#--export_poses: export all camera poses (4x4 matrix, camera to world)</span>
<span class="token comment">#--export_intrinsics: export camera intrinsics (4x4 matrix)</span>
</code></pre> <p>为了便于可视化解析进程，建议对SensorData.py文件进行修改，增加进度条部分代码</p> <pre><code class="prism language-python"><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 
<span class="token comment">#更换71行代码：for i in range(num_frames): 为：</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span>ncols<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token comment">#相应的81行、93行 也可以相应更换为：</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_skip<span class="token punctuation">)</span><span class="token punctuation">,</span>ncols<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_skip<span class="token punctuation">)</span><span class="token punctuation">,</span>ncols<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</code></pre> <p><img src="https://images2.imgbox.com/00/6a/5G8hNOud_o.png" alt="在这里插入图片描述"></p> </li><li> <p>解析结果：</p> <p>row：<br> <img src="https://images2.imgbox.com/53/5f/Nx09mk1w_o.png" alt="在这里插入图片描述"><br> filtered ：<br> <img src="https://images2.imgbox.com/66/a2/2pp8k1ij_o.png" alt="在这里插入图片描述"></p> </li></ol> 
<h4><a id="122_scannet_frames_25k__115"></a>1.2.2 scannet_frames_25k 数据</h4> 
<p>数据组成：</p> 
<p><img src="https://images2.imgbox.com/cf/eb/6cZznrR6_o.png" alt="在这里插入图片描述"><br> color图为每隔100帧进行二次采样的结果，depth、instance、label和pose分别对应其深度图、实例图、标签图和位置信息。# TODO intrinsics_color.txt和intrinsics_depth.txt为相机矩阵。<br> <img src="https://images2.imgbox.com/80/83/ccqZiXcW_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/30/cd/iECdWc8T_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="13__124"></a>1.3 数据集分割</h3> 
<p>还未开始相关工作，<font face="楷体">详细信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料3.</a></font></p> 
<p><a href="https://github.com/ScanNet/ScanNet/tree/master/Tasks/Benchmark">官方分割文件</a></p> 
<h2><a id="2_SUN_RGBD_httprgbdcsprincetonedu_129"></a><a href="http://rgbd.cs.princeton.edu/" rel="nofollow">2. SUN RGB-D 数据集</a></h2> 
<p>该数据集有四个评测任务：场景分类，语义分割，室内布局估计，3D目标检测。</p> 
<ul><li>包含10,335个 RGB-­D 图像，其规模与 PASCAL VOC 相似；</li><li>是NYU depth v2 , Berkeley B3DO , and SUN3D ，三个数据集的并集；</li><li>整个数据集都进行了密集注释，其中包括 146,617 个 2D 多边形（平面目标框）和64,595个具有精确物体方向的3D 边界框（三维目标框）；</li><li>具有较高的物体方向的准确性及 3D 空间布局和场景分类。</li></ul> 
<h3><a id="21__135"></a>2.1 获取数据集</h3> 
<p>Download：<a href="http://rgbd.cs.princeton.edu/challenge.html" rel="nofollow">http://rgbd.cs.princeton.edu/challenge.html</a></p> 
<pre><code class="prism language-python"><span class="token comment"># see: http://rgbd.cs.princeton.edu/ in section Data and Annotation</span>
DATASET_URL <span class="token operator">=</span> <span class="token string">'http://rgbd.cs.princeton.edu/data/SUNRGBD.zip'</span>
DATASET_TOOLBOX_URL <span class="token operator">=</span> <span class="token string">'http://rgbd.cs.princeton.edu/data/SUNRGBDtoolbox.zip'</span>
</code></pre> 
<h3><a id="22__144"></a>2.2 解析数据集</h3> 
<p>README.txt：</p> 
<pre><code class="prism language-bash">********************************************************************************
Data: Image depth and label data are <span class="token keyword">in</span> SUNRGBD.zip
image: rgb image
depth: 
depth image  to <span class="token builtin class-name">read</span> the depth see the code <span class="token keyword">in</span> SUNRGBDtoolbox/read3dPoints/.
	extrinsics: the rotation matrix to align the point could with gravity
fullres: full resolution depth and rgb image
intrinsics.txt  <span class="token builtin class-name">:</span> sensor intrinsic
scene.txt  <span class="token builtin class-name">:</span> scene <span class="token builtin class-name">type</span>
annotation2Dfinal  <span class="token builtin class-name">:</span> 2D segmentation
annotation3Dfinal  <span class="token builtin class-name">:</span> 3D bounding box
annotation3Dlayout <span class="token builtin class-name">:</span> 3D room layout bounding box

*********************************************************************************
Label: 
In SUNRGBDtoolbox/Metadata 
SUNRGBDMeta.mat:  
	2D,3D bounding box ground truth and image information <span class="token keyword">for</span> each frame.
SUNRGBD2Dseg.mat:  
	2D segmetation ground truth. 
The index <span class="token keyword">in</span> <span class="token string">"SUNRGBD2Dseg(imageId).seglabelall"</span>  
	mapping the name to <span class="token string">"seglistall"</span><span class="token builtin class-name">.</span> 
The index <span class="token keyword">in</span> <span class="token string">"SUNRGBD2Dseg(imageId).seglabel"</span> 
	are mapping the object name <span class="token keyword">in</span> <span class="token string">"seg37list"</span><span class="token builtin class-name">.</span>
 
********************************************************************************
</code></pre> 
<p>共有37个类别</p> 
<pre><code class="prism language-bash">wall,floor,cabinet,bed,chair,sofa,
table,door,window,bookshelf,picture,
counter,blinds,desk,shelves,curtain,
dresser,pillow,mirror,floor_mat,clothes,
ceiling,books,fridge,tv,paper,towel,
shower_curtain,box,whiteboard,person,
night_stand,toilet,sink,lamp,bathtub,bag
</code></pre> 
<p>部分解析代码：</p> 
<ol><li>直接从SUNRGBDtoolbox/Metadata中解析数据路径<pre><code class="prism language-python"><span class="token keyword">for</span> i<span class="token punctuation">,</span> meta <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>SUNRGBDMeta<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    meta_dir <span class="token operator">=</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>meta<span class="token punctuation">.</span>rgbpath<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    real_dir <span class="token operator">=</span> meta_dir<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/n/fs/sun3d/data/SUNRGBD/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    depth_bfx_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>real_dir<span class="token punctuation">,</span> <span class="token string">'depth_bfx/'</span> <span class="token operator">+</span> meta<span class="token punctuation">.</span>depthname<span class="token punctuation">)</span>
    rgb_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>real_dir<span class="token punctuation">,</span> <span class="token string">'image/'</span> <span class="token operator">+</span> meta<span class="token punctuation">.</span>rgbname<span class="token punctuation">)</span>

    label_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>real_dir<span class="token punctuation">,</span> <span class="token string">'label/label.npy'</span><span class="token punctuation">)</span>
    label_path_full <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_path<span class="token punctuation">,</span> <span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> label_path<span class="token punctuation">)</span>

    <span class="token comment"># save segmentation (label_path) as numpy array</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>label_path_full<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>label_path_full<span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        label <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
            SUNRGBD2Dseg<span class="token punctuation">[</span>seglabel<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>\
            astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
        np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>label_path_full<span class="token punctuation">,</span> label<span class="token punctuation">)</span>

    <span class="token keyword">if</span> meta_dir <span class="token keyword">in</span> split_train<span class="token punctuation">:</span>
        img_dir_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> rgb_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        depth_dir_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> depth_bfx_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        label_dir_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> label_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        img_dir_test<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> rgb_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        depth_dir_test<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> depth_bfx_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        label_dir_test<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'SUNRGBD'</span><span class="token punctuation">,</span> label_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> </li><li>数据可视化 <img src="https://images2.imgbox.com/b1/6e/J0nwfOQF_o.png" alt="在这里插入图片描述"></li></ol> 
<p><a href="https://blog.csdn.net/weixin_36662031/article/details/85599624?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=RGBD%E6%95%B0%E6%8D%AE%E9%9B%86&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-8-.first_rank_v2_pc_rank_v29&amp;spm=1018.2226.3001.4187">SUN RGB-D 数据集论文翻译</a></p> 
<p><font face="楷体">更多信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料5.</a></font></p> 
<h2><a id="3_NYUDepth_V2httpscsnyuedusilbermandatasetsnyu_depth_v2html_223"></a><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="nofollow">3. NYU-Depth V2数据集</a></h2> 
<ul><li>自3个城市的64个场景;</li><li>包含了1449张具有语义标注的RGB和深度图像和407024张没有语义标注的图像;</li></ul> 
<p>V2和V1的区别：<br> <img src="https://images2.imgbox.com/d2/c3/rTRObJaB_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/f5/86/773iDF3u_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="31__232"></a>3.1 获取数据集</h3> 
<p><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="nofollow">Download</a></p> 
<h3><a id="32__236"></a>3.2 解析数据集</h3> 
<p><img src="https://images2.imgbox.com/f0/8f/kYbjuQpz_o.png" alt="在这里插入图片描述"></p> 
<ul><li>accelData-采用Nx4的加速度计值矩阵，当每帧都被取走。这些列包括设备的滚动、偏航、俯仰和倾斜角度。</li><li>depths-HxWxN维度的矩阵深度图，其中H和W分别为高度和宽度，N为图像的个数。深度元素的值是米。</li><li>images-HxWx3xN RGB图像矩阵，其中H和W分别是高度和宽度，N是图像的数量</li><li>labels-HxWxN标签矩阵，其中H和W分别是高度和宽度，N是图像数量。 标签范围从1…C，其中C是类的总数。 标签的范围从1…C是类的总数。如果一个像素的标签值为0，那么这个像素就没有标记。</li><li>names-每个类的英文名称的Cx1单元格数组</li><li>namesTolds-从英文标签名称到ID（使用C键值对）</li><li>rawDepths-HxWxN深度图矩阵，其中H和W分别是高度和宽度，N是图像数量。 这些深度图是kinect的原始输出</li><li>scenes-每个图像拍摄场景名称的Cx1单元阵列</li></ul> 
<p><font face="楷体">详细信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料6</a></font></p> 
<p><a href="https://blog.csdn.net/shilling_bai/article/details/117653487?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162540820016780261944140%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=162540820016780261944140&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-117653487.pc_search_result_cache&amp;utm_term=NYU%20Depth%20Dataset%20V2&amp;spm=1018.2226.3001.4187">解析代码</a></p> 
<h2><a id="4TUMhttpsvisionintumdedatadatasetsrgbddatasetdownload_258"></a><a href="https://vision.in.tum.de/data/datasets/rgbd-dataset/download" rel="nofollow">4.TUM数据集</a></h2> 
<ul><li>包含从RGB­-D传感器采集到的一些室内的序列图像，</li><li>同时TUM提供很多数据子集，每个子集中包含了图像序列、相应的轮廓和完整的校准参数。</li><li>通过数据集可以在不同的纹理下、不同的光照和不同的结构条件下去评估物体重建和SLAM/视觉里程计的性能。</li></ul> 
<h2><a id="5_SceneNet_RGBDhttpsrobotvaultbitbucketioscenenetrgbdhtml_264"></a><a href="https://robotvault.bitbucket.io/scenenet-rgbd.html" rel="nofollow">5. SceneNet RGB-D数据集</a></h2> 
<p><font face="楷体">详细信息见<a href="#id_1" rel="nofollow noopener noreferrer" target="_self">参考资料</a></font></p> 
<h2><a id="_269"></a>参考资料</h2> 
<h2 id="id_1"></h2> 
<blockquote> 
 <ol><li><a href="https://blog.csdn.net/weixin_40766438/article/details/102969299">关于ScanNet数据集</a></li><li><a href="https://blog.csdn.net/PJCSDN/article/details/108668071">OSError: Unable to download ‘freeimage-3.15.1-win64.dll‘. Perhaps there is a no internet connection?</a></li><li><a href="https://blog.csdn.net/qq_35781447/article/details/115078283?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-3.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-3.control">ScanNetV2 数据集讲解和选择性下载</a></li><li><a href="https://blog.csdn.net/phy12321/article/details/103554254?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162426877416780264059083%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=162426877416780264059083&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-103554254.first_rank_v2_pc_rank_v29&amp;utm_term=RGBD%E6%95%B0%E6%8D%AE%E9%9B%86&amp;spm=1018.2226.3001.4187">主流RGBD数据集简介</a></li><li><a href="https://blog.csdn.net/weixin_36662031/article/details/85599624?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=RGBD%E6%95%B0%E6%8D%AE%E9%9B%86&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-8-.first_rank_v2_pc_rank_v29&amp;spm=1018.2226.3001.4187">《《《翻译》》》SUN RGB-D数据集</a></li><li><a href="https://blog.csdn.net/shilling_bai/article/details/117653487?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162540820016780261944140%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=162540820016780261944140&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-117653487.pc_search_result_cache&amp;utm_term=NYU%20Depth%20Dataset%20V2&amp;spm=1018.2226.3001.4187">NYU Depth Dataset V2数据集的读取</a></li></ol> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dccd0a6528d3e2e886de85984e32700e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C4D使用注意事项</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/735dd6f8b5f7fb9911c4ece6f2339b3c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">报错：UnicodeDecodeError：: ‘utf-8‘ codec can‘t decode byte 0xc8 in position 0: invalid contin</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>