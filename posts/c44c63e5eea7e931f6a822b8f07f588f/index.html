<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka的相关知识 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Kafka的相关知识" />
<meta property="og:description" content="一. Kafka基本介绍 Kafka是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统。具有：高吞吐量、低延迟、可扩展性、持久性、可靠性、容错性、高并发等特性。常见的应用场景有：日志收集、消息系统、流式处理等。
二. Kafka的基本架构 Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其发送到 Kafka。Consumer：消费者，也就是接受消息的一方。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。Consumer Group：一个消费者组可以包含一个或多个消费者。使用多分区 &#43; 多消费者方式可以极大提高数据下游的处理速度，同一消费组中的消费者不会重复消费消息，同样的，不同消费组中的消费者消息时互不影响。Kafka 就是通过消费组的方式来实现消息 P2P 模式和广播模式。Broker：服务代理节点。Broker 是 Kafka 的服务节点，即 Kafka 的服务器。Topic：Kafka 中的消息以 Topic 为单位进行划分，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。Partition：Topic 是一个逻辑的概念，它可以细分为多个分区，每个分区只属于单个主题。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。Offset：offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序性而不是主题有序性。Replication：副本，是 Kafka 保证数据高可用的方式，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常只有主副本对外提供读写服务，当主副本所在 broker 崩溃或发生网络一场，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。Record：实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 key、value 和 timestamp。 三. Kafka如何保证消息顺序消费 Kafka 在 Topic 级别本身是无序的，只有 partition 上才有序，所以为了保证处理顺序，可以自定义分区器，将需顺序处理的数据发送到同一个 partition。自定义分区器需要实现接口 Partitioner接口并实现 3 个方法:partition,close,configure，在partition 方法中返回分区号即可。
Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数，partiton 和 key 是可选的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c44c63e5eea7e931f6a822b8f07f588f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-17T16:30:26+08:00" />
<meta property="article:modified_time" content="2023-03-17T16:30:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka的相关知识</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_Kafka_0"></a>一. Kafka基本介绍</h2> 
<p>Kafka是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统。具有：<strong>高吞吐量</strong>、<strong>低延迟</strong>、<strong>可扩展性</strong>、<strong>持久性</strong>、<strong>可靠性</strong>、<strong>容错性</strong>、<strong>高并发</strong>等特性。常见的应用场景有：<strong>日志收集</strong>、<strong>消息系统</strong>、<strong>流式处理</strong>等。</p> 
<h2><a id="_Kafka_2"></a>二. Kafka的基本架构</h2> 
<p><img src="https://images2.imgbox.com/d6/81/bzPH2Qrl_o.png" alt="在这里插入图片描述"></p> 
<ul><li><code>Producer</code>：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其发送到 Kafka。</li><li><code>Consumer</code>：消费者，也就是接受消息的一方。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。</li><li><code>Consumer Group</code>：一个消费者组可以包含一个或多个消费者。使用多分区 + 多消费者方式可以极大提高数据下游的处理速度，同一消费组中的消费者不会重复消费消息，同样的，不同消费组中的消费者消息时互不影响。Kafka 就是通过消费组的方式来实现消息 P2P 模式和广播模式。</li><li><code>Broker</code>：服务代理节点。Broker 是 Kafka 的服务节点，即 Kafka 的服务器。</li><li><code>Topic</code>：Kafka 中的消息以 Topic 为单位进行划分，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。</li><li><code>Partition</code>：Topic 是一个逻辑的概念，它可以细分为多个分区，每个分区只属于单个主题。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。</li><li><code>Offset</code>：offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序性而不是主题有序性。</li><li><code>Replication</code>：副本，是 Kafka 保证数据高可用的方式，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常只有主副本对外提供读写服务，当主副本所在 broker 崩溃或发生网络一场，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。</li><li><code>Record</code>：实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 key、value 和 timestamp。</li></ul> 
<h2><a id="_Kafka_14"></a>三. Kafka如何保证消息顺序消费</h2> 
<p>Kafka 在 <code>Topic</code> 级别本身是无序的，只有 <code>partition</code> 上才有序，所以为了保证处理顺序，可以自定义分区器，将需顺序处理的数据发送到同一个 <code>partition</code>。自定义分区器需要实现接口 <code>Partitioner</code>接口并实现 3 个方法:<code>partition</code>,<code>close</code>,<code>configure</code>，在<code>partition</code> 方法中返回分区号即可。<br> Kafka 中发送 1 条消息的时候，可以指定<code>(topic, partition, key)</code> 3 个参数，<code>partiton</code> 和 <code>key</code> 是可选的。<br> Kafka 分布式的单位是 <code>partition</code>，同一个 <code>partition</code> 用一个 <code>write ahead log</code> 组织，所以可以保证<code>FIFO</code> 的顺序。不同 <code>partition</code> 之间不能保证顺序。因此你可以指定 <code>partition</code>，将相应的消息发往同 1个 <code>partition</code>，并且在消费端，Kafka 保证1 个 <code>partition</code> 只能被1 个 <code>consumer</code> 消费，就可以实现这些消息的顺序消费。<br> 另外，也可以指定 key（比如 order id），具有同 1 个 key 的所有消息，会发往同 1 个<code>partition</code>，那这样也实现了消息的顺序消息。</p> 
<h2><a id="_Kafka_19"></a>四. Kafka发送消息选择分区的逻辑</h2> 
<p>Kafka在数据生产的时候，有一个数据分发策略。默认的情况使用<code>org.apache.kafka.clients.producer.internals.DefaultPartitioner</code>类，这个类中就是定义数据分发的策略。默认策略为：</p> 
<ol><li>如果在发消息的时候指定了分区，则消息投递到指定的分区</li><li>如果没有指定分区，但是消息的key不为空，则基于key的哈希值来选择一个分区</li><li>如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区</li></ol> 
<h2><a id="_Kafka_25"></a>五. Kafka如何避免消息丢失</h2> 
<p>Kafka的消息避免丢失可以从三个方面考虑处理：<strong>Producer发送消息避免失败</strong>、<strong>Broker能成功保存接收到的消息</strong>、<strong>Consumer确认消费消息</strong>。</p> 
<ol><li> <p><strong>Producer发送消息避免失败</strong><br> 想要Produce发送消息不失败，那就得知道发送结果，网络抖动这些情况是无法避免的，只能是发送后获取发送结果，那么最直接的方式就是把Kafka默认的异步发送改为同步发送(Broker收到消息后<code>ack</code>回复确认)，这样就能实时知道消息发送的结果，但是这样会让Kafka的发送效率大大降低，因为Kafka在默认的异步发送消息的时候可以批量发送，以此大幅度提高发送效率，因此一般很少使用同步发送的方式，除非消息很重要绝不允许丢失。<br> 但是我们可以采用<strong>添加异步或调函数，监听消息发送的结果，如果失败可以在回调中重试</strong>，以此来达到尽可能的发送成功。同时<code>Producer</code>本身提供了一个<code>retries</code>的机制，如果因为网络问题，或者Broker故障 导致发送失败，就是重试。一般这个<code>retries</code>设置3-5次或者更高，同时重试间隔时间也随着次数增长。</p> </li><li> <p><strong>Broker能成功保存接收到的消息</strong> <br> Broker要成功的保存接收到的消息并且不丢失，就需要把接收到的消息保存到磁盘。Kafka为了提高性能采用的是异步批量，存储到磁盘的机制，就是有一定的消息量和时间间隔要求的，刷磁盘的这个动作是操作系统来调度的，如果在刷盘之前系统就崩溃了，就会数据丢失。<br> 针对这个情况，Kafka采用<code>Partition</code>分区<code>ack</code>机制，<code>Partition</code>分区是指一个Topic下的多个分区，有一个<code>Leader</code>分区，其他的都是<code>Follower</code>分区，<code>Leader</code>分区负责接收和被读取消息，<code>Follower</code>分区会通过<code>Replication</code>机制同步<code>Leader</code>的数据，负责高可用(Kafka在2.4之后，Kafka提供了读写分离，<code>Follower</code>也可以提供读取)，当<code>Leader</code>出现故障时会从<code>Follower</code>中选取一个成为新的<code>Leader</code>。那么当一个消息发送到<code>Leader</code>分区之后，Kafka提供了一个 <code>acks</code>的参数，<code>Producer</code>可以设置这个参数，去结合<code>broker</code>的<code>Partition</code>机制来共同保障数据的可靠性，这个参数的值有三个</p> 
  <ul><li><code>0</code>，表示<code>Producer</code>不需要等待<code>broker</code>的响应，就认为消息发送成功了(可能存在数据丢失)</li><li><code>1</code>，表示<code>Leader</code>收到消息之后,不等待其他的<code>Follower</code>的同步就给<code>Producer</code>发一个确认，如果<code>Leader</code>和<code>Partition</code>挂了就可能存在数据丢失</li><li><code>-1</code>，表示<code>Leader</code>收到消息之后还会等待<code>ISR</code>列表(与<code>Leader</code>保持正常连接的<code>Follwer</code>节点列表)中的<code>Follower</code>同步完成，再给<code>Producer</code>返回一个确认，也就是所有分区节点都确认收到消息，保证数据不丢失</li></ul> </li><li> <p><strong>Consumer确认消费消息</strong><br> 当<code>Producer</code>确定发送消息成功并且<code>Broker</code>成功保存消息之后，基本上<code>Consumer</code>就肯定能消费到消息。Kafka在消费者消费时有一个<code>offset</code>机制，代表了当前消费者消费到了<code>Partition</code>的哪一条消息。kafka的<code>Consumer</code>的配置中，默认的<code>enable.auto.commit = true</code>,表示在<code>Consumer</code> 通过<code>poll</code>方法 获取到消息以后，每过5秒（通过配置项可修改）会自动获取<code>poll</code>中得到的最大的<code>offset</code>, 提交给<code>Partition</code>中的<code>offset_consumer</code>(存储 offset 的特定topic)。如果<code>enable.auto.commit = false</code>时，则关闭了自动提交，需要手动的通过应用程序代码<code>commitSync()</code>进行提交。<br> 所以在<code>Consumer</code>消费消息时，丢失消息的可能会有两种，比如开启了<code>offset</code>自动提交，但是消息消费失败；或者没有开启自动提交<code>offset</code>，但是在消费消息之前提交了<code>offset</code>。针对这两种情况，可以设置在消息消费完成后手动提交<code>offset</code>。总之<code>Consumer</code>端确认消息消费成功后再提交<code>offset</code>即可保证消息正常消费。</p> </li></ol> 
<p>所以Kafka如果要尽量避免消息丢失的话，可以进行如下配置：</p> 
<pre><code class="prism language-bash"><span class="token comment"># producer</span>
acks <span class="token operator">=</span> -1  								// producer会获得所有同步replicas都收到数据的确认
block.on.buffer.full <span class="token operator">=</span> <span class="token boolean">true</span>			//当我们内存缓存用尽时，必须停止接收新消息记录或抛出错误  设置为false会抛出BufferExhaustedException
retries <span class="token operator">=</span> MAX_INT					// 设置大于0的值一旦这些数据发送失败，将使客户端重新发送任何数据，但是重新发送可能会影响消息顺序
max.inflight.requests.per.connection <span class="token operator">=</span> <span class="token number">1</span>	// 表示允许最多没有返回 ack 的次数，默认为 <span class="token number">5</span>，开启幂等性要保证该值是 <span class="token number">1</span>-5 的数字，设置为1表示逐个发送消息

<span class="token comment"># consumer</span>
enable.auto.commit <span class="token operator">=</span> <span class="token boolean">false</span>			// 不自动提交offset，可以在消息消费成功后通过commitSync<span class="token punctuation">(</span><span class="token punctuation">)</span>手动提交

<span class="token comment"># broker</span>
offsets.topic.replication.factor <span class="token operator">&gt;=</span> <span class="token number">3</span>				// topic的offset的备份份数。设置更高的数字保证更高的可用性
min.insync.replicas <span class="token operator">=</span> <span class="token number">2</span>								// 当producer设置request.required.acks为-1时，min.insync.replicas指定replicas的最小数目，表示确认每一个repica的写数据都是成功的  设置为2表示至少2个follower是写成功的
unclean.leader.election.enable <span class="token operator">=</span> <span class="token boolean">false</span>		// 是否可以从非ISR集合中选举follower副本称为新的leader
</code></pre> 
<h2><a id="_Kafkaoffset_60"></a>六. Kafka的offset机制</h2> 
<p>​Kafka中的每个<code>Partition</code>都由一系列有序的、不可变的消息组成，这些消息被连续的追加到<code>Partition</code>中。<code>Partition</code>中的每个消息都有一个连续的序号，用于<code>Partition</code>唯一标识一条消息，这个唯一标识就是<code>offset</code>。<br> <code>Offset</code>从语义上来看拥有两种：<code>Current Offset</code> 和 <code>Committed Offset</code>。</p> 
<p><code>Current Offset</code>保存在<code>Consumer</code>客户端中，它表示<code>Consumer</code>希望收到的下一条消息的序号。它仅仅在<code>poll()</code>方法中使用。例如，<code>Consumer</code>第一次调用<code>poll()</code>方法后收到了20条消息，那么<code>Current Offset</code>就被设置为<code>20</code>。这样<code>Consumer</code>下一次调用<code>poll()</code>方法时，Kafka就知道应该从序号为21的消息开始读取。这样就能够保证每次<code>Consumer poll</code>消息时，都能够收到不重复的消息。</p> 
<p><code>Committed Offset</code>保存在<code>Broker</code>上，它表示<code>Consumer</code>已经确认消费过的消息的序号。主要通过 <code>commitSync</code> 和 <code>commitAsync</code> API来操作。举个例子，<code>Consumer</code>通过<code>poll()</code> 方法收到20条消息后，此时<code>Current Offset</code>就是20，经过一系列的逻辑处理后，并没有调用<code>consumer.commitAsync()</code>或<code>consumer.commitSync()</code>来提交<code>Committed Offset</code>，那么此时<code>Committed Offset</code>依旧是0。<br> <code>Committed Offset</code>主要用于<code>Consumer Rebalance</code>。在<code>Consumer Rebalance</code>的过程中，一个<code>partition</code>被分配给了一个<code>Consumer</code>，那么这个<code>Consumer</code>该从什么位置开始消费消息呢？答案就是<code>Committed Offset</code>。另外，如果一个<code>Consumer</code>消费了5条消息（poll并且成功<code>commitSync</code>）之后宕机了，重新启动之后它仍然能够从第6条消息开始消费，因为<code>Committed Offset</code>已经被Kafka记录为5。</p> 
<p>在Kafka 0.9前，<code>Committed Offset</code>信息保存在<code>zookeeper</code>的<code>consumers/{group}/offsets/{topic}/{partition}</code>目录中（<code>zookeeper</code>并不适合进行大批量的读写操作，尤其是写操作）。而在0.9之后，所有的<code>offset</code>信息都保存在了<code>Broker</code>上的一个名为<code>_consumer_offsets</code>的<code>topic</code>中。</p> 
<h2><a id="_Kafka_70"></a>七. Kafka性能高的原因</h2> 
<ol><li> <p><strong>顺序读写</strong><br> Kafka的<code>Partition</code>中写入数据，是通过分段、追加日志的方式，这在很大程度上将读写限制为顺序 I/O（sequential I/O），这在大多数的存储介质上都很快。实际上不管是内存还是磁盘，快或慢关键在于寻址的方式，磁盘分为顺序读写与随机读写，内存也一样分为顺序读写与随机读写。基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，一般而言要高出磁盘随机读写三个数量级，一些情况下磁盘顺序读写性能甚至要高于内存随机读写。<br> <img src="https://images2.imgbox.com/6d/25/mS16JDpU_o.png" alt="在这里插入图片描述"></p> </li><li> <p><strong>Page Cache</strong> <br> 为了优化读写性能，Kafka利用了操作系统本身的<code>Page Cache</code>，就是利用操作系统自身的内存而不是JVM空间内存。这样做可以避免Object消耗，如果是使用 Java 堆，Java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多；还能避免GC问题，随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题。</p> <p>相比于使用<code>JVM</code>或<code>in-memory cache</code>等数据结构，利用操作系统的<code>Page Cache</code>更加简单可靠。首先，操作系统层面的缓存利用率会更高，因为存储的都是紧凑的字节结构而不是独立的对象。其次，操作系统本身也对于<code>Page Cache</code>做了大量优化，提供了 <code>write-behind</code>、<code>read-ahead</code>以及<code>flush</code>等多种机制。再者，即使服务进程重启，系统缓存依然不会消失，避免了<code>in-process cache</code>重建缓存的过程。</p> <p>通过操作系统的<code>Page Cache</code>，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。</p> </li><li> <p><strong>零拷贝</strong><br> Linux操作系统 <strong>零拷贝</strong> 机制使用了<code>sendfile</code>方法， 允许操作系统将数据从<code>Page Cache</code> 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据。零拷贝的技术基础是DMA，又称之为直接内存访问。DMA 传输将数据从一个地址空间复制到另外一个地址空间。当CPU 初始化这个传输动作，传输动作本身是由 DMA 控制器来实行和完成。因此通过DMA，硬件则可以绕过CPU，自己去直接访问系统主内存。很多硬件都支持DMA，其中就包括网卡、声卡、磁盘驱动控制器等。通过这种 “零拷贝” 的机制，<code>Page Cache</code> 结合 <code>sendfile</code> 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。</p> <p>当Kafka客户端从服务器读取数据时，如果不使用零拷贝技术，那么大致需要经历这样的一个过程：</p> 
  <ul><li>操作系统将数据从磁盘上读入到内核空间的读缓冲区中。</li><li>Kafka应用程序从内核空间的读缓冲区将数据拷贝到用户空间的缓冲区中。</li><li>Kafka应用程序将数据从用户空间的缓冲区再写回到内核空间的socket缓冲区中。</li><li>操作系统将socket缓冲区中的数据拷贝到NIC缓冲区中，然后通过网络发送给客户端。</li></ul> <p>如果使用零拷贝技术，那么只需要：</p> 
  <ul><li>操作系统将数据从磁盘中加载到内核空间的Read Buffer（页缓存区）中</li><li>操作系统之间将数据从内核空间的Read Buffer（页缓存区）传输到网卡中，并通过网卡将数据发送给接收方</li></ul> </li><li> <p><strong>批量读写</strong><br> Kafka数据读写也是批量的而不是单条的。除了利用底层的技术外，Kafka还在应用程序层面提供了一些手段来提升性能，最明显的就是使用批次，在向Kafka写入数据时，可以启用批次写入，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。</p> </li><li> <p><strong>批量压缩</strong><br> Kafka可以把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，写入数据的时候由于单个Partion是末尾添加所以速度最优，读取数据的时候配合sendfile直接输出。并且Kafka支持多种压缩协议，包括Gzip和Snappy压缩协议。</p> </li></ol> 
<h2><a id="_Kafkatopic_97"></a>八. Kafka的topic数量太多性能会急剧下降的原因是什么</h2> 
<p>Kafka的<code>topic</code>数量多性能会下降的主要原因是<code>topic</code>在物理层面以<code>partition</code>为分组，一个<code>topic</code>可以分成若干个<code>partition</code>，<code>partition</code>还可以细分为<code>logSegment</code>，一个<code>partition</code>物理上由多个<code>logSegment</code>组成，<code>logSegment</code> 文件由两部分组成，分别为<code>.index</code>文件和<code>.log</code>文件，分别表示为 <code>Segment</code> 索引文件和数据文件。Kafka在<code>Broker</code>接受并存储消息的时候，是将消息数据使用分段、追加日志的方式写入log文件，在很大程度上将读写限制为顺序 I/O（sequential I/O），那么如果<code>topic</code>数量很多，即使每个<code>topic</code>只有1个<code>partition</code>，也会导致总分区数很多，磁盘读写退化为随机，影响性能。同时Kafka中<code>topic</code>的元数据是在<code>zookeeper</code>中的，大量<code>topic</code>确实会造成性能瓶颈(zk不适合做高并发的读写操作)，不仅在磁盘读写上。而且<code>topic</code>太多造成<code>partition</code>过多。<code>partition</code>是kafka的最小并行单元，每个<code>partition</code>都会在对应的<code>broker</code>上有日志文件。当<code>topic</code>过多，<code>partition</code>增加，日志文件数也随之增加，就需要允许打开更多的文件数。<code>partition</code>过多在<code>controller</code>选举和<code>controller</code>重新选举<code>partition leader</code>的耗时会大大增加，造成kafka不可用的时间延长。</p> 
<h2><a id="_KafkaReplication_99"></a>九. Kafka的Replication机制</h2> 
<p>Kafka的<code>Replication</code>机制用来保证某个节点发生问题的时候仍然能够保证数据不丢失并正常工作，也就是<code>Leader</code>节点和<code>Follower</code>节点之间的数据同步和通信。Kafka的消息是从<code>Topic</code>开始区分，<code>Topic</code>下有<code>partition</code>，<code>partition</code>下有<code>replica</code>，<code>replica</code>分为主节点<code>Leader</code>和副本节点<code>Follower</code>。<code>Partition</code> 是复制的基本单位，每个 <code>Partition</code> 有多个 <code>Replica</code>，其中的一个 <code>Replica</code> 是 <code>Leader</code>， <code>Leader</code> 负责着与 <code>Consumer</code> 之间的所有读写交互，而 <code>Follower</code> 从 <code>Leader</code> 中通过 <code>Fetch RPC</code> 去拉取同步。<code>default.replication.factor</code> 参数决定着一个 <code>Topic</code> 下的 <code>Partition</code> 含有多少个 <code>Replica</code>。<br> <code>Leader</code> 维护着一组 <code>ISR（In-Sync-Replica）</code>列表，表示认为处于正常同步状态的 <code>Follower</code> 集合。Kafka 依据 <code>replica.lag.time.max.ms</code> 参数来判定一个 <code>Replica</code> 是否仍属于 <code>ISR</code>，如果 <code>Follower</code> 较长时间未与 <code>Leader</code> 保持同步，则 <code>Leader</code> 会考虑将这个 <code>Follower</code> 从 <code>ISR</code> 中去除。<br> 除非设置 <code>unclean.leader.election.enable</code>，则新的 <code>Leader</code> 总是从 <code>ISR</code> 中选举得出。<code>min.insync.replicas</code> 决定着每个 topic 能接受的最少 <code>ISR</code> 个数，如果存活 <code>ISR</code> 个数太少，生产消息侧会报异常。<br> Kafka的<code>Producer</code> 可以配置 <code>request.required.acks</code> 来决定消息的持久性程度，<code>0</code> 表示不需要确认<code>ack</code>，<code>1</code> 是收到 <code>Leader</code> 的 <code>ack</code>，而 <code>-1</code>是收到所有 <code>ISR</code> 的 <code>ack</code>。一旦 <code>Producer</code> 生产的消息同步给了所有 <code>ISR</code>，便可以将这条消息的下标设置为 <code>HW（High Watermark）</code>，小于 <code>HW</code> 下标的消息视为 <code>Committed</code>。消费者只能看到大于 <code>HW</code> 的消息。如下图：<br> <img src="https://images2.imgbox.com/a1/d8/td3g726F_o.png" alt="在这里插入图片描述"><br> <code>LogStartOffset</code>一般简称<code>LSO</code>，表示存放在log文件中的第一条消息的offset，<code>HW （High Watermark）</code>俗称<strong>高水位</strong>，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。<code>LEO （Log End Offset）</code>标识当前日志文件中下一条待写入的消息的offset。这个图表示了一个log文件，其中文件中第一条消息的<code>LSO</code>为0，<code>HW</code>为6，<code>LEO</code>为9，消费者只能消费<code>HW</code>之前的消息，最新加入这个log文件的消息就从<code>LEO</code>也就是9的位置开始。</p> 
<h2><a id="_KafkaConsumer_Group_106"></a>十. Kafka的Consumer Group</h2> 
<p>Kafka的<code>Consumer Group</code>是由多个<code>Consumer</code>实例共同组成的一个<strong>消费组</strong>，<code>Consumer Group</code>由一个<code>Group ID</code>来标识，该组内的所有<code>Consumer</code>共同协调来消费<code>Topic</code>下的所有分区，当然一个<code>Consumer</code>实例只能够消费一个分区。所以最为理想的情况下当你的<code>Consumer Group</code>下的<code>Consumer</code>实例个数和你的<code>Topic</code>分区个数相同时，那么每个<code>Consumer</code>都能消费一个分区的数据。但如果你的<code>Consumer</code>个数比分区数还多的话，比如： 3个<code>Consumer</code>实例，<code>Topic</code>中只有两个分区，那么总有一个<code>Consumer</code>实例会处于空闲状态。同时<code>Consumer Group</code>下的<code>Consumer</code>实例个数发生变化时会导致发生<code>Rebalance</code>。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/954c894bc80459e55fe14af004655a52/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">TypeScript 详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/077b5ca98e53406a750f035cdcaf3e5c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">机械臂学习——标准DH法和改进MDH法建模法对比学习</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>