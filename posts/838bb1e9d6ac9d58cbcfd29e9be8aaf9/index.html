<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python数据分析案例17——电影人气预测(特征工程构建) - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python数据分析案例17——电影人气预测(特征工程构建)" />
<meta property="og:description" content="案例背景 本次案例是中国人民大学“人工智能与机器学习（2022年秋季）”课程的课堂竞赛。
比赛是根据有关电影的各种信息来预测电影的受欢迎程度，包括演员、工作人员、情节关键字、预算、收入、海报、上映日期、语言、制作公司、国家、TMDB 投票计数、平均投票等。
比赛是在kaggle上进行的，需要这代码演示数据的同学可以参考：数据
由于原始数据特征变量基本都是文本，本次案例最大价值在于特征工程的构建，即怎么把文本变为数值型变量。
数据读取 导入常用包
#导入数据分析常用包 import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;KaiTi&#39;] #中文 plt.rcParams[&#39;axes.unicode_minus&#39;] = False #负号 读取训练集和测试集
data=pd.read_csv(&#39;movies_train.csv&#39;) data2=pd.read_csv(&#39;movies_test.csv&#39;) 查看数据前五行
data.head() 有点多就不展示完了
查看训练集和测试集数据基础信息
data=data.infer_objects() data2=data2.infer_objects() data.info() ,data2.info() 可以看到大部分变量都不是数值型，需要进行处理
变量信息解释 id- 电影ID。
title- 电影名称 文本变量
homepage- 电影主页 文本变量
genres- 电影类型 分类型变量
overview- 电影概述 文本变量
poster_path- 电影海报的位置 图片文本
tagline- 电影标语 文本变量
runtime- 电影的运行时间 数值型变量" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/838bb1e9d6ac9d58cbcfd29e9be8aaf9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-02T10:07:00+08:00" />
<meta property="article:modified_time" content="2024-01-02T10:07:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python数据分析案例17——电影人气预测(特征工程构建)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>案例背景</h3> 
<p>本次案例是中国人民大学“人工智能与机器学习（2022年秋季）”课程的课堂竞赛。</p> 
<p>比赛是根据有关电影的各种信息来预测电影的受欢迎程度，包括演员、工作人员、情节关键字、预算、收入、海报、上映日期、语言、制作公司、国家、TMDB 投票计数、平均投票等。</p> 
<p>比赛是在kaggle上进行的，需要这代码演示数据的同学可以参考：<a class="link-info" href="https://mbd.pub/o/bread/ZZmUmJhp" rel="nofollow" title="数据">数据</a></p> 
<p>由于原始数据特征变量基本都是文本，本次案例最大价值在于特征工程的构建，即怎么把文本变为数值型变量。</p> 
<p></p> 
<hr> 
<h3>数据读取</h3> 
<p>导入常用包</p> 
<pre><code class="language-python">#导入数据分析常用包
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns 

%matplotlib inline
plt.rcParams['font.sans-serif'] = ['KaiTi']  #中文
plt.rcParams['axes.unicode_minus'] = False   #负号</code></pre> 
<p>读取训练集和测试集</p> 
<pre><code class="language-python">data=pd.read_csv('movies_train.csv')
data2=pd.read_csv('movies_test.csv')</code></pre> 
<p>查看数据前五行</p> 
<pre><code class="language-python">data.head()</code></pre> 
<p><img alt="" height="491" src="https://images2.imgbox.com/dd/ae/3RzNX3O3_o.png" width="1200"></p> 
<p> 有点多就不展示完了</p> 
<p> 查看训练集和测试集数据基础信息</p> 
<pre><code class="language-python">data=data.infer_objects()
data2=data2.infer_objects()
data.info() ,data2.info()</code></pre> 
<p><img alt="" height="510" src="https://images2.imgbox.com/6f/e2/XVeZSvvI_o.png" width="410"></p> 
<p> 可以看到大部分变量都不是数值型，需要进行处理</p> 
<p></p> 
<h4 id="变量信息解释">变量信息解释</h4> 
<p>id- 电影ID。</p> 
<p>title- 电影名称 文本变量</p> 
<p>homepage- 电影主页 文本变量</p> 
<p>genres- 电影类型 分类型变量</p> 
<p>overview- 电影概述 文本变量</p> 
<p>poster_path- 电影海报的位置 图片文本</p> 
<p>tagline- 电影标语 文本变量</p> 
<p>runtime- 电影的运行时间 数值型变量</p> 
<p>spoken_languages- 电影口语 分类型变量</p> 
<p>original_language- 电影原文 分类型变量</p> 
<p>original_title- 电影原名 文本变量</p> 
<p>production_companies- 电影制作公司 分类型变量</p> 
<p>production_countries- 电影的制作国家 分类型变量</p> 
<p>release_date- 电影上映日期 时间变量</p> 
<p>budget- 电影预算 数值型变量</p> 
<p>revenue- 电影收入 数值型变量</p> 
<p>status- 电影状态 分类型变量</p> 
<p>vote_count- 电影票数 数值型变量</p> 
<p>vote_average- 电影的平均票数 数值型变量</p> 
<p>keywords- 电影关键词 文本变量</p> 
<p>cast- 电影演员 字典变量</p> 
<p>crew- 电影剧组 字典变量</p> 
<p>popularity- 电影的人气评分 目标变量，数值型</p> 
<p></p> 
<hr> 
<h3 id="数据预处理">数据预处理</h3> 
<h4 id="特征筛选">特征筛选</h4> 
<p>由于数据的文本型变量较多，较难处理。将一些没用的文本变量和难以提取信息的文本特征选择删除</p> 
<p>这里先选择删除电影ID，电影主页，电影概述，电影海报的位置，电影标语，电影关键词,电影制作公司，电影的制作国家</p> 
<pre><code class="language-python">#删除的变量
col_drop=['id','homepage','overview','poster_path','tagline','keywords','production_companies','production_countries']
#测试集ID留着后面提交
ID=data2['id']
data.drop(col_drop,axis=1,inplace=True)
data2.drop(col_drop,axis=1,inplace=True)</code></pre> 
<h4 id="新特征构建">新特征构建</h4> 
<p style="margin-left:0;text-align:justify;">剩余的文本变量，一一进行处理，进行新的特征工程的构建。</p> 
<ol><li style="text-align:justify;">首先对电影名称title和电影的原始名original_title称进行一个匹配，相同返回1，不相同返回0，从而构建一个新特征name_change。</li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#000000;">通过对电影源</span></span>语言spoken_languages是否<span style="background-color:#ffffff;"><span style="color:#000000;">含有英语</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">(</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">最通用的语言</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">)</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，构建一个虚拟变量</span></span>spoken，语言里面包含语言返回1，不包含返回0。</li><li style="text-align:justify;">同样我们对电影语言original_language是否为英语，构建虚拟变量original，是英语返回1，不是英语返回0。</li><li style="text-align:justify;">通过对上映日期release_date计算，得到该影片的年龄movie_age。使用2022(今年)-发行年份得到，并转化为整形数。由于计算过程中发行存在缺失值，对缺失值采用均值进行填充。</li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#000000;">对电影演员</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">cast</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、电影剧组</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">crew</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">的字典变量进行简单处理，计算它们的个数，构建新的特征——电影知名演员个数</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">cast_num</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，电影剧组成员个数</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">crew_num</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#000000;">对于电影类别，进行虚拟变量处理。通过代码发现总共有</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">20</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">种电影类别。由于每个电影可能涉及不止一个类别，所以整体构建</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">20</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">个虚拟变量，如果电影类别存在这一类就为</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">1</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，不存在就为</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">0</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#000000;">剩下的变量</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">status</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">表示电影的状态，直接进行独立热编码处理就行，生成</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">5</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">个虚拟变量。</span></span></li></ol> 
<p>首先对电影名称和电影的原始名称进行一个匹配，相同返回1，不相同返回0，从而构建一个新特征</p> 
<pre><code class="language-python">data=data.assign(name_change=lambda d: (d.title==d.original_title)*1)
data2=data2.assign(name_change=lambda d: (d.title==d.original_title)*1)</code></pre> 
<pre><code class="language-python">def check_languages(txt):
    txt=eval(txt)
    if 'en'in txt:
        languages=1
    else:
        languages=0
    return languages</code></pre> 
<pre><code class="language-python">data['spoken']=data['spoken_languages'].apply(check_languages)
data2['spoken']=data2['spoken_languages'].apply(check_languages)</code></pre> 
<p> 电影原文也是一样的处理</p> 
<pre><code class="language-python">def check_languages2(txt):
    if  txt=='en':
        languages=1
    else:
        languages=0
    return languages</code></pre> 
<pre><code class="language-python">data['original']=data['original_language'].apply(check_languages2)
data2['original']=data2['original_language'].apply(check_languages2)</code></pre> 
<p>通过对发行日期计算，得到该影片的年龄, 缺失值采用均值填充</p> 
<pre><code class="language-python">data['movie_age']=(2022-pd.to_datetime(data['release_date']).dt.year).fillna((2022-pd.to_datetime(data['release_date']).dt.year).mean()).astype('int')
data2['movie_age']=(2022-pd.to_datetime(data2['release_date']).dt.year).fillna((2022-pd.to_datetime(data2['release_date']).dt.year).mean()).astype('int')</code></pre> 
<p>对电影演员、电影剧组的字典变量进行简单处理，计算它们的个数，构建一个新的特征</p> 
<pre><code class="language-python">def check(d):
    return len(d)
data['cast_num']=data['cast'].apply(check)
data2['cast_num']=data2['cast'].apply(check)

data['crew_num']=data['crew'].apply(check)
data2['crew_num']=data2['crew'].apply(check)</code></pre> 
<p>对于电影类别，进行虚拟变量处理，由于一个电影可能属于多个类别，不能直接独立热编码，需要进行处理。</p> 
<p>首先得到所有类别的名称列表</p> 
<pre><code class="language-python">all_kind=[]
for a in [eval(i)for i in data['genres'].unique()]:
    for a1 in a:
        all_kind.append(a1)
set_kind=list(set(all_kind))</code></pre> 
<p> 定义处理函数，生成虚拟变量</p> 
<pre><code class="language-python">def check2(txt):
    txt=eval(txt)
    dummys=[]
    for k in set_kind:
        if k in txt:
            dummys.append(1)
        else:
            dummys.append(0)
    return np.array(dummys)
def check3(col,data):
    all_kind=[]
    for a in [eval(i)for i in data[col].unique()]:
        for a1 in a:
            all_kind.append(a1)
    set_kind=list(set(all_kind))
    print(f'{col}特征里面有{len(set_kind)}个类别，生成{len(set_kind)}个虚拟变量')
    dummys_max=np.array([np.array(arr) for arr in data[col].apply(check2).to_numpy()])
    for i,kind in enumerate(set_kind):
        data[f'{col}_{kind}']=dummys_max[:,i]</code></pre> 
<p> 应用函数</p> 
<pre><code class="language-python">check3('genres',data)
check3('genres',data2)</code></pre> 
<p><img alt="" height="82" src="https://images2.imgbox.com/96/1c/teEr1hkb_o.png" width="446"></p> 
<p> 这样每个电影对应20个类别特征，如果它属于这个类别，取值为1，不属于取值为0。</p> 
<p><strong>将构建完的旧特征进行删除</strong></p> 
<pre><code class="language-python">#删除的变量
col_drop2=['original_title','title','release_date','cast','crew','genres','spoken_languages','original_language']
data.drop(col_drop2,axis=1,inplace=True)
data2.drop(col_drop2,axis=1,inplace=True)</code></pre> 
<p>剩下的变量status是典型的分类变量，可以直接进行虚拟变量独热处理</p> 
<pre><code class="language-python">data=pd.get_dummies(data)
data2=pd.get_dummies(data2)</code></pre> 
<p>再次查看所有变量的信息</p> 
<pre><code class="language-python">data.info()
data2.info()</code></pre> 
<p><img alt="" height="788" src="https://images2.imgbox.com/42/13/Qz433Ptq_o.png" width="401"></p> 
<p> 可以看到所有的特征变量都是数值型，可以进行模型运算了。</p> 
<p>但是电影时间一列还有缺失值，需要填充,采用均值进行填充。</p> 
<pre><code class="language-python">data['runtime']=data['runtime'].fillna(data['runtime'].mean())
data2['runtime']=data2['runtime'].fillna(data2['runtime'].mean())</code></pre> 
<p>status这个变量测试集独热出来多了一列，由于训练集的status没有status_Canceled这个情况，我们选择进行删除这个虚拟变量特征</p> 
<pre><code class="language-python">data2.drop(columns=['status_Canceled'],inplace=True)</code></pre> 
<p> 最后我们将训练集的y——popularity作为响应变量提取出来，完成特征工程的构建。</p> 
<p>取出y</p> 
<pre><code class="language-python">y=data['popularity']
data.drop(columns=['popularity'],inplace=True)</code></pre> 
<p>取出X</p> 
<pre><code class="language-python">X=data.copy()
X2=data2[data.columns]</code></pre> 
<p>查看训练集，测试集，y的形状</p> 
<pre><code class="language-python">print(X.shape,y.shape,X2.shape)</code></pre> 
<p><img alt="" height="52" src="https://images2.imgbox.com/b4/be/sKJpcA0M_o.png" width="432"></p> 
<p>可以看到最终训练集和测试集都是36个变量，训练集31801条，测试集13629条，下面开始数据探索分析机器学习的模型构建。</p> 
<p></p> 
<hr> 
<h3 id="数据探索">数据探索</h3> 
<h4 id="特征变量分布探索">特征变量分布探索</h4> 
<pre><code class="language-python">#查看特征变量的箱线图分布
columns = data.columns.tolist() # 列表头
dis_cols = 6                   #一行几个
dis_rows = len(columns)
plt.figure(figsize=(4 * dis_cols, 4 * dis_rows))
 
for i in range(len(columns)):
    plt.subplot(dis_rows,dis_cols,i+1)
    sns.boxplot(data=data[columns[i]], orient="v",width=0.5)
    plt.xlabel(columns[i],fontsize = 20)
plt.tight_layout()
#plt.savefig('特征变量箱线图.jpg',dpi=512)
plt.show()</code></pre> 
<p> <img alt="" height="601" src="https://images2.imgbox.com/28/7a/LKeZoQnV_o.png" width="604"></p> 
<p> 可以看到分类型的虚拟变量较多，数值型变量——budget,revenue,runtime的极大值较多</p> 
<p>#画密度图，训练集和测试集对比 </p> 
<pre><code class="language-python">dis_cols = 6                   #一行几个
dis_rows = len(columns)
plt.figure(figsize=(4 * dis_cols, 4 * dis_rows))
 
for i in range(len(columns)):
    ax = plt.subplot(dis_rows, dis_cols, i+1)
    ax = sns.kdeplot(data[columns[i]], color="Red" ,shade=True)
    ax = sns.kdeplot(data2[columns[i]], color="Blue",warn_singular=False,shade=True)
    ax.set_xlabel(columns[i],fontsize = 20)
    ax.set_ylabel("Frequency",fontsize = 18)
    ax = ax.legend(["train", "test"])
plt.tight_layout()
#plt.savefig('训练测试特征变量核密度图.jpg',dpi=500)
plt.show()</code></pre> 
<p><img alt="" height="670" src="https://images2.imgbox.com/f2/ad/AK0qnFbT_o.png" width="669"></p> 
<p> 训练集和测试集数据的分布还是较为一致</p> 
<hr> 
<p></p> 
<h3 id="异常值处理">异常值处理</h3> 
<h4>y异常值处理</h4> 
<p>y是数值型变量，画其箱线图直方图密度图</p> 
<pre><code class="language-python"># 查看y的分布
#回归问题
plt.figure(figsize=(6,2),dpi=128)
plt.subplot(1,3,1)
y.plot.box(title='响应变量箱线图')
plt.subplot(1,3,2)
y.plot.hist(title='响应变量直方图')
plt.subplot(1,3,3)
y.plot.kde(title='响应变量核密度图')
#sns.kdeplot(y, color='Red', shade=True)
#plt.savefig('处理前响应变量.png')
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="199" src="https://images2.imgbox.com/75/80/9KrfAr4O_o.png" width="621"></p> 
<p> 可以看到y有很严重的异常值，要筛掉，将y大于50的样本都筛掉</p> 
<pre><code class="language-python">#处理y的异常值
y=y[y &lt;= 50]
plt.figure(figsize=(6,2),dpi=128)
plt.subplot(1,3,1)
y.plot.box(title='响应变量箱线图')
plt.subplot(1,3,2)
y.plot.hist(title='响应变量直方图')
plt.subplot(1,3,3)
y.plot.kde(title='响应变量核密度图')
#sns.kdeplot(y, color='Red', shade=True)
#plt.savefig('处理后响应变量.png')
plt.tight_layout()
plt.show()</code></pre> 
<p> <img alt="" height="366" src="https://images2.imgbox.com/2d/23/DSaPvrLC_o.png" width="1157"></p> 
<p>可以看到极端值情况好了一些，然后将筛出来的样本赋值给x</p> 
<pre><code class="language-python">#筛选给x
X=X.iloc[y.index,:]
X.shape</code></pre> 
<p> <img alt="" height="37" src="https://images2.imgbox.com/ee/16/gV8DY4RU_o.png" width="238"></p> 
<p>31801数据变成了31771条。</p> 
<p></p> 
<h4>X异常值处理</h4> 
<p>#X异常值处理，先标准化</p> 
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_s = scaler.fit_transform(X)
X2_s = scaler.fit_transform(X2)</code></pre> 
<p> #然后画图查看</p> 
<pre><code class="language-python">plt.figure(figsize=(20,8))
plt.boxplot(x=X_s,labels=data.columns)
plt.hlines([-20,20],0,len(columns))
plt.xticks(rotation=40)
#plt.savefig('特征变量标准化箱线图.png',dpi=256)
plt.show()</code></pre> 
<p><img alt="" height="682" src="https://images2.imgbox.com/c6/71/p49aVDIo_o.png" width="1200"></p> 
<p>可以看到budget,revenue,runtime,vote_count,genres_Family,status_In Production,status_Planned这几个特征都有严重的异常值，超过了20倍的方差，需要进行筛除。</p> 
<p> #异常值多的列进行处理 </p> 
<pre><code class="language-python">def deal_outline(data,col,n):   #数据，要处理的列名，几倍的方差
    for c in col:
        mean=data[c].mean()
        std=data[c].std()
        data=data[(data[c]&gt;mean-n*std)&amp;(data[c]&lt;mean+n*std)]
        #print(data.shape)
    return data</code></pre> 
<p>超过10倍方差进行删除</p> 
<pre><code class="language-python">X=deal_outline(X,['budget','revenue','runtime','vote_count','genres_Family','status_In Production','status_Planned'],10)
y=y[X.index]
X.shape,y.shape</code></pre> 
<p><img alt="" height="59" src="https://images2.imgbox.com/7b/0a/fJGD0G4O_o.png" width="338"></p> 
<p>还剩31536个样本</p> 
<p></p> 
<h4 id="相关系数矩阵">相关系数矩阵</h4> 
<pre><code class="language-python">corr = plt.subplots(figsize = (18,16),dpi=128)
corr= sns.heatmap(data.assign(Y=y).corr(method='spearman'),annot=True,square=True)
#plt.savefig('训练集特征热力图.png',dpi=512)</code></pre> 
<p><img alt="" height="568" src="https://images2.imgbox.com/d8/13/tw21OuKu_o.png" width="631"></p> 
<p> 特征有点多，可能不是很清楚</p> 
<p>可以看到y与budget,revenue,cast_num,crew_num,vote_count这几个变量的相关性高，说明这几个变量对于y的影响较大。</p> 
<p></p> 
<hr> 
<h3 id="机器学习">机器学习</h3> 
<p>划分训练集和验证集,80%训练，20%进行验证</p> 
<pre><code class="language-python">from sklearn.model_selection import train_test_split
X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=0)</code></pre> 
<p>数据标准化</p> 
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train_s = scaler.transform(X_train)
X_val_s = scaler.transform(X_val)
X2_s=scaler.transform(X2)
print('训练数据形状：')
print(X_train_s.shape,y_train.shape)
print('验证测试数据形状：')
(X_val_s.shape,y_val.shape,X2_s.shape)</code></pre> 
<p><img alt="" height="146" src="https://images2.imgbox.com/a1/81/fP8TalTN_o.png" width="493"></p> 
<p></p> 
<h4 id="模型选择">模型选择</h4> 
<p>采用十种模型，对比验证集精度</p> 
<pre><code class="language-python">from sklearn.linear_model import LinearRegression
from sklearn.linear_model import ElasticNet
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost.sklearn import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor</code></pre> 
<p><img alt="" height="419" src="https://images2.imgbox.com/06/20/wt99IMmN_o.png" width="629"></p> 
<p>定义评估函数</p> 
<pre><code class="language-python">from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error,r2_score
 
def evaluation(y_test, y_predict):
    mae = mean_absolute_error(y_test, y_predict)
    mse = mean_squared_error(y_test, y_predict)
    rmse = np.sqrt(mean_squared_error(y_test, y_predict))
    #mape=(abs(y_predict -y_test)/ y_test).mean()
    r_2=r2_score(y_test, y_predict)
    return mae, rmse, r_2  #mse</code></pre> 
<p>模型实例化</p> 
<pre><code class="language-python">#线性回归
model1 = LinearRegression()
 
#弹性网回归
model2 = ElasticNet(alpha=0.05, l1_ratio=0.5)
 
#K近邻
model3 = KNeighborsRegressor(n_neighbors=10)
 
#决策树
model4 = DecisionTreeRegressor(random_state=77)
 
#随机森林
model5= RandomForestRegressor(n_estimators=500,  max_features=int(X_train.shape[1]/3) , random_state=0)
 
#梯度提升
model6 = GradientBoostingRegressor(n_estimators=500,random_state=123)
 
#极端梯度提升
model7 =  XGBRegressor(objective='reg:squarederror', n_estimators=1000, random_state=0)
 
#轻量梯度提升
model8 = LGBMRegressor(n_estimators=1000,objective='regression', # 默认是二分类
                      random_state=0)
 
#支持向量机
model9 = SVR(kernel="rbf")
 
#神经网络
model10 = MLPRegressor(hidden_layer_sizes=(16,8), random_state=77, max_iter=10000)
 
model_list=[model1,model2,model3,model4,model5,model6,model7,model8,model9,model10]
model_name=['线性回归','惩罚回归','K近邻','决策树','随机森林','梯度提升','极端梯度提升','轻量梯度提升','支持向量机','神经网络']</code></pre> 
<p>拟合训练模型，计算模型误差指标 </p> 
<pre><code class="language-python">df_eval=pd.DataFrame(columns=['MAE','RMSE','R2'])
for i in range(10):
    model_C=model_list[i]
    name=model_name[i]
    model_C.fit(X_train_s, y_train)
    pred=model_C.predict(X_val_s)
    s=evaluation(y_val,pred)
    df_eval.loc[name,:]=list(s)</code></pre> 
<p>查看不同模型的评价指标</p> 
<pre><code class="language-python">df_eval</code></pre> 
<p><img alt="" height="330" src="https://images2.imgbox.com/13/88/eWTQ09gM_o.png" width="274"></p> 
<p> 画图查看</p> 
<pre><code class="language-python">bar_width = 0.4
colors=['c', 'b', 'g', 'tomato', 'm', 'y', 'lime', 'k','orange','pink','grey','tan']
fig, ax = plt.subplots(3,1,figsize=(6,12))
for i,col in enumerate(df_eval.columns):
    n=int(str('31')+str(i+1))
    plt.subplot(n)
    df_col=df_eval[col]
    m =np.arange(len(df_col))
    
    #hatch=['-','/','+','x'],
    plt.bar(x=m,height=df_col.to_numpy(),width=bar_width,color=colors)
    
    #plt.xlabel('Methods',fontsize=12)
    names=df_col.index
    plt.xticks(range(len(df_col)),names,fontsize=14)
    plt.xticks(rotation=40)
    
    if col=='R2':
        plt.ylabel(r'$R^{2}$',fontsize=14)
    else:
        plt.ylabel(col,fontsize=14)
plt.tight_layout()
#plt.savefig('柱状图.jpg',dpi=512)
plt.show()</code></pre> 
<p><img alt="" height="629" src="https://images2.imgbox.com/5a/c2/Mcm5MrSR_o.png" width="330"></p> 
<p> 我们采用三种最优的模型进一步搜索最优超参数：随机森林，梯度提升，轻量梯度，然后进行预测和存储。</p> 
<p></p> 
<hr> 
<h3>超参数搜索 </h3> 
<h4>轻量梯度超参数优化</h4> 
<pre><code class="language-python">#利用K折交叉验证搜索最优超参数
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV</code></pre> 
<pre><code class="language-python"># Choose best hyperparameters by RandomizedSearchCV
#随机搜索决策树的参数
param_distributions = {'max_depth': range(4, 10), 'subsample':np.linspace(0.5,1,5 ),'num_leaves': [15, 31, 63, 127],
                       'colsample_bytree': [0.6, 0.7, 0.8, 1.0]}
                        # 'min_child_weight':np.linspace(0,0.1,2 ),
kfold = KFold(n_splits=3, shuffle=True, random_state=1)
model =RandomizedSearchCV(estimator= LGBMRegressor(objective='regression',random_state=0),
                          param_distributions=param_distributions, n_iter=200)
model.fit(X_train_s, y_train)</code></pre> 
<p><img alt="" height="236" src="https://images2.imgbox.com/4e/6c/Lg4paJyt_o.png" width="1078"></p> 
<pre><code class="language-python">#查看最优参数
model.best_params_ </code></pre> 
<p><img alt="" height="50" src="https://images2.imgbox.com/59/2a/OorrpCbN_o.png" width="878"></p> 
<p>最优参数赋值给模型，然后拟合评价</p> 
<pre><code class="language-python">model = model.best_estimator_
model.score(X_val_s, y_val)</code></pre> 
<p> <img alt="" height="42" src="https://images2.imgbox.com/2d/61/pDDfYuST_o.png" width="364"></p> 
<p>可以看到拟合优度上升了一点</p> 
<p>#利用找出来的最优超参数在所有的训练集上训练，然后预测</p> 
<pre><code class="language-python">model=LGBMRegressor(objective='regression',subsample=0.625,learning_rate= 0.01,n_estimators= 1000,num_leaves=15,
                    max_depth= 4,colsample_bytree=1.0,random_state=0)
model.fit(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val])
print(model.score(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val]))
pred=model.predict(X2_s)</code></pre> 
<p>储存预测结果</p> 
<pre><code class="language-python">df=pd.DataFrame(ID)
df['popularity']=pred
df.to_csv('LGBM预测结果.csv',index=False)</code></pre> 
<p>#梯度提升和随机森林也是一样搜索超参数，然后训练和预测</p> 
<pre><code class="language-python">#梯度提升
param_distributions = {'max_depth': range(4, 10), 'subsample':np.linspace(0.5,1,5 ),'learning_rate': np.linspace(0.05,0.3,6 ), 'n_estimators':[100,500,1000,1500, 2000]}
                        # 'min_child_weight':np.linspace(0,0.1,2 ),
kfold = KFold(n_splits=3, shuffle=True, random_state=1)
model =RandomizedSearchCV(estimator= GradientBoostingRegressor(n_estimators=500,random_state=123),param_distributions=param_distributions, n_iter=5)
model.fit(X_train_s, y_train)
model = model.best_estimator_
model.fit(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val])
print(model.score(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val]))
pred=model.predict(X2_s)
df['popularity']=pred
df.to_csv('梯度提升预测结果.csv',index=False)</code></pre> 
<p><img alt="" height="46" src="https://images2.imgbox.com/3f/14/XSZ6MvLZ_o.png" width="310"></p> 
<pre><code class="language-python">#随机森林
param_distributions = {'max_depth': range(4, 10), 'n_estimators':[100,500,1000,1500, 2000]}
kfold = KFold(n_splits=3, shuffle=True, random_state=1)
model =RandomizedSearchCV(estimator=RandomForestRegressor(n_estimators=500,  max_features=int(X_train.shape[1]/3) , random_state=0),param_distributions=param_distributions, n_iter=5)
model.fit(X_train_s, y_train)
model = model.best_estimator_
model.fit(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val])
print(model.score(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val]))
pred=model.predict(X2_s)
df['popularity']=pred
df.to_csv('随机森林提升预测结果.csv',index=False)</code></pre> 
<p> <img alt="" height="54" src="https://images2.imgbox.com/36/76/m4WTTgnV_o.png" width="284"></p> 
<p>下面就可以将这三个预测结果题kaggle提交了！！！</p> 
<hr> 
<h3 id="变量重要性">变量重要性</h3> 
<p>以LGBM为例，画出每个特征变量对响应变量影响程度的图。</p> 
<pre><code class="language-python">model=LGBMRegressor(objective='regression',subsample=0.5,learning_rate= 0.01,n_estimators= 1000,num_leaves=127,
                    max_depth= 4,colsample_bytree=1.0,random_state=0)
model.fit(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val])
plt.figure(figsize=(4,8))
sorted_index = model.feature_importances_.argsort()
plt.barh(range(data.shape[1]), model.feature_importances_[sorted_index])
plt.yticks(np.arange(data.shape[1]), data.columns[sorted_index])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.show()</code></pre> 
<p><img alt="" height="535" src="https://images2.imgbox.com/d4/af/bxRLKRQj_o.png" width="394"></p> 
<p></p> 
<p>可以看到影响y变量最重要的是vote_count,movie_age,cast_num,crew_num等变量， </p> 
<p>movie_age,cast_num,crew_num变量是自己构建的变量，说明这几个特征还是很有效的。</p> 
<hr> 
<p></p> 
<p id="目前在kaggle上能得到最好的预测结果的最好的模型参数">目前在kaggle上能得到最好的预测结果的最好的模型参数。</p> 
<pre><code class="language-python">model=LGBMRegressor(objective='regression',subsample=0.65,learning_rate= 0.01,n_estimators= 800,num_leaves=127,
                    max_depth= 5,colsample_bytree=0.75,random_state=10)
model.fit(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val])
print(model.score(np.r_[X_train_s,X_val_s],np.r_[y_train,y_val]))
pred=model.predict(X2_s)
df['popularity']=pred
df.to_csv('LGBM2.csv',index=False)</code></pre> 
<p> </p> 
<hr> 
<p>创作不易，看官觉得写得还不错的话点个关注和赞吧，本人会持续更新python数据分析领域的代码文章~(需要定制代码可私信)</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a8d5743b9662995ad48a2f1bbc84048d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">yolov8seg 瑞芯微RKNN芯片、地平线Horizon芯片、TensorRT部署</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/18582a076263a0f6c1eb4eb6ba1840a4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">varchar(max)、nvarchar(max) 和varbinary(max) 的区别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>