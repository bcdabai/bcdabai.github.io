<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>k8s1.25版本集群部署（亲测有效） - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="k8s1.25版本集群部署（亲测有效）" />
<meta property="og:description" content="1.实验环境准备
准备三台centos7虚拟机，用来部署k8s集群：
master（hadoop1，192.168.229.111）配置：
操作系统：centos7.3以及更高版本都可以配置：4核cpu，4G内存，30G硬盘
网络：网络地址转换
node（hadoop2，192.168.229.112）配置：
操作系统：centos7.3以及更高版本都可以配置：4核cpu，4G内存，30G硬盘
网络：网络地址转换
2.初始化实验环境（所有节点）
2.1 配置静态IP
#查看网络信息
#配置静态IP
#重启网络服务
systemctl start network.service或者service network restart
#重启虚拟机
2.2 修改yum源
#yum在线下载wgetyum -y install wget#备份原有yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup#下载阿里云yum源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#生成新的yum缓存yum makecache fast#配置k8s需要的yum源cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0EOF#清理缓存yum clean all#生成新的yum缓存yum makecache fast#更新yum源yum -y update#安装软件依赖包yum -y install yum-utils device-mapper-persistent-data lvm2 备注：yum-utils是yum的安装工具包，可以简化安装过程中设置安装源的配置过程。docker内部容器如果需要进行数据存储，需要通过device-mapper-persistent-data和lvm2数据存储驱动来完成数据存储。
#添加新的docker软件源
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum clean allyum makecache fast 2.3 安装基础软件包
yum -y install wget net-tools nfs-utils lrzsz gcc gcc-c&#43;&#43; make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel python-devel epel-release openssh-server socat ipvsadm conntrack ntpdate 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/38b4898ec3f3ab5c4eed3ae1a392edf0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-23T10:51:40+08:00" />
<meta property="article:modified_time" content="2022-11-23T10:51:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">k8s1.25版本集群部署（亲测有效）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="color:#fe2c24;"><strong>1.实验环境准备</strong></span></p> 
<p>准备三台centos7虚拟机，用来部署k8s集群：</p> 
<p>master（hadoop1，192.168.229.111）配置：</p> 
<p>操作系统：centos7.3以及更高版本都可以配置：4核cpu，4G内存，30G硬盘</p> 
<p>网络：网络地址转换</p> 
<p></p> 
<p>node（hadoop2，192.168.229.112）配置：</p> 
<p>操作系统：centos7.3以及更高版本都可以配置：4核cpu，4G内存，30G硬盘</p> 
<p>网络：网络地址转换</p> 
<p><span style="color:#fe2c24;"><strong>2.初始化实验环境（所有节点）</strong></span></p> 
<p><strong><span style="color:#1a439c;">2.1 配置静态IP</span></strong></p> 
<p>#查看网络信息</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/0d/54/4BET0o0H_o.png"></p> 
<p>#配置静态IP</p> 
<p>              <img alt="" height="403" src="https://images2.imgbox.com/36/67/al1zpsYr_o.png" width="554"></p> 
<p></p> 
<p>#重启网络服务</p> 
<p>systemctl start network.service或者service network restart</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4b/a1/g0NquXNV_o.png"></p> 
<p>#重启虚拟机</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/76/93/ZlUCFXv6_o.png"></p> 
<p>               <img alt="" height="176" src="https://images2.imgbox.com/32/8a/CZ4QIw8n_o.png" width="554"></p> 
<p><span style="color:#1a439c;"><strong>2.2 修改yum源</strong></span></p> 
<p></p> 
<pre><code>#yum在线下载wget</code><code>yum -y install wget</code><code>#备份原有yum源</code><code>mv /etc/yum.repos.d/CentOS-Base.repo   /etc/yum.repos.d/CentOS-Base.repo.backup</code><code>#下载阿里云yum源</code><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code><code>#生成新的yum缓存</code><code>yum makecache fast</code><code>#配置k8s需要的yum源</code><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</code><code>[kubernetes]</code><code>name=Kubernetes</code><code>baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</code><code>enabled=1</code><code>gpgcheck=0</code><code>EOF</code><code>#清理缓存</code><code>yum clean all</code><code>#生成新的yum缓存</code><code>yum makecache fast</code><code>#更新yum源</code><code>yum -y update</code><code>#安装软件依赖包</code><code>yum -y install yum-utils device-mapper-persistent-data lvm2</code></pre> 
<p>备注：yum-utils是yum的安装工具包，可以简化安装过程中设置安装源的配置过程。docker内部容器如果需要进行数据存储，需要通过device-mapper-persistent-data和lvm2数据存储驱动来完成数据存储。</p> 
<p>#添加新的docker软件源</p> 
<ul><li></ul> 
<pre><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</code><code>yum clean all</code><code>yum makecache fast</code></pre> 
<p><span style="color:#1a439c;"><strong>2.3 安装基础软件包</strong></span></p> 
<pre><code>yum -y install wget net-tools nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel python-devel epel-release openssh-server socat  ipvsadm conntrack ntpdate</code></pre> 
<p><span style="color:#1a439c;"><strong>2.4 关闭防火墙</strong></span></p> 
<p>#查看防火墙状态</p> 
<p>systemctl status firewalld</p> 
<p>#停止并禁用防火墙</p> 
<p>systemctl stop firewalld &amp;&amp; systemctl  disable  firewalld</p> 
<p><span style="color:#1a439c;"><strong>2.5 时钟同步</strong></span></p> 
<p>#查看时间类型</p> 
<p>在hadoop1节点上输入date命令，可以查看到当前系统时间如下所示。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/86/e9/e3K279J8_o.png"></p> 
<p>如果结果中系统时间为HKT（即香港时间），可以把时间改为CST（CST表示中部标准时间，即上海时间）。</p> 
<p>#修改时间类型</p> 
<p>使用shanghai时间来覆盖当前的系统默认时间，具体操作如下所示。</p> 
<p>注意：上述操作在集群各个节点都要执行，保证当前系统时间标准为上海时间。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/6c/a7/K7HxbQFn_o.png"></p> 
<p>#配置 NTP 服务器</p> 
<p>我们选择hadoop1节点来配置 NTP 服务器，集群其他节点定时同步hadoop1节点时间即可。</p> 
<p>（1）检查 NTP 服务是否已经安装。</p> 
<p>输入rpm -qa | grep ntp命令查看NTP服务是否安装，操作结果如下所示。</p> 
<ul><li></ul> 
<pre><code>[root@hadoop1 ~]# rpm -qa | grep ntp</code><code>ntp-4.2.6p5-12.el6.centos.2.x86_64</code><code>ntpdate-4.2.6p5-12.el6.centos.2.x86_64</code></pre> 
<p>如果NTP服务已经安装，可以直接进行下一步，否则输入yum install -y ntp命令可以在线安装NTP服务。实际上就是安装两个软件， ntpdate-4.2.6p5-12.el6.centos.2.x86_64是用来和某台服务器进行同步的，ntp-4.2.6p5-12.el6.centos.2.x86_64ntp-4.2.6p5-1.el6.centos.x86_64 是用来提供时间同步服务的。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/e6/88/nFuOfGge_o.png"></p> 
<p>（2）修改配置文件ntp.conf</p> 
<p>修改NTP服务配置，具体操作如下所示。</p> 
<p>[root@hadoop1 ~]# vi /etc/ntp.conf</p> 
<p>#启用 restrict限定该机器网段，192.168.229.111为当前节点的IP地址</p> 
<p>restrict 192.168.229.111 mask 255.255.255.0 nomodify notrap</p> 
<p>#注释掉 server 域名配置</p> 
<p></p> 
<pre><code>#server 0.centos.pool.ntp.org iburst</code><code>#server 1.centos.pool.ntp.org iburst</code><code>#server 2.centos.pool.ntp.org iburst</code><code>#server 3.centos.pool.ntp.org iburst</code></pre> 
<p>#添加如下两行配置，让本机和本地硬件时间同步</p> 
<p>server 127.127.1.0</p> 
<p>fudge 127.127.1.0 stratum 10</p> 
<p>（3）启动NTP服务</p> 
<p>执行chkconfig ntpd on命令，可以保证每次机器启动时，NTP服务都会自动启动，具体操作如下所示。</p> 
<p>[root@hadoop1 ~]# chkconfig ntpd on </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/11/c3/x1AOxmzH_o.png"></p> 
<p>（4）配置其他节点定时同步时间</p> 
<p>hadoop2节点通过Linux crontab 命令，可以定时同步hadoop1节点的系统时间，具体操作如下所示。</p> 
<p>[root@hadoop2 ~]# crontab -e</p> 
<p>#表示每个10分钟进行一次时钟同步</p> 
<p>0-59/10 * * * * /usr/sbin/ntpdate hadoop1</p> 
<p>备注：hadoop2节点也需要使用yum install -y ntp命令安装NTP服务，才能使用ntpdate时间同步命令。</p> 
<p><span style="color:#1a439c;"><strong>2.6 关闭selinux</strong></span></p> 
<p>#关闭selinux</p> 
<p>vi /etc/sysconfig/selinux</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a7/4c/iH4glum4_o.png"></p> 
<p>#重启虚拟机</p> 
<p>reboot</p> 
<p>#查看配置结果</p> 
<p>getenforce</p> 
<p><span style="color:#1a439c;"><strong>2.7 关闭交换分区</strong></span></p> 
<p>#设置开机自动关闭分区</p> 
<p>swapoff -a</p> 
<p>#设置永久禁用分区，打开/etc/fstab文件注释掉带有swap</p> 
<p>sed -i 's/.*swap.*/#&amp;/' /etc/fstab</p> 
<p><span style="color:#1a439c;"><strong>2.8 修改内核参数</strong></span></p> 
<p>#开启网络参数</p> 
<pre><code>cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</code><code>net.bridge.bridge-nf-call-ip6tables = 1</code><code>net.bridge.bridge-nf-call-iptables = 1</code><code>EOF</code></pre> 
<p>#手动加载所有的配置文件</p> 
<p>sysctl --system</p> 
<p><span style="color:#1a439c;"><strong>2.9 修改主机名</strong></span></p> 
<p>#通过/etc/hostname文件修改节点主机名</p> 
<p>vi /etc/hostname</p> 
<p>hadoop1</p> 
<p><span style="color:#1a439c;"><strong>2.10 配置hosts文件</strong></span></p> 
<pre><code>[root@hadoop1 ~]# cat /etc/hosts</code><code>127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4</code><code>::1 localhost localhost.localdomain localhost6 localhost6.localdomain6</code><code>192.168.229.111 hadoop1</code><code>192.168.229.112 hadoop2</code></pre> 
<p><span style="color:#1a439c;"><strong>2.11 ssh免密登录</strong></span></p> 
<p>1.在root用户下，配置节点本身ssh免密</p> 
<p>#生成密钥对</p> 
<p>ssh-keygen -t rsa</p> 
<p>#将公钥文件id_rsa.pub 中的内容拷贝到相同目录下的authorized_keys文件中</p> 
<p>cd .ssh/</p> 
<p>cp id_rsa.pub authorized_keys</p> 
<p>#为.ssh目录及文件赋予相应的权限</p> 
<p>cd ..</p> 
<p>chmod 700 .ssh</p> 
<p>chmod 600 .ssh/*</p> 
<p>#ssh免密登录</p> 
<p>ssh hadoop1</p> 
<p>2.实现集群节点间ssh免密登录</p> 
<p>#将hadoop2的公钥id_ras.pub复制到hadoo01中的authorized_keys文件中</p> 
<p>cat ~/.ssh/id_rsa.pub | ssh root@hadoop1 'cat &gt;&gt; ~/.ssh/authorized_keys'</p> 
<p>#将hadoop1中的authorized_keys文件分发到hadoop2节点</p> 
<p>scp -r  ~/.ssh/authorized_keys  root@hadoop2:~/.ssh/</p> 
<p>#hadoop1 ssh免密登录hadoop2</p> 
<p>ssh hadoop2</p> 
<p><span style="color:#fe2c24;"><strong>3.docker安装部署（所有节点）</strong></span></p> 
<p><span style="color:#1a439c;"><strong>3.1 查看支持哪些docker版本</strong></span></p> 
<p>yum list docker-ce --showduplicates |sort -r</p> 
<p><span style="color:#1a439c;"><strong>3.2 安装docker社区版</strong></span></p> 
<p>yum -y install docker-ce-20.10.7-3.el7</p> 
<p><span style="color:#1a439c;"><strong>3.3 设置开机启动docker</strong></span></p> 
<p>systemctl enable docker &amp;&amp; systemctl start docker</p> 
<p><span style="color:#1a439c;"><strong>3.4 查看docker运行状态</strong></span></p> 
<p>systemctl status docker</p> 
<p><span style="color:#1a439c;"><strong>3.5 修改docker配置</strong></span></p> 
<p>#设置更多镜像地址</p> 
<p>​​​​​​​</p> 
<pre><code>cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</code><code>{<!-- --></code><code>"registry-mirrors": [</code><code>"https://7mimmp7p.mirror.aliyuncs.com",</code><code>"https://registry.docker-cn.com",</code><code>"http://hub-mirror.c.163.com",</code><code>"https://docker.mirrors.ustc.edu.cn"</code><code>],</code><code>"exec-opts": ["native.cgroupdriver=systemd"],</code><code>"log-driver": "json-file",</code><code>"log-opts": {<!-- --></code><code>"max-size": "100m"</code><code>},</code><code>"storage-driver": "overlay2",</code><code>"storage-opts": [</code><code>"overlay2.override_kernel_check=true"</code><code>]</code><code>}</code><code>EOF</code></pre> 
<p><span style="color:#1a439c;"><strong>3.6 重启docker</strong></span></p> 
<p>systemctl daemon-reload &amp;&amp; systemctl restart docker</p> 
<p><span style="color:#1a439c;"><strong>3.7 配置k8s网络</strong></span></p> 
<p>​​​​​​​</p> 
<pre><code>#配置网络</code><code>echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</code><code>echo 1 &gt;/proc/sys/net/bridge/bridge-nf-call-ip6tables</code><code>echo """</code><code>vm.swappiness = 0</code><code>net.bridge.bridge-nf-call-iptables = 1</code><code>net.ipv4.ip_forward = 1</code><code>net.bridge.bridge-nf-call-ip6tables = 1</code><code>""" &gt; /etc/sysctl.conf</code><code>#加载配置</code><code>sysctl -p</code></pre> 
<p><span style="color:#1a439c;"><strong>3.8 开启ipvs</strong></span></p> 
<p>#不开启ipvs将会使用iptables，但是效率低，所以官网推荐需要开通ipvs内核​​​​​​​</p> 
<pre><code>cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</code><code>#!/bin/bash</code><code>ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack"</code><code>for kernel_module in \${ipvs_modules}; do</code><code>/sbin/modinfo -F filename \${kernel_module} &gt; /dev/null 2&gt;&amp;1</code><code>if [ $? -eq 0 ]; then</code><code>/sbin/modprobe \${kernel_module}</code><code>fi</code><code>done</code><code>EOF</code><code>#修改执行权限并执行</code><code>chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</code></pre> 
<p><span style="color:#1a439c;"><strong>3.9 安装cri-docker</strong></span></p> 
<p>Docker通过cri-docker软件与k8s进行整合。​​​​​​​</p> 
<pre><code>#下载cri-docker</code><code>wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.2.6/cri-dockerd-0.2.6-3.el7.x86_64.rpm</code><code>#安装cri-docker</code><code>rpm -ivh cri-dockerd-0.2.6-3.el7.x86_64.rpm</code><code>#重载沙箱（pause）镜像</code><code>vi /usr/lib/systemd/system/cri-docker.service</code><code>ExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.8 --container-runtime-endpoint fd://</code><code>#启动并设置开机重启cri-docker</code><code>systemctl start cri-docker</code><code>systemctl enable cri-docker</code></pre> 
<p><span style="color:#fe2c24;"><strong>4.k8s安装部署（所有节点）</strong></span></p> 
<p><span style="color:#1a439c;"><strong>4.1 安装kubectl、kubelet、kubeadm组件</strong></span></p> 
<p>#指定版本下载</p> 
<p>yum install -y kubelet-1.25.0 kubeadm-1.25.0 kubectl-1.25.0</p> 
<p><span style="color:#1a439c;"><strong>4.2 启动kubelet并设置为开机启动</strong></span></p> 
<p>systemctl enable kubelet</p> 
<p>systemctl start kubelet</p> 
<p><span style="color:#1a439c;"><strong>4.3 主节点部署k8s master（仅主节点）</strong></span></p> 
<p>#初始化k8s集群（cpu核必须大于1）</p> 
<p>​​​​​​​</p> 
<pre><code>kubeadm init \</code><code>--apiserver-advertise-address=192.168.229.111 \</code><code>--image-repository registry.aliyuncs.com/google_containers \</code><code>--kubernetes-version v1.25.0 \</code><code>--service-cidr=10.96.0.0/12 \</code><code>--pod-network-cidr=10.244.0.0/16 \</code><code>--cri-socket unix:///var/run/cri-dockerd.sock</code><code># 对于root用户, 直接添加变量即可开始使用集群</code><code>echo "export KUBECONFIG=/etc/kubernetes/admin.conf" &gt;&gt; ~/.bash_profile</code><code>source ~/.bash_profile</code></pre> 
<p><span style="color:#1a439c;"><strong>4.4 加入k8s集群（仅从节点）</strong></span></p> 
<p># 这段话是在主节点kubeadm init时复制过来的, 注意添加--cri-socket​​​​​​​</p> 
<pre><code>kubeadm join 192.168.229.111:6443 --token q1asjl.zb0ihzewm7ilx895 \</code><code>--discovery-token-ca-cert-hash sha256:8b30a783d6398b178a8c241380bc63ac4b728730d9f344fc1ebee8d61900fadf \</code><code>--cri-socket unix:///var/run/cri-dockerd.sock</code><code>#查看k8s集群节点</code><code>kubectl get nodes</code><code>#查看系统默认pods</code><code>kubectl get pods -n kube-system</code></pre> 
<p><span style="color:#1a439c;"><strong>4.5 安装网络插件calico</strong></span></p> 
<p>Calico网络插件可以实现跨主机间容器通信</p> 
<p># 下载 Pod 网络插件(CNI)</p> 
<p>wget https://docs.projectcalico.org/manifests/calico.yaml --no-check-certificate</p> 
<p>#下载calico镜像压缩包，收到上传至每台主机</p> 
<p>calico~kube~controllers~v3.24.3.tar.gz</p> 
<p>calico~cni~v3.24.3.tar.gz</p> 
<p>calico~node~v3.24.3.tar.gz</p> 
<p>备注：calico插件下载经常失败，加微信提供网盘下载链接。</p> 
<p>#每个节点手动通过docker离线加载镜像</p> 
<p>docker load -i calico~cni~v3.24.3.tar.gz</p> 
<p>docker load -i calico~kube~controllers~v3.24.3.tar.gz</p> 
<p>docker load -i calico~node~v3.24.3.tar.gz</p> 
<p>#查看calico是否安装成功</p> 
<p>docker images | grep calico</p> 
<p>#在master节点执行命令进行calico插件安装</p> 
<p>kubectl apply -f calico.yaml</p> 
<p><span style="color:#1a439c;"><strong>4.6 查看节点状况</strong></span></p> 
<p>#在主节点执行命令看集群是否成功</p> 
<p>kubectl get node -o wide</p> 
<p>备注：如果status列中的状态都为ready，表明集群安装成功。</p> 
<p><span style="color:#fe2c24;"><strong>5.部署Dashboard（仅主节点）</strong></span></p> 
<p><span style="color:#1a439c;"><strong>5.1 部署Dashboard</strong></span></p> 
<p>#部署 Dashboard UI</p> 
<ul><li></ul> 
<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml</code></pre> 
<p>#设置访问端口，找到 type: ClusterIP 改为 type: NodePort</p> 
<p>kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</p> 
<p>#查看端口</p> 
<p>kubectl get svc -A |grep kubernetes-dashboard</p> 
<p>#访问：https://集群任意IP:端口 进入登录界面</p> 
<p>https://192.168.229.111:30178</p> 
<p><span style="color:#1a439c;"><strong>5.2 创建访问账号</strong></span></p> 
<p>​​​​​​​</p> 
<pre><code># 准备一个yaml文件</code><code>vi dashuser.yaml</code><code>apiVersion: v1</code><code>kind: ServiceAccount</code><code>metadata:</code><code>name: admin-user</code><code>namespace: kubernetes-dashboard</code><code>---</code><code>apiVersion: rbac.authorization.k8s.io/v1</code><code>kind: ClusterRoleBinding</code><code>metadata:</code><code>name: admin-user</code><code>roleRef:</code><code>apiGroup: rbac.authorization.k8s.io</code><code>kind: ClusterRole</code><code>name: cluster-admin</code><code>subjects:</code><code>- kind: ServiceAccount</code><code>name: admin-user</code><code>namespace: kubernetes-dashboard</code><code>#创建访问账号</code><code>kubectl apply -f dashuser.yaml</code></pre> 
<p><span style="color:#1a439c;"><strong>5.3 令牌访问</strong></span></p> 
<p># 获取访问令牌</p> 
<p>kubectl -n kubernetes-dashboard create token admin-user</p> 
<p># 现在复制令牌并将其粘贴到登录屏幕上的Enter令牌字段中</p> 
<p><span style="color:#1a439c;"><strong>5.4 登录成功</strong></span></p> 
<p>#看到如下界面说明Dashboard部署成功</p> 
<p><span style="color:#fe2c24;"><strong>6.测试k8s集群（仅主节点）</strong></span></p> 
<p>​​​​​​​</p> 
<pre><code># 创建Nginx容器</code><code>kubectl create deployment nginx --image=nginx</code><code>#暴露端口</code><code>kubectl expose deployment nginx --port=80 --type=NodePort</code><code>查看pod</code><code>kubectl get pod,svc</code><code># 访问地址（http://NodeIP:Port）</code><code>http://192.168.229.111:30985/</code><strong><span style="color:#fe2c24;">重要！重要！重要！添加下方二维码获取相关资料。</span></strong></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/95a9dd7035e5ad993d4ca679e6087041/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux查看显卡信息和NVIDIA驱动查询命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/04b23e715d95c56fd2d9781ef86b0413/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python绘制GPS轨迹图</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>