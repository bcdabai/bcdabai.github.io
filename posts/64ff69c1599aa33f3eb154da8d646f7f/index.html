<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>面向BEV感知的4D标注方案 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="面向BEV感知的4D标注方案" />
<meta property="og:description" content="提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档
文章目录 技术简介整体技术路线常用传感器数据规格定义与HD Map的对比地库场景动态物体标注静态要素标注通用障碍物自动标注纯视觉标注方案路面静态要素动态要素标注通用障碍物标注高效的人工标注能力数据链路-HD Flow大模型用于辅助标注总结 技术简介 4D标注主要在3D空间&#43;时序（动态物体）维度上进行标注；
以BEV为代表的感知任务输出空间从2D透视图像空间转换到3D空间，相应地从空间也转换到3D空间。
相关感知任务分为静态感知（路面要素、灯牌锥），动态感知（Detection、Tracking、Prediction、属性），通用障碍物感知（Occupancy/Occupancy Flow）
整体技术路线 通过4D重建实现点云级别或者object级别的重建，通过人工标注积累原始数据。
随着数据积累到一定程度，可以训练云端大模型逐步替换人工标注，可提升80%&#43;的标注效率。
基本流程为：采集数据（包括极光雷达、相机、IMU、GPS）等→输入给动/静态场景进行4D重建→进行人工标注与之间→进行云端模型训练→进行模型预刷（3D or BEV）→进行多传感器交叉验证。
常用传感器 传感器布局：周视7v摄像头&#43;环视4v摄像头；采集车安装Pandar128外参标定：Lidar-camera标定重投影误差&lt;3px；在线标定角度误差&lt;0.1deg，标定方式包括工厂标定和在线标定。时间同步：时间同步偏差&lt;5ms，11v图像同步曝光。
-11v图像同步曝光 数据规格定义 Clip是一段固定时间长度（15s）或者空间距离长度（300m）的视频片段，包括多有传感器的数据Site是空间中的物理坐标点，由位于同一位置的多个clips构成 路面静态要素标注-局部建图：利用Lidar数据结合IMU/GNSS实现cm级别精度的路面重建；采用单趟重建和多趟聚合的方式，既能保证局部建图的完整性，满足远距离真值感知的需求，又能够平摊标注成本。
单趟局部建图：Lidar 定位建图依然面临着挑战，例如车辆高速行驶导致初始化困难；采用多传感器融合结合Lidar-seg语义信息提升单次建图的精度和鲁棒性，初始化成功率&gt;98%，单趟重建的精度达到cm级（与高精度RTK进行评测）多趟聚合：多趟聚合的核心点在于位置重试别即回环检测，由于驾驶场景环境单一，容易引起回环检测失败率搞等问题；采用Lidar-seg结合Learing based features，多躺聚合的成功率可提升到90%以上。 大模型预刷：输入语义、Intensity、纹理图、通过云端模型实现高度自动化标注，可节省80%以上的人工标注成本；模型支持离散要素、几何、属性、连接关系的标注；通过多个clip的聚合，不但可以保证局部建图的完整性，以满足远距离感知的需求，同时可以通过共享标注的方式减少标注成本，平均重投影误差&lt;3px。
与HD Map的对比 图商的HDmap：
高精度传感器，成本高，可扩展性差；受地图鲜度影响，地图更新慢；定位精度差，横向误差10cm，纵向误差40&#43;cm；完整度高、信息丰富 4D Label：
一般精度传感器，适用于采集车；即建即用，不存在地图鲜度的问题；定位精度高，横纵向&lt;10cm；局部的建图，可快速覆盖 地库场景 地库泊车场景采用全局建图的方式，建图精度可以达到cm级别（人工构造回环评测）
动态物体标注 针对bev3E 感知以及端到端模型的真值需求，提供3D det，Tracking，速度，加速度状态针织采用Lidar&#43;camera后融合的方式进行大模型预刷，结合图像感知结果cross check实现全自动标注。 静态要素标注 采用Lidar&#43;camera后融合的方式实现锥桶的3D真值全自动标注锥桶针织标注precision &gt; 95%，recall &gt; 95%，dxyp &lt; 5% 通用障碍物自动标注 Occupancy反映了场景中动静态物体的占据情况，用于识别场景中的通用障碍物Occupancy真值的标注过程应该减少对语义的依赖，更多地使用几何信息Occupancy真值对小物体（50cm * 50cm）的recall &gt; 92%，能有效地识别场景中的宠物、不规则障碍物，推车人等。 纯视觉标注方案 纯视觉方案的核心在于高精度的pose重建，我们采用改造的SFM方案实现了cm精度的重建相比较于多模态方案，纯视觉方案避免了不同传感器之间的外参标定和时间同步问题，生产的真值一致性更高 路面静态要素 对传统的增量incremental SFM进行优化，采用GNN&#43;Wheel&#43;IMU优化后的姿态作为初始值，直接进行Multiple-camera及时序上的三角化，可以提升10&#43;倍的计算效率，RTE &lt; 0.5%采用Learning based features（Superpoint/Superglue）提升再弱纹理区域的重建鲁棒性采用语义引导的MVS提升的点云的重建精度。在SFM提供的准确的视觉pose以及稀疏3D点的基础之上，采用Nerf对路面进行重建，从而对路面的要素进行标注。采用Nerf对路面进行重建，同时获取路面高度和纹理信息，利用语义信息进行监督，可以有效地址弱纹理的影响将路面高度和语义用MLP进行表达其他静态要素：以SFM提供的准确的视觉pose和系数3D点为基础，获取3D空间中交通牌的proposal，之后和2D图像预刷结果进行联合优化，角点重投影误差&lt; 2px。与多模方案对比，一致性更好，与相机运动完全自洽。云上大模型可以采用更大容量的模型以及性能更高的时空融合策略当云端大模型性能指标高于端上10个点以上，便具备作为真值预刷的可行性。 动态要素标注 大模型有效感知范围150m，测距误差 &lt; 5%，AP &gt; 90%纯视觉动态链路真值与Lidar gt对端上模型的提升作用基本一致（AP相差在1个点内） 通用障碍物标注 采用多传感器之间的空间约束和时序约束进行自监督学习。采用DRO的优化模块提升网络的泛化性能。对于depth的估计，采用仿真数据，可以有效地提升动态物体边缘的感知效果。Occupancy/Occupancy flow的真值可以用于处理场景中的通用障碍物，Occupancy/Occupancy flow可以看作是depth的端到端融合100m以内对有较好的测距精度 abs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/64ff69c1599aa33f3eb154da8d646f7f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-21T11:43:58+08:00" />
<meta property="article:modified_time" content="2023-07-21T11:43:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">面向BEV感知的4D标注方案</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_7" rel="nofollow">技术简介</a></li><li><a href="#_14" rel="nofollow">整体技术路线</a></li><li><a href="#_19" rel="nofollow">常用传感器</a></li><li><a href="#_25" rel="nofollow">数据规格定义</a></li><li><a href="#HD_Map_36" rel="nofollow">与HD Map的对比</a></li><li><a href="#_49" rel="nofollow">地库场景</a></li><li><a href="#_52" rel="nofollow">动态物体标注</a></li><li><a href="#_57" rel="nofollow">静态要素标注</a></li><li><a href="#_62" rel="nofollow">通用障碍物自动标注</a></li><li><a href="#_68" rel="nofollow">纯视觉标注方案</a></li><li><a href="#_73" rel="nofollow">路面静态要素</a></li><li><a href="#_86" rel="nofollow">动态要素标注</a></li><li><a href="#_91" rel="nofollow">通用障碍物标注</a></li><li><a href="#_99" rel="nofollow">高效的人工标注能力</a></li><li><a href="#HD_Flow_106" rel="nofollow">数据链路-HD Flow</a></li><li><a href="#_111" rel="nofollow">大模型用于辅助标注</a></li><li><a href="#_120" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_7"></a>技术简介</h2> 
<ul><li> <p>4D标注主要在3D空间+时序（动态物体）维度上进行标注；</p> </li><li> <p>以BEV为代表的感知任务输出空间从2D透视图像空间转换到3D空间，相应地从空间也转换到3D空间。</p> <p>相关感知任务分为静态感知（路面要素、灯牌锥），动态感知（Detection、Tracking、Prediction、属性），通用障碍物感知（Occupancy/Occupancy Flow）</p> </li></ul> 
<h2><a id="_14"></a>整体技术路线</h2> 
<p>通过4D重建实现点云级别或者object级别的重建，通过人工标注积累原始数据。<br> 随着数据积累到一定程度，可以训练云端大模型逐步替换人工标注，可提升80%+的标注效率。<br> 基本流程为：采集数据（包括极光雷达、相机、IMU、GPS）等→输入给动/静态场景进行4D重建→进行人工标注与之间→进行云端模型训练→进行模型预刷（3D or BEV）→进行多传感器交叉验证。</p> 
<h2><a id="_19"></a>常用传感器</h2> 
<ul><li>传感器布局：周视7v摄像头+环视4v摄像头；采集车安装Pandar128</li><li>外参标定：Lidar-camera标定重投影误差&lt;3px；在线标定角度误差&lt;0.1deg，标定方式包括工厂标定和在线标定。</li><li>时间同步：时间同步偏差&lt;5ms，11v图像同步曝光。<br> -11v图像同步曝光</li></ul> 
<h2><a id="_25"></a>数据规格定义</h2> 
<ul><li>Clip是一段固定时间长度（15s）或者空间距离长度（300m）的视频片段，包括多有传感器的数据</li><li>Site是空间中的物理坐标点，由位于同一位置的多个clips构成</li></ul> 
<p>路面静态要素标注-局部建图：利用Lidar数据结合IMU/GNSS实现cm级别精度的路面重建；采用单趟重建和多趟聚合的方式，既能保证局部建图的完整性，满足远距离真值感知的需求，又能够平摊标注成本。</p> 
<ul><li>单趟局部建图：Lidar 定位建图依然面临着挑战，例如车辆高速行驶导致初始化困难；采用多传感器融合结合Lidar-seg语义信息提升单次建图的精度和鲁棒性，初始化成功率&gt;98%，单趟重建的精度达到cm级（与高精度RTK进行评测）</li><li>多趟聚合：多趟聚合的核心点在于位置重试别即回环检测，由于驾驶场景环境单一，容易引起回环检测失败率搞等问题；采用Lidar-seg结合Learing based features，多躺聚合的成功率可提升到90%以上。</li></ul> 
<p>大模型预刷：输入语义、Intensity、纹理图、通过云端模型实现高度自动化标注，可节省80%以上的人工标注成本；模型支持离散要素、几何、属性、连接关系的标注；通过多个clip的聚合，不但可以保证局部建图的完整性，以满足远距离感知的需求，同时可以通过共享标注的方式减少标注成本，平均重投影误差&lt;3px。</p> 
<h2><a id="HD_Map_36"></a>与HD Map的对比</h2> 
<p>图商的HDmap：</p> 
<ul><li>高精度传感器，成本高，可扩展性差；</li><li>受地图鲜度影响，地图更新慢；</li><li>定位精度差，横向误差10cm，纵向误差40+cm；</li><li>完整度高、信息丰富</li></ul> 
<p>4D Label：</p> 
<ul><li>一般精度传感器，适用于采集车；</li><li>即建即用，不存在地图鲜度的问题；</li><li>定位精度高，横纵向&lt;10cm；</li><li>局部的建图，可快速覆盖</li></ul> 
<h2><a id="_49"></a>地库场景</h2> 
<p>地库泊车场景采用全局建图的方式，建图精度可以达到cm级别（人工构造回环评测）</p> 
<h2><a id="_52"></a>动态物体标注</h2> 
<ul><li>针对bev3E 感知以及端到端模型的真值需求，提供3D det，Tracking，速度，加速度状态针织</li><li>采用Lidar+camera后融合的方式进行大模型预刷，结合图像感知结果cross check实现全自动标注。</li></ul> 
<h2><a id="_57"></a>静态要素标注</h2> 
<ul><li>采用Lidar+camera后融合的方式实现锥桶的3D真值全自动标注</li><li>锥桶针织标注precision &gt; 95%，recall &gt; 95%，dxyp &lt; 5%</li></ul> 
<h2><a id="_62"></a>通用障碍物自动标注</h2> 
<ul><li>Occupancy反映了场景中动静态物体的占据情况，用于识别场景中的通用障碍物</li><li>Occupancy真值的标注过程应该减少对语义的依赖，更多地使用几何信息</li><li>Occupancy真值对小物体（50cm * 50cm）的recall &gt; 92%，能有效地识别场景中的宠物、不规则障碍物，推车人等。</li></ul> 
<h2><a id="_68"></a>纯视觉标注方案</h2> 
<ul><li>纯视觉方案的核心在于高精度的pose重建，我们采用改造的SFM方案实现了cm精度的重建</li><li>相比较于多模态方案，纯视觉方案避免了不同传感器之间的外参标定和时间同步问题，生产的真值一致性更高</li></ul> 
<h2><a id="_73"></a>路面静态要素</h2> 
<ul><li>对传统的增量incremental SFM进行优化，采用GNN+Wheel+IMU优化后的姿态作为初始值，直接进行Multiple-camera及时序上的三角化，可以提升10+倍的计算效率，RTE &lt; 0.5%</li><li>采用Learning based features（Superpoint/Superglue）提升再弱纹理区域的重建鲁棒性</li><li>采用语义引导的MVS提升的点云的重建精度。</li><li>在SFM提供的准确的视觉pose以及稀疏3D点的基础之上，采用Nerf对路面进行重建，从而对路面的要素进行标注。</li><li>采用Nerf对路面进行重建，同时获取路面高度和纹理信息，利用语义信息进行监督，可以有效地址弱纹理的影响</li><li>将路面高度和语义用MLP进行表达</li><li>其他静态要素：以SFM提供的准确的视觉pose和系数3D点为基础，获取3D空间中交通牌的proposal，之后和2D图像预刷结果进行联合优化，角点重投影误差&lt; 2px。</li><li>与多模方案对比，一致性更好，与相机运动完全自洽。</li><li>云上大模型可以采用更大容量的模型以及性能更高的时空融合策略</li><li>当云端大模型性能指标高于端上10个点以上，便具备作为真值预刷的可行性。</li></ul> 
<h2><a id="_86"></a>动态要素标注</h2> 
<ul><li>大模型有效感知范围150m，测距误差 &lt; 5%，AP &gt; 90%</li><li>纯视觉动态链路真值与Lidar gt对端上模型的提升作用基本一致（AP相差在1个点内）</li></ul> 
<h2><a id="_91"></a>通用障碍物标注</h2> 
<ul><li>采用多传感器之间的空间约束和时序约束进行自监督学习。</li><li>采用DRO的优化模块提升网络的泛化性能。</li><li>对于depth的估计，采用仿真数据，可以有效地提升动态物体边缘的感知效果。</li><li>Occupancy/Occupancy flow的真值可以用于处理场景中的通用障碍物，Occupancy/Occupancy flow可以看作是depth的端到端融合</li><li>100m以内对有较好的测距精度 abs.rel &lt; 8%</li></ul> 
<h2><a id="_99"></a>高效的人工标注能力</h2> 
<ul><li>静态要素4D标注、动态物体3D框检测与跟踪</li><li>任务调度机制支持千人级并发作业</li><li>物理层（如车道线）标注和逻辑层标注（如交通灯与车道关联关系）</li><li>点/线/面/体 标注、人机交互式半自动化提取，自动贴合点云、3D向量反投影图像空间、标注结果播放质检等</li><li>动态物体3D框标注、跟踪标注、属性标注</li></ul> 
<h2><a id="HD_Flow_106"></a>数据链路-HD Flow</h2> 
<ul><li>Hrizon Data Flow（HDFlow）是在AIDI之上构建的，基于DAG的算法自动化开发全链路闭环工具</li><li>DAG指有向无环图，我们通过DAG引擎串联独立的任务（OP），形成自动化的工作流</li><li>HDFlow对不同的DAG引擎进行了抽象和封装，简化OP接口，同时支持本地和分布式执行</li></ul> 
<h2><a id="_111"></a>大模型用于辅助标注</h2> 
<ul><li>从Low level的任务到High Level的任务，大模型会在标注重发挥越来越重要的作用</li><li>模型的迭代效率和成本是AI产品的核心竞争力</li><li>高精度高为你当选的定位和建图是4D Label的基础</li><li>端到端模型是实现数据闭环的重要环境，一些后处理的任务奖会从端上走到云上，成为真值标注方案，甚至云端智能驾驶方案</li><li>数据防着你合成是解决corner case的非常有潜力的途径。</li></ul> 
<hr> 
<h2><a id="_120"></a>总结</h2> 
<p>提示：这里对文章进行总结：</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2b0b5b0e0b065080d9188aac34708e08/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">程序员必须掌握的重要算法及其应用领域</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/11d3f116d8605395c7e8ec522847c9e7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于Qt的飞机小游戏实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>