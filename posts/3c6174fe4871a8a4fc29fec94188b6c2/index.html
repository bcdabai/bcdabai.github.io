<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>互联网防反爬机制的六种反爬技术大解析 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="互联网防反爬机制的六种反爬技术大解析" />
<meta property="og:description" content="前言 互联网时代，无论在工作上，还是生活上都离不开网络，而网络能给我们带来什么？
新闻，小说，资料，各行业的数据或者报表等等；
比如：快毕业了为了论文，在各种网站上爬取需要的数据进行分析；还有一些为了兴趣爱好，爬取各种类型的图片，视频，文章，数据等。
各网站的开发人员为了约束这种行为，开始绞尽脑汁，采取各种手段去约束爬虫，于是，有了反爬机制！
反爬虫 今天小编来和大家谈谈反爬技术。要了解反爬技术就必须要知道爬虫，所谓爬虫其实就是由计算机自动与服务器交互获取数据的工具。
目前常见而好用的反爬技术有七种，它们分别是：user-agent，验证码，封IP，滑块验证，关联请求上下文，JavaScript 参与运算以及提高数据获取成本。
仔细分析这七种反爬技术 1、user-agent 数据请求头，最初级的反爬，只要在请求中模拟请求头即可轻松飘过。
解决方法：可以自己设置一下user-agent，或者更好的是，可以从一系列的user-agent里随机挑出一个符合标准的使用
无论是浏览器，程序，还是爬虫，在向服务器发起网络请求时，都会先发送一个请求头文件 headers
比如：
{ &#34;headers&#34;: { &#34;Accept&#34;: &#34;text/html,application/xhtml&#43;xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&#34;, &#34;Accept-Encoding&#34;: &#34;gzip, deflate, br&#34;, &#34;Accept-Language&#34;: &#34;zh-CN,zh;q=0.9,zh-HK;q=0.8&#34;, &#34;Host&#34;: &#34;httpbin.org&#34;, &#34;Sec-Fetch-Dest&#34;: &#34;document&#34;, &#34;Sec-Fetch-Mode&#34;: &#34;navigate&#34;, &#34;Sec-Fetch-Site&#34;: &#34;none&#34;, &#34;Upgrade-Insecure-Requests&#34;: &#34;1&#34;, &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#34;, &#34;X-Amzn-Trace-Id&#34;: &#34;Root=1-5fe2b4fe-6e4edc1c4dbbe85a3c25492b&#34; } } # &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#34; 请求头大部分的字段主要是浏览器向服务端 “表明自己的身份”用的，很多网站都会建立 user-agent 白名单，只有在正常范围内的 user-agent 才能正常访问 。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/3c6174fe4871a8a4fc29fec94188b6c2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-06T11:15:25+08:00" />
<meta property="article:modified_time" content="2024-01-06T11:15:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">互联网防反爬机制的六种反爬技术大解析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>前言</h2> 
<p>互联网时代，无论在工作上，还是生活上都离不开网络，而网络能给我们带来什么？</p> 
<p><strong>新闻，小说，资料，各行业的数据或者报表等等；</strong></p> 
<p>比如：快毕业了为了论文，在各种网站上爬取需要的数据进行分析；还有一些为了兴趣爱好，爬取各种类型的图片，视频，文章，数据等。</p> 
<p>各网站的开发人员为了约束这种行为，开始绞尽脑汁，采取各种手段去约束爬虫，于是，<strong>有了反爬机制！</strong></p> 
<h2><a id="_10"></a>反爬虫</h2> 
<p>今天小编来和大家谈谈反爬技术。要了解反爬技术就必须要知道爬虫，所谓爬虫其实就是由计算机自动与服务器交互获取数据的工具。</p> 
<p>目前常见而好用的反爬技术有七种，它们分别是：user-agent，验证码，封IP，滑块验证，关联请求上下文，JavaScript 参与运算以及提高数据获取成本。</p> 
<p><img src="https://images2.imgbox.com/d3/b2/EdwQeq2f_o.png" alt=""></p> 
<h2><a id="_19"></a>仔细分析这七种反爬技术</h2> 
<h3><a id="1useragent_21"></a><strong>1、user-agent</strong></h3> 
<p>数据请求头，最初级的反爬，只要在请求中模拟请求头即可轻松飘过。</p> 
<p>解决方法：可以自己设置一下user-agent，或者更好的是，可以从一系列的user-agent里随机挑出一个符合标准的使用</p> 
<p>无论是浏览器，程序，还是爬虫，在向服务器发起网络请求时，都会先发送一个请求头文件 headers</p> 
<p>比如：</p> 
<pre><code class="prism language-python"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"headers"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"Accept"</span><span class="token punctuation">:</span> <span class="token string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span class="token punctuation">,</span> 
    <span class="token string">"Accept-Encoding"</span><span class="token punctuation">:</span> <span class="token string">"gzip, deflate, br"</span><span class="token punctuation">,</span> 
    <span class="token string">"Accept-Language"</span><span class="token punctuation">:</span> <span class="token string">"zh-CN,zh;q=0.9,zh-HK;q=0.8"</span><span class="token punctuation">,</span> 
    <span class="token string">"Host"</span><span class="token punctuation">:</span> <span class="token string">"httpbin.org"</span><span class="token punctuation">,</span> 
    <span class="token string">"Sec-Fetch-Dest"</span><span class="token punctuation">:</span> <span class="token string">"document"</span><span class="token punctuation">,</span> 
    <span class="token string">"Sec-Fetch-Mode"</span><span class="token punctuation">:</span> <span class="token string">"navigate"</span><span class="token punctuation">,</span> 
    <span class="token string">"Sec-Fetch-Site"</span><span class="token punctuation">:</span> <span class="token string">"none"</span><span class="token punctuation">,</span> 
    <span class="token string">"Upgrade-Insecure-Requests"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span> 
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36"</span><span class="token punctuation">,</span> 
    <span class="token string">"X-Amzn-Trace-Id"</span><span class="token punctuation">:</span> <span class="token string">"Root=1-5fe2b4fe-6e4edc1c4dbbe85a3c25492b"</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment"># "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36"</span>
</code></pre> 
<blockquote> 
 <p>请求头大部分的字段主要是浏览器向服务端 “表明自己的身份”用的，很多网站都会建立 user-agent 白名单，只有在正常范围内的 user-agent 才能正常访问 。</p> 
 <p>user-agent 是一个阅读器标志，用户都是一中阅读器，网站很粗糙的辨别你有咩有作弊，必须要结构不同的阅读器标志，不然就会认为你是爬虫，宁杀错，不放过，你说气不气；</p> 
 <p>缺点：很容易伪造头部</p> 
</blockquote> 
<p><strong>处理方案：</strong></p> 
<p>修改阅读器标志，模拟其他阅读器的标志（定义一个标志库，随机获取一个），能够通过API接口实现各种阅读器的收集模拟；</p> 
<pre><code class="prism language-python"><span class="token comment"># 定义 user-agent/标志库</span>
<span class="token comment"># 第一种方法</span>
<span class="token keyword">def</span> <span class="token function">get_user_agent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    模拟headers的user-agent字段，
    返回一个随机的user-agent字典类型的键值对
    """</span>
    agents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (Windows NT 10.0;) Gecko/20100101 Firefox/61.0"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)"</span><span class="token punctuation">,</span>
    <span class="token string">"Mozilla/5.0 (Macintosh; U; PPC Mac OS X 10.5; en-US; rv:1.9.2.15) Gecko/20110303 Firefox/3.6.15"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
    
    fakeheader <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    fakeheader<span class="token punctuation">[</span><span class="token string">'User-agent'</span><span class="token punctuation">]</span> <span class="token operator">=</span> agents<span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>agents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> fakeheader

<span class="token keyword">def</span> <span class="token function">get_html</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        r<span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>get_user_agent<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        r<span class="token punctuation">.</span>raise_for_status
        r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encding
        <span class="token keyword">return</span> r<span class="token punctuation">.</span>status_code
   <span class="token keyword">except</span><span class="token punctuation">:</span>
    	<span class="token keyword">return</span> <span class="token string">"someting wrong!"</span>
    
 <span class="token comment"># 第二种方法</span>
<span class="token keyword">def</span> <span class="token function">get_html</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    agents <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
    headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>user_agent_list<span class="token punctuation">)</span><span class="token punctuation">,</span>
    	<span class="token string">'Referer'</span><span class="token punctuation">:</span> <span class="token string">'https://www.baidu.com'</span><span class="token punctuation">,</span>
        <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'</span><span class="token punctuation">,</span>
        <span class="token string">'Accept-Encoding'</span><span class="token punctuation">:</span> <span class="token string">'gzip, deflate, br'</span><span class="token punctuation">,</span>
        <span class="token string">'Accept-Language'</span><span class="token punctuation">:</span> <span class="token string">'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7'</span><span class="token punctuation">,</span>
        <span class="token string">'Cookie'</span><span class="token punctuation">:</span> <span class="token string">'...'</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        r<span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
        r<span class="token punctuation">.</span>raise_for_status
        r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encding
        <span class="token keyword">return</span> r<span class="token punctuation">.</span>status_code
   <span class="token keyword">except</span><span class="token punctuation">:</span>
    	<span class="token keyword">return</span> <span class="token string">"someting wrong!"</span>
</code></pre> 
<h3><a id="2_113"></a><strong>2、验证码</strong></h3> 
<p>验证码是最常用的反爬虫措施，但简单验证码通过机器学习自动识别，通常正确率能达到50%以上甚至更高。</p> 
<p>复杂验证码通过提交到专门的打码平台进行人工打码，依据验证码的复杂度，打码工人平均每码收1-2分钱，成本比较低。也同样容易被绕过，使得数据容易被爬取。</p> 
<blockquote> 
 <p>验证码（CAPTCHA）是“Completely Automated Public Turing test to tell Computers and Humans Apart”（全自动区分计算机和人类的图灵测试）的缩写，是一种区分用户是计算机还是人的公共全自动程序。可以防止：恶意破解密码、刷票、论坛灌水，有效防止某个黑客对某一个特定注册用户用特定程序暴力破解方式进行不断的登陆尝试，实际上用验证码是现在很多网站通行的方式，我们利用比较简易的方式实现了这个功能。这个问题可以由计算机生成并评判，但是必须只有人类才能解答。由于 计算机无法解答CAPTCHA的问题，所以回答出问题的用户就可以被认为是人类。</p> 
</blockquote> 
<p><strong>（1）图片验证码</strong></p> 
<p>​ 复杂性</p> 
<blockquote> 
 <p>​ 打码平台雇佣了人力，专门帮人识别验证码。识别完把结果传回去。总共的过程用不了几秒时间。这样的打码平台还有记忆功能。图片被识别为“锅铲”之后，那么下次这张图片再出现的时候，系统就直接判断它是“锅铲”。时间一长，图片验证码服务器里的图片就被标记完了，机器就能自动识别了。</p> 
</blockquote> 
<p>简单型</p> 
<blockquote> 
 <p>​ OCR识别技术(利用python第三方库–tesserocr)来识别，经过灰度变换和二值化后,由模糊的验证码背景变成清晰可见的验证码。对于容易迷惑人得图片验证码，在这种验证码,语言一般自带图形库,添加上扭曲就成了这个样子,我们可以利用9万张图片进行训练,完成类似人的精准度,到达识别验证码的效果</p> 
</blockquote> 
<p><strong>（2）短信验证码</strong></p> 
<p>​ 用Webbrowser技术，模拟用户打开短信的行为,最终获取短信验证码。</p> 
<p><strong>（3）计算题图片验证码</strong></p> 
<blockquote> 
 <p>​ 把所有可能出现的汉字都人工取出来，保存为黑白图片,把验证码按照字体颜色二值化，去除噪点,然后将所有图片依次与之进行像素对比,计算出相似值,找到最像的那张图片</p> 
</blockquote> 
<p><strong>（4）滑块验证码</strong></p> 
<blockquote> 
 <p>​ 我们可以利用图片的像素作为线索,确定好基本属性值,查看位置的差值,对于差值超过基本属性值,我们就可以确定图片的大概位置。</p> 
 <p>滑块验证结合了机器学习技术，只需要滑动滑块，而不用看那些复杂到有时人眼也无法分辨的字母。</p> 
 <p>但由于部分厂商实现时校验算法较为简单，导致经常只需要相对简单的模拟滑动操作就能绕过，从而使得数据被恶意爬取。类似案例：淘宝，阿里云，淘宝联盟。</p> 
</blockquote> 
<p><strong>（5）图案验证码</strong></p> 
<blockquote> 
 <p>​ 对于这种每次拖动的顺序不一样,结果就不一样,我们怎么做来识别呢?</p> 
 <p>利用机器学习所有的拖动顺序,利用1万张图片进行训练,完成类似人的操作,最终将其识别</p> 
 <p>利用selenium技术来模拟人的拖动顺序,穷尽所有拖动方式,这样达到是别的效果</p> 
</blockquote> 
<p><strong>（6）标记倒立文字验证码</strong></p> 
<blockquote> 
 <p>​ 首先点击前两个倒立的文字,可确定7个文字的坐标， 验证码中7个汉字的位置是确定的，只需要提前确认每个字所在的坐标并将其放入列表中，然后人工确定倒立文字的文字序号，将列表中序号对应的坐标即可实现成功登录。</p> 
</blockquote> 
<p>解决方法：接入第三方验证码平台，实时破解网站得验证码</p> 
<p>缺点：影响正常得用户体验操作，验证码越复杂，网站体验感越差。</p> 
<h3><a id="3IP_164"></a><strong>3、封IP</strong></h3> 
<p>这是最有效也最容易误杀的方案。该策略建立在 IP 稀有的前提下，目前通过代理池购买，ADSL，或者拨号 VPS 等方式，可以低成本获取数十万的 IP 池，导致单纯的封IP策略效果越来越差。</p> 
<p>解决方法：</p> 
<p>比较成熟的方式是：IP代理池</p> 
<p>简单的说，就是通过ip代理，从不同的ip进行访问，这样就不会被封掉ip了。可是ip代理的获取本身就是一个很麻烦的事情，网上有免费和付费的，但是质量都层次不齐。如果是企业里需要的话，可以通过自己购买集群云服务来自建代理池。</p> 
<p><img src="https://images2.imgbox.com/03/c3/FZHfq5VS_o.png" alt=""></p> 
<h3><a id="4_177"></a><strong>4、关联请求上下文</strong></h3> 
<p>反爬虫可以通过 Token 或网络请求上下文是否进行了完整流程的方式来判断是否真人访问。但对具有协议分析能力的技术人员来说进行全量模拟并没有太大困难。类似案例：知乎，百度登录过程。</p> 
<h3><a id="5JavaScript__182"></a><strong>5、JavaScript 参与运算</strong></h3> 
<p>简单的爬虫无法进行 js 运算，如果部分中间结果需要 js 引擎对 js 进行解析和运算，那么就可以让攻击者无法简单进行爬取。但爬虫开发者依然可以通过自带 js 引擎模块或直接使用 phantomjs ，chrome等无端浏览器进行自动化解析。</p> 
<p>解决方法：这里就要请出一个大杀器：”PhantomJS“PhantomJS是一个Python包，他可以在没有图形界面的情况下，完全模拟一个”浏览器“，js脚本验证什么的再也不是问题了。</p> 
<h3><a id="6_189"></a><strong>6、提高数据获取成本</strong></h3> 
<p>当面对的是职业选手时，只能通过提升对方人力成本来实现，比如代码混淆、动态加密方案、假数据，混淆数据等方式，利用开发速度大于分析速度的优势，来拖垮对方的意志。如果对方咬定不放松，那只能持续对抗，直到一方由于机器成本或人力成本放弃。典型案例：汽车之家字体替换，去哪儿网网隐藏在CSS元素坐标中。</p> 
<p>以上就是六种反爬技术的解析，大家都弄清楚了吗？</p> 
<p><img src="https://images2.imgbox.com/c9/ea/WxzOfSOm_o.gif" alt=""></p> 
<p>如果你对Python感兴趣，想要学习python，这里给大家分享一份<strong>Python全套学习资料</strong>，都是我自己学习时整理的，希望可以帮到你，一起加油！</p> 
<p>😝有需要的小伙伴，可以<mark>V扫描下方二维码免费领取</mark>🆓</p> 
<p>​<img src="https://images2.imgbox.com/1c/f1/zOnsP7FI_o.jpg"></p> 
<h3><a id="1_206"></a>1️⃣零基础入门</h3> 
<h4><a id="__208"></a>① 学习路线</h4> 
<p>对于从来没有接触过Python的同学，我们帮你准备了详细的<strong>学习成长路线图</strong>。可以说是<strong>最科学最系统的学习路线</strong>，你可以按照上面的知识点去找对应的学习资源，保证自己学得较为全面。<br> <img src="https://images2.imgbox.com/bf/a2/pLUUfBJB_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="__213"></a>② 路线对应学习视频</h4> 
<p>还有很多适合0基础入门的学习视频，有了这些视频，轻轻松松上手Python~<br> <img src="https://images2.imgbox.com/ad/8a/KiCUMUGr_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_218"></a>③练习题</h4> 
<p>每节视频课后，都有对应的练习题哦，可以检验学习成果哈哈！<br> <img src="https://images2.imgbox.com/c2/10/D0JOBKCu_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2Python_223"></a><strong>2️⃣国内外Python书籍、文档</strong></h3> 
<h4><a id="__225"></a>① 文档和书籍资料</h4> 
<p><img src="https://images2.imgbox.com/f3/1d/WIoor1xD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3Python_229"></a>3️⃣Python工具包+项目源码合集</h3> 
<h4><a id="Python_231"></a>①Python工具包</h4> 
<p>学习Python常用的开发软件都在这里了！每个都有详细的安装教程，保证你可以安装成功哦！<br> <img src="https://images2.imgbox.com/2f/7d/VSvASIxG_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Python_236"></a>②Python实战案例</h4> 
<p>光学理论是没用的，要学会跟着一起敲代码，动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<strong>100+实战案例源码等你来拿！</strong><br> <img src="https://images2.imgbox.com/95/23/qt2A37zU_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Python_241"></a>③Python小游戏源码</h4> 
<p>如果觉得上面的实战案例有点枯燥，可以试试自己用Python编写小游戏，让你的学习过程中增添一点趣味！<br> <img src="https://images2.imgbox.com/a7/9f/dbsJvasy_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4Python_246"></a>4️⃣Python面试题</h3> 
<p>我们学会了Python之后，有了技能就可以出去找工作啦！下面这些面试题是都来自阿里、腾讯、字节等一线互联网大厂，并且有阿里大佬给出了权威的解答，刷完这一套面试资料相信大家都能找到满意的工作。<br> <img src="https://images2.imgbox.com/c6/b7/ibSwI4Vx_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/02/46/3YG1IbZh_o.png" alt="在这里插入图片描述"></p> 
<p>上述所有资料 ⚡️ ，朋友们如果有需要的，可以扫描下方👇👇👇二维码免费领取🆓<br> ​<img src="https://images2.imgbox.com/a9/59/8ZKC1sPH_o.jpg"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3175da9b8ec16e7b6ac8e5b70fcd27ae/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;的介绍前景和在实际开发中的运用及与java对比（嵌入式，游戏）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a90d48c50ebb72e6967f0e97f3864702/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">DMX512输出协议详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>