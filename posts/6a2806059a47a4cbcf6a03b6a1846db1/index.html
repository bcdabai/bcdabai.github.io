<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>计算机视觉——立体图像 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="计算机视觉——立体图像" />
<meta property="og:description" content="文章目录 立体图像一、计算视差图二、双目立体匹配三、NCC算法实验3.1实验要求3.2实验准备3.3实验代码3.4实验结果及分析 四、实验总结 立体图像 一个多视图成像的特殊例子是立体视觉（或者立体成像），即使用两台只有水平（向 一侧）偏移的照相机观测同一场景。当照相机的位置如上设置，两幅图像具有相同 的图像平面，图像的行是垂直对齐的，那么称图像对是经过矫正的。该设置在机器 人学中很常见，常被称为立体平台。
一、计算视差图 归一化相关性，简称NCC，就是用于归一化待匹配目标之间的相关程度，注意这里比较的是原始像素。通过在待匹配像素位置p（px，py）构建n*n邻域匹配窗口，与目标像素位置p’(px&#43;d,py）同样构建邻域匹配窗口的方式建立目标函数来对匹配窗口进行度量相关性，注意这里构建相关窗口的前提是两帧图像之间已经校正到水平位置，即光心处于同一水平线上，此时极线是水平的，否则匹配过程只能在倾斜的极线方向上完成，这将消耗更多的计算资源。相关程度的度量方式由如下式子定义：
上式中的变量需要解释一下：其中p点表示图像I1待匹配像素坐标（px,py），d表示在图像I2被查询像素位置在水平方向上与px的距离。如下图所示：
左边为图像I1，右边为图像I2。图像I1,蓝色方框表示待匹配像素坐标（px,py）,图像I2蓝色方框表示坐标位置为（px,py），红色方框表示坐标位置（px&#43;d,py）。
上述公式表示度量两个匹配窗口之间的相关性，通过归一化将匹配结果限制在 [-1,1]的范围内，可以非常方便得到判断匹配窗口相关程度：
若NCC = -1，则表示两个匹配窗口完全不相关，相反，若NCC = 1时，表示两个匹配窗口相关程度非常高。
二、双目立体匹配 假设有校正过的两帧图像I1,、I2，由上述NCC计算流程的描述可知，对图像I1一个待匹配像素构建n*n匹配窗口，在图像I2极线上对每一个像素构建匹配窗口与待匹配像素匹配窗口计算相关性，相关性最高的视为最优匹配。
双目立体匹配流程如下：
采集图像：通过标定好的双目相机采集图像，当然也可以用两个单目相机来组合成双目相机。（标定方法下次再说）极线校正：校正的目的是使两帧图像极线处于水平方向，或者说是使两帧图像的光心处于同一水平线上。通过校正极线可以方便后续的NCC操作。
特征匹配：这里便是我们利用NCC做匹配的步骤啦，匹配方法如上所述，右视图中与左视图待测像素同一水平线上相关性最高的即为最优匹配。完成匹配后，我们需要记录其视差d，即待测像素水平方向xl与匹配像素水平方向 X r Xr Xr之间的差值 d = X r − X l d = Xr - Xl d=Xr−Xl，最终我们可以得到一个与原始图像尺寸相同的视差图D。深度恢复：通过上述匹配结果得到的视差图D，我们可以很简单的利用相似三角形反推出以左视图为参考系的深度图。计算原理如下图所示：
如图， T x Tx Tx为双目相机基线， f f f为相机焦距，这些可以通过相机标定步骤得到。而 X r − X l Xr - Xl Xr−Xl就是视差 d d d。通过公式 z = f ∗ T x d z = \frac{f*Tx}{d} z=df∗Tx​可以很简单地得到以左视图为参考系的深度图了。 三、NCC算法实验 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6a2806059a47a4cbcf6a03b6a1846db1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-26T15:36:01+08:00" />
<meta property="article:modified_time" content="2020-04-26T15:36:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">计算机视觉——立体图像</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">立体图像</a></li><li><ul><li><a href="#_3" rel="nofollow">一、计算视差图</a></li><li><a href="#_13" rel="nofollow">二、双目立体匹配</a></li><li><a href="#NCC_23" rel="nofollow">三、NCC算法实验</a></li><li><ul><li><a href="#31_24" rel="nofollow">3.1实验要求</a></li><li><a href="#32_28" rel="nofollow">3.2实验准备</a></li><li><a href="#33_31" rel="nofollow">3.3实验代码</a></li><li><a href="#34_115" rel="nofollow">3.4实验结果及分析</a></li></ul> 
   </li><li><a href="#_148" rel="nofollow">四、实验总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>立体图像</h2> 
<p>一个多视图成像的特殊例子是立体视觉（或者立体成像），即使用两台只有水平（向 一侧）偏移的照相机观测同一场景。当照相机的位置如上设置，两幅图像具有相同 的图像平面，图像的行是垂直对齐的，那么称图像对是经过矫正的。该设置在机器 人学中很常见，常被称为立体平台。</p> 
<h3><a id="_3"></a>一、计算视差图</h3> 
<p>归一化相关性，简称NCC，就是用于归一化待匹配目标之间的相关程度，注意这里比较的是原始像素。通过在待匹配像素位置p（px，py）构建n*n邻域匹配窗口，与目标像素位置p’(px+d,py）同样构建邻域匹配窗口的方式建立目标函数来对匹配窗口进行度量相关性，注意这里构建相关窗口的前提是两帧图像之间已经校正到水平位置，即光心处于同一水平线上，此时极线是水平的，否则匹配过程只能在倾斜的极线方向上完成，这将消耗更多的计算资源。相关程度的度量方式由如下式子定义：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/61/0d/1oIfPqdt_o.png"><br> 上式中的变量需要解释一下：其中p点表示图像I1待匹配像素坐标（px,py），d表示在图像I2被查询像素位置在水平方向上与px的距离。如下图所示：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/03/43/2G7kgo9P_o.png"><br> 左边为图像I1，右边为图像I2。图像I1,蓝色方框表示待匹配像素坐标（px,py）,图像I2蓝色方框表示坐标位置为（px,py），红色方框表示坐标位置（px+d,py）。<br> 上述公式表示度量两个匹配窗口之间的相关性，通过归一化将匹配结果限制在 [-1,1]的范围内，可以非常方便得到判断匹配窗口相关程度：</p> 
<blockquote> 
 <p>若NCC = -1，则表示两个匹配窗口完全不相关，相反，若NCC = 1时，表示两个匹配窗口相关程度非常高。</p> 
</blockquote> 
<h3><a id="_13"></a>二、双目立体匹配</h3> 
<p>假设有校正过的两帧图像I1,、I2，由上述NCC计算流程的描述可知，对图像I1一个待匹配像素构建n*n匹配窗口，在图像I2极线上对每一个像素构建匹配窗口与待匹配像素匹配窗口计算相关性，相关性最高的视为最优匹配。<br> 双目立体匹配流程如下：</p> 
<ol><li>采集图像：通过标定好的双目相机采集图像，当然也可以用两个单目相机来组合成双目相机。（标定方法下次再说）</li><li>极线校正：校正的目的是使两帧图像极线处于水平方向，或者说是使两帧图像的光心处于同一水平线上。通过校正极线可以方便后续的NCC操作。<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/0f/ca/eyMFZIn6_o.png"></li><li>特征匹配：这里便是我们利用NCC做匹配的步骤啦，匹配方法如上所述，右视图中与左视图待测像素同一水平线上相关性最高的即为最优匹配。完成匹配后，我们需要记录其视差d，即待测像素水平方向xl与匹配像素水平方向<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          X 
         
        
          r 
         
        
       
         Xr 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07em;">X</span><span class="mord mathdefault" style="margin-right: 0.02em;">r</span></span></span></span></span>之间的差值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          d 
         
        
          = 
         
        
          X 
         
        
          r 
         
        
          − 
         
        
          X 
         
        
          l 
         
        
       
         d = Xr - Xl 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69em; vertical-align: 0em;"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right: 0.27em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.27em;"></span></span><span class="base"><span class="strut" style="height: 0.76em; vertical-align: -0.08em;"></span><span class="mord mathdefault" style="margin-right: 0.07em;">X</span><span class="mord mathdefault" style="margin-right: 0.02em;">r</span><span class="mspace" style="margin-right: 0.22em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.22em;"></span></span><span class="base"><span class="strut" style="height: 0.69em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07em;">X</span><span class="mord mathdefault" style="margin-right: 0.01em;">l</span></span></span></span></span>，最终我们可以得到一个与原始图像尺寸相同的视差图D。</li><li>深度恢复：通过上述匹配结果得到的视差图D，我们可以很简单的利用相似三角形反推出以左视图为参考系的深度图。计算原理如下图所示：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/f8/10/Ei51sQYA_o.png"><br> 如图，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          T 
         
        
          x 
         
        
       
         Tx 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13em;">T</span><span class="mord mathdefault">x</span></span></span></span></span>为双目相机基线，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          f 
         
        
       
         f 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88em; vertical-align: -0.19em;"></span><span class="mord mathdefault" style="margin-right: 0.1em;">f</span></span></span></span></span>为相机焦距，这些可以通过相机标定步骤得到。而<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          X 
         
        
          r 
         
        
          − 
         
        
          X 
         
        
          l 
         
        
       
         Xr - Xl 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.76em; vertical-align: -0.08em;"></span><span class="mord mathdefault" style="margin-right: 0.07em;">X</span><span class="mord mathdefault" style="margin-right: 0.02em;">r</span><span class="mspace" style="margin-right: 0.22em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.22em;"></span></span><span class="base"><span class="strut" style="height: 0.69em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07em;">X</span><span class="mord mathdefault" style="margin-right: 0.01em;">l</span></span></span></span></span>就是视差<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          d 
         
        
       
         d 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69em; vertical-align: 0em;"></span><span class="mord mathdefault">d</span></span></span></span></span>。通过公式 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          z 
         
        
          = 
         
         
          
          
            f 
           
          
            ∗ 
           
          
            T 
           
          
            x 
           
          
         
           d 
          
         
        
       
         z = \frac{f*Tx}{d} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.04em;">z</span><span class="mspace" style="margin-right: 0.27em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.27em;"></span></span><span class="base"><span class="strut" style="height: 1.27em; vertical-align: -0.34em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.93em;"><span style="top: -2.65em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.44em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.1em;">f</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.13em;">T</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.34em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>可以很简单地得到以左视图为参考系的深度图了。</li></ol> 
<h3><a id="NCC_23"></a>三、NCC算法实验</h3> 
<h4><a id="31_24"></a>3.1实验要求</h4> 
<ol><li>从理论角度，分析以窗口代价计算视差的原理</li><li>实现NCC 视差匹配方法，即给定左右两张视图，根据NCC计算视差图</li><li>分析不同窗口值对匹配结果的影响，重点考查那些点（或者哪些类型的点）在不同窗口大小下的匹配精度影响</li></ol> 
<h4><a id="32_28"></a>3.2实验准备</h4> 
<ol><li>实验平台：Python 3</li><li>实验数据：这些图像来自于参考文献，可以从 http://vision.middlebury.edu/stereo/data/ 下载。这里我们使用 “tsukuba”和“cones”图像，在标准版本中设置 wid 为 9，高斯版本中设置 wid 为 3。</li></ol> 
<h4><a id="33_31"></a>3.3实验代码</h4> 
<pre><code class="prism language-bash"><span class="token function">import</span> stereo
<span class="token function">import</span> scipy.misc
from PIL <span class="token function">import</span> Image
from pylab <span class="token function">import</span> *
from scipy.ndimage <span class="token function">import</span> *



def plane_sweep_ncc<span class="token punctuation">(</span>im_l,im_r,start,steps,wid<span class="token punctuation">)</span>:
<span class="token comment">#使用归一化的互相关计算视差图像 """</span>
 m,n <span class="token operator">=</span> im_l.shape
 <span class="token comment"># 保存不同求和值的数组</span>
 mean_l <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 mean_r <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s_l <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s_r <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 <span class="token comment"># 保存深度平面的数组</span>
 dmaps <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">,</span>steps<span class="token punctuation">))</span></span>
 <span class="token comment"># 计算图像块的平均值</span>
 filters.uniform_filter<span class="token punctuation">(</span>im_l,wid,mean_l<span class="token punctuation">)</span>
 filters.uniform_filter<span class="token punctuation">(</span>im_r,wid,mean_r<span class="token punctuation">)</span>
 <span class="token comment"># 归一化图像</span>
 norm_l <span class="token operator">=</span> im_l - mean_l
 norm_r <span class="token operator">=</span> im_r - mean_r
 <span class="token comment"># 尝试不同的视差</span>
 <span class="token keyword">for</span> displ <span class="token keyword">in</span> range<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>:
 <span class="token comment"># 将左边图像移动到右边，计算加和</span>
  filters.uniform_filter<span class="token punctuation">(</span>roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>*norm_r,wid,s<span class="token punctuation">)</span> <span class="token comment"># 和归一化</span>
  filters.uniform_filter<span class="token punctuation">(</span>roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>*roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>,wid,s_l<span class="token punctuation">)</span>
  filters.uniform_filter<span class="token punctuation">(</span>norm_r*norm_r,wid,s_r<span class="token punctuation">)</span> <span class="token comment"># 和反归一化</span>
 <span class="token comment"># 保存 ncc 的分数</span>
  dmaps<span class="token punctuation">[</span>:,:,displ<span class="token punctuation">]</span> <span class="token operator">=</span> s/sqrt<span class="token punctuation">(</span>s_l*s_r<span class="token punctuation">)</span>
 <span class="token comment"># 为每个像素选取最佳深度</span>
 <span class="token keyword">return</span> argmax<span class="token punctuation">(</span>dmaps,axis<span class="token operator">=</span>2<span class="token punctuation">)</span>


def plane_sweep_gauss<span class="token punctuation">(</span>im_l,im_r,start,steps,wid<span class="token punctuation">)</span>:
 <span class="token comment">#使用带有高斯加权周边的归一化互相关计算视差图像 """</span>
 m,n <span class="token operator">=</span> im_l.shape
 <span class="token comment"># 保存不同加和的数组</span>
 mean_l <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 mean_r <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s_l <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 s_r <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">))</span></span>
 <span class="token comment"># 保存深度平面的数组</span>
 dmaps <span class="token operator">=</span> zeros<span class="token variable"><span class="token punctuation">((</span>m<span class="token punctuation">,</span>n<span class="token punctuation">,</span>steps<span class="token punctuation">))</span></span>
 <span class="token comment"># 计算平均值</span>
 filters.gaussian_filter<span class="token punctuation">(</span>im_l,wid,0,mean_l<span class="token punctuation">)</span>
 filters.gaussian_filter<span class="token punctuation">(</span>im_r,wid,0,mean_r<span class="token punctuation">)</span>
 <span class="token comment"># 归一化图像</span>
 norm_l <span class="token operator">=</span> im_l - mean_l
 norm_r <span class="token operator">=</span> im_r - mean_r
 <span class="token comment"># 尝试不同的视差</span>
 <span class="token keyword">for</span> displ <span class="token keyword">in</span> range<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>:
 <span class="token comment"># 将左边图像移动到右边，计算加和</span>
  filters.gaussian_filter<span class="token punctuation">(</span>roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>*norm_r,wid,0,s<span class="token punctuation">)</span> <span class="token comment"># 和归一化</span>
 
  filters.gaussian_filter<span class="token punctuation">(</span>roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>*roll<span class="token punctuation">(</span>norm_l,-displ-start<span class="token punctuation">)</span>,wid,0,s_l<span class="token punctuation">)</span>
  filters.gaussian_filter<span class="token punctuation">(</span>norm_r*norm_r,wid,0,s_r<span class="token punctuation">)</span> <span class="token comment"># 和反归一化</span>
 <span class="token comment"># 保存 ncc 的分数</span>
 dmaps<span class="token punctuation">[</span>:,:,displ<span class="token punctuation">]</span> <span class="token operator">=</span> s/sqrt<span class="token punctuation">(</span>s_l*s_r<span class="token punctuation">)</span>
 <span class="token comment"># 为每个像素选取最佳深度</span>
 <span class="token keyword">return</span> argmax<span class="token punctuation">(</span>dmaps,axis<span class="token operator">=</span>2<span class="token punctuation">)</span>


im_l <span class="token operator">=</span> array<span class="token punctuation">(</span>Image.open<span class="token punctuation">(</span><span class="token string">'G:/QQdata/tsukuba/scene1.row3.col1.ppm'</span><span class="token punctuation">)</span>.convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span>,<span class="token string">'f'</span><span class="token punctuation">)</span>
im_r <span class="token operator">=</span> array<span class="token punctuation">(</span>Image.open<span class="token punctuation">(</span><span class="token string">'G:/QQdata/tsukuba/scene1.row3.col5.ppm'</span><span class="token punctuation">)</span>.convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span>,<span class="token string">'f'</span><span class="token punctuation">)</span>
<span class="token comment"># 开始偏移，并设置步长</span>
steps <span class="token operator">=</span> 50
start <span class="token operator">=</span> 4 

<span class="token comment"># ncc 的宽度</span>
wid <span class="token operator">=</span> 12

res <span class="token operator">=</span> stereo.plane_sweep_ncc<span class="token punctuation">(</span>im_l,im_r,start,steps,wid<span class="token punctuation">)</span>

imsave<span class="token punctuation">(</span><span class="token string">'depth.png'</span>,res<span class="token punctuation">)</span></code></pre> 
<h4><a id="34_115"></a>3.4实验结果及分析</h4> 
<p>1）不同图像的匹配结果</p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/8d/b1/EKsIYpzU_o.jpg"><br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/be/d6/4k4jCVB6_o.jpg"></p> 
<blockquote> 
 <p>小结：比较两幅细节特征不同的图像的匹配结果图可以看出：<br> 1.两幅图像中的物体远近距离关系都有通过颜色亮度变换表现出来，越高亮的区域则表示物体离摄像点更近，越暗沉的区域则表示物体离摄像点更远<br> 2.在第一张图像中，雕塑的面部特征没有清晰的变现出来，这或许是因为雕塑的面部特征比如耳朵、眼睛、嘴巴等等是趋近平面的，左右视差不明显导致<br> 3.在第二张图像中，台灯的匹配展示特别复杂紊乱，这是因为台灯表面因为光线明亮变化区域较大，导致特征匹配时左右视图的匹配点对应了多个错误匹配</p> 
</blockquote> 
<p>2）不同窗口值的匹配结果<br> 左右原图像：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/8d/c6/qNYE7RQb_o.png"><br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/e8/d3/dmBr6stY_o.png"></p> 
<p>不同ncc 的宽度结果图像：<br> wid = 3<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/4d/28/IpHXz6pR_o.jpg"><br> wid = 5<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/b6/27/Y6dmnYmX_o.jpg"><br> wid = 7<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/4a/dc/CRzPIXm2_o.jpg"><br> wid = 9<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/9a/3d/g7EUJ4YN_o.jpg"><br> wid = 12<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/70/39/cdPLaO91_o.jpg"></p> 
<blockquote> 
 <p>小结：通过比对几组不同的窗口值可以看出：<br> 1.当wid值很小，如wid=3时，图像的匹配结果变得特别模糊、尖锐，像红框中表现出来的，线条变得很生硬，无法识别出物体特征，这是因为wid值过小，窗口变成3*3的大小，这样使得匹配点不够精准，在极线上有太多相似点匹配，造成了误差。<br> 2.当wid=5，7时，如图像中红框表示的，图像中物体的边缘变得逐渐清晰，不会有太多类似噪声点的情况，同时，在蓝框中表示的台灯特征变得越加清晰，这是因为窗口变得更加大，所包含的数据更多，使得匹配点更加精准，图像更加平滑<br> 3.当wid值很大，如wid=12时，结果图像开始丢失一些边缘信息，如红框和蓝框标识所示，图像中人物雕塑的边缘变得过于平滑，缺少棱角，这是因为窗口变得太大，相邻的两个匹配点的窗口中的值容易出现重叠，也就是有一些同样的像素点被包含进特征匹配算法中，冲淡了匹配点的数值，导致掩盖掉了一些细节信息</p> 
</blockquote> 
<h3><a id="_148"></a>四、实验总结</h3> 
<p>1.NCC视差匹配方法，能够有效的标示出图像中物体的远近位置关系，但是其受到很多方面因素的约束，例如在拍摄图像时，明亮光线、角度变换等等物理因素容易导致拍摄的物体反光强弱不同，这对特征匹配结果有着较大的影响，以及在图像中的物体是透明，或者角度变换、遮挡等因素时，NCC算法容易受到干扰。<br> 2.不同的窗口值会直接影响匹配结果，过大容易丢失细节信息、过小容易无法识别出物体特征，产生无用的噪声点，匹配代价区分度过低，在低纹理区域容易出现误匹配，匹配精度较低，在实验中发现，wid = 9是比较适合的窗口值。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/62ae2286aa22da2c12109783916febbf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">NC57 登录报错--该账套已过期！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/62cf83ab93f96f6070a26507987d782a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2020“远光杯”网络资格赛L 捕鱼达人（树状数组/区间最大值/单点更新）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>