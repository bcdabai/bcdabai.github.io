<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大众点评文字反爬 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大众点评文字反爬" />
<meta property="og:description" content="【注】1、2022年4月10日抓取的大众点评的评论数据
2、该网站采用了字体反爬，是抓取过程中的主要难点
3、网站反爬更新的速度很快，基本上几个礼拜，一个月就会更新一次，所以本文的代码直接copy的话，可能会执行不了。但是大概思路是没问题的
1、分析网站 经过分析，发现网站的评论 被加密了。而且他不是全部加密他是有几个字进行了加密，有几个字又没有进行加密，这无疑是增加了我们爬取的工作量，但是，第一步应该还是先进行解密，即找到对应的css字体加密文件（.woff文件）
2、如何打开我们下载的woff 字体文件 这里打开方式有两种：一种下载 FontCreator 软件。第二种使用在线字体编辑器。这里两种方式都提供给大家，供大家参考使用.
FontCreator
链接：点击下载
提取码：dzd4
在线字体编辑器
链接：点击使用
3、处理下载的 woff 文件 处理woff文件，使用 fontTools 的模块去进行解析，但是需要注意几个点：
1、 woff_str_601 : 里面的文字来源于下载的woff文件，这里需要手动输入不过这里面的字体好像一直都没有变化过，理论上直接copy即可。但是时间久的话，楼主也不太确定了。
2、注意两个方法的区别： getBestCmap() 与 getGlyphOrder() getBestCmap() # 获取code和name的关系
getGlyphOrder() # 形状和字体的关系
【注】 为什么要提一个这个，因为之前用的值 getBestCmap() 转成的 十与十六进制的形式，方便与加密的字符进行匹配，最后发现其实不对，匹对的数据有误！！最后改用 getGlyphOrder() 用最原始的unicode 代码来进行匹配，可以见 下面的 步骤 第六步 最后说明一下，这里需要自己尝试，一开始谁也不能确定一定就行，所以还是需要多实践，尝试，从错误中寻找答案。
代码如下：
from fontTools.ttLib import TTFont def woff_dict(key): woff = TTFont(r&#39;./字体文件/2850eeb5.woff&#39;) # 读取woff文件 # woff文件中ID编号为2~602的601个字符 woff_str_601 = &#39;1234567890店中美家馆小车大市公酒行国品发电金心业商司超生装园场食有新限天面工服海华水房饰城乐汽香部利子老艺花专东肉菜学福饭人百餐茶务通味所山区门药银农龙停尚安广鑫一容动南具源兴鲜记时机烤文康信果阳理锅宝达地儿衣特产西批坊州牛佳化五米修爱北养卖建材三会鸡室红站德王光名丽油院堂烧江社合星货型村自科快便日民营和活童明器烟育宾精屋经居庄石顺林尔县手厅销用好客火雅盛体旅之鞋辣作粉包楼校鱼平彩上吧保永万物教吃设医正造丰健点汤网庆技斯洗料配汇木缘加麻联卫川泰色世方寓风幼羊烫来高厂兰阿贝皮全女拉成云维贸道术运都口博河瑞宏京际路祥青镇厨培力惠连马鸿钢训影甲助窗布富牌头四多妆吉苑沙恒隆春干饼氏里二管诚制售嘉长轩杂副清计黄讯太鸭号街交与叉附近层旁对巷栋环省桥湖段乡厦府铺内侧元购前幢滨处向座下臬凤港开关景泉塘放昌线湾政步宁解白田町溪十八古双胜本单同九迎第台玉锦底后七斜期武岭松角纪朝峰六振珠局岗洲横边济井办汉代临弄团外塔杨铁浦字年岛陵原梅进荣友虹央桂沿事津凯莲丁秀柳集紫旗张谷的是不了很还个也这我就在以可到错没去过感次要比觉看得说常真们但最喜哈么别位能较境非为欢然他挺着价那意种想出员两推做排实分间甜度起满给热完格荐喝等其再几只现朋候样直而买于般豆量选奶打每评少算又因情找些份置适什蛋师气你姐棒试总定啊足级整带虾如态且尝主话强当更板知己无酸让入啦式笑赞片酱差像提队走嫩才刚午接重串回晚微周值费性桌拍跟块调糕&#39; # [&#39;cmap&#39;]为字符与Unicode编码的映射关系列表 woff_unicode = woff[&#39;cmap&#39;]." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/99ffa980db9b90397bf1037f5bf96837/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-10T11:31:03+08:00" />
<meta property="article:modified_time" content="2022-04-10T11:31:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大众点评文字反爬</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>【注】1、2022年4月10日抓取的大众点评的评论数据<br> 2、该网站采用了字体反爬，是抓取过程中的主要难点<br> 3、网站反爬更新的速度很快，基本上几个礼拜，一个月就会更新一次，所以本文的代码直接copy的话，可能会执行不了。但是大概思路是没问题的</p> 
<h4><a id="1_5"></a>1、分析网站</h4> 
<p>经过分析，发现网站的评论 被加密了。而且他不是全部加密他是有几个字进行了加密，有几个字又没有进行加密，这无疑是增加了我们爬取的工作量，但是，第一步应该还是先进行解密，即找到对应的css字体加密文件（.woff文件）<br> <img src="https://images2.imgbox.com/02/57/2CbMmPmi_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/5e/76/17NlQdQt_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/88/85/MYfnpuTp_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/af/b9/RGS98jkV_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2woff__14"></a>2、如何打开我们下载的woff 字体文件</h4> 
<p>这里打开方式有两种：一种下载 <code>FontCreator</code> 软件。第二种使用<code>在线字体编辑器</code>。这里两种方式都提供给大家，供大家参考使用.</p> 
<p><code>FontCreator</code><br> 链接：<a href="https://pan.baidu.com/s/1MWXO51mGFl59eM3N4ljjzQ" rel="nofollow">点击下载</a><br> 提取码：dzd4<br> <code>在线字体编辑器</code><br> 链接：<a href="http://font.qqe2.com/index-en.html" rel="nofollow">点击使用</a></p> 
<p><img src="https://images2.imgbox.com/57/9a/4RIRpoNn_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3_woff__24"></a>3、处理下载的 woff 文件</h4> 
<p>处理woff文件，使用 <code>fontTools</code> 的模块去进行解析，但是需要注意几个点：<br> 1、 <code>woff_str_601 : 里面的文字来源于下载的woff文件，这里需要手动输入</code>不过这里面的字体好像一直都没有变化过，理论上直接copy即可。但是时间久的话，楼主也不太确定了。<br> 2、注意两个方法的区别： <code>getBestCmap() </code> 与 <code>getGlyphOrder() </code><br> <code>getBestCmap() </code> # 获取code和name的关系<br> <code>getGlyphOrder() </code> # 形状和字体的关系<br> 【注】 为什么要提一个这个，因为之前用的值 <strong>getBestCmap()</strong> 转成的 十与十六进制的形式，方便与加密的字符进行匹配，最后发现其实不对，匹对的数据有误！！最后改用 <strong>getGlyphOrder()</strong> 用最原始的unicode 代码来进行匹配，可以见 下面的 步骤 <code>第六步 </code></p> 
<p><code>最后说明一下，这里需要自己尝试，一开始谁也不能确定一定就行，所以还是需要多实践，尝试，从错误中寻找答案。</code><br> 代码如下：</p> 
<pre><code class="prism language-python">
<span class="token keyword">from</span> fontTools<span class="token punctuation">.</span>ttLib <span class="token keyword">import</span> TTFont

<span class="token keyword">def</span> <span class="token function">woff_dict</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">:</span>
        woff <span class="token operator">=</span> TTFont<span class="token punctuation">(</span><span class="token string">r'./字体文件/2850eeb5.woff'</span><span class="token punctuation">)</span> <span class="token comment"># 读取woff文件</span>
        <span class="token comment"># woff文件中ID编号为2~602的601个字符</span>
        woff_str_601 <span class="token operator">=</span> <span class="token string">'1234567890店中美家馆小车大市公酒行国品发电金心业商司超生装园场食有新限天面工服海华水房饰城乐汽香部利子老艺花专东肉菜学福饭人百餐茶务通味所山区门药银农龙停尚安广鑫一容动南具源兴鲜记时机烤文康信果阳理锅宝达地儿衣特产西批坊州牛佳化五米修爱北养卖建材三会鸡室红站德王光名丽油院堂烧江社合星货型村自科快便日民营和活童明器烟育宾精屋经居庄石顺林尔县手厅销用好客火雅盛体旅之鞋辣作粉包楼校鱼平彩上吧保永万物教吃设医正造丰健点汤网庆技斯洗料配汇木缘加麻联卫川泰色世方寓风幼羊烫来高厂兰阿贝皮全女拉成云维贸道术运都口博河瑞宏京际路祥青镇厨培力惠连马鸿钢训影甲助窗布富牌头四多妆吉苑沙恒隆春干饼氏里二管诚制售嘉长轩杂副清计黄讯太鸭号街交与叉附近层旁对巷栋环省桥湖段乡厦府铺内侧元购前幢滨处向座下臬凤港开关景泉塘放昌线湾政步宁解白田町溪十八古双胜本单同九迎第台玉锦底后七斜期武岭松角纪朝峰六振珠局岗洲横边济井办汉代临弄团外塔杨铁浦字年岛陵原梅进荣友虹央桂沿事津凯莲丁秀柳集紫旗张谷的是不了很还个也这我就在以可到错没去过感次要比觉看得说常真们但最喜哈么别位能较境非为欢然他挺着价那意种想出员两推做排实分间甜度起满给热完格荐喝等其再几只现朋候样直而买于般豆量选奶打每评少算又因情找些份置适什蛋师气你姐棒试总定啊足级整带虾如态且尝主话强当更板知己无酸让入啦式笑赞片酱差像提队走嫩才刚午接重串回晚微周值费性桌拍跟块调糕'</span>
        <span class="token comment"># ['cmap']为字符与Unicode编码的映射关系列表</span>
        woff_unicode <span class="token operator">=</span> woff<span class="token punctuation">[</span><span class="token string">'cmap'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tables<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ttFont<span class="token punctuation">.</span>getGlyphOrder<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 获取603个字符对应的unicode编码</span>
        woff_character <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'.notdef'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>woff_str_601<span class="token punctuation">)</span> <span class="token comment"># 添加编号为0、1的两个特殊字符</span>
        woff_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>woff_unicode<span class="token punctuation">,</span> woff_character<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">#print(woff_dict)</span>
        <span class="token keyword">return</span>   woff_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
</code></pre> 
<p><code>最终字典数据如下：</code><br> <img src="https://images2.imgbox.com/7f/9d/IMXj0FGF_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4_54"></a>4、开始获取网页数据</h4> 
<p>经分析发现，该网站的评论数据并不是静态的，而是json数据，所以我们需要改变抓取策略。去响应一下json数据。<br> <img src="https://images2.imgbox.com/75/81/1htCLWIS_o.png" alt="在这里插入图片描述"></p> 
<p>爬取之后的数据显示：<br> copy了一下，方便大家观察。<br> <img src="https://images2.imgbox.com/ce/41/8n3zGVEt_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5_61"></a>5、处理从网页种获取的数据</h4> 
<p>经分析发现，我们需要的是 <code>&amp;#xef33 </code> 这种加密的字符，然后对其进行解析。所以我这里 直接使用replace 进行替换，（1、这里刚开始想的使用正则表达式，然后发现不太方便 如： <code>大董（环贸店）：淮海中路999号环贸isomer商&lt;svgmtsi class="review"&gt;&amp;#xe726;&lt;/svgmtsi&gt;6楼 </code> 像这种数据就不好处理，我们需要的是前面的 <code>汉字 </code>+ 后面的 <code>&amp;#xef33 </code>，实践得出失败。2、后面想到用 lxml 序列化 如 ：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span>  lxml <span class="token keyword">import</span> etree
html<span class="token operator">=</span>etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>all_comment<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># all_comment为抓取的评论数据</span>
content<span class="token operator">=</span>html<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//text()'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span>
</code></pre> 
<p>经测试发现结果较为理想，如下图所示：<br> <img src="https://images2.imgbox.com/e7/45/HmjDuzmy_o.png" alt="在这里插入图片描述"><br> 但是，当时提取字符的时候，会发现乱码[就不截图了，感兴趣的小伙伴可以自己尝试一下，然后告诉一下楼主有没有解决方案]，so,第二次尝试失败<br> ）<br> <code>正确处理：</code><br> 用replace 替换之后，在用split分割<img src="https://images2.imgbox.com/33/5e/geKXXM2P_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="6__76"></a>6 、查字典</h4> 
<p>到了这里，已经快接近胜利了，回顾一下，我们已经得到了 <code>woff的字典数据 </code>、<code>网页进行加密的字符数据 </code>，那么如何把他们进行对应呢。<br> 1、首先回顾一下： <code>第三步 </code><br> 2、找规律，为了看起来方便，我都写一起，省的看起来头疼。如下图：</p> 
<p><img src="https://images2.imgbox.com/ae/9c/1SlqD1wG_o.png" alt="在这里插入图片描述"></p> 
<p><code>到此，发现我们的爬取方式正确。接下来只要按照这种规律进行匹配即可</code></p> 
<h4><a id="7__84"></a>7 、完整代码</h4> 
<p><code>接下来就是大家心心念念的完整代码</code></p> 
<p><strong>把读取woff的模块封装成单独的 字典 模块</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 封装一个读取css字体的模块</span>
<span class="token keyword">from</span> fontTools<span class="token punctuation">.</span>ttLib <span class="token keyword">import</span> TTFont

<span class="token keyword">def</span> <span class="token function">woff_dict</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">:</span>
        woff <span class="token operator">=</span> TTFont<span class="token punctuation">(</span><span class="token string">r'./字体文件/2850eeb5.woff'</span><span class="token punctuation">)</span> <span class="token comment"># 读取woff文件</span>
        <span class="token comment"># woff文件中ID编号为2~602的601个字符</span>
        woff_str_601 <span class="token operator">=</span> <span class="token string">'1234567890店中美家馆小车大市公酒行国品发电金心业商司超生装园场食有新限天面工服海华水房饰城乐汽香部利子老艺花专东肉菜学福饭人百餐茶务通味所山区门药银农龙停尚安广鑫一容动南具源兴鲜记时机烤文康信果阳理锅宝达地儿衣特产西批坊州牛佳化五米修爱北养卖建材三会鸡室红站德王光名丽油院堂烧江社合星货型村自科快便日民营和活童明器烟育宾精屋经居庄石顺林尔县手厅销用好客火雅盛体旅之鞋辣作粉包楼校鱼平彩上吧保永万物教吃设医正造丰健点汤网庆技斯洗料配汇木缘加麻联卫川泰色世方寓风幼羊烫来高厂兰阿贝皮全女拉成云维贸道术运都口博河瑞宏京际路祥青镇厨培力惠连马鸿钢训影甲助窗布富牌头四多妆吉苑沙恒隆春干饼氏里二管诚制售嘉长轩杂副清计黄讯太鸭号街交与叉附近层旁对巷栋环省桥湖段乡厦府铺内侧元购前幢滨处向座下臬凤港开关景泉塘放昌线湾政步宁解白田町溪十八古双胜本单同九迎第台玉锦底后七斜期武岭松角纪朝峰六振珠局岗洲横边济井办汉代临弄团外塔杨铁浦字年岛陵原梅进荣友虹央桂沿事津凯莲丁秀柳集紫旗张谷的是不了很还个也这我就在以可到错没去过感次要比觉看得说常真们但最喜哈么别位能较境非为欢然他挺着价那意种想出员两推做排实分间甜度起满给热完格荐喝等其再几只现朋候样直而买于般豆量选奶打每评少算又因情找些份置适什蛋师气你姐棒试总定啊足级整带虾如态且尝主话强当更板知己无酸让入啦式笑赞片酱差像提队走嫩才刚午接重串回晚微周值费性桌拍跟块调糕'</span>
        <span class="token comment"># ['cmap']为字符与Unicode编码的映射关系列表</span>
        woff_unicode <span class="token operator">=</span> woff<span class="token punctuation">[</span><span class="token string">'cmap'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tables<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ttFont<span class="token punctuation">.</span>getGlyphOrder<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 获取603个字符对应的unicode编码</span>
        woff_character <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'.notdef'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>woff_str_601<span class="token punctuation">)</span> <span class="token comment"># 添加编号为0、1的两个特殊字符</span>
        woff_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>woff_unicode<span class="token punctuation">,</span> woff_character<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">#print(woff_dict)</span>
        <span class="token keyword">return</span>   woff_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
</code></pre> 
<p><strong>主代码模块</strong></p> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> requests
<span class="token keyword">import</span>  json
<span class="token keyword">import</span>  pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> font


headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"Accept"</span><span class="token punctuation">:</span> <span class="token string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span class="token punctuation">,</span>
    <span class="token string">"Accept-Language"</span><span class="token punctuation">:</span> <span class="token string">"zh-CN,zh;q=0.9"</span><span class="token punctuation">,</span>
    <span class="token string">"Cache-Control"</span><span class="token punctuation">:</span> <span class="token string">"max-age=0"</span><span class="token punctuation">,</span>
    <span class="token string">"Connection"</span><span class="token punctuation">:</span> <span class="token string">"keep-alive"</span><span class="token punctuation">,</span>
    <span class="token string">"Upgrade-Insecure-Requests"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>
    <span class="token string">'Cookie'</span><span class="token punctuation">:</span><span class="token string">'fspop=test; cy=1; cye=shanghai; _lxsdk_cuid=18006e84946c8-0edfb5359bc9cf-1a343370-144000-18006e8494683; _lxsdk=18006e84946c8-0edfb5359bc9cf-1a343370-144000-18006e8494683; _hc.v=26a2d697-b910-5ca3-2811-7cb9de72b061.1649383329; s_ViewType=10; dplet=54a75cdaf24b303d3f910da18f7722de; dper=4a8592a6f6069c93adacd0d4efa1208e88ad3f679ac3884773372a379298967e9afc526b24332076b0f0409a6044bd2f677d3ff6943921a4f97c10ac407f85f59c4531048bb3ff331e87b08beac013239986b3821d73a2d7ad662074a343d534; ua=%E5%B0%8F%E7%99%BD%E8%8F%9C; ctu=43203cd8c3de60575d04dea3547e7bc86b19a461a533987b78fafea2df8f4bd5; ll=7fd06e815b796be3df069dec7836c3df; Hm_lvt_602b80cf8079ae6591966cc70a3940e7=1649383329,1649421529,1649469353; _lx_utm=utm_source%3DBaidu%26utm_medium%3Dorganic; Hm_lpvt_602b80cf8079ae6591966cc70a3940e7=1649469364; _lxsdk_s=1800c08ea8e-63d-fe7-70e%7C%7C57'</span><span class="token punctuation">,</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36"</span>
<span class="token punctuation">}</span>
url <span class="token operator">=</span> <span class="token string">"http://www.dianping.com/ajax/json/shopDynamic/allReview?shopId=Emnne5KsrYwPeJ4I&amp;cityId=1&amp;shopType=10&amp;tcv=0x0xrqr5le&amp;_token=eJxVj19vgjAUxb9LnxtooRQh8cG%2FiYBzo1Y0iw8MmSIWHe1EXPbdVzL3sOQm59zfvSe59wvUsx3wMUKIYAiueQ18gA1kUACBknpCiUeoRyxquy4E2X%2FmYs3e6tUY%2BK%2FYsSl0bbTtSKzBL%2BlRsoUPa1tbaBFd3c5Mr4CDUhffNJumMXZFWl2Kam9kZ2HKw%2FliTkRV5U4o603znAdkpk8COimWXdKhCLrI7UDZAa3pQ9VfP9fP6JAs9pV2eXBbMknkx3s8l8sVb1svZMxqowxHjNvRfaKeOLsu2lFvwOqjcD6Tk6jO6ylKkiGNqVgXoxuff4xwoMYvNi9Kdc9uiyi8IpbhRbwLNuXJK9PV8MCnQ56IPC3D%2FWRgDuQRN%2F0%2B%2BP4BbKFpyA%3D%3D&amp;uuid=26a2d697-b910-5ca3-2811-7cb9de72b061.1649383329&amp;platform=1&amp;partner=150&amp;optimusCode=10&amp;originUrl=http%3A%2F%2Fwww.dianping.com%2Fshop%2FEmnne5KsrYwPeJ4I"</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span><span class="token punctuation">.</span>text
data_json<span class="token operator">=</span>json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>response<span class="token punctuation">)</span>

all_user<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
all_comment<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> item <span class="token keyword">in</span> data_json<span class="token punctuation">[</span><span class="token string">'reviewAllDOList'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
     user<span class="token operator">=</span>item<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'userNickName'</span><span class="token punctuation">]</span>
     comment<span class="token operator">=</span>item<span class="token punctuation">[</span><span class="token string">'reviewDataVO'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'reviewData'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'reviewBody'</span><span class="token punctuation">]</span>
     all_user<span class="token punctuation">.</span>append<span class="token punctuation">(</span>user<span class="token punctuation">)</span>
     all_comment<span class="token punctuation">.</span>append<span class="token punctuation">(</span>comment<span class="token punctuation">)</span>
     
<span class="token comment">#print(all_comment)</span>
all_comData<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment"># 处理所有的评论</span>
<span class="token keyword">for</span>  strr <span class="token keyword">in</span> all_comment<span class="token punctuation">:</span>
    <span class="token comment"># 把获取到的字符串，去掉 标签</span>
    string<span class="token operator">=</span>strr<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'&lt;svgmtsi class="review"&gt;'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
    string2<span class="token operator">=</span>string<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">';&lt;/svgmtsi&gt;'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
    ingergrate_str<span class="token operator">=</span>string2<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'&amp;'</span><span class="token punctuation">)</span>

    intergrate<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># 判断有没有 加密的字符串,有就替换，没有就，正常输出</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> ingergrate_str<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            k<span class="token operator">=</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 截取第一个字符，判断是不是这种 【#xe2da聚】 的格式</span>
            <span class="token keyword">if</span> k <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'#'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token comment"># 拼凑关键字,在下载的css文件里面 查找</span>
                key<span class="token operator">=</span><span class="token string">'uni'</span><span class="token operator">+</span>item<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span>
                integrate_str<span class="token operator">=</span>font<span class="token punctuation">.</span>woff_dict<span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token operator">+</span>item<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 只替换 【#xe2da】  剩下的 【聚】  保留 》》结果展示：【的聚】</span>
                intergrate<span class="token punctuation">.</span>append<span class="token punctuation">(</span>integrate_str<span class="token punctuation">)</span>
                <span class="token comment">#print(item)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                intergrate<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            <span class="token comment"># 把单个评论的列表数据,整合成一条</span>
            data<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>intergrate<span class="token punctuation">)</span>
        <span class="token keyword">except</span> <span class="token punctuation">:</span> <span class="token keyword">continue</span>
    <span class="token comment"># 把for 循环的数据都 放在一个列表里面</span>
    all_comData<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment">#输出至excel中</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'用户名'</span><span class="token punctuation">:</span>all_user<span class="token punctuation">,</span><span class="token string">'评论'</span><span class="token punctuation">:</span>all_comData<span class="token punctuation">}</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>index<span class="token operator">+=</span><span class="token number">1</span>
data<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span><span class="token string">r'E:\pythonProject\spieder项目\da_comment\shuju\评论.xlsx'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_comData<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'完成'</span><span class="token punctuation">)</span>
</code></pre> 
<p>【总结】<br> 1、这里有个小插曲，加了一个try()…except()…模块，它的评论中带有一下 <strong>表情</strong>、<strong>特殊符号</strong> 然后我们在截取的时候，会报错，这时我们可以选择忽略，其实也并不影响我们评论的整体爬取。</p> 
<p>2、这里总结了整体的一个爬取流程，爬取的时候遇到了很多的坑，在这里也希望能帮到大家。然后，我在强调一下，这个网站的更新速度很快，遇到代码运行不了的情况也不要急，先把握整体思路，然后在逐个模块突破，解决，最后拿到我们所需要的数据。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/30f0674b85f780281556045f54e0792f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数据库学习记录——错题总结（一）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b24dce881625ca505419684a4b6bbd7d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PTA——7-3 我是升旗手</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>