<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Rotate to Attend 三分支结构捕获跨维度交互的注意力机制 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Rotate to Attend 三分支结构捕获跨维度交互的注意力机制" />
<meta property="og:description" content="Rotate to Attend: Convolutional Triplet Attention Module 论文的名字很好，反映了本文的核心想法：triplet attention，这是一种通过使用三分支结构捕获跨维度交互来计算注意力权重的新方法。对于输入张量，triplet attention通过旋转操作，然后使用残差变换建立维度间的依存关系，并以可忽略的计算开销对通道间和空间信息进行编码。 paper：https://arxiv.org/pdf/2010.03045.pdf
github：https://github.com/landskape-ai/triplet-attention/
前言 这次是复现WACV2021的一篇论文，本论文的注意力非常简单，而且是一个即插即用的小模块，接近于无参数可用于多种网络。
本文的主要创新点是提出了一个新的注意力机制，是一个Channel &amp; Spatial attention，在各CV任务测试性能如下
相关代码 具体的网络结构如上图所示：
1.第一个分支：通道C和空间W维度交互捕获分支，输入特征先经过permute，变为H X C X W维度特征，接着在H维度上进行Z-Pool，后面操作类似。最后需要经过permuter变为C X H X W维度特征，方便进行element-wise相加
2.第二个分支：通道C和空间H维度交互捕获分支，输入特征先经过permute，变为W X H X C维度特征，接着在W维度上进行Z-Pool，后面操作类似。最后需要经过permuter变为C X H X W维度特征，方便进行element-wise相加
3.第三个分支：通道注意力计算分支，输入特征经过Z-Pool，再接着7 x 7卷积，最后Sigmoid激活函数生成空间注意力权重
最后对3个分支输出特征进行相加求Avg
import paddle import paddle.nn as nn import cv2 class BasicConv(nn.Layer): def __init__( self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias_attr=False, ): super(BasicConv, self).__init__() self.out_channels = out_planes self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/d2ff17bc386fa24ece25f392c147de83/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-17T21:48:23+08:00" />
<meta property="article:modified_time" content="2021-12-17T21:48:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Rotate to Attend 三分支结构捕获跨维度交互的注意力机制</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Rotate_to_Attend_Convolutional_Triplet_Attention_Module_0"></a>Rotate to Attend: Convolutional Triplet Attention Module</h2> 
<ul><li><strong>论文的名字很好，反映了本文的核心想法：triplet attention，这是一种通过使用三分支结构捕获跨维度交互来计算注意力权重的新方法。对于输入张量，triplet attention通过旋转操作，然后使用残差变换建立维度间的依存关系，并以可忽略的计算开销对通道间和空间信息进行编码。</strong></li></ul> 
<p><img src="https://images2.imgbox.com/c2/a3/6IYmeo9b_o.png" alt=""></p> 
<p>paper：<a href="https://arxiv.org/pdf/2010.03045.pdf" rel="nofollow">https://arxiv.org/pdf/2010.03045.pdf</a></p> 
<p>github：<a href="https://github.com/landskape-ai/triplet-attention/">https://github.com/landskape-ai/triplet-attention/</a></p> 
<h3><a id="_15"></a>前言</h3> 
<ul><li> <p>这次是复现WACV2021的一篇论文，本论文的注意力非常简单，而且是一个即插即用的小模块，接近于无参数可用于多种网络。</p> </li><li> <p>本文的主要创新点是提出了一个新的注意力机制，是一个Channel &amp; Spatial attention，在各CV任务测试性能如下</p> </li></ul> 
<p><img src="https://images2.imgbox.com/11/1f/8FfIYW00_o.png" alt=""></p> 
<h3><a id="_24"></a>相关代码</h3> 
<p><img src="https://images2.imgbox.com/c1/dc/P72eOd23_o.png" alt=""></p> 
<p>具体的网络结构如上图所示：</p> 
<ul><li> <p>1.第一个分支：通道C和空间W维度交互捕获分支，输入特征先经过permute，变为H X C X W维度特征，接着在H维度上进行Z-Pool，后面操作类似。最后需要经过permuter变为C X H X W维度特征，方便进行element-wise相加</p> </li><li> <p>2.第二个分支：通道C和空间H维度交互捕获分支，输入特征先经过permute，变为W X H X C维度特征，接着在W维度上进行Z-Pool，后面操作类似。最后需要经过permuter变为C X H X W维度特征，方便进行element-wise相加</p> </li><li> <p>3.第三个分支：通道注意力计算分支，输入特征经过Z-Pool，再接着7 x 7卷积，最后Sigmoid激活函数生成空间注意力权重</p> </li></ul> 
<p>最后对3个分支输出特征进行相加求Avg</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> cv2

<span class="token keyword">class</span> <span class="token class-name">BasicConv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        in_planes<span class="token punctuation">,</span>
        out_planes<span class="token punctuation">,</span>
        kernel_size<span class="token punctuation">,</span>
        stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
        dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        relu<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        bn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> out_planes
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            in_planes<span class="token punctuation">,</span>
            out_planes<span class="token punctuation">,</span>
            kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>
            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
            padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>
            dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>
            groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
            bias_attr<span class="token operator">=</span>bias_attr<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn <span class="token operator">=</span> <span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>BatchNorm2D<span class="token punctuation">(</span>out_planes<span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> bn
            <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> relu <span class="token keyword">else</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>bn <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>relu <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


<span class="token keyword">class</span> <span class="token class-name">ZPool</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#print(x.shape)#[4, 16, 512, 16][512, 1, 16][4, 1, 512, 16]</span>

        <span class="token comment">#print(paddle.max(x, 1).unsqueeze(1).shape)</span>
        <span class="token comment">#print(paddle.mean(x, 1).unsqueeze(1).shape)</span>
        <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>
                            <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            paddle<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                            <span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">AttentionGate</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AttentionGate<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        kernel_size <span class="token operator">=</span> <span class="token number">7</span>
        self<span class="token punctuation">.</span>compress <span class="token operator">=</span> ZPool<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> BasicConv<span class="token punctuation">(</span>
            <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> relu<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_compress <span class="token operator">=</span> self<span class="token punctuation">.</span>compress<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x_out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x_compress<span class="token punctuation">)</span>
        scale <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x_out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x <span class="token operator">*</span> scale


<span class="token keyword">class</span> <span class="token class-name">TripletAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> no_spatial<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TripletAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cw <span class="token operator">=</span> AttentionGate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hc <span class="token operator">=</span> AttentionGate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>no_spatial <span class="token operator">=</span> no_spatial
        <span class="token keyword">if</span> <span class="token keyword">not</span> no_spatial<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>hw <span class="token operator">=</span> AttentionGate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_perm1 <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        x_out1 <span class="token operator">=</span> self<span class="token punctuation">.</span>cw<span class="token punctuation">(</span>x_perm1<span class="token punctuation">)</span>
        x_out11 <span class="token operator">=</span> x_out1<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        x_perm2 <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        x_out2 <span class="token operator">=</span> self<span class="token punctuation">.</span>hc<span class="token punctuation">(</span>x_perm2<span class="token punctuation">)</span>
        x_out21 <span class="token operator">=</span> x_out2<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>no_spatial<span class="token punctuation">:</span>
            x_out <span class="token operator">=</span> self<span class="token punctuation">.</span>hw<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x_out <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x_out <span class="token operator">+</span> x_out11 <span class="token operator">+</span> x_out21<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            x_out <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x_out11 <span class="token operator">+</span> x_out21<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x_out


</code></pre> 
<pre><code>[1, 512, 16, 16]
</code></pre> 
<h4><a id="_145"></a>验证</h4> 
<p><code>input size = 64,512,16,16 --&gt; TA --&gt; output size = 64,512,16,16</code></p> 
<pre><code class="prism language-python"><span class="token keyword">if</span> __name__<span class="token operator">==</span><span class="token string">"__main__"</span><span class="token punctuation">:</span>
    a <span class="token operator">=</span> paddle<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> TripletAttention<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
    a <span class="token operator">=</span> model<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="TA_157"></a>对TA性能进行验证</h3> 
<p>论文中，作者在Resnet34测试，但是对于ResNet18深层网络作者没有做相关实验，我们这次搭建一个ResNet18网络来验证性能，TA模块插入位置如下。</p> 
<p><img src="https://images2.imgbox.com/b6/06/xtAj1VjD_o.png" alt=""></p> 
<h4><a id="TA_ResNet18__165"></a>TA_ResNet18 搭建</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>download <span class="token keyword">import</span> get_weights_path_from_url

<span class="token keyword">class</span> <span class="token class-name">BasicBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    expansion <span class="token operator">=</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 inplanes<span class="token punctuation">,</span>
                 planes<span class="token punctuation">,</span>
                 stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 base_width<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                 dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 norm_layer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BasicBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> norm_layer <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            norm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2D

        <span class="token keyword">if</span> dilation <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span>
                <span class="token string">"Dilation &gt; 1 not supported in BasicBlock"</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            inplanes<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>planes<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>planes<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>planes<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out


<span class="token keyword">class</span> <span class="token class-name">BottleneckBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>

    expansion <span class="token operator">=</span> <span class="token number">4</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 inplanes<span class="token punctuation">,</span>
                 planes<span class="token punctuation">,</span>
                 stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 downsample<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 base_width<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                 dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                 norm_layer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BottleneckBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> norm_layer <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            norm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2D
        width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>planes <span class="token operator">*</span> <span class="token punctuation">(</span>base_width <span class="token operator">/</span> <span class="token number">64</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> groups

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>inplanes<span class="token punctuation">,</span> width<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>width<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            width<span class="token punctuation">,</span>
            width<span class="token punctuation">,</span>
            <span class="token number">3</span><span class="token punctuation">,</span>
            padding<span class="token operator">=</span>dilation<span class="token punctuation">,</span>
            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
            groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>
            dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>
            bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>width<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            width<span class="token punctuation">,</span> planes <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn3 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>planes <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>downsample <span class="token operator">=</span> downsample
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> TripletAttention<span class="token punctuation">(</span>planes <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>



    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>downsample <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            identity <span class="token operator">=</span> self<span class="token punctuation">.</span>downsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        out <span class="token operator">+=</span> identity
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out


<span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 block<span class="token punctuation">,</span>
                 depth<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
                 width<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                 num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
                 with_pool<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        layer_cfg <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token number">18</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token number">34</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token number">50</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token number">101</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token number">152</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
        layers <span class="token operator">=</span> layer_cfg<span class="token punctuation">[</span>depth<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>groups <span class="token operator">=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>base_width <span class="token operator">=</span> width
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        self<span class="token punctuation">.</span>with_pool <span class="token operator">=</span> with_pool
        self<span class="token punctuation">.</span>_norm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2D

        self<span class="token punctuation">.</span>inplanes <span class="token operator">=</span> <span class="token number">64</span>
        self<span class="token punctuation">.</span>dilation <span class="token operator">=</span> <span class="token number">1</span>

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            <span class="token number">3</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span>
            kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>
            stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_norm_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inplanes<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> with_pool<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> num_classes <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> blocks<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilate<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        norm_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>_norm_layer
        downsample <span class="token operator">=</span> <span class="token boolean">None</span>
        previous_dilation <span class="token operator">=</span> self<span class="token punctuation">.</span>dilation
        <span class="token keyword">if</span> dilate<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dilation <span class="token operator">*=</span> stride
            stride <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>inplanes <span class="token operator">!=</span> planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>
            downsample <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span>
                    planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span>
                    <span class="token number">1</span><span class="token punctuation">,</span>
                    stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>
                    bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                norm_layer<span class="token punctuation">(</span>planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>

        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> downsample<span class="token punctuation">,</span> self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                  self<span class="token punctuation">.</span>base_width<span class="token punctuation">,</span> previous_dilation<span class="token punctuation">,</span> norm_layer<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inplanes <span class="token operator">=</span> planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                block<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span>
                    planes<span class="token punctuation">,</span>
                    groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>
                    base_width<span class="token operator">=</span>self<span class="token punctuation">.</span>base_width<span class="token punctuation">,</span>
                    norm_layer<span class="token operator">=</span>norm_layer<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_pool<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_classes <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> paddle<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x


<span class="token keyword">def</span> <span class="token function">_resnet</span><span class="token punctuation">(</span>arch<span class="token punctuation">,</span> Block<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ResNet<span class="token punctuation">(</span>Block<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token keyword">if</span> pretrained<span class="token punctuation">:</span>
        <span class="token keyword">assert</span> arch <span class="token keyword">in</span> model_urls<span class="token punctuation">,</span> <span class="token string">"{} model do not have a pretrained model now, you should set pretrained=False"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            arch<span class="token punctuation">)</span>
        weight_path <span class="token operator">=</span> get_weights_path_from_url<span class="token punctuation">(</span>model_urls<span class="token punctuation">[</span>arch<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                model_urls<span class="token punctuation">[</span>arch<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        param <span class="token operator">=</span> paddle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>weight_path<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>set_dict<span class="token punctuation">(</span>param<span class="token punctuation">)</span>

    <span class="token keyword">return</span> model


<span class="token keyword">def</span> <span class="token function">resnet18</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'resnet18'</span><span class="token punctuation">,</span> BasicBlock<span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet34</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'resnet34'</span><span class="token punctuation">,</span> BasicBlock<span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet50</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'resnet50'</span><span class="token punctuation">,</span> BottleneckBlock<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet101</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'resnet101'</span><span class="token punctuation">,</span> BottleneckBlock<span class="token punctuation">,</span> <span class="token number">101</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">resnet152</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'resnet152'</span><span class="token punctuation">,</span> BottleneckBlock<span class="token punctuation">,</span> <span class="token number">152</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">wide_resnet50_2</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    kwargs<span class="token punctuation">[</span><span class="token string">'width'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'wide_resnet50_2'</span><span class="token punctuation">,</span> BottleneckBlock<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">wide_resnet101_2</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    kwargs<span class="token punctuation">[</span><span class="token string">'width'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token keyword">return</span> _resnet<span class="token punctuation">(</span><span class="token string">'wide_resnet101_2'</span><span class="token punctuation">,</span> BottleneckBlock<span class="token punctuation">,</span> <span class="token number">101</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span>
                   <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">Ta_res50 <span class="token operator">=</span> resnet50<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
paddle<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>Ta_res50<span class="token punctuation">)</span><span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="Cifar10_443"></a>Cifar10数据准备</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Cifar10
paddle<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span><span class="token string">'gpu'</span><span class="token punctuation">)</span>

<span class="token comment"># 数据准备</span>
transform <span class="token operator">=</span> T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    T<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    T<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data_format<span class="token operator">=</span><span class="token string">'HWC'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> Cifar10<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="ResNet18Cifar10_462"></a>ResNet18在Cifar10训练</h4> 
<pre><code class="prism language-python"><span class="token comment"># 模型准备</span>
res50 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
res50<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># 训练准备</span>
epoch_num <span class="token operator">=</span> <span class="token number">10</span>
optim <span class="token operator">=</span> paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>parameters<span class="token operator">=</span>res50<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

res50_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
res50_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            
        labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            
        predicts <span class="token operator">=</span> res50<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    

        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> paddle<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch: {}, batch_id: {}, loss is: {}, acc is: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> batch_id<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>

            res50_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            res50_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>clear_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="TA_ResNet18Cifar10_501"></a>TA_ResNet18在Cifar10数据集训练</h4> 
<pre><code class="prism language-python"><span class="token comment"># 模型准备</span>
ta_res50 <span class="token operator">=</span> resnet18<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
ta_res50<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练准备</span>
epoch_num <span class="token operator">=</span> <span class="token number">10</span>
optim <span class="token operator">=</span> paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>parameters<span class="token operator">=</span>ta_res50<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

ta_res50_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
ta_res50_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            
        labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            
        predicts <span class="token operator">=</span> ta_res50<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    

        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> paddle<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch: {}, batch_id: {}, loss is: {}, acc is: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> batch_id<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
        <span class="token keyword">if</span> batch_id <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            ta_res50_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            ta_res50_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>clear_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_ResNet18__TA_ResNet18__538"></a>绘制 ResNet18 和 TA_ResNet18 训练曲线</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'iter'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'train loss'</span><span class="token punctuation">)</span>

x<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ta_res50_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>res50_loss<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'ResNet18'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>ta_res50_loss<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'ResNet18 + TA'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'iter'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'train acc'</span><span class="token punctuation">)</span>

x<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ta_res50_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res50_acc<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'ResNet18'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> ta_res50_acc<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'ResNet18 + CA'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>模型训练总结：通过曲线可以看到加入了TA注意力机制之后模型收敛的速度会提高，识别的精准度也会提高，说明TA注意力的有效性。</li></ul> 
<p><img src="https://images2.imgbox.com/07/37/oyByAn3o_o.png" alt=""><br> <img src="https://images2.imgbox.com/c7/f8/iJ5Z3zR3_o.png" alt=""></p> 
<h3><a id="_580"></a>总结</h3> 
<p><img src="https://images2.imgbox.com/da/d5/3iel94XL_o.png" alt=""></p> 
<ul><li> <p>作者观察到CBAM中的通道注意力方法虽然提供了显着的性能改进，却不是因为跨通道交互。</p> </li><li> <p>因此作者提出了可以有效解决跨维度交互的triplet attention。相较于以往的注意力方法，主要有两个优点：</p> </li><li> <p>1.可以忽略的计算开销</p> </li><li> <p>2.强调了多维交互而不降低维度的重要性，因此消除了通道和权重之间的间接对应。</p> </li></ul> 
<blockquote> 
 <p>特别感谢：仰世而来丶(本文参考了<a href="http://" rel="nofollow">https://aistudio.baidu.com/aistudio/projectdetail/1884947?channelType=0&amp;channel=0</a>)</p> 
</blockquote> 
<p>请点击<a href="https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576" rel="nofollow">此处</a>查看本环境基本用法. <br><br> Please click <a href="https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576" rel="nofollow">here </a> for more detailed instructions.</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/712ca02eadb4a8e6daccd8d6f775fe9b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">软考电子证书打印时间及有关问题解答</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/30136395f01879792198317c11831ea4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Kubernetes</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>