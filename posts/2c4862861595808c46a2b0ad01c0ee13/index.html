<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DJL Java环境下部署pytorch模型推理 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="DJL Java环境下部署pytorch模型推理" />
<meta property="og:description" content="由于大数据基本都是Java环境，希望与深度学习结合的话，需要将深度学习模型部署在Java环境下。传统方式使用flask搭建接口，在Java环境中对其调用，但通信时间和内存问题限制了这种方式的发展。
DJL是采用Java编写的深度学习框架，支持MXnet，Tensorflow，Pytorch引擎，这意味着同一个模型采用不同语言编写，在DJL框架中运行只需要更改依赖，代码完全一样即可执行。关于DJL更多的介绍大家可以浏览DJL官网，知乎，以及b站的课程。
知乎专栏：DJL深度学习库 - 知乎
b站课程录播：深度学习兽的个人空间_哔哩哔哩_Bilibili GitHub：DeepJavaLibrary · GitHub 下面介绍部署pytorch模型步骤以及我个人遇到的一些坑，希望对大家有所帮助
首先是pom文件依赖
import torch print(torch.__version__) 首先使用该命令查看本地环境下的pytorch版本，根据本地的pytorch版本，选取合适的engine
PyTorch Engine - Deep Java Library
这是DJL官网的例子，也包含Linux和maxOS下的依赖配置，我的pytorch版本是1.9.0，给出我的pom文件做参考
&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;ai.djl&lt;/groupId&gt; &lt;artifactId&gt;api&lt;/artifactId&gt; &lt;version&gt;0.18.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt; &lt;artifactId&gt;pytorch-engine&lt;/artifactId&gt; &lt;version&gt;0.18.0&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt; &lt;artifactId&gt;pytorch-native-auto&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt; &lt;artifactId&gt;pytorch-native-cpu&lt;/artifactId&gt; &lt;classifier&gt;win-x86_64&lt;/classifier&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;1.11.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt; &lt;artifactId&gt;pytorch-jni&lt;/artifactId&gt; &lt;version&gt;1.11.0-0.18.0&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 对于加载自己的本地模型，踩到的两个坑，第一个就是如果该模型是用GPU训练的，那么之后推理也需要使用GPU，如果想用CPU推理，那就需要用CPU训练网络（这一条我不确定是否正确，只是我这样修改后确实没有报错了）第二个坑就是在python中保存模型时，要使用下面的代码
net.eval() input = np.random.uniform(0, 1, (1,1, 2048, 1)) input = input.astype(np.float32) input = torch.from_numpy(input) script = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/2c4862861595808c46a2b0ad01c0ee13/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-27T20:27:06+08:00" />
<meta property="article:modified_time" content="2022-07-27T20:27:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DJL Java环境下部署pytorch模型推理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>由于大数据基本都是Java环境，希望与深度学习结合的话，需要将深度学习模型部署在Java环境下。传统方式使用flask搭建接口，在Java环境中对其调用，但通信时间和内存问题限制了这种方式的发展。</p> 
<p>DJL是采用Java编写的深度学习框架，支持MXnet，Tensorflow，Pytorch引擎，这意味着同一个模型采用不同语言编写，在DJL框架中运行只需要更改依赖，代码完全一样即可执行。关于DJL更多的介绍大家可以浏览DJL官网，知乎，以及b站的课程。</p> 
<p>知乎专栏：<a href="https://www.zhihu.com/column/c_1255493231133417472" rel="nofollow" title="DJL深度学习库 - 知乎">DJL深度学习库 - 知乎</a></p> 
<p>b站课程录播：<a href="https://space.bilibili.com/9828026?spm_id_from=333.337.search-card.all.click" rel="nofollow" title="深度学习兽的个人空间_哔哩哔哩_Bilibili">深度学习兽的个人空间_哔哩哔哩_Bilibili</a> </p> 
<p>GitHub：<a href="https://github.com/deepjavalibrary" title="DeepJavaLibrary · GitHub">DeepJavaLibrary · GitHub</a> </p> 
<p>下面介绍部署pytorch模型步骤以及我个人遇到的一些坑，希望对大家有所帮助</p> 
<p>首先是pom文件依赖</p> 
<pre><code>import torch
print(torch.__version__)</code></pre> 
<p> 首先使用该命令查看本地环境下的pytorch版本，根据本地的pytorch版本，选取合适的engine</p> 
<p><a href="http://docs.djl.ai/engines/pytorch/pytorch-engine/index.html" rel="nofollow" title="PyTorch Engine - Deep Java Library">PyTorch Engine - Deep Java Library</a></p> 
<p>这是DJL官网的例子，也包含Linux和maxOS下的依赖配置，我的pytorch版本是1.9.0，给出我的pom文件做参考</p> 
<pre><code> &lt;dependencies&gt;
        
        &lt;dependency&gt;
            &lt;groupId&gt;ai.djl&lt;/groupId&gt;
            &lt;artifactId&gt;api&lt;/artifactId&gt;
            &lt;version&gt;0.18.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt;
            &lt;artifactId&gt;pytorch-engine&lt;/artifactId&gt;
            &lt;version&gt;0.18.0&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt;
            &lt;artifactId&gt;pytorch-native-auto&lt;/artifactId&gt;
            &lt;version&gt;1.9.1&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt;
            &lt;artifactId&gt;pytorch-native-cpu&lt;/artifactId&gt;
            &lt;classifier&gt;win-x86_64&lt;/classifier&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
            &lt;version&gt;1.11.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ai.djl.pytorch&lt;/groupId&gt;
            &lt;artifactId&gt;pytorch-jni&lt;/artifactId&gt;
            &lt;version&gt;1.11.0-0.18.0&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;</code></pre> 
<p> 对于加载自己的本地模型，踩到的两个坑，第一个就是如果该模型是用GPU训练的，那么之后推理也需要使用GPU，如果想用CPU推理，那就需要用CPU训练网络（这一条我不确定是否正确，只是我这样修改后确实没有报错了）第二个坑就是在python中保存模型时，要使用下面的代码</p> 
<pre><code>net.eval()

input = np.random.uniform(0, 1, (1,1, 2048, 1))
input = input.astype(np.float32)
input = torch.from_numpy(input)
script = torch.jit.trace(net, input)
script.save(save_path+"/"+"0726+"+str(test_acc)+".pt")</code></pre> 
<p>使用script.save保存模型，之前我的代码是torch.save，保存的模型在DJL中加载会报错</p> 
<p>DJL加载model首先获取本地模型的url</p> 
<pre><code>Path modeldir = Paths.get("D:\\1.pt");</code></pre> 
<p>之后重写Translator，这个需要自定义模型的输入输出类型</p> 
<pre><code>Translator&lt;NDList, Long&gt; translator = new NoBatchifyTranslator&lt;NDList, Long&gt;() {
            @Override
            public NDList processInput(TranslatorContext translatorContext, NDList inputs) throws Exception {
                NDManager ndManager = translatorContext.getNDManager();
                NDArray ndArray = ndManager.create(new float[2048]).reshape(1,1,2048,1);
                //ndArray作为输入
                System.out.println(ndArray);
                return new NDList(ndArray);
            }
            @Override
            public Long processOutput(TranslatorContext translatorContext, NDList ndList) throws Exception {
                System.out.println("process: " + ndList);
                System.out.println("process-1:" + ndList.get(0));
                System.out.println("process-2:" + ndList.get(0).argMax());
                NDArray tmp = ndList.get(0).argMax();
                Long label =  tmp.max().getLong();
                return  label;
            }

        };</code></pre> 
<p>这个输入还是有问题的，传入的NDList完全没用上，一直在定义新的ndArray</p> 
<p>translator完成后，调用Criteria，加载模型</p> 
<pre><code>        Criteria&lt;NDList, Long&gt; criteria = Criteria.builder()
                .setTypes(NDList.class,Long.class)
                .optModelPath(modeldir)
                .optTranslator(translator)
                .build();</code></pre> 
<p>之后调用predictor，生成预测器 </p> 
<pre><code>Predictor&lt;NDList, Long&gt; predictor = criteria.loadModel().newPredictor();</code></pre> 
<p>创建样本，测试样本输出（由于translator的问题，这里传什么进去结果都一样）</p> 
<pre><code>NDManager manager = NDManager.newBaseManager();

NDArray array = manager.randomUniform(0, 1, new Shape(2048));

NDList testarray = new NDList(array);

Long result = predictor.predict(testarray);

System.out.println("result:" + result);</code></pre> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5066a8af0959ad0fee9438e453fec0ec/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">安装PostgreSQL &#43; 修改数据文件路径</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/63cb093158a3b18ffb42dafaaec963bc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">uni-app：关于自定义组件、easycom规范、uni_modules等问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>