<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>熵权法计算权重 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="熵权法计算权重" />
<meta property="og:description" content="文章目录 1. 多属性决策问题2. 熵（entropy）3. 信息熵4. 熵权法5. 熵权法的实现 基于信息论的熵值法是根据各指标所含信息有序程度的差异性来确定指标权重的客观赋权方法，仅依赖于数据本身的离散程度。 熵用于度量不确定性，指标的离散程度越大（不确定性越大）则熵值越大，表明指标值提供的信息量越多，则该指标的权重也应越大。
1. 多属性决策问题 熵权法多用于多属性决策问题中求解各个属性的权值。我们先简单介绍下多属性决策：
多属性决策指的是在考虑多个属性的情况下，对一组（有限个）备选方案进行排序或者择优。
主要包含以下几个组成部分：
（1）获取属性信息。
（2）属性权重确定：包括主观赋权法、客观赋权法、主客观结合的赋权法。
（3）多属性决策：对决策所需的属性信息进行集结，并基于相应策略对备选方案进行排序和择优。
这里，假设我们的数据的样本数量为 n n n，每个样本有 j j j个feature，那么对于一个样本的一个feature的取值为： x i j x_{ij} xij​
其中：
i i i ：第个样本
j j j ：第个feature
假设有这样一个应用场景，由于每一个样本都有很多feature，我想把这个样本的这些feature总结为一个值，应该怎么做？即
我们有一万种方法能达到这个目的，有了这个值，我们就可以进行排名、比较等操作。所以，这个值还得有点实际意义，不能是瞎攒出来的一个数。
熵权法(EEM, entropy evaluation method)是根据指标信息熵的大小对指标客观赋值的一种方法，信息熵越大，代表该指标的离散程度很大，包含的信息就多，所赋予的权重就越大。也就是说，这个方法实际上关注的是变量的取值的多样性，取值大小差异越大的，即离散程度越高的，就说明这个feature的重要程度很大，包含了更多的信息。
2. 熵（entropy） 熵的概念是由德国物理学家克劳修斯于1865年所提出。最初是用来描述“能量退化”的物质状态参数之一，在热力学中有广泛的应用。
热力学第二定律又被称为”熵增“定律，从它的描述中大家也能明白一二：在自然状态下，热量只会从热水杯传递给冷水杯，这个过程是不可逆的，而”熵“则是这个不可逆过程的度量。换而言之，封闭系统的熵只会不变或增加，不会减少。关于“热力学熵”，最原始的宏观表达式是：
那时的熵仅仅是一个可以通过热量改变来测定的物理量，其本质仍没有很好的解释，直到统计物理、信息论等一系列科学理论发展，熵的本质才逐渐被解释清楚，即，熵的本质是一个系统“内在的混乱程度”。
3. 信息熵 信息熵是一个数学上颇为抽象的概念，由大名鼎鼎的信息论之父——克劳德 • 香农提出。在这里不妨把信息熵理解成某种特定信息的出现概率（离散随机事件的出现概率）。一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。信息熵也可以说是系统有序化程度的一个度量。
一般说来，信息熵的表达式为：
举例1：
假设一个硬币，投出正反两面的概率都是50%，那么它的entropy为：
也就是说，一个公平的硬币，其正反面概率都是50%的情况下，熵最大化了。这件事推广到有多个面的骰子也是一样的，每个事件出现的概率越接近，样本的混乱程度就越高，熵就越大。而如果某个事件的出现概率是压倒性的，比其他所有事件出现概率加一起都高得多，那么熵就会比较小。
举例2：
假设4个元素，每个元素的feature有1个特征x1，并且它有个类型y，即
我们发现一个很有趣的现象，就是进行分组以后，熵降低了。这实际上就是决策树的基本原理，通过对属性进行分割，从而降低整体的混乱程度。即对一个属性的不同取值进行分组以后，每一组的混乱程度做个加权和，整体混乱程度要比分组之前的混乱程度还要低，也就是说每一组都更纯粹一些。
当然，这里计算entropy的 l o g 2 log_2 log2​是以2为底，也可以以自然对数为底，函数图像形状是基本不变的。
4. 熵权法 回到最开始我们问的问题，就是我怎么对一大堆指标(feature)进行综合一下，形成一个综合的值。当然我们就是用简单的加权和来做，但是我们还希望这个值具有一定的代表性。这个代表性我们就视为该feature下取值的多样性，或者说离散程度。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/60484bb0fbf6e483a1c22011da16068d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-21T16:04:08+08:00" />
<meta property="article:modified_time" content="2023-02-21T16:04:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">熵权法计算权重</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#1__6" rel="nofollow">1. 多属性决策问题</a></li><li><a href="#2_entropy_28" rel="nofollow">2. 熵（entropy）</a></li><li><a href="#3__38" rel="nofollow">3. 信息熵</a></li><li><a href="#4__61" rel="nofollow">4. 熵权法</a></li><li><a href="#5__124" rel="nofollow">5. 熵权法的实现</a></li></ul> 
 </li></ul> 
</div> 
<br> 基于信息论的熵值法是根据各指标所含信息有序程度的差异性来确定指标权重的客观赋权方法，仅依赖于数据本身的离散程度。 
<p></p> 
<p><strong>熵用于度量不确定性，指标的离散程度越大（不确定性越大）则熵值越大，表明指标值提供的信息量越多，则该指标的权重也应越大。</strong></p> 
<h3><a id="1__6"></a>1. 多属性决策问题</h3> 
<p>熵权法多用于多属性决策问题中求解各个属性的权值。我们先简单介绍下多属性决策：<br> 多属性决策指的是在考虑多个属性的情况下，对一组（有限个）备选方案进行排序或者择优。<br> 主要包含以下几个组成部分：<br> （1）获取属性信息。<br> （2）属性权重确定：包括主观赋权法、客观赋权法、主客观结合的赋权法。<br> （3）多属性决策：对决策所需的属性信息进行集结，并基于相应策略对备选方案进行排序和择优。</p> 
<p>这里，假设我们的数据的样本数量为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
      
        n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span>，每个样本有<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         j 
        
       
      
        j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>个feature，那么对于一个样本的一个feature的取值为： <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
         
         
           i 
          
         
           j 
          
         
        
       
      
        x_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span><br> 其中：<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> ：第个样本<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         j 
        
       
      
        j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span> ：第个feature</p> 
<p>假设有这样一个应用场景，由于每一个样本都有很多feature，我想把这个样本的这些feature总结为一个值，应该怎么做？即</p> 
<p><img src="https://images2.imgbox.com/b7/38/O4nUSrBj_o.png" alt="![在这里插入图片描述](https://img-blog.csdnimg.cn/75b679b827594e2bb40b53975f5df77b.p"><br> 我们有一万种方法能达到这个目的，有了这个值，我们就可以进行排名、比较等操作。所以，这个值还得有点实际意义，不能是瞎攒出来的一个数。</p> 
<p>熵权法(EEM, entropy evaluation method)是根据指标信息熵的大小对指标客观赋值的一种方法，信息熵越大，代表该指标的离散程度很大，包含的信息就多，所赋予的权重就越大。也就是说，这个方法实际上关注的是变量的取值的多样性，取值大小差异越大的，即离散程度越高的，就说明这个feature的重要程度很大，包含了更多的信息。</p> 
<h3><a id="2_entropy_28"></a>2. 熵（entropy）</h3> 
<p>熵的概念是由德国物理学家克劳修斯于1865年所提出。最初是用来描述“能量退化”的物质状态参数之一，在热力学中有广泛的应用。</p> 
<p>热力学第二定律又被称为”熵增“定律，从它的描述中大家也能明白一二：在自然状态下，热量只会从热水杯传递给冷水杯，这个过程是不可逆的，而”熵“则是这个不可逆过程的度量。换而言之，封闭系统的熵只会不变或增加，不会减少。关于“热力学熵”，最原始的宏观表达式是：<br> <img src="https://images2.imgbox.com/ad/dc/ussABzuI_o.png" alt="在这里插入图片描述"></p> 
<p>那时的熵仅仅是一个可以通过热量改变来测定的物理量，其本质仍没有很好的解释，直到统计物理、信息论等一系列科学理论发展，熵的本质才逐渐被解释清楚，即，熵的本质是一个系统“内在的混乱程度”。</p> 
<h3><a id="3__38"></a>3. 信息熵</h3> 
<p>信息熵是一个数学上颇为抽象的概念，由大名鼎鼎的信息论之父——克劳德 • 香农提出。在这里不妨把信息熵理解成某种特定信息的出现概率（离散随机事件的出现概率）。一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。信息熵也可以说是系统有序化程度的一个度量。</p> 
<p>一般说来，信息熵的表达式为：<br> <img src="https://images2.imgbox.com/f5/91/2Okm3MLc_o.png" alt="在这里插入图片描述"></p> 
<p><strong>举例1：</strong></p> 
<p>假设一个硬币，投出正反两面的概率都是50%，那么它的entropy为：<br> <img src="https://images2.imgbox.com/62/37/s5pBfRE6_o.png" alt="在这里插入图片描述"><br> 也就是说，一个公平的硬币，其正反面概率都是50%的情况下，熵最大化了。这件事推广到有多个面的骰子也是一样的，每个事件出现的概率越接近，样本的混乱程度就越高，熵就越大。而如果某个事件的出现概率是压倒性的，比其他所有事件出现概率加一起都高得多，那么熵就会比较小。</p> 
<p><strong>举例2：</strong></p> 
<p>假设4个元素，每个元素的feature有1个特征x1，并且它有个类型y，即<br> <img src="https://images2.imgbox.com/89/5f/UaoZxfUt_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/37/28/97pfOSej_o.png" alt="在这里插入图片描述"><br> 我们发现一个很有趣的现象，就是进行分组以后，熵降低了。这实际上就是决策树的基本原理，通过对属性进行分割，从而降低整体的混乱程度。即对一个属性的不同取值进行分组以后，每一组的混乱程度做个加权和，整体混乱程度要比分组之前的混乱程度还要低，也就是说每一组都更纯粹一些。</p> 
<p>当然，这里计算entropy的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
        
        
          g 
         
        
          2 
         
        
       
      
        log_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是以2为底，也可以以自然对数为底，函数图像形状是基本不变的。</p> 
<h3><a id="4__61"></a>4. 熵权法</h3> 
<p>回到最开始我们问的问题，就是我怎么对一大堆指标(feature)进行综合一下，形成一个综合的值。当然我们就是用简单的加权和来做，但是我们还希望这个值具有一定的代表性。这个代表性我们就视为该feature下取值的多样性，或者说离散程度。</p> 
<p>也就是说，如果一张数据表有很多行数据，每个数据又有很多feature，**如果某个feature的取值大家都一样，这实际上也说明这个feature可以丢掉了，用什么数据训练模型它都没啥用。但如果这个feature的取值特别多，那么这么指标对于决策更有用。**因此我们如果要综合一个指标的话，我们就要给最多样化，即离散程度最高的feature以最高的权重。</p> 
<p>主要计算步骤如下：</p> 
<p><strong>（1）归一化数据</strong></p> 
<p>这里对数据进行归一化，主要是消除量纲的影响。可以采用 min-max归一化或者mean-std归一化方法。<br> 数据归一化方法可以参考博客：<a href="https://blog.csdn.net/u012856866/article/details/129057448">数据预处理——数据无量纲化（归一化、标准化）</a></p> 
<p>这里以min-max归一化为例：<br> <img src="https://images2.imgbox.com/f4/51/4sKTbL0Q_o.png" alt="在这里插入图片描述"></p> 
<p>这里有几点需要注意的：</p> 
<ul><li>如果原始数据中，不同属性的取值在相近的量级上，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
          
          
            m 
           
          
            a 
           
          
            x 
           
          
         
        
       
         x_{max} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
          
          
            m 
           
          
            i 
           
          
            n 
           
          
         
        
       
         x_{min} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>可以直接取所有数据的最大最小值。</li></ul> 
<pre><code class="prism language-python">X_std <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</code></pre> 
<ul><li>如果原始数据中，不同属性的取值量级相差较大，可以考虑使用列归一化，即<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
          
          
            m 
           
          
            a 
           
          
            x 
           
          
         
        
       
         x_{max} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
          
          
            m 
           
          
            i 
           
          
            n 
           
          
         
        
       
         x_{min} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>取列数据的列最大值和列最小值。</li></ul> 
<pre><code class="prism language-python">X_std <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> X<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>如果原始数据中，某个属性的取值完全一样为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
         
           v 
          
         
        
       
         x_{v} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，min、max、x 均相等，则基于min-max归一化方法计算分子分母均为0，默认算出的该属性数据均为0。</li></ul> 
<p>该属性的取值大家都一样，对于决策没有作用，参与决策过程的权重理应很小很小。而归一化后的0值数据，经过信息熵的计算后，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         = 
        
       
         1 
        
       
      
        P=1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>， <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
       
         g 
        
       
         ( 
        
       
         P 
        
       
         ) 
        
       
         = 
        
       
         0 
        
       
      
        log(P)=0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         − 
        
       
         P 
        
       
         ∗ 
        
       
         l 
        
       
         o 
        
       
         g 
        
       
         ( 
        
       
         P 
        
       
         ) 
        
       
         = 
        
       
         0 
        
       
      
        -P * log(P) = 0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         E 
        
       
         = 
        
       
         0 
        
       
      
        E = 0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>，安全权重系数计算公式，最后算出来的权值很大，不符合实际情况。</p> 
<p><img src="https://images2.imgbox.com/0d/d9/32JiAbl9_o.png" alt="在这里插入图片描述"></p> 
<p>这种情况下，我们可以在数据归一化后，给数据加上一个很小的数值（比如1e-3）来避免样本取值为0情况，即：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
         
         
           x 
          
          
          
            ′ 
           
          
            ′ 
           
          
         
         
         
           i 
          
         
           j 
          
         
        
       
         = 
        
        
        
          x 
         
         
         
           i 
          
         
           j 
          
         
        
          ′ 
         
        
       
         + 
        
       
         0.001 
        
       
      
        {x''}_{ij}=x'_{ij} + 0.001 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.038em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1467em; vertical-align: -0.3948em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4413em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3948em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.001</span></span></span></span></span></p> 
<p><strong>（2）只关注第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
       
         j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>个feature，计算每个样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            x 
           
           
           
             ′ 
            
           
             ′ 
            
           
          
          
          
            i 
           
          
            j 
           
          
         
        
       
         {x''}_{ij} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.038em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>在第个feature下所占的全部取值的比例。</strong><br> <img src="https://images2.imgbox.com/93/75/8yUQAvjJ_o.png" alt="在这里插入图片描述"><br> 这个比例其实就是视为概率了。<br> 举个例子，如果对于第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         j 
        
       
      
        j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>个feature，我们的样本经过归一化以后取值为：<br> <img src="https://images2.imgbox.com/06/19/SXevW6Ks_o.png" alt="在这里插入图片描述"><br> 我们可以理解为，取值越大，这个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          p 
         
         
         
           i 
          
         
           j 
          
         
        
       
      
        p_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的值就越大。相当于我们自定义了一个"概率"，将其与取值联系到了一起，这么做，是因为我们要计算的熵仅仅与概率有关，而如果<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
         
         
           i 
          
         
           j 
          
         
        
       
      
        x_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的取值特别多样化，我们用它算出来的这个概率也会特别多样化，有大有小，从而降低熵。</p> 
<p><strong>（3）计算第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
       
         j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>个feature的熵</strong>。<br> <img src="https://images2.imgbox.com/0a/c8/St7gjvjy_o.png" alt="在这里插入图片描述"><br> <strong>（4）计算第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
       
         j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>个feature的差异系数</strong>。</p> 
<p><img src="https://images2.imgbox.com/e5/cb/MEBzZupk_o.png" alt="在这里插入图片描述"></p> 
<p>这个差异系数的含义显而易见，就是该feature的离散程度越高，该差异系数越高。</p> 
<p><strong>（5）对差异系数归一化，计算第个feature的权重</strong><br> <img src="https://images2.imgbox.com/0d/e7/BBi0W918_o.png" alt="在这里插入图片描述"></p> 
<p>这样对于每个feature，其离散程度越高，所占比重就会越高。这样一来，我们就有了每个feature的权重了，下面我们用这个权重来算每个样本的指标</p> 
<p><strong>（6）计算最终的统计测度：</strong><br> <img src="https://images2.imgbox.com/4b/84/TXjj0UHt_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5__124"></a>5. 熵权法的实现</h3> 
<p>先定义基础数据：</p> 
<pre><code class="prism language-python">data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">'人均专著'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'生师比'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'科研经费'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5000</span><span class="token punctuation">,</span> <span class="token number">6000</span><span class="token punctuation">,</span> <span class="token number">7000</span><span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token string">'逾期毕业率'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4.7</span><span class="token punctuation">,</span> <span class="token number">5.6</span><span class="token punctuation">,</span> <span class="token number">6.7</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token number">1.8</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'院校'</span> <span class="token operator">+</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'ABCDE'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<p><strong>【实现代码 1】：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">get_entropy_weight_1</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 熵权法需要使用原始数据作为输入</span>
	data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
	<span class="token comment"># 数据归一化</span>
	<span class="token comment"># 这里可以根据需要选择mean-std归一化或者min-max归一化</span>
	
    <span class="token comment"># 计算Pij</span>
	P <span class="token operator">=</span> data <span class="token operator">/</span> data<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 需要考虑分子为0的情况，可以考虑加一个epsilon=1e-3</span>

	<span class="token comment"># 计算熵值</span>
	E <span class="token operator">=</span> np<span class="token punctuation">.</span>nansum<span class="token punctuation">(</span><span class="token operator">-</span>P <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>P<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

	<span class="token comment"># 计算权系数</span>
	<span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> E<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> E<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

get_entropy_weight_1<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> 
<p>程序输出结果：</p> 
<pre><code class="prism language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.41803075</span><span class="token punctuation">,</span>  <span class="token number">0.14492264</span><span class="token punctuation">,</span>  <span class="token number">0.28588943</span><span class="token punctuation">,</span>  <span class="token number">0.15115718</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>【实现代码 2】：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_entropy_weight_2</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    :param data: dataframe类型
    :return: 各指标权重列表
    """</span>
    <span class="token comment"># 数据归一化</span>
    <span class="token comment"># 这里可以根据需要选择mean-std归一化或者min-max归一化</span>
    
    m<span class="token punctuation">,</span>n<span class="token operator">=</span>data<span class="token punctuation">.</span>shape
    
    <span class="token comment">#将dataframe格式转化为matrix格式</span>
    data<span class="token operator">=</span>data<span class="token punctuation">.</span>as_matrix<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 第一步：计算k</span>
    k<span class="token operator">=</span><span class="token number">1</span><span class="token operator">/</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>m<span class="token punctuation">)</span>
    
    <span class="token comment">#第二步:计算pij</span>
    pij<span class="token operator">=</span>data<span class="token operator">/</span>data<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># 第三步：计算每种指标的信息熵</span>
    tmp<span class="token operator">=</span>np<span class="token punctuation">.</span>nan_to_num<span class="token punctuation">(</span>pij<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>pij<span class="token punctuation">)</span><span class="token punctuation">)</span>
    ej<span class="token operator">=</span><span class="token operator">-</span>k<span class="token operator">*</span><span class="token punctuation">(</span>tmp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 第四步：计算每种指标的权重</span>
    wi<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>ej<span class="token punctuation">)</span><span class="token operator">/</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>ej<span class="token punctuation">)</span>
    wi_list<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>wi<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span>  wi_list

get_entropy_weight_2<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token number">0.41803075156086411</span><span class="token punctuation">,</span>
 <span class="token number">0.14492263660659988</span><span class="token punctuation">,</span>
 <span class="token number">0.28588943395852595</span><span class="token punctuation">,</span>
 <span class="token number">0.15115717787401006</span><span class="token punctuation">]</span>
</code></pre> 
<p>可以看到，两个代码的输出结果一致，且各个属性的权值加起来和为1。</p> 
<p>这里，有几个需要注意的点：</p> 
<ul><li>数据归一化：在原始数据量纲不一致时，我们使用熵权法之前可以先对数据做归一化处理。这里可以根据数据的实际情况和业务需要选择mean-std归一化或者min-max归一化。不同的归一化方法，对最后求出来的权值会有影响。</li><li>可以在数据归一化后，给数据加上一个很小的数值（比如1e-3）来避免样本取值为0情况，即：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            x 
           
           
           
             ′ 
            
           
             ′ 
            
           
          
          
          
            i 
           
          
            j 
           
          
         
        
          = 
         
         
         
           x 
          
          
          
            i 
           
          
            j 
           
          
         
           ′ 
          
         
        
          + 
         
        
          0.001 
         
        
       
         {x''}_{ij}=x'_{ij} + 0.001 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.038em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1467em; vertical-align: -0.3948em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4413em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3948em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.001</span></span></span></span></span></li><li>除数为0的情况：上述计算过程涉及除法，会遇到除数为0的情况。可以给除数加一个很小的数值，如epsilon=1e-3，以避免除以0的情况发生。</li></ul> 
<p>【参考博客】：</p> 
<ul><li><a href="https://blog.csdn.net/u012856866/article/details/118491772">TOPSIS法(优劣解距离法)介绍及 python3 实现</a></li><li><a href="https://zhuanlan.zhihu.com/p/551107230" rel="nofollow">https://zhuanlan.zhihu.com/p/551107230</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a86f1e541d9274dd1111770877add938/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Ubuntu22.04安装</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c51e98da149b83ee9ab4cd3325cac386/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ChatGPT的出现网络安全专家是否会被替代?</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>