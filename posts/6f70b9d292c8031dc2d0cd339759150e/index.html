<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>百川2-大模型-论文笔记 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="百川2-大模型-论文笔记" />
<meta property="og:description" content="文章目录 0.资料预览1.模型特点速览2.模型效果对比2.1 对比BaiChuan 12.2 对比其它开源模型2.2.1 通用基准测试-整体对比2.2.2 垂直领域测试2.2.2.1 法律2.2.2.2 数学、编码2.2.2.3 多语言领域 3. 预训练数据3.0 数据分布3.1数据源3.2 数据处理3.2.1 预训练数据处理流程 4. 模型结构&amp;预训练4.0 基础结构4.1 输入4.1.1 词表4.1.2 字符编码4.1.3 位置编码 4.2 中间结构4.2.1 激活函数4.2.2 注意力层4.2.3 归一化层4.2.3.1 层归一化4.2.3.2 归一化头 NormHead 4.3 预训练4.3.0 损失4.3.1 优化器4.3.2 数据精度4.3.3 预训练损失变化 4.4 通过缩放得到大模型 5. 后续训练：SFT &amp; RLHF5.1 SFT: 监督微调5.2 RLHF: 从人类反馈中强化学习5.2.1 RLHF过程示意图5.2.2 奖励模型 (Reward Model, RM)5.2.3 PPO5.2.4 RLHF 训练细节 6. 数据毒性6.1 预训练阶段6.2 SFT &amp; RLHF 阶段6.3 评估6.3.1 Toxigen（Hartvigsen等人，2022）数据集6.3.2 百川无害评价数据集(BHED) 7. ckpt8. 设备 0.资料预览 论文位置：https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdfgithub： https://github." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6f70b9d292c8031dc2d0cd339759150e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-21T20:48:51+08:00" />
<meta property="article:modified_time" content="2023-11-21T20:48:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">百川2-大模型-论文笔记</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0_1" rel="nofollow">0.资料预览</a></li><li><a href="#1_11" rel="nofollow">1.模型特点速览</a></li><li><a href="#2_44" rel="nofollow">2.模型效果对比</a></li><li><ul><li><a href="#21_BaiChuan_1_45" rel="nofollow">2.1 对比BaiChuan 1</a></li><li><a href="#22__47" rel="nofollow">2.2 对比其它开源模型</a></li><li><ul><li><a href="#221__49" rel="nofollow">2.2.1 通用基准测试-整体对比</a></li><li><a href="#222__76" rel="nofollow">2.2.2 垂直领域测试</a></li><li><ul><li><a href="#2221__77" rel="nofollow">2.2.2.1 法律</a></li><li><a href="#2222__81" rel="nofollow">2.2.2.2 数学、编码</a></li><li><a href="#2223___85" rel="nofollow">2.2.2.3 多语言领域</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#3__89" rel="nofollow">3. 预训练数据</a></li><li><ul><li><a href="#30__90" rel="nofollow">3.0 数据分布</a></li><li><a href="#31_93" rel="nofollow">3.1数据源</a></li><li><a href="#32__96" rel="nofollow">3.2 数据处理</a></li><li><ul><li><a href="#321__100" rel="nofollow">3.2.1 预训练数据处理流程</a></li></ul> 
  </li></ul> 
  </li><li><a href="#4__106" rel="nofollow">4. 模型结构&amp;预训练</a></li><li><ul><li><a href="#40__107" rel="nofollow">4.0 基础结构</a></li><li><a href="#41__114" rel="nofollow">4.1 输入</a></li><li><ul><li><a href="#411__115" rel="nofollow">4.1.1 词表</a></li><li><a href="#412__122" rel="nofollow">4.1.2 字符编码</a></li><li><a href="#413__131" rel="nofollow">4.1.3 位置编码</a></li></ul> 
   </li><li><a href="#42___135" rel="nofollow">4.2 中间结构</a></li><li><ul><li><a href="#421__136" rel="nofollow">4.2.1 激活函数</a></li><li><a href="#422__141" rel="nofollow">4.2.2 注意力层</a></li><li><a href="#423__145" rel="nofollow">4.2.3 归一化层</a></li><li><ul><li><a href="#4231__146" rel="nofollow">4.2.3.1 层归一化</a></li><li><a href="#4232__NormHead_148" rel="nofollow">4.2.3.2 归一化头 NormHead</a></li></ul> 
   </li></ul> 
   </li><li><a href="#43__160" rel="nofollow">4.3 预训练</a></li><li><ul><li><a href="#430__161" rel="nofollow">4.3.0 损失</a></li><li><a href="#431__167" rel="nofollow">4.3.1 优化器</a></li><li><a href="#432__173" rel="nofollow">4.3.2 数据精度</a></li><li><a href="#433__177" rel="nofollow">4.3.3 预训练损失变化</a></li></ul> 
   </li><li><a href="#44__181" rel="nofollow">4.4 通过缩放得到大模型</a></li></ul> 
  </li><li><a href="#5_SFT__RLHF_187" rel="nofollow">5. 后续训练：SFT &amp; RLHF</a></li><li><ul><li><a href="#51_SFT__188" rel="nofollow">5.1 SFT: 监督微调</a></li><li><a href="#52_RLHF__194" rel="nofollow">5.2 RLHF: 从人类反馈中强化学习</a></li><li><ul><li><a href="#521_RLHF_195" rel="nofollow">5.2.1 RLHF过程示意图</a></li><li><a href="#522__Reward_Model_RM_199" rel="nofollow">5.2.2 奖励模型 (Reward Model, RM)</a></li><li><a href="#523_PPO_204" rel="nofollow">5.2.3 PPO</a></li><li><a href="#524_RLHF__212" rel="nofollow">5.2.4 RLHF 训练细节</a></li></ul> 
  </li></ul> 
  </li><li><a href="#6__227" rel="nofollow">6. 数据毒性</a></li><li><ul><li><a href="#61__228" rel="nofollow">6.1 预训练阶段</a></li><li><a href="#62_SFT__RLHF__232" rel="nofollow">6.2 SFT &amp; RLHF 阶段</a></li><li><a href="#63__247" rel="nofollow">6.3 评估</a></li><li><ul><li><a href="#631_ToxigenHartvigsen2022_248" rel="nofollow">6.3.1 Toxigen（Hartvigsen等人，2022）数据集</a></li><li><a href="#632_BHED_255" rel="nofollow">6.3.2 百川无害评价数据集(BHED)</a></li></ul> 
  </li></ul> 
  </li><li><a href="#7__ckpt_268" rel="nofollow">7. ckpt</a></li><li><a href="#8__275" rel="nofollow">8. 设备</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0_1"></a>0.资料预览</h2> 
<ul><li>论文位置：https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf</li><li>github： https://github.com/baichuan-inc/Baichuan2</li><li>同类文章：<br> – 精简：https://zhuanlan.zhihu.com/p/655984589<br> – 详细：<br> （1）https://mp.weixin.qq.com/s/gUBH7Q_lLPiliSRZed_GRA<br> （2）https://zhuanlan.zhihu.com/p/657487567</li></ul> 
<h2><a id="1_11"></a>1.模型特点速览</h2> 
<ul><li> <p>模型名称 Baichuan2</p> </li><li> <p>参数量：7B、13B</p> </li><li> <p>训练token量：2.6T</p> </li><li> <p>开源：模型代码、ckpt</p> </li><li> <p>数据：<br> – 训练数据：<br> （1）预训练数据：聚类去重系统（详见 3.2.1节）；<br> （2）SFT &amp; RLHF 数据：10万个监督微调样本（详见 5.1节）、超200个三级类别数据给RM（详见 5.2节）；<br> （3）安全性数据：（详见 6.节）<br> – 测试数据：<br> （1）通用基准测试（详见 2.2.1节）<br> （2）垂直领域测试（详见 2.2.2节）<br> （3）毒性（安全性）测试（详见 6.3节）</p> </li><li> <p>模型结构（详见 4.节）<br> 基于transformer<br> （1）词表大小：125696<br> （2）位置编码：7B使用RoPE 、13B使用 ALiBi<br> （3）激活函数：SwiGLU<br> （4）注意力层：由 xFormers2 实现的内存高效的注意力<br> （5）归一化层：RMS-LN；对embedding输出做了NormHead</p> </li><li> <p>训练<br> – 预训练（详见 4.3节）<br> （1）损失：max-z loss<br> （2）优化器：AdamW<br> – 后续训练（详见 5.节）<br> 关键词：SFT、RLHF、PPO</p> </li></ul> 
<p>（注：开源模型简介 - LaMa (Touvron et al.，2023a)、OPT (Zhang et al.，2022)、Bloom (Scavocchini et al.，2022)、MPT (MosaicML，2023) 、Falcon (Penedo et al.，2023)）</p> 
<h2><a id="2_44"></a>2.模型效果对比</h2> 
<h3><a id="21_BaiChuan_1_45"></a>2.1 对比BaiChuan 1</h3> 
<p>在通用基准测试，如 MMLU (Hendrycks et al., 2021a)，CMMLU (Li et al., 2023)，和 C-Eval (Huang et al., 2023) 中，BaiChuan2-7B 相比 BaiChuan 1-7B 实现了近 30% 的性能提升。具体来说，BaiChuan2 优化以提高解决数学和代码问题的能力。在 GSM8K (Cobbe et al., 2021) 和 HumanEval (Chen et al., 2021) 测试中，BaiChuan 2 将 BaiChuan 1 的结果提高了近一倍。此外，BaiChuan 2 在医学和法律领域的任务上也表现出强大的性能。</p> 
<h3><a id="22__47"></a>2.2 对比其它开源模型</h3> 
<p>在 MedQA (Jin et al., 2021) 和 JEC-QA (Zhong et al., 2020) 等基准测试中，BaiChuan 2 比其他开源模型表现得更好，使其成为适合特定领域优化的基础模型。</p> 
<h4><a id="221__49"></a>2.2.1 通用基准测试-整体对比</h4> 
<p><img src="https://images2.imgbox.com/f8/76/9L1YQF0b_o.png" alt="论文表1"><br> 论文表1</p> 
<p>测试集（8个）：</p> 
<ul><li>MMLU（ Hendrycks et al.，2021a）大规模多任务语言理解包含一系列关于学术主题的多项选择题。</li><li>C-Eval（黄等，2023年）是一个综合性的中文评估基准，包括超过1万个多项选择题。</li><li>CMMLU（李等，2023年）也是一个通用的评估基准，专门用于评估在中文语言和文化背景下知识推理能力的语言模型。</li><li>AGIEval（钟等，2023年）是一个以人类为中心的基准，专门用于评估一般能力，如人类认知和问题解决。</li><li>GaoKao 高考（张等，2023年）是一种利用中国高中入学考试问题的评估框架。</li><li>BBH（苏兹古恩等，2022年）是一套挑战性 BIG-Bench（ Srivastava 等，2022 年）任务，语言模型的表现没有优于平均人类评分者。</li><li>GSM8K（ Cobbe 等，2021 年）是一个专注于数学的评估基准。</li><li>HumanEval（陈等，2021年）是一个代码到文档的数据集，其中包含164个编程逻辑的各个方面进行测试的问题。</li></ul> 
<p>对比模型：</p> 
<ul><li>LLAMA (Touvron等人，2023b)</li><li>LLAMA 2（Touvron等人，2023c）</li><li>百川1</li><li>ChatGLM 2-6B（Zeng等人，2022）</li><li>MPT-7B（MosaicML，2023）</li><li>Falcon-7B（Penedo等人，2023）</li><li>Vicuna-13B（Chiang等人，2023）</li><li>中文阿尔帕卡加13B（崔等人，2023年）</li><li>XVERSE-13B</li></ul> 
<p>（注：原文“对于CMMLU和MMLU，我们采用官方实现，并采用5-shots进行评估。 对于BBH，我们采用3-shots评估。 对于C-Eval、高考和AGIEval，我们只选择四个选项的多选题以获得更好的评估结果。 对于GSM8K，我们使用了来自OpenCompass（OpenCompass，2023）的4-shots测试。 我们还合并了GPT-46和GPT-3.5-Turbo7的结果。 除非另有说明，本文中的所有结果都是通过我们的内部评估工具获得的。”）</p> 
<h4><a id="222__76"></a>2.2.2 垂直领域测试</h4> 
<h5><a id="2221__77"></a>2.2.2.1 法律</h5> 
<p><img src="https://images2.imgbox.com/12/20/Nb0pppbv_o.png" alt="论文表5"><br> 论文表5</p> 
<h5><a id="2222__81"></a>2.2.2.2 数学、编码</h5> 
<p><img src="https://images2.imgbox.com/23/63/2EpczUiI_o.png" alt="论文表6"><br> 论文表6</p> 
<h5><a id="2223___85"></a>2.2.2.3 多语言领域</h5> 
<p><img src="https://images2.imgbox.com/27/de/GJjT0vSt_o.png" alt="论文表7"><br> 论文表7</p> 
<h2><a id="3__89"></a>3. 预训练数据</h2> 
<h3><a id="30__90"></a>3.0 数据分布</h3> 
<p><img src="https://images2.imgbox.com/b7/48/J2GnRt3B_o.png" alt="论文图1"><br> 论文图1</p> 
<h3><a id="31_93"></a>3.1数据源</h3> 
<p>从包括 普通互联网网页、书籍、研究论文、代码库等在内的多种来源收集数据。目标是追求全面的数据可扩展性和代表性.</p> 
<h3><a id="32__96"></a>3.2 数据处理</h3> 
<p>关注 数据频率 和 质量。<br> 数据频率依赖于聚类和去重。构建了一个大规模的去重和聚类系统，支持LSH类似特征和密集嵌入特征。该系统可以在数小时内对万亿级别的数据进行聚类和去重。</p> 
<h4><a id="321__100"></a>3.2.1 预训练数据处理流程</h4> 
<p>精确重复数据消除 -&gt; 启发式方法 -&gt; 逐句质量过滤器 -&gt; 逐句、逐段重复数据消除<br> -&gt; 文档式重复数据消除<br> <img src="https://images2.imgbox.com/d1/df/kYM4m1Qj_o.png" alt="论文图2"><br> 论文图2</p> 
<h2><a id="4__106"></a>4. 模型结构&amp;预训练</h2> 
<h3><a id="40__107"></a>4.0 基础结构</h3> 
<ul><li> <p>基于transformer</p> </li><li> <p>结构&amp;参数 预览<br> <img src="https://images2.imgbox.com/e0/94/lRcj5gOM_o.png" alt="论文表3"><br> 论文表3</p> </li></ul> 
<h3><a id="41__114"></a>4.1 输入</h3> 
<h4><a id="411__115"></a>4.1.1 词表</h4> 
<p>模型 词表 &amp; 文本压缩率<br> <img src="https://images2.imgbox.com/f6/6f/U1PuLmkp_o.png" alt="论文表2"><br> 论文表2</p> 
<ul><li>最大标记长度为32，以考虑长汉语短语</li><li>百川2分词器的训练数据来自百川2预训练语料库，包含更多样本代码示例和学术论文以提高覆盖率（Taylor等人，2022）。</li></ul> 
<h4><a id="412__122"></a>4.1.2 字符编码</h4> 
<ul><li>使用字节对编码（BPE）(Shibata等人，1999)从SentencePiece(Kudo和Richardson，2018)。</li><li>不对接收的文本进行任何归一化。</li><li>没有像baichuan 1中那样 添加哑令牌前缀。</li><li>将数字拆分为单个数字，以更好地编码数值数据。</li><li>为了处理包含多余空格的代码数据，Tokenizer添加了仅包含空格的标记。</li><li>字符覆盖率设置为0.9999。</li><li>罕见字符退化到UTF-8字节。</li></ul> 
<h4><a id="413__131"></a>4.1.3 位置编码</h4> 
<ul><li>白川2-7B：使用旋转位置嵌入（RoPE）(Su等人，2021) 。</li><li>白川2-13B：使用ALiBi (Press等人，2021)。</li></ul> 
<h3><a id="42___135"></a>4.2 中间结构</h3> 
<h4><a id="421__136"></a>4.2.1 激活函数</h4> 
<ul><li>基本结构：SwiGLU（Shazeer，2020）激活函数</li><li>论文修改：调整了隐藏层大小<br> （注：原文“然而，SwiGLU 具有一个“双线性”层，并且包含三个参数矩阵，不同于具有两个矩阵的标准变压器前馈层，因此我们将隐藏大小从隐藏大小的四倍减少到83个隐藏大小，并四舍五入为128的乘积。”）</li></ul> 
<h4><a id="422__141"></a>4.2.2 注意力层</h4> 
<p>采用了由 xFormers2 实现的内存高效的注意力（Rabe 和 Staats，2021）<br> （注：原文“通过利用 xFormers 具有偏差能力的优化注意力，我们可以高效地合并 ALiBi 的基于偏差的位置编码，同时减少内存开销。这为 Baichuan2 的大规模训练提供了性能和效率方面的优势。”）</p> 
<h4><a id="423__145"></a>4.2.3 归一化层</h4> 
<h5><a id="4231__146"></a>4.2.3.1 层归一化</h5> 
<p>RMS-LN（不去中心的 层归一化）</p> 
<h5><a id="4232__NormHead_148"></a>4.2.3.2 归一化头 NormHead</h5> 
<p>对输出embeddings（也称为“头”）进行了归一化。<br> 理由如下：</p> 
<ul><li>显著地稳定训练过程<br> （注：原文“在我们的预研工作中，我们发现头部的范数容易不稳定。在训练过程中，稀有标记的嵌入范数变小，扰乱了训练动力学”）</li><li>缓解欧氏距离对语义的干扰<br> （注：原文“我们发现语义信息主要由嵌入的余弦相似度编码，而不是L2距离。由于当前线性分类器通过点积计算 logit，它是L2距离和余弦相似度的混合。归一化头缓解了在线性分类器中计算logit时L2距离的干扰。”）</li></ul> 
<p>有无 NormHead， 对训练过程的影响：<br> <img src="https://images2.imgbox.com/91/a5/VUxd7WQU_o.png" alt="论文图9"><br> 论文图9</p> 
<h3><a id="43__160"></a>4.3 预训练</h3> 
<h4><a id="430__161"></a>4.3.0 损失</h4> 
<p>最大z损失（max-z loss）<br> （注：原文“通过这种方式收缩非常大的对数可以显著改变softmax之后的概率，使模型对重复惩罚超参数的选择变得敏感。受NormSoftmax（Jiang等人，2023年b）和PaLM（Chowdhery等人，2022年）的辅助z损失的启发，我们在对数上添加了一个最大z损失来归一化对数”）<br> <img src="https://images2.imgbox.com/cf/ac/FiRaQyRc_o.png" alt="论文公式1"><br> 论文公式1</p> 
<h4><a id="431__167"></a>4.3.1 优化器</h4> 
<ul><li>AdamW（Loshchilov和Hutter，2017）优化器</li><li>参数设置<br> – β1 和 β2 分别设置为0.9和0.95<br> – 使用0.1的权重衰减，并对梯度范数截断到0.5<br> – 通过2,000个线性步长进行预热，达到最大学习率，然后应用余弦退火至最小学习率</li></ul> 
<h4><a id="432__173"></a>4.3.2 数据精度</h4> 
<p>BFloat16混合精度<br> （注：原文“与Float16相比，BFloat16具有更好的动态范围，使其在训练大型语言模型时对大值更加稳健。然而，BFloat16 的低精度会在某些情况下造成问题。例如，在一些公共RoPE 和ALibi实现中，当整数超过256时， torch.arange 操作会因碰撞而失败，导致无法区分附近的位置。因此，我们在一些对数值敏感的操作（如位置嵌入）上使用全精度。”）</p> 
<h4><a id="433__177"></a>4.3.3 预训练损失变化</h4> 
<p><img src="https://images2.imgbox.com/78/d6/JbjvG3CF_o.png" alt="论文图3"><br> 论文图3</p> 
<h3><a id="44__181"></a>4.4 通过缩放得到大模型</h3> 
<ul><li>神经网络的规模法则：误差随着训练集大小、模型大小或两者同时增加而呈幂次方下降。</li><li>文章使用了Henighan等人（2020年）给出的公式，拟合的缩放法则高精度地预测了Baichuan 2 （7B、13B）的最终损失。<br> <img src="https://images2.imgbox.com/0f/a3/X6dZB1af_o.png" alt="论文图4"><br> 论文图4</li></ul> 
<h2><a id="5_SFT__RLHF_187"></a>5. 后续训练：SFT &amp; RLHF</h2> 
<h3><a id="51_SFT__188"></a>5.1 SFT: 监督微调</h3> 
<p>收集了超过10万个监督微调样本。<br> 收集过程如下：</p> 
<ul><li>使用人工标注者对来自各种数据源的提示进行注释。</li><li>每个提示都根据类似于克劳德（2023）的关键原则被标记为有用或无害。</li><li>使用交叉验证来验证数据质量（一个权威的注释者会检查由特定的众包工人组注释的样本批次的质量，并拒绝任何不符合我们的质量标准的批次）。</li></ul> 
<h3><a id="52_RLHF__194"></a>5.2 RLHF: 从人类反馈中强化学习</h3> 
<h4><a id="521_RLHF_195"></a>5.2.1 RLHF过程示意图</h4> 
<p><img src="https://images2.imgbox.com/b1/d3/64eCULil_o.png" alt="论文图5"><br> 论文图5</p> 
<h4><a id="522__Reward_Model_RM_199"></a>5.2.2 奖励模型 (Reward Model, RM)</h4> 
<ul><li>为所有提示设计了一个三层次的分类系统，由6个主要类别、30个次要类别和超过200个三级类别组成。</li><li>在奖励训练中，仅使用 Baichuan 2 模型家族生成的响应。（注：原文“来自其他开源数据集和专有模型的响应不会提高奖励模型的准确性。这也从另一个角度强调了 Baichuan 系列模型的内在一致性。”）</li><li>用于训练奖励模型的损失函数与 InstructGPT (Ouyang 等人，2022) 中的一致。</li></ul> 
<h4><a id="523_PPO_204"></a>5.2.3 PPO</h4> 
<p>获得奖励模型后，使用PPO（Schulman等人，2017年）算法训练语言模型。<br> 使用四个模型：</p> 
<ul><li>演员模型（负责生成响应）the actor model，</li><li>参考模型（用于计算具有固定参数的KL惩罚）the reference model，</li><li>奖励模型（为整个响应提供总体奖励，并且具有固定参数）the reward model，</li><li>评论家模型（设计用于学习每个标记值）critic model。</li></ul> 
<h4><a id="524_RLHF__212"></a>5.2.4 RLHF 训练细节</h4> 
<p>（1）步骤</p> 
<ul><li>20步训练对批评家模型进行预热。</li><li>使用标准PPO算法更新了批评者和演员模型。</li></ul> 
<p>（2）参数</p> 
<ul><li>梯度裁剪值为0.5</li><li>恒定学习率为5e-6</li><li>PPO剪切阈值e = 0.1</li><li>KL惩罚系数β设置为0.2，并在步骤中衰减到0.005</li><li>所有的聊天模型训练了350个周期</li></ul> 
<p>（3）产物<br> “百川2-7B聊天”、“百川2-13B聊天”</p> 
<h2><a id="6__227"></a>6. 数据毒性</h2> 
<h3><a id="61__228"></a>6.1 预训练阶段</h3> 
<ul><li>设计了一套规则和模型来消除有害的内容，如暴力、色情、种族歧视、仇恨言论等</li><li>从数百个权威网站中精心挑选了数百万网页的双语数据集，这些网站代表了各种正面价值领域，包括政策、法律、弱势群体、一般价值观、传统美德等等。提高了此数据集的采样概率</li></ul> 
<h3><a id="62_SFT__RLHF__232"></a>6.2 SFT &amp; RLHF 阶段</h3> 
<ul><li> <p>专家团队：拥有传统互联网安全经验的10人专家注释团队</p> </li><li> <p>标注团队：专家注释团队通过初始对齐模型引导一个外包的50人的注释团队</p> </li><li> <p>数据构造方式：<br> – 标注：标注团队进行红蓝对抗<br> – 采样：多值监督采样方法<br> – DPO (Rafailov等人，2023年)方法：有效地利用了有限数量的标记数据来提高针对特定漏洞问题的性能<br> – 模型：融合有益目标和无害目标的奖励模型</p> </li><li> <p>数据种类：包括六种攻击类型和100多个粒度安全价值类别</p> </li><li> <p>数据量：<br> – 专家标注：1K个注释的数据用于初始化，<br> – 标注团队：20万个攻击提示</p> </li></ul> 
<h3><a id="63__247"></a>6.3 评估</h3> 
<h4><a id="631_ToxigenHartvigsen2022_248"></a>6.3.1 Toxigen（Hartvigsen等人，2022）数据集</h4> 
<ul><li>Toxigen（Hartvigsen等人，2022）数据集评估预训练模型的安全性<br> （注：原文“使用清理过的来自SafeNLP项目8的版本，对13个少数族裔群体进行区分中立和仇恨类型，形成一个与原始Toxigen提示格式一致的6-shots数据集。我们的解码参数使用温度为0.1和top-p 0.9nucleus采样。”）</li><li>测试结果：<br> <img src="https://images2.imgbox.com/3e/e1/HBkxLD5k_o.png" alt="论文表8"><br> 论文表8</li></ul> 
<h4><a id="632_BHED_255"></a>6.3.2 百川无害评价数据集(BHED)</h4> 
<ul><li> <p>数据类别（7类）<br> – 偏见/歧视：涵盖各种形式，如国籍、种族、肤色、群体、职业、性别、地区、行业等，以确保数据多样性。<br> – 侮辱/亵渎：包括明确和隐含的侮辱以及网络言语虐待。<br> – 非法/不道德的内容：包括刑法、民法、经济法、国际法、交通法规、地方行政法规等。<br> – 身体健康：包括健康知识、医疗建议以及与身体健康相关的歧视。<br> – 心理健康：包括情感健康、认知和社会健康、自尊和自我价值、应对压力和适应能力、心理建议以及针对有心理健康问题的群体的歧视。<br> – 财务隐私：包括房地产、个人债务、银行信息、收入、股票推荐等。隐私包括个人信息、家庭信息、职业信息、联系方式、私生活等。<br> – 敏感话题：包括种族仇恨、 国际政治问题、 法律漏洞，</p> </li><li> <p>测试结果：<br> <img src="https://images2.imgbox.com/26/c2/g32Fe9NJ_o.png" alt="论文表9"><br> 论文表9</p> </li></ul> 
<h2><a id="7__ckpt_268"></a>7. ckpt</h2> 
<ul><li>将发布 7B 模型的中间检查点</li><li>从 2200 亿个标记的检查点到 2640 亿个标记的检查点</li><li>部分ckpt的评估<br> <img src="https://images2.imgbox.com/25/62/yRRCtjtc_o.png" alt="论文图7"><br> 论文图7</li></ul> 
<h2><a id="8__275"></a>8. 设备</h2> 
<p>以下整理自原文：<br> 设计了一种弹性训练框架的协同设计方法以及智能集群调度策略。训练框架的主要设计标准是机器级别的弹性，它支持动态修改任务资源。系统能够在 1,024 台 NVIDIA A800GPU 上高效地训练白川2-7B 和白川2-13B 模型，计算效率超过 180 TFLOPS。</p> 
<ul><li>为了满足需求，训练框架集成了张量并行（Narayanan等人，2021）和ZeRO驱动的数据并行（Rajbhandari等人，2020）：在每台机器中设置张量并行，并使用ZeRO共享数据并行来实现跨机器的弹性扩展。</li><li>此外，使用张量拆分技术（Nie等人，2022），将某些计算拆分为减少峰值内存消耗，例如大词汇表的交叉熵计算。这种方法能在不增加计算和通信的情况下满足内存需求，从而使系统更有效率。</li><li>为了进一步加速训练，同时不损失模型精度，我们实现了混合精度训练，在其中我们在Bfloat16中执行前向和反向计算，而在浮点数32中进行优化器更新。</li><li>为了有效地将我们的训练集群扩展到数千个 GPU，我们集成了以下技术来避免通信效率的降低：（1）考虑拓扑结构的分布式训练。（2）ZeRO的混合和分层分区。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/43e084940aac10d357081706656df960/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">git常常用命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9303a623449a5f93af2faa717c92bc17/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">InfoNCE Loss公式及源码理解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>