<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>keras 自然语言处理 lstm_seq2seq 案例分析 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="keras 自然语言处理 lstm_seq2seq 案例分析" />
<meta property="og:description" content="本例演示了如何实现一个基本的字符级使用 LSTM（长短期记忆神经网络）和 Seq2Seq（序列到序列模型）来进行自然语言处理的模型。我们将其应用于逐个字符，将短英语句子翻译为短法语句子。需要注意的是，在这个领域里，使用字符级机器翻译是相当不寻常的，因为使用单词级的模型更为常见。
算法摘要
我们从一个领域（例如英语句子）的输入序列开始，并从另一个领域（例如法语句子）中获得相应的目标序列。一个编码器 LSTM 将输入序列转换为 2 个状态向量（我们保留最后一个 LSTM 状态并丢弃输出）。一个解码器 LSTM 被训练，将目标序列转换为相同的序列，但是将时间步向前偏移一个步长，这个训练过程在这个上下文中称为“teacher forcing”。它使用来自编码器的状态向量作为初始状态。实际上，解码器在输入序列的条件下学习生成“targets[t&#43;1…]”给定“targets[…t]”。在推理模式下，当我们想要解码未知的输入序列时，我们要做以下操作： 编码输入序列为状态向量。以大小为 1 的目标序列开始（只有开始字符）。将状态向量和 1 个字符的目标序列提供给解码器，生成下一个字符的预测值。使用这些预测值采样下一个字符 (我们简单地使用 argmax)。将采样的字符添加到目标序列中。重复操作，直到生成结束字符或达到字符限制。 导入依赖 import numpy as np import tensorflow as tf from tensorflow import keras 加载数据：fra-eng 这是一个包含超过64000个法语-英语单词和短语的Anki词汇卡组，它可以帮助学习者提高词汇量并加强其语言技能。Anki是一种基于记忆卡片的学习方法，被广泛用于学习基础词汇和语法规则。该词汇卡组可以在线或离线使用，并可以导入到Anki应用程序中，以便离线学习。该词汇卡组的单词和短语都包含音频发音，可以帮助学习者正确地发音字词。这里用于机器翻译。
!!curl -O http://www.manythings.org/anki/fra-eng.zip !!unzip fra-eng.zip 配置项 这些配置决定着模型的参数和训练的行为。在配置模型时，我们需要用经过实验验证的数值来平衡训练时间和模型性能。
latent_dim：这是解码器中LSTM层的隐藏状态的维度大小。通俗地说，这决定了模型学习到的内部表示的复杂度。num_samples：这是用于训练模型的语料库中的句子数量。更多的语料库可以带来更好的性能，但需要更多的训练时间和计算资源。batch_size：这是一次传递给模型的句子数。更大的批量可以加速训练，但也可能导致内存不足等问题。 batch_size = 64 # 训练的 batch 大小。 epochs = 100 # 训练的 epoch 数。 latent_dim = 256 # 编码器空间的潜在维度。 num_samples = 10000 # 训练样本数量。 # 存储在磁盘上的数据文本文件路径。 data_path = &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/9630fe63daabcbdfd04a3eae8b9d1fb2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-11T12:06:16+08:00" />
<meta property="article:modified_time" content="2023-06-11T12:06:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">keras 自然语言处理 lstm_seq2seq 案例分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/50/64/ynMDH5Cm_o.png" alt="封面"></p> 
<p>本例演示了如何实现一个基本的字符级使用 LSTM（长短期记忆神经网络）和 Seq2Seq（序列到序列模型）来进行自然语言处理的模型。我们将其应用于逐个字符，将短英语句子翻译为短法语句子。需要注意的是，在这个领域里，使用字符级机器翻译是相当不寻常的，因为使用单词级的模型更为常见。</p> 
<p><strong>算法摘要</strong></p> 
<ul><li>我们从一个领域（例如英语句子）的输入序列开始，并从另一个领域（例如法语句子）中获得相应的目标序列。</li><li>一个编码器 LSTM 将输入序列转换为 2 个状态向量（我们保留最后一个 LSTM 状态并丢弃输出）。</li><li>一个解码器 LSTM 被训练，将目标序列转换为相同的序列，但是将时间步向前偏移一个步长，这个训练过程在这个上下文中称为“teacher forcing”。它使用来自编码器的状态向量作为初始状态。实际上，解码器在输入序列的条件下学习生成“targets[t+1…]”给定“targets[…t]”。</li><li>在推理模式下，当我们想要解码未知的输入序列时，我们要做以下操作： 
  <ul><li>编码输入序列为状态向量。</li><li>以大小为 1 的目标序列开始（只有开始字符）。</li><li>将状态向量和 1 个字符的目标序列提供给解码器，生成下一个字符的预测值。</li><li>使用这些预测值采样下一个字符 (我们简单地使用 argmax)。</li><li>将采样的字符添加到目标序列中。</li><li>重复操作，直到生成结束字符或达到字符限制。</li></ul> </li></ul> 
<h3><a id="_18"></a>导入依赖</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras

</code></pre> 
<h3><a id="fraenghttpsdownloadcsdnnetdownloadm0_3757374087893583_27"></a>加载数据：<a href="https://download.csdn.net/download/m0_37573740/87893583">fra-eng</a></h3> 
<p>这是一个包含超过64000个法语-英语单词和短语的Anki词汇卡组，它可以帮助学习者提高词汇量并加强其语言技能。Anki是一种基于记忆卡片的学习方法，被广泛用于学习基础词汇和语法规则。该词汇卡组可以在线或离线使用，并可以导入到Anki应用程序中，以便离线学习。该词汇卡组的单词和短语都包含音频发音，可以帮助学习者正确地发音字词。这里用于机器翻译。</p> 
<pre><code>!!curl -O http://www.manythings.org/anki/fra-eng.zip
!!unzip fra-eng.zip

</code></pre> 
<h3><a id="_37"></a>配置项</h3> 
<p>这些配置决定着模型的参数和训练的行为。在配置模型时，我们需要用经过实验验证的数值来平衡训练时间和模型性能。</p> 
<ul><li><code>latent_dim</code>：这是解码器中LSTM层的隐藏状态的维度大小。通俗地说，这决定了模型学习到的内部表示的复杂度。</li><li><code>num_samples</code>：这是用于训练模型的语料库中的句子数量。更多的语料库可以带来更好的性能，但需要更多的训练时间和计算资源。</li><li><code>batch_size</code>：这是一次传递给模型的句子数。更大的批量可以加速训练，但也可能导致内存不足等问题。</li></ul> 
<pre><code class="prism language-python">batch_size <span class="token operator">=</span> <span class="token number">64</span>  <span class="token comment"># 训练的 batch 大小。</span>
epochs <span class="token operator">=</span> <span class="token number">100</span>  <span class="token comment"># 训练的 epoch 数。</span>
latent_dim <span class="token operator">=</span> <span class="token number">256</span>  <span class="token comment"># 编码器空间的潜在维度。</span>
num_samples <span class="token operator">=</span> <span class="token number">10000</span>  <span class="token comment"># 训练样本数量。</span>
<span class="token comment"># 存储在磁盘上的数据文本文件路径。</span>
data_path <span class="token operator">=</span> <span class="token string">"fra.txt"</span>

</code></pre> 
<h3><a id="_58"></a>数据预处理</h3> 
<p>该部分介绍了 LSTM Seq2Seq 模型中数据的预处理过程，包括读取数据、建立字典、将句子转换为序列、补全序列等操作。其中读取数据时，原始的文本形式数据被转换成形如 [input_text, target_text] 的列表，其中 input_text 和 target_text 分别表示源语言和目标语言的句子。接着建立了源语言和目标语言的字典，并将句子转换为单词序列，同时在序列前后添加特殊标记，使其具有一定的通用性。最后，需要对序列进行补全，以保证所有句子的长度一致。这些预处理操作可以提高模型的训练效果和泛化能力。</p> 
<pre><code class="prism language-python"><span class="token comment"># 对数据进行向量化处理。</span>
input_texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 编码器的输入</span>
target_texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 解码器的目标输出</span>
input_characters <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 所有的输入字符（去重）</span>
target_characters <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 所有的输出字符（去重）</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span> <span class="token comment"># 读取数据</span>
    lines <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    input_text<span class="token punctuation">,</span> target_text<span class="token punctuation">,</span> _ <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
    <span class="token comment"># 将"\t"作为目标文本的"开始序列"字符，将"\n"作为"结束序列"字符。</span>
    target_text <span class="token operator">=</span> <span class="token string">"\t"</span> <span class="token operator">+</span> target_text <span class="token operator">+</span> <span class="token string">"\n"</span>
    input_texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_text<span class="token punctuation">)</span>
    target_texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>target_text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> char <span class="token keyword">in</span> input_text<span class="token punctuation">:</span>
        <span class="token keyword">if</span> char <span class="token keyword">not</span> <span class="token keyword">in</span> input_characters<span class="token punctuation">:</span> <span class="token comment"># 若当前字符不在输入字符集中，则添加进去</span>
            input_characters<span class="token punctuation">.</span>add<span class="token punctuation">(</span>char<span class="token punctuation">)</span>
    <span class="token keyword">for</span> char <span class="token keyword">in</span> target_text<span class="token punctuation">:</span>
        <span class="token keyword">if</span> char <span class="token keyword">not</span> <span class="token keyword">in</span> target_characters<span class="token punctuation">:</span> <span class="token comment"># 若当前字符不在输出字符集中，则添加进去</span>
            target_characters<span class="token punctuation">.</span>add<span class="token punctuation">(</span>char<span class="token punctuation">)</span>

<span class="token comment"># 将字符集按英文字母表顺序排序，并给每个字符赋一个数字作为索引，即编码</span>
input_characters <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>input_characters<span class="token punctuation">)</span><span class="token punctuation">)</span>
target_characters <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>target_characters<span class="token punctuation">)</span><span class="token punctuation">)</span>
num_encoder_tokens <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_characters<span class="token punctuation">)</span> <span class="token comment"># 输入字符数量</span>
num_decoder_tokens <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>target_characters<span class="token punctuation">)</span> <span class="token comment"># 输出字符数量</span>
max_encoder_seq_length <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>txt<span class="token punctuation">)</span> <span class="token keyword">for</span> txt <span class="token keyword">in</span> input_texts<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 最大输入序列长度</span>
max_decoder_seq_length <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>txt<span class="token punctuation">)</span> <span class="token keyword">for</span> txt <span class="token keyword">in</span> target_texts<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 最大输出序列长度</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Number of samples:"</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_texts<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Number of unique input tokens:"</span><span class="token punctuation">,</span> num_encoder_tokens<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Number of unique output tokens:"</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Max sequence length for inputs:"</span><span class="token punctuation">,</span> max_encoder_seq_length<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Max sequence length for outputs:"</span><span class="token punctuation">,</span> max_decoder_seq_length<span class="token punctuation">)</span>

<span class="token comment"># 编码器的输入要进行one-hot编码。</span>
input_token_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>char<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> char <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>input_characters<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 解码器的输入和输出都要进行one-hot编码。</span>
target_token_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>char<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> char <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>target_characters<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

encoder_input_data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_texts<span class="token punctuation">)</span><span class="token punctuation">,</span> max_encoder_seq_length<span class="token punctuation">,</span> num_encoder_tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float32"</span>
<span class="token punctuation">)</span>
decoder_input_data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_texts<span class="token punctuation">)</span><span class="token punctuation">,</span> max_decoder_seq_length<span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float32"</span>
<span class="token punctuation">)</span>
decoder_target_data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_texts<span class="token punctuation">)</span><span class="token punctuation">,</span> max_decoder_seq_length<span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float32"</span>
<span class="token punctuation">)</span>

<span class="token comment"># 构建编码器和解码器输入、输出数据</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_text<span class="token punctuation">,</span> target_text<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>input_texts<span class="token punctuation">,</span> target_texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> t<span class="token punctuation">,</span> char <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>input_text<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 对于输入文本中的每个字符</span>
        encoder_input_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t<span class="token punctuation">,</span> input_token_index<span class="token punctuation">[</span>char<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token comment"># 将该字符的one-hot向量赋值给输入数据中相应的位置</span>
    encoder_input_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t <span class="token operator">+</span> <span class="token number">1</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> input_token_index<span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token comment"># 将剩余的位置赋值为空格（padding的作用）</span>
    <span class="token keyword">for</span> t<span class="token punctuation">,</span> char <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>target_text<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 对于目标文本中的每个字符</span>
        <span class="token comment"># 解码器的输入和目标输出相差一个时间步</span>
        decoder_input_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t<span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span>char<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token comment"># 将该字符的one-hot向量赋值给解码器输入数据中相应的位置</span>
        <span class="token keyword">if</span> t <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># 从第二个字符开始，目标输出才能在当前时间步进行预测</span>
            <span class="token comment"># decoder_target_data的时间步比decoder_input_data多1，且不需要起始序列字符</span>
            <span class="token comment"># 因此需要将解码器目标输出的one-hot向量赋值给decoder_target_data中的上一个时间步</span>
            decoder_target_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span>char<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>
    decoder_input_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t <span class="token operator">+</span> <span class="token number">1</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>
    decoder_target_data<span class="token punctuation">[</span>i<span class="token punctuation">,</span> t<span class="token punctuation">:</span><span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

</code></pre> 
<h3><a id="_130"></a>定义模型</h3> 
<p>这部分代码主要是使用Keras构建了一个LSTM Seq2Seq模型，将一个序列映射到另一个序列。简单的说，就是将输入语句翻译成另外一种语言。在该模型中主要分为编码器和解码器两个部分，建议在理解代码和注释后再进行深入学习。</p> 
<pre><code class="prism language-python"><span class="token comment"># 定义输入序列并对其进行处理</span>
encoder_inputs <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_encoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># encoder_inputs是输入序列，维度为 (None, num_encoder_tokens)</span>
encoder <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> return_state<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 用LSTM层对输入序列进行处理，返回输出和状态</span>
encoder_outputs<span class="token punctuation">,</span> state_h<span class="token punctuation">,</span> state_c <span class="token operator">=</span> encoder<span class="token punctuation">(</span>encoder_inputs<span class="token punctuation">)</span> 

<span class="token comment"># 我们丢弃encoder_outputs，只保留状态</span>
encoder_states <span class="token operator">=</span> <span class="token punctuation">[</span>state_h<span class="token punctuation">,</span> state_c<span class="token punctuation">]</span>

<span class="token comment"># 设置decoder，并使用encoder_states作为初始状态。</span>
decoder_inputs <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#我们设置decoder返回完整的输出序列和内部状态。我们不在训练模型中使用返回状态，但是在推断时会用到。</span>
decoder_lstm <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_state<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 设置decoder，使用LSTM层，返回完整的输出序列和状态</span>
decoder_outputs<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> decoder_lstm<span class="token punctuation">(</span>decoder_inputs<span class="token punctuation">,</span> initial_state<span class="token operator">=</span>encoder_states<span class="token punctuation">)</span>  <span class="token comment"># decoder_inputs为decoder的输入，initial_state为decoder的初始状态</span>

decoder_dense <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>num_decoder_tokens<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span>  <span class="token comment"># 设置全连接层，输出概率值</span>
decoder_outputs <span class="token operator">=</span> decoder_dense<span class="token punctuation">(</span>decoder_outputs<span class="token punctuation">)</span>  <span class="token comment">#decoder_outputs为decoder的输出序列</span>

<span class="token comment"># 定义模型，将encoder_input_data和decoder_input_data转换为decoder_target_data</span>
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span><span class="token punctuation">[</span>encoder_inputs<span class="token punctuation">,</span> decoder_inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_outputs<span class="token punctuation">)</span>

</code></pre> 
<h3><a id="_158"></a>载入训练好的模型</h3> 
<p>这部分，介绍了如何使用已经训练好的序列到序列模型进行推理，即输入一段源语言文本，输出对应的翻译结果。</p> 
<p>该部分首先加载了之前训练好的模型，包括编码器和解码器。然后，对于给定的源语言（英语）文本输入，通过构建Encoder模型，将其转化为一系列隐状态向量，并将这些状态向量作为输入，通过构建解码器模型，生成目标语言（法语）的翻译结果。其中，在解码器中，使用了beam search的方法来解码，以提高翻译的准确性。</p> 
<p>在代码中，最后提供了一个函数，使得用户可以方便地输入自己的源语言文本，并输出对应的翻译结果。在实际应用中，可以将该函数集成到一个大型的自然语言处理系统中，以提供自然语言翻译的功能，例如在线翻译软件等。</p> 
<ol><li>对输入进行编码并检索初始解码器状态</li><li>在这个初始状态下运行解码器的一个步骤以及作为目标的“序列开始”令牌。输出将是下一个目标令牌。</li><li>对当前目标令牌和当前状态重复</li></ol> 
<pre><code class="prism language-python"><span class="token comment"># 定义采样模型</span>
<span class="token comment"># 恢复模型并构建编码器和解码器</span>
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"s2s"</span><span class="token punctuation">)</span>

<span class="token comment"># 确认输入</span>
encoder_inputs <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># input_1</span>

<span class="token comment"># 获取编码器的输出, 包括两个状态变量 h 和 c</span>
encoder_outputs<span class="token punctuation">,</span> state_h_enc<span class="token punctuation">,</span> state_c_enc <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>output  <span class="token comment"># lstm_1</span>
encoder_states <span class="token operator">=</span> <span class="token punctuation">[</span>state_h_enc<span class="token punctuation">,</span> state_c_enc<span class="token punctuation">]</span> <span class="token comment"># 将状态保持到列表中</span>
encoder_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>encoder_inputs<span class="token punctuation">,</span> encoder_states<span class="token punctuation">)</span> <span class="token comment"># 定义模型的输入和输出</span>

<span class="token comment"># 确认解码器的输入</span>
decoder_inputs <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># input_2</span>

<span class="token comment"># 定义解码器的状态变量</span>
decoder_state_input_h <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
decoder_state_input_c <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
decoder_states_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>decoder_state_input_h<span class="token punctuation">,</span> decoder_state_input_c<span class="token punctuation">]</span> <span class="token comment"># 将状态变量放入列表</span>
decoder_lstm <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token comment"># 导入lstm层</span>
decoder_outputs<span class="token punctuation">,</span> state_h_dec<span class="token punctuation">,</span> state_c_dec <span class="token operator">=</span> decoder_lstm<span class="token punctuation">(</span>
    decoder_inputs<span class="token punctuation">,</span> initial_state<span class="token operator">=</span>decoder_states_inputs <span class="token comment"># 使用传递进来的状态变量作为初始状态</span>
<span class="token punctuation">)</span>
decoder_states <span class="token operator">=</span> <span class="token punctuation">[</span>state_h_dec<span class="token punctuation">,</span> state_c_dec<span class="token punctuation">]</span> <span class="token comment"># 将新的状态值存储到列表中</span>
decoder_dense <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token comment">#定义完全连接层</span>
decoder_outputs <span class="token operator">=</span> decoder_dense<span class="token punctuation">(</span>decoder_outputs<span class="token punctuation">)</span> <span class="token comment"># 初始化完成后，传递到完全连接层中</span>
decoder_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>decoder_inputs<span class="token punctuation">]</span> <span class="token operator">+</span> decoder_states_inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span>decoder_outputs<span class="token punctuation">]</span> <span class="token operator">+</span> decoder_states <span class="token comment"># 定义输入和状态的列表作为输入和输出</span>
<span class="token punctuation">)</span>


<span class="token comment"># Reverse-lookup token index to decode sequences back to</span>
<span class="token comment"># something readable.</span>
<span class="token comment"># 将编码后的数据反转回可读形式的字典</span>
reverse_input_char_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> char<span class="token punctuation">)</span> <span class="token keyword">for</span> char<span class="token punctuation">,</span> i <span class="token keyword">in</span> input_token_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
reverse_target_char_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> char<span class="token punctuation">)</span> <span class="token keyword">for</span> char<span class="token punctuation">,</span> i <span class="token keyword">in</span> target_token_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 解码器解码序列函数</span>
<span class="token keyword">def</span> <span class="token function">decode_sequence</span><span class="token punctuation">(</span>input_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Encode the input as state vectors.</span>
    <span class="token comment"># 对输入进行编码</span>
    states_value <span class="token operator">=</span> encoder_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input_seq<span class="token punctuation">)</span>

    <span class="token comment"># Generate empty target sequence of length 1.</span>
    <span class="token comment"># 生成空的目标序列，并加入开始字符标记</span>
    target_seq <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>
    target_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span><span class="token string">"\t"</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

    <span class="token comment"># Sampling loop for a batch of sequences</span>
    <span class="token comment"># (to simplify, here we assume a batch of size 1).</span>
    <span class="token comment"># 采样循环</span>
    stop_condition <span class="token operator">=</span> <span class="token boolean">False</span>
    decoded_sentence <span class="token operator">=</span> <span class="token string">""</span>
    <span class="token keyword">while</span> <span class="token keyword">not</span> stop_condition<span class="token punctuation">:</span>
        output_tokens<span class="token punctuation">,</span> h<span class="token punctuation">,</span> c <span class="token operator">=</span> decoder_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>target_seq<span class="token punctuation">]</span> <span class="token operator">+</span> states_value<span class="token punctuation">)</span>

        <span class="token comment"># Sample a token</span>
        <span class="token comment"># 采样一个标记</span>
        sampled_token_index <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        sampled_char <span class="token operator">=</span> reverse_target_char_index<span class="token punctuation">[</span>sampled_token_index<span class="token punctuation">]</span>
        decoded_sentence <span class="token operator">+=</span> sampled_char

        <span class="token comment"># Exit condition: either hit max length</span>
        <span class="token comment"># or find stop character.</span>
        <span class="token comment"># 终止条件有两个，一个是采样的字符达到规定的长度，另一个是采样的字符为终止字符</span>
        <span class="token keyword">if</span> sampled_char <span class="token operator">==</span> <span class="token string">"\n"</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span>decoded_sentence<span class="token punctuation">)</span> <span class="token operator">&gt;</span> max_decoder_seq_length<span class="token punctuation">:</span>
            stop_condition <span class="token operator">=</span> <span class="token boolean">True</span>

        <span class="token comment"># Update the target sequence (of length 1).</span>
        <span class="token comment"># 更新目标序列，输入采样的字符，并使用新的标记为输入进入下一轮采样循环</span>
        target_seq <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>
        target_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> sampled_token_index<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

        <span class="token comment"># Update states</span>
        <span class="token comment"># 更新状态变量</span>
        states_value <span class="token operator">=</span> <span class="token punctuation">[</span>h<span class="token punctuation">,</span> c<span class="token punctuation">]</span>
    <span class="token keyword">return</span> decoded_sentence
<span class="token comment"># 定义采样模型</span>
<span class="token comment"># 恢复模型并构建编码器和解码器</span>
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"s2s"</span><span class="token punctuation">)</span>

<span class="token comment"># 确认输入</span>
encoder_inputs <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># input_1</span>

<span class="token comment"># 获取编码器的输出, 包括两个状态变量 h 和 c</span>
encoder_outputs<span class="token punctuation">,</span> state_h_enc<span class="token punctuation">,</span> state_c_enc <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>output  <span class="token comment"># lstm_1</span>
encoder_states <span class="token operator">=</span> <span class="token punctuation">[</span>state_h_enc<span class="token punctuation">,</span> state_c_enc<span class="token punctuation">]</span> <span class="token comment"># 将状态保持到列表中</span>
encoder_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>encoder_inputs<span class="token punctuation">,</span> encoder_states<span class="token punctuation">)</span> <span class="token comment"># 定义模型的输入和输出</span>

<span class="token comment"># 确认解码器的输入</span>
decoder_inputs <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># input_2</span>

<span class="token comment"># 定义解码器的状态变量</span>
decoder_state_input_h <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
decoder_state_input_c <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
decoder_states_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>decoder_state_input_h<span class="token punctuation">,</span> decoder_state_input_c<span class="token punctuation">]</span> <span class="token comment"># 将状态变量放入列表</span>
decoder_lstm <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token comment"># 导入lstm层</span>
decoder_outputs<span class="token punctuation">,</span> state_h_dec<span class="token punctuation">,</span> state_c_dec <span class="token operator">=</span> decoder_lstm<span class="token punctuation">(</span>
    decoder_inputs<span class="token punctuation">,</span> initial_state<span class="token operator">=</span>decoder_states_inputs <span class="token comment"># 使用传递进来的状态变量作为初始状态</span>
<span class="token punctuation">)</span>
decoder_states <span class="token operator">=</span> <span class="token punctuation">[</span>state_h_dec<span class="token punctuation">,</span> state_c_dec<span class="token punctuation">]</span> <span class="token comment"># 将新的状态值存储到列表中</span>
decoder_dense <span class="token operator">=</span> model<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token comment">#定义完全连接层</span>
decoder_outputs <span class="token operator">=</span> decoder_dense<span class="token punctuation">(</span>decoder_outputs<span class="token punctuation">)</span> <span class="token comment"># 初始化完成后，传递到完全连接层中</span>
decoder_model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>decoder_inputs<span class="token punctuation">]</span> <span class="token operator">+</span> decoder_states_inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span>decoder_outputs<span class="token punctuation">]</span> <span class="token operator">+</span> decoder_states <span class="token comment"># 定义输入和状态的列表作为输入和输出</span>
<span class="token punctuation">)</span>


<span class="token comment"># Reverse-lookup token index to decode sequences back to</span>
<span class="token comment"># something readable.</span>
<span class="token comment"># 将编码后的数据反转回可读形式的字典</span>
reverse_input_char_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> char<span class="token punctuation">)</span> <span class="token keyword">for</span> char<span class="token punctuation">,</span> i <span class="token keyword">in</span> input_token_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
reverse_target_char_index <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> char<span class="token punctuation">)</span> <span class="token keyword">for</span> char<span class="token punctuation">,</span> i <span class="token keyword">in</span> target_token_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 解码器解码序列函数</span>
<span class="token keyword">def</span> <span class="token function">decode_sequence</span><span class="token punctuation">(</span>input_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Encode the input as state vectors.</span>
    <span class="token comment"># 对输入进行编码</span>
    states_value <span class="token operator">=</span> encoder_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input_seq<span class="token punctuation">)</span>

    <span class="token comment"># Generate empty target sequence of length 1.</span>
    <span class="token comment"># 生成空的目标序列，并加入开始字符标记</span>
    target_seq <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>
    target_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> target_token_index<span class="token punctuation">[</span><span class="token string">"\t"</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

    <span class="token comment"># Sampling loop for a batch of sequences</span>
    <span class="token comment"># (to simplify, here we assume a batch of size 1).</span>
    <span class="token comment"># 采样循环</span>
    stop_condition <span class="token operator">=</span> <span class="token boolean">False</span>
    decoded_sentence <span class="token operator">=</span> <span class="token string">""</span>
    <span class="token keyword">while</span> <span class="token keyword">not</span> stop_condition<span class="token punctuation">:</span>
        output_tokens<span class="token punctuation">,</span> h<span class="token punctuation">,</span> c <span class="token operator">=</span> decoder_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>target_seq<span class="token punctuation">]</span> <span class="token operator">+</span> states_value<span class="token punctuation">)</span>

        <span class="token comment"># Sample a token</span>
        <span class="token comment"># 采样一个标记</span>
        sampled_token_index <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        sampled_char <span class="token operator">=</span> reverse_target_char_index<span class="token punctuation">[</span>sampled_token_index<span class="token punctuation">]</span>
        decoded_sentence <span class="token operator">+=</span> sampled_char

        <span class="token comment"># Exit condition: either hit max length</span>
        <span class="token comment"># or find stop character.</span>
        <span class="token comment"># 终止条件有两个，一个是采样的字符达到规定的长度，另一个是采样的字符为终止字符</span>
        <span class="token keyword">if</span> sampled_char <span class="token operator">==</span> <span class="token string">"\n"</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span>decoded_sentence<span class="token punctuation">)</span> <span class="token operator">&gt;</span> max_decoder_seq_length<span class="token punctuation">:</span>
            stop_condition <span class="token operator">=</span> <span class="token boolean">True</span>

        <span class="token comment"># Update the target sequence (of length 1).</span>
        <span class="token comment"># 更新目标序列，输入采样的字符，并使用新的标记为输入进入下一轮采样循环</span>
        target_seq <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_decoder_tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>
        target_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> sampled_token_index<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

        <span class="token comment"># Update states</span>
        <span class="token comment"># 更新状态变量</span>
        states_value <span class="token operator">=</span> <span class="token punctuation">[</span>h<span class="token punctuation">,</span> c<span class="token punctuation">]</span>
    <span class="token keyword">return</span> decoded_sentence

</code></pre> 
<p>调用函数翻译语句：</p> 
<ul><li><code>seq_index</code> 是当前选取的序列的索引。</li><li><code>encoder_input_data</code> 是编码器输入的数据。</li><li><code>input_seq = encoder_input_data[seq_index : seq_index + 1]</code> 选取一个序列，注意这里是选取一个序列而不是一组序列，所以需要添加一个维度。</li><li><code>decoded_sentence = decode_sequence(input_seq)</code> 解码这个序列，得到解码后的句子。</li><li><code>print("-")</code> 打印一个分隔行。</li><li><code>print("输入的句子:", input_texts[seq_index])</code> 打印输入的句子。</li><li><code>print("解码后的句子:", decoded_sentence)</code> 打印解码后的句子。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">for</span> seq_index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 选取一个序列（训练集中的一部分）</span>
    <span class="token comment"># 用于尝试解码。</span>
    input_seq <span class="token operator">=</span> encoder_input_data<span class="token punctuation">[</span>seq_index <span class="token punctuation">:</span> seq_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
    decoded_sentence <span class="token operator">=</span> decode_sequence<span class="token punctuation">(</span>input_seq<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输入的句子:"</span><span class="token punctuation">,</span> input_texts<span class="token punctuation">[</span>seq_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"解码后的句子:"</span><span class="token punctuation">,</span> decoded_sentence<span class="token punctuation">)</span>

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c1484b5c5f9b0c5f9ae4bd85e35f7174/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">获取网卡ip地址代码实现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/78aa419bcf9d4e94ffaac79161150a5f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">第十四届蓝桥杯大赛软件组国赛 Python大学A组 个人暴力题解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>