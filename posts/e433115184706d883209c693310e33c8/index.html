<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TensorRT安装及验证 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TensorRT安装及验证" />
<meta property="og:description" content="博主的一些基本环境配置可见之前博客非虚拟机环境下Ubuntu配置_jiugeshao的专栏-CSDN博客
TensorRT的介绍见之前博客，TensorRT的安装、TensorRT如何加速Pytorch、Tensorflow、Caffe等框架模型的资料还不是很多,建议还是先多看看官网提供的手册，原汁原味。
Developer Guide :: NVIDIA Deep Learning TensorRT Documentationhttps://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html整了那么多东西之后发现，掌握了多少东西并不重要，快速获取知识的能力才是重要的，要善于从一些官网手册中获取最原始的资料。（博主工作中也经常需要这种探索，无人告知，只能自己去琢磨探索，无形之中适应了这种节奏）
这里安装Anaconda是为了在其python环境里去验证下cuda和cudnn是否配置成功了，同时后面系列博客的python环境也是在通过此Anaconda版本配置
第一步: 准备安装Anaconda
Index of /anaconda/archive/ | 清华大学开源软件镜像站 | Tsinghua Open Source MirrorIndex of /anaconda/archive/ | 清华大学开源软件镜像站，致力于为国内和校内用户提供高质量的开源软件镜像、Linux 镜像源服务，帮助用户更方便地获取开源软件。本镜像站由清华大学 TUNA 协会负责运行维护。https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/下载3.5.2版本，完毕后，cd到文件所在目录下，输入如下命令进行安装
bash Anaconda3-5.2.0-Linux-x86_64.sh 按照提示操作即可，到如下信息提示的时候，输入no,完成安装。
重启终端后，输入python,看到如下信息：
第二步：安装显卡驱动
先增加如下的源
sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt update 如下命令检查可以安装的驱动版本
ubuntu-drivers devices 出现如下信息：
博主这里选择推荐的那一个驱动版本，如下命令进行安装
sudo apt install nvidia-driver-470 安装前输入nvidia-smi，会出现如下信息：
安装完毕后，输入nvidia-smi
第三步：安装cuda
CUDA Toolkit Archive | NVIDIA Developerhttps://developer.nvidia.com/cuda-toolkit-archive网页上下载cuda11.0
选择配置后，按照提示执行两条命令语句进行下载安装
wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda_11.0.2_450.51.05_linux.run sh cuda_11.0.2_450.51.05_linux.run 安装就按照指引来就行了，注意到如下时，去掉驱动安装的选择，因为前面显卡驱动已经安装好了，在每个选项前面enter下即可以选择安装还是不安装
安装完毕后，配置下环境变量
sudo gedit ~/." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/e433115184706d883209c693310e33c8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-18T14:46:27+08:00" />
<meta property="article:modified_time" content="2022-06-18T14:46:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TensorRT安装及验证</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>博主的一些基本环境配置可见之前博客<a href="https://blog.csdn.net/jiugeshao/article/details/122969766?spm=1001.2014.3001.5501" title="非虚拟机环境下Ubuntu配置_jiugeshao的专栏-CSDN博客">非虚拟机环境下Ubuntu配置_jiugeshao的专栏-CSDN博客</a></p> 
<p>TensorRT的介绍见之前<a class="link-info" href="https://blog.csdn.net/jiugeshao/article/details/122888437?spm=1001.2014.3001.5501" title="博客">博客</a>，TensorRT的安装、TensorRT如何加速Pytorch、Tensorflow、Caffe等框架模型的资料还不是很多,建议还是先多看看官网提供的手册，原汁原味。</p> 
<p><a class="has-card" href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html" rel="nofollow" title="Developer Guide :: NVIDIA Deep Learning TensorRT Documentation"><span class="link-card-box"><span class="link-title">Developer Guide :: NVIDIA Deep Learning TensorRT Documentation</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/7f/66/0RZQW2DB_o.png">https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html</span></span></a>整了那么多东西之后发现，掌握了多少东西并不重要，快速获取知识的能力才是重要的，要善于从一些官网手册中获取最原始的资料。（博主工作中也经常需要这种探索，无人告知，只能自己去琢磨探索，无形之中适应了这种节奏）</p> 
<p><span style="color:#fe2c24;">这里安装Anaconda是为了在其python环境里去验证下cuda和cudnn是否配置成功了，同时后面系列博客的python环境也是在通过此Anaconda版本配置</span></p> 
<p><strong>第一步: 准备安装Anaconda</strong></p> 
<p><a class="has-card" href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" rel="nofollow" title="Index of /anaconda/archive/ | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror"><span class="link-card-box"><span class="link-title">Index of /anaconda/archive/ | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror</span><span class="link-desc">Index of /anaconda/archive/ | 清华大学开源软件镜像站，致力于为国内和校内用户提供高质量的开源软件镜像、Linux 镜像源服务，帮助用户更方便地获取开源软件。本镜像站由清华大学 TUNA 协会负责运行维护。</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/d0/1f/Ft23PATZ_o.png">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</span></span></a>下载3.5.2版本，完毕后，cd到文件所在目录下，输入如下命令进行安装</p> 
<pre><code>bash Anaconda3-5.2.0-Linux-x86_64.sh
</code></pre> 
<p>按照提示操作即可，到如下信息提示的时候，输入no,完成安装。</p> 
<p><img alt="" height="92" src="https://images2.imgbox.com/eb/41/FPKGBtTs_o.png" width="712"></p> 
<p>重启终端后，输入python,看到如下信息：</p> 
<p><img alt="" height="120" src="https://images2.imgbox.com/70/ad/EHz6HZCk_o.png" width="676"></p> 
<p></p> 
<p><strong>第二步：安装显卡驱动</strong></p> 
<p>先增加如下的源</p> 
<pre><code>sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt update</code></pre> 
<p>如下命令检查可以安装的驱动版本</p> 
<pre><code>ubuntu-drivers devices</code></pre> 
<p>出现如下信息：<img alt="" height="248" src="https://images2.imgbox.com/41/ff/tGtiaGWN_o.png" width="734"></p> 
<p> 博主这里选择推荐的那一个驱动版本，如下命令进行安装</p> 
<pre><code>sudo apt install nvidia-driver-470</code></pre> 
<p> 安装前输入nvidia-smi，会出现如下信息：</p> 
<p><img alt="" height="64" src="https://images2.imgbox.com/41/dc/35oTTgu7_o.png" width="732"></p> 
<p>安装完毕后，输入nvidia-smi</p> 
<p><img alt="" height="235" src="https://images2.imgbox.com/3c/34/EleWLa2k_o.png" width="721"></p> 
<p></p> 
<p><strong>第三步：安装cuda</strong></p> 
<p><a class="has-card" href="https://developer.nvidia.com/cuda-toolkit-archive" rel="nofollow" title="CUDA Toolkit Archive | NVIDIA Developer"><span class="link-card-box"><span class="link-title">CUDA Toolkit Archive | NVIDIA Developer</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/2e/2d/BSojDAjd_o.png">https://developer.nvidia.com/cuda-toolkit-archive</span></span></a>网页上下载cuda11.0</p> 
<p style="text-align:center;"><img alt="" height="317" src="https://images2.imgbox.com/46/e6/gxXtuIDr_o.png" width="583"></p> 
<p>选择配置后，按照提示执行两条命令语句进行下载安装</p> 
<pre><code>wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda_11.0.2_450.51.05_linux.run
sh cuda_11.0.2_450.51.05_linux.run</code></pre> 
<p>安装就按照指引来就行了，注意到如下时，去掉驱动安装的选择，因为前面显卡驱动已经安装好了，在每个选项前面enter下即可以选择安装还是不安装</p> 
<p style="text-align:center;"><img alt="" height="365" src="https://images2.imgbox.com/81/b4/We0gm2vy_o.png" width="559"></p> 
<p> 安装完毕后，配置下环境变量</p> 
<pre><code>sudo gedit ~/.bashrc</code></pre> 
<pre><code>export PATH=/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/nsight-compute-2020.1.1${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.0/extras/CUPTI/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}</code></pre> 
<pre><code>sudo source ~/.bashrc</code></pre> 
<p style="text-align:center;"><img alt="" height="124" src="https://images2.imgbox.com/d5/4e/swIl3hJ6_o.png" width="542"></p> 
<p>可以运行下cuda自带的sample示例</p> 
<pre><code>cd /usr/local/cuda-11.0/samples/1_Utilities/deviceQuery
sudo make
./deviceQuery</code></pre> 
<p><img alt="" height="376" src="https://images2.imgbox.com/6e/50/FRzULIaV_o.png" width="792"></p> 
<p> 成功安装</p> 
<p>若要卸载可以参考博客，亲测是可以的。<a href="https://blog.csdn.net/weixin_44711603/article/details/110233047" title="ubuntu完全卸载CUDA_Venquieu的博客-CSDN博客_ubuntu卸载cuda">ubuntu完全卸载CUDA_Venquieu的博客-CSDN博客_ubuntu卸载cuda</a></p> 
<p></p> 
<p><strong>第四步：安装cudnn</strong></p> 
<p><a class="has-card" href="https://developer.nvidia.com/rdp/cudnn-archive" rel="nofollow" title="cuDNN Archive | NVIDIA Developer"><span class="link-card-box"><span class="link-title">cuDNN Archive | NVIDIA Developer</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/98/ef/dgR5sO4B_o.png">https://developer.nvidia.com/rdp/cudnn-archive</span></span></a>下载cudnn8.0版本，选择Linux(x86_64)版本</p> 
<p style="text-align:center;"><img alt="" height="237" src="https://images2.imgbox.com/0c/77/6pdcQ3Df_o.png" width="963"></p> 
<p> 下载完毕后解压，cd到所下载的文件夹目录下</p> 
<pre><code>cd /home/sxhlvye/Downloads/cudnn-11.0-linux-x64-v8.0.5.39</code></pre> 
<p> 然后执行如下命令，替换cuda中的和神经网络相关的库和文件</p> 
<pre><code>sudo cp cuda/include/cudnn.h /usr/local/cuda-11.0/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda-11.0/lib64
sudo chmod a+r /usr/local/cuda-11.0/include/cudnn.h 
sudo chmod a+r /usr/local/cuda-11.0/lib64/libcudnn*</code></pre> 
<p> 验证：</p> 
<p>在Anaconda3的python环境下安装库</p> 
<pre><code>pip install tensorflow-gpu==2.4.0
</code></pre> 
<p>tensorflow和cuda、cudnn之间的对应关系可见网址<a href="https://tensorflow.google.cn/install/source#gpu_support_2" rel="nofollow" title="从源代码构建  |  TensorFlow">从源代码构建  |  TensorFlow</a></p> 
<p>安装完毕后执行如下语句：</p> 
<pre><code>import tensorflow as tf
sess = tf.compat.v1.Session()</code></pre> 
<p>输入如下信息,成功安装：</p> 
<p><img alt="" height="394" src="https://images2.imgbox.com/9f/4c/yAca7rtG_o.png" width="1006"></p> 
<p></p> 
<p><strong>第五步：安装TensorRT</strong></p> 
<p><span style="color:#fe2c24;">官网上介绍了好几种装方式，博主使用的是从tar文件进行安装</span></p> 
<p>Installation Guide :: NVIDIA Deep Learning TensorRT Documentation</p> 
<p style="text-align:center;"><img alt="" height="115" src="https://images2.imgbox.com/42/51/qnzgck03_o.png" width="462"></p> 
<p></p> 
<p>如下网页上进行下载</p> 
<p><a class="has-card" href="https://developer.nvidia.com/nvidia-tensorrt-download" rel="nofollow" title="https://developer.nvidia.com/nvidia-tensorrt-download"><span class="link-card-box"><span class="link-title">https://developer.nvidia.com/nvidia-tensorrt-download</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/f0/4b/HkOyrBcD_o.png">https://developer.nvidia.com/nvidia-tensorrt-download</span></span></a></p> 
<p style="text-align:center;"><img alt="" height="276" src="https://images2.imgbox.com/8c/42/FTVN7Dkv_o.png" width="506"></p> 
<p></p> 
<p>1. 解压下载的文件</p> 
<pre><code>tar -xzvf TensorRT-8.0.0.3.Linux.x86_64-gnu.cuda-11.0.cudnn8.2.tar.gz
</code></pre> 
<p>解压后的文件夹名为 ensorRT-8.0.0.3</p> 
<p style="text-align:center;"><img alt="" height="125" src="https://images2.imgbox.com/7b/20/kcAogoIC_o.png" width="253"></p> 
<p>2. 添加环境变量</p> 
<pre><code>sudo gedit ~/.bashrc</code></pre> 
<pre><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/sxhlvye/Downloads/TensorRT-8.0.0.3/lib</code></pre> 
<pre><code>source ~/.bashrc</code></pre> 
<p><img alt="" height="183" src="https://images2.imgbox.com/27/f1/dJKzgMat_o.png" width="942"></p> 
<p></p> 
<p>3.这里先省去给python添加TensorRT的库，后面博客会用到，到时候再说</p> 
<p></p> 
<p><strong><span style="color:#fe2c24;">验证：</span></strong></p> 
<p>这里跑下其自带的例子sampleMNIST,路径如下</p> 
<pre><code>cd /home/sxhlvye/Downloads/TensorRT-8.0.0.3/samples/sampleMNIST</code></pre> 
<p>然后直接输入make进行编译，完毕后会在路径/home/sxhlvye/Downloads/TensorRT-8.0.0.3/bin下看到编译好的可执行文件</p> 
<p style="text-align:center;"><img alt="" height="172" src="https://images2.imgbox.com/43/cf/C08ek4sJ_o.png" width="574"></p> 
<pre><code>./sample_mnist</code></pre> 
<p>输出如下信息：</p> 
<p style="text-align:center;"><img alt="" height="367" src="https://images2.imgbox.com/b4/7f/bMFsgypd_o.png" width="581"></p> 
<p> 该自带例子演示了如何用用TensorRT在预测阶段如何加快caffe模型对一张图片的预测时间，默认参数下，其会利用路径下/home/sxhlvye/Downloads/TensorRT-8.0.0.3/data/mnist下的deploy.prototxt、mnist.caffemodel、mnist_mean.binaryproto来对该目录下的一张图片预测结果</p> 
<p><img alt="" height="392" src="https://images2.imgbox.com/c4/c3/DXv7SeNg_o.png" width="872"></p> 
<p>预测结果以一堆字符堆积形状而成。</p> 
<p>Caffe的一些知识点可见我之前博客<a class="has-card" href="https://blog.csdn.net/jiugeshao/article/details/104072324" title="Caffe基础（二）-使用命令行方式训练预测mnist、cifar10及自己的数据集_jiugeshao的专栏-CSDN博客"><span class="link-card-box"><span class="link-title">Caffe基础（二）-使用命令行方式训练预测mnist、cifar10及自己的数据集_jiugeshao的专栏-CSDN博客</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/4c/0e/muYYLaja_o.png">https://blog.csdn.net/jiugeshao/article/details/104072324</span></span></a></p> 
<p>接下来会有系列博客，基本就是围绕如何使用TensorRT来加速各框架训练出来的模型（预测一张图片的速度）</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p><strong><span style="color:#fe2c24;">补充：</span></strong></p> 
<p>nvcc -V可以查看cuda的版本</p> 
<p><img alt="" height="130" src="https://images2.imgbox.com/cf/50/dWh8GN6h_o.png" width="720"></p> 
<p> cudnn的版本要去看cudnn_version.h, 但我们一般只是拷贝cudnn.h文件到cuda的文件夹下，然后cudnn的下载文件夹可能也被删掉了，就没有办法查看了</p> 
<p class="img-center"><img alt="" height="216" src="https://images2.imgbox.com/96/1a/eIakTykq_o.png" width="515"></p> 
<p> 此时也可以通过执行加载tensorrt模型脚本</p> 
<pre><code class="language-python">import torch
import torchvision
from PIL import Image
from torchvision import transforms
import torchvision.models as models
import matplotlib.pyplot as plt
import time
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import pdb
import os
import numpy as np
import cv2

# This logger is required to build an engine
TRT_LOGGER = trt.Logger()

filename = "2008_002682.jpg"
engine_file_path = "vgg16.trt"

class HostDeviceMem(object):
    def __init__(self, host_mem, device_mem):
        """Within this context, host_mom means the cpu memory and device means the GPU memory
        """
        self.host = host_mem
        self.device = device_mem
    def __str__(self):
        return "Host:\n" + str(self.host) + "\nDevice:\n" + str(self.device)
    def __repr__(self):
        return self.__str__()

def allocate_buffers(engine):
    inputs = []
    outputs = []
    bindings = []
    stream = cuda.Stream()
    for binding in engine:
        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size
        dtype = trt.nptype(engine.get_binding_dtype(binding))
        # Allocate host and device buffers
        host_mem = cuda.pagelocked_empty(size, dtype)
        device_mem = cuda.mem_alloc(host_mem.nbytes)
        # Append the device buffer to device bindings.
        bindings.append(int(device_mem))
        # Append to the appropriate list.
        if engine.binding_is_input(binding):
            inputs.append(HostDeviceMem(host_mem, device_mem))
        else:
            outputs.append(HostDeviceMem(host_mem, device_mem))

    return inputs, outputs, bindings, stream

print("Reading engine from file {}".format(engine_file_path))
with open(engine_file_path, "rb") as f, trt.Runtime(TRT_LOGGER) as runtime:
    engine =  runtime.deserialize_cuda_engine(f.read())

#create the context for this engine
context = engine.create_execution_context()

# #allocate buffers for input and output
inputs, outputs, bindings, stream = allocate_buffers(engine) # input, output: host # bindings

</code></pre> 
<p>结果如下：</p> 
<pre><code>/home/sxhlvye/anaconda3/envs/pytorch-yolo/bin/python /home/sxhlvye/Trial/yolov3-9.5.0/test_logger.py
Reading engine from file vgg16.trt
[TensorRT] WARNING: TensorRT was linked against cuBLAS/cuBLAS LT 11.2.0 but loaded cuBLAS/cuBLAS LT 11.1.0
[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.0 but loaded cuDNN 8.0.5
[TensorRT] WARNING: TensorRT was linked against cuBLAS/cuBLAS LT 11.2.0 but loaded cuBLAS/cuBLAS LT 11.1.0
[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.0 but loaded cuDNN 8.0.5

Process finished with exit code 0
</code></pre> 
<p>从上面的提醒可以看到当前配置所用的cudnn版本</p> 
<p></p> 
<p><span style="color:#fe2c24;">注意执行如下脚本查看到的cuda和cudnn版本不是你通过上面配置的cuda、cudnn版本，而是库里自带的版本。</span></p> 
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-
# author：Icecream.Shao
import torch
import torchvision
from torch import nn

print(torch.cuda.is_available()) #判断是否支持cuda
print(torch.cuda.device_count()) #当前支持cuda的硬件个数
print(torch.version.cuda)
print(torch.backends.cudnn.version())

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") #选择一个gpu
print(device)
used_gpu_name = torch.cuda.get_device_name(device) #获取所选择的gpu名字
print(used_gpu_name)

#print的常用语法
n=3
print('The squre of',n,'is',n*n)
print('The squre of ' + str(n) + ' is ' + str(n*n))
print('The squre of %s is %s' % (n,n*n))
print('The squre of {1} is {0}'.format(n*n, n))
print(f'model cost:{0.3:.3f}s')

#内置模型的加载方法
#vgg16 = torchvision.models.vgg16(pretrained=True).cuda()
# vgg16 = torchvision.models.vgg16(pretrained=True).to(device)
# print(vgg16)
#
# #增加层以及修改层参数
# vgg16.classifier.add_module('my_linear', nn.Linear(1000, 10))
# vgg16.classifier[7] = nn.Linear(1000,2)
# print(vgg16)

#内置数据集的获取方法
#train_data = torchvision.datasets.CIFAR10("./data",train=True,transform=torchvision.transforms.ToTensor)
#print("load ok")</code></pre> 
<p>执行结果如下：</p> 
<pre><code>/home/sxhlvye/anaconda3/envs/pytorch-yolo/bin/python /home/sxhlvye/Trial/yolov3-9.5.0/test_pytorch.py
True
1
11.0
8005
cuda:0
NVIDIA GeForce GTX 1660 Ti with Max-Q Design
The squre of 3 is 9
The squre of 3 is 9
The squre of 3 is 9
The squre of 3 is 9
model cost:0.300s

Process finished with exit code 0
</code></pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d0b752f06031bf281d2f401d93bf1513/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">《数据结构：c语言版》（严蔚敏）知识点整合</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3bc34cd95770d2b11f043d5839d3f545/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ANSI Common Lisp Chapter 2 习题参考答案</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>