<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg开发XPlay2.0播放器-02 FFmpeg解封装 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg开发XPlay2.0播放器-02 FFmpeg解封装" />
<meta property="og:description" content="avformat_open_input /** * Open an input stream and read the header. The codecs are not opened. * The stream must be closed with avformat_close_input(). * * @param ps Pointer to user-supplied AVFormatContext (allocated by avformat_alloc_context). * May be a pointer to NULL, in which case an AVFormatContext is allocated by this * function and written into ps. * Note that a user-supplied AVFormatContext will be freed on failure. * @param url URL of the stream to open." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/50ba762908ac90def4e33257fd922b72/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-03T07:30:29+08:00" />
<meta property="article:modified_time" content="2021-05-03T07:30:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg开发XPlay2.0播放器-02 FFmpeg解封装</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>avformat_open_input</h4> 
<pre><code>/**
 * Open an input stream and read the header. The codecs are not opened.
 * The stream must be closed with avformat_close_input().
 *
 * @param ps Pointer to user-supplied AVFormatContext (allocated by avformat_alloc_context).
 *           May be a pointer to NULL, in which case an AVFormatContext is allocated by this
 *           function and written into ps.
 *           Note that a user-supplied AVFormatContext will be freed on failure.
 * @param url URL of the stream to open.
 * @param fmt If non-NULL, this parameter forces a specific input format.
 *            Otherwise the format is autodetected.
 * @param options  A dictionary filled with AVFormatContext and demuxer-private options.
 *                 On return this parameter will be destroyed and replaced with a dict containing
 *                 options that were not found. May be NULL.
 *
 * @return 0 on success, a negative AVERROR on failure.
 *
 * @note If you want to use custom IO, preallocate the format context and set its pb field.
 */
int avformat_open_input(AVFormatContext **ps, const char *url, AVInputFormat *fmt, AVDictionary **options);</code></pre> 
<h4><strong>AVFormatContext</strong></h4> 
<pre><code>/**
 * Format I/O context.
 * New fields can be added to the end with minor version bumps.
 * Removal, reordering and changes to existing fields require a major
 * version bump.
 * sizeof(AVFormatContext) must not be used outside libav*, use
 * avformat_alloc_context() to create an AVFormatContext.
 *
 * Fields can be accessed through AVOptions (av_opt*),
 * the name string used matches the associated command line parameter name and
 * can be found in libavformat/options_table.h.
 * The AVOption/command line parameter names differ in some cases from the C
 * structure field names for historic reasons or brevity.
 */
typedef struct AVFormatContext {
     ......
    自定义读写格式，如从内存中读
    /**
     * I/O context.
     *
     * - demuxing: either set by the user before avformat_open_input() (then
     *             the user must close it manually) or set by avformat_open_input().
     * - muxing: set by the user before avformat_write_header(). The caller must
     *           take care of closing / freeing the IO context.
     *
     * Do NOT set this field if AVFMT_NOFILE flag is set in
     * iformat/oformat.flags. In such a case, the (de)muxer will handle
     * I/O in some other way and this field will be NULL.
     */
    AVIOContext *pb;


    //流的个数
    /**
     * Number of elements in AVFormatContext.streams.
     *
     * Set by avformat_new_stream(), must not be modified by any other code.
     */
    unsigned int nb_streams;

    //流：包括音频，视频，字幕
    /**
     * A list of all streams in the file. New streams are created with
     * avformat_new_stream().
     *
     * - demuxing: streams are created by libavformat in avformat_open_input().
     *             If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also
     *             appear in av_read_frame().
     * - muxing: streams are created by the user before avformat_write_header().
     *
     * Freed by libavformat in avformat_free_context().
     */
    AVStream **streams;

    //文件名
    /**
     * input or output filename
     *
     * - demuxing: set by avformat_open_input()
     * - muxing: may be set by the caller before avformat_write_header()
     */
    char filename[1024];

    
     //持续时间：微秒，以AV_TIME_BASE（1000000） 为单位，表示一秒钟有多少个单位，秒=duration/AV_TIME_BASE.这个值不一定能获取到，获取不到通过帧数计算时间
    /**
     * Duration of the stream, in AV_TIME_BASE fractional
     * seconds. Only set this value if you know none of the individual stream
     * durations and also do not set any of them. This is deduced from the
     * AVStream values if not set.
     *
     * Demuxing only, set by libavformat.
     */
    int64_t duration;

    //比特率
    /**
     * Total stream bitrate in bit/s, 0 if not
     * available. Never set it directly if the file_size and the
     * duration are known as FFmpeg can compute it automatically.
     */
    int64_t bit_rate;

    ......
} AVFormatContext;</code></pre> 
<p> </p> 
<h4>avformat_close_input</h4> 
<p>关闭上下文，如果通过delete清理的话，里面的stream不会被清理掉。还有，动态库中delete动态库中的内容删除会出错，在代码中删除动态链接库创建的空间会出错:</p> 
<p><a href="https://blog.csdn.net/zj510/article/details/35290505">https://blog.csdn.net/zj510/article/details/35290505</a></p> 
<p><a href="https://www.cnblogs.com/minggoddess/archive/2010/12/15/1907179.html" rel="nofollow">https://www.cnblogs.com/minggoddess/archive/2010/12/15/1907179.html</a></p> 
<p><a href="https://blog.csdn.net/weixin_33991727/article/details/85503550?utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control">https://blog.csdn.net/weixin_33991727/article/details/85503550?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control</a></p> 
<pre><code>/**
 * Close an opened input AVFormatContext. Free it and all its contents
 * and set *s to NULL.
 */
void avformat_close_input(AVFormatContext **s)</code></pre> 
<p> </p> 
<h4>AVStream</h4> 
<pre><code>/**
 * Stream structure.
 * New fields can be added to the end with minor version bumps.
 * Removal, reordering and changes to existing fields require a major
 * version bump.
 * sizeof(AVStream) must not be used outside libav*.
 */
typedef struct AVStream {
    int index;    /**&lt; stream index in AVFormatContext */
    /**
     * Format-specific stream ID.
     * decoding: set by libavformat
     * encoding: set by the user, replaced by libavformat if left unset
     */
    int id;
#if FF_API_LAVF_AVCTX
    /**
     * @deprecated use the codecpar struct instead
     */
    attribute_deprecated
    AVCodecContext *codec;//淘汰 
#endif
    void *priv_data;

#if FF_API_LAVF_FRAC
    /**
     * @deprecated this field is unused
     */
    attribute_deprecated
    struct AVFrac pts;
#endif

    /**
     * This is the fundamental unit of time (in seconds) in terms
     * of which frame timestamps are represented.
     *
     * decoding: set by libavformat
     * encoding: May be set by the caller before avformat_write_header() to
     *           provide a hint to the muxer about the desired timebase. In
     *           avformat_write_header(), the muxer will overwrite this field
     *           with the timebase that will actually be used for the timestamps
     *           written into the file (which may or may not be related to the
     *           user-provided one, depending on the format).
     */
    AVRational time_base;//分数  如果用浮点数有精度损失

    /**
     * Decoding: pts of the first frame of the stream in presentation order, in stream time base.
     * Only set this if you are absolutely 100% sure that the value you set
     * it to really is the pts of the first frame.
     * This may be undefined (AV_NOPTS_VALUE).
     * @note The ASF header does NOT contain a correct start_time the ASF
     * demuxer must NOT set this.
     */
    int64_t start_time;

    /**
     * Decoding: duration of the stream, in stream time base.
     * If a source file does not specify a duration, but does specify
     * a bitrate, this value will be estimated from bitrate and file size.
     *
     * Encoding: May be set by the caller before avformat_write_header() to
     * provide a hint to the muxer about the estimated duration.
     */
    int64_t duration;//不一定赋值

    int64_t nb_frames;                 ///&lt; number of frames in this stream if known or 0

    int disposition; /**&lt; AV_DISPOSITION_* bit field */

    enum AVDiscard discard; ///&lt; Selects which packets can be discarded at will and do not need to be demuxed.

    /**
     * sample aspect ratio (0 if unknown)
     * - encoding: Set by user.
     * - decoding: Set by libavformat.
     */
    AVRational sample_aspect_ratio;

    AVDictionary *metadata;

    /**
     * Average framerate
     *
     * - demuxing: May be set by libavformat when creating the stream or in
     *             avformat_find_stream_info().
     * - muxing: May be set by the caller before avformat_write_header().
     */
    AVRational avg_frame_rate;//

    /**
     * For streams with AV_DISPOSITION_ATTACHED_PIC disposition, this packet
     * will contain the attached picture.
     *
     * decoding: set by libavformat, must not be modified by the caller.
     * encoding: unused
     */
    AVPacket attached_pic;

    /**
     * An array of side data that applies to the whole stream (i.e. the
     * container does not allow it to change between packets).
     *
     * There may be no overlap between the side data in this array and side data
     * in the packets. I.e. a given side data is either exported by the muxer
     * (demuxing) / set by the caller (muxing) in this array, then it never
     * appears in the packets, or the side data is exported / sent through
     * the packets (always in the first packet where the value becomes known or
     * changes), then it does not appear in this array.
     *
     * - demuxing: Set by libavformat when the stream is created.
     * - muxing: May be set by the caller before avformat_write_header().
     *
     * Freed by libavformat in avformat_free_context().
     *
     * @see av_format_inject_global_side_data()
     */
    AVPacketSideData *side_data;
    /**
     * The number of elements in the AVStream.side_data array.
     */
    int            nb_side_data;

    /**
     * Flags for the user to detect events happening on the stream. Flags must
     * be cleared by the user once the event has been handled.
     * A combination of AVSTREAM_EVENT_FLAG_*.
     */
    int event_flags;
#define AVSTREAM_EVENT_FLAG_METADATA_UPDATED 0x0001 ///&lt; The call resulted in updated metadata.

    /*****************************************************************
     * All fields below this line are not part of the public API. They
     * may not be used outside of libavformat and can be changed and
     * removed at will.
     * Internal note: be aware that physically removing these fields
     * will break ABI. Replace removed fields with dummy fields, and
     * add new fields to AVStreamInternal.
     *****************************************************************
     */

    /**
     * Stream information used internally by avformat_find_stream_info()
     */
#define MAX_STD_TIMEBASES (30*12+30+3+6)
    struct {
        int64_t last_dts;
        int64_t duration_gcd;
        int duration_count;
        int64_t rfps_duration_sum;
        double (*duration_error)[2][MAX_STD_TIMEBASES];
        int64_t codec_info_duration;
        int64_t codec_info_duration_fields;

        /**
         * 0  -&gt; decoder has not been searched for yet.
         * &gt;0 -&gt; decoder found
         * &lt;0 -&gt; decoder with codec_id == -found_decoder has not been found
         */
        int found_decoder;

        int64_t last_duration;

        /**
         * Those are used for average framerate estimation.
         */
        int64_t fps_first_dts;
        int     fps_first_dts_idx;
        int64_t fps_last_dts;
        int     fps_last_dts_idx;

    } *info;

    int pts_wrap_bits; /**&lt; number of bits in pts (used for wrapping control) */

    // Timestamp generation support:
    /**
     * Timestamp corresponding to the last dts sync point.
     *
     * Initialized when AVCodecParserContext.dts_sync_point &gt;= 0 and
     * a DTS is received from the underlying container. Otherwise set to
     * AV_NOPTS_VALUE by default.
     */
    int64_t first_dts;
    int64_t cur_dts;
    int64_t last_IP_pts;
    int last_IP_duration;

    /**
     * Number of packets to buffer for codec probing
     */
    int probe_packets;

    /**
     * Number of frames that have been demuxed during avformat_find_stream_info()
     */
    int codec_info_nb_frames;

    /* av_read_frame() support */
    enum AVStreamParseType need_parsing;
    struct AVCodecParserContext *parser;

    /**
     * last packet in packet_buffer for this stream when muxing.
     */
    struct AVPacketList *last_in_packet_buffer;
    AVProbeData probe_data;
#define MAX_REORDER_DELAY 16
    int64_t pts_buffer[MAX_REORDER_DELAY+1];

    AVIndexEntry *index_entries; /**&lt; Only used if the format does not
                                    support seeking natively. */
    int nb_index_entries;
    unsigned int index_entries_allocated_size;

    /**
     * Real base framerate of the stream.
     * This is the lowest framerate with which all timestamps can be
     * represented accurately (it is the least common multiple of all
     * framerates in the stream). Note, this value is just a guess!
     * For example, if the time base is 1/90000 and all frames have either
     * approximately 3600 or 1800 timer ticks, then r_frame_rate will be 50/1.
     *
     * Code outside avformat should access this field using:
     * av_stream_get/set_r_frame_rate(stream)
     */
    AVRational r_frame_rate;

    /**
     * Stream Identifier
     * This is the MPEG-TS stream identifier +1
     * 0 means unknown
     */
    int stream_identifier;

    int64_t interleaver_chunk_size;
    int64_t interleaver_chunk_duration;

    /**
     * stream probing state
     * -1   -&gt; probing finished
     *  0   -&gt; no probing requested
     * rest -&gt; perform probing with request_probe being the minimum score to accept.
     * NOT PART OF PUBLIC API
     */
    int request_probe;
    /**
     * Indicates that everything up to the next keyframe
     * should be discarded.
     */
    int skip_to_keyframe;

    /**
     * Number of samples to skip at the start of the frame decoded from the next packet.
     */
    int skip_samples;

    /**
     * If not 0, the number of samples that should be skipped from the start of
     * the stream (the samples are removed from packets with pts==0, which also
     * assumes negative timestamps do not happen).
     * Intended for use with formats such as mp3 with ad-hoc gapless audio
     * support.
     */
    int64_t start_skip_samples;

    /**
     * If not 0, the first audio sample that should be discarded from the stream.
     * This is broken by design (needs global sample count), but can't be
     * avoided for broken by design formats such as mp3 with ad-hoc gapless
     * audio support.
     */
    int64_t first_discard_sample;

    /**
     * The sample after last sample that is intended to be discarded after
     * first_discard_sample. Works on frame boundaries only. Used to prevent
     * early EOF if the gapless info is broken (considered concatenated mp3s).
     */
    int64_t last_discard_sample;

    /**
     * Number of internally decoded frames, used internally in libavformat, do not access
     * its lifetime differs from info which is why it is not in that structure.
     */
    int nb_decoded_frames;

    /**
     * Timestamp offset added to timestamps before muxing
     * NOT PART OF PUBLIC API
     */
    int64_t mux_ts_offset;

    /**
     * Internal data to check for wrapping of the time stamp
     */
    int64_t pts_wrap_reference;

    /**
     * Options for behavior, when a wrap is detected.
     *
     * Defined by AV_PTS_WRAP_ values.
     *
     * If correction is enabled, there are two possibilities:
     * If the first time stamp is near the wrap point, the wrap offset
     * will be subtracted, which will create negative time stamps.
     * Otherwise the offset will be added.
     */
    int pts_wrap_behavior;

    /**
     * Internal data to prevent doing update_initial_durations() twice
     */
    int update_initial_durations_done;

    /**
     * Internal data to generate dts from pts
     */
    int64_t pts_reorder_error[MAX_REORDER_DELAY+1];
    uint8_t pts_reorder_error_count[MAX_REORDER_DELAY+1];

    /**
     * Internal data to analyze DTS and detect faulty mpeg streams
     */
    int64_t last_dts_for_order_check;
    uint8_t dts_ordered;
    uint8_t dts_misordered;

    /**
     * Internal data to inject global side data
     */
    int inject_global_side_data;

    /*****************************************************************
     * All fields above this line are not part of the public API.
     * Fields below are part of the public API and ABI again.
     *****************************************************************
     */

    /**
     * String containing paris of key and values describing recommended encoder configuration.
     * Paris are separated by ','.
     * Keys are separated from values by '='.
     */
    char *recommended_encoder_configuration;

    /**
     * display aspect ratio (0 if unknown)
     * - encoding: unused
     * - decoding: Set by libavformat to calculate sample_aspect_ratio internally
     */
    AVRational display_aspect_ratio;

    struct FFFrac *priv_pts;

    /**
     * An opaque field for libavformat internal usage.
     * Must not be accessed in any way by callers.
     */
    AVStreamInternal *internal;

    /*
     * Codec parameters associated with this stream. Allocated and freed by
     * libavformat in avformat_new_stream() and avformat_free_context()
     * respectively.
     *
     * - demuxing: filled by libavformat on stream creation or in
     *             avformat_find_stream_info()
     * - muxing: filled by the caller before avformat_write_header()
     */
    AVCodecParameters *codecpar;//替代codec
} AVStream;</code></pre> 
<p> </p> 
<h4>AVCodecParameters</h4> 
<pre><code>/**
 * This struct describes the properties of an encoded stream.
 *
 * sizeof(AVCodecParameters) is not a part of the public ABI, this struct must
 * be allocated with avcodec_parameters_alloc() and freed with
 * avcodec_parameters_free().
 */
typedef struct AVCodecParameters {
    /**
     * General type of the encoded data.
     */
    enum AVMediaType codec_type;//音频 or 视频
    /**
     * Specific type of the encoded data (the codec used).
     */
    enum AVCodecID   codec_id;
    /**
     * Additional information about the codec (corresponds to the AVI FOURCC).
     */
    uint32_t         codec_tag;//

    /**
     * Extra binary data needed for initializing the decoder, codec-dependent.
     *
     * Must be allocated with av_malloc() and will be freed by
     * avcodec_parameters_free(). The allocated size of extradata must be at
     * least extradata_size + AV_INPUT_BUFFER_PADDING_SIZE, with the padding
     * bytes zeroed.
     */
    uint8_t *extradata;
    /**
     * Size of the extradata content in bytes.
     */
    int      extradata_size;

    /**
     * - video: the pixel format, the value corresponds to enum AVPixelFormat.
     * - audio: the sample format, the value corresponds to enum AVSampleFormat.
     */
    int format;//视频像素格式;音频采样格式

    /**
     * The average bitrate of the encoded data (in bits per second).
     */
    int64_t bit_rate;

    /**
     * The number of bits per sample in the codedwords.
     *
     * This is basically the bitrate per sample. It is mandatory for a bunch of
     * formats to actually decode them. It's the number of bits for one sample in
     * the actual coded bitstream.
     *
     * This could be for example 4 for ADPCM
     * For PCM formats this matches bits_per_raw_sample
     * Can be 0
     */
    int bits_per_coded_sample;

    /**
     * This is the number of valid bits in each output sample. If the
     * sample format has more bits, the least significant bits are additional
     * padding bits, which are always 0. Use right shifts to reduce the sample
     * to its actual size. For example, audio formats with 24 bit samples will
     * have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32.
     * To get the original sample use "(int32_t)sample &gt;&gt; 8"."
     *
     * For ADPCM this might be 12 or 16 or similar
     * Can be 0
     */
    int bits_per_raw_sample;

    /**
     * Codec-specific bitstream restrictions that the stream conforms to.
     */
    int profile;
    int level;

    /**
     * Video only. The dimensions of the video frame in pixels.
     */
    int width;
    int height;

    /**
     * Video only. The aspect ratio (width / height) which a single pixel
     * should have when displayed.
     *
     * When the aspect ratio is unknown / undefined, the numerator should be
     * set to 0 (the denominator may have any value).
     */
    AVRational sample_aspect_ratio;

    /**
     * Video only. The order of the fields in interlaced video.
     */
    enum AVFieldOrder                  field_order;

    /**
     * Video only. Additional colorspace characteristics.
     */
    enum AVColorRange                  color_range;
    enum AVColorPrimaries              color_primaries;
    enum AVColorTransferCharacteristic color_trc;
    enum AVColorSpace                  color_space;
    enum AVChromaLocation              chroma_location;

    /**
     * Video only. Number of delayed frames.
     */
    int video_delay;

    /**
     * Audio only. The channel layout bitmask. May be 0 if the channel layout is
     * unknown or unspecified, otherwise the number of bits set must be equal to
     * the channels field.
     */
    uint64_t channel_layout;//
    /**
     * Audio only. The number of audio channels.
     */
    int      channels;
    /**
     * Audio only. The number of audio samples per second.
     */
    int      sample_rate;
    /**
     * Audio only. The number of bytes per coded audio frame, required by some
     * formats.
     *
     * Corresponds to nBlockAlign in WAVEFORMATEX.
     */
    int      block_align;
    /**
     * Audio only. Audio frame size, if known. Required by some formats to be static.
     */
    int      frame_size;

    /**
     * Audio only. The amount of padding (in samples) inserted by the encoder at
     * the beginning of the audio. I.e. this number of leading decoded samples
     * must be discarded by the caller to get the original audio without leading
     * padding.
     */
    int initial_padding;
    /**
     * Audio only. The amount of padding (in samples) appended by the encoder to
     * the end of the audio. I.e. this number of decoded samples must be
     * discarded by the caller from the end of the stream to get the original
     * audio without any trailing padding.
     */
    int trailing_padding;
    /**
     * Audio only. Number of samples to skip after a discontinuity.
     */
    int seek_preroll;
} AVCodecParameters;</code></pre> 
<p> </p> 
<p>代码：</p> 
<pre><code>#include &lt;iostream&gt;
extern "C" {
#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
}

static double r2d(AVRational r)
{
  return r.den == 0 ? 0 : (double)r.num / (double)r.den;
}

int main()
{
  //初始化封装库
  av_register_all();

  //初始化网络库:可以打开rtsp（摄像机） rtmp(直播) http协议的流媒体视频
  avformat_network_init();


  AVFormatContext *ic = NULL;
  const char *path = "../../res/test.mp4";
  AVDictionary *opts = NULL;

  //如果是rtsp流时
  //设置rtsp流已tcp协议打开
  av_dict_set(&amp;opts, "rtsp_transport", "tcp", 0);

  //网络延时时间
  av_dict_set(&amp;opts, "max_delay", "500", 0);

  //打开一个文件
  int ret = avformat_open_input(&amp;ic, path,0, &amp;opts);
  if (ret != 0) {
    char buf[1024] = { 0 };
    av_strerror(ret, buf,sizeof(buf)-1);
    std::cout &lt;&lt; "open:" &lt;&lt; path &lt;&lt; "fail,error:" &lt;&lt; buf &lt;&lt; std::endl;
    return -1;
  }

  //获取流信息:这一步的目的是flv格式avformat_open_input并不能获取所有信息，没有写在header中，sps流中存放信息
  ret = avformat_find_stream_info(ic, 0);

  //总时长 秒： ic-&gt;duration / AV_TIME_BASE ; 
  int totalMs = ic-&gt;duration / (AV_TIME_BASE / 1000);
  std::cout &lt;&lt; "totalMs = " &lt;&lt; totalMs &lt;&lt; std::endl;

  //打印视频流详细信息： index和url经测试没有用，对输出没影响
  //void av_dump_format(AVFormatContext *ic,int index,const char *url,int is_output);
  std::cout &lt;&lt; "\nav_dump_format:" &lt;&lt; std::endl;
  av_dump_format(ic, 0, path, 0);


  //音视频索引，读取时区分音视频
  int videoStream = 0;
  int audioStream = 1;

  //获取音视频流信息 （遍历，函数获取）
  for (int i = 0; i &lt; ic-&gt;nb_streams; i++)
  {
    AVStream *as = ic-&gt;streams[i];
    std::cout &lt;&lt; "codec_id = " &lt;&lt; as-&gt;codecpar-&gt;codec_id &lt;&lt; std::endl;
    std::cout &lt;&lt; "format = " &lt;&lt; as-&gt;codecpar-&gt;format &lt;&lt; std::endl;

    //音频 AVMEDIA_TYPE_AUDIO
    if (as-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_AUDIO)
    {
      audioStream = i;
      std::cout &lt;&lt; i &lt;&lt; "\n音频信息:" &lt;&lt; std::endl;
      std::cout &lt;&lt; "sample_rate = " &lt;&lt; as-&gt;codecpar-&gt;sample_rate &lt;&lt; std::endl;
      //AVSampleFormat;
      std::cout &lt;&lt; "channels = " &lt;&lt; as-&gt;codecpar-&gt;channels &lt;&lt; std::endl;
      //单通道样本数 
      std::cout &lt;&lt; "frame_size = " &lt;&lt; as-&gt;codecpar-&gt;frame_size &lt;&lt; std::endl;

    }
    //视频 AVMEDIA_TYPE_VIDEO
    else if (as-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_VIDEO)
    {
      videoStream = i;
      std::cout &lt;&lt; i &lt;&lt; "\n视频信息:" &lt;&lt; std::endl;
      std::cout &lt;&lt; "width=" &lt;&lt; as-&gt;codecpar-&gt;width &lt;&lt; std::endl;//宽高有可能是没有的，解码时候会有
      std::cout &lt;&lt; "height=" &lt;&lt; as-&gt;codecpar-&gt;height &lt;&lt; std::endl;
      //帧率 fps 分数转换
      std::cout &lt;&lt; "video fps = " &lt;&lt; r2d(as-&gt;avg_frame_rate) &lt;&lt; std::endl;
    }
  }

  //第二种获取视频流下标的方式：
  videoStream = av_find_best_stream(ic, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
  ///ic-&gt;streams[videoStream]


  if (ic) {
    avformat_close_input(&amp;ic);
  }


  system("pause");
  return 0;
}

</code></pre> 
<p><img alt="" height="478" src="https://images2.imgbox.com/ee/e2/xdLjP0RX_o.png" width="1200"></p> 
<p>资源：<a href="https://download.csdn.net/download/LIJIWEI0611/18336008">https://download.csdn.net/download/LIJIWEI0611/18336008</a></p> 
<p>av_read_frame</p> 
<pre><code>/**
 * Return the next frame of a stream.
 * This function returns what is stored in the file, and does not validate
 * that what is there are valid frames for the decoder. It will split what is
 * stored in the file into frames and return one for each call. It will not
 * omit invalid data between valid frames so as to give the decoder the maximum
 * information possible for decoding.
 *
 * If pkt-&gt;buf is NULL, then the packet is valid until the next
 * av_read_frame() or until avformat_close_input(). Otherwise the packet
 * is valid indefinitely. In both cases the packet must be freed with
 * av_packet_unref when it is no longer needed. For video, the packet contains
 * exactly one frame. For audio, it contains an integer number of frames if each
 * frame has a known fixed size (e.g. PCM or ADPCM data). If the audio frames
 * have a variable size (e.g. MPEG audio), then it contains one frame.
 *
 * pkt-&gt;pts, pkt-&gt;dts and pkt-&gt;duration are always set to correct
 * values in AVStream.time_base units (and guessed if the format cannot
 * provide them). pkt-&gt;pts can be AV_NOPTS_VALUE if the video format
 * has B-frames, so it is better to rely on pkt-&gt;dts if you do not
 * decompress the payload.
 *
 * @return 0 if OK, &lt; 0 on error or end of file
 */
int av_read_frame(AVFormatContext *s, AVPacket *pkt);</code></pre> 
<h4>AVPacket </h4> 
<pre><code>typedef struct AVPacket {
    /**
     * A reference to the reference-counted buffer where the packet data is
     * stored.
     * May be NULL, then the packet data is not reference-counted.
     */
    AVBufferRef *buf;//引用计数空间，有可能多个AVPacket引用同一个buf，通过av_packet_unref 使得引用计数-1
    /**
     * Presentation timestamp in AVStream-&gt;time_base units; the time at which
     * the decompressed packet will be presented to the user.
     * Can be AV_NOPTS_VALUE if it is not stored in the file.
     * pts MUST be larger or equal to dts as presentation cannot happen before
     * decompression, unless one wants to view hex dumps. Some formats misuse
     * the terms dts and pts/cts to mean something different. Such timestamps
     * must be converted to true pts/dts before they are stored in AVPacket.
     */
    int64_t pts;//显示时间
    /**
     * Decompression timestamp in AVStream-&gt;time_base units; the time at which
     * the packet is decompressed.
     * Can be AV_NOPTS_VALUE if it is not stored in the file.
     */
    int64_t dts;//解码时间
    uint8_t *data;
    int   size;
    int   stream_index;
    /**
     * A combination of AV_PKT_FLAG values
     */
    int   flags;
    /**
     * Additional packet data that can be provided by the container.
     * Packet can contain several types of side information.
     */
    AVPacketSideData *side_data;
    int side_data_elems;

    /**
     * Duration of this packet in AVStream-&gt;time_base units, 0 if unknown.
     * Equals next_pts - this_pts in presentation order.
     */
    int64_t duration;

    int64_t pos;                            ///&lt; byte position in stream, -1 if unknown

#if FF_API_CONVERGENCE_DURATION
    /**
     * @deprecated Same as the duration field, but as int64_t. This was required
     * for Matroska subtitles, whose duration values could overflow when the
     * duration field was still an int.
     */
    attribute_deprecated
    int64_t convergence_duration;
#endif
} AVPacket;</code></pre> 
<p><img alt="" height="372" src="https://images2.imgbox.com/46/1c/32e7KiHR_o.png" width="1008"></p> 
<h4>av_seek_frame</h4> 
<pre><code>/**
 * Seek to the keyframe at timestamp.
 * 'timestamp' in 'stream_index'.
 *
 * @param s media file handle
 * @param stream_index If stream_index is (-1), a default
 * stream is selected, and timestamp is automatically converted
 * from AV_TIME_BASE units to the stream specific time_base.
 * @param timestamp Timestamp in AVStream.time_base units
 *        or, if no stream is specified, in AV_TIME_BASE units.
 * @param flags flags which select direction and seeking mode
 * @return &gt;= 0 on success
 */
int av_seek_frame(AVFormatContext *s, int stream_index, int64_t timestamp,
                  int flags);

stream_index一般选择视频，因为视频存在B帧，假如一个视频移动到第7秒的位置，一共10秒；如果正好不是关键帧，解码后画面有问题。针对视频，必须移动到关键帧位置
timestamp:如果是6.9s 当前时间可能没有帧，会存在两个帧  向后找（6.8s） 向前找（7.0s）
flags: 向后找（当前帧的前面）且找关键帧  （1 || 8）</code></pre> 
<p><img alt="" height="202" src="https://images2.imgbox.com/cd/a0/a1f47TYd_o.png" width="965"></p> 
<pre><code>#include &lt;iostream&gt;
extern "C" {
#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
}

static double r2d(AVRational r)
{
  return r.den == 0 ? 0 : (double)r.num / (double)r.den;
}

int main()
{
  //初始化封装库
  av_register_all();

  //初始化网络库:可以打开rtsp（摄像机） rtmp(直播) http协议的流媒体视频
  avformat_network_init();


  AVFormatContext *ic = NULL;
  const char *path = "../../res/test.mp4";
  AVDictionary *opts = NULL;

  //如果是rtsp流时
  //设置rtsp流已tcp协议打开
  av_dict_set(&amp;opts, "rtsp_transport", "tcp", 0);

  //网络延时时间
  av_dict_set(&amp;opts, "max_delay", "500", 0);

  //打开一个文件
  int ret = avformat_open_input(&amp;ic, path,0, &amp;opts);
  if (ret != 0) {
    char buf[1024] = { 0 };
    av_strerror(ret, buf,sizeof(buf)-1);
    std::cout &lt;&lt; "open:" &lt;&lt; path &lt;&lt; "fail,error:" &lt;&lt; buf &lt;&lt; std::endl;
    return -1;
  }

  //获取流信息:这一步的目的是flv格式avformat_open_input并不能获取所有信息，没有写在header中，sps流中存放信息
  ret = avformat_find_stream_info(ic, 0);

  //总时长 秒： ic-&gt;duration / AV_TIME_BASE ; 
  int totalMs = ic-&gt;duration / (AV_TIME_BASE / 1000);
  std::cout &lt;&lt; "totalMs = " &lt;&lt; totalMs &lt;&lt; std::endl;

  //打印视频流详细信息： index和url经测试没有用，对输出没影响
  //void av_dump_format(AVFormatContext *ic,int index,const char *url,int is_output);
  std::cout &lt;&lt; "\nav_dump_format:" &lt;&lt; std::endl;
  av_dump_format(ic, 0, path, 0);


  //音视频索引，读取时区分音视频
  int videoStream = 0;
  int audioStream = 1;

  //获取音视频流信息 （遍历，函数获取）
  for (int i = 0; i &lt; ic-&gt;nb_streams; i++)
  {
    AVStream *as = ic-&gt;streams[i];
    std::cout &lt;&lt; "codec_id = " &lt;&lt; as-&gt;codecpar-&gt;codec_id &lt;&lt; std::endl;
    std::cout &lt;&lt; "format = " &lt;&lt; as-&gt;codecpar-&gt;format &lt;&lt; std::endl;

    //音频 AVMEDIA_TYPE_AUDIO
    if (as-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_AUDIO)
    {
      audioStream = i;
      std::cout &lt;&lt; i &lt;&lt; "\n音频信息:" &lt;&lt; std::endl;
      std::cout &lt;&lt; "sample_rate = " &lt;&lt; as-&gt;codecpar-&gt;sample_rate &lt;&lt; std::endl;
      //AVSampleFormat;
      std::cout &lt;&lt; "channels = " &lt;&lt; as-&gt;codecpar-&gt;channels &lt;&lt; std::endl;
      //单通道样本数 
      std::cout &lt;&lt; "frame_size = " &lt;&lt; as-&gt;codecpar-&gt;frame_size &lt;&lt; std::endl;

    }
    //视频 AVMEDIA_TYPE_VIDEO
    else if (as-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_VIDEO)
    {
      videoStream = i;
      std::cout &lt;&lt; i &lt;&lt; "\n视频信息:" &lt;&lt; std::endl;
      std::cout &lt;&lt; "width=" &lt;&lt; as-&gt;codecpar-&gt;width &lt;&lt; std::endl;//宽高有可能是没有的，解码时候会有
      std::cout &lt;&lt; "height=" &lt;&lt; as-&gt;codecpar-&gt;height &lt;&lt; std::endl;
      //帧率 fps 分数转换
      std::cout &lt;&lt; "video fps = " &lt;&lt; r2d(as-&gt;avg_frame_rate) &lt;&lt; std::endl;
    }
  }

  //第二种获取视频流下标的方式：
  videoStream = av_find_best_stream(ic, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
  ///ic-&gt;streams[videoStream]

  //malloc AVPacket并初始化,使用指针方式的好处是如果avpacket需要存放到queue中，存储指针更有优势
  AVPacket *pkt = av_packet_alloc();
  for (;;)
  {
    int ret = av_read_frame(ic, pkt);
    if (ret != 0)
    {
      //循环播放
      std::cout &lt;&lt; "==============================end==============================" &lt;&lt; std::endl;
      int ms = 3000; //三秒位置 根据时间基数（分数）转换
      long long pos = (double)ms / (double)1000 * r2d(ic-&gt;streams[pkt-&gt;stream_index]-&gt;time_base);
      av_seek_frame(ic, videoStream, pos, AVSEEK_FLAG_BACKWARD | AVSEEK_FLAG_FRAME);
      continue;
    }
    std::cout &lt;&lt; "pkt-&gt;size = " &lt;&lt; pkt-&gt;size &lt;&lt; std::endl;
    //显示的时间
    std::cout &lt;&lt; "pkt-&gt;pts = " &lt;&lt; pkt-&gt;pts &lt;&lt; std::endl;

    //转换为毫秒，方便做同步
    std::cout &lt;&lt; "pkt-&gt;pts ms = " &lt;&lt; pkt-&gt;pts * (r2d(ic-&gt;streams[pkt-&gt;stream_index]-&gt;time_base) * 1000) &lt;&lt; std::endl;



    //解码时间
    std::cout &lt;&lt; "pkt-&gt;dts = " &lt;&lt; pkt-&gt;dts &lt;&lt; std::endl;
    if (pkt-&gt;stream_index == videoStream)
    {
      std::cout &lt;&lt; "图像" &lt;&lt; std::endl;
    }
    if (pkt-&gt;stream_index == audioStream)
    {
      std::cout &lt;&lt; "音频" &lt;&lt; std::endl;
    }


    //释放，引用计数-1 为0释放空间
    av_packet_unref(pkt);

    //XSleep(500);
  }

  av_packet_free(&amp;pkt);

  if (ic) {
    avformat_close_input(&amp;ic);
  }

 
  system("pause");
  return 0;
}

</code></pre> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/38ff4db9bbb82d7a8e591217990ad46f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">linux v4l2系统详解,v4l2驱动2-linux3.0.8中V4L2_CAP_*详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/32e34fc5e5f88ff392765d6029f86aeb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2021-05-03</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>