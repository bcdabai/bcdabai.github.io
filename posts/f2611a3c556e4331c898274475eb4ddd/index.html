<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ä½¿ç”¨ EmbeddingBag å’Œ Embedding å®Œæˆè¯åµŒå…¥ - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ä½¿ç”¨ EmbeddingBag å’Œ Embedding å®Œæˆè¯åµŒå…¥" />
<meta property="og:description" content="ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥å­¦ä¹ è®°å½•åšå®¢\nğŸ¦ å‚è€ƒæ–‡ç« ï¼š365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥\nğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶]\nğŸš€ æ–‡ç« æ¥æºï¼š[KåŒå­¦çš„å­¦ä¹ åœˆå­](https://www.yuque.com/mingtian-fkmxf/zxwb45)
ä½¿ç”¨ EmbeddingBag å’Œ Embedding å®Œæˆè¯åµŒå…¥ï¼Œé¦–å…ˆéœ€è¦å¤„ç†æ–‡æ¡£ä¸­çš„æ–‡æœ¬ï¼Œå°†å…¶è½¬æ¢ä¸ºé€‚åˆè¿›è¡Œè¯åµŒå…¥çš„æ ¼å¼ï¼Œæ¶‰åŠåˆ°ä»¥ä¸‹æ­¥éª¤ï¼š
æ–‡æœ¬æ¸…æ´—ï¼šç§»é™¤æ–‡æ¡£ä¸­çš„ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ç¬¦å·ï¼Œå°†æ–‡æœ¬ç»Ÿä¸€ä¸ºå°å†™ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚åˆ†è¯ï¼šå°†æ–‡æœ¬åˆ†å‰²æˆå•è¯æˆ–æ ‡è®°ï¼ˆtokensï¼‰ã€‚å»ºç«‹è¯æ±‡è¡¨ï¼šä»åˆ†è¯åçš„æ–‡æœ¬ä¸­åˆ›å»ºä¸€ä¸ªè¯æ±‡è¡¨ï¼Œæ¯ä¸ªå”¯ä¸€çš„å•è¯å¯¹åº”ä¸€ä¸ªç´¢å¼•ã€‚æ–‡æœ¬å‘é‡åŒ–ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å½¢å¼ï¼Œä»¥ä¾¿è¿›è¡ŒåµŒå…¥å¤„ç†ã€‚ ç¬¬äºŒæ­¥ï¼Œä½¿ç”¨ EmbeddingBag å’Œ Embedding å±‚è¿›è¡Œè¯åµŒå…¥ã€‚EmbeddingBag å±‚é€‚ç”¨äºå¤„ç†å˜é•¿çš„æ–‡æœ¬ï¼Œå®ƒä¼šè®¡ç®—æ‰€æœ‰åµŒå…¥å‘é‡çš„å¹³å‡å€¼æˆ–å’Œã€‚è€Œ Embedding å±‚é€‚ç”¨äºå•ä¸ªå•è¯æˆ–å›ºå®šé•¿åº¦çš„åºåˆ—ã€‚
ç›®æ ‡æ–‡ä»¶ï¼š å®ç°ä»£ç ï¼šÂ from collections import Counter import torch import torch.nn as nn import re # æ¸…æ´—æ–‡æœ¬å¹¶è¿›è¡Œåˆ†è¯ def tokenize(text): # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ï¼Œå¹¶è½¬æ¢ä¸ºå°å†™ text = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, text).lower() # åˆ†è¯ return text.split() # åˆ›å»ºè¯æ±‡è¡¨ def create_vocab(text_tokens): vocab = Counter(text_tokens) vocab = sorted(vocab, key=vocab.get, reverse=True) vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)} # ç´¢å¼•ä»1å¼€å§‹ return vocab_to_int # å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å½¢å¼ def text_to_int(tokens, vocab_to_int): return [vocab_to_int[word] for word in tokens if word in vocab_to_int] # å®šä¹‰Embeddingå’ŒEmbeddingBagå±‚ def define_embedding_layers(vocab_size, embedding_dim=100): embedding = nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/f2611a3c556e4331c898274475eb4ddd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-12T18:47:12+08:00" />
<meta property="article:modified_time" content="2024-01-12T18:47:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ä½¿ç”¨ EmbeddingBag å’Œ Embedding å®Œæˆè¯åµŒå…¥</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>ğŸ¨ æœ¬æ–‡ä¸º[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥å­¦ä¹ è®°å½•åšå®¢\nğŸ¦ å‚è€ƒæ–‡ç« ï¼š365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥\nğŸ– åŸä½œè€…ï¼š[KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶]\nğŸš€ æ–‡ç« æ¥æºï¼š[KåŒå­¦çš„å­¦ä¹ åœˆå­](https://www.yuque.com/mingtian-fkmxf/zxwb45)</p> 
</blockquote> 
<p>ä½¿ç”¨ <code>EmbeddingBag</code> å’Œ <code>Embedding</code> å®Œæˆè¯åµŒå…¥ï¼Œé¦–å…ˆéœ€è¦å¤„ç†æ–‡æ¡£ä¸­çš„æ–‡æœ¬ï¼Œå°†å…¶è½¬æ¢ä¸ºé€‚åˆè¿›è¡Œè¯åµŒå…¥çš„æ ¼å¼ï¼Œæ¶‰åŠåˆ°ä»¥ä¸‹æ­¥éª¤ï¼š</p> 
<ol><li><strong>æ–‡æœ¬æ¸…æ´—</strong>ï¼šç§»é™¤æ–‡æ¡£ä¸­çš„ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ç¬¦å·ï¼Œå°†æ–‡æœ¬ç»Ÿä¸€ä¸ºå°å†™ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚</li><li><strong>åˆ†è¯</strong>ï¼šå°†æ–‡æœ¬åˆ†å‰²æˆå•è¯æˆ–æ ‡è®°ï¼ˆtokensï¼‰ã€‚</li><li><strong>å»ºç«‹è¯æ±‡è¡¨</strong>ï¼šä»åˆ†è¯åçš„æ–‡æœ¬ä¸­åˆ›å»ºä¸€ä¸ªè¯æ±‡è¡¨ï¼Œæ¯ä¸ªå”¯ä¸€çš„å•è¯å¯¹åº”ä¸€ä¸ªç´¢å¼•ã€‚</li><li><strong>æ–‡æœ¬å‘é‡åŒ–</strong>ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å½¢å¼ï¼Œä»¥ä¾¿è¿›è¡ŒåµŒå…¥å¤„ç†ã€‚</li></ol> 
<p>ç¬¬äºŒæ­¥ï¼Œä½¿ç”¨ <code>EmbeddingBag</code> å’Œ <code>Embedding</code> å±‚è¿›è¡Œè¯åµŒå…¥ã€‚<code>EmbeddingBag</code> å±‚é€‚ç”¨äºå¤„ç†å˜é•¿çš„æ–‡æœ¬ï¼Œå®ƒä¼šè®¡ç®—æ‰€æœ‰åµŒå…¥å‘é‡çš„å¹³å‡å€¼æˆ–å’Œã€‚è€Œ <code>Embedding</code> å±‚é€‚ç”¨äºå•ä¸ªå•è¯æˆ–å›ºå®šé•¿åº¦çš„åºåˆ—ã€‚</p> 
<h4><strong>ç›®æ ‡æ–‡ä»¶ï¼š</strong></h4> 
<p><img alt="" height="273" src="https://images2.imgbox.com/9a/de/8o2lZljE_o.png" width="1200"></p> 
<h4><strong>å®ç°ä»£ç ï¼šÂ </strong></h4> 
<pre><code class="language-python">from collections import Counter
import torch
import torch.nn as nn
import re

# æ¸…æ´—æ–‡æœ¬å¹¶è¿›è¡Œåˆ†è¯
def tokenize(text):
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ï¼Œå¹¶è½¬æ¢ä¸ºå°å†™
    text = re.sub(r'[^\w\s]', '', text).lower()
    # åˆ†è¯
    return text.split()

# åˆ›å»ºè¯æ±‡è¡¨
def create_vocab(text_tokens):
    vocab = Counter(text_tokens)
    vocab = sorted(vocab, key=vocab.get, reverse=True)
    vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)} # ç´¢å¼•ä»1å¼€å§‹
    return vocab_to_int

# å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å½¢å¼
def text_to_int(tokens, vocab_to_int):
    return [vocab_to_int[word] for word in tokens if word in vocab_to_int]

# å®šä¹‰Embeddingå’ŒEmbeddingBagå±‚
def define_embedding_layers(vocab_size, embedding_dim=100):
    embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)
    embedding_bag = nn.EmbeddingBag(num_embeddings=vocab_size, embedding_dim=embedding_dim, mode='mean')
    return embedding, embedding_bag

# è¯»å–æ–‡ä»¶å†…å®¹
file_path = 'D:/ä»»åŠ¡æ–‡ä»¶ (1).txt'
with open(file_path, 'r', encoding='utf-8') as file:
    file_content = file.read()

# æ–‡æœ¬æ¸…æ´—å’Œåˆ†è¯
tokens = tokenize(file_content)

# åˆ›å»ºè¯æ±‡è¡¨
vocab_to_int = create_vocab(tokens)

# å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å½¢å¼
int_text = text_to_int(tokens, vocab_to_int)

# å®šä¹‰åµŒå…¥å±‚å‚æ•°
embedding_dim = 100
vocab_size = len(vocab_to_int) + 1

# å®šä¹‰Embeddingå’ŒEmbeddingBagå±‚
embedding, embedding_bag = define_embedding_layers(vocab_size, embedding_dim)

# è½¬æ¢ä¸ºtensorä»¥ä¾›åµŒå…¥å±‚ä½¿ç”¨
input_tensor = torch.tensor([int_text], dtype=torch.long)

# ä½¿ç”¨Embeddingå’ŒEmbeddingBagè¿›è¡Œè¯åµŒå…¥
embedded = embedding(input_tensor)
embedded_bag = embedding_bag(input_tensor)

# æ‰“å°ç»“æœ
print("Embedding shape:", embedded.shape)
print("EmbeddingBag shape:", embedded_bag.shape)
</code></pre> 
<p><img alt="" height="86" src="https://images2.imgbox.com/53/af/4MSq6XR6_o.png" width="901"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/79607b975c3267af95f1192b9c1948c6/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">æœ€ä½³è§£å†³æ–¹æ¡ˆï¼šå¦‚ä½•åœ¨ç½‘ç»œçˆ¬è™«ä¸­è§£å†³éªŒè¯ç </p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/81fa872675c9ec713863006e2d178404/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">åŸºäºLVGLç¼–å†™çš„windowsä¸²å£å·¥å…·ï¼š LCOM</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>