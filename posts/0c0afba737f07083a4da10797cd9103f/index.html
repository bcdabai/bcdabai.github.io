<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ELK日志分析系统，ELFK详解部署 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ELK日志分析系统，ELFK详解部署" />
<meta property="og:description" content="目录
概念简述
可以添加的其他组件
完整日志系统基本特征
原理
部署实例
环境准备
ELK Elasticsearch 集群部署（在Node1、Node2节点上操作）
部署 Elasticsearch 软件
安装 Elasticsearch-head 插件
ELK Logstash 部署（在 Apache 节点上操作）
ELK Kiabana 部署（在 Node1 节点上操作）
ELFK（Filebeat&#43;ELK 部署）
环境准备
Node1节点配置
安装Filebeat
filebeat.yml配置
启动Filebeat
Logstash节点配置
新建Logstash 配置文件
启动logstash
浏览器测试
概念简述 ELK日志分析系统是一个开源的日志管理平台，它由三个主要组件组成，分别是Elasticsearch、Logstash和Kibana。这三个组件协同工作，提供了一个完整的解决方案，用于收集、存储、搜索、分析和可视化大规模的日志数据。以下是ELK日志分析系统的主要组件及其功能：
Elasticsearch：
基于Lucene的分布式存储检索引擎，用于存储各类日志。
通过RESTful Web接口进行通信，允许用户通过浏览器与Elasticsearch交互。
实时、分布式、可扩展的搜索引擎，支持全文和结构化搜索。通常用于索引和搜索大容量的日志数据，也适用于其他类型的文档。
Kibana：
与Elasticsearch一起部署，是Elasticsearch的数据可视化Dashboard。
提供图形化的web界面，用于浏览、汇总、分析和搜索Elasticsearch日志数据，方便用户快速理解和利用数据。
Logstash：
作为数据收集引擎，支持动态地从各种数据源收集数据。
对数据进行过滤、分析、丰富和格式统一等操作，然后将处理后的数据存储到用户指定的位置，通常发送给Elasticsearch。
使用Ruby语言编写，运行在Java虚拟机上，拥有强大的数据处理能力和插件功能。通常用于日志处理，其工作流程涉及输入（数据采集）、过滤（数据过滤）、输出（数据输出）的处理过程。
ELK的优势在于集成了这三个工具，形成一个完整的日志处理生态系统，使用户能够从数据采集、清洗、存储到可视化展示，完成对日志数据的全方位管理和利用。
工作流程:
Logstash负责采集、处理和转发日志数据。
Elasticsearch用于存储和索引处理后的数据，提供高效的检索和分析功能。
Kibana通过Web界面与Elasticsearch交互，提供用户友好的数据可视化和分析工具。
应用场景:
ELK日志分析系统广泛用于监控和分析应用程序日志、系统日志、安全事件等。
它可以帮助系统管理员、开发人员和运维团队追踪问题、进行故障排除、监测系统性能，并提供实时的可视化报告。
为什么使用ELK呢？ELK 是一个广泛使用的开源工具组合，由 ElasticSearch、Logstash 和 Kibana 组成，它们合作来实现日志管理、分析和可视化。
集中式管理：当日志分散在不同设备上时，传统的查看方法变得低效且繁琐。ELK 的 Logstash 组件可以帮助集中收集来自各服务器的日志，并将它们统一存储在 ElasticSearch 中，简化了日志管理的复杂性。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/0c0afba737f07083a4da10797cd9103f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-12T09:07:22+08:00" />
<meta property="article:modified_time" content="2024-01-12T09:07:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ELK日志分析系统，ELFK详解部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E6%A6%82%E5%BF%B5%E7%AE%80%E8%BF%B0-toc" style="margin-left:0px;"><a href="#%E6%A6%82%E5%BF%B5%E7%AE%80%E8%BF%B0" rel="nofollow">概念简述</a></p> 
<p id="-1-toc" style="margin-left:0px;"><a href="#-1" rel="nofollow">可以添加的其他组件</a></p> 
<p id="-2-toc" style="margin-left:0px;"><a href="#-2" rel="nofollow">完整日志系统基本特征</a></p> 
<p id="-3-toc" style="margin-left:0px;"><a href="#-3" rel="nofollow">原理</a></p> 
<p id="-4-toc" style="margin-left:0px;"><a href="#-4" rel="nofollow">部署实例</a></p> 
<p id="-5-toc" style="margin-left:40px;"><a href="#-5" rel="nofollow">环境准备</a></p> 
<p id="elkelasticsearchnode1node2-toc" style="margin-left:40px;"><a href="#elkelasticsearchnode1node2" rel="nofollow">ELK Elasticsearch 集群部署（在Node1、Node2节点上操作）</a></p> 
<p id="elasticsearch-toc" style="margin-left:40px;"><a href="#elasticsearch" rel="nofollow">部署 Elasticsearch 软件</a></p> 
<p id="elasticsearchhead-toc" style="margin-left:40px;"><a href="#elasticsearchhead" rel="nofollow">安装 Elasticsearch-head 插件</a></p> 
<p id="elklogstashapache-toc" style="margin-left:40px;"><a href="#elklogstashapache" rel="nofollow">ELK Logstash 部署（在 Apache 节点上操作）</a></p> 
<p id="elkkiabananode1-toc" style="margin-left:40px;"><a href="#elkkiabananode1" rel="nofollow">ELK Kiabana 部署（在 Node1 节点上操作）</a></p> 
<p id="elfkfilebeatelk-toc" style="margin-left:0px;"><a href="#elfkfilebeatelk" rel="nofollow">ELFK（Filebeat+ELK 部署）</a></p> 
<p id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-toc" style="margin-left:40px;"><a href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">环境准备</a></p> 
<p id="node1-toc" style="margin-left:40px;"><a href="#node1" rel="nofollow">Node1节点配置</a></p> 
<p id="filebeat-toc" style="margin-left:80px;"><a href="#filebeat" rel="nofollow">安装Filebeat</a></p> 
<p id="filebeatyml-toc" style="margin-left:80px;"><a href="#filebeatyml" rel="nofollow">filebeat.yml配置</a></p> 
<p id="filebeat-1-toc" style="margin-left:80px;"><a href="#filebeat-1" rel="nofollow">启动Filebeat</a></p> 
<p id="logstash-toc" style="margin-left:40px;"><a href="#logstash" rel="nofollow">Logstash节点配置</a></p> 
<p id="logstash-1-toc" style="margin-left:80px;"><a href="#logstash-1" rel="nofollow">新建Logstash 配置文件</a></p> 
<p id="logstash-2-toc" style="margin-left:80px;"><a href="#logstash-2" rel="nofollow">启动logstash</a></p> 
<p id="%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95-toc" style="margin-left:40px;"><a href="#%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95" rel="nofollow">浏览器测试</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E6%A6%82%E5%BF%B5%E7%AE%80%E8%BF%B0">概念简述</h2> 
<p><img alt="" height="416" src="https://images2.imgbox.com/6c/54/3nKynlKT_o.png" width="867"></p> 
<p>ELK日志分析系统是一个开源的日志管理平台，它由三个主要组件组成，分别是Elasticsearch、Logstash和Kibana。这三个组件协同工作，提供了一个完整的解决方案，用于收集、存储、搜索、分析和可视化大规模的日志数据。以下是ELK日志分析系统的主要组件及其功能：</p> 
<p><strong>Elasticsearch：</strong></p> 
<ul><li> <p>基于Lucene的分布式存储检索引擎，用于存储各类日志。</p> </li><li> <p>通过RESTful Web接口进行通信，允许用户通过浏览器与Elasticsearch交互。</p> </li><li> <p>实时、分布式、可扩展的搜索引擎，支持全文和结构化搜索。通常用于索引和搜索大容量的日志数据，也适用于其他类型的文档。</p> </li></ul> 
<p><strong>Kibana：</strong></p> 
<ul><li> <p>与Elasticsearch一起部署，是Elasticsearch的数据可视化Dashboard。</p> </li><li> <p>提供图形化的web界面，用于浏览、汇总、分析和搜索Elasticsearch日志数据，方便用户快速理解和利用数据。</p> </li></ul> 
<p><strong>Logstash：</strong></p> 
<ul><li> <p>作为数据收集引擎，支持动态地从各种数据源收集数据。</p> </li><li> <p>对数据进行过滤、分析、丰富和格式统一等操作，然后将处理后的数据存储到用户指定的位置，通常发送给Elasticsearch。</p> </li><li> <p>使用Ruby语言编写，运行在Java虚拟机上，拥有强大的数据处理能力和插件功能。通常用于日志处理，其工作流程涉及输入（数据采集）、过滤（数据过滤）、输出（数据输出）的处理过程。</p> </li></ul> 
<p>ELK的优势在于集成了这三个工具，形成一个完整的日志处理生态系统，使用户能够从数据采集、清洗、存储到可视化展示，完成对日志数据的全方位管理和利用。</p> 
<p><strong>工作流程:</strong></p> 
<ul><li> <p>Logstash负责采集、处理和转发日志数据。</p> </li><li> <p>Elasticsearch用于存储和索引处理后的数据，提供高效的检索和分析功能。</p> </li><li> <p>Kibana通过Web界面与Elasticsearch交互，提供用户友好的数据可视化和分析工具。</p> </li></ul> 
<p><strong>应用场景:</strong></p> 
<ul><li> <p>ELK日志分析系统广泛用于监控和分析应用程序日志、系统日志、安全事件等。</p> </li><li> <p>它可以帮助系统管理员、开发人员和运维团队追踪问题、进行故障排除、监测系统性能，并提供实时的可视化报告。</p> </li></ul> 
<p>为什么使用ELK呢？ELK 是一个广泛使用的开源工具组合，由 ElasticSearch、Logstash 和 Kibana 组成，它们合作来实现日志管理、分析和可视化。</p> 
<ol><li> <p><strong>集中式管理</strong>：当日志分散在不同设备上时，传统的查看方法变得低效且繁琐。ELK 的 Logstash 组件可以帮助集中收集来自各服务器的日志，并将它们统一存储在 ElasticSearch 中，简化了日志管理的复杂性。</p> </li><li> <p><strong>分析和检索</strong>：在日志量庞大、服务器数量众多的情况下，使用传统的 grep、awk 或 Linux 命令来搜索和统计日志信息效率较低。ElasticSearch 提供了强大的搜索和查询功能，通过使用其灵活的查询语言，可以更高效地检索和分析日志数据。</p> </li><li> <p><strong>分布式系统支持</strong>：对于大型分布式系统，问题的定位需要迅速而精准的信息定位。ELK 通过收集和索引分布在不同服务器上的日志数据，结合 Kibana 的可视化功能，使得定位问题的效率大大提高，能够快速定位到具体的服务器和服务模块。</p> </li></ol> 
<p>综上所述，ELK 提供了集中式的日志管理、强大的搜索和分析功能，以及分布式系统支持，使得管理者和开发人员能够更高效地管理、分析和定位问题，尤其适用于大规模的分布式架构环境。</p> 
<hr> 
<h2 id="-1">可以添加的其他组件</h2> 
<p>虽然ELK本身已经是一个强大的日志分析系统，但用户可以根据特定的需求和场景，添加其他组件来扩展其功能和增强性能。以下是一些常见的与ELK组合使用的其他组件：</p> 
<p><strong>Filebeat：</strong></p> 
<ul><li> <p>轻量级的开源日志文件数据搜集器。</p> </li><li> <p>安装在需要采集数据的客户端，可指定目录与日志格式。</p> </li><li> <p>快速收集数据并发送给 Logstash 或直接发送给 Elasticsearch 存储。</p> </li><li> <p>相对于运行在JVM上的Logstash，具有明显的性能优势，常用于EFLK（Elasticsearch + Filebeat + Logstash + Kibana）架构。</p> </li></ul> 
<ol><li><strong>Filebeat 结合 Logstash 的好处：</strong></li></ol> 
<ul><li> <p>Logstash 具有基于磁盘的自适应缓冲系统，可减轻 Elasticsearch 持续写入数据的压力。</p> </li><li> <p>可从其他数据源提取数据，发送到多个目的地，使用条件数据流逻辑组成更复杂的处理管道。</p> </li></ul> 
<ol><li><strong>缓存/消息队列（如Redis、Kafka、RabbitMQ等）：</strong></li></ol> 
<ul><li> <p>用于对高并发日志数据进行流量削峰和缓冲。</p> </li><li> <p>缓冲可以一定程度地保护数据不丢失，同时对整个架构进行应用解耦。</p> </li></ul> 
<ol><li><strong>Fluentd：</strong></li></ol> 
<ul><li> <p>开源数据收集器，常用于EFK（Elasticsearch + Fluentd + Kibana）架构。</p> </li><li> <p>相对于Logstash，Fluentd更易用、资源消耗更少、性能更高，成为Logstash的替代方案。</p> </li><li> <p>在Kubernetes集群中通过DaemonSet运行，通过获取容器日志文件、过滤和转换日志数据，将数据传递到Elasticsearch集群。</p> </li></ul> 
<h2 id="-2">完整日志系统基本特征</h2> 
<ol><li> <p><strong>日志收集（Collection）：</strong> 能够采集多种来源的日志数据，包括系统日志、应用程序日志、安全日志等。这确保系统管理员和开发人员能够获取全面的信息，从而更好地了解系统的运行状况。</p> </li><li> <p><strong>日志传输（Transmission）：</strong> 能够稳定地把日志数据解析、过滤并传输到存储系统。这确保了日志数据能够安全、及时地传递到日志存储的地方，以备后续的分析和查询。</p> </li><li> <p><strong>日志存储（Storage）：</strong> 能够有效地存储日志数据。这可能涉及到数据的归档、索引和压缩，以便在需要时能够快速检索和分析历史日志数据。</p> </li><li> <p><strong>日志分析（Analysis）：</strong> 提供对日志数据的分析功能，通常通过用户界面（UI）实现。这使得用户能够以直观的方式理解日志信息，发现潜在的问题或趋势，并作出相应的决策。</p> </li><li> <p><strong>错误报告和警告（Alerting）：</strong> 能够提供错误报告和监控机制，以便及时发现和响应系统中的问题。这包括对异常事件的警报、通知和报告，有助于预防潜在的故障和安全威胁。</p> </li></ol> 
<p>一个典型的实现这些特征的日志系统是 ELK（Elasticsearch、Logstash、Kibana）堆栈。ELK 能够收集、传输、存储和分析大量的日志数据，提供了强大的搜索和可视化功能，同时支持实时监控和警报。其他类似的日志系统也存在，具体的选择取决于需求和系统架构。</p> 
<h2 id="-3">原理</h2> 
<p><strong>Logstash 部署：</strong></p> 
<ul><li> <p>在需要收集日志的服务器上，部署 Logstash 实例。</p> </li><li> <p>或者，可以选择将日志集中管理在一个服务器上，然后在该日志服务器上部署 Logstash。</p> </li></ul> 
<p><strong>Logstash 日志收集和格式化：</strong></p> 
<ul><li> <p>Logstash 负责从各个部署了 Logstash 的服务器上收集日志数据。</p> </li><li> <p>收集到的原始日志数据经过 Logstash 的过滤和解析，以进行格式化。这包括对日志进行结构化、提取关键字段等操作。</p> </li></ul> 
<p><strong>数据输出到 Elasticsearch：</strong></p> 
<ul><li> <p>格式化后的日志数据被输出到 Elasticsearch 群集中。</p> </li><li> <p>Logstash 与 Elasticsearch 之间使用 Elasticsearch 的 RESTful API 进行通信，将数据发送到 Elasticsearch 节点。</p> </li></ul> 
<p><strong>Elasticsearch 数据存储和索引：</strong></p> 
<ul><li> <p>Elasticsearch 接收 Logstash 发送的数据，负责对数据进行索引、存储和提供搜索功能。</p> </li><li> <p>索引操作使得数据能够被高效地检索，同时 Elasticsearch 利用分布式架构提供高可用性和横向扩展性。</p> </li></ul> 
<p><strong>Kibana 可视化和分析：</strong></p> 
<ul><li> <p>Kibana 是 ELK 堆栈中的可视化工具，通过与 Elasticsearch 通信，查询和检索存储在 Elasticsearch 中的数据。</p> </li><li> <p>用户可以通过 Kibana 创建仪表板、图表和报表，对日志数据进行实时监控、分析和可视化。</p> </li></ul> 
<p><strong>总体而言</strong>，ELK 的工作流程是将日志数据从源系统（服务器）经过 Logstash 过滤和格式化，输出到 Elasticsearch 进行存储和索引，最后通过 Kibana 进行可视化和分析。</p> 
<p>整个 ELK 堆栈的工作流程如下：</p> 
<ol><li> <p><strong>数据收集：</strong> Logstash 从各种数据源中收集原始日志数据。</p> </li><li> <p><strong>数据处理：</strong> Logstash 对原始日志数据进行过滤、解析和结构化。</p> </li><li> <p><strong>数据传输：</strong> 处理后的日志数据通过网络传输到 Elasticsearch。</p> </li><li> <p><strong>数据存储：</strong> Elasticsearch 存储并索引日志数据，使其能够被高效地检索。</p> </li><li> <p><strong>可视化和分析：</strong> Kibana 提供用户界面，用户可以通过它可视化和分析 Elasticsearch 中的日志数据。</p> </li></ol> 
<h2 id="-4">部署实例</h2> 
<h3 id="-5">环境准备</h3> 
<pre><code>Node1节点（2C/4G）：node1/192.168.41.32                    Elasticsearch  Kibana
Node2节点（2C/4G）：node2/192.168.41.33                    Elasticsearch
Apache节点：apache/192.168.41.11                        Logstash  Apache
</code></pre> 
<pre><code>systemctl stop firewalld
setenforce 0
</code></pre> 
<h3 id="elkelasticsearchnode1node2">ELK Elasticsearch 集群部署（在Node1、Node2节点上操作）</h3> 
<p><strong>配置域名解析：</strong></p> 
<ul><li> <p>使用编辑器（vim）打开 "/etc/hosts" 文件。</p> </li><li> <p>在文件中添加如下内容：</p> <pre><code>192.168.41.32 node1
192.168.41.33 node2
</code></pre> <p>这样做的目的是将主机名与相应的IP地址关联起来，以实现域名解析。</p> </li></ul> 
<p><strong>查看Java环境：</strong></p> 
<ul><li> <p>使用命令 <code>java -version</code> 查看Java版本信息。</p> </li><li> <p>如果没有安装Java，则使用命令 <code>yum -y install java</code> 安装Java。</p> </li></ul> 
<h3 id="elasticsearch">部署 Elasticsearch 软件</h3> 
<p><strong>安装 Elasticsearch RPM 包：</strong></p> 
<pre><code>cd /opt
rpm -ivh elasticsearch-5.5.0.rpm   
</code></pre> 
<ul><li> <p>将 Elasticsearch 的 RPM 包（elasticsearch-5.5.0.rpm）上传到 <code>/opt</code> 目录。</p> </li><li> <p>进入 <code>/opt</code> 目录。</p> </li><li> <p>使用 <code>rpm</code> 命令安装 Elasticsearch。</p> </li></ul> 
<p><strong>加载系统服务：</strong></p> 
<pre><code>systemctl daemon-reload    
systemctl enable elasticsearch.service
</code></pre> 
<ul><li> <p>使用 <code>systemctl</code> 命令重新加载系统服务。</p> </li><li> <p>启用 Elasticsearch 服务，使其在系统启动时自动启动。</p> </li></ul> 
<p><strong>修改 Elasticsearch 主配置文件：</strong></p> 
<pre><code>cp /etc/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml.bak
vim /etc/elasticsearch/elasticsearch.yml
--17--取消注释，指定集群名字
cluster.name: my-elk-cluster
--23--取消注释，指定节点名字：Node1节点为node1，Node2节点为node2
node.name: node1
--33--取消注释，指定数据存放路径
path.data: /data/elk_data
--37--取消注释，指定日志存放路径
path.logs: /var/log/elasticsearch/
--43--取消注释，改为在启动的时候不锁定内存
bootstrap.memory_lock: false
--55--取消注释，设置监听地址，0.0.0.0代表所有地址
network.host: 0.0.0.0
--59--取消注释，ES 服务的默认监听端口为9200
http.port: 9200
--68--取消注释，集群发现通过单播实现，指定要发现的节点 node1、node2
discovery.zen.ping.unicast.hosts: ["no1de", "node2"]

grep -v "^#" /etc/elasticsearch/elasticsearch.yml
</code></pre> 
<ul><li> <p>备份原始的 Elasticsearch 配置文件。</p> </li><li> <p>使用 <code>vim</code> 编辑器修改 Elasticsearch 配置文件。</p> 
  <ul><li> <p>取消注释并设置集群名称为 "my-elk-cluster"。</p> </li><li> <p>取消注释并设置节点名称，Node1 节点为 "node1"，Node2 节点为 "node2"。</p> </li><li> <p>取消注释并指定数据存放路径。</p> </li><li> <p>取消注释并指定日志存放路径。</p> </li><li> <p>取消注释并设置启动时不锁定内存。</p> </li><li> <p>取消注释并设置监听地址为 "0.0.0.0"，表示所有地址。</p> </li><li> <p>取消注释并设置 HTTP 监听端口为 9200。</p> </li><li> <p>取消注释并设置集群发现通过单播实现，指定要发现的节点为 "node1"、"node2"。</p> </li></ul></li></ul> 
<p><strong>创建数据存放路径并授权：</strong></p> 
<pre><code>mkdir -p /data/elk_data
chown elasticsearch:elasticsearch /data/elk_data/
</code></pre> 
<ul><li> <p>创建数据存放路径 <code>/data/elk_data</code>。</p> </li><li> <p>授权该路径给 Elasticsearch 用户。</p> </li></ul> 
<p><strong>启动 Elasticsearch 服务：</strong></p> 
<pre><code>systemctl start elasticsearch.service
netstat -antp | grep 9200
</code></pre> 
<ul><li> <p>使用 <code>systemctl</code> 启动 Elasticsearch 服务。</p> </li><li> <p>使用 <code>netstat</code> 命令检查端口 9200 是否被监听。</p> </li></ul> 
<p><strong>查看节点信息：</strong></p> 
<ul><li> <p>通过浏览器访问 <code>http://192.168.41.32:9200</code> 和 <code>http://192.168.41.33:9200</code> 查看 Node1 和 Node2 的信息。</p> </li><li> <p>通过访问 <code>http://192.168.41.32:9200/_cluster/health?pretty</code> 和 <code>http://192.168.41.33:9200/_cluster/health?pretty</code> 检查群集的健康情况，确保状态值为 "green" 表示节点健康运行。</p> </li><li> <p>通过访问 <code>http://192.168.41.32:9200/_cluster/state?pretty</code> 检查群集状态信息。</p> <p>使用上述方式查看群集的状态对用户并不友好，可以通过安装 Elasticsearch-head 插件，可以更方便地管理群集。</p> </li></ul> 
<p><strong>关于 Elasticsearch-head 插件：</strong></p> 
<ul><li>建议安装 Elasticsearch-head 插件以更方便地管理群集。</li></ul> 
<p>前端代码使用 Vue.js（vus）、HTML 和 Node.js 管理工具 npm，以及后端代码使用 Java，使用 Maven 作为打包管理工具，支持生成 war 和 jar 包。</p> 
<h3 id="elasticsearchhead">安装 Elasticsearch-head 插件</h3> 
<p>Elasticsearch 在 5.0 版本后，Elasticsearch-head 插件需要作为独立服务进行安装，需要使用npm工具（NodeJS的包管理工具）安装。</p> 
<p>安装 Elasticsearch-head 需要提前安装好依赖软件 node 和 phantomjs。</p> 
<p>node：是一个基于 Chrome V8 引擎的 JavaScript 运行环境。</p> 
<p>phantomjs：是一个基于 webkit 的JavaScriptAPI，可以理解为一个隐形的浏览器，任何基于 webkit 浏览器做的事情，它都可以做到。</p> 
<p><strong>编译安装 Node.js：</strong></p> 
<pre><code>yum install gcc gcc-c++ make -y
cd /opt
tar zxvf node-v8.2.1.tar.gz

cd node-v8.2.1/
./configure
make &amp;&amp; make install
</code></pre> 
<ul><li> <p>上传 Node.js 软件包 <code>node-v8.2.1.tar.gz</code> 到 <code>/opt</code> 目录。</p> </li><li> <p>安装编译 Node.js 所需的依赖软件（gcc、gcc-c++、make）。</p> </li><li> <p>进入 Node.js 目录，配置、编译并安装 Node.js。</p> </li></ul> 
<p><strong>安装 PhantomJS：</strong>（前端的框架）</p> 
<pre><code>cd /opt
tar jxvf phantomjs-2.1.1-linux-x86_64.tar.bz2 -C /usr/local/src/
cd /usr/local/src/phantomjs-2.1.1-linux-x86_64/bin
cp phantomjs /usr/local/bin
</code></pre> 
<ul><li> <p>上传 PhantomJS 软件包 <code>phantomjs-2.1.1-linux-x86_64.tar.bz2</code> 到 <code>/opt</code> 目录。</p> </li><li> <p>解压 PhantomJS 软件包到 <code>/usr/local/src/</code> 目录。</p> </li><li> <p>进入 PhantomJS 可执行文件目录，将 <code>phantomjs</code> 复制到 <code>/usr/local/bin</code>。</p> </li></ul> 
<p><strong>安装 Elasticsearch-head 数据可视化工具：</strong></p> 
<pre><code>cd /opt
tar zxvf elasticsearch-head.tar.gz -C /usr/local/src/
cd /usr/local/src/elasticsearch-head/
npm install
</code></pre> 
<ul><li> <p>上传 Elasticsearch-head 软件包 <code>elasticsearch-head.tar.gz</code> 到 <code>/opt</code> 目录。</p> </li><li> <p>解压 Elasticsearch-head 软件包到 <code>/usr/local/src/elasticsearch-head/</code> 目录。</p> </li><li> <p>进入 Elasticsearch-head 目录，使用 <code>npm</code> 安装依赖。</p> </li></ul> 
<p><strong>修改 Elasticsearch 主配置文件：</strong></p> 
<pre><code>vim /etc/elasticsearch/elasticsearch.yml
......
--末尾添加以下内容--
http.cors.enabled: true                #开启跨域访问支持，默认为 false
http.cors.allow-origin: "*"            #指定跨域访问允许的域名地址为所有

systemctl restart elasticsearch
</code></pre> 
<ul><li> <p>使用 <code>vim</code> 编辑器修改 Elasticsearch 配置文件，在末尾添加跨域访问的配置。</p> </li><li> <p>重启 Elasticsearch 服务。</p> </li></ul> 
<p><strong>启动 Elasticsearch-head 服务：</strong></p> 
<pre><code>#必须在解压后的 elasticsearch-head 目录下启动服务，进程会读取该目录下的 gruntfile.js 文件，否则可能启动失败。
cd /usr/local/src/elasticsearch-head/
npm run start &amp;

#运行日志输出的信息
&gt; elasticsearch-head@0.0.0 start /usr/local/src/elasticsearch-head
&gt; grunt server

Running "connect:server" (connect) task
Waiting forever...
Started connect web server on http://localhost:9100

#elasticsearch-head 监听的端口是 9100
netstat -natp |grep 9100
</code></pre> 
<ul><li> <p>在解压后的 Elasticsearch-head 目录下启动服务，监听端口为 9100。</p> </li><li> <p>使用 <code>netstat</code> 命令检查端口 9100 是否被监听。</p> </li></ul> 
<p><strong>通过 Elasticsearch-head 查看 Elasticsearch 信息：</strong></p> 
<ul><li> <p>通过浏览器访问 <code>http://192.168.41.32:9100/</code> 地址并连接到 Elasticsearch 群集。</p> </li><li> <p>确保群集健康值为 green（绿色），表示群集很健康。</p> </li></ul> 
<p><strong>插入索引：</strong></p> 
<pre><code>#将一条数据插入到索引 index-demo1 下的类型 test 中的文档 ID 为 1 的位置
curl -X PUT 'localhost:9200/index-demo1/test/1?pretty&amp;pretty' -H 'content-Type: application/json' -d '{"user":"zhangsan","mesg":"hello world"}'

#返回的结果
{
"_index" : "index-demo",
"_type" : "test",
"_id" : "1",
"_version" : 1,
"result" : "created",
"_shards" : {
"total" : 2,
"successful" : 2,
"failed" : 0
},
"created" : true
}
</code></pre> 
<pre><code>对返回结果的解释：

_index：显示文档被索引到的索引名称为 index-demo。
_type：显示文档所属的类型为 test。
_id：显示文档的唯一标识符为 1。
_version：显示文档的版本号为 1。
result：显示请求的结果为 "created"，表示文档被成功创建。
_shards：显示了有关分片的信息。
total：显示了总共有 2 个分片。
successful：显示成功的分片数量为 2。
failed：显示失败的分片数量为 0。
created：显示文档是否被创建，结果为 true，表示文档创建成功。
</code></pre> 
<ul><li> <p>使用 <code>curl</code> 命令插入一个测试索引，索引名称为 <code>index-demo</code>，类型为 <code>test</code>。</p> </li><li> <p>浏览器访问 <code>http://192.168.41.32:9100/</code> 查看索引信息，可以看到索引默认被分片为 5 个，并且有一个副本。</p> </li><li> <p>点击 "数据浏览" ，会发现在 Node1 上创建的索引为 <code>index-demo</code>，类型为 <code>test</code> 的相关信息。</p> </li></ul> 
<h3 id="elklogstashapache">ELK Logstash 部署（在 Apache 节点上操作）</h3> 
<p>Logstash 一般部署在需要监控其日志的服务器。在本案例中，Logstash 部署在 Apache 服务器上，用于收集 Apache 服务器的日志信息并发送到 Elasticsearch。</p> 
<p><strong>安装Apache服务（httpd）：</strong></p> 
<pre><code>yum -y install httpd
systemctl start httpd
</code></pre> 
<ul><li> <p>使用 <code>yum</code> 包管理器安装Apache服务，命令为 <code>yum -y install httpd</code>。</p> </li><li> <p>启动Apache服务，命令为 <code>systemctl start httpd</code>。</p> </li></ul> 
<p><strong>安装Java环境：</strong></p> 
<pre><code>yum -y install java
java -version
</code></pre> 
<ul><li> <p>使用 <code>yum</code> 包管理器安装Java环境，命令为 <code>yum -y install java</code>。</p> </li><li> <p>使用 <code>java -version</code> 命令检查已安装的Java版本。</p> </li></ul> 
<p><strong>安装Logstash：</strong></p> 
<pre><code>#上传软件包 logstash-5.5.1.rpm 到/opt目录下
cd /opt
rpm -ivh logstash-5.5.1.rpm                           
systemctl start logstash.service                      
systemctl enable logstash.service

ln -s /usr/share/logstash/bin/logstash /usr/local/bin/
</code></pre> 
<ul><li> <p>将Logstash软件包（logstash-5.5.1.rpm）上传到 <code>/opt</code> 目录。</p> </li><li> <p>进入 <code>/opt</code> 目录，命令为 <code>cd /opt</code>。</p> </li><li> <p>使用 <code>rpm -ivh</code> 安装Logstash软件包，命令为 <code>rpm -ivh logstash-5.5.1.rpm</code>。</p> </li><li> <p>启动Logstash服务，命令为 <code>systemctl start logstash.service</code>。</p> </li><li> <p>设置Logstash服务开机自启动，命令为 <code>systemctl enable logstash.service</code>。</p> </li><li> <p>创建Logstash可执行文件的符号链接，命令为 <code>ln -s /usr/share/logstash/bin/logstash /usr/local/bin/</code>。</p> </li></ul> 
<p><strong>测试 Logstash</strong></p> 
<p>常用选项解释：</p> 
<ul><li> <p><code>-f</code>：指定Logstash的配置文件。根据配置文件配置 Logstash 的输入和输出流。</p> </li><li> <p><code>-e</code>：从命令行中获取配置字符串。该字符串可以被当作 Logstash 的配置（如果是空，则默认使用 stdin 作为输入，stdout 作为输出）。</p> </li><li> <p><code>-t</code>：测试配置文件是否正确，然后退出。</p> </li></ul> 
<p><strong>定义输入和输出流</strong>：</p> 
<pre><code>#输入采用标准输入，输出采用标准输出（类似管道）
logstash -e 'input { stdin{} } output { stdout{} }'
......
www.baidu.com                                        #键入内容（标准输入）
                                                    #输出结果（标准输出）
www.sina.com.cn                                        #键入内容（标准输入）
                                                     #输出结果（标准输出）

//执行 ctrl+c 退出
</code></pre> 
<p>Logstash的基本用法和交互式命令行模式下的示例。在这个例子中：</p> 
<ul><li> <p><code>logstash -e 'input { stdin{} } output { stdout{} }'</code>：这个命令启动了Logstash，并使用标准输入作为输入，标准输出作为输出。它创建了一个类似管道的功能，接收输入并输出经过处理后的结果。</p> </li><li> <p>接着你键入了 <code>www.baidu.com</code> 作为输入，Logstash对其进行处理并输出了时间戳、节点信息以及输入内容。</p> </li><li> <p>随后你键入了 <code>www.sina.com.cn</code>，Logstash同样对其进行处理并输出了时间戳、节点信息和输入内容。</p> </li><li> <p>最后通过执行 <code>ctrl+c</code> 中断了Logstash的运行，退出了这个交互式命令行模式。</p> </li></ul> 
<pre><code>#**使用 rubydebug 输出详细格式显示，codec 为一种编解码器**
logstash -e 'input { stdin{} } output { stdout{ codec=&gt;rubydebug } }'

logstash -e 'input { stdin{} } output { elasticsearch { hosts=&gt;["192.168.31.32:9200"] } }'

www.baidu.com                                        #键入内容（标准输入）
www.sina.com.cn                                        #键入内容（标准输入）
www.google.com                                        #键入内容（标准输入）
</code></pre> 
<p>两个Logstash的命令行示例，分别演示了如何使用 <code>rubydebug</code> 编解码器将详细格式显示在标准输出中，以及如何将信息通过Logstash发送到Elasticsearch中。</p> 
<ol><li><strong>使用 <code>rubydebug</code> 输出详细格式</strong>：</li></ol> 
<ul><li> <p><code>logstash -e 'input { stdin{} } output { stdout{ codec=&gt;rubydebug } }'</code>：这个命令启动Logstash，使用标准输入作为输入，将处理结果以详细的 <code>rubydebug</code> 格式输出到标准输出。</p> </li><li> <p>输入了 <code>www.baidu.com</code>，Logstash对其进行处理，并以JSON格式输出了包含时间戳、版本、主机信息和消息的结果。</p> </li></ul> 
<ol><li><strong>使用 Logstash 将信息写入 Elasticsearch 中</strong>：</li></ol> 
<ul><li> <p><code>logstash -e 'input { stdin{} } output { elasticsearch { hosts=&gt;["192.168.41.32:9200"] } }'</code>：这个命令启动Logstash，使用标准输入作为输入，并将处理结果发送到Elasticsearch中。</p> </li><li> <p>输入了三个网址，但结果并没有直接显示在标准输出中，而是被发送到Elasticsearch中。</p> </li></ul> 
<ol><li><strong>查看结果</strong>：</li></ol> 
<ul><li>你可以通过浏览器访问 <code>http://192.168.41.32:9100/</code> 来查看Elasticsearch中的索引信息和数据浏览。</li></ul> 
<p><strong>定义 logstash 配置文件</strong></p> 
<p>配置文件组成，Logstash 配置文件基本由三部分组成：input、output 以及 filter（可选，根据需要选择使用）。</p> 
<ul><li> <p>输入 (input)：从数据源采集数据，常见的数据源如Kafka、日志文件等</p> </li><li> <p>过滤器 (filter)：数据处理层，包括对数据进行格式化处理、数据类型转换、数据过滤等，支持正则表达式</p> </li><li> <p>输出 (output)：将Logstash收集的数据经由过滤器处理之后输出到Elasticsearch。</p> </li></ul> 
<pre><code>#格式如下：
input {...}
filter {...}
output {...}

#在每个部分中，也可以指定多个访问方式。例如，若要指定两个日志来源文件，则格式如下：
input {
    file { path =&gt;"/var/log/messages" type =&gt;"syslog"}
    file { path =&gt;"/var/log/httpd/access.log" type =&gt;"apache"}
}
</code></pre> 
<p><strong>修改Logstash配置文件</strong>：</p> 
<pre><code>#修改 Logstash 配置文件，让其收集系统日志/var/log/messages，并将其输出到 elasticsearch 中。
chmod +r /var/log/messages                    #让 Logstash 可以读取日志

vim /etc/logstash/conf.d/system.conf
input {
    file{
        path =&gt;"/var/log/messages"                        #指定要收集的日志的位置
        type =&gt;"system"                                    #自定义日志类型标识
        start_position =&gt;"beginning"                    #表示从开始处收集
    }
}
output {
    elasticsearch {                                        #输出到 elasticsearch
        hosts =&gt; ["192.168.41.32:9200"]                    #指定 elasticsearch 服务器的地址和端口
        index =&gt;"system-%{+YYYY.MM.dd}"                    #指定输出到 elasticsearch 的索引格式
    }
}
</code></pre> 
<ul><li> <p>设置Logstash读取系统日志文件<code>/var/log/messages</code>。</p> </li><li> <p>使用<code>chmod</code>命令确保Logstash有权限读取日志文件。</p> </li><li> <p>创建一个新的Logstash配置文件<code>system.conf</code>并指定输入和输出配置。</p> </li></ul> 
<p><strong>重启Logstash</strong>：</p> 
<pre><code>systemctl restart logstash 
</code></pre> 
<ul><li>使用<code>systemctl restart logstash</code>命令重启Logstash服务。</li></ul> 
<p><strong>查看结果</strong>：</p> 
<ul><li>通过浏览器访问指定的Elasticsearch地址（如<code>http://192.168.41.12:9100/</code>）可以查看到收集的索引信息。</li></ul> 
<h3 id="elkkiabananode1">ELK Kiabana 部署（在 Node1 节点上操作）</h3> 
<p><strong>安装 Kibana:</strong></p> 
<pre><code>#上传软件包 kibana-5.5.1-x86_64.rpm 到/opt目录
cd /opt
rpm -ivh kibana-5.5.1-x86_64.rpm
</code></pre> 
<ul><li> <p>进入 <code>/opt</code> 目录。</p> </li><li> <p>使用 <code>rpm</code> 命令安装 Kibana 软件包 <code>kibana-5.5.1-x86_64.rpm</code>。</p> </li></ul> 
<p><strong>设置 Kibana 的主配置文件:</strong></p> 
<pre><code>vim /etc/kibana/kibana.yml
--2--取消注释，Kiabana 服务的默认监听端口为5601
server.port: 5601
--7--取消注释，设置 Kiabana 的监听地址，0.0.0.0代表所有地址
server.host: "0.0.0.0"
--21--取消注释，设置和 Elasticsearch 建立连接的地址和端口
elasticsearch.url: "http://192.168.41.32:9200" 
--30--取消注释，设置在 elasticsearch 中添加.kibana索引
kibana.index: ".kibana"
</code></pre> 
<ul><li> <p>使用 <code>vim</code> 编辑器打开 Kibana 的主配置文件 <code>kibana.yml</code>。</p> </li><li> <p>在第 2 行取消注释，设置 Kibana 服务的默认监听端口为 5601。</p> </li><li> <p>在第 7 行取消注释，设置 Kibana 的监听地址为 "0.0.0.0"，表示对所有地址开放。</p> </li><li> <p>在第 21 行取消注释，设置连接 Elasticsearch 的地址和端口为 "http://192.168.41.32:9200"。</p> </li><li> <p>在第 30 行取消注释，设置在 Elasticsearch 中添加 <code>.kibana</code> 索引。</p> </li></ul> 
<p><strong>启动 Kibana 服务:</strong></p> 
<pre><code>systemctl start kibana.service
systemctl enable kibana.service

netstat -natp | grep 5601
</code></pre> 
<ul><li> <p>使用 <code>systemctl</code> 启动 Kibana 服务。</p> </li><li> <p>使用 <code>systemctl</code> 启用 Kibana 服务，确保在系统启动时自动启动。</p> </li><li> <p>使用 <code>netstat</code> 命令检查端口 5601 是否被监听。</p> </li></ul> 
<p><strong>验证 Kibana:</strong></p> 
<ul><li> <p>在浏览器中访问 <code>http://192.168.41.32:5601</code>。</p> </li><li> <p>第一次登录需要添加一个 Elasticsearch 索引：</p> 
  <ul><li> <p>在 "Index name or pattern" 中输入：<code>system-*</code>，这是之前配置的 Output 前缀。</p> </li><li> <p>点击 "create" 按钮创建索引。</p> </li><li> <p>点击 "Discover" 按钮查看图表信息和日志信息。</p> </li></ul></li><li> <p>数据展示可以分类显示，在 "Available Fields" 中选择 "host"，然后点击 "add" 按钮，可以看到按照 "host" 筛选后的结果。</p> </li></ul> 
<p><strong>将 Apache 服务器的日志（访问的、错误的）添加到 Elasticsearch 并通过 Kibana 显示</strong></p> 
<p><strong>编辑 Logstash 配置文件：</strong></p> 
<pre><code>vim /etc/logstash/conf.d/apache_log.conf
</code></pre> 
<ul><li> <p>使用 <code>vim</code> 编辑器打开 Logstash 配置文件 <code>apache_log.conf</code>。</p> </li><li> <p>配置 Logstash 输入插件，将 Apache 服务器的访问日志 <code>/etc/httpd/logs/access_log</code> 和错误日志 <code>/etc/httpd/logs/error_log</code> 添加为输入。</p> </li><li> <p>设置日志类型为 "access" 和 "error"，并从文件开头读取日志。</p> </li></ul> 
<pre><code>input {
    file {
        path =&gt; "/etc/httpd/logs/access_log"
        type =&gt; "access"
        start_position =&gt; "beginning"
    }
    file {
        path =&gt; "/etc/httpd/logs/error_log"
        type =&gt; "error"
        start_position =&gt; "beginning"
    }
}

output {
    if [type] == "access" {
        elasticsearch {
            hosts =&gt; ["192.168.41.32:9200"]
            index =&gt; "apache_access-%{+YYYY.MM.dd}"
        }
    }
    if [type] == "error" {
        elasticsearch {
            hosts =&gt; ["192.168.41.32:9200"]
            index =&gt; "apache_error-%{+YYYY.MM.dd}"
        }
    }
}
</code></pre> 
<p><strong>运行 Logstash:</strong></p> 
<ul><li> <p>进入 Logstash 配置文件所在的目录。</p> </li><li> <p>使用 Logstash 执行配置文件 <code>apache_log.conf</code>。</p> </li></ul> 
<pre><code>cd /etc/logstash/conf.d/
/usr/share/logstash/bin/logstash -f apache_log.conf
</code></pre> 
<p><strong>检查索引是否创建：</strong></p> 
<ul><li>在浏览器中访问 <code>http://192.168.41.32:9100</code>，查看索引是否已经成功创建。</li></ul> 
<p><strong>登录 Kibana 添加索引：</strong></p> 
<ul><li> <p>在浏览器中访问 <code>http://192.168.41.32:5601</code>，登录 Kibana。</p> </li><li> <p>点击 "Create Index Pattern" 按钮，添加索引。输入之前配置的 Output 前缀 <code>apache_access-*</code> 并单击“Create”按钮。在用相同的方法添加 apache_error-*索引。</p> </li><li> <p>在 "Discover" 选项卡中选择刚添加的 <code>apache_access-*</code> 和 <code>apache_error-*</code> 索引，可以查看相应的图表和日志信息。</p> </li></ul> 
<hr> 
<h2 id="elfkfilebeatelk">ELFK（Filebeat+ELK 部署）</h2> 
<h3 id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">环境准备</h3> 
<pre><code>Node1节点（2C/4G）：node1/192.168.41.32                    Elasticsearch  Kibana
Node2节点（2C/4G）：node2/192.168.41.33                    Elasticsearch
Apache节点：apache/192.168.41.11                        Logstash  Apache
Filebeat节点：filebeat/192.168.41.34                    Filebeat
</code></pre> 
<h3 id="node1"><strong>Node1节点配置</strong></h3> 
<h4 id="filebeat">安装Filebeat</h4> 
<pre><code>1．安装 Filebeat
#上传软件包 filebeat-6.2.4-linux-x86_64.tar.gz 到/opt目录
tar zxvf filebeat-6.2.4-linux-x86_64.tar.gz
mv filebeat-6.2.4-linux-x86_64/ /usr/local/filebeat
</code></pre> 
<ul><li> <p>安装Filebeat软件包，并将其解压到<code>/usr/local/filebeat</code>目录。</p> </li><li> <p>切换到Filebeat目录：<code>cd /usr/local/filebeat</code></p> </li><li> <p>编辑Filebeat主配置文件<code>filebeat.yml</code>，配置日志路径、字段和输出目的地。</p> </li></ul> 
<h4 id="filebeatyml"><strong>filebeat.yml配置</strong></h4> 
<pre><code>2．设置 filebeat 的主配置文件
cd /usr/local/filebeat

vim filebeat.yml
filebeat.prospectors:
- type: log         #指定 log 类型，从日志文件中读取消息
  enabled: true
  paths:
    - /var/log/messages       #指定监控的日志文件
    - /var/log/*.log
  fields:           #可以使用 fields 配置选项设置一些参数字段添加到 output 中
    service_name: filebeat
    log_type: log
    service_id: 192.168.41.34

--------------Elasticsearch output-------------------
(全部注释掉)

----------------Logstash output---------------------
output.logstash:
  hosts: ["192.168.41.11:5044"]      #指定 logstash 的 IP 和端口

#启动 filebeat
./filebeat -e -c filebeat.yml
</code></pre> 
<p>解释一下其中的部分：</p> 
<ul><li> <p><strong>filebeat.prospectors</strong>:</p> </li><li> <p><code>type: log</code>: 指定Filebeat监视的是日志文件类型的数据。</p> </li><li> <p><code>enabled: true</code>: 表示启用了这个prospector，即Filebeat会监视这些路径下的日志文件。</p> </li><li> <p><code>paths</code>: 列出了要监视的日志文件路径。在这里，监视了<code>/var/log/messages</code>和<code>/var/log/*.log</code>等通配符匹配的日志文件。</p> </li><li> <p><code>fields</code>: 这个部分用于设置一些附加的字段，这些字段将被添加到输出中。</p> 
  <ul><li> <p><code>service_name</code>: 设置了一个服务名称字段为<code>filebeat</code>。</p> </li><li> <p><code>log_type</code>: 定义了日志类型字段为<code>log</code>。</p> </li><li> <p><code>service_id</code>: 标识了服务ID为<code>192.168.41.34</code>。</p> </li></ul></li><li> <p><strong>Elasticsearch output</strong>:</p> </li><li> <p>这部分的配置已经全部被注释掉了，意味着Filebeat不会将数据直接发送到Elasticsearch。</p> </li><li> <p><strong>Logstash output</strong>:</p> </li><li> <p><code>output.logstash</code>: 这里指定了Filebeat要将数据发送到Logstash的配置。</p> 
  <ul><li><code>hosts</code>: 指定Logstash的IP和端口为<code>192.168.41.11:5044</code>，这是Logstash接收Beats数据的地址和端口。</li></ul></li></ul> 
<p>最后的部分是启动Filebeat的命令<code>./filebeat -e -c filebeat.yml</code>，它会以命令行方式启动Filebeat，使用配置文件<code>filebeat.yml</code>来运行。这意味着Filebeat将开始监视指定的日志文件，并将数据发送到指定的Logstash地址和端口。</p> 
<p><strong>filebeat.yml配置说明：</strong></p> 
<ul><li> <p><code>filebeat.prospectors</code>: 配置Filebeat监控的日志文件路径。</p> </li><li> <p><code>fields</code>: 设置一些参数字段，这些字段将添加到输出中。</p> </li><li> <p>Elasticsearch输出：注释掉该部分。</p> </li><li> <p>Logstash输出：指定Logstash的IP和端口。</p> </li></ul> 
<h4 id="filebeat-1"><strong>启动Filebeat</strong></h4> 
<pre><code>./filebeat -e -c filebeat.yml
</code></pre> 
<h3 id="logstash"><strong>Logstash节点配置</strong></h3> 
<h4 id="logstash-1">新建Logstash 配置文件</h4> 
<pre><code>cd /etc/logstash/conf.d

vim logstash.conf
input {
    beats {
        port =&gt; "5044"
    }
}
output {
    elasticsearch {
        hosts =&gt; ["192.168.41.32:9200"]
        index =&gt; "%{[fields][service_name]}-%{+YYYY.MM.dd}"
    }
    stdout {
        codec =&gt; rubydebug
    }
}
#启动 logstash
logstash -f logstash.conf
</code></pre> 
<p>解释其中的部分：</p> 
<ul><li> <p><strong>Input</strong>:</p> </li><li> <p><code>beats</code>: 这是Logstash的输入插件，用于接收来自Beats系列产品（比如Filebeat）的数据。指定了Logstash监听的端口为5044，这是Beats默认发送数据的端口。</p> </li><li> <p><strong>Output</strong>:</p> </li><li> <p><code>elasticsearch</code>: 这部分指定了Logstash输出到Elasticsearch的设置。</p> 
  <ul><li> <p><code>hosts</code>: 指定Elasticsearch的地址为<code>192.168.41.32:9200</code>，这是Elasticsearch的默认地址和端口。</p> </li><li> <p><code>index</code>: 这是用于指定数据写入Elasticsearch时的索引模式。在这里，使用了<code>%{[fields][service_name]}-%{+YYYY.MM.dd}</code>，它会根据Filebeat中指定的<code>service_name</code>字段和当前日期来创建索引，例如，如果<code>service_name</code>是<code>filebeat</code>，则索引会类似于<code>filebeat-2023.12.25</code>（根据当前日期）。</p> </li></ul></li><li> <p><strong>stdout</strong>:</p> </li><li> <p>这部分是可选的，它会将接收到的数据以Ruby编程语言的调试格式输出到标准输出（通常是命令行窗口），以便开发和调试时查看日志。</p> </li></ul> 
<p>这个配置文件告诉Logstash从5044端口接收Beats数据，然后将其输出到指定的Elasticsearch地址，并根据指定的索引模式进行索引。同时，还会在标准输出中以Ruby调试格式显示数据，以帮助调试Logstash配置。</p> 
<h4 id="logstash-2">启动logstash</h4> 
<pre><code>#启动 logstash
logstash -f logstash.conf
</code></pre> 
<h3 id="%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95">浏览器测试</h3> 
<p><strong>Kibana操作：</strong></p> 
<ul><li> <p>在浏览器中访问<code>http://192.168.41.32:5601</code>，登录Kibana。</p> </li><li> <p>在Kibana界面中，单击“Create Index Pattern”按钮，添加索引模式“filebeat-*”。</p> </li><li> <p>单击“Create”按钮创建索引模式。</p> </li><li> <p>单击“Discover”按钮，可以查看图表信息和日志信息。</p> </li></ul> 
<p>在一个分布式环境中如何设置和配置日志收集和展示系统，使用Filebeat负责收集日志，Logstash负责处理和传输，Elasticsearch存储，而Kibana则用于可视化和查询。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3e4c98ba3a6cb87bda87544bbec80745/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker简述与基础部署详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1523869b09f4d760bba41007625dff22/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">GFS分布式文件系统（详解与配置）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>