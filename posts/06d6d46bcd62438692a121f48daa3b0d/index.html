<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>bpython怎么保存_python  - 如何使用b将文件上传到S3存储桶中的目录 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="bpython怎么保存_python  - 如何使用b将文件上传到S3存储桶中的目录" />
<meta property="og:description" content="python - 如何使用b将文件上传到S3存储桶中的目录
我想使用python在s3存储桶中复制一个文件。
例如：我有桶名=测试。 在桶中，我有2个文件夹名称“dump”＆amp;“输入”。 现在我想使用python将文件从本地目录复制到S3“dump”文件夹...任何人都可以帮助我吗？
10个解决方案
81 votes
试试这个...
import boto
import boto.s3
import sys
from boto.s3.key import Key
AWS_ACCESS_KEY_ID = &#39;&#39;
AWS_SECRET_ACCESS_KEY = &#39;&#39;
bucket_name = AWS_ACCESS_KEY_ID.lower() &#43; &#39;-dump&#39;
conn = boto.connect_s3(AWS_ACCESS_KEY_ID,
AWS_SECRET_ACCESS_KEY)
bucket = conn.create_bucket(bucket_name,
location=boto.s3.connection.Location.DEFAULT)
testfile = &#34;replace this with an actual filename&#34;
print &#39;Uploading %s to Amazon S3 bucket %s&#39; % \
(testfile, bucket_name)
def percent_cb(complete, total):
sys.stdout.write(&#39;.&#39;)
sys.stdout.flush()
k = Key(bucket)
k.key = &#39;my test file&#39;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/06d6d46bcd62438692a121f48daa3b0d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-05T14:32:43+08:00" />
<meta property="article:modified_time" content="2020-12-05T14:32:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">bpython怎么保存_python  - 如何使用b将文件上传到S3存储桶中的目录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>python - 如何使用b将文件上传到S3存储桶中的目录</p> 
 <p>我想使用python在s3存储桶中复制一个文件。</p> 
 <p>例如：我有桶名=测试。 在桶中，我有2个文件夹名称“dump”＆amp;“输入”。 现在我想使用python将文件从本地目录复制到S3“dump”文件夹...任何人都可以帮助我吗？</p> 
 <p>10个解决方案</p> 
 <p>81 votes</p> 
 <p>试试这个...</p> 
 <p>import boto</p> 
 <p>import boto.s3</p> 
 <p>import sys</p> 
 <p>from boto.s3.key import Key</p> 
 <p>AWS_ACCESS_KEY_ID = ''</p> 
 <p>AWS_SECRET_ACCESS_KEY = ''</p> 
 <p>bucket_name = AWS_ACCESS_KEY_ID.lower() + '-dump'</p> 
 <p>conn = boto.connect_s3(AWS_ACCESS_KEY_ID,</p> 
 <p>AWS_SECRET_ACCESS_KEY)</p> 
 <p>bucket = conn.create_bucket(bucket_name,</p> 
 <p>location=boto.s3.connection.Location.DEFAULT)</p> 
 <p>testfile = "replace this with an actual filename"</p> 
 <p>print 'Uploading %s to Amazon S3 bucket %s' % \</p> 
 <p>(testfile, bucket_name)</p> 
 <p>def percent_cb(complete, total):</p> 
 <p>sys.stdout.write('.')</p> 
 <p>sys.stdout.flush()</p> 
 <p>k = Key(bucket)</p> 
 <p>k.key = 'my test file'</p> 
 <p>k.set_contents_from_filename(testfile,</p> 
 <p>cb=percent_cb, num_cb=10)</p> 
 <p>[UPDATE]我不是pythonist，所以感谢关于import语句的提醒。另外，我不建议在自己的源代码中放置凭据。 如果您在AWS内部运行，请使用带有实例配置文件的IAM凭据([http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html]，并保持不变 您的开发/测试环境中的行为，使用来自AdRoll的全息图([https://github.com/AdRoll/hologram]]</p> 
 <p>Felipe Garcia answered 2019-06-14T21:32:32Z</p> 
 <p>36 votes</p> 
 <p>不需要那么复杂：</p> 
 <p>s3_connection = boto.connect_s3()</p> 
 <p>bucket = s3_connection.get_bucket('your bucket name')</p> 
 <p>key = boto.s3.key.Key(bucket, 'some_file.zip')</p> 
 <p>with open('some_file.zip') as f:</p> 
 <p>key.send_file(f)</p> 
 <p>vcarel answered 2019-06-14T21:32:56Z</p> 
 <p>31 votes</p> 
 <p>我用过它，实现起来非常简单</p> 
 <p>import tinys3</p> 
 <p>conn = tinys3.Connection('S3_ACCESS_KEY','S3_SECRET_KEY',tls=True)</p> 
 <p>f = open('some_file.zip','rb')</p> 
 <p>conn.upload('some_file.zip',f,'my_bucket')</p> 
 <p>[https://www.smore.com/labs/tinys3/]</p> 
 <p>Oren Efron answered 2019-06-14T21:33:26Z</p> 
 <p>15 votes</p> 
 <p>import boto3</p> 
 <p>s3 = boto3.resource('s3')</p> 
 <p>BUCKET = "test"</p> 
 <p>s3.Bucket(BUCKET).upload_file("your/local/file", "dump/file")</p> 
 <p>Boris answered 2019-06-14T21:33:43Z</p> 
 <p>10 votes</p> 
 <p>这也有效：</p> 
 <p>import os</p> 
 <p>import boto</p> 
 <p>import boto.s3.connection</p> 
 <p>from boto.s3.key import Key</p> 
 <p>try:</p> 
 <p>conn = boto.s3.connect_to_region('us-east-1',</p> 
 <p>aws_access_key_id = 'AWS-Access-Key',</p> 
 <p>aws_secret_access_key = 'AWS-Secrete-Key',</p> 
 <p># host = 's3-website-us-east-1.amazonaws.com',</p> 
 <p># is_secure=True, # uncomment if you are not using ssl</p> 
 <p>calling_format = boto.s3.connection.OrdinaryCallingFormat(),</p> 
 <p>)</p> 
 <p>bucket = conn.get_bucket('YourBucketName')</p> 
 <p>key_name = 'FileToUpload'</p> 
 <p>path = 'images/holiday' #Directory Under which file should get upload</p> 
 <p>full_key_name = os.path.join(path, key_name)</p> 
 <p>k = bucket.new_key(full_key_name)</p> 
 <p>k.set_contents_from_filename(key_name)</p> 
 <p>except Exception,e:</p> 
 <p>print str(e)</p> 
 <p>print "error"</p> 
 <p>Piyush S. Wanare answered 2019-06-14T21:34:01Z</p> 
 <p>9 votes</p> 
 <p>from boto3.s3.transfer import S3Transfer</p> 
 <p>import boto3</p> 
 <p>#have all the variables populated which are required below</p> 
 <p>client = boto3.client('s3', aws_access_key_id=access_key,aws_secret_access_key=secret_key)</p> 
 <p>transfer = S3Transfer(client)</p> 
 <p>transfer.upload_file(filepath, bucket_name, folder_name+"/"+filename)</p> 
 <p>Manish Mehra answered 2019-06-14T21:34:18Z</p> 
 <p>4 votes</p> 
 <p>import boto</p> 
 <p>from boto.s3.key import Key</p> 
 <p>AWS_ACCESS_KEY_ID = ''</p> 
 <p>AWS_SECRET_ACCESS_KEY = ''</p> 
 <p>END_POINT = '' # eg. us-east-1</p> 
 <p>S3_HOST = '' # eg. s3.us-east-1.amazonaws.com</p> 
 <p>BUCKET_NAME = 'test'</p> 
 <p>FILENAME = 'upload.txt'</p> 
 <p>UPLOADED_FILENAME = 'dumps/upload.txt'</p> 
 <p># include folders in file path. If it doesn't exist, it will be created</p> 
 <p>s3 = boto.s3.connect_to_region(END_POINT,</p> 
 <p>aws_access_key_id=AWS_ACCESS_KEY_ID,</p> 
 <p>aws_secret_access_key=AWS_SECRET_ACCESS_KEY,</p> 
 <p>host=S3_HOST)</p> 
 <p>bucket = s3.get_bucket(BUCKET_NAME)</p> 
 <p>k = Key(bucket)</p> 
 <p>k.key = UPLOADED_FILENAME</p> 
 <p>k.set_contents_from_filename(FILENAME)</p> 
 <p>Shakti answered 2019-06-14T21:34:35Z</p> 
 <p>0 votes</p> 
 <p>xmlstr = etree.tostring(listings, encoding='utf8', method='xml')</p> 
 <p>conn = boto.connect_s3(</p> 
 <p>aws_access_key_id = access_key,</p> 
 <p>aws_secret_access_key = secret_key,</p> 
 <p># host = '.s3.amazonaws.com',</p> 
 <p>host = 'bycket.s3.amazonaws.com',</p> 
 <p>#is_secure=False, # uncomment if you are not using ssl</p> 
 <p>calling_format = boto.s3.connection.OrdinaryCallingFormat(),</p> 
 <p>)</p> 
 <p>conn.auth_region_name = 'us-west-1'</p> 
 <p>bucket = conn.get_bucket('resources', validate=False)</p> 
 <p>key= bucket.get_key('filename.txt')</p> 
 <p>key.set_contents_from_string("SAMPLE TEXT")</p> 
 <p>key.set_canned_acl('public-read')</p> 
 <p>Martin answered 2019-06-14T21:34:51Z</p> 
 <p>0 votes</p> 
 <p>这是一个三班轮。 只需按照boto3文档中的说明操作即可。</p> 
 <p>import boto3</p> 
 <p>s3 = boto3.resource(service_name = 's3')</p> 
 <p>s3.meta.client.upload_file(Filename = 'C:/foo/bar/baz.filetype', Bucket = 'yourbucketname', Key = 'baz.filetype')</p> 
 <p>一些重要的论点是：</p> 
 <p>参数：</p> 
 <p>文件名(~\.aws) - 要上载的文件的路径。</p> 
 <p>Bucket(~\.aws) - 要上载到的存储桶的名称。</p> 
 <p>密钥(~\.aws) - 要在s3存储桶中分配给文件的名称。 这可能与文件名或您选择的其他名称相同，但文件类型应保持不变。</p> 
 <p>注意：我假设您已将凭据保存在~\.aws文件夹中，如boto3文档中的最佳配置实践中所述。</p> 
 <p>Nde Samuel Mbah answered 2019-06-14T21:35:56Z</p> 
 <p>0 votes</p> 
 <p>对于上传文件夹示例如下代码和S3文件夹图片</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>import boto</p> 
 <p>import boto.s3</p> 
 <p>import boto.s3.connection</p> 
 <p>import os.path</p> 
 <p>import sys</p> 
 <p># Fill in info on data to upload</p> 
 <p># destination bucket name</p> 
 <p>bucket_name = 'willie20181121'</p> 
 <p># source directory</p> 
 <p>sourceDir = '/home/willie/Desktop/x/' #Linux Path</p> 
 <p># destination directory name (on s3)</p> 
 <p>destDir = '/test1/' 'S3 Path</p> 
 <p>#max size in bytes before uploading in parts. between 1 and 5 GB recommended</p> 
 <p>MAX_SIZE = 20 * 1000 * 1000</p> 
 <p>#size of parts when uploading in parts</p> 
 <p>PART_SIZE = 6 * 1000 * 1000</p> 
 <p>access_key = 'MPBVAQ*******IT****'</p> 
 <p>secret_key = '11t63yDV***********HgUcgMOSN*****'</p> 
 <p>conn = boto.connect_s3(</p> 
 <p>aws_access_key_id = access_key,</p> 
 <p>aws_secret_access_key = secret_key,</p> 
 <p>host = '******.org.tw',</p> 
 <p>is_secure=False, # uncomment if you are not using ssl</p> 
 <p>calling_format = boto.s3.connection.OrdinaryCallingFormat(),</p> 
 <p>)</p> 
 <p>bucket = conn.create_bucket(bucket_name,</p> 
 <p>location=boto.s3.connection.Location.DEFAULT)</p> 
 <p>uploadFileNames = []</p> 
 <p>for (sourceDir, dirname, filename) in os.walk(sourceDir):</p> 
 <p>uploadFileNames.extend(filename)</p> 
 <p>break</p> 
 <p>def percent_cb(complete, total):</p> 
 <p>sys.stdout.write('.')</p> 
 <p>sys.stdout.flush()</p> 
 <p>for filename in uploadFileNames:</p> 
 <p>sourcepath = os.path.join(sourceDir + filename)</p> 
 <p>destpath = os.path.join(destDir, filename)</p> 
 <p>print ('Uploading %s to Amazon S3 bucket %s' % \</p> 
 <p>(sourcepath, bucket_name))</p> 
 <p>filesize = os.path.getsize(sourcepath)</p> 
 <p>if filesize &gt; MAX_SIZE:</p> 
 <p>print ("multipart upload")</p> 
 <p>mp = bucket.initiate_multipart_upload(destpath)</p> 
 <p>fp = open(sourcepath,'rb')</p> 
 <p>fp_num = 0</p> 
 <p>while (fp.tell() &lt; filesize):</p> 
 <p>fp_num += 1</p> 
 <p>print ("uploading part %i" %fp_num)</p> 
 <p>mp.upload_part_from_file(fp, fp_num, cb=percent_cb, num_cb=10, size=PART_SIZE)</p> 
 <p>mp.complete_upload()</p> 
 <p>else:</p> 
 <p>print ("singlepart upload")</p> 
 <p>k = boto.s3.key.Key(bucket)</p> 
 <p>k.key = destpath</p> 
 <p>k.set_contents_from_filename(sourcepath,</p> 
 <p>cb=percent_cb, num_cb=10)</p> 
 <p>PS：有关更多参考URL</p> 
 <p>Willie Cheng answered 2019-06-14T21:36:26Z</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2e6e063ca58d2978a276c705979345b3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">pythonarp工具_Python 实现ARP扫描欺骗工具</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/294d15975a1e35d995aa44a536165295/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue 基础知识</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>