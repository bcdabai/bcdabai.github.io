<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【研一小白论文精读】SwAV - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【研一小白论文精读】SwAV" />
<meta property="og:description" content="Unsupervised Learning of Visual Features by Contrasting Cluster Assignments The main contribution of this article is to provide an online algorithm for self-supervised learning. This method does not need to be trained on a large and complete data set, and data can be continuously added to improve its effect. In addtion, this paper also proproses a new image enhancement strategy called mult-crop. Muti-crop can intercept a small piece of the image as an enhanced samples while saving memory as much as possible." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/537d8e9095e62c775464945fed705f14/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-06T12:19:36+08:00" />
<meta property="article:modified_time" content="2022-05-06T12:19:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【研一小白论文精读】SwAV</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Unsupervised_Learning_of_Visual_Features_by_Contrasting_Cluster_Assignments_0"></a>Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</h2> 
<p>The main contribution of this article is to provide an online algorithm for self-supervised learning. This method does not need to be trained on a large and complete data set, and data can be continuously added to improve its effect. In addtion, this paper also proproses a new image enhancement strategy called mult-crop. Muti-crop can intercept a small piece of the image as an enhanced samples while saving memory as much as possible.</p> 
<h3><a id="Intuition_2"></a>Intuition</h3> 
<p>contrastive learning 肯定要对比两个图像的feature，但是这样会产生两个问题。一就是需要很多样本来做对比，也就是batchsize一定要大。随之而来的第二个问题就是计算量成指数倍增长。所以作者觉得用聚类的方法减少我们对比feature的数量。而且聚类不能是单向的，我们不但从feature投影到聚类领域里面，也要从聚类领域不同程度投影到feature，可以防止模型坍缩在聚类空间的某一点上。为了避免这个问题，作者提出了Swap，也就是交换投影方向。</p> 
<h3><a id="Online_clustering_4"></a>Online clustering</h3> 
<p><img src="https://images2.imgbox.com/0c/16/UAgQ5Ccd_o.png" alt="在这里插入图片描述"></p> 
<p>传统的contrastive learning的方法来讲呢，我们的图像进来，经过不同的图像增强策略啊，得到了不同的图像，进入同样的encdoer里面，然后得到不同的这个特征。那么对于这些不同的特征来说，我们知道哪些特征是来自于同一幅图像的，因此呢，我们需要把这些特征聚到一起，哪些特征呢？来自于不同的图像，然后呢，我们就要把这些特征远离开。把该聚的聚在一起，把该分开的分开，这样的一种情况，但是呢，这种传统的 loss又带来的问题，我们之前已经介绍过了，那么本文的作者呢，在这里引入了一个叫做Prototype这个矩阵呢，其实就是很多个聚类中心的，他们的这个集合，但是这个聚类中心的数量呢，是要小于我们原来feature的它的尺度的，那我现在把我原来的feature全部。<br> 我投到这个聚类的中心里面，然后呢，我就会有一个code，那我通过对比这个位置的code，因为它相对于飞是他的维度是比较低的，那么我就可以减少运算量，同时呢，因为我们过去所有的样本都是经过这个prototype，他的描述之后来得到这个code的.那么这个prototypes呢，你就可以理解成我们坐标系中的一个横轴纵轴一样，他就是我们定位用的坐标，而且这个坐标系呢，是对于所有的batch都通用的，也就是说我如果把图像的feature全部都用这prototypes来表示，那么其实大家就都统一在一个相同的维度下面。这个呢，就像我们地理定位里面的坐标对吧，精度纬度一样啊，你原原来的情况就是每个人家里的地址对吧，很长一串儿的地址写出来啊，你要对比两个人家里之间的地址，它不太好对比，那现在呢，你大家所有的把自己的位置，全部都改成经纬度啊，就两个数。这样来对比他们之间的距离就会变得很轻松。<br> <img src="https://images2.imgbox.com/0f/00/uNGLM23W_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/00/0e/hvai0O37_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/73/17/MBJXB5jr_o.png" alt="在这里插入图片描述"><br> 这个prototypes呢，就是我们之前说的所有的聚类中心的集合。假如呢，这里我们有K个这个prototypes的vector，那么对于我一个样本的feature，我的这个feature和每一个protests它的相似的程度，我们给他计算出来，那么如何计算两个向量的相似程度呢？就是两个向量的内积，然后你再除以两个向量的长度，你就可以得到这两个向量的夹角，他们的这个距离，那么你把这个feature的vector呢，那么你把这个feature的vector呢，和每一个Prototype都去做这么一个内积，那么每一个内积呢，就会给你一个描述，这个描述呢，就衡量你现在这个feature和这个Prototype它们之间的相似程度，那么你现在把这K的不同的相似程度换起来，作为一个新的vector，那么这个长度为K的vector，其实就可以用来描述你之前的这个feature。当然你在计算这些距离之后呢，你可以用一个soft max把它变成一个概率分布，那么这里呢，还有一个套，这个套呢，我们叫temperature，也是用来控制我们的p，p就是其中的一个distribution。那么另一个distribution在哪里呢？<br> 这里这个图我感觉他们画的有点不清晰，好像是这个乘积向量p通过Q然后得到了codes。我是看了代码才弄明白，事实上这个乘积向量是p，code的维度和p的维度是一样的，假设是B，所以B个code，经过一个特殊的处理变换成code就叫小q，B个小q得到了一个新的矩阵，这个矩阵就是大Q。也就是Q=codes<br> 那么另一个distribution这个小q是怎么产生的？这个呢，我们就要看到下面这根，下面这支儿呢，我们一要通过不同的随机的图像增强的策略得到一张新的图像，过encoder之后得到一个feature，那么这个feature呢，也是先和这个prototype相乘，乘出来呢，得到了类似于跟我们上面这帧儿一样的p，但是还没完，我们要经过特殊的处理。这个p呢，跟我们之前的p，它的尺寸大小都是一样的，唯一的区别呢，就是它经过了这样一个特殊的变化，但是尺寸没有变，变成了我们的一个code。code其实就是小q。那么这样我们对比这个target code，在对比我们上边儿的这个code，我们就形成了一个contractive loss，我希望相同图像。在这两边儿产生的这个code和这个target code，他们要尽量的接近，那么同样呢，我也可以交换这个对比，使用另一个target code，对吧，和这个projection来对比，这样就会产生一个相同的loss。那么把他们两个这个loss加起来，那就是我们最终的要训练这个loss这个。</p> 
<h4><a id="Optimal_Transportation_15"></a>Optimal Transportation</h4> 
<p>那么特殊的变化是怎么实现的呢？为了使我们的方法在线，我们只使用一批图像的特征计算codes。直观地说，由于prototype C是跨不同批次使用的，所以SwAV为原型聚集了多个实例。我们使用prototype C来计算code，这样批处理中的所有示例都被原型平等地划分。这种均分约束保证了批处理中不同图像的code是不同的，从而避免了每个图像都有相同code的平凡解。我们观察到强熵正则化(即使用高ε)通常导致一个平凡解，其中所有样本坍缩成一个唯一的表示，并全部均匀地分配给所有原型。<br> 所以关键就是Q是怎么得到的，首先先看p矩阵，也就是下面公式左边这一项后两个公式相乘，p矩阵被被定义成了一个最优运输问题。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          C 
         
        
          T 
         
        
       
         Z 
        
       
      
        C^{T}Z 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right: 0.07153em;">Z</span></span></span></span></span>就是p矩阵：<br> <img src="https://images2.imgbox.com/d9/ad/R9rubxuM_o.png" alt="在这里插入图片描述"><br> Z和每一个prototype相乘，做出一个矩阵，通过每一个feature和prototype之间的关系来描述当前的feature。ZB去哪个prototype Ck多一点，说明这个sample的represenation的相似程度和这个prototype的更大一些.如图所示，其实p就是从B个samples到K个centers的一个过渡矩阵，其实就是sample到聚类中心的一种投影。<br> <img src="https://images2.imgbox.com/7e/21/rs0KNJWv_o.png" alt="在这里插入图片描述"><br> 后面那一项是一个正则化项，就是Q的entropy，限制Q不要太激进。而Q也是这么的一个过渡矩阵，所以相乘就乘出来一个方阵，方阵的的对角线上的元素就是Q和CZ和两个矩阵每一个vector的一个相似程度，这个相似程度可以用乘起来矩阵的特征值之和来决定，也就迹。我们希望最大化这个迹其实就是希望这两个矩阵对应的vetcor尽可能的相似。Q矩阵还不能照抄CZ矩阵，Q矩阵是需要有限制条件的，Q矩阵每一行相加都是1/K，每一列相加都是1/B，这样据作者说每一个prototype可以至少被选择B/K次，也就是让每一个prototype，每一个聚类中心发挥自己的作用。</p> 
<p><img src="https://images2.imgbox.com/13/bc/q7yPv7RP_o.png" alt="在这里插入图片描述"><br> 也就是为了在这样的约束之下，优化上面那个问题，其实就是数学问题，在这上面的相关研究已经有很多了。作者选择了Sinkhorn-algorithm这个算法。<img src="https://images2.imgbox.com/5a/19/bx8Q3Xfh_o.png" alt="在这里插入图片描述"><br> 其中u和v是和是1的向量。<br> <img src="https://images2.imgbox.com/61/34/d7Q2ncz9_o.png" alt="在这里插入图片描述"><br> 这里输入一个scores，这里的scores就是CZ，得到Q矩阵，Q是K行B列，Q是prototype的数量，K是一个batch sample的数量。核心就是这个矩阵在每次循环中，Q按行求和做归一乘到原来的矩阵上，按列求和做归一乘到原来的矩阵上，最后得到这个矩阵再做归一化。</p> 
<h3><a id="Multicrop_augmentation_28"></a>Multi-crop augmentation</h3> 
<p><img src="https://images2.imgbox.com/c6/f2/XcxaMHWG_o.png" alt="在这里插入图片描述"><br> 除了用两个增强的原尺寸图片之外，还使用了V个低像素crops，这样就一共有了V+2个sanmples，但是为了计算方便，作者只在原尺寸图像上计算了q，对于低像素的图片，这里并没有计算code。</p> 
<h3><a id="Resultcinclusion_31"></a>Result&amp;cinclusion</h3> 
<p><img src="https://images2.imgbox.com/22/41/GxAiwAEK_o.png" alt="在这里插入图片描述"></p> 
<p>实验结果请大家自行查看论文，这里不多赘述，其实就是mutli-crop才是正真提点的东西，提了4个点，没有mutli-crop可能只和mocoV2差不多，75.3已经超过之前的BYOL，但是如果把mutli-crop的方法用到BYOL上可能会更强。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aabb66b6c48fd3f4c5d7e8621060eac9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">appium</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/05b3303c54fba3b4fa09ffab0f7dbfdf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android 最简单实用的打开手机通知权限设置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>