<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>resnet152训练_ResNet改进版来了！可训练网络超过3000层！相同深度精度更高 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="resnet152训练_ResNet改进版来了！可训练网络超过3000层！相同深度精度更高" />
<meta property="og:description" content="学习了~
来自阿联酋起源人工智能研究院(IIAI)的研究人员公布了一篇论文Improved Residual Networks for Image and Video Recognition，深入研究了残差网络不能更深的原因，提出了改进版的残差网络(Improved Residual Networks，iResNet)，使得训练超深网络时更容易收敛，在多个计算机视觉任务(图像分类，COCO目标检测，视频动作识别)中精度也更高。
作者成功在ImageNet数据集上训练了404层网络的模型，在CIFAR-10和CIFAR-100数据集上训练了3002层网络的模型，而原始的残差网络在达到上述层数的时候已经无法收敛。
该文作者信息：
因残差网络几乎已经成为所有深度卷积网络的标配，“涨点又不涨计算量”的iResNet的出现，或可影响深远。
算法思想
作者主要从三个方向来思考残差网络的改进：
1)促进信息在网络中的流动(Improved flow of information)
2)减少信息损失(Improved projection shortcut)
3)不增加计算量前提下增强残差模块的学习能力(Grouped building block)
1. Improved information flow through the network
作者认为原始的ResNet网络模块中的ReLU在将负信号置0时影响了信息的传播，这种情形在刚开始训练时尤其严重，提出了一种分网络阶段(stage)的三种不同残差构建模块。
以50层的残差网络为例，作者按照网络中特征的空间分辨率大小划分四个阶段(stage)，相同分辨率的残差模块被分为同一个stage，
每个stage都包含有下图中start ResBlock、Middle ResBlock、End ResBlock三种残差模块，每个stage有一个start ResBlock 、一个End ResBlock 和数个Middle ResBlock。
减少整体上ReLU对信息流通的影响。
2. Improved projection shortcut
projection shortcut 被用于残差网络特征维度改变的时候，用于将不同特征维度的特征相加之前的处理。原始的残差网络使用stride为2的1x1卷积进行通道的改变。如下图中的(a)。
作者认为1x1卷积丢弃了大量信息，提出先使用3x3 max Pooling再使用1x1卷积的方案，即实现了保留重要信息的降维。
3. Grouped building block
作者认为原始的残差网络中瓶颈模块(bottleneck block)不够好，这种上下粗中间细的结构中，前面的1x1卷积是为了降通道数进而减少计算量，后面的1x1卷积是为了特征对齐，3x3卷积部分被限制了，只有它在“认真的”学习特征模式，将其通道数减少虽然提高了计算速度，却降低了网络表达能力。(算是一种不得已而为之的设计吧)
而新的组卷积(Group conv)技术方案恰好可以解决这个问题。所以作者提出使用组卷积构建模块替换瓶颈模块。
如下图：
ResGroup在不增加计算量的前提下可更好的让3x3卷积发挥作用。
实验结果
使用上述改进方案，可以训练更深层的网络模型，而且相对原始方案，在相同深度时，iResNet的精度也更高。
下图为在ImageNet上训练50、101、152、200层网络时的结果比较：
可见原始残差网络在超过152层时精度开始下降，iResNet精度一直在上升，且比其他方案的精度更好。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/552f447afa929c7acf754efe2d70c53d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-22T00:10:40+08:00" />
<meta property="article:modified_time" content="2021-02-22T00:10:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">resnet152训练_ResNet改进版来了！可训练网络超过3000层！相同深度精度更高</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>学习了~</p> 
 <p>来自阿联酋起源人工智能研究院(IIAI)的研究人员公布了一篇论文Improved Residual Networks for Image and Video Recognition，深入研究了残差网络不能更深的原因，提出了改进版的残差网络(Improved Residual Networks，iResNet)，使得训练超深网络时更容易收敛，在多个计算机视觉任务(图像分类，COCO目标检测，视频动作识别)中精度也更高。</p> 
 <p>作者成功在ImageNet数据集上训练了404层网络的模型，在CIFAR-10和CIFAR-100数据集上训练了3002层网络的模型，而原始的残差网络在达到上述层数的时候已经无法收敛。</p> 
 <p>该文作者信息：</p> 
 <p align="center"><img src="https://images2.imgbox.com/c6/13/86y6zK9X_o.png" alt="899e4d14a930410e3c6c225ed4f49de4.png"></p> 
 <p>因残差网络几乎已经成为所有深度卷积网络的标配，“涨点又不涨计算量”的iResNet的出现，或可影响深远。</p> 
 <p>算法思想</p> 
 <p>作者主要从三个方向来思考残差网络的改进：</p> 
 <p>1)促进信息在网络中的流动(Improved flow of information)</p> 
 <p>2)减少信息损失(Improved projection shortcut)</p> 
 <p>3)不增加计算量前提下增强残差模块的学习能力(Grouped building block)</p> 
 <p>1. Improved information flow through the network</p> 
 <p>作者认为原始的ResNet网络模块中的ReLU在将负信号置0时影响了信息的传播，这种情形在刚开始训练时尤其严重，提出了一种分网络阶段(stage)的三种不同残差构建模块。</p> 
 <p>以50层的残差网络为例，作者按照网络中特征的空间分辨率大小划分四个阶段(stage)，相同分辨率的残差模块被分为同一个stage，</p> 
 <p align="center"><img src="https://images2.imgbox.com/89/1d/6cOZCAeG_o.png" alt="cb97e126bc01ed3db028f0ac762f9cde.png"></p> 
 <p>每个stage都包含有下图中start ResBlock、Middle ResBlock、End ResBlock三种残差模块，每个stage有一个start ResBlock 、一个End ResBlock 和数个Middle ResBlock。</p> 
 <p>减少整体上ReLU对信息流通的影响。</p> 
 <p align="center"><img src="https://images2.imgbox.com/ea/b0/PLlGw819_o.png" alt="2727eb5b967106fde8663bc808050399.png"></p> 
 <p>2. Improved projection shortcut</p> 
 <p>projection shortcut 被用于残差网络特征维度改变的时候，用于将不同特征维度的特征相加之前的处理。原始的残差网络使用stride为2的1x1卷积进行通道的改变。如下图中的(a)。</p> 
 <p align="center"><img src="https://images2.imgbox.com/22/fc/zy2wt5vn_o.png" alt="753d3aed16a23c7024b0d936b1dc9303.png"></p> 
 <p>作者认为1x1卷积丢弃了大量信息，提出先使用3x3 max Pooling再使用1x1卷积的方案，即实现了保留重要信息的降维。</p> 
 <p>3. Grouped building block</p> 
 <p>作者认为原始的残差网络中瓶颈模块(bottleneck block)不够好，这种上下粗中间细的结构中，前面的1x1卷积是为了降通道数进而减少计算量，后面的1x1卷积是为了特征对齐，3x3卷积部分被限制了，只有它在“认真的”学习特征模式，将其通道数减少虽然提高了计算速度，却降低了网络表达能力。(算是一种不得已而为之的设计吧)</p> 
 <p>而新的组卷积(Group conv)技术方案恰好可以解决这个问题。所以作者提出使用组卷积构建模块替换瓶颈模块。</p> 
 <p>如下图：</p> 
 <p align="center"><img src="https://images2.imgbox.com/0f/f8/R2CtQFzs_o.png" alt="1db1f8849e509dbe01c8b23730d177bf.png"></p> 
 <p>ResGroup在不增加计算量的前提下可更好的让3x3卷积发挥作用。</p> 
 <p>实验结果</p> 
 <p>使用上述改进方案，可以训练更深层的网络模型，而且相对原始方案，在相同深度时，iResNet的精度也更高。</p> 
 <p>下图为在ImageNet上训练50、101、152、200层网络时的结果比较：</p> 
 <p align="center"><img src="https://images2.imgbox.com/52/7f/X4ApY9WP_o.png" alt="0fed7ca60c2e1b837aab257093220645.png"></p> 
 <p>可见原始残差网络在超过152层时精度开始下降，iResNet精度一直在上升，且比其他方案的精度更好。</p> 
 <p>下图为训练时的验证集精度曲线，从趋势上看，iResNet具有持续精度提升的表现。</p> 
 <p align="center"><img src="https://images2.imgbox.com/de/9b/Nt5A1GTo_o.png" alt="60fe9d6914769686d8b551008f5f3e3e.png"></p> 
 <p>下图为训练404层iResNet网络和152、200层ResNet网络的比较：</p> 
 <p align="center"><img src="https://images2.imgbox.com/4c/89/pYDU9B3Z_o.png" alt="782165128327402ad565b10aab8c5478.png"></p> 
 <p>随着层数增多，iResNet网络的精度持续提高。</p> 
 <p align="center"><img src="https://images2.imgbox.com/b9/42/2rwlP6Uy_o.png" alt="60cf4fc8889a258e1574587cf93333d6.png"></p> 
 <p>在视频动作识别人中中使用iResNet也明显改进了结果：</p> 
 <p align="center"><img src="https://images2.imgbox.com/3a/b7/bFvB6wmv_o.png" alt="3dd1bb534d8b5f096bc824320401e53e.png"></p> 
 <p>在CIFAR-10和CIFAR-100数据集上，不同深度网络的表现：</p> 
 <p align="center"><img src="https://images2.imgbox.com/6c/4e/yuq5wNyA_o.png" alt="312a9bfb93e1265c66053f373ec7f61e.png"></p> 
 <p>iResNet的精度随着层数增加到2000层时精度还在提升，达到3002层时精度下降，而ResNet无法在2000层收敛。</p> 
 <p>在COCO目标检测数据集训练使用了iResNet的SSD算法，同样取得了精度提升。</p> 
 <p align="center"><img src="https://images2.imgbox.com/53/c9/UuFfHQRY_o.png" alt="fd50b9a11c975b2b41432268764612ce.png"></p> 
 <p>iResNet与其他知名图像分类算法在ImageNet数据集上的比较：</p> 
 <p align="center"><img src="https://images2.imgbox.com/dd/f0/NfWTr6Z4_o.png" alt="0c5b55eebc8efb0087ff215c5b449506.png"></p> 
 <p>iResNet 比大部分方法好，但使用了其他技巧的顶尖选手NASNet-A和SENet-154的精度更高，而 iResNet 可以用来构建这些网络。</p> 
 <p>这么深，有必要吗？</p> 
 <p>作者提出的算法的确比原始的残差网络收敛性要好，甚至训练了3002层的网络，但这么深真的有必要吗？而且我们也可以看到超深网络带来的精度增益不太明显，但计算量的增加是显然的。</p> 
 <p>作者在文末特意说明了，我们应当以“发展的眼光”看问题，超深网络在实际应用中目前是不可取的，但随着新技术的出现，这终有一天不会是问题。本文提出的方法可成为训练超深网络的工具，或可启发其他算法的出现。</p> 
 <p>iResNet 可完美替换ResNet，精度提高计算量不增加，所以在实际应用中也不失为一个好的选择。</p> 
 <p>论文地址：</p> 
 <p>https://arxiv.org/abs/2004.04989</p> 
 <p>代码地址：</p> 
 <p>https://github.com/iduta/iresnet</p> 
 <p>关注公众号~</p> 
 <p align="center"></p> 
 <p>在看，让更多人看到</p> 
 <p align="center"><img src="https://images2.imgbox.com/03/a1/r5iGacPp_o.gif" alt="71ff8905bb54b1bb7a1212a16b169219.gif"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/25470ac9a3836b8a9070668e232150c1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">qpython 教程_极简Qlearning教程（附Python源码）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/49ba10db11d16f3ae99568745baea979/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java环境教程_java环境配置的详细教程（图文）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>