<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python --selenium&#43;phantomjs爬取动态页面广告源码 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python --selenium&#43;phantomjs爬取动态页面广告源码" />
<meta property="og:description" content="背景：利用爬虫，爬取网站页面广告元素，监控爬取元素的数目，定时发送监控邮件
#!/usr/bin/env python2.7 # -*- coding: utf-8 -*- &#39;&#39;&#39; @xiayun @896365105@qq.com #爬取网站内容，利用phantomjs:IP代理&#43;修改UA&#43;动态页面执行JS &#39;&#39;&#39; from selenium import webdriver from selenium.webdriver.common.desired_capabilities import DesiredCapabilities import time import urllib,urllib2 import smtplib import re from email.mime.text import MIMEText from email.header import Header import sys def reptile(): global result, data #proxy_ip.txt为IP代理池，可以自己爬IP，也可以买，不过都不稳定， #需要在前面再加一个IP验证程序。 IPS = [i for i in open(&#34;./proxy_ip.txt&#34;, &#39;r&#39;).readline().split(&#39;\n&#39;) if i] print IPS for i in IPS: service_args = [] service_args = [&#39;--proxy-type=HTTP&#39;,] IP_str = &#39;&#39;." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/590d322977136f24f1865fb0623bae1f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-01-23T16:43:34+08:00" />
<meta property="article:modified_time" content="2017-01-23T16:43:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python --selenium&#43;phantomjs爬取动态页面广告源码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="artical-content-bak main-content editor-side-new"> 
 <div class="con editor-preview-side" id="result"> 
  <p>背景：利用爬虫，爬取网站页面广告元素，监控爬取元素的数目，定时发送监控邮件</p> 
  <pre><code class="language-python">#!/usr/bin/env python2.7
# -*- coding: utf-8 -*-

'''
@xiayun
@896365105@qq.com
#爬取网站内容，利用phantomjs:IP代理+修改UA+动态页面执行JS
'''

from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
import time
import urllib,urllib2
import smtplib
import re
from email.mime.text import MIMEText
from email.header import Header
import sys


def reptile():
    global result, data
    #proxy_ip.txt为IP代理池，可以自己爬IP，也可以买，不过都不稳定，
    #需要在前面再加一个IP验证程序。
    IPS = [i for i in open("./proxy_ip.txt", 'r').readline().split('\n') if i]
    print IPS
    for i in IPS:
        service_args = []
        service_args = ['--proxy-type=HTTP',]
        IP_str = ''.join(i)
        print IP_str
        proxy_IP = '--proxy=%s' % IP_str
        service_args.append(proxy_IP)
        dcap = dict(DesiredCapabilities.PHANTOMJS)
        #创建UA头
        dcap["phantomjs.page.settings.userAgent"] = ('Mozilla/5.0 (baomihua@iPhone; 
        CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) 
        Version/9.0 Mobile/13B143 Safari/601.1')
        #利用phantomjs仿浏览器动作，参数2是代理IP
        driver = webdriver.PhantomJS(desired_capabilities=dcap, service_args=service_args)
        #设置访问超时时间
        driver.implicitly_wait(60)
        driver.set_page_load_timeout(60)
        try:
            driver.get('网页地址')
        except:
            print "timeout"
        finally:
            data = driver.page_source
            time.sleep(20)

            req = r"广告元素"
            rule1 = re.compile(req)
            lists = re.findall(rule1, data)
            counts = len(lists)
            print counts
            # print data
            driver.quit()
            #判断广告元素是否为22
            if counts == 22:
                print "The webpage is OK!"
                result = "The webpage is OK!Find 22 广告元素!
                proxy_IP:%s " % IP_str
                break
            if counts != 22:
                #IPS.remove(i)
                print "%s is bad!" % i.strip()
                result = "The webpage maybe bad"
    print "close"
    #返回结果和网页代码
    return result, data


def send_mail(result,data):
    
    receivers = ['XXX@XX.com'] #接收人
    mail_host = 'smtp.exmail.qq.com' #代理邮箱smtp协议
    mail_user = 'xxx@xxx.com' #发送人
    mail_pass = 'xxxx'  #密码
    mail_postfix = 'xxxx'  #发件箱的后缀
    title = str(result)
    msg = MIMEText(data, 'plain', 'utf-8')  #文本格式内容
    me = title.decode('utf-8') + "&lt;" + mail_user + "&gt;"
    msg['Subject'] = Header(title, 'utf-8')
    msg['From'] = Header(me, 'utf-8')
    msg['To'] = Header(";".join(receivers), 'utf-8')
    try:
        s = smtplib.SMTP()
        s.connect(mail_host)
        s.login(mail_user, mail_pass)
        s.sendmail(me,receivers , msg.as_string())
        s.close()
        print "发送成功"
        return True
    except smtplib.SMTPException:
        print "Error: 无法发送邮件"
        return False

if __name__ == '__main__':
    while 1:
        print 'start' + ' ' + ''.join(time.ctime(time.time()))
        result, data = reptile()
        send_mail(result=result, data=data)
        print 'stop' + ' ' + ''.join(time.ctime(time.time()))
        time.sleep(600)
    sys.exit(0)</code></pre> 
  <p><br></p> 
 </div> 
</div> 
<p>转载于:https://blog.51cto.com/linuxerxy/1893893</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/96c41b22f913d294b134f1778dcaef5b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">介绍一个非常好用的跨平台C&#43;&#43;开源框架:openFrameworks</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e796fb2e200d58fd53d23047df12671b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java内存分析工具</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>