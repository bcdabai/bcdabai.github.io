<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ä½¿ç”¨EfficientNetè¿›è¡ŒCIFAR100è®­ç»ƒ - ç¼–ç¨‹å¤§ç™½çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ä½¿ç”¨EfficientNetè¿›è¡ŒCIFAR100è®­ç»ƒ" />
<meta property="og:description" content="è®ºæ–‡ä¸‹è½½åœ°å€ï¼šhttps://arxiv.org/pdf/1905.11946.pdf
å…·ä½“æ¨¡å‹ç»†èŠ‚çŸ¥è¯†ç‚¹ï¼šEfficientNetæ¨¡å‹çš„å®Œæ•´ç»†èŠ‚_å–œæ¬¢æ‰“é…±æ²¹çš„è€é¸Ÿçš„åšå®¢-CSDNåšå®¢
ä½¿ç”¨EfficientNetè¿›è¡ŒCIFAR-10æ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯å°†CIFAR-10æ•°æ®é›†çš„åˆ†è¾¨ç‡æ‰©å¤§åˆ°32X32ï¼Œå› ä¸ºç®—åŠ›ç›¸å…³çš„é—®é¢˜æ‰€ä»¥æˆ‘é€‰æ‹©äº†è¾ƒä½çš„è®­ç»ƒå›¾åƒåˆ†è¾¨ç‡ã€‚ä½†æ˜¯å‡å¦‚ä½ è‡ªå·±çš„ç®—åŠ›æ¯”è¾ƒå……è¶³çš„è¯ï¼Œæˆ‘å»ºè®®ä½¿ç”¨è®­ç»ƒçš„ä½¿ç”¨å›¾åƒçš„åˆ†è¾¨ç‡è®¾ç½®ä¸º224X224ï¼ˆè¿™ä¸ªå¯ä»¥åœ¨ä»£ç é‡Œé¢çš„transforms.RandomResizedCrop(32)å’Œtransforms.Resize((32, 32)),è¿›è¡Œä¿®æ”¹ï¼Œå¾ˆç®€å•ï¼‰ï¼Œå› ä¸ºåœ¨æµ‹è¯•è®­ç»ƒçš„æ—¶å€™ï¼Œå‘ç°å°†CIFAR10æ•°æ®é›†çš„åˆ†è¾¨ç‡æ‹‰å¤§å¯ä»¥è®©æ¨¡å‹æ›´å¿«åœ°è¿›è¡Œæ”¶æ•›ï¼Œå¹¶ä¸”è¯†åˆ«çš„æ•ˆæœä¹Ÿæ˜¯æ¯”ä½åˆ†è¾¨ç‡çš„æ›´åŠ å¥½ã€‚
å¦‚æœå¯¹ä½ æœ‰ç”¨çš„è¯ï¼Œå¸Œæœ›èƒ½å¤Ÿç‚¹èµæ”¯æŒä¸€ä¸‹ï¼Œè¿™æ ·æˆ‘å°±èƒ½æœ‰æ›´å¤šçš„åŠ¨åŠ›æ›´æ–°æ›´å¤šçš„å­¦ä¹ ç¬”è®°äº†ã€‚ğŸ˜„ğŸ˜„Â ä»£ç ç»“æ„çš„ç›®å½•ï¼š
ä»£ç å®ç°å¦‚ä¸‹ï¼š
train.py
# -*- coding:utf-8 -*- # @Time : 2023-01-16 15:39 # @Author : DaFuChen # @File : CSDNå†™ä½œä»£ç ç¬”è®° # @software: PyCharm import torchvision import os import function import torch import torch.nn as nn import torch.optim as optim from torchvision import transforms from tqdm import tqdm import parameters from model import efficientnet_b0 def main(): device = torch.device(&#34;cuda:0&#34; if torch.cuda.is_available() else &#34;cpu&#34;) print(&#34;using {} device." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/8986dd0b9da5e3b1aea923fa70719323/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-16T16:40:26+08:00" />
<meta property="article:modified_time" content="2023-01-16T16:40:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§ç™½çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§ç™½çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ä½¿ç”¨EfficientNetè¿›è¡ŒCIFAR100è®­ç»ƒ</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>è®ºæ–‡ä¸‹è½½åœ°å€ï¼š<strong><a href="https://arxiv.org/pdf/1905.11946.pdf" rel="nofollow" title="https://arxiv.org/pdf/1905.11946.pdf">https://arxiv.org/pdf/1905.11946.pdf</a></strong></strong></p> 
<p><strong>å…·ä½“æ¨¡å‹ç»†èŠ‚çŸ¥è¯†ç‚¹ï¼š<strong><a href="https://blog.csdn.net/weixin_42137700/article/details/108735114" title="EfficientNetæ¨¡å‹çš„å®Œæ•´ç»†èŠ‚_å–œæ¬¢æ‰“é…±æ²¹çš„è€é¸Ÿçš„åšå®¢-CSDNåšå®¢">EfficientNetæ¨¡å‹çš„å®Œæ•´ç»†èŠ‚_å–œæ¬¢æ‰“é…±æ²¹çš„è€é¸Ÿçš„åšå®¢-CSDNåšå®¢</a></strong></strong></p> 
<p><strong>Â  ä½¿ç”¨EfficientNetè¿›è¡ŒCIFAR-10æ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯å°†CIFAR-10æ•°æ®é›†çš„åˆ†è¾¨ç‡æ‰©å¤§åˆ°32X32ï¼Œå› ä¸ºç®—åŠ›ç›¸å…³çš„é—®é¢˜æ‰€ä»¥æˆ‘é€‰æ‹©äº†è¾ƒä½çš„è®­ç»ƒå›¾åƒåˆ†è¾¨ç‡ã€‚ä½†æ˜¯å‡å¦‚ä½ è‡ªå·±çš„ç®—åŠ›æ¯”è¾ƒå……è¶³çš„è¯ï¼Œæˆ‘å»ºè®®ä½¿ç”¨è®­ç»ƒçš„ä½¿ç”¨å›¾åƒçš„åˆ†è¾¨ç‡è®¾ç½®ä¸º224X224ï¼ˆè¿™ä¸ªå¯ä»¥åœ¨ä»£ç é‡Œé¢çš„transforms.RandomResizedCrop(32)å’Œtransforms.Resize((32, 32)),è¿›è¡Œä¿®æ”¹ï¼Œå¾ˆç®€å•ï¼‰ï¼Œå› ä¸ºåœ¨æµ‹è¯•è®­ç»ƒçš„æ—¶å€™ï¼Œå‘ç°å°†CIFAR10æ•°æ®é›†çš„åˆ†è¾¨ç‡æ‹‰å¤§å¯ä»¥è®©æ¨¡å‹æ›´å¿«åœ°è¿›è¡Œæ”¶æ•›ï¼Œå¹¶ä¸”è¯†åˆ«çš„æ•ˆæœä¹Ÿæ˜¯æ¯”ä½åˆ†è¾¨ç‡çš„æ›´åŠ å¥½ã€‚</strong><br> Â </p> 
<p><strong>Â Â Â Â Â Â Â Â å¦‚æœå¯¹ä½ æœ‰ç”¨çš„è¯ï¼Œå¸Œæœ›èƒ½å¤Ÿç‚¹èµæ”¯æŒä¸€ä¸‹ï¼Œè¿™æ ·æˆ‘å°±èƒ½æœ‰æ›´å¤šçš„åŠ¨åŠ›æ›´æ–°æ›´å¤šçš„å­¦ä¹ ç¬”è®°äº†ã€‚ğŸ˜„ğŸ˜„Â Â Â </strong></p> 
<p><strong>ä»£ç ç»“æ„çš„ç›®å½•ï¼š</strong></p> 
<p><img alt="" height="177" src="https://images2.imgbox.com/1f/2b/bLZ3288g_o.png" width="437"></p> 
<p></p> 
<p><strong>ä»£ç å®ç°å¦‚ä¸‹ï¼š</strong></p> 
<p><strong>train.py</strong></p> 
<pre><code class="language-python"># -*- coding:utf-8 -*-
# @Time : 2023-01-16 15:39
# @Author : DaFuChen
# @File : CSDNå†™ä½œä»£ç ç¬”è®°
# @software: PyCharm


import torchvision
import os
import function
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from tqdm import tqdm
import parameters
from model import efficientnet_b0

def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))
    epochs = parameters.epoch
    save_model = parameters.save_model
    save_path = parameters.save_path

    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(32),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),

        "val": transforms.Compose([transforms.Resize((32, 32)),  # cannot 224, must (224, 224)
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
    }

    train_dataset = torchvision.datasets.CIFAR100(root='./data/CIFAR100', train=True,
                                                 download=True, transform=data_transform["train"])

    val_dataset = torchvision.datasets.CIFAR100(root='./data/CIFAR100', train=False,
                                               download=False, transform=data_transform["val"])
    train_num = len(train_dataset)
    val_num = len(val_dataset)
    print("using {} images for training, {} images for validation.".format(train_num, val_num))
    batch_size = parameters.batch_size

    nw = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size,
                                               shuffle=True,
                                               pin_memory=True,
                                               num_workers=nw,
                                               )

    val_loader = torch.utils.data.DataLoader(val_dataset,
                                             batch_size=batch_size,
                                             shuffle=False,
                                             pin_memory=True,
                                             num_workers=nw,
                                             )

    model = efficientnet_b0(num_classes=parameters.num_class)
    model.to(device)
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=parameters.lr)
    best_acc = 0.0

    train_acc_list = []
    train_loss_list = []
    val_acc_list = []

    for epoch in range(epochs):
        # train
        model.train()
        running_loss_train = 0.0
        train_accurate = 0.0
        train_bar = tqdm(train_loader)
        for images, labels in train_bar:
            optimizer.zero_grad()

            outputs = model(images.to(device))
            loss = loss_function(outputs, labels.to(device))
            loss.backward()
            optimizer.step()

            predict = torch.max(outputs, dim=1)[1]
            train_accurate += torch.eq(predict, labels.to(device)).sum().item()
            running_loss_train += loss.item()

        train_accurate = train_accurate / train_num
        running_loss_train = running_loss_train / train_num
        train_acc_list.append(train_accurate)
        train_loss_list.append(running_loss_train)

        print('[epoch %d] train_loss: %.7f  train_accuracy: %.3f' %
              (epoch + 1, running_loss_train, train_accurate))

        # validate
        model.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_loader = tqdm(val_loader)
            for val_data in val_loader:
                val_images, val_labels = val_data
                outputs = model(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        val_acc_list.append(val_accurate)
        print('[epoch %d] val_accuracy: %.3f' %
              (epoch + 1, val_accurate))

        function.writer_into_excel_onlyval(save_path, train_loss_list, train_acc_list, val_acc_list, "CIFAR10")

        # é€‰æ‹©æœ€bestçš„æ¨¡å‹è¿›è¡Œä¿å­˜ è¯„ä»·æŒ‡æ ‡æ­¤å¤„æ˜¯acc
        if val_accurate &gt; best_acc:
            best_acc = val_accurate
            torch.save(model.state_dict(), save_model)


if __name__ == '__main__':
    main()</code></pre> 
<p></p> 
<p><strong>parameters.py</strong></p> 
<pre><code class="language-python"># -*- coding:utf-8 -*-
# @Time : 2023-01-16 15:39
# @Author : DaFuChen
# @File : CSDNå†™ä½œä»£ç ç¬”è®°
# @software: PyCharm


import math
import copy
from functools import partial
from collections import OrderedDict
from typing import Optional, Callable
import parameters
import torch
import torch.nn as nn
from torch import Tensor
from torch.nn import functional as F


def _make_divisible(ch, divisor=8, min_ch=None):
    """
    This function is taken from the original tf repo.
    It ensures that all layers have a channel number that is divisible by 8
    It can be seen here:
    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py
    """
    if min_ch is None:
        min_ch = divisor
    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)
    # Make sure that round down does not go down by more than 10%.
    if new_ch &lt; 0.9 * ch:
        new_ch += divisor
    return new_ch


def drop_path(x, drop_prob: float = 0., training: bool = False):
    """
    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
    "Deep Networks with Stochastic Depth", https://arxiv.org/pdf/1603.09382.pdf

    This function is taken from the rwightman.
    It can be seen here:
    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/drop.py#L140
    """
    if drop_prob == 0. or not training:
        return x
    keep_prob = 1 - drop_prob
    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
    random_tensor.floor_()  # binarize
    output = x.div(keep_prob) * random_tensor
    return output


class DropPath(nn.Module):
    """
    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    "Deep Networks with Stochastic Depth", https://arxiv.org/pdf/1603.09382.pdf
    """
    def __init__(self, drop_prob=None):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob

    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training)


class ConvBNActivation(nn.Sequential):
    def __init__(self,
                 in_planes: int,
                 out_planes: int,
                 kernel_size: int = 3,
                 stride: int = 1,
                 groups: int = 1,
                 norm_layer: Optional[Callable[..., nn.Module]] = None,
                 activation_layer: Optional[Callable[..., nn.Module]] = None):
        padding = (kernel_size - 1) // 2
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if activation_layer is None:
            activation_layer = nn.SiLU  # alias Swish  (torch&gt;=1.7)

        super(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,
                                                         out_channels=out_planes,
                                                         kernel_size=kernel_size,
                                                         stride=stride,
                                                         padding=padding,
                                                         groups=groups,
                                                         bias=False),
                                               norm_layer(out_planes),
                                               activation_layer())


class SqueezeExcitation(nn.Module):
    def __init__(self,
                 input_c: int,   # block input channel
                 expand_c: int,  # block expand channel
                 squeeze_factor: int = 4):
        super(SqueezeExcitation, self).__init__()
        squeeze_c = input_c // squeeze_factor
        self.fc1 = nn.Conv2d(expand_c, squeeze_c, 1)
        self.ac1 = nn.SiLU()  # alias Swish
        self.fc2 = nn.Conv2d(squeeze_c, expand_c, 1)
        self.ac2 = nn.Sigmoid()

    def forward(self, x: Tensor) -&gt; Tensor:
        scale = F.adaptive_avg_pool2d(x, output_size=(1, 1))
        scale = self.fc1(scale)
        scale = self.ac1(scale)
        scale = self.fc2(scale)
        scale = self.ac2(scale)
        return scale * x


class InvertedResidualConfig:
    # kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate
    def __init__(self,
                 kernel: int,          # 3 or 5
                 input_c: int,
                 out_c: int,
                 expanded_ratio: int,  # 1 or 6
                 stride: int,          # 1 or 2
                 use_se: bool,         # True
                 drop_rate: float,
                 index: str,           # 1a, 2a, 2b, ...
                 width_coefficient: float):
        self.input_c = self.adjust_channels(input_c, width_coefficient)
        self.kernel = kernel
        self.expanded_c = self.input_c * expanded_ratio
        self.out_c = self.adjust_channels(out_c, width_coefficient)
        self.use_se = use_se
        self.stride = stride
        self.drop_rate = drop_rate
        self.index = index

    @staticmethod
    def adjust_channels(channels: int, width_coefficient: float):
        return _make_divisible(channels * width_coefficient, 8)


class InvertedResidual(nn.Module):
    def __init__(self,
                 cnf: InvertedResidualConfig,
                 norm_layer: Callable[..., nn.Module]):
        super(InvertedResidual, self).__init__()

        if cnf.stride not in [1, 2]:
            raise ValueError("illegal stride value.")

        self.use_res_connect = (cnf.stride == 1 and cnf.input_c == cnf.out_c)

        layers = OrderedDict()
        activation_layer = nn.SiLU  # alias Swish

        # expand
        if cnf.expanded_c != cnf.input_c:
            layers.update({"expand_conv": ConvBNActivation(cnf.input_c,
                                                           cnf.expanded_c,
                                                           kernel_size=1,
                                                           norm_layer=norm_layer,
                                                           activation_layer=activation_layer)})

        # depthwise
        layers.update({"dwconv": ConvBNActivation(cnf.expanded_c,
                                                  cnf.expanded_c,
                                                  kernel_size=cnf.kernel,
                                                  stride=cnf.stride,
                                                  groups=cnf.expanded_c,
                                                  norm_layer=norm_layer,
                                                  activation_layer=activation_layer)})

        if cnf.use_se:
            layers.update({"se": SqueezeExcitation(cnf.input_c,
                                                   cnf.expanded_c)})

        # project
        layers.update({"project_conv": ConvBNActivation(cnf.expanded_c,
                                                        cnf.out_c,
                                                        kernel_size=1,
                                                        norm_layer=norm_layer,
                                                        activation_layer=nn.Identity)})

        self.block = nn.Sequential(layers)
        self.out_channels = cnf.out_c
        self.is_strided = cnf.stride &gt; 1

        # åªæœ‰åœ¨ä½¿ç”¨shortcutè¿æ¥æ—¶æ‰ä½¿ç”¨dropoutå±‚
        if self.use_res_connect and cnf.drop_rate &gt; 0:
            self.dropout = DropPath(cnf.drop_rate)
        else:
            self.dropout = nn.Identity()

    def forward(self, x: Tensor) -&gt; Tensor:
        result = self.block(x)
        result = self.dropout(result)
        if self.use_res_connect:
            result += x

        return result


class EfficientNet(nn.Module):
    def __init__(self,
                 width_coefficient: float,
                 depth_coefficient: float,
                 num_classes: int = 1000,
                 dropout_rate: float = 0.2,
                 drop_connect_rate: float = 0.2,
                 block: Optional[Callable[..., nn.Module]] = None,
                 norm_layer: Optional[Callable[..., nn.Module]] = None
                 ):
        super(EfficientNet, self).__init__()

        # kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate, repeats
        default_cnf = [[3, 32, 16, 1, 1, True, drop_connect_rate, 1],
                       [3, 16, 24, 6, 2, True, drop_connect_rate, 2],
                       [5, 24, 40, 6, 2, True, drop_connect_rate, 2],
                       [3, 40, 80, 6, 2, True, drop_connect_rate, 3],
                       [5, 80, 112, 6, 1, True, drop_connect_rate, 3],
                       [5, 112, 192, 6, 2, True, drop_connect_rate, 4],
                       [3, 192, 320, 6, 1, True, drop_connect_rate, 1]]

        def round_repeats(repeats):
            """Round number of repeats based on depth multiplier."""
            return int(math.ceil(depth_coefficient * repeats))

        if block is None:
            block = InvertedResidual

        if norm_layer is None:
            norm_layer = partial(nn.BatchNorm2d, eps=1e-3, momentum=0.1)

        adjust_channels = partial(InvertedResidualConfig.adjust_channels,
                                  width_coefficient=width_coefficient)

        # build inverted_residual_setting
        bneck_conf = partial(InvertedResidualConfig,
                             width_coefficient=width_coefficient)

        b = 0
        num_blocks = float(sum(round_repeats(i[-1]) for i in default_cnf))
        inverted_residual_setting = []
        for stage, args in enumerate(default_cnf):
            cnf = copy.copy(args)
            for i in range(round_repeats(cnf.pop(-1))):
                if i &gt; 0:
                    # strides equal 1 except first cnf
                    cnf[-3] = 1  # strides
                    cnf[1] = cnf[2]  # input_channel equal output_channel

                cnf[-1] = args[-2] * b / num_blocks  # update dropout ratio
                index = str(stage + 1) + chr(i + 97)  # 1a, 2a, 2b, ...
                inverted_residual_setting.append(bneck_conf(*cnf, index))
                b += 1

        # create layers
        layers = OrderedDict()

        # first conv
        layers.update({"stem_conv": ConvBNActivation(in_planes=3,
                                                     out_planes=adjust_channels(32),
                                                     kernel_size=3,
                                                     stride=2,
                                                     norm_layer=norm_layer)})

        # building inverted residual blocks
        for cnf in inverted_residual_setting:
            layers.update({cnf.index: block(cnf, norm_layer)})

        # build top
        last_conv_input_c = inverted_residual_setting[-1].out_c
        last_conv_output_c = adjust_channels(1280)
        layers.update({"top": ConvBNActivation(in_planes=last_conv_input_c,
                                               out_planes=last_conv_output_c,
                                               kernel_size=1,
                                               norm_layer=norm_layer)})

        self.features = nn.Sequential(layers)
        self.avgpool = nn.AdaptiveAvgPool2d(1)

        classifier = []
        if dropout_rate &gt; 0:
            classifier.append(nn.Dropout(p=dropout_rate, inplace=True))
        classifier.append(nn.Linear(last_conv_output_c, num_classes))

        # æ›´æ–°åˆ é™¤çš„ä¸€ä¸ªåˆ†ç±»å™¨ è¾“å‡ºä¿®æ”¹æˆ 512X1X1ç»´åº¦çš„ç‰¹å¾çŸ©é˜µ
        self.classifier = nn.Sequential(*classifier)

        # initial weights
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out")
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.zeros_(m.bias)


    def _forward_impl(self, x: Tensor) -&gt; Tensor:
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

    def forward(self, x: Tensor) -&gt; Tensor:
        return self._forward_impl(x)


def efficientnet_b0(num_classes=1000):
    # input image size 224x224
    return EfficientNet(width_coefficient=1.0,
                        depth_coefficient=1.0,
                        dropout_rate=0.2,
                        num_classes=num_classes)


</code></pre> 
<p></p> 
<p><strong>function.py</strong></p> 
<pre><code class="language-python"># -*- coding:utf-8 -*-
# @Time : 2023-01-11 20:25
# @Author : DaFuChen
# @File : CSDNå†™ä½œä»£ç ç¬”è®°
# @software: PyCharm


import xlwt



def writer_into_excel_onlyval(excel_path,loss_train_list, acc_train_list, val_acc_list,dataset_name:str=""):
    workbook = xlwt.Workbook(encoding='utf-8')  # è®¾ç½®ä¸€ä¸ªworkbookï¼Œå…¶ç¼–ç æ˜¯utf-8
    worksheet = workbook.add_sheet("sheet1", cell_overwrite_ok=True)  # æ–°å¢ä¸€ä¸ªsheet
    worksheet.write(0, 0, label='Train_loss')
    worksheet.write(0, 1, label='Train_acc')
    worksheet.write(0, 2, label='Val_acc')


    for i in range(len(loss_train_list)):  # å¾ªç¯å°†aå’Œbåˆ—è¡¨çš„æ•°æ®æ’å…¥è‡³excel
        worksheet.write(i + 1, 0, label=loss_train_list[i])  # åˆ‡ç‰‡çš„åŸæ¥æ˜¯ä¼ è¿›æ¥çš„Imgsæ˜¯ä¸€ä¸ªè·¯å¾„çš„ä¿¡æ¯
        worksheet.write(i + 1, 1, label=acc_train_list[i])
        worksheet.write(i + 1, 2, label=val_acc_list[i])


    workbook.save(excel_path + str(dataset_name) +".xls")  # è¿™é‡Œsaveéœ€è¦ç‰¹åˆ«æ³¨æ„ï¼Œæ–‡ä»¶æ ¼å¼åªèƒ½æ˜¯xlsï¼Œä¸èƒ½æ˜¯xlsxï¼Œä¸ç„¶ä¼šæŠ¥é”™
    print('save success!   .')



</code></pre> 
<p></p> 
<p><strong>model.py</strong></p> 
<pre><code class="language-python"># -*- coding:utf-8 -*-
# @Time : 2023-01-16 15:39
# @Author : DaFuChen
# @File : CSDNå†™ä½œä»£ç ç¬”è®°
# @software: PyCharm


import math
import copy
from functools import partial
from collections import OrderedDict
from typing import Optional, Callable
import parameters
import torch
import torch.nn as nn
from torch import Tensor
from torch.nn import functional as F


def _make_divisible(ch, divisor=8, min_ch=None):
    """
    This function is taken from the original tf repo.
    It ensures that all layers have a channel number that is divisible by 8
    It can be seen here:
    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py
    """
    if min_ch is None:
        min_ch = divisor
    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)
    # Make sure that round down does not go down by more than 10%.
    if new_ch &lt; 0.9 * ch:
        new_ch += divisor
    return new_ch


def drop_path(x, drop_prob: float = 0., training: bool = False):
    """
    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
    "Deep Networks with Stochastic Depth", https://arxiv.org/pdf/1603.09382.pdf

    This function is taken from the rwightman.
    It can be seen here:
    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/drop.py#L140
    """
    if drop_prob == 0. or not training:
        return x
    keep_prob = 1 - drop_prob
    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
    random_tensor.floor_()  # binarize
    output = x.div(keep_prob) * random_tensor
    return output


class DropPath(nn.Module):
    """
    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    "Deep Networks with Stochastic Depth", https://arxiv.org/pdf/1603.09382.pdf
    """
    def __init__(self, drop_prob=None):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob

    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training)


class ConvBNActivation(nn.Sequential):
    def __init__(self,
                 in_planes: int,
                 out_planes: int,
                 kernel_size: int = 3,
                 stride: int = 1,
                 groups: int = 1,
                 norm_layer: Optional[Callable[..., nn.Module]] = None,
                 activation_layer: Optional[Callable[..., nn.Module]] = None):
        padding = (kernel_size - 1) // 2
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if activation_layer is None:
            activation_layer = nn.SiLU  # alias Swish  (torch&gt;=1.7)

        super(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,
                                                         out_channels=out_planes,
                                                         kernel_size=kernel_size,
                                                         stride=stride,
                                                         padding=padding,
                                                         groups=groups,
                                                         bias=False),
                                               norm_layer(out_planes),
                                               activation_layer())


class SqueezeExcitation(nn.Module):
    def __init__(self,
                 input_c: int,   # block input channel
                 expand_c: int,  # block expand channel
                 squeeze_factor: int = 4):
        super(SqueezeExcitation, self).__init__()
        squeeze_c = input_c // squeeze_factor
        self.fc1 = nn.Conv2d(expand_c, squeeze_c, 1)
        self.ac1 = nn.SiLU()  # alias Swish
        self.fc2 = nn.Conv2d(squeeze_c, expand_c, 1)
        self.ac2 = nn.Sigmoid()

    def forward(self, x: Tensor) -&gt; Tensor:
        scale = F.adaptive_avg_pool2d(x, output_size=(1, 1))
        scale = self.fc1(scale)
        scale = self.ac1(scale)
        scale = self.fc2(scale)
        scale = self.ac2(scale)
        return scale * x


class InvertedResidualConfig:
    # kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate
    def __init__(self,
                 kernel: int,          # 3 or 5
                 input_c: int,
                 out_c: int,
                 expanded_ratio: int,  # 1 or 6
                 stride: int,          # 1 or 2
                 use_se: bool,         # True
                 drop_rate: float,
                 index: str,           # 1a, 2a, 2b, ...
                 width_coefficient: float):
        self.input_c = self.adjust_channels(input_c, width_coefficient)
        self.kernel = kernel
        self.expanded_c = self.input_c * expanded_ratio
        self.out_c = self.adjust_channels(out_c, width_coefficient)
        self.use_se = use_se
        self.stride = stride
        self.drop_rate = drop_rate
        self.index = index

    @staticmethod
    def adjust_channels(channels: int, width_coefficient: float):
        return _make_divisible(channels * width_coefficient, 8)


class InvertedResidual(nn.Module):
    def __init__(self,
                 cnf: InvertedResidualConfig,
                 norm_layer: Callable[..., nn.Module]):
        super(InvertedResidual, self).__init__()

        if cnf.stride not in [1, 2]:
            raise ValueError("illegal stride value.")

        self.use_res_connect = (cnf.stride == 1 and cnf.input_c == cnf.out_c)

        layers = OrderedDict()
        activation_layer = nn.SiLU  # alias Swish

        # expand
        if cnf.expanded_c != cnf.input_c:
            layers.update({"expand_conv": ConvBNActivation(cnf.input_c,
                                                           cnf.expanded_c,
                                                           kernel_size=1,
                                                           norm_layer=norm_layer,
                                                           activation_layer=activation_layer)})

        # depthwise
        layers.update({"dwconv": ConvBNActivation(cnf.expanded_c,
                                                  cnf.expanded_c,
                                                  kernel_size=cnf.kernel,
                                                  stride=cnf.stride,
                                                  groups=cnf.expanded_c,
                                                  norm_layer=norm_layer,
                                                  activation_layer=activation_layer)})

        if cnf.use_se:
            layers.update({"se": SqueezeExcitation(cnf.input_c,
                                                   cnf.expanded_c)})

        # project
        layers.update({"project_conv": ConvBNActivation(cnf.expanded_c,
                                                        cnf.out_c,
                                                        kernel_size=1,
                                                        norm_layer=norm_layer,
                                                        activation_layer=nn.Identity)})

        self.block = nn.Sequential(layers)
        self.out_channels = cnf.out_c
        self.is_strided = cnf.stride &gt; 1

        # åªæœ‰åœ¨ä½¿ç”¨shortcutè¿æ¥æ—¶æ‰ä½¿ç”¨dropoutå±‚
        if self.use_res_connect and cnf.drop_rate &gt; 0:
            self.dropout = DropPath(cnf.drop_rate)
        else:
            self.dropout = nn.Identity()

    def forward(self, x: Tensor) -&gt; Tensor:
        result = self.block(x)
        result = self.dropout(result)
        if self.use_res_connect:
            result += x

        return result


class EfficientNet(nn.Module):
    def __init__(self,
                 width_coefficient: float,
                 depth_coefficient: float,
                 num_classes: int = 1000,
                 dropout_rate: float = 0.2,
                 drop_connect_rate: float = 0.2,
                 block: Optional[Callable[..., nn.Module]] = None,
                 norm_layer: Optional[Callable[..., nn.Module]] = None
                 ):
        super(EfficientNet, self).__init__()

        # kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate, repeats
        default_cnf = [[3, 32, 16, 1, 1, True, drop_connect_rate, 1],
                       [3, 16, 24, 6, 2, True, drop_connect_rate, 2],
                       [5, 24, 40, 6, 2, True, drop_connect_rate, 2],
                       [3, 40, 80, 6, 2, True, drop_connect_rate, 3],
                       [5, 80, 112, 6, 1, True, drop_connect_rate, 3],
                       [5, 112, 192, 6, 2, True, drop_connect_rate, 4],
                       [3, 192, 320, 6, 1, True, drop_connect_rate, 1]]

        def round_repeats(repeats):
            """Round number of repeats based on depth multiplier."""
            return int(math.ceil(depth_coefficient * repeats))

        if block is None:
            block = InvertedResidual

        if norm_layer is None:
            norm_layer = partial(nn.BatchNorm2d, eps=1e-3, momentum=0.1)

        adjust_channels = partial(InvertedResidualConfig.adjust_channels,
                                  width_coefficient=width_coefficient)

        # build inverted_residual_setting
        bneck_conf = partial(InvertedResidualConfig,
                             width_coefficient=width_coefficient)

        b = 0
        num_blocks = float(sum(round_repeats(i[-1]) for i in default_cnf))
        inverted_residual_setting = []
        for stage, args in enumerate(default_cnf):
            cnf = copy.copy(args)
            for i in range(round_repeats(cnf.pop(-1))):
                if i &gt; 0:
                    # strides equal 1 except first cnf
                    cnf[-3] = 1  # strides
                    cnf[1] = cnf[2]  # input_channel equal output_channel

                cnf[-1] = args[-2] * b / num_blocks  # update dropout ratio
                index = str(stage + 1) + chr(i + 97)  # 1a, 2a, 2b, ...
                inverted_residual_setting.append(bneck_conf(*cnf, index))
                b += 1

        # create layers
        layers = OrderedDict()

        # first conv
        layers.update({"stem_conv": ConvBNActivation(in_planes=3,
                                                     out_planes=adjust_channels(32),
                                                     kernel_size=3,
                                                     stride=2,
                                                     norm_layer=norm_layer)})

        # building inverted residual blocks
        for cnf in inverted_residual_setting:
            layers.update({cnf.index: block(cnf, norm_layer)})

        # build top
        last_conv_input_c = inverted_residual_setting[-1].out_c
        last_conv_output_c = adjust_channels(1280)
        layers.update({"top": ConvBNActivation(in_planes=last_conv_input_c,
                                               out_planes=last_conv_output_c,
                                               kernel_size=1,
                                               norm_layer=norm_layer)})

        self.features = nn.Sequential(layers)
        self.avgpool = nn.AdaptiveAvgPool2d(1)

        classifier = []
        if dropout_rate &gt; 0:
            classifier.append(nn.Dropout(p=dropout_rate, inplace=True))
        classifier.append(nn.Linear(last_conv_output_c, num_classes))

        # æ›´æ–°åˆ é™¤çš„ä¸€ä¸ªåˆ†ç±»å™¨ è¾“å‡ºä¿®æ”¹æˆ 512X1X1ç»´åº¦çš„ç‰¹å¾çŸ©é˜µ
        self.classifier = nn.Sequential(*classifier)

        # initial weights
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out")
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.zeros_(m.bias)


    def _forward_impl(self, x: Tensor) -&gt; Tensor:
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

    def forward(self, x: Tensor) -&gt; Tensor:
        return self._forward_impl(x)


def efficientnet_b0(num_classes=1000):
    # input image size 224x224
    return EfficientNet(width_coefficient=1.0,
                        depth_coefficient=1.0,
                        dropout_rate=0.2,
                        num_classes=num_classes)


</code></pre> 
<p></p> 
<p><strong>Â Â Â Â Â Â Â Â å¦‚æœå¯¹ä½ æœ‰ç”¨çš„è¯ï¼Œå¸Œæœ›èƒ½å¤Ÿç‚¹èµæ”¯æŒä¸€ä¸‹ï¼Œè¿™æ ·æˆ‘å°±èƒ½æœ‰æ›´å¤šçš„åŠ¨åŠ›æ›´æ–°æ›´å¤šçš„å­¦ä¹ ç¬”è®°äº†ã€‚ğŸ˜„ğŸ˜„Â Â Â </strong></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d84c61e9f6b14ea6c1318198425fc283/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">c&#43;&#43; ç±»çš„æˆå‘˜å‡½æ•°ç”¨å›è°ƒå‡½æ•°è¾“å…¥</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/59437e22d8a73667fafded1e9965ae8b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">Javaåˆ·ç®—æ³•ä¹‹èƒŒåŒ…é—®é¢˜</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§ç™½çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>