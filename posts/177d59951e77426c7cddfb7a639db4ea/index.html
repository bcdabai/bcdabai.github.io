<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>swin transformer解读 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="swin transformer解读" />
<meta property="og:description" content="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows --论文解读 论文信息、概要 Swin transformer是微软今年三月25日公布的一篇利用transformer架构处理计算机视觉任务的论文。源码仅仅公布两天就在github上收获了2.2k个stars。它是我个人认为迄今为止用tranformer架构处理计算机视觉任务最有实用价值的一篇文章，在图像分割，目标检测各个领域已经霸榜，让很多人看到了transformer完全替代卷积的可能。而且它的设计思想吸取了resnet的精华，从局部到全局，将transformer设计成逐步扩大感受野的工具，它的成功背后绝不是偶然，而是厚厚的积累与沉淀。
论文链接https://arxiv.org/abs/2103.14030
总体结构 输入的图像先经过一层卷积进行patch映射，我有看过源代码，具体是将图像先分割成 4 × 4 4\times4 4×4的小块，然后将每一个小块通过映射成一个像素点，进行了通道上的扩充。以swin-s为例，输入的 224 × 224 224\times224 224×224图像经过这一步操作就变成了 56 × 56 56\times56 56×56的特征图。特征图一开始开始输入到stage1，stage1由两层transformer组成，这两层transformer的核心一个是普通的window attention, 另一个是shift window attention。可以将window attention 和shift window attention视为两个模块，在每一个stage内部就是直接堆积这两个模块。然后在stage与stage之间要有一个pooling操作来降低要处理的数据的尺寸，也就是为了从一开始的局部信息搜索到全局信息的提取。当然这个pooling操作与传统卷积里面的pooling也不太一样，它是将特征图先经过一个space to depth变为 1 4 \frac{1}{4} 41​，通道数变为原来的4倍，再又一个MLP缩减一半。也就是说没经过一个stage，总的数据量变为原来的 1 2 \frac{1}{2} 21​。
此时可以很容易的看出，swin transformer和resnet一样设计的是一个层次结果很明显的网络，底部的结构处理的数据更多也更局部，顶部的网络处理的数据更少但是语义信息是更加丰富的。不同的是swin主要提取信息的方式是采用transformer，而resnet是卷积核。
window attention 和 shift window attention 如图，window attention就是按照一定的尺寸将图像划分为不同的window，每次transformer的attention只在window内部进行计算。那么如果只有window attention就会带来每一个像素点的感受野得不到提升的问题，所以它又设计了一个shift window attention的方法，就是换一下window划分的方式，让每一个像素点做attention计算的window块处于变化之中。那么就起到了提升感受野的作用。
存在的问题 在同尺寸通计算量的前提下，swin确实效果远好于resnet。但是有几个问题：
1. 受缚于shift操作，对不同尺寸的输入要设计不同的网络，而且也要重新开始训练，这是很难接受的。
2. 和Detr一样训练的时候收敛的太慢。我自己有训练了一下最小的swin-tiny版本，大概训练了一百多轮的时候也才到72～73左右。有这方面改进的想法的朋友可以和我交流，整一篇B类应该没问题。
3. shift操作其实主要是为了提升感受野，可以换一种更好的方式。在这个方面我也有一点思路，可以交流。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/177d59951e77426c7cddfb7a639db4ea/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-02T14:41:36+08:00" />
<meta property="article:modified_time" content="2021-05-02T14:41:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">swin transformer解读</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Swin_Transformer_Hierarchical_Vision_Transformer_using_Shifted_Windows__0"></a>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows --论文解读</h2> 
<h3><a id="_1"></a>论文信息、概要</h3> 
<p>Swin transformer是微软今年三月25日公布的一篇利用transformer架构处理计算机视觉任务的论文。源码仅仅公布两天就在github上收获了2.2k个stars。它是我个人认为迄今为止用tranformer架构处理计算机视觉任务最有实用价值的一篇文章，在图像分割，目标检测各个领域已经霸榜，让很多人看到了transformer完全替代卷积的可能。而且它的设计思想吸取了resnet的精华，从局部到全局，将transformer设计成逐步扩大感受野的工具，它的成功背后绝不是偶然，而是厚厚的积累与沉淀。<br> 论文链接<a href="https://arxiv.org/abs/2103.14030" rel="nofollow">https://arxiv.org/abs/2103.14030</a></p> 
<h3><a id="_4"></a>总体结构</h3> 
<p>输入的图像先经过一层卷积进行patch映射，我有看过源代码，具体是将图像先分割成<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         4 
        
       
         × 
        
       
         4 
        
       
      
        4\times4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">4</span></span></span></span></span>的小块，然后将每一个小块通过映射成一个像素点，进行了通道上的扩充。以swin-s为例，输入的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         224 
        
       
         × 
        
       
         224 
        
       
      
        224\times224 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span></span></span></span></span>图像经过这一步操作就变成了<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         56 
        
       
         × 
        
       
         56 
        
       
      
        56\times56 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">5</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">5</span><span class="mord">6</span></span></span></span></span>的特征图。特征图一开始开始输入到stage1，stage1由两层transformer组成，这两层transformer的核心一个是普通的window attention, 另一个是shift window attention。可以将window attention 和shift window attention视为两个模块，在每一个stage内部就是直接堆积这两个模块。然后在stage与stage之间要有一个pooling操作来降低要处理的数据的尺寸，也就是为了从一开始的局部信息搜索到全局信息的提取。当然这个pooling操作与传统卷积里面的pooling也不太一样，它是将特征图先经过一个space to depth变为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          1 
         
        
          4 
         
        
       
      
        \frac{1}{4} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.19011em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>，通道数变为原来的4倍，再又一个MLP缩减一半。也就是说没经过一个stage，总的数据量变为原来的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          1 
         
        
          2 
         
        
       
      
        \frac{1}{2} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.19011em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>。<br> 此时可以很容易的看出，swin transformer和resnet一样设计的是一个层次结果很明显的网络，底部的结构处理的数据更多也更局部，顶部的网络处理的数据更少但是语义信息是更加丰富的。不同的是swin主要提取信息的方式是采用transformer，而resnet是卷积核。<br> <img src="https://images2.imgbox.com/bb/f8/z4yZ4xSD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="window_attention__shift_window_attention_8"></a>window attention 和 shift window attention</h3> 
<p>如图，window attention就是按照一定的尺寸将图像划分为不同的window，每次transformer的attention只在window内部进行计算。那么如果只有window attention就会带来每一个像素点的感受野得不到提升的问题，所以它又设计了一个shift window attention的方法，就是换一下window划分的方式，让每一个像素点做attention计算的window块处于变化之中。那么就起到了提升感受野的作用。</p> 
<p><img src="https://images2.imgbox.com/85/9f/2p2zrDcF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_12"></a>存在的问题</h3> 
<p>在同尺寸通计算量的前提下，swin确实效果远好于resnet。但是有几个问题：<br> 1. 受缚于shift操作，对不同尺寸的输入要设计不同的网络，而且也要重新开始训练，这是很难接受的。<br> 2. 和Detr一样训练的时候收敛的太慢。我自己有训练了一下最小的swin-tiny版本，大概训练了一百多轮的时候也才到72～73左右。有这方面改进的想法的朋友可以和我交流，整一篇B类应该没问题。<br> 3. shift操作其实主要是为了提升感受野，可以换一种更好的方式。在这个方面我也有一点思路，可以交流。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/65686b704b175e2aa8477ece4f9c0020/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">A simple introduction to HashTable in C</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a460a41b7124ca8499e71e587d253af8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">linux防火墙禁止所以端口,利用iptables来配置linux禁止所有端口登陆和开放指定端口...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>