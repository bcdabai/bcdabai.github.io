<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>爬虫基础-Ajax爬取实战 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="爬虫基础-Ajax爬取实战" />
<meta property="og:description" content="注：本文章为学习过程中对知识点的记录，供自己复习使用，也给大家做个参考，如有错误，麻烦指出，大家共同探讨，互相进步。
借鉴出处：
该文章的路线和主要内容：崔庆才（第2版）python3网络爬虫开发实战
爬取目标： https://spa1.scrape.center
1、电影的名称、封面、类别、上映日期、评分、剧情简介等信息。
2、用requests实现Ajax数据的爬取
3、对爬取的数据进行存储
分析：
首先：我们要获取电影的名称、封面、类别、上映日期、评分、剧情简介等信息在每一首电影的详情接口可以获取，所以只要搜集所有的电影的详情页即可爬取所有电影的信息。
对详情页接口进行分析，每个url后缀传入了一个数字，分析而知是每部电影的id且所有电影的id都是不同的，那就要找所有的id。
其次：对每一页接口分析而知，响应中包含当前页所有电影的id，那对所有页遍历完之后就可以获取全部的id了。
最后：将每部电影数据存储到json文件中，要将dict转换为json对象后，以追加的方式存入bb.json文件中即可。
输入：
import requests import json import logging logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s - %(levelname)s : %(message)s&#39;) BASE_URL = &#39;https://spa1.scrape.center/api/movie?limit={limit}&amp;offset={offset}&#39; INDEX_URl = &#39;https://spa1.scrape.center/api/movie/{id}/&#39; &#39;&#39;&#39;通用爬取方法&#39;&#39;&#39; def scrape_method(url): try: response = requests.get(url) if response.status_code == 200: return response.json() else: logging.error(f&#34;请求{url}的状态码:{requests.status_codes}&#34;) except requests.RequestException as e: logging.error(e) &#39;&#39;&#39;爬取每一页的url&#39;&#39;&#39; def scrape_baseUrl(limitA,offsetA): url = BASE_URL.format(limit=limitA,offset=offsetA) return scrape_method(url) &#39;&#39;&#39;爬取每一个电影&#39;&#39;&#39; def scrape_indexRul(id): url = INDEX_URl.format(id = id) return scrape_method(url) def main(): limitNum = 10 # 一共11页offset依次传入0 10 20 ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/b060e935a8f68a933745c80d0361d5d2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-26T00:14:09+08:00" />
<meta property="article:modified_time" content="2022-10-26T00:14:09+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">爬虫基础-Ajax爬取实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>注：本文章为学习过程中对知识点的记录，供自己复习使用，也给大家做个参考，如有错误，麻烦指出，大家共同探讨，互相进步。<br> 借鉴出处：<br> <a href="https://book.douban.com/subject/35681856/" rel="nofollow">该文章的路线和主要内容：崔庆才（第2版）python3网络爬虫开发实战</a></p> 
<hr> 
<p><strong>爬取目标：</strong> https://spa1.scrape.center<br> 1、电影的名称、封面、类别、上映日期、评分、剧情简介等信息。<br> 2、用requests实现Ajax数据的爬取<br> 3、对爬取的数据进行存储</p> 
<p><strong>分析：</strong><br> 首先：我们要获取电影的名称、封面、类别、上映日期、评分、剧情简介等信息在每一首电影的详情接口可以获取，所以只要搜集所有的电影的详情页即可爬取所有电影的信息。<br> <img src="https://images2.imgbox.com/c9/bb/sGFVQFOv_o.png" alt="在这里插入图片描述">对详情页接口进行分析，每个url后缀传入了一个数字，分析而知是每部电影的id且所有电影的id都是不同的，那就要找所有的id。<br> <img src="https://images2.imgbox.com/45/6f/yP4Lr4dB_o.png" alt="在这里插入图片描述">其次：对每一页接口分析而知，响应中包含当前页所有电影的id，那对所有页遍历完之后就可以获取全部的id了。<br> <img src="https://images2.imgbox.com/2c/31/5cg4PNNY_o.png" alt="在这里插入图片描述">最后：将每部电影数据存储到json文件中，要将dict转换为json对象后，以追加的方式存入bb.json文件中即可。</p> 
<p><strong>输入：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> json
<span class="token keyword">import</span> logging
logging<span class="token punctuation">.</span>basicConfig<span class="token punctuation">(</span>level<span class="token operator">=</span>logging<span class="token punctuation">.</span>INFO<span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'%(asctime)s - %(levelname)s : %(message)s'</span><span class="token punctuation">)</span>

BASE_URL <span class="token operator">=</span> <span class="token string">'https://spa1.scrape.center/api/movie?limit={limit}&amp;offset={offset}'</span>
INDEX_URl <span class="token operator">=</span> <span class="token string">'https://spa1.scrape.center/api/movie/{id}/'</span>


<span class="token triple-quoted-string string">'''通用爬取方法'''</span>
<span class="token keyword">def</span> <span class="token function">scrape_method</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        <span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            logging<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"请求</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>url<span class="token punctuation">}</span></span><span class="token string">的状态码:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>requests<span class="token punctuation">.</span>status_codes<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">except</span> requests<span class="token punctuation">.</span>RequestException <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        logging<span class="token punctuation">.</span>error<span class="token punctuation">(</span>e<span class="token punctuation">)</span>


<span class="token triple-quoted-string string">'''爬取每一页的url'''</span>
<span class="token keyword">def</span> <span class="token function">scrape_baseUrl</span><span class="token punctuation">(</span>limitA<span class="token punctuation">,</span>offsetA<span class="token punctuation">)</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span> BASE_URL<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>limit<span class="token operator">=</span>limitA<span class="token punctuation">,</span>offset<span class="token operator">=</span>offsetA<span class="token punctuation">)</span>
    <span class="token keyword">return</span> scrape_method<span class="token punctuation">(</span>url<span class="token punctuation">)</span>


<span class="token triple-quoted-string string">'''爬取每一个电影'''</span>
<span class="token keyword">def</span> <span class="token function">scrape_indexRul</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span> INDEX_URl<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">id</span> <span class="token operator">=</span> <span class="token builtin">id</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> scrape_method<span class="token punctuation">(</span>url<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    limitNum <span class="token operator">=</span> <span class="token number">10</span>
    <span class="token comment"># 一共11页offset依次传入0 10 20 .... 100</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        jsonObject <span class="token operator">=</span> scrape_baseUrl<span class="token punctuation">(</span>limitNum<span class="token punctuation">,</span>i<span class="token punctuation">)</span>
        logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>jsonObject<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'results'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 此时results是dict类型，需要转换为json对象，再存入json文件</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> jsonObject<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'results'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">id</span> <span class="token operator">=</span> item<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'id'</span><span class="token punctuation">)</span>
            indexData <span class="token operator">=</span> scrape_indexRul<span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">)</span>
            <span class="token comment"># 以追加的方式将每一部电影的所有属性都存入到bb.json文件中</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'bb.json'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
                <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>indexData<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>输出：</strong><br> <img src="https://images2.imgbox.com/a6/33/hoHopmSg_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c07909a87aca28ab56ba7d6ffc95adac/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vit~3</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/022471a77b3889561ab6004c9cee608e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">爬虫基础-数据存储</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>