<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>解开Kafka神秘的面纱(三)：kafka单机部署和集群部署 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="解开Kafka神秘的面纱(三)：kafka单机部署和集群部署" />
<meta property="og:description" content="文章目录 一、前言二、kafka单机安装2.1 下载压缩包2.2 zookeeper安装2.3 kafka安装 三、kafka集群安装3.1 zookeeper安装3.2 kafka的安装3.3 两种Topic 四、尾声 一、前言 本文主要介绍kafka的单机和集群模式部署。
二、kafka单机安装 2.1 下载压缩包 需要先到官网下载zookeeper和kafka压缩包，先下载zookeeper，如下
然后进入kafka官网下载，如下图：
下载到本地
2.2 zookeeper安装 第一步：使用FileZilla或者xftp可以通过ftp将zookeeper压缩包上传到 192.168.100.120 机器，解压，进入到 conf 目录，看到 zoo_sample.cfg 文件，cp 复制生成 zoo.cfg 文件，如下：
第二步，启动并查看状态
启动zookeeper ./bin/zkServer.sh start 查看zookeeper状态 ./bin/zkServer.sh status standalone代表单机启动，后面讲解集群启动
2.3 kafka安装 第一步：使用FileZilla或者xftp可以通过ftp将kafka压缩包上传到 192.168.100.120 机器，解压，进入到 conf 目录，看到config/server.properties 文件，并做如下修改
第二步：启动kafka
./bin/kafka-server-start.sh config/server.properties &amp; 第三步：新建topic并查看状态
./bin/kafka-topics.sh --create --topic test2 --bootstrap-server 192.168.100.120:9092 --partitions 1 --replication-factor 1 ./bin/kafka-topics.sh --describe --topic test2 --bootstrap-server 192.168.100.120:9092 然后zoo.cfg指定的目录就有了topic了
第五步：生产消息和消费消息" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/0fb9e95b0cfe58466dd7bee1326ffc98/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-01T22:58:03+08:00" />
<meta property="article:modified_time" content="2022-12-01T22:58:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">解开Kafka神秘的面纱(三)：kafka单机部署和集群部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">一、前言</a></li><li><a href="#kafka_3" rel="nofollow">二、kafka单机安装</a></li><li><ul><li><a href="#21__4" rel="nofollow">2.1 下载压缩包</a></li><li><a href="#22_zookeeper_18" rel="nofollow">2.2 zookeeper安装</a></li><li><a href="#23_kafka_35" rel="nofollow">2.3 kafka安装</a></li></ul> 
  </li><li><a href="#kafka_79" rel="nofollow">三、kafka集群安装</a></li><li><ul><li><a href="#31_zookeeper_84" rel="nofollow">3.1 zookeeper安装</a></li><li><a href="#32_kafka_154" rel="nofollow">3.2 kafka的安装</a></li><li><a href="#33_Topic_259" rel="nofollow">3.3 两种Topic</a></li></ul> 
  </li><li><a href="#_283" rel="nofollow">四、尾声</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>一、前言</h2> 
<p>本文主要介绍kafka的单机和集群模式部署。</p> 
<h2><a id="kafka_3"></a>二、kafka单机安装</h2> 
<h3><a id="21__4"></a>2.1 下载压缩包</h3> 
<p>需要先到官网下载zookeeper和kafka压缩包，先下载zookeeper，如下</p> 
<p><img src="https://images2.imgbox.com/60/58/GiPUQYRf_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/55/00/geOCKkbp_o.png" alt="在这里插入图片描述"></p> 
<p>然后进入kafka官网下载，如下图：</p> 
<p><img src="https://images2.imgbox.com/ef/49/cMijZFfr_o.png" alt="在这里插入图片描述"><br> 下载到本地</p> 
<p><img src="https://images2.imgbox.com/52/71/8mTEqgyb_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_zookeeper_18"></a>2.2 zookeeper安装</h3> 
<p>第一步：使用FileZilla或者xftp可以通过ftp将zookeeper压缩包上传到 192.168.100.120 机器，解压，进入到 conf 目录，看到 zoo_sample.cfg 文件，cp 复制生成 zoo.cfg 文件，如下：</p> 
<p><img src="https://images2.imgbox.com/74/73/PaLAQOS7_o.png" alt="在这里插入图片描述"><br> 第二步，启动并查看状态</p> 
<pre><code class="prism language-bash">启动zookeeper
./bin/zkServer.sh start
查看zookeeper状态
./bin/zkServer.sh status
</code></pre> 
<p><img src="https://images2.imgbox.com/8a/d2/6viwprEn_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>standalone代表单机启动，后面讲解集群启动</p> 
</blockquote> 
<h3><a id="23_kafka_35"></a>2.3 kafka安装</h3> 
<p>第一步：使用FileZilla或者xftp可以通过ftp将kafka压缩包上传到 192.168.100.120 机器，解压，进入到 conf 目录，看到config/server.properties 文件，并做如下修改<br> <img src="https://images2.imgbox.com/80/38/eXKWmZbm_o.png" alt="在这里插入图片描述"><br> 第二步：启动kafka</p> 
<pre><code class="prism language-bash">./bin/kafka-server-start.sh config/server.properties <span class="token operator">&amp;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/af/20/dm8wbbTp_o.png" alt="在这里插入图片描述"></p> 
<p>第三步：新建topic并查看状态</p> 
<pre><code class="prism language-bash">./bin/kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> test2 --bootstrap-server <span class="token number">192.168</span>.100.120:9092 
<span class="token parameter variable">--partitions</span> <span class="token number">1</span> --replication-factor <span class="token number">1</span> 
</code></pre> 
<pre><code class="prism language-bash">./bin/kafka-topics.sh <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> test2 --bootstrap-server <span class="token number">192.168</span>.100.120:9092 
</code></pre> 
<p><img src="https://images2.imgbox.com/49/a4/lx84WNQ1_o.png" alt="在这里插入图片描述"></p> 
<p>然后zoo.cfg指定的目录就有了topic了<br> <img src="https://images2.imgbox.com/9d/1a/eZ4Jp7xp_o.png" alt="在这里插入图片描述"></p> 
<p>第五步：生产消息和消费消息</p> 
<pre><code class="prism language-bash"><span class="token comment"># 生产消息</span>
./bin/kafka-console-producer.sh --bootstrap-server <span class="token number">192.168</span>.100.120:9092 <span class="token parameter variable">--topic</span> test2
</code></pre> 
<pre><code class="prism language-bash"><span class="token comment"># 消费消息</span>
./bin/kafka-console-consumer.sh --bootstrap-server <span class="token number">192.168</span>.100.120:9092 <span class="token parameter variable">--topic</span> test2 --from-beginning
</code></pre> 
<p>生产的消息被消费了</p> 
<p><img src="https://images2.imgbox.com/02/7f/bilRxUsp_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="kafka_79"></a>三、kafka集群安装</h2> 
<p>同时准备好三个虚拟机， 我这里192.168.100.136、192.168.100.137、192.168.100.138，下面无论是zookeeper还是kafka，我们都先对136操作，然后配置文件复制到137、138上面去，改一改就好了。</p> 
<h3><a id="31_zookeeper_84"></a>3.1 zookeeper安装</h3> 
<p>第一步：使用FileZilla或者xftp可以通过ftp将zookeeper压缩包上传到192.168.100.136机器，解压，进入到 conf 目录，看到 zoo_sample.cfg 文件，cp 复制生成 zoo.cfg 文件，如下：</p> 
<p><img src="https://images2.imgbox.com/93/13/q5MU99On_o.png" alt="在这里插入图片描述"></p> 
<p>第二步，在192.168.100.136机器上，修改zoo.cfg，如下：</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">dataDir</span><span class="token operator">=</span>/data/zookeeper/data 
<span class="token assign-left variable">dataLogDir</span><span class="token operator">=</span>/data/zookeeper/logs 

<span class="token assign-left variable">server.1</span><span class="token operator">=</span><span class="token number">192.168</span>.100.136:8880:7770 
<span class="token assign-left variable">server.2</span><span class="token operator">=</span><span class="token number">192.168</span>.100.137:8880:7770 
<span class="token assign-left variable">server.3</span><span class="token operator">=</span><span class="token number">192.168</span>.100.138:8880:7770
</code></pre> 
<p><img src="https://images2.imgbox.com/27/19/bLY5ibvh_o.png" alt="在这里插入图片描述"></p> 
<p>第三步：在192.168.100.136机器上，新建 /data/zookeeper/data 和 /data/zookeeper/logs 目录，因为 zoo.cfg 配置文件中指定了这两个目录，所以需要新建出来。</p> 
<p><img src="https://images2.imgbox.com/ac/b8/VVuvZ8eb_o.png" alt="在这里插入图片描述"></p> 
<p>第四步：将 zoo.cfg 复制到另外两个节点192.168.10.137、192.168.100.138上，并在这两个机器上新建 /data/zookeeper/data 和 /data/zookeeper/logs 目录。</p> 
<p>第五步：分别在三个节点的 dataDir （即/data/zookeeper/data） 目录下创建myid文件，内容为：</p> 
<p>第一个节点 192.168.100.136 为 1，<br> 第二个节点 192.168.100.137 为 2，<br> 第三个节点 192.168.100.138 为 3。</p> 
<p>注意：myid文件里的值是和刚才zoo.cfg文件配置的server.1 server.2 server.3 对应的，第一台服务器就是 192.168.100.136，第二台服务器就是 192.168.100.137，第三台服务器就是 192.168.100.138。</p> 
<p>第六步：三台机器上，启动zookeeper，并查看zookeeper状态，确定zookeeper启动是否正常</p> 
<pre><code class="prism language-bash">启动zookeeper
./bin/zkServer.sh start
</code></pre> 
<pre><code class="prism language-bash">查看zookeeper状态
./bin/zkServer.sh status
</code></pre> 
<p>注意，zk三个命令<br> 停止： <code>./bin/zkServer.sh stop</code><br> 启动： <code>./bin/zkServer.sh start</code><br> 查看状态：<code>./bin/zkServer.sh status</code></p> 
<p>如果是启动第一个节点，查看状态如下，没关系，这是因为才启动一个节点，还没有形成集群的原因，用 <code>ps -ef|grep zookeeper</code> 可以看到进程启动了就行了。<br> <img src="https://images2.imgbox.com/80/a4/Lnu3P47O_o.png" alt="在这里插入图片描述"><br> 只要看到启动了就好了</p> 
<p><img src="https://images2.imgbox.com/5c/31/P89Y30WG_o.png" alt="在这里插入图片描述"></p> 
<p>三个节点zookeeper均启动之后，如下：<br> <img src="https://images2.imgbox.com/49/2e/wZ4bLWMV_o.png" alt="在这里插入图片描述"></p> 
<p>eg1: zookeeper的注册中心和配置中心只是zk分布式协调的两个功能而已，主要协调数据一致性；<br> eg2: zookeeper集群只能部署奇数个节点(2n+1)个节点，避免选主失败；<br> eg3: kafka生产消息不需要依赖zookeeper，只有消费消息的时候，需要zookeeper用来记录offset。</p> 
<h3><a id="32_kafka_154"></a>3.2 kafka的安装</h3> 
<p>第一步：使用FileZilla或者xftp可以通过ftp将kafka压缩包上传到 192.168.100.136 机器，解压，进入到 conf 目录，看到config/server.properties 文件，并做如下修改</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">0</span> 
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://192.168.100.136:9092 
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/data/kafka/kafka-logs 
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span><span class="token number">192.168</span>.100.136:2181,192.168.100.137:2181,192.168.100.138:2181  
</code></pre> 
<p><img src="https://images2.imgbox.com/bb/db/yRwrKTkt_o.png" alt="在这里插入图片描述"></p> 
<p>同理，使用FileZilla或者xftp可以通过ftp将kafka压缩包上传到 192.168.100.137 机器，解压，进入到 conf 目录，看到config/server.properties 文件，并做如下修改</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span> 
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://192.168.100.137:9092 
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/data/kafka/kafka-logs 
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span><span class="token number">192.168</span>.100.136:2181,192.168.100.137:2181,192.168.100.138:2181  
</code></pre> 
<p>注意：这里的 broker.id 和 listeners 这两个需要修改，log.dirs 和 zookeeper.connect 不需要改变，三个节点 broker.id 不能重复，哪个机器配哪个broker.id，就和 zoo.cfg 文件保持一致即可，listener 这里配置自己的ip地址。</p> 
<p>继续，使用FileZilla或者xftp可以通过ftp将kafka压缩包上传到 192.168.100.138 机器，解压，进入到 conf 目录，看到config/server.properties 文件，并做如下修改</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">2</span> 
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://192.168.100.138:9092 
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/data/kafka/kafka-logs 
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span><span class="token number">192.168</span>.100.136:2181,192.168.100.137:2181,192.168.100.138:2181  
</code></pre> 
<p>也是 broker.id 和 listeners 需要改变，log.dirs 和 zookeeper.connect 不需要改变。</p> 
<p>第二步：三个节点kafka启动</p> 
<p>在 192.168.100.136、192.168.100.137、192.168.100.138 三个机器上，分别运行这句</p> 
<pre><code class="prism language-bash">./bin/kafka-server-start.sh config/server.properties <span class="token operator">&amp;</span>
</code></pre> 
<p>额外注意：有的时候，zookeeper或kafka启动会失败，这个一般是zk日志中有老数据，删掉各个节点 /data/zookeeper/data 和 /data/zookeeper/logs 就好，一般只要 zookeeper 不出问题，kafka启动是不会出问题的。</p> 
<p>第三步：创建topic（默认需要手动创建，可以修改配置文件让kafka自动创建不存在的topic）</p> 
<p>创建一个名称为 test2 的 topic ，指定 test topic有一个分区，一个副本。</p> 
<pre><code class="prism language-bash">./bin/kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> test2 --bootstrap-server <span class="token number">192.168</span>.100.137:9092 <span class="token parameter variable">--partitions</span> <span class="token number">1</span> --replication-factor <span class="token number">1</span> 
</code></pre> 
<p>注意理解一下分区数和副本数的意思：因为这个topic只设置存放一个分区，且每个分区一个副本，所以 1 * 1 = 1 ，分区名称就是 test2-0，如果是三个分区，每个分区三个副本，所以 3 *3 = 9 个，如图：</p> 
<p>查看topic信息</p> 
<pre><code class="prism language-bash">./bin/kafka-topics.sh <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> test2 --bootstrap-server <span class="token number">192.168</span>.100.137:9092 
</code></pre> 
<p><img src="https://images2.imgbox.com/f3/c6/lBmOBp10_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/30/22/QfQ5eL26_o.png" alt="在这里插入图片描述"></p> 
<p>额外注意： kafka 中 topic 的概念类似rabbitmq 中 exchage 的概念。不同的是，rabbitmq中，消息存在在queue队列中，生产者生产消息的时候，如果没有这个exchange，会自己创建一个并发送消息到rabbitmq，经过exchange中转到queue队列中；但是，kafka中，生产者生产消息的时候，如果没有这个topic，不会自己创建一个并完成发送消息到kafka的partition中，而是会直接报错，所以，需要先创建topic，再发送消息。</p> 
<p>第四步：发送消息，用kafka自带的命名模拟消息发送</p> 
<pre><code class="prism language-bash">./bin/kafka-console-producer.sh --bootstrap-server <span class="token number">192.168</span>.100.137:9092 <span class="token parameter variable">--topic</span> test2
</code></pre> 
<p>第五步：消费消息，用kafka自带的命名模拟消息消费</p> 
<pre><code class="prism language-bash">./bin/kafka-console-consumer.sh --bootstrap-server <span class="token number">192.168</span>.100.136:9092 <span class="token parameter variable">--topic</span> test2 --from-beginning
</code></pre> 
<p><img src="https://images2.imgbox.com/6f/80/MyTzfupR_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>生产消息和消费消息都是需要指定topic的;<br> 消费消息还需要指定从头开始消费还是从尾开始消费，指定参数–from-beginning从头开始.</p> 
</blockquote> 
<p>eg: 消费位置也可以通过auto.offset.reset 参数来指定，如下：<br> (1) earliest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费。<br> (2) latest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据。<br> (3) none：topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常。</p> 
<p>小结：kafka常见<br> ./bin/kafka-server-start.sh 启动<br> ./bin/kafka-server-stop.sh 停止<br> ./bin/kafka-topics.sh topic创建与查看状态<br> ./bin/kafka-console-producer.sh 生产<br> sh./bin/kafka-console-consumer.sh 消费</p> 
<h3><a id="33_Topic_259"></a>3.3 两种Topic</h3> 
<p>除了程序员自己手动用命令创建的topic，kafka中还有一种topic。</p> 
<p>第一次消费topic的时候，kafka会默认创建一个名为__consumer_offsets的topic，这个topic有50个partition，每个partition一个副本replication，所以一共是 50*1=50个，这50个partition分布到整个kafka集群中，单机模式是分布到 192.168.100.120 机器上，集群模式是分布到 192.168.100.136、192.168.100.137、192.168.100.138 三个机器上。</p> 
<p>这种设计为了应对有很多个consumer来消费，所以kafka默认为集群创建50个partition，我们可以通过命令随时查看kafka集群上的topic，如下：</p> 
<pre><code class="prism language-bash">./bin/kafka-topics.sh --bootstrap-server <span class="token number">192.168</span>.100.120:9092 <span class="token parameter variable">--list</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/2c/04/K77BsqU7_o.png" alt="在这里插入图片描述"></p> 
<p>如上图，我们看到了， __consumer_offset就是一个topic名，当第一次消费的时候，kafka自动创建的一个名为 __consumer_offset 的topic，还有一个test2是程序员自己用命令手动创建的topic，不管是哪种，都存放在server.properties中log.dirs指定的目录下，如下图：<br> <img src="https://images2.imgbox.com/bb/e6/pxhlHObz_o.png" alt="在这里插入图片描述"></p> 
<p>我们需要区分好两种topic，如下：</p> 
<p>(1) __consumer_offset 就是一个topic，这个topic是在消息被第一次消费的时候，kafka自动创建的，默认有50个partition，每个partition只有一个副本，就是自己，均放在kafka中server.properties文件配置的 log.dirs 属性指定目录下；<br> (2) test2 也是topic，这个topic是程序员手动命令创建的，也是存放在partition里面，分区数partition和副本数replication也是自己设置。</p> 
<p>eg: 集群情况下也是这样，经过第一次消费，我们可以看到50个partition，只是这50个partition被分布到整个kafka集群上，我们这里是 192.168.100.136、192.168.100.137、192.168.100.138 三个机器上。</p> 
<h2><a id="_283"></a>四、尾声</h2> 
<p>本文主要介绍了kafka的单机和集群模式部署。</p> 
<p>天天打码，天天进步！！</p> 
<p>1、启动zookeeper</p> 
<pre><code class="prism language-bash">//挂起运行
bin/zookeeper-server-start.sh config/zookeeper.properties 
//后台运行
 <span class="token function">nohup</span> bin/zookeeper-server-start.sh config/zookeeper.properties <span class="token operator">&gt;</span>/dev/null <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>
</code></pre> 
<p>2、启动kafka</p> 
<pre><code class="prism language-bash">//挂起运行
bin/kafka-server-start.sh config/server.properties 
//后台运行 
<span class="token function">nohup</span> bin/kafka-server-start.sh config/server.properties <span class="token operator">&gt;</span>/dev/null <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>
</code></pre> 
<p>关闭</p> 
<p>1、关闭kafka</p> 
<pre><code class="prism language-bash">关闭挂起运行
ctrl+c
//关闭后台运行
bin/kafka-server-stop.sh
</code></pre> 
<p>2、关闭zookeeper</p> 
<pre><code class="prism language-bash">关闭挂起运行
ctrl+c
//关闭后台运行
bin/zookeeper-server-stop.sh
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/242401003e18f49f5027034f10746966/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">EGE基础：图像操作篇</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c5eac5fda7d2381472dad29fa66e8df8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Centos Stream 8虚拟机搭建单节点OpenStack</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>