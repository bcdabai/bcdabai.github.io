<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>实例分割新思路之SOLO v1&amp;v2深度解析 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="实例分割新思路之SOLO v1&amp;v2深度解析" />
<meta property="og:description" content="前言 实例分割一般有两种做法，一种是top-down，既先检测 bbox，后在每个bbox中进行mask的分割，例如Mask R-CNN。第二种为bottom-up做法，先分割出每一个像素，再进行归类。本文介绍的两篇论文另辟蹊径, 直接分割实例 mask，属于box-free的做法。正如YOLO大神Joseph Redmon所说“Boxes are stupid anyway though, I’m probably a true believer in masks except I can’t get YOLO to learn them“。本文就是摒弃了boxes进行实例分割，因此有必要对该论文进行深入分析。
论文地址:v1: https://arxiv.org/abs/1912.04488 ，v2: https://arxiv.org/abs/2003.10152。
参考的代码为在mmdetection的基础上实现的：https://github.com/WXinlong/SOLO
SOLO v1 head设计 首先思考一个问题，能否像语义分割一样进行实例分割？实例分割和语义分割在算法处理上最大的不同就是，实例分割需要处理同类别的实例重叠或粘连的问题。那么如果将不同的实例分配到不同的输出channel上，不就可以解决这个问题了吗？本文作者正是这种思路，不过这样也面临两个问题: 一是通道分配顺序的问题，语义分割是根据类别进行通道分配的。而对于实例分割，相同类别的不同实例需要分配到不同通道上，需要解决按照什么样的规则分配。二是尺度问题，不同尺度的物体利用相同大小的输出来预测会导致正负样本不平衡，以及小目标分割边缘不够精细的问题。对于这两个问题，本文作者给出了解答。作者首先对MS COCO数据集进行统计，发现在验证集中，绝大多数（约98.9%）的实例要么中心位置不同，要么大小不同。因此可以通过中心位置和对象大小直接区分实例， 既location 和 sizes。所以作者利用位置来分配实例应该落入哪一个通道，利用FPN来解决尺度问题。
具体做法为: 类似YOLO中的做法，首先将图片等分为 S×S\epsilon=0.2 。当被缩小后的box落入原图上某几个格子，这些格子对应的分类分支位置以及mask分支channel为正样本，否则为负样本。每一个gt平均有3个正样本。代码如下：
# 分类分支的正负样本分配，这里的top,down,left,right为gt box缩小sigma倍后的box上下左右值 cate_label[top:(down&#43;1), left:(right&#43;1)] = gt_label 对于mask分支的正样本分配，在0.2倍的gt box内grid cell对应的通道均分配为mask正样本 seg_mask = mmcv.imrescale(seg_mask, scale=1. / output_stride)
seg_mask = torch.Tensor(seg_mask)
for i in range(top, down&#43;1):
for j in range(left, right&#43;1):" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/4402eaf873b18df6752e58736c9a2a74/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-20T09:43:05+08:00" />
<meta property="article:modified_time" content="2023-07-20T09:43:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实例分割新思路之SOLO v1&amp;v2深度解析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <div class="Post-RichTextContainer"> 
 <div class="css-1yuhvjn"> 
  <div class="css-376mun"> 
   <div class="RichText ztext Post-RichText css-1g0fqss"> 
    <h3><b>前言</b></h3> 
    <p>实例分割一般有两种做法，一种是top-down，既先检测 bbox，后在每个bbox中进行mask的分割，例如Mask R-CNN。第二种为bottom-up做法，先分割出每一个像素，再进行归类。本文介绍的两篇论文另辟蹊径, 直接分割实例 mask，属于box-free的做法。正如YOLO大神Joseph Redmon所说<i>“Boxes are stupid anyway though, I’m probably a true believer in masks except I can’t get YOLO to learn them“</i>。本文就是摒弃了boxes进行实例分割，因此有必要对该论文进行深入分析。</p> 
    <p>论文地址:v1: <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1912.04488" rel="nofollow noreferrer noopener noreferrer" class=" external" target="_blank"><span class="invisible">https://</span><span class="visible">arxiv.org/abs/1912.0448</span><span class="invisible">8</span><span class="ellipsis"></span></a> ，v2: <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2003.10152" rel="nofollow noreferrer noopener noreferrer" class=" external" target="_blank"><span class="invisible">https://</span><span class="visible">arxiv.org/abs/2003.1015</span><span class="invisible">2</span><span class="ellipsis"></span></a>。</p> 
    <p>参考的代码为在mmdetection的基础上实现的：<a href="https://link.zhihu.com/?target=https%3A//github.com/WXinlong/SOLO" rel="nofollow noreferrer noopener noreferrer" class=" external" target="_blank"><span class="invisible">https://</span><span class="visible">github.com/WXinlong/SOL</span><span class="invisible">O</span><span class="ellipsis"></span></a></p> 
    <h3><b>SOLO v1</b></h3> 
    <h3><b>head设计</b></h3> 
    <p>首先思考一个问题，能否像语义分割一样进行实例分割？实例分割和语义分割在算法处理上最大的不同就是，实例分割需要处理同类别的实例重叠或粘连的问题。那么如果将不同的实例分配到不同的输出channel上，不就可以解决这个问题了吗？本文作者正是这种思路，不过这样也面临两个问题: 一是通道分配顺序的问题，语义分割是根据类别进行通道分配的。而对于实例分割，相同类别的不同实例需要分配到不同通道上，需要解决按照什么样的规则分配。二是尺度问题，不同尺度的物体利用相同大小的输出来预测会导致正负样本不平衡，以及小目标分割边缘不够精细的问题。对于这两个问题，本文作者给出了解答。作者首先对MS COCO数据集进行统计，发现在验证集中，绝大多数（约98.9%）的实例要么中心位置不同，要么大小不同。因此可以通过中心位置和对象大小直接区分实例， 既location 和 sizes。所以作者利用位置来分配实例应该落入哪一个通道，利用FPN来解决尺度问题。</p> 
    <figure> 
     <img src="https://images2.imgbox.com/a9/bd/9zpmOrXu_o.jpg" class="origin_image zh-lightbox-thumb" width="1390"> 
     <div> 
      <img src="https://images2.imgbox.com/72/c5/wVWkryjP_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="1390" height="461"> 
     </div> 
    </figure> 
    <p>具体做法为: </p> 
    <p>类似YOLO中的做法，首先将图片等分为 <span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0"> 
        <svg width="5.839ex" height="2.094ex" viewbox="0 -799.9 2513.9 901.7"> 
         <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
          <use x="0" y="0"></use> 
          <use x="867" y="0"></use> 
          <use x="1868" y="0"></use> 
         </g> 
        </svg><span class="MJX_Assistive_MathML">S×S</span></span></span><span class="tex2jax_ignore math-holder">\epsilon=0.2</span> 。当被缩小后的box落入原图上某几个格子，这些格子对应的分类分支位置以及mask分支channel为正样本，否则为负样本。每一个gt平均有3个正样本。代码如下：</p> 
    <div class="highlight"> 
     <pre><code class="language-text"># 分类分支的正负样本分配，这里的top,down,left,right为gt box缩小sigma倍后的box上下左右值
cate_label[top:(down+1), left:(right+1)] = gt_label
</code></pre> 
    </div> 
   </div> 
  </div> 
 </div> 
</div> 
<h2><a id="mask02gt_boxgrid_cellmask_3"></a>对于mask分支的正样本分配，在0.2倍的gt box内grid cell对应的通道均分配为mask正样本</h2> 
<p>seg_mask = mmcv.imrescale(seg_mask, scale=1. / output_stride)<br> seg_mask = torch.Tensor(seg_mask)<br> for i in range(top, down+1):<br> for j in range(left, right+1):<br> label = int(i * num_grid + j)<br> ins_label[label, :seg_mask.shape[0], :seg_mask.shape[1]] = seg_mask</p> 
<h4><b>FPN不同层</b></h4> 
<p></p> 
<p>论文设置scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))，分别对应不同FPN的输出层。当实例的尺度落入某一个区间，则该FPN分支负责该实例的预测。由于不同区间存在重叠的情况，因此会存在不同FPN层预测相同的目标，这样同样会增加正样本的数量。代码如下：</p> 
<div class="highlight"> 
 <pre><code class="language-text">gt_areas = torch.sqrt((gt_bboxes_raw[:, 2] - gt_bboxes_raw[:, 0]) * (gt_bboxes_raw[:, 3] - gt_bboxes_raw[:, 1])) # gt的面积, 这里采用的是sqrt(W*H)
</code></pre> 
</div> 
<h2><a id="FPN__scale_ranges1_96_48_192_96_384_192_768_384_2048_gt_areas_FPN_10"></a>对FPN进行遍历, 区间为 scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)), gt_areas所属哪一个区间, 则该层FPN负责该实例的预测</h2> 
<p>for (lower_bound, upper_bound), stride, featmap_size, num_grid in zip(self.scale_ranges, self.strides, featmap_sizes, self.seg_num_grids):<br> hit_indices = ((gt_areas &gt;= lower_bound) &amp; (gt_areas &lt;= upper_bound)).nonzero().flatten() # 收集该层负责的个数<br> if len(hit_indices) == 0:<br> continue</p> 
<h4><b>可视化分析</b></h4> 
<p></p> 
<p>为了更清晰理解样本分配策略，这里进行了可视化。如图所示，在原图中，蓝色框表示图片等分的格子，这里设置分为5X5个格子。绿色框为目标物体的gt box，黄色框表示缩小到0.2倍数的box，红色框表示负责预测该实例的格子。下方黑白图为mask分支的target可视化，为了便于显示，这里对不同通道进行了拼接。 左边的第一幅图，图中有一个实例，其gt box缩小到0.2倍占据两个格子，因此这两个格子负责预测该实例。下方的mask分支，只有两个FPN的输出匹配到了该实例，因此在红色格子对应的channel负责预测该实例的mask。第二幅图，图中分布大小不同的实例，可见在FPN输出的mask分支上，从小到大负责不同尺度的实例。这里值得注意的是，FPN输出的mask分支，其尺度并不是统一的，而是从大到小的，这里为了便于显示才缩放到统一尺寸上。</p> 
<figure> 
 <img src="https://images2.imgbox.com/5d/e4/YsD5DTLl_o.jpg" class="origin_image zh-lightbox-thumb" width="1320"> 
 <div> 
  <img src="https://images2.imgbox.com/09/9d/ohVfdJjW_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="1320" height="662"> 
 </div> 
</figure> 
<h3><b>CoordConv</b></h3> 
<p>本文利用了CoordConv，目的是为了加强卷积神经网络对位置信息的处理。CoordConv做法非常简单， 直接在原始tensor上利用concatenate的方式扩两个通道，分别存储x和y的坐标，并归一化到[-1,1]之间。显式地把位置信息带入到下一个卷积操作里面。不过CoordConv也引起了一些争议，但该论文（SOLO）中使用还是起到了不错的效果，本文不去讨论。这一点，原作在知乎也给出了自己的看法:</p> 
<p><i>关于CoordConv和Dice Loss：这些并不是比普通Conv和BCE Loss更高级的东西，只是在我们这种情况下更适用而已: CoordConv用来提供全局位置信息，Dice Loss来解决分割区域小的问题。而Mask R-CNN是没有这样的需求的。</i></p> 
<p>具体做法如下，创建一个包含像素坐标tensor（标准化至 <span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0"> 
    <svg width="6.461ex" height="2.789ex" viewbox="0 -849.8 2781.7 1200.9"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <use x="0" y="0"></use> 
      <use x="278" y="0"></use> 
      <use x="1057" y="0"></use> 
      <use x="1557" y="0"></use> 
      <use x="2002" y="0"></use> 
      <use x="2503" y="0"></use> 
     </g> 
    </svg><span class="MJX_Assistive_MathML">[−1,1]</span></span></span><span class="tex2jax_ignore math-holder">[-1,1]</span> ），和原始通道concatenate，因此可以看到Channel数为（256+2），最后两个通道提供全图位置信息，再送入到后续的卷积运算中。代码如下：</p> 
<div class="highlight"> 
 <pre><code class="language-text">ins_feat = x # 当前实例特征tensor
</code></pre> 
</div> 
<h2><a id="11_15"></a>生成从-1到1的线性值</h2> 
<p>x_range = torch.linspace(-1, 1, ins_feat.shape[-1], device=ins_feat.device)<br> y_range = torch.linspace(-1, 1, ins_feat.shape[-2], device=ins_feat.device)<br> y, x = torch.meshgrid(y_range, x_range) # 生成二维坐标网格<br> y = y.expand([ins_feat.shape[0], 1, -1, -1]) # 扩充到和ins_feat相同维度<br> x = x.expand([ins_feat.shape[0], 1, -1, -1])<br> coord_feat = torch.cat([x, y], 1) # 位置特征<br> ins_feat = torch.cat([ins_feat, coord_feat], 1) # concatnate一起作为下一个卷积的输入</p> 
<h3><b>Decoupled head</b></h3> 
<p></p> 
<p>由于mask分支预测 <span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0"> 
    <svg width="2.576ex" height="2.326ex" viewbox="0 -899.7 1109.1 1001.4"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <use x="0" y="0"></use> 
      <use transform="scale(0.707)" x="926" y="513"></use> 
     </g> 
    </svg><span class="MJX_Assistive_MathML">S2</span></span></span><span class="tex2jax_ignore math-holder">k = iS + j </span> 。</p> 
<figure> 
 <img src="https://images2.imgbox.com/89/8f/e193RACt_o.jpg" class="origin_image zh-lightbox-thumb" width="479"> 
 <div> 
  <img src="https://images2.imgbox.com/e1/38/gH9t9PFw_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="479" height="651"> 
 </div> 
</figure> 
<p>代码如下：</p> 
<div class="highlight"> 
 <pre><code class="language-text"># 利用两个kernel=3的卷积分别输出x和y两个分支<br>
self.dsolo_ins_list_x = nn.ModuleList()<br>
self.dsolo_ins_list_y = nn.ModuleList()<br>
for seg_num_grid in self.seg_num_grids:<br>
self.dsolo_ins_list_x.append(nn.Conv2d(self.seg_feat_channels, seg_num_grid, 3, padding=1))<br>
self.dsolo_ins_list_y.append(nn.Conv2d(self.seg_feat_channels, seg_num_grid, 3, padding=1))
</code></pre> 
</div> 
<h2><a id="mask_xy_sigmoidx_indsy_inds_29"></a>获取最终预测的mask, x和y分支直接相乘, 注意两个分支提前经过sigmoid。x_inds和y_inds是提前计算出来的</h2> 
<p>seg_masks_soft = seg_preds_x[x_inds, …] * seg_preds_y[y_inds, …]</p> 
<h3><b>loss</b></h3> 
<p></p> 
<p>loss包括两部分，分别是分类分支的loss和mask分支的loss。分类loss直接使用FocalLoss，注意这里输出采用的是sigmoid激活。总loss为：</p> 
<p><span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" tabindex="0"> 
    <svg width="19.388ex" height="2.326ex" viewbox="0 -750.1 8347.8 1001.4"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <use x="0" y="0"></use> 
      <use x="959" y="0"></use> 
      <g transform="translate(2015,0)"> 
       <use x="0" y="0"></use> 
       <g transform="translate(681,-150)"> 
        <use transform="scale(0.707)" x="0" y="0"></use> 
        <use transform="scale(0.707)" x="433" y="0"></use> 
        <use transform="scale(0.707)" x="963" y="0"></use> 
        <use transform="scale(0.707)" x="1324" y="0"></use> 
       </g> 
      </g> 
      <use x="4285" y="0"></use> 
      <use x="5286" y="0"></use> 
      <g transform="translate(5869,0)"> 
       <use x="0" y="0"></use> 
       <g transform="translate(681,-150)"> 
        <use transform="scale(0.707)" x="0" y="0"></use> 
        <use transform="scale(0.707)" x="878" y="0"></use> 
        <use transform="scale(0.707)" x="1408" y="0"></use> 
        <use transform="scale(0.707)" x="1877" y="0"></use> 
       </g> 
      </g> 
     </g> 
    </svg><span class="MJX_Assistive_MathML">L=Lcate+λLmask</span></span></span><span class="tex2jax_ignore math-holder">j</span> 通道利用element-wise相乘的方式获取该类别的mask；</p> 
<ul><li>利用阈值（例如0.5）对mask进行筛选；</li><li>对所有mask进行nms；</li><li>将最终mask缩放到原图大小。</li><li><h3><b>solo v2</b></h3> 
<p></p> 
<p>v2在v1的基础上进行改进，其网格设计、正负样本分配策略、CoordConv、loss等操作完全继承与V1。主要区别有以下两点:</p> 
<ol><li>继续优化改进了mask输出的head，利用动态的方式获取；</li><li>提出了Matrix NMS，可以更快速的进行mask的NMS；</li></ol> 
<h3><b>动态mask head</b></h3> 
<p>v1采用的是Decoupled head的方式，分别预测X分支和Y分支，使用的时候再进行element-wise相乘。v2继续进行了优化，提出了dynamic head。如下图，mask预测分为了kernel 分支和feature 分支。</p> 
<figure> 
 <img src="https://images2.imgbox.com/c4/7a/5nd62gby_o.jpg" class="origin_image zh-lightbox-thumb" width="1349"> 
 <div> 
  <img src="https://images2.imgbox.com/37/2a/9gn8kOZB_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="1349" height="365"> 
 </div> 
</figure> 
<p><b>feature 分支：</b></p> 
<p>直接将FPN的输出进行融合为一个tensor，融合的方式为卷积+上采样来保证所有层尺寸相同，最终为输入图片1/4大小。值得注意的是在FPN最小输出层的处理上，同样利用了CoordConv来保证位置编码被输入进行。融合方式如下：</p> 
<figure> 
 <img src="https://images2.imgbox.com/4d/25/yTn9vCUv_o.jpg" class="origin_image zh-lightbox-thumb" width="637"> 
 <div> 
  <img src="https://images2.imgbox.com/50/6f/xVMClBRB_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="637" height="230"> 
 </div> 
</figure> 
<p><b>kernel分支：</b></p> 
<p>kernel分别直接来自FPN每个分支，和FPN的数目是对应上的。因此对于每一个FPN分支来说：</p> 
<div class="highlight"> 
 <pre><code class="language-text"># 直接进行双线性插值，尺度变化为： [1,256+2,h,w] -&gt; [1,256+2，S，S]
</code></pre> 
</div> 
<h2><a id="2562CorrdConvSgrid_cell_38"></a>这里的256+2同样利用了CorrdConv，S为grid cell的个数</h2> 
<p>kernel_feat = F.interpolate(kernel_feat, size=seg_num_grid, mode=‘bilinear’)<br> #后续还有一些卷积操作，最终输出的tensor为[1,256,S,S]</p> 
<p>对于最终每一个 <span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-28-Frame" tabindex="0"> 
    <svg width="12.044ex" height="2.789ex" viewbox="0 -849.8 5185.5 1200.9"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <use x="0" y="0"></use> 
      <use x="278" y="0"></use> 
      <use x="779" y="0"></use> 
      <g transform="translate(1224,0)"> 
       <use></use> 
       <use x="500" y="0"></use> 
       <use x="1001" y="0"></use> 
      </g> 
      <use x="2725" y="0"></use> 
      <use x="3170" y="0"></use> 
      <use x="3816" y="0"></use> 
      <use x="4261" y="0"></use> 
      <use x="4907" y="0"></use> 
     </g> 
    </svg><span class="MJX_Assistive_MathML">[1,256,S,S]</span></span></span><span class="tex2jax_ignore math-holder">1\times 1</span> 的卷积操作，即可以提取预测的mask。预测过程中，只需要将经过阈值过滤的类别得分对应的位置提取卷积核进行卷积提取mask操作既可，提高了运算的速度。</p> 
<h3><b>Matrix NMS</b></h3> 
<p>文章提出了Matrix NMS，可以理解为：Matrix NMS 结合soft NMS 、 Fast NMS ，并实现对mask 求IOU。这里分别回顾一下这三种技术：</p> 
<p><b>soft NMS</b>：NMS改进之一，为了防止IOU较大且非虚检的预测被删掉，来自论文《<i>Improving Object Detection With One Line of Code</i>》。传统的NMS将IOU大于阈值的检测框直接删掉，而soft NMS将IOU大于阈值框得分做了惩罚，惩罚分为线性惩罚和高斯惩罚两种。 当所有box经过惩罚修正后，再利用阈值对box进行过滤。代码解析如下：</p> 
<div class="highlight"> 
 <pre><code class="language-text">if method == ‘linear’: # 线性惩罚，惩罚因子为： 1-iou，注意只有iou大于阈值的才进行惩罚<br>
weight = np.ones_like(iou)<br>
weight[iou &gt; iou_thr] -= iou[iou &gt; iou_thr]<br>
elif method == ‘gaussian’: # 高斯惩罚， 所有的box均会被惩罚<br>
weight = np.exp(-(iou * iou) / sigma)<br>
else:  # 传统方法，直接将iou大于iou_thr的box的得分置0<br>
weight = np.ones_like(iou)<br>
weight[iou &gt; iou_thr] = 0
</code></pre> 
</div> 
<h2><a id="boxscore_48"></a>对所有box的score进行更新</h2> 
<p>dets[1:, 4] *= weight</p> 
<p><b>Fast NMS</b>： NMS改进之一，目的是为了提速，来自论文YOLACT。由于IOU计算具有对称性，即 <span class="ztext-math"><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-31-Frame" tabindex="0"> 
    <svg width="25.254ex" height="2.789ex" viewbox="0 -849.8 10873.4 1200.9"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <use x="0" y="0"></use> 
      <use x="504" y="0"></use> 
      <use x="1268" y="0"></use> 
      <use x="2035" y="0"></use> 
      <use x="2425" y="0"></use> 
      <use x="3175" y="0"></use> 
      <use x="3620" y="0"></use> 
      <use x="4380" y="0"></use> 
      <use x="5047" y="0"></use> 
      <use x="6103" y="0"></use> 
      <use x="6608" y="0"></use> 
      <use x="7371" y="0"></use> 
      <use x="8139" y="0"></use> 
      <use x="8528" y="0"></use> 
      <use x="9288" y="0"></use> 
      <use x="9733" y="0"></use> 
      <use x="10483" y="0"></use> 
     </g> 
    </svg><span class="MJX_Assistive_MathML">IOU(A,B)=IOU(B,A)</span></span></span><span class="tex2jax_ignore math-holder">IOU(A,B)=IOU(B,A)</span> ，因此该方法是利用triu函数对IOU 矩阵进行上三角化，然后对IOU Matrix执行按列取最大值操作，再抑制IOU大于阈值的box。代码如下：</p> 
<div class="highlight"> 
 <pre><code class="language-text">def fast_nms(boxes, scores, NMS_threshold=0.5):<br>
scores, idx = scores.sort(1, descending=True)<br>
boxes = boxes[idx]  # 对框按得分降序排列<br>
iou = box_iou(boxes, boxes)  # 获取IoU矩阵<br>
iou.triu_(diagonal=1)  # 对IoU矩阵上三角化<br>
keep = iou.max(dim=0)[0] &lt; NMS_threshold  # 列最大值向量，二值化<br>
return boxes[keep], scores[keep]</code></pre> 
</div> 
<p><b>mask求IOU</b>：由于box 求IOU比较简单，这里不再给出。而mask 求IOU，会比box复杂，也更耗时，这里给出直接求出IOU matrix的方式：</p> 
<div class="highlight"> 
 <pre><code class="language-python3"><span class="k">def</span> <span class="nf">mask_iou</span><span class="p">(</span><span class="n">masks1</span><span class="p">,</span><span class="n">masks2</span><span class="p">):</span><br>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">masks1</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># mask的个数</span><br>
<span class="n">sum_masks</span> <span class="o">=</span> <span class="n">seg_masks</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># 求面积操作</span><br>
<span class="n">seg_masks</span> <span class="o">=</span> <span class="n">seg_masks</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># 将wh拉成一个维度</span><br>
<span class="c1"># IOU即为交并比，这里进行求相交的部分</span><br>
<span class="n">inter_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">seg_masks</span><span class="p">,</span> <span class="n">seg_masks</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span><br>
<span class="c1"># 求并的部分</span><br>
<span class="n">sum_masks_x</span> <span class="o">=</span> <span class="n">sum_masks</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span><br>
<span class="c1"># iou.</span><br>
<span class="n">iou_matrix</span> <span class="o">=</span> <span class="p">(</span><span class="n">inter_matrix</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_masks_x</span> <span class="o">+</span> <span class="n">sum_masks_x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">inter_matrix</span><span class="p">))</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 计算IoU矩阵并进行上三角化</span><br>
<span class="k">return</span> <span class="n">iou_matrix</span></code></pre> 
</div> 
<p>本文中提出了Matrix NMS，使用并行的矩阵运算单次地实现NMS，不需要多次迭代。Matrix NMS可以做到在不到1ms的时间里处理500张mask，并且比目前最快的Faster NMS要高0.4% AP。论文给出的伪代码如下：</p> 
<figure> 
 <img src="https://images2.imgbox.com/a2/6a/vHdGywE4_o.jpg" class="origin_image zh-lightbox-thumb" width="653"> 
 <div> 
  <img src="https://images2.imgbox.com/a0/5e/74dr4dsq_o.jpg" class="origin_image zh-lightbox-thumb lazy" width="653" height="605"> 
 </div> 
</figure> 
<h3><b>预测过程</b></h3> 
<p>预测过程和v1类似，主要区别是v2提取mask的利用分类分支对应的卷积核，对特征图进行卷积求mask。另外，获取得到的所有mask进行Matrix NMS合并重复的mask。</p> 
<h3><b>后记</b></h3> 
<p>SOLO利用直接预测mask的方式进行实例分割，并做到的非常不错的效果，是一种很好的思路，期待后续会有新版本的出现。</p></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0d6e8639f48d8033bb81a7a22a7dacfc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RK3568 MIPI DSI单通道/双通道支持最大分辨率</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/da4af02389b4e2ab853d028b8c6018f5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Nginx代理nginx.conf配置——nginx对静态文件代理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>