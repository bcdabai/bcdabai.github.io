<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Ceph性能优化总结(v0.94) - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Ceph性能优化总结(v0.94)" />
<meta property="og:description" content="如需转载请标明作者，原文地址：http://xiaoquqi.github.io/blog/2015/06/28/ceph-performance-optimization-summary/
最近一直在忙着搞Ceph存储的优化和测试，看了各种资料，但是好像没有一篇文章把其中的方法论交代清楚，所以呢想在这里进行一下总结，很多内容并不是我原创，只是做一个总结。如果其中有任何的问题，欢迎各位喷我，以便我提高。
优化方法论 做任何事情还是要有个方法论的，“授人以鱼不如授人以渔”的道理吧，方法通了，所有的问题就有了解决的途径。通过对公开资料的分析进行总结，对分布式存储系统的优化离不开以下几点：
1. 硬件层面 硬件规划SSD选择BIOS设置 2. 软件层面 Linux OSCeph ConfigurationsPG Number调整CRUSH Map其他因素 硬件优化 1. 硬件规划 Processor ceph-osd进程在运行过程中会消耗CPU资源，所以一般会为每一个ceph-osd进程绑定一个CPU核上。当然如果你使用EC方式，可能需要更多的CPU资源。
ceph-mon进程并不十分消耗CPU资源，所以不必为ceph-mon进程预留过多的CPU资源。
ceph-msd也是非常消耗CPU资源的，所以需要提供更多的CPU资源。
内存 ceph-mon和ceph-mds需要2G内存，每个ceph-osd进程需要1G内存，当然2G更好。
网络规划 万兆网络现在基本上是跑Ceph必备的，网络规划上，也尽量考虑分离cilent和cluster网络。
2. SSD选择 硬件的选择也直接决定了Ceph集群的性能，从成本考虑，一般选择SATA SSD作为Journal，Intel® SSD DC S3500 Series基本是目前看到的方案中的首选。400G的规格4K随机写可以达到11000 IOPS。如果在预算足够的情况下，推荐使用PCIE SSD，性能会得到进一步提升，但是由于Journal在向数据盘写入数据时Block后续请求，所以Journal的加入并未呈现出想象中的性能提升，但是的确会对Latency有很大的改善。
如何确定你的SSD是否适合作为SSD Journal，可以参考SÉBASTIEN HAN的Ceph: How to Test if Your SSD Is Suitable as a Journal Device?，这里面他也列出了常见的SSD的测试结果，从结果来看SATA SSD中，Intel S3500性能表现最好。
3. BIOS设置 Hyper-Threading(HT) 基本做云平台的，VT和HT打开都是必须的，超线程技术(HT)就是利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。
关闭节能 关闭节能后，对性能还是有所提升的，所以坚决调整成性能型(Performance)。当然也可以在操作系统级别进行调整，详细的调整过程请参考链接，但是不知道是不是由于BIOS已经调整的缘故，所以在CentOS 6.6上并没有发现相关的设置。
for CPUFREQ in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do [ -f $CPUFREQ ] || continue; echo -n performance &gt; $CPUFREQ; done NUMA 简单来说，NUMA思路就是将内存和CPU分割为多个区域，每个区域叫做NODE,然后将NODE高速互联。 node内cpu与内存访问速度快于访问其他node的内存，NUMA可能会在某些情况下影响ceph-osd。解决的方案，一种是通过BIOS关闭NUMA，另外一种就是通过cgroup将ceph-osd进程与某一个CPU Core以及同一NODE下的内存进行绑定。但是第二种看起来更麻烦，所以一般部署的时候可以在系统层面关闭NUMA。CentOS系统下，通过修改/etc/grub." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/c4153557cd5fbe66f8c6e4db54998d2d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2015-06-30T23:02:15+08:00" />
<meta property="article:modified_time" content="2015-06-30T23:02:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Ceph性能优化总结(v0.94)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>如需转载请标明作者，原文地址：<a href="http://xiaoquqi.github.io/blog/2015/06/28/ceph-performance-optimization-summary/" rel="nofollow">http://xiaoquqi.github.io/blog/2015/06/28/ceph-performance-optimization-summary/</a></p> 
<p>最近一直在忙着搞Ceph存储的优化和测试，看了各种资料，但是好像没有一篇文章把其中的方法论交代清楚，所以呢想在这里进行一下总结，很多内容并不是我原创，只是做一个总结。如果其中有任何的问题，欢迎各位喷我，以便我提高。</p> 
<h3 id="优化方法论">优化方法论</h3> 
<p>做任何事情还是要有个方法论的，“授人以鱼不如授人以渔”的道理吧，方法通了，所有的问题就有了解决的途径。通过对公开资料的分析进行总结，对分布式存储系统的优化离不开以下几点：</p> 
<h4 id="1-硬件层面">1. 硬件层面</h4> 
<ul><li>硬件规划</li><li>SSD选择</li><li>BIOS设置</li></ul> 
<h4 id="2-软件层面">2. 软件层面</h4> 
<ul><li>Linux OS</li><li>Ceph Configurations</li><li>PG Number调整</li><li>CRUSH Map</li><li>其他因素</li></ul> 
 
<h3 id="硬件优化">硬件优化</h3> 
<h4 id="1-硬件规划">1. 硬件规划</h4> 
<ul><li>Processor</li></ul> 
<p>ceph-osd进程在运行过程中会消耗CPU资源，所以一般会为每一个ceph-osd进程绑定一个CPU核上。当然如果你使用EC方式，可能需要更多的CPU资源。</p> 
<p>ceph-mon进程并不十分消耗CPU资源，所以不必为ceph-mon进程预留过多的CPU资源。</p> 
<p>ceph-msd也是非常消耗CPU资源的，所以需要提供更多的CPU资源。</p> 
<ul><li>内存</li></ul> 
<p>ceph-mon和ceph-mds需要2G内存，每个ceph-osd进程需要1G内存，当然2G更好。</p> 
<ul><li>网络规划</li></ul> 
<p>万兆网络现在基本上是跑Ceph必备的，网络规划上，也尽量考虑分离cilent和cluster网络。</p> 
<h4 id="2-ssd选择">2. SSD选择</h4> 
<p>硬件的选择也直接决定了Ceph集群的性能，从成本考虑，一般选择SATA SSD作为Journal，<a href="http://www.intel.com/content/www/us/en/solid-state-drives/solid-state-drives-dc-s3500-series.html" rel="nofollow">Intel® SSD DC S3500 Series</a>基本是目前看到的方案中的首选。400G的规格4K随机写可以达到11000 IOPS。如果在预算足够的情况下，推荐使用PCIE SSD，性能会得到进一步提升，但是由于Journal在向数据盘写入数据时Block后续请求，所以Journal的加入并未呈现出想象中的性能提升，但是的确会对Latency有很大的改善。</p> 
<p>如何确定你的SSD是否适合作为SSD Journal，可以参考SÉBASTIEN HAN的<a href="http://www.sebastien-han.fr/blog/2014/10/10/ceph-how-to-test-if-your-ssd-is-suitable-as-a-journal-device/" rel="nofollow">Ceph: How to Test if Your SSD Is Suitable as a Journal Device?</a>，这里面他也列出了常见的SSD的测试结果，从结果来看SATA SSD中，Intel S3500性能表现最好。</p> 
<h4 id="3-bios设置">3. BIOS设置</h4> 
<ul><li>Hyper-Threading(HT)</li></ul> 
<p>基本做云平台的，VT和HT打开都是必须的，超线程技术(HT)就是利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。</p> 
<ul><li>关闭节能</li></ul> 
<p>关闭节能后，对性能还是有所提升的，所以坚决调整成性能型(Performance)。当然也可以在操作系统级别进行调整，详细的调整过程请参考<a href="http://www.servernoobs.com/avoiding-cpu-speed-scaling-in-modern-linux-distributions-running-cpu-at-full-speed-tips/" rel="nofollow">链接</a>，但是不知道是不是由于BIOS已经调整的缘故，所以在CentOS 6.6上并没有发现相关的设置。</p> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-keyword">for</span> CPUFREQ <span class="hljs-keyword">in</span> /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; <span class="hljs-keyword">do</span> [ <span class="hljs-operator">-f</span> <span class="hljs-variable">$CPUFREQ</span> ] || <span class="hljs-keyword">continue</span>; <span class="hljs-built_in">echo</span> -n performance &gt; <span class="hljs-variable">$CPUFREQ</span>; <span class="hljs-keyword">done</span></code></pre> 
<ul><li><a href="http://www.ibm.com/developerworks/cn/linux/l-numa/" rel="nofollow">NUMA</a></li></ul> 
<p>简单来说，NUMA思路就是将内存和CPU分割为多个区域，每个区域叫做NODE,然后将NODE高速互联。 node内cpu与内存访问速度快于访问其他node的内存，<a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2013-December/036211.html" rel="nofollow">NUMA可能会在某些情况下影响ceph-osd</a>。解决的方案，一种是通过BIOS关闭NUMA，另外一种就是通过cgroup将ceph-osd进程与某一个CPU Core以及同一NODE下的内存进行绑定。但是第二种看起来更麻烦，所以一般部署的时候可以在系统层面关闭NUMA。CentOS系统下，通过修改/etc/grub.conf文件，添加numa=off来关闭NUMA。</p> 
<pre class="prettyprint"><code class=" hljs avrasm">kernel /vmlinuz-<span class="hljs-number">2.6</span><span class="hljs-number">.32</span>-<span class="hljs-number">504.12</span><span class="hljs-number">.2</span><span class="hljs-preprocessor">.el</span>6<span class="hljs-preprocessor">.x</span>86_64 ro root=UUID=<span class="hljs-number">870</span>d47f8-<span class="hljs-number">0357</span>-<span class="hljs-number">4</span>a32-<span class="hljs-number">909</span>f-<span class="hljs-number">74173</span>a9f0633 rd_NO_LUKS rd_NO_LVM LANG=en_US<span class="hljs-preprocessor">.UTF</span>-<span class="hljs-number">8</span> rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM   biosdevname=<span class="hljs-number">0</span> numa=off</code></pre> 
<h3 id="软件优化">软件优化</h3> 
<h4 id="1-linux-os">1. Linux OS</h4> 
<ul><li>Kernel pid max</li></ul> 
<pre class="prettyprint"><code class=" hljs ruby">echo <span class="hljs-number">4194303</span> &gt; <span class="hljs-regexp">/proc/sys</span><span class="hljs-regexp">/kernel/pid</span>_max</code></pre> 
<ul><li>Jumbo frames, 交换机端需要支持该功能，系统网卡设置才有效果</li></ul> 
<pre class="prettyprint"><code class=" hljs ">ifconfig eth0 mtu 9000</code></pre> 
<p>永久设置</p> 
<pre class="prettyprint"><code class=" hljs lasso">echo <span class="hljs-string">"MTU=9000"</span> <span class="hljs-subst">|</span> tee <span class="hljs-attribute">-a</span> /etc/sysconfig/network<span class="hljs-attribute">-script</span>/ifcfg<span class="hljs-attribute">-eth0</span>
/etc/init<span class="hljs-built_in">.</span>d/networking restart</code></pre> 
<ul><li>read_ahead, 通过数据预读并且记载到随机访问内存方式提高磁盘读操作，查看默认值</li></ul> 
<pre class="prettyprint"><code class=" hljs bash">cat /sys/block/sda/queue/<span class="hljs-built_in">read</span>_ahead_kb</code></pre> 
<p>根据一些Ceph的公开分享，8192是比较理想的值</p> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">"8192"</span> &gt; /sys/block/sda/queue/<span class="hljs-built_in">read</span>_ahead_kb</code></pre> 
<ul><li>swappiness, 主要控制系统对swap的使用，这个参数的调整最先见于UnitedStack公开的文档中，猜测调整的原因主要是使用swap会影响系统的性能。</li></ul> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">"vm.swappiness = 0"</span> | tee <span class="hljs-operator">-a</span> /etc/sysctl.conf</code></pre> 
<ul><li>I/O Scheduler，关于I/O Scheculder的调整网上已经有很多资料，这里不再赘述，简单说SSD要用noop，SATA/SAS使用deadline。</li></ul> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">"deadline"</span> &gt; /sys/block/sd[x]/queue/scheduler
<span class="hljs-built_in">echo</span> <span class="hljs-string">"noop"</span> &gt; /sys/block/sd[x]/queue/scheduler</code></pre> 
<ul><li>cgroup</li></ul> 
<p>这方面的文章好像比较少，昨天在和Ceph社区交流过程中，Jan Schermer说准备把生产环境中的一些脚本贡献出来，但是暂时还没有，他同时也列举了一些使用cgroup进行隔离的<a href="https://www.mail-archive.com/ceph-users@lists.ceph.com/msg21111.html" rel="nofollow">原因</a>。</p> 
<blockquote> 
 <ul><li>不在process和thread在不同的core上移动(更好的缓存利用)</li><li>减少NUMA的影响</li><li>网络和存储控制器影响 - 较小</li><li>通过限制cpuset来限制Linux调度域(不确定是不是重要但是是最佳实践)</li><li>如果开启了HT，可能会造成OSD在thread1上，KVM在thread2上，并且是同一个core。Core的延迟和性能取决于其他一个线程做什么。</li></ul> 
</blockquote> 
<p>这一点具体实现待补充！！！</p> 
<h4 id="2-ceph-configurations">2. Ceph Configurations</h4> 
<h5 id="global">[global]</h5> 
<h3 id="参数名-描述-默认值-建议值-public-network-客户端访问网络-192168100024-cluster-network-集群网络-1921681024-max-open-files-如果设置了该选项ceph会设置系统的max-open-fds-0-131072"> 
 </h3><table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>public network</td><td>客户端访问网络</td><td></td><td>192.168.100.0/24</td></tr><tr><td>cluster network</td><td>集群网络</td><td></td><td>192.168.1.0/24</td></tr><tr><td>max open files</td><td>如果设置了该选项，Ceph会设置系统的max open fds</td><td>0</td><td>131072</td></tr></tbody></table>  
<ul><li>查看系统最大文件打开数可以使用命令</li></ul> 
<pre class="prettyprint"><code class=" hljs mel">    cat /<span class="hljs-keyword">proc</span>/sys/fs/<span class="hljs-keyword">file</span>-<span class="hljs-keyword">max</span></code></pre> 
<hr> 
<h5 id="osd-filestore">[osd] - filestore</h5> 
<h3 id="参数名-描述-默认值-建议值-filestore-xattr-use-omap-为xattrs使用object-mapext4文件系统时使用xfs或者btrfs也可以使用-false-true-filestore-max-sync-interval-从日志到数据盘最大同步间隔seconds-5-15-filestore-min-sync-interval-从日志到数据盘最小同步间隔seconds-01-10-filestore-queue-max-ops-数据盘最大接受的操作数-500-25000-filestore-queue-max-bytes-数据盘一次操作最大字节数bytes-100-20-10485760-filestore-queue-committing-max-ops-数据盘能够commit的操作数-500-5000-filestore-queue-committing-max-bytes-数据盘能够commit的最大字节数bytes-100-20-10485760000-filestore-op-threads-并发文件系统操作数-2-32"> 
 </h3><table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>filestore xattr use omap</td><td>为XATTRS使用object map，EXT4文件系统时使用，XFS或者btrfs也可以使用</td><td>false</td><td>true</td></tr><tr><td>filestore max sync interval</td><td>从日志到数据盘最大同步间隔(seconds)</td><td>5</td><td>15</td></tr><tr><td>filestore min sync interval</td><td>从日志到数据盘最小同步间隔(seconds)</td><td>0.1</td><td>10</td></tr><tr><td>filestore queue max ops</td><td>数据盘最大接受的操作数</td><td>500</td><td>25000</td></tr><tr><td>filestore queue max bytes</td><td>数据盘一次操作最大字节数(bytes)</td><td>100 &lt;&lt; 20</td><td>10485760</td></tr><tr><td>filestore queue committing max ops</td><td>数据盘能够commit的操作数</td><td>500</td><td>5000</td></tr><tr><td>filestore queue committing max bytes</td><td>数据盘能够commit的最大字节数(bytes)</td><td>100 &lt;&lt; 20</td><td>10485760000</td></tr><tr><td>filestore op threads</td><td>并发文件系统操作数</td><td>2</td><td>32</td></tr></tbody></table>  
<ul><li>调整omap的原因主要是EXT4文件系统默认仅有4K</li><li>filestore queue相关的参数对于性能影响很小，参数调整不会对性能优化有本质上提升</li></ul> 
<hr> 
<h5 id="osd-journal">[osd] - journal</h5> 
<h3 id="参数名-描述-默认值-建议值-osd-journal-size-osd日志大小mb-5120-20000-journal-max-write-bytes-journal一次性写入的最大字节数bytes-10-20-1073714824-journal-max-write-entries-journal一次性写入的最大记录数-100-10000-journal-queue-max-ops-journal一次性最大在队列中的操作数-500-50000-journal-queue-max-bytes-journal一次性最大在队列中的字节数bytes-10-20-10485760000"> 
 </h3><table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>osd journal size</td><td>OSD日志大小(MB)</td><td>5120</td><td>20000</td></tr><tr><td>journal max write bytes</td><td>journal一次性写入的最大字节数(bytes)</td><td>10 &lt;&lt; 20</td><td>1073714824</td></tr><tr><td>journal max write entries</td><td>journal一次性写入的最大记录数</td><td>100</td><td>10000</td></tr><tr><td>journal queue max ops</td><td>journal一次性最大在队列中的操作数</td><td>500</td><td>50000</td></tr><tr><td>journal queue max bytes</td><td>journal一次性最大在队列中的字节数(bytes)</td><td>10 &lt;&lt; 20</td><td>10485760000</td></tr></tbody></table>  
<ul><li>Ceph OSD Daemon stops writes and synchronizes the journal with the filesystem, allowing Ceph OSD Daemons to trim operations from the journal and reuse the space.</li><li>上面这段话的意思就是，Ceph OSD进程在往数据盘上刷数据的过程中，是停止写操作的。</li></ul> 
<hr> 
<h5 id="osd-osd-config-tuning">[osd] - osd config tuning</h5> 
<h3 id="参数名-描述-默认值-建议值-osd-max-write-size-osd一次可写入的最大值mb-90-512-osd-client-message-size-cap-客户端允许在内存中的最大数据bytes-524288000-2147483648-osd-deep-scrub-stride-在deep-scrub时候允许读取的字节数bytes-524288-131072-osd-op-threads-osd进程操作的线程数-2-8-osd-disk-threads-osd密集型操作例如恢复和scrubbing时的线程-1-4-osd-map-cache-size-保留osd-map的缓存mb-500-1024-osd-map-cache-bl-size-osd进程在内存中的osd-map缓存mb-50-128-osd-mount-options-xfs-ceph-osd-xfs-mount选项-rwnoatimeinode64-rwnoexecnodevnoatimenodiratimenobarrier"> 
 </h3><table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>osd max write size</td><td>OSD一次可写入的最大值(MB)</td><td>90</td><td>512</td></tr><tr><td>osd client message size cap</td><td>客户端允许在内存中的最大数据(bytes)</td><td>524288000</td><td>2147483648</td></tr><tr><td>osd deep scrub stride</td><td>在Deep Scrub时候允许读取的字节数(bytes)</td><td>524288</td><td>131072</td></tr><tr><td>osd op threads</td><td>OSD进程操作的线程数</td><td>2</td><td>8</td></tr><tr><td>osd disk threads</td><td>OSD密集型操作例如恢复和Scrubbing时的线程</td><td>1</td><td>4</td></tr><tr><td>osd map cache size</td><td>保留OSD Map的缓存(MB)</td><td>500</td><td>1024</td></tr><tr><td>osd map cache bl size</td><td>OSD进程在内存中的OSD Map缓存(MB)</td><td>50</td><td>128</td></tr><tr><td>osd mount options xfs</td><td>Ceph OSD xfs Mount选项</td><td>rw,noatime,inode64</td><td>rw,noexec,nodev,noatime,nodiratime,nobarrier</td></tr></tbody></table>  
<ul><li>增加osd op threads和disk threads会带来额外的CPU开销</li></ul> 
<hr> 
<h5 id="osd-recovery-tuning">[osd] - recovery tuning</h5> 
<table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>osd recovery op priority</td><td>恢复操作优先级，取值1-63，值越高占用资源越高</td><td>10</td><td>4</td></tr><tr><td>osd recovery max active</td><td>同一时间内活跃的恢复请求数</td><td>15</td><td>10</td></tr><tr><td>osd max backfills</td><td>一个OSD允许的最大backfills数</td><td>10</td><td>4</td></tr></tbody></table> 
<h5 id="osd-client-tuning">[osd] - client tuning</h5> 
<table><thead><tr><th>参数名</th><th>描述</th><th>默认值</th><th>建议值</th></tr></thead><tbody><tr><td>rbd cache</td><td>RBD缓存</td><td>true</td><td>true</td></tr><tr><td>rbd cache size</td><td>RBD缓存大小(bytes)</td><td>33554432</td><td>268435456</td></tr><tr><td>rbd cache max dirty</td><td>缓存为write-back时允许的最大dirty字节数(bytes)，如果为0，使用write-through</td><td>25165824</td><td>134217728</td></tr><tr><td>rbd cache max dirty age</td><td>在被刷新到存储盘前dirty数据存在缓存的时间(seconds)</td><td>1</td><td>5</td></tr></tbody></table> 
<h5 id="关闭debug">关闭Debug</h5> 
<h4 id="3-pg-number">3. PG Number</h4> 
<p>PG和PGP数量一定要根据OSD的数量进行调整，计算公式如下，但是最后算出的结果一定要接近或者等于一个2的指数。</p> 
<pre><code>Total PGs = (Total_number_of_OSD * 100) / max_replication_count
</code></pre> 
<p>例如15个OSD，副本数为3的情况下，根据公式计算的结果应该为500，最接近512，所以需要设定该pool(volumes)的pg_num和pgp_num都为512.</p> 
<pre class="prettyprint"><code class=" hljs bash">ceph osd pool <span class="hljs-keyword">set</span> volumes pg_num <span class="hljs-number">512</span>
ceph osd pool <span class="hljs-keyword">set</span> volumes pgp_num <span class="hljs-number">512</span></code></pre> 
<h4 id="4-crush-map">4. CRUSH Map</h4> 
<p>CRUSH是一个非常灵活的方式，CRUSH MAP的调整取决于部署的具体环境，这个可能需要根据具体情况进行分析，这里面就不再赘述了。</p> 
<h4 id="5-其他因素的影响">5. 其他因素的影响</h4> 
<p>在今年的(2015年)的Ceph Day上，海云捷迅在调优过程中分享过一个由于在集群中存在一个性能不好的磁盘，导致整个集群性能下降的case。通过osd perf可以提供磁盘latency的状况，同时在运维过程中也可以作为监控的一个重要指标，很明显在下面的例子中，OSD 8的磁盘延时较长，所以需要考虑将该OSD剔除出集群：</p> 
<pre class="prettyprint"><code class=" hljs ">ceph osd perf</code></pre> 
<pre><code>osd fs_commit_latency(ms) fs_apply_latency(ms)
  0                    14                   17
  1                    14                   16
  2                    10                   11
  3                     4                    5
  4                    13                   15
  5                    17                   20
  6                    15                   18
  7                    14                   16
  8                   299                  329
</code></pre> 
<h3 id="cephconf">ceph.conf</h3> 
<pre class="prettyprint"><code class=" hljs mel">[<span class="hljs-keyword">global</span>]
fsid = <span class="hljs-number">059</span>f27e8-a23f-<span class="hljs-number">4587</span>-<span class="hljs-number">9033</span>-<span class="hljs-number">3e3679</span>d03b31
mon_host = <span class="hljs-number">10.10</span><span class="hljs-number">.20</span><span class="hljs-number">.102</span>, <span class="hljs-number">10.10</span><span class="hljs-number">.20</span><span class="hljs-number">.101</span>, <span class="hljs-number">10.10</span><span class="hljs-number">.20</span><span class="hljs-number">.100</span>
auth <span class="hljs-keyword">cluster</span> required = cephx
auth service required = cephx
auth client required = cephx
osd pool <span class="hljs-keyword">default</span> <span class="hljs-keyword">size</span> = <span class="hljs-number">3</span>
osd pool <span class="hljs-keyword">default</span> <span class="hljs-keyword">min</span> <span class="hljs-keyword">size</span> = <span class="hljs-number">1</span>

public network = <span class="hljs-number">10.10</span><span class="hljs-number">.20</span><span class="hljs-number">.0</span>/<span class="hljs-number">24</span>
<span class="hljs-keyword">cluster</span> network = <span class="hljs-number">10.10</span><span class="hljs-number">.20</span><span class="hljs-number">.0</span>/<span class="hljs-number">24</span>

<span class="hljs-keyword">max</span> open files = <span class="hljs-number">131072</span>

[mon]
mon data = /var/lib/ceph/mon/ceph-<span class="hljs-variable">$id</span>

[osd]
osd data = /var/lib/ceph/osd/ceph-<span class="hljs-variable">$id</span>
osd journal <span class="hljs-keyword">size</span> = <span class="hljs-number">20000</span>
osd mkfs type = xfs
osd mkfs options xfs = -f

filestore xattr use omap = true
filestore <span class="hljs-keyword">min</span> sync interval = <span class="hljs-number">10</span>
filestore <span class="hljs-keyword">max</span> sync interval = <span class="hljs-number">15</span>
filestore queue <span class="hljs-keyword">max</span> ops = <span class="hljs-number">25000</span>
filestore queue <span class="hljs-keyword">max</span> bytes = <span class="hljs-number">10485760</span>
filestore queue committing <span class="hljs-keyword">max</span> ops = <span class="hljs-number">5000</span>
filestore queue committing <span class="hljs-keyword">max</span> bytes = <span class="hljs-number">10485760000</span>

journal <span class="hljs-keyword">max</span> write bytes = <span class="hljs-number">1073714824</span>
journal <span class="hljs-keyword">max</span> write entries = <span class="hljs-number">10000</span>
journal queue <span class="hljs-keyword">max</span> ops = <span class="hljs-number">50000</span>
journal queue <span class="hljs-keyword">max</span> bytes = <span class="hljs-number">10485760000</span>

osd <span class="hljs-keyword">max</span> write <span class="hljs-keyword">size</span> = <span class="hljs-number">512</span>
osd client message <span class="hljs-keyword">size</span> cap = <span class="hljs-number">2147483648</span>
osd deep scrub stride = <span class="hljs-number">131072</span>
osd op threads = <span class="hljs-number">8</span>
osd disk threads = <span class="hljs-number">4</span>
osd map cache <span class="hljs-keyword">size</span> = <span class="hljs-number">1024</span>
osd map cache bl <span class="hljs-keyword">size</span> = <span class="hljs-number">128</span>
osd mount options xfs = <span class="hljs-string">"rw,noexec,nodev,noatime,nodiratime,nobarrier"</span>
osd recovery op priority = <span class="hljs-number">4</span>
osd recovery <span class="hljs-keyword">max</span> active = <span class="hljs-number">10</span>
osd <span class="hljs-keyword">max</span> backfills = <span class="hljs-number">4</span>

[client]
rbd cache = true
rbd cache <span class="hljs-keyword">size</span> = <span class="hljs-number">268435456</span>
rbd cache <span class="hljs-keyword">max</span> dirty = <span class="hljs-number">134217728</span>
rbd cache <span class="hljs-keyword">max</span> dirty age = <span class="hljs-number">5</span></code></pre> 
<h3 id="总结">总结</h3> 
<p>优化是一个长期迭代的过程，所有的方法都是别人的，只有在实践过程中才能发现自己的，本篇文章仅仅是一个开始，欢迎各位积极补充，共同完成一篇具有指导性的文章。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ea543de7a233d2adfcf0c5535dacf727/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">NWERC2013题解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6e5340efb830315fcd9ffea27823adf5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">快乐之道：游戏设计的黄金法则</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>