<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ElasticSearch相关内容 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ElasticSearch相关内容" />
<meta property="og:description" content="用途：数据搜索、存储和分析引擎
地理位置搜索、前缀搜索
一个索引就相当于一个 table
索引三结构：aliases、mappings、settings
node 角色 只有 data.master = true（候选节点） 属性的节点才能参与 master 的选举
1）、master：集群中只有一个master节点，一般只负责分片负载均衡以及创建和删除索引，属性是 data.master = true，节点不要设置 node.data ＝ true ，避免存储数据，加大节点压力
2）、coordinating：协调节点，属性：data.master = false 和 data.data = false，只负责分片的负载均衡
3）、数据节点：做数据的存储和查询等，属性：data.master = false 和 data.data = true
4）、voting：投票节点，属性：Node.voting_only = true，仅投票节点，即使配置了data.master = true，也不会参选, 但是仍然可以作为数据节点
倒排索引：基于 term（分词）查找 doc（文档）
正排索引：基于 doc（文档）查找 term（分词），doc_values
TF: term 在每个 doc 中出现的次数（频率），频率越高相关度越高
IDF: term 在整个索引中出现的次数（频率），频率越高相关度越低
可以使用 painless 脚本处理逻辑，类似于 redis 使用 lua 脚本，使用脚本时尽量使用变量方式，这样可以加快脚本执行速度（脚本会在第一次执行后编译好，后序不需要编译了，只需要将变量的值通过参数替换即可）
分词器：ik 中文分词器，分析器：ik_max_word（默认，细粒度）、ik_smart（粗粒度）
text：应用于全文检索，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个个词项，不能用于排序聚合（排序聚合时text内容会加载到堆内存中，占用内存较高）
keyword：text 类型默认都会同时生成 keyword 类型，专门用于聚合和排序，只能通过精确值（exact value）搜索到，Id应该用keyword" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/35fb7033da475117133a582e77ff2a85/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-01T09:30:19+08:00" />
<meta property="article:modified_time" content="2021-03-01T09:30:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ElasticSearch相关内容</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>用途：数据搜索、存储和分析引擎</p> 
<p>地理位置搜索、前缀搜索</p> 
<p>一个索引就相当于一个 table<br> 索引三结构：<span style="color:#f33b45;">aliases、mappings、settings</span></p> 
<h4>node 角色</h4> 
<p>只有 data.master = true（候选节点） 属性的节点才能参与 master 的选举<br> 1）、master：集群中只有一个master节点，一般只负责分片负载均衡以及创建和删除索引，属性是 data.master = true，节点不要设置 node.data ＝ true ，避免存储数据，加大节点压力<br> 2）、coordinating：协调节点，属性：data.master = false 和 data.data = false，只负责分片的负载均衡<br> 3）、数据节点：做数据的存储和查询等，属性：data.master = false 和 data.data = true<br> 4）、voting：投票节点，属性：Node.voting_only = true，仅投票节点，即使配置了data.master = true，也不会参选, 但是仍然可以作为数据节点</p> 
<p><strong>倒排索引</strong>：基于 term（分词）查找 doc（文档）</p> 
<p><strong>正排索引</strong>：基于 doc（文档）查找 term（分词），doc_values</p> 
<p><strong>TF</strong>: term 在每个 doc 中出现的次数（频率），频率越高相关度越高</p> 
<p><strong>IDF</strong>: term 在整个索引中出现的次数（频率），频率越高相关度越低</p> 
<p>可以使用 <span style="color:#f33b45;">painless </span>脚本处理逻辑，类似于 redis 使用 lua 脚本，使用脚本时尽量使用变量方式，这样可以加快脚本执行速度（脚本会在第一次执行后编译好，后序不需要编译了，只需要将变量的值通过参数替换即可）</p> 
<p>分词器：<span style="color:#f33b45;">ik 中文分词器</span>，分析器：ik_max_word（默认，细粒度）、ik_smart（粗粒度）</p> 
<p><span style="color:#f33b45;">text</span>：应用于全文检索，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个个词项，不能用于排序聚合（排序聚合时text内容会加载到堆内存中，占用内存较高）</p> 
<p><span style="color:#f33b45;">keyword</span>：text 类型默认都会同时生成 keyword 类型，专门用于聚合和排序，只能通过精确值（exact value）搜索到，Id应该用keyword</p> 
<p>在同一字段中同时具有全文本（text）和关键字（keyword）版本会很有用：一个用于全文本搜索（text），另一个用于聚合和排序（keyword）</p> 
<p>es 通过版本号乐观锁来实现并发修改数据的</p> 
<p>deep_page_search：深度分页查询使用 scroll 来解决 或者避免这种分页查询</p> 
<p>filter ：查询到一定次数时会进行缓存，filter 时不会计算 score</p> 
<h4>Highlight高亮查询</h4> 
<p>1）、unified highlighter：默认的高亮方式，使用Lucene的实现方式<br> 2）、plain highlighter：性能较高，消耗少量内存，性价比高<br> 3）、fast vactor highlighter 适合字段较大，较复杂的查询情况<br> 自定义标签<br> 1）pre_tag：起始标签，如&lt;b&gt;<br> 2）    post_tag：结束标签，如&lt;/b&gt;<br> 注意：每个高亮字段都需要对应一个查询</p> 
<h4>Suggest搜索推荐（目前使用 completion suggester（支持中文））</h4> 
<p>suggest：term suggester、phrase suggester、completion suggester、context suggester<br> completion suggester：基于内存（内存占用高），性能很高，自动补全，自动完成，支持三种查询【前缀查询（prefix）/模糊查询（fuzzy）/正则表达式查询（regex）】</p> 
<h4>地理位置搜索 （疫情地图）</h4> 
<p>geo_point：地理位置类型，经纬度坐标<br> 1）latitude：维度  缩写：lat<br> 2）longitude：经度  缩写：lon<br> Geo-bounding box query：两个点确定一个矩形，搜索中间的点<br> 1）top_left：矩形左上点坐标<br> 2）bottom_right：矩形右上角表</p> 
<p>尽量不要使用 fielddata 来做字段的聚合，因为 fielddata 会导致索引数据在堆内存中创建，占用大量的堆内存</p> 
<p>rollover index：防止索引过大影响性能，当索引（索引必须指定别名）达到一定条件时自动创建新的索引，原有索引的别名会绑定到新的索引上去</p> 
<h4>master 选举过程</h4> 
<p>1）、master 选举，可能会产生脑裂，通过 discovery.zen.minimum_master_nodes = N/2 + 1（最小投票节点数）数量来决定当选 master，解决脑裂问题<br> 2）、Replica 容错，新的master或者原有的master会将丢失的Primary对应的某个副本提升为Primary<br> 3）、Master节点会尝试重启故障机<br> 4）、数据同步，Master会将宕机期间丢失的数据同步到重启机器对应的分片上去</p> 
<h4><br> 索引压缩</h4> 
<p>实际上是压缩的分片，并非在原有索引上压缩，而是生成了一个新的索引，由于使用了hash路由算法以及索引不可变的特性，target index 分片数量必须为source index的约数。比如source index p shard：12,那么target index p shard只能是6 4 3 2 1，如果比如source index p shard是质数，那target index p shard只能是1<br> 工作原理和过程：<br> 1）、创建一个新的目标索引，其定义与源索引相同，但主碎片数量较少。<br> 2）、将段从源索引硬链接到目标索引。如果文件系统不支持硬链接，则将所有segment file都复制到新索引中，复制过程很耗时。<br> 3）、shard recovery操作，恢复目标索引</p> 
<h4><br> 索引写入原理</h4> 
<p>1）、索引先写入 buffer 中，同时将索引写入 translog 文件中（防止数据丢失）此时索引无法访问<br> 2）、buffer 中的索引默认每隔 1s refresh 写入 index segment file（段文件） 文件系统缓存中（os buffer cache（pageCache），清空buffer数据，此时打开搜索限制，索引才可以访问<br> 3）、每隔一定时间(默认30分钟), 或者当translog文件达到一定大小时, 发生flush操作, 并执行一次全量提交<br>  3.1）将此时内存buffer(缓冲区)中的所有数据写入一个新的segment, 并commit到文件系统的cache中;<br>  3.2）打开这个新的segment, 供搜索使用;<br>  3.3）清空当前的内存buffer(缓冲区);<br>  3.4）将translog文件中的所有segment通过fsync强制刷到磁盘上;<br>  3.5）将此次写入磁盘的所有segment记录到commit point中, 并写入磁盘;<br>  3.6）删除当前translog, 创建新的translog接收下一波创建请求</p> 
<p><strong><span style="color:#f33b45;">translog：</span></strong>防止数据丢失，存储了上一次flush(即上一个commit point)到当前时间的所有数据的变更记录. —— 即translog中存储的是还没有被刷到磁盘的所有最新变更记录</p> 
<p><strong><span style="color:#f33b45;">commit point：</span></strong>做恢复数据，记录成功写入磁盘的所有 segment。ES发生故障, 或重启ES时, 将根据磁盘中的commit point去加载已经写入磁盘的segment, 并重做translog文件中的所有操作, 从而保证数据的一致性</p> 
<h4><strong>index segment file merge过程</strong></h4> 
<p>1）、选择一些相似大小的 segment merge 成一个新的 segment<br> 2）、执行 flush 操作，将新的 segment 刷新到磁盘持久化<br> 3）、更新commit文件: 写一个新的commit point, 包括了新的segment, 并删除旧的segment<br> 4）、打开新的segment, 完成搜索请求的转移<br> 5）、删除旧的小segment</p> 
<h4><br> 日志收集分析</h4> 
<p>fileBeat  -&gt; kafka -&gt; logstash  -&gt; elasticSearch -&gt; kibana</p> 
<p>fileBeat ：日志收集</p> 
<p>logstash：日志进行filter（内容格式处理） 、output 到 elasticSearch</p> 
<p>elasticSearch：日志的存储</p> 
<p>kibana：日志的 dasboard 展示</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/188c8a1a19a490374223585f96c3f642/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">1103 Integer Factorization (30 分)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/878dd83fefebb1961b0c6090f929cefc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">VS 2015用C&#43;&#43;项目生成dll并调用（2021.3.1）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>