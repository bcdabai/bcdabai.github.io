<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka磁盘写满日志清理操作 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Kafka磁盘写满日志清理操作" />
<meta property="og:description" content="最近项目组的kafka集群，老是由于应用端写入kafka topic的消息太多，导致所在的broker节点占满，导致其他的组件接连宕机。
这里和应用端沟通可以删除1天之前的消息来清理磁盘，并且可以调整topic的消息存活时间。
一、调整Topic的消息存活时长删除消息 kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name topicName --alter --add-config retention.ms=86400000 如上调整topic的消息存活时长为为1天，当执行完之后执行查询topic详细信息，可以看到已经发生了修改，并且过一会过期的消息会被删除。
kafka-topics --bootstrap-server localhost:9092 --describe --topic topicName 二、不修改Topic消息存活时长删除消息 1.登录到相应的机器上。
2.找到写满的磁盘，删除掉不需要的业务数据。数据清理原则：
不可直接删除Kafka的数据目录，避免造成不必要的数据丢失。找到占用空间较多或者明确不需要的Topic，选择其中某些Partition，从最早的日志数据开始删除。删除segment及相应地index和timeindex文件。不要清理内置的Topic，例如__consumer_offsets和_schema等。 3.重启磁盘被写满的相应的Broker节点，使日志目录online。
参考：Kafka磁盘写满时如何运维操作_开源大数据平台E-MapReduce-阿里云帮助中心 (aliyun.com)
怎么删除kafka中的数据-火山引擎 (volcengine.com)
三、Kafka消息清理策略 在Kafka中，存在数据过期的机制，称为data expire。如何处理过期数据是根据指定的policy（策略）决定的，而处理过期数据的行为，即为log cleanup。
在Kafka中有以下几种处理过期数据的策略：
log.cleanup.policy=delete（Kafka中所有用户创建的topics，默认均为此策略） 根据数据已保存的时间，进行删除（默认为1周）根据log的max size，进行删除（默认为-1，也就是无限制） log.cleanup.policy=compact（topic __consumer_offsets 默认为此策略） 根据messages中的key，进行删除操作在active segment 被commit 后，会删除掉old duplicate keys无限制的时间与空间的日志保留 自动清理Kafka中的数据可以控制磁盘上数据的大小、删除不需要的数据，同时也减少了对Kafka集群的维护成本。
那Log cleanup 在什么时候发生呢？
首先值得注意的是：log cleanup 在partition segment 上发生更小/更多的segment，也就意味着log cleanup 发生的频率会上升Log cleanup 不应该频繁发生=&gt; 因为它会消耗CPU与内存资源Cleaner的检查会在每15秒进行一次，由log.cleaner.backoff.ms 控制 log.cleanup.policy=delete log.cleanup.policy=delete 的策略，根据数据保留的时间、以及log的max size，对数据进行cleanup。控制数据保留时间以及log max size的参数分别为：
log.retention.hours：指定数据保留的时常（默认为一周，168） 将参数调整到更高的值，也就意味着会占据更多的磁盘空间更小值意味着保存的数据量会更少（假如consumer 宕机超过一周，则数据便会再未处理前即丢失） log." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/16639035f57b466357e4d77394545215/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-24T10:32:24+08:00" />
<meta property="article:modified_time" content="2023-10-24T10:32:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka磁盘写满日志清理操作</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>最近项目组的kafka集群，老是由于应用端写入kafka topic的消息太多，导致所在的broker节点占满，导致其他的组件接连宕机。</p> 
<p>这里和应用端沟通可以删除1天之前的消息来清理磁盘，并且可以调整topic的消息存活时间。</p> 
<h2>一、调整Topic的消息存活时长删除消息</h2> 
<pre><code class="language-bash">kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name topicName --alter --add-config retention.ms=86400000</code></pre> 
<p>如上调整topic的消息存活时长为为1天，当执行完之后执行查询topic详细信息，可以看到已经发生了修改，并且过一会过期的消息会被删除。</p> 
<pre><code class="language-bash">kafka-topics --bootstrap-server localhost:9092 --describe --topic topicName</code></pre> 
<h2>二、不修改Topic消息存活时长删除消息</h2> 
<p>1.登录到相应的机器上。</p> 
<p>2.找到写满的磁盘，删除掉不需要的业务数据。数据清理原则：</p> 
<ul id="ul-bmr-gi9-at4"><li id="li-4q7-4pq-z82">不可直接删除Kafka的数据目录，避免造成不必要的数据丢失。</li><li id="li-w8o-5aw-jqs">找到占用空间较多或者明确不需要的Topic，选择其中某些Partition，从最早的日志数据开始删除。删除segment及相应地index和timeindex文件。不要清理内置的Topic，例如__consumer_offsets和_schema等。</li></ul> 
<p>3.重启磁盘被写满的相应的Broker节点，使日志目录online。</p> 
<p>参考：<a href="https://help.aliyun.com/zh/emr/emr-on-ecs/user-guide/perform-maintenance-operations-when-the-disk-space-of-an-emr-kafka-cluster-is-full" rel="nofollow" title="Kafka磁盘写满时如何运维操作_开源大数据平台E-MapReduce-阿里云帮助中心 (aliyun.com)">Kafka磁盘写满时如何运维操作_开源大数据平台E-MapReduce-阿里云帮助中心 (aliyun.com)</a></p> 
<p><a href="https://www.volcengine.com/theme/748665-Z-7-1" rel="nofollow" title="怎么删除kafka中的数据-火山引擎 (volcengine.com)">怎么删除kafka中的数据-火山引擎 (volcengine.com)</a></p> 
<p></p> 
<h2>三、Kafka消息清理策略</h2> 
<p>在Kafka中，存在数据过期的机制，称为data expire。如何处理过期数据是根据指定的policy（策略）决定的，而处理过期数据的行为，即为log cleanup。</p> 
<p>在Kafka中有以下几种处理过期数据的策略：</p> 
<h4>log.cleanup.policy=delete（Kafka中所有用户创建的topics，默认均为此策略）</h4> 
<ul><li>根据数据已保存的时间，进行删除（默认为1周）</li><li>根据log的max size，进行删除（默认为-1，也就是无限制）</li></ul> 
<h4>log.cleanup.policy=compact（topic __consumer_offsets 默认为此策略）</h4> 
<ul><li>根据messages中的key，进行删除操作</li><li>在active segment 被commit 后，会删除掉old duplicate keys</li><li>无限制的时间与空间的日志保留</li></ul> 
<p>自动清理Kafka中的数据可以控制磁盘上数据的大小、删除不需要的数据，同时也减少了对Kafka集群的维护成本。</p> 
<p>那Log cleanup 在什么时候发生呢？</p> 
<ul><li>首先值得注意的是：log cleanup 在partition segment 上发生</li><li>更小/更多的segment，也就意味着log cleanup 发生的频率会上升</li><li>Log cleanup 不应该频繁发生=&gt; 因为它会消耗CPU与内存资源</li><li>Cleaner的检查会在每15秒进行一次，由log.cleaner.backoff.ms 控制</li></ul> 
<h3><strong>log.cleanup.policy=delete</strong></h3> 
<p>log.cleanup.policy=delete 的策略，根据数据保留的时间、以及log的max size，对数据进行cleanup。控制数据保留时间以及log max size的参数分别为：</p> 
<h4>log.retention.hours：指定数据保留的时常（默认为一周，168）</h4> 
<ul><li>将参数调整到更高的值，也就意味着会占据更多的磁盘空间</li><li>更小值意味着保存的数据量会更少（假如consumer 宕机超过一周，则数据便会再未处理前即丢失）</li></ul> 
<h4>log.retention.bytes：每个partition中保存的最大数据量大小（默认为-1，也就是无限大）</h4> 
<ul><li>再控制log的大小不超过一个阈值时，会比较有用</li></ul> 
<p></p> 
<p>在到达log cleanup 的条件后，cleaner会自动根据时间或是空间的规则进行删除，新数据仍写入active segment：</p> 
<p></p> 
<p class="img-center"><img alt="" height="457" src="https://images2.imgbox.com/d1/ef/XbSEet7V_o.png" width="1200"></p> 
<p></p> 
<p>针对于这个参数，一般有以下两种使用场景，分别为：</p> 
<h4>log保留周期为一周，根据log保留期进行log cleanup：</h4> 
<ul><li>log.retention.hours=168 以及 log.retention.bytes=-1</li></ul> 
<h4>log保留期为无限制，根据log大小进行进行log cleanup：</h4> 
<ul><li>log.retention.hours=17520以及 log.retention.bytes=524288000</li></ul> 
<p>其中第一个场景会更常见。</p> 
<p></p> 
<h3><strong>Log Compaction</strong></h3> 
<p>Log compaction用于确保：在一个partition中，对任意一个key，它所对应的value都是最新的。</p> 
<p>这里举个例子：我们有个topic名为employee-salary，我们希望维护每个employee当前最新的工资情况。</p> 
<p>左边的是compaction前，segments中的数据，右边为compaction 后，segments中的数据，其中有部分key对应的value有更新：</p> 
<p></p> 
<p class="img-center"><img alt="" height="605" src="https://images2.imgbox.com/7f/c3/5coPQMAG_o.png" width="1200"></p> 
<p>  </p> 
<p>可以看到在log compaction后，相对于更新后的key-value message，旧的message被删除。</p> 
<p>Log Compaction 有如下特点：</p> 
<ul><li>messages的顺序仍然是保留的，log compaction 仅移除一些messages，但不会重新对它们进行排序</li><li>一条message的offset是无法改变的（immutable），如果一条message缺失，则offset会直接被跳过</li><li>被删除的records在一段时间内仍然可以被consumers访问到，这段时间由参数delete.retention.ms（默认为24小时）控制</li></ul> 
<p>需要注意的是：Kafka 本身是不会组织用户发送duplicate data的。这些重复数据也仅会在一个segment在被commit 的时候做重复数据删除，所以consumer仍会读取到这部分重复数据（如果客户端有发的话）。</p> 
<p>Log Compaction也会有时失败，compaction thread 可能会crash，所以需要确保给Kafka server 足够的内存用于做这些操作。如果log compaction异常，则需要重启Kafka（此为一个已知的bug）。</p> 
<p>Log Compaction也无法通过API手动触发（至少到现在为止是这样），只能server端自动触发。</p> 
<p>下面是一个 Log Compaction过程的示意图：</p> 
<p></p> 
<p class="img-center"><img alt="" height="690" src="https://images2.imgbox.com/84/7c/mznIM7D3_o.png" width="1200"></p> 
<p></p> 
<p>正在写入的records仍会被写入Active Segment，已经committed segments会自动做compaction。此过程会遍历所有segments中的records，并移除掉所有需要被移除的messages。</p> 
<p>Log compaction由上文提到的log.cleanup.policy=compact进行配置，其中：</p> 
<ul><li>Segment.ms（默认为7天）：在关闭一个active segment前，所需等待的最长时间</li><li>Segment.bytes（默认为1G）：一个segment的最大大小</li><li>Min.compaction .lag.ms（默认为0）：在一个message可以被compact前，所需等待的时间</li><li>Delete.retention.ms（默认为24小时）：在一条message被加上删除标记后，在实际删除前等待的时间</li><li>Min.Cleanable.dirty.ratio（默认为0.5）：若是设置的更高，则会有更高效的清理，但是更少的清理操作触发。若是设置的更低，则清理的效率稍低，但是会有更多的清理操作被触发</li></ul> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/38eaddf0d55d25f7319c39c42ba9c36c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">九联UNT413A-403A-411A-S905L3A-B芯片蓝牙语音免拆卡刷固件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/557fda8045a414dfecbc4c17fa6df375/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Mac安装多个版本Node.js</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>