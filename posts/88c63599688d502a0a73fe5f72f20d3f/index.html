<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文阅读笔记（6）: GNN-快速局部光谱滤波 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文阅读笔记（6）: GNN-快速局部光谱滤波" />
<meta property="og:description" content="实验：
代码论文中有，这里只是解读部分代码： # -*- coding: utf-8 -*- # author: cuihu # time : 2021/4/10 15:07 # task: 本文图神经网络网的使用，详细请看论文 # 《Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering》 import sys sys.path.append(&#34;./lib&#34;) from lib import models, graph, coarsening, utils import numpy as np import matplotlib.pyplot as plt import sklearn.metrics import sklearn.neighbors import matplotlib.pyplot as plt import scipy.sparse import scipy.sparse.linalg import scipy.spatial.distance import numpy as np # step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1 # :建立数据。 d = 100 # Dimensionality." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/88c63599688d502a0a73fe5f72f20d3f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-12T18:28:10+08:00" />
<meta property="article:modified_time" content="2021-04-12T18:28:10+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文阅读笔记（6）: GNN-快速局部光谱滤波</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/4c/7f/93ZMdVxC_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0d/95/7P3kUskD_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ae/af/AYzfh96d_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8e/ba/EpjGaYBq_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ee/18/y7dDM3Cb_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/91/0e/50yFmvCk_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/98/24/6hrBEPx2_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/01/3a/TCPwqQjx_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d4/e5/tWcwDbEd_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b5/63/qc450Ysg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/de/ed/9qbAGBFY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/5a/9d/Lp7ck3DV_o.png" alt="在这里插入图片描述"></p> 
<ul><li>实验：<br> 代码论文中有，这里只是解读部分代码：</li></ul> 
<pre><code class="prism language-cpp"># <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> coding<span class="token operator">:</span> utf<span class="token operator">-</span><span class="token number">8</span> <span class="token operator">-</span><span class="token operator">*</span><span class="token operator">-</span> 
<span class="token macro property"># author: cuihu</span>
<span class="token macro property"># time : 2021/4/10 15:07</span>
<span class="token macro property"># task:  本文图神经网络网的使用，详细请看论文</span>
# 《Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering》

import sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"./lib"</span><span class="token punctuation">)</span>
from lib import models<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> coarsening<span class="token punctuation">,</span> utils
import numpy as np
import matplotlib<span class="token punctuation">.</span>pyplot as plt
import sklearn<span class="token punctuation">.</span>metrics
import sklearn<span class="token punctuation">.</span>neighbors
import matplotlib<span class="token punctuation">.</span>pyplot as plt
import scipy<span class="token punctuation">.</span>sparse
import scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>linalg
import scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance
import numpy as np

<span class="token macro property"># step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1 step 1</span>
# <span class="token operator">:</span>建立数据。

d <span class="token operator">=</span> <span class="token number">100</span>    # Dimensionality<span class="token punctuation">.</span>
n <span class="token operator">=</span> <span class="token number">10000</span>  # Number of samples<span class="token punctuation">.</span>
c <span class="token operator">=</span> <span class="token number">5</span>      # Number of feature communities<span class="token punctuation">.</span>

<span class="token macro property"># Data matrix, structured in communities (feature-wise).</span>
# 一共<span class="token number">3</span>类。
X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>n<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
X <span class="token operator">+</span><span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">linspace</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">repeat</span><span class="token punctuation">(</span>d <span class="token comment">// c)</span>

<span class="token macro property"># Noisy non-linear target.</span>
w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">.02</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span>
t <span class="token operator">=</span> X<span class="token punctuation">.</span><span class="token function">dot</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">.001</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span>
t <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">tanh</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span>
<span class="token macro property"># plt.figure(figsize=(15, 5))</span>
<span class="token macro property"># plt.plot(t, '.')</span>
# # plt<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token macro property"># Classification.</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">ones</span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
y<span class="token punctuation">[</span>t <span class="token operator">&gt;</span> t<span class="token punctuation">.</span><span class="token function">mean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.4</span> <span class="token operator">*</span> t<span class="token punctuation">.</span><span class="token function">std</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
y<span class="token punctuation">[</span>t <span class="token operator">&lt;</span> t<span class="token punctuation">.</span><span class="token function">mean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.4</span> <span class="token operator">*</span> t<span class="token punctuation">.</span><span class="token function">std</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'Class imbalance: '</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token function">unique</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> return_counts<span class="token operator">=</span>True<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
# <span class="token punctuation">[</span><span class="token number">3592</span> <span class="token number">3057</span> <span class="token number">3351</span><span class="token punctuation">]</span>
# 划分数据集：
n_train <span class="token operator">=</span> n <span class="token comment">// 2</span>
n_val <span class="token operator">=</span> n <span class="token comment">// 10</span>

X_train <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token operator">:</span>n_train<span class="token punctuation">]</span>
X_val   <span class="token operator">=</span> X<span class="token punctuation">[</span>n_train<span class="token operator">:</span>n_train<span class="token operator">+</span>n_val<span class="token punctuation">]</span>
X_test  <span class="token operator">=</span> X<span class="token punctuation">[</span>n_train<span class="token operator">+</span>n_val<span class="token operator">:</span><span class="token punctuation">]</span>

y_train <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token operator">:</span>n_train<span class="token punctuation">]</span>
y_val   <span class="token operator">=</span> y<span class="token punctuation">[</span>n_train<span class="token operator">:</span>n_train<span class="token operator">+</span>n_val<span class="token punctuation">]</span>
y_test  <span class="token operator">=</span> y<span class="token punctuation">[</span>n_train<span class="token operator">+</span>n_val<span class="token operator">:</span><span class="token punctuation">]</span>

##### step2 ##### step2 ##### step2 ##### step2 ##### step2 ##### step2
# 根据数据集的特性建立图，也就是相应的邻接矩阵，这里使用的方法像素之间的欧式距离。
def <span class="token function">distance_scipy_spatial</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'euclidean'</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"Compute exact pairwise distances."</span><span class="token string">""</span>
    d <span class="token operator">=</span> scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance<span class="token punctuation">.</span><span class="token function">pdist</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> metric<span class="token punctuation">)</span> # 得到<span class="token number">100</span>x100的距离矩阵。
    d <span class="token operator">=</span> scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance<span class="token punctuation">.</span><span class="token function">squareform</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    <span class="token macro property"># k-NN graph.</span>
    idx <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">argsort</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> # 对列排序，找到前k个最小的节点序列。
    d<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    d <span class="token operator">=</span> d<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> #前k小的距离矩阵。
    <span class="token keyword">return</span> d<span class="token punctuation">,</span> idx

def <span class="token function">adjacency</span><span class="token punctuation">(</span>dist<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"Return the adjacency matrix of a kNN graph."</span><span class="token string">""</span>
    M<span class="token punctuation">,</span> k <span class="token operator">=</span> dist<span class="token punctuation">.</span>shape
    assert M<span class="token punctuation">,</span> k <span class="token operator">==</span> idx<span class="token punctuation">.</span>shape
    assert dist<span class="token punctuation">.</span><span class="token function">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">0</span>

    <span class="token macro property"># Weights. 对距离进行处理。</span>
    sigma2 <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">mean</span><span class="token punctuation">(</span>dist<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token operator">*</span><span class="token number">2</span>
    dist <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">exp</span><span class="token punctuation">(</span><span class="token operator">-</span> dist<span class="token operator">*</span><span class="token operator">*</span><span class="token number">2</span> <span class="token operator">/</span> sigma2<span class="token punctuation">)</span>

    <span class="token macro property"># Weight matrix.</span>
    I <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">arange</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">repeat</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span>  # M X K  一共M个点。
    J <span class="token operator">=</span> idx<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>M<span class="token operator">*</span>k<span class="token punctuation">)</span> # 顶点编号就行排序。
    V <span class="token operator">=</span> dist<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>M<span class="token operator">*</span>k<span class="token punctuation">)</span> # 相应的距离进行排序。
    W <span class="token operator">=</span> scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">coo_matrix</span><span class="token punctuation">(</span><span class="token punctuation">(</span>V<span class="token punctuation">,</span> <span class="token punctuation">(</span>I<span class="token punctuation">,</span> J<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token macro property"># W[I[k], J[k]] = v[k] ，一共M X K 个值，按照这种位置存放。</span>

    <span class="token macro property"># No self-connections.</span>
    W<span class="token punctuation">.</span><span class="token function">setdiag</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> # 对角为<span class="token number">0</span>

    <span class="token macro property"># Non-directed graph.</span>
    bigger <span class="token operator">=</span> W<span class="token punctuation">.</span>T <span class="token operator">&gt;</span> W
    W <span class="token operator">=</span> W <span class="token operator">-</span> W<span class="token punctuation">.</span><span class="token function">multiply</span><span class="token punctuation">(</span>bigger<span class="token punctuation">)</span> <span class="token operator">+</span> W<span class="token punctuation">.</span>T<span class="token punctuation">.</span><span class="token function">multiply</span><span class="token punctuation">(</span>bigger<span class="token punctuation">)</span> # 使矩阵对称。

    assert W<span class="token punctuation">.</span>nnz <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span>
    assert np<span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span>W <span class="token operator">-</span> W<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">mean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1e-10</span>
    assert <span class="token function">type</span><span class="token punctuation">(</span>W<span class="token punctuation">)</span> is scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>csr<span class="token punctuation">.</span>csr_matrix
    <span class="token keyword">return</span> W

# 以上两个函数一个是计算距离并返回最近的k个顶点的编号以及距离的值。
<span class="token macro property"># adjacency 是用来从上一步得到距离和顶点编号来求邻接矩阵的A的。</span>
dist<span class="token punctuation">,</span> idx <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">distance_scipy_spatial</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>T<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'euclidean'</span><span class="token punctuation">)</span>
# 计算特征之间的距离。
A <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">adjacency</span><span class="token punctuation">(</span>dist<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

assert A<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'d = |V| = {}, k|V| &lt; |E| = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> A<span class="token punctuation">.</span>nnz<span class="token punctuation">)</span><span class="token punctuation">)</span> # 返回顶点的数量和邻接矩阵非<span class="token number">0</span>值。
<span class="token macro property"># d = |V| = 100, k|V| &lt; |E| = 1324</span>
<span class="token macro property"># plt.spy(A, markersize=2, color='black')</span>
<span class="token macro property"># plt.show()</span>

### step3 ### step3 ### step3 ### step3 ### step3 ### step3 ### step3 ### step3
# 粗化处理，因为需要进行池化操作，为了实现论文中的方法，需要进行粗化和排序，添加
# 伪节点。
# 粗化函数 coarsen <span class="token operator">:</span>
import numpy as np
import scipy<span class="token punctuation">.</span>sparse

# 粗化的函数。
def <span class="token function">coarsen</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> levels<span class="token punctuation">,</span> self_connections<span class="token operator">=</span>False<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span>"
    Coarsen a graph<span class="token punctuation">,</span> represented by its adjacency matrix A<span class="token punctuation">,</span> at multiple
    levels<span class="token punctuation">.</span>
    <span class="token string">""</span>"
    graphs<span class="token punctuation">,</span> parents <span class="token operator">=</span> <span class="token function">metis</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> levels<span class="token punctuation">)</span> # metis方法进行粗化。
    perms <span class="token operator">=</span> <span class="token function">compute_perm</span><span class="token punctuation">(</span>parents<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> A in <span class="token function">enumerate</span><span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token operator">:</span>
        M<span class="token punctuation">,</span> M <span class="token operator">=</span> A<span class="token punctuation">.</span>shape

        <span class="token keyword">if</span> <span class="token operator">not</span> self_connections<span class="token operator">:</span>
            A <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token function">tocoo</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            A<span class="token punctuation">.</span><span class="token function">setdiag</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> levels<span class="token operator">:</span>
            A <span class="token operator">=</span> <span class="token function">perm_adjacency</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> perms<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

        A <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token function">tocsr</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        A<span class="token punctuation">.</span><span class="token function">eliminate_zeros</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        graphs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A

        Mnew<span class="token punctuation">,</span> Mnew <span class="token operator">=</span> A<span class="token punctuation">.</span>shape
        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'Layer {0}: M_{0} = |V| = {1} nodes ({2} added),'</span>
              <span class="token string">'|E| = {3} edges'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> Mnew<span class="token punctuation">,</span> Mnew<span class="token operator">-</span>M<span class="token punctuation">,</span> A<span class="token punctuation">.</span>nnz<span class="token comment">//2))</span>

    <span class="token keyword">return</span> graphs<span class="token punctuation">,</span> perms<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">if</span> levels <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> None


def <span class="token function">metis</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> levels<span class="token punctuation">,</span> rid<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span>"
    Coarsen a graph multiple times <span class="token keyword">using</span> the METIS algorithm<span class="token punctuation">.</span>

    INPUT
    W<span class="token operator">:</span> symmetric sparse weight <span class="token punctuation">(</span>adjacency<span class="token punctuation">)</span> matrix
    levels<span class="token operator">:</span> the number of coarsened graphs

    OUTPUT
    graph<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">:</span> original graph of size N_1
    graph<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span> coarser graph of size N_2 <span class="token operator">&lt;</span> N_1
    graph<span class="token punctuation">[</span>levels<span class="token punctuation">]</span><span class="token operator">:</span> coarsest graph of Size N_levels <span class="token operator">&lt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">&lt;</span> N_2 <span class="token operator">&lt;</span> N_1
    parents<span class="token punctuation">[</span>i<span class="token punctuation">]</span> is a vector of size N_i with entries ranging from <span class="token number">1</span> to N_<span class="token punctuation">{<!-- --></span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span>
        which indicate the parents in the coarser graph<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
    nd_sz<span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span> is a vector of size N_i that contains the size of the supernode in the graph<span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span>

    NOTE
    <span class="token keyword">if</span> <span class="token string">"graph"</span> is a list of length k<span class="token punctuation">,</span> then <span class="token string">"parents"</span> will be a list of length k<span class="token operator">-</span><span class="token number">1</span>
    <span class="token string">""</span>"

    N<span class="token punctuation">,</span> N <span class="token operator">=</span> W<span class="token punctuation">.</span>shape #邻接矩阵
    <span class="token keyword">if</span> rid is None<span class="token operator">:</span>
        rid <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">permutation</span><span class="token punctuation">(</span><span class="token function">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">)</span>  # 随机打乱N个节点的次序。
    parents <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    degree <span class="token operator">=</span> W<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> W<span class="token punctuation">.</span><span class="token function">diagonal</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    graphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    graphs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>W<span class="token punctuation">)</span>
    <span class="token macro property">#supernode_size = np.ones(N)</span>
    <span class="token macro property">#nd_sz = [supernode_size]</span>
    <span class="token macro property">#count = 0</span>

    <span class="token macro property">#while N &gt; maxsize:</span>
    <span class="token keyword">for</span> _ in <span class="token function">range</span><span class="token punctuation">(</span>levels<span class="token punctuation">)</span><span class="token operator">:</span>

        <span class="token macro property">#count += 1</span>

        <span class="token macro property"># CHOOSE THE WEIGHTS FOR THE PAIRING</span>
        <span class="token macro property"># weights = ones(N,1)       # metis weights</span>
        weights <span class="token operator">=</span> degree            # graclus weights
        <span class="token macro property"># weights = supernode_size  # other possibility</span>
        weights <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token macro property"># PAIR THE VERTICES AND CONSTRUCT THE ROOT VECTOR</span>
        idx_row<span class="token punctuation">,</span> idx_col<span class="token punctuation">,</span> val <span class="token operator">=</span> scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span>W<span class="token punctuation">)</span> # 非零元素的索引和值。
        perm <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">argsort</span><span class="token punctuation">(</span>idx_row<span class="token punctuation">)</span>   #对行索引进行排序。
        rr <span class="token operator">=</span> idx_row<span class="token punctuation">[</span>perm<span class="token punctuation">]</span>
        cc <span class="token operator">=</span> idx_col<span class="token punctuation">[</span>perm<span class="token punctuation">]</span>  # rr cc 就是非零元素的坐标。
        vv <span class="token operator">=</span> val<span class="token punctuation">[</span>perm<span class="token punctuation">]</span>  # 相应的值。
        cluster_id <span class="token operator">=</span> <span class="token function">metis_one_level</span><span class="token punctuation">(</span>rr<span class="token punctuation">,</span>cc<span class="token punctuation">,</span>vv<span class="token punctuation">,</span>rid<span class="token punctuation">,</span>weights<span class="token punctuation">)</span>  # rr is ordered
        parents<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>cluster_id<span class="token punctuation">)</span>

        <span class="token macro property"># COMPUTE THE EDGES WEIGHTS FOR THE NEW GRAPH</span>
        nrr <span class="token operator">=</span> cluster_id<span class="token punctuation">[</span>rr<span class="token punctuation">]</span>   #新的图的rr，cc ，将原来的相应的节点用聚类编号代替。
        ncc <span class="token operator">=</span> cluster_id<span class="token punctuation">[</span>cc<span class="token punctuation">]</span>   #也就是减少了一半。
        nvv <span class="token operator">=</span> vv
        Nnew <span class="token operator">=</span> cluster_id<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token macro property"># CSR is more appropriate: row,val pairs appear multiple times</span>
        W <span class="token operator">=</span> scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">csr_matrix</span><span class="token punctuation">(</span><span class="token punctuation">(</span>nvv<span class="token punctuation">,</span><span class="token punctuation">(</span>nrr<span class="token punctuation">,</span>ncc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>Nnew<span class="token punctuation">,</span>Nnew<span class="token punctuation">)</span><span class="token punctuation">)</span>  #新图的邻接矩阵。
        <span class="token macro property"># W(nrr(k), ncc(k)) = nvv(k)</span>
        W<span class="token punctuation">.</span><span class="token function">eliminate_zeros</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token macro property"># Add new graph to the list of all coarsened graphs</span>
        graphs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>W<span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> N <span class="token operator">=</span> W<span class="token punctuation">.</span>shape

        <span class="token macro property"># COMPUTE THE DEGREE (OMIT OR NOT SELF LOOPS)</span>
        degree <span class="token operator">=</span> W<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        ss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>W<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  #度的列表。
        rid <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">argsort</span><span class="token punctuation">(</span>ss<span class="token punctuation">)</span> # 子图需要排序。

    <span class="token keyword">return</span> graphs<span class="token punctuation">,</span> parents # 粗化的图和每一个图中结点对应的聚类列表。

<span class="token macro property"># Coarsen a graph given by rr,cc,vv.  rr is assumed to be ordered</span>
def <span class="token function">metis_one_level</span><span class="token punctuation">(</span>rr<span class="token punctuation">,</span>cc<span class="token punctuation">,</span>vv<span class="token punctuation">,</span>rid<span class="token punctuation">,</span>weights<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">''</span><span class="token string">'进行一次粗化，返回的是粗化的节点的粗化编号（父节点编号）'</span><span class="token string">''</span>
    nnz <span class="token operator">=</span> rr<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    N <span class="token operator">=</span> rr<span class="token punctuation">[</span>nnz<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>  # rr<span class="token punctuation">[</span>nnz<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> 的值最大行索引，也就是节点数量。

    marked <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">zeros</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token keyword">bool</span><span class="token punctuation">)</span> # 是否聚类过的标记。
    rowstart <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">zeros</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> # 开始位置？？。
    rowlength <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">zeros</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> # 长度。
    cluster_id <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">zeros</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> #聚类选择的点？？

    oldval <span class="token operator">=</span> rr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    count <span class="token operator">=</span> <span class="token number">0</span>
    clustercount <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token macro property">#
    for ii in range(nnz):</span>
        rowlength<span class="token punctuation">[</span>count<span class="token punctuation">]</span> <span class="token operator">=</span> rowlength<span class="token punctuation">[</span>count<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span> #统计N个结点的度也就是长度。
        <span class="token keyword">if</span> rr<span class="token punctuation">[</span>ii<span class="token punctuation">]</span> <span class="token operator">&gt;</span> oldval<span class="token operator">:</span> #判断是否换了结点。
            oldval <span class="token operator">=</span> rr<span class="token punctuation">[</span>ii<span class="token punctuation">]</span>
            rowstart<span class="token punctuation">[</span>count<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> ii #每个节点开始的索引。
            count <span class="token operator">=</span> count <span class="token operator">+</span> <span class="token number">1</span>

    <span class="token keyword">for</span> ii in <span class="token function">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token operator">:</span>
        tid <span class="token operator">=</span> rid<span class="token punctuation">[</span>ii<span class="token punctuation">]</span> # 打乱的N个节点。<span class="token number">0</span> <span class="token operator">-</span> N<span class="token operator">-</span><span class="token number">1</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> marked<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token operator">:</span> #默认都是没有被聚类的。
            wmax <span class="token operator">=</span> <span class="token number">0.0</span> # 最大的权重。
            rs <span class="token operator">=</span> rowstart<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> #边开始的位置。
            marked<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> True
            bestneighbor <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
            <span class="token keyword">for</span> jj in <span class="token function">range</span><span class="token punctuation">(</span>rowlength<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> #行的非零元素的长度。
                nid <span class="token operator">=</span> cc<span class="token punctuation">[</span>rs<span class="token operator">+</span>jj<span class="token punctuation">]</span> # 另一个点的索引。开始的索引<span class="token operator">+</span>长度就是所有的边，用它找出对应的节点的索引。
                # 判断这个节点是否被标记过了。

                # 计算该聚类的点。
                <span class="token keyword">if</span> marked<span class="token punctuation">[</span>nid<span class="token punctuation">]</span><span class="token operator">:</span> # 已经被标记了。
                    tval <span class="token operator">=</span> <span class="token number">0.0</span>
                <span class="token keyword">else</span><span class="token operator">:</span>
                    tval <span class="token operator">=</span> vv<span class="token punctuation">[</span>rs<span class="token operator">+</span>jj<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span><span class="token operator">/</span>weights<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1.0</span><span class="token operator">/</span>weights<span class="token punctuation">[</span>nid<span class="token punctuation">]</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> tval <span class="token operator">&gt;</span> wmax<span class="token operator">:</span>
                    wmax <span class="token operator">=</span> tval
                    bestneighbor <span class="token operator">=</span> nid  # 找出聚类的点。

            cluster_id<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> clustercount # 聚类编号。从<span class="token number">0</span>开始排。

            <span class="token keyword">if</span> bestneighbor <span class="token operator">&gt;</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span>
                cluster_id<span class="token punctuation">[</span>bestneighbor<span class="token punctuation">]</span> <span class="token operator">=</span> clustercount #对应的那个点，也是同样的聚类编号。
                marked<span class="token punctuation">[</span>bestneighbor<span class="token punctuation">]</span> <span class="token operator">=</span> True #并且标记成已聚类。

            clustercount <span class="token operator">+</span><span class="token operator">=</span> <span class="token number">1</span>

    <span class="token keyword">return</span> cluster_id # N个点的聚类编号列表。

graphs<span class="token punctuation">,</span> perm <span class="token operator">=</span> coarsening<span class="token punctuation">.</span><span class="token function">coarsen</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> levels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> self_connections<span class="token operator">=</span>False<span class="token punctuation">)</span>
<span class="token macro property"># plt.spy(graphs[3], markersize=2, color='black')</span>
<span class="token macro property"># plt.show() # 查看粗化的结果。</span>


</code></pre> 
<p>以上是数据预处理和使用部分代码。<br> GNN 部分代码：</p> 
<p>基类：</p> 
<pre><code class="prism language-python">
<span class="token keyword">class</span> <span class="token class-name">base_model</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>regularizers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># High-level interface which runs the constructed computational graph.</span>
    
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> sess<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss <span class="token operator">=</span> <span class="token number">0</span>
        size <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        predictions <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>size<span class="token punctuation">)</span>
        sess <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_session<span class="token punctuation">(</span>sess<span class="token punctuation">)</span>
        <span class="token keyword">for</span> begin <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            end <span class="token operator">=</span> begin <span class="token operator">+</span> self<span class="token punctuation">.</span>batch_size
            end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">[</span>end<span class="token punctuation">,</span> size<span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            batch_data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            tmp_data <span class="token operator">=</span> data<span class="token punctuation">[</span>begin<span class="token punctuation">:</span>end<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>tmp_data<span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>
                tmp_data <span class="token operator">=</span> tmp_data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># convert sparse matrices</span>
            batch_data<span class="token punctuation">[</span><span class="token punctuation">:</span>end<span class="token operator">-</span>begin<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_data
            feed_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>ph_data<span class="token punctuation">:</span> batch_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ph_dropout<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
            
            <span class="token comment"># Compute loss if labels are given.</span>
            <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                batch_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
                batch_labels<span class="token punctuation">[</span><span class="token punctuation">:</span>end<span class="token operator">-</span>begin<span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span>begin<span class="token punctuation">:</span>end<span class="token punctuation">]</span>
                feed_dict<span class="token punctuation">[</span>self<span class="token punctuation">.</span>ph_labels<span class="token punctuation">]</span> <span class="token operator">=</span> batch_labels
                batch_pred<span class="token punctuation">,</span> batch_loss <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>op_prediction<span class="token punctuation">,</span> self<span class="token punctuation">.</span>op_loss<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token punctuation">)</span>
                loss <span class="token operator">+=</span> batch_loss
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                batch_pred <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>self<span class="token punctuation">.</span>op_prediction<span class="token punctuation">,</span> feed_dict<span class="token punctuation">)</span>
            
            predictions<span class="token punctuation">[</span>begin<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token operator">=</span> batch_pred<span class="token punctuation">[</span><span class="token punctuation">:</span>end<span class="token operator">-</span>begin<span class="token punctuation">]</span>
            
        <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> predictions<span class="token punctuation">,</span> loss <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size <span class="token operator">/</span> size
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> predictions
        
    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> sess<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Runs one evaluation against the full epoch of data.
        Return the precision and the number of correct predictions.
        Batch evaluation saves memory and enables this to run on smaller GPUs.

        sess: the session in which the model has been trained.
        op: the Tensor that returns the number of correct predictions.
        data: size N x M
            N: number of signals (samples)
            M: number of vertices (features)
        labels: size N
            N: number of signals (samples)
        """</span>
        t_process<span class="token punctuation">,</span> t_wall <span class="token operator">=</span> time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        predictions<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> sess<span class="token punctuation">)</span>
        <span class="token comment">#print(predictions)</span>
        ncorrects <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>predictions <span class="token operator">==</span> labels<span class="token punctuation">)</span>
        accuracy <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span>
        f1 <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> predictions<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'weighted'</span><span class="token punctuation">)</span>
        string <span class="token operator">=</span> <span class="token string">'accuracy: {:.2f} ({:d} / {:d}), f1 (weighted): {:.2f}, loss: {:.2e}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                accuracy<span class="token punctuation">,</span> ncorrects<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">,</span> f1<span class="token punctuation">,</span> loss<span class="token punctuation">)</span>
        <span class="token keyword">if</span> sess <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            string <span class="token operator">+=</span> <span class="token string">'\ntime: {:.0f}s (wall {:.0f}s)'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t_process<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t_wall<span class="token punctuation">)</span>
        <span class="token keyword">return</span> string<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> f1<span class="token punctuation">,</span> loss

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> val_data<span class="token punctuation">,</span> val_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        t_process<span class="token punctuation">,</span> t_wall <span class="token operator">=</span> time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span>graph<span class="token operator">=</span>self<span class="token punctuation">.</span>graph<span class="token punctuation">)</span>  <span class="token comment"># 调用图。</span>
        shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'summaries'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ignore_errors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        writer <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>FileWriter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'summaries'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>graph<span class="token punctuation">)</span>
        shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'checkpoints'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ignore_errors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'checkpoints'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'checkpoints'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model'</span><span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>self<span class="token punctuation">.</span>op_init<span class="token punctuation">)</span> <span class="token comment"># 初始化。</span>

        <span class="token comment"># Training.</span>
        accuracies <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        indices <span class="token operator">=</span> collections<span class="token punctuation">.</span>deque<span class="token punctuation">(</span><span class="token punctuation">)</span>
        num_steps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_epochs <span class="token operator">*</span> train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

            <span class="token comment"># Be sure to have used all the samples before using one a second time.</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>indices<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">:</span>
                indices<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            idx <span class="token operator">=</span> <span class="token punctuation">[</span>indices<span class="token punctuation">.</span>popleft<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">]</span>

            batch_data<span class="token punctuation">,</span> batch_labels <span class="token operator">=</span> train_data<span class="token punctuation">[</span>idx<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_labels<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
            <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>batch_data<span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>
                batch_data <span class="token operator">=</span> batch_data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># convert sparse matrices</span>
            feed_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>ph_data<span class="token punctuation">:</span> batch_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ph_labels<span class="token punctuation">:</span> batch_labels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ph_dropout<span class="token punctuation">:</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">}</span>
            learning_rate<span class="token punctuation">,</span> loss_average <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>op_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>op_loss_average<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token punctuation">)</span>

            <span class="token comment"># Periodical evaluation of the model.</span>
            <span class="token keyword">if</span> step <span class="token operator">%</span> self<span class="token punctuation">.</span>eval_frequency <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> step <span class="token operator">==</span> num_steps<span class="token punctuation">:</span>
                epoch <span class="token operator">=</span> step <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size <span class="token operator">/</span> train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'step {} / {} (epoch {:.2f} / {}):'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>step<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  learning_rate = {:.2e}, loss_average = {:.2e}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">,</span> loss_average<span class="token punctuation">)</span><span class="token punctuation">)</span>
                string<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> f1<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>val_data<span class="token punctuation">,</span> val_labels<span class="token punctuation">,</span> sess<span class="token punctuation">)</span>
                accuracies<span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span>
                losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  validation {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>string<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  time: {:.0f}s (wall {:.0f}s)'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t_process<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t_wall<span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token comment"># Summaries for TensorBoard.</span>
                summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>Summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
                summary<span class="token punctuation">.</span>ParseFromString<span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>self<span class="token punctuation">.</span>op_summary<span class="token punctuation">,</span> feed_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
                summary<span class="token punctuation">.</span>value<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tag<span class="token operator">=</span><span class="token string">'validation/accuracy'</span><span class="token punctuation">,</span> simple_value<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
                summary<span class="token punctuation">.</span>value<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tag<span class="token operator">=</span><span class="token string">'validation/f1'</span><span class="token punctuation">,</span> simple_value<span class="token operator">=</span>f1<span class="token punctuation">)</span>
                summary<span class="token punctuation">.</span>value<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tag<span class="token operator">=</span><span class="token string">'validation/loss'</span><span class="token punctuation">,</span> simple_value<span class="token operator">=</span>loss<span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>add_summary<span class="token punctuation">(</span>summary<span class="token punctuation">,</span> step<span class="token punctuation">)</span>
                
                <span class="token comment"># Save model parameters (for evaluation).</span>
                self<span class="token punctuation">.</span>op_saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> path<span class="token punctuation">,</span> global_step<span class="token operator">=</span>step<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'validation accuracy: peak = {:.2f}, mean = {:.2f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>accuracies<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>accuracies<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        t_step <span class="token operator">=</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t_wall<span class="token punctuation">)</span> <span class="token operator">/</span> num_steps
        <span class="token keyword">return</span> accuracies<span class="token punctuation">,</span> losses<span class="token punctuation">,</span> t_step

    <span class="token keyword">def</span> <span class="token function">get_var</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sess <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_session<span class="token punctuation">(</span><span class="token punctuation">)</span>
        var <span class="token operator">=</span> self<span class="token punctuation">.</span>graph<span class="token punctuation">.</span>get_tensor_by_name<span class="token punctuation">(</span>name <span class="token operator">+</span> <span class="token string">':0'</span><span class="token punctuation">)</span>
        val <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>var<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> val

    <span class="token comment"># Methods to construct the computational graph.</span>
    <span class="token keyword">def</span> <span class="token function">build_graph</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> M_0<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Build the computational graph of the model."""</span>
        self<span class="token punctuation">.</span>graph <span class="token operator">=</span> tf<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> self<span class="token punctuation">.</span>graph<span class="token punctuation">.</span>as_default<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># Define operations and tensors in `self.graph`.</span>
            <span class="token comment"># 添加tensor和操作到计算图中。</span>
            <span class="token comment"># Inputs.</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'inputs'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>ph_data <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> M_0<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>ph_labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>ph_dropout <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'dropout'</span><span class="token punctuation">)</span>

            <span class="token comment"># Model.</span>
            op_logits <span class="token operator">=</span> self<span class="token punctuation">.</span>inference<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ph_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ph_dropout<span class="token punctuation">)</span>  <span class="token comment"># 相当于前向传播。</span>
            <span class="token comment"># 等于是建立了图。</span>
            <span class="token comment"># 定义操作。</span>
            self<span class="token punctuation">.</span>op_loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>op_loss_average <span class="token operator">=</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>op_logits<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ph_labels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>regularization<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>op_train <span class="token operator">=</span> self<span class="token punctuation">.</span>training<span class="token punctuation">(</span>self<span class="token punctuation">.</span>op_loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>learning_rate<span class="token punctuation">,</span>
                    self<span class="token punctuation">.</span>decay_steps<span class="token punctuation">,</span> self<span class="token punctuation">.</span>decay_rate<span class="token punctuation">,</span> self<span class="token punctuation">.</span>momentum<span class="token punctuation">)</span> <span class="token comment"># 进行训练，返回当前学习率。</span>
            self<span class="token punctuation">.</span>op_prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>prediction<span class="token punctuation">(</span>op_logits<span class="token punctuation">)</span>

            <span class="token comment"># Initialize variables, i.e. weights and biases.</span>
            self<span class="token punctuation">.</span>op_init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 初始化参数。</span>
            
            <span class="token comment"># Summaries for TensorBoard and Save for model parameters.</span>
            self<span class="token punctuation">.</span>op_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge_all<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>op_saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span>max_to_keep<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>graph<span class="token punctuation">.</span>finalize<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># 完成建图，保证整个图没有新的操作加进去。</span>
    
    <span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        It builds the model, i.e. the computational graph, as far as
        is required for running the network forward to make predictions,
        i.e. return logits given raw data.

        data: size N x M
            N: number of signals (samples)
            M: number of vertices (features)
        training: we may want to discriminate the two, e.g. for dropout.
            True: the model is built for training.
            False: the model is built for evaluation.
        """</span>
        <span class="token comment"># TODO: optimizations for sparse data</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>_inference<span class="token punctuation">(</span>data<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits
    
    <span class="token keyword">def</span> <span class="token function">probabilities</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> logits<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Return the probability of a sample to belong to each class."""</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'probabilities'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            probabilities <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
            <span class="token keyword">return</span> probabilities

    <span class="token keyword">def</span> <span class="token function">prediction</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> logits<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Return the predicted classes."""</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'prediction'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            prediction <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> prediction

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> regularization<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Adds to the inference model the layers required to generate loss."""</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'cross_entropy'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>to_int64<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
                cross_entropy <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sparse_softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits<span class="token operator">=</span>logits<span class="token punctuation">,</span> labels<span class="token operator">=</span>labels<span class="token punctuation">)</span>
                cross_entropy <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span> <span class="token comment">#均值损失</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'regularization'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                regularization <span class="token operator">*=</span> tf<span class="token punctuation">.</span>add_n<span class="token punctuation">(</span>self<span class="token punctuation">.</span>regularizers<span class="token punctuation">)</span>  <span class="token comment">#规范</span>
            loss <span class="token operator">=</span> cross_entropy <span class="token operator">+</span> regularization
            
            <span class="token comment"># Summaries for TensorBoard.生成摘要。</span>
            tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/cross_entropy'</span><span class="token punctuation">,</span> cross_entropy<span class="token punctuation">)</span>
            tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/regularization'</span><span class="token punctuation">,</span> regularization<span class="token punctuation">)</span>
            tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/total'</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'averages'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#求均值。</span>
                averages <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>ExponentialMovingAverage<span class="token punctuation">(</span><span class="token number">0.9</span><span class="token punctuation">)</span>  <span class="token comment">#指数移动平均。</span>
                op_averages <span class="token operator">=</span> averages<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token punctuation">[</span>cross_entropy<span class="token punctuation">,</span> regularization<span class="token punctuation">,</span> loss<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token comment"># 求平均值。</span>
                tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/avg/cross_entropy'</span><span class="token punctuation">,</span> averages<span class="token punctuation">.</span>average<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
                tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/avg/regularization'</span><span class="token punctuation">,</span> averages<span class="token punctuation">.</span>average<span class="token punctuation">(</span>regularization<span class="token punctuation">)</span><span class="token punctuation">)</span>
                tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss/avg/total'</span><span class="token punctuation">,</span> averages<span class="token punctuation">.</span>average<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">with</span> tf<span class="token punctuation">.</span>control_dependencies<span class="token punctuation">(</span><span class="token punctuation">[</span>op_averages<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    loss_average <span class="token operator">=</span> tf<span class="token punctuation">.</span>identity<span class="token punctuation">(</span>averages<span class="token punctuation">.</span>average<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'control'</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> loss<span class="token punctuation">,</span> loss_average
    
    <span class="token keyword">def</span> <span class="token function">training</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> decay_steps<span class="token punctuation">,</span> decay_rate<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Adds to the loss model the Ops required to generate and apply gradients."""</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'training'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># Learning rate.</span>
            global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'global_step'</span><span class="token punctuation">,</span> trainable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> decay_rate <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
                learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span>
                        learning_rate<span class="token punctuation">,</span> global_step<span class="token punctuation">,</span> decay_steps<span class="token punctuation">,</span> decay_rate<span class="token punctuation">,</span> staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'learning_rate'</span><span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
            <span class="token comment"># Optimizer.</span>
            <span class="token keyword">if</span> momentum <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span>
                <span class="token comment">#optimizer = tf.train.AdamOptimizer(learning_rate=0.001)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>MomentumOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">,</span> momentum<span class="token punctuation">)</span> <span class="token comment"># 优化器。</span>
            grads <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>compute_gradients<span class="token punctuation">(</span>loss<span class="token punctuation">)</span> <span class="token comment">#计算梯度。</span>
            op_gradients <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads<span class="token punctuation">,</span> global_step<span class="token operator">=</span>global_step<span class="token punctuation">)</span> <span class="token comment"># 更新权重。</span>
            <span class="token comment"># Histograms.</span>
            <span class="token keyword">for</span> grad<span class="token punctuation">,</span> var <span class="token keyword">in</span> grads<span class="token punctuation">:</span>
                <span class="token keyword">if</span> grad <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'warning: {} has no gradient'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>var<span class="token punctuation">.</span>op<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>histogram<span class="token punctuation">(</span>var<span class="token punctuation">.</span>op<span class="token punctuation">.</span>name <span class="token operator">+</span> <span class="token string">'/gradients'</span><span class="token punctuation">,</span> grad<span class="token punctuation">)</span>
            <span class="token comment"># The op return the learning rate.</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>control_dependencies<span class="token punctuation">(</span><span class="token punctuation">[</span>op_gradients<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                op_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>identity<span class="token punctuation">(</span>learning_rate<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'control'</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> op_train

    <span class="token comment"># Helper methods.</span>

    <span class="token keyword">def</span> <span class="token function">_get_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> folder<span class="token punctuation">)</span><span class="token punctuation">:</span>
        path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>realpath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> folder<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dir_name<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_get_session</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sess<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Restore parameters if no session given."""</span>
        <span class="token keyword">if</span> sess <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span>graph<span class="token operator">=</span>self<span class="token punctuation">.</span>graph<span class="token punctuation">)</span>
            filename <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>latest_checkpoint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_path<span class="token punctuation">(</span><span class="token string">'checkpoints'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>op_saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sess

    <span class="token keyword">def</span> <span class="token function">_weight_variable</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> shape<span class="token punctuation">,</span> regularization<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        initial <span class="token operator">=</span> tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
        var <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span> shape<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> initializer<span class="token operator">=</span>initial<span class="token punctuation">)</span>
        <span class="token keyword">if</span> regularization<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>var<span class="token punctuation">)</span><span class="token punctuation">)</span>
        tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>histogram<span class="token punctuation">(</span>var<span class="token punctuation">.</span>op<span class="token punctuation">.</span>name<span class="token punctuation">,</span> var<span class="token punctuation">)</span>
        <span class="token keyword">return</span> var

    <span class="token keyword">def</span> <span class="token function">_bias_variable</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> shape<span class="token punctuation">,</span> regularization<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        initial <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
        var <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> shape<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> initializer<span class="token operator">=</span>initial<span class="token punctuation">)</span>
        <span class="token keyword">if</span> regularization<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>var<span class="token punctuation">)</span><span class="token punctuation">)</span>
        tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>histogram<span class="token punctuation">(</span>var<span class="token punctuation">.</span>op<span class="token punctuation">.</span>name<span class="token punctuation">,</span> var<span class="token punctuation">)</span>
        <span class="token keyword">return</span> var

    <span class="token keyword">def</span> <span class="token function">_conv2d</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
</code></pre> 
<p>gnn:</p> 
<pre><code class="prism language-c">
class <span class="token function">cgcnn</span><span class="token punctuation">(</span>base_model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">""</span>"
    Graph CNN which uses the Chebyshev approximation<span class="token punctuation">.</span>

    The following are hyper<span class="token operator">-</span>parameters of graph convolutional layers<span class="token punctuation">.</span>
    They are lists<span class="token punctuation">,</span> which length is equal to the number of gconv layers<span class="token punctuation">.</span>
        F<span class="token punctuation">:</span> Number of features<span class="token punctuation">.</span>
        K<span class="token punctuation">:</span> List of polynomial orders<span class="token punctuation">,</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> filter sizes or number of hopes<span class="token punctuation">.</span>
        p<span class="token punctuation">:</span> Pooling size<span class="token punctuation">.</span>
           Should be <span class="token number">1</span> <span class="token punctuation">(</span>no pooling<span class="token punctuation">)</span> or a power of <span class="token number">2</span> <span class="token punctuation">(</span>reduction by <span class="token number">2</span> at each coarser level<span class="token punctuation">)</span><span class="token punctuation">.</span>
           Beware to have coarsened enough<span class="token punctuation">.</span>

    L<span class="token punctuation">:</span> List of Graph Laplacians<span class="token punctuation">.</span> Size M x M<span class="token punctuation">.</span> One per coarsening level<span class="token punctuation">.</span>

    The following are hyper<span class="token operator">-</span>parameters of fully connected layers<span class="token punctuation">.</span>
    They are lists<span class="token punctuation">,</span> which length is equal to the number of fc layers<span class="token punctuation">.</span>
        M<span class="token punctuation">:</span> Number of features per sample<span class="token punctuation">,</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> number of hidden neurons<span class="token punctuation">.</span>
           The last layer is the softmax<span class="token punctuation">,</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> M<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> is the number of classes<span class="token punctuation">.</span>
    
    The following are choices of implementation <span class="token keyword">for</span> various blocks<span class="token punctuation">.</span>
        filter<span class="token punctuation">:</span> filtering operation<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> chebyshev5<span class="token punctuation">,</span> lanczos2 etc<span class="token punctuation">.</span>
        brelu<span class="token punctuation">:</span> bias and relu<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> b1relu or b2relu<span class="token punctuation">.</span>
        pool<span class="token punctuation">:</span> pooling<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> mpool1<span class="token punctuation">.</span>
    
    Training parameters<span class="token punctuation">:</span>
        num_epochs<span class="token punctuation">:</span>    Number of training epochs<span class="token punctuation">.</span>
        learning_rate<span class="token punctuation">:</span> Initial learning rate<span class="token punctuation">.</span>
        decay_rate<span class="token punctuation">:</span>    Base of exponential decay<span class="token punctuation">.</span> No decay with <span class="token number">1.</span>
        decay_steps<span class="token punctuation">:</span>   Number of steps after which the learning rate decays<span class="token punctuation">.</span>
        momentum<span class="token punctuation">:</span>      Momentum<span class="token punctuation">.</span> <span class="token number">0</span> indicates no momentum<span class="token punctuation">.</span>

    Regularization parameters<span class="token punctuation">:</span>
        regularization<span class="token punctuation">:</span> L2 regularizations of weights and biases<span class="token punctuation">.</span>
        dropout<span class="token punctuation">:</span>        Dropout <span class="token punctuation">(</span>fc layers<span class="token punctuation">)</span><span class="token punctuation">:</span> probability to keep hidden neurons<span class="token punctuation">.</span> No dropout with <span class="token number">1.</span>
        batch_size<span class="token punctuation">:</span>     Batch size<span class="token punctuation">.</span> Must divide evenly into the dataset sizes<span class="token punctuation">.</span>
        eval_frequency<span class="token punctuation">:</span> Number of steps between evaluations<span class="token punctuation">.</span>

    Directories<span class="token punctuation">:</span>
        dir_name<span class="token punctuation">:</span> Name <span class="token keyword">for</span> directories <span class="token punctuation">(</span>summaries and model parameters<span class="token punctuation">)</span><span class="token punctuation">.</span>
    <span class="token string">""</span>"
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> L<span class="token punctuation">,</span> F<span class="token punctuation">,</span> K<span class="token punctuation">,</span> p<span class="token punctuation">,</span> M<span class="token punctuation">,</span> filter<span class="token operator">=</span><span class="token string">'chebyshev5'</span><span class="token punctuation">,</span> brelu<span class="token operator">=</span><span class="token string">'b1relu'</span><span class="token punctuation">,</span> pool<span class="token operator">=</span><span class="token string">'mpool1'</span><span class="token punctuation">,</span>
                num_epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> decay_rate<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span> decay_steps<span class="token operator">=</span>None<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
                regularization<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> eval_frequency<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
                dir_name<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token function">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token macro property"># Verify the consistency w.r.t. the number of layers.</span>
        assert <span class="token function">len</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token function">len</span><span class="token punctuation">(</span>F<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token function">len</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token function">len</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span>  # 每一层的拉普拉斯，parent。。。。
        assert np<span class="token punctuation">.</span><span class="token function">all</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        p_log2 <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">where</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token function">log2</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
        assert np<span class="token punctuation">.</span><span class="token function">all</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">mod</span><span class="token punctuation">(</span>p_log2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>  # Powers of <span class="token number">2.</span>
        assert <span class="token function">len</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span>p_log2<span class="token punctuation">)</span>  # Enough coarsening levels <span class="token keyword">for</span> pool sizes<span class="token punctuation">.</span>
        
        <span class="token macro property"># Keep the useful Laplacians only. May be zero.</span>
        M_0 <span class="token operator">=</span> L<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        j <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>L <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> pp in p<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>L<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>L<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
            j <span class="token operator">+</span><span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">log2</span><span class="token punctuation">(</span>pp<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> pp <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span>
        L <span class="token operator">=</span> self<span class="token punctuation">.</span>L
        
        <span class="token macro property"># Print information about NN architecture.</span>
        Ngconv <span class="token operator">=</span> <span class="token function">len</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> # 卷积层数。
        Nfc <span class="token operator">=</span> <span class="token function">len</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span>
        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'NN architecture'</span><span class="token punctuation">)</span>
        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'  input: M_0 = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>M_0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>Ngconv<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'  layer {0}: cgconv{0}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    representation: M_{0} * F_{1} / p_{1} = {2} * {3} / {4} = {5}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>
                    i<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token comment">//p[i]))</span>
            F_last <span class="token operator">=</span> F<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">if</span> i <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">1</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    weights: F_{0} * F_{1} * K_{1} = {2} * {3} * {4} = {5}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>
                    i<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> F_last<span class="token punctuation">,</span> F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> K<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> F_last<span class="token operator">*</span>F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">*</span>K<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> brelu <span class="token operator">==</span> <span class="token string">'b1relu'</span><span class="token punctuation">:</span>
                <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    biases: F_{} = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            elif brelu <span class="token operator">==</span> <span class="token string">'b2relu'</span><span class="token punctuation">:</span>
                <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    biases: M_{0} * F_{0} = {1} * {2} = {3}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>
                        i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>Nfc<span class="token punctuation">)</span><span class="token punctuation">:</span>
            name <span class="token operator">=</span> <span class="token string">'logits (softmax)'</span> <span class="token keyword">if</span> i <span class="token operator">==</span> Nfc<span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'fc{}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'  layer {}: {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>Ngconv<span class="token operator">+</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    representation: M_{} = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>Ngconv<span class="token operator">+</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            M_last <span class="token operator">=</span> M<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">if</span> i <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> M_0 <span class="token keyword">if</span> Ngconv <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> L<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> F<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment">// p[-1]</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    weights: M_{} * M_{} = {} * {} = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>
                    Ngconv<span class="token operator">+</span>i<span class="token punctuation">,</span> Ngconv<span class="token operator">+</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> M_last<span class="token punctuation">,</span> M<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> M_last<span class="token operator">*</span>M<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">'    biases: M_{} = {}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>Ngconv<span class="token operator">+</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        <span class="token macro property"># Store attributes and bind operations.</span>
        self<span class="token punctuation">.</span>L<span class="token punctuation">,</span> self<span class="token punctuation">.</span>F<span class="token punctuation">,</span> self<span class="token punctuation">.</span>K<span class="token punctuation">,</span> self<span class="token punctuation">.</span>p<span class="token punctuation">,</span> self<span class="token punctuation">.</span>M <span class="token operator">=</span> L<span class="token punctuation">,</span> F<span class="token punctuation">,</span> K<span class="token punctuation">,</span> p<span class="token punctuation">,</span> M
        self<span class="token punctuation">.</span>num_epochs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> num_epochs<span class="token punctuation">,</span> learning_rate
        self<span class="token punctuation">.</span>decay_rate<span class="token punctuation">,</span> self<span class="token punctuation">.</span>decay_steps<span class="token punctuation">,</span> self<span class="token punctuation">.</span>momentum <span class="token operator">=</span> decay_rate<span class="token punctuation">,</span> decay_steps<span class="token punctuation">,</span> momentum
        self<span class="token punctuation">.</span>regularization<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> regularization<span class="token punctuation">,</span> dropout
        self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>eval_frequency <span class="token operator">=</span> batch_size<span class="token punctuation">,</span> eval_frequency
        self<span class="token punctuation">.</span>dir_name <span class="token operator">=</span> dir_name
        self<span class="token punctuation">.</span>filter <span class="token operator">=</span> <span class="token function">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filter<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>brelu <span class="token operator">=</span> <span class="token function">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> brelu<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> <span class="token function">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pool<span class="token punctuation">)</span>
        
        <span class="token macro property"># Build the computational graph.</span>
        self<span class="token punctuation">.</span><span class="token function">build_graph</span><span class="token punctuation">(</span>M_0<span class="token punctuation">)</span>
        
    def <span class="token function">filter_in_fourier</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">,</span> U<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token macro property"># TODO: N x F x M would avoid the permutations</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>Fin<span class="token punctuation">)</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin x N
        <span class="token macro property"># Transform to Fourier domain</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fin<span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin<span class="token operator">*</span>N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>U<span class="token punctuation">,</span> x<span class="token punctuation">)</span>  # M x Fin<span class="token operator">*</span>N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fin<span class="token punctuation">,</span> N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin x N
        <span class="token macro property"># Filter</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> x<span class="token punctuation">)</span>  # <span class="token keyword">for</span> each feature
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  # N x Fout x M
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token operator">*</span>Fout<span class="token punctuation">,</span> M<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N<span class="token operator">*</span>Fout x M
        <span class="token macro property"># Transform back to graph domain</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> U<span class="token punctuation">)</span>  # N<span class="token operator">*</span>Fout x M
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> M<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x Fout x M
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M x Fout

    def <span class="token function">fourier</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>
        assert K <span class="token operator">==</span> L<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  # artificial but useful to compute number of parameters
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>Fin<span class="token punctuation">)</span>
        <span class="token macro property"># Fourier basis</span>
        _<span class="token punctuation">,</span> U <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">fourier</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
        U <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">constant</span><span class="token punctuation">(</span>U<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token macro property"># Weights</span>
        W <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_weight_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> Fin<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token function">filter_in_fourier</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">,</span> U<span class="token punctuation">,</span> W<span class="token punctuation">)</span>

    def <span class="token function">spline</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>Fin<span class="token punctuation">)</span>
        <span class="token macro property"># Fourier basis</span>
        lamb<span class="token punctuation">,</span> U <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">fourier</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
        U <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">constant</span><span class="token punctuation">(</span>U<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  # M x M
        <span class="token macro property"># Spline basis</span>
        B <span class="token operator">=</span> <span class="token function">bspline_basis</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> lamb<span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  # M x K
        <span class="token macro property">#B = bspline_basis(K, len(lamb), degree=3)  # M x K</span>
        B <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">constant</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token macro property"># Weights</span>
        W <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_weight_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span>K<span class="token punctuation">,</span> Fout<span class="token operator">*</span>Fin<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        W <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  # M x Fout<span class="token operator">*</span>Fin
        W <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> <span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> Fin<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token function">filter_in_fourier</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">,</span> U<span class="token punctuation">,</span> W<span class="token punctuation">)</span>

    def <span class="token function">chebyshev2</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span>"
        Filtering with Chebyshev interpolation
        Implementation<span class="token punctuation">:</span> numpy<span class="token punctuation">.</span>
        
        Data<span class="token punctuation">:</span> x of size N x M x F
            N<span class="token punctuation">:</span> number of signals
            M<span class="token punctuation">:</span> number of vertices
            F<span class="token punctuation">:</span> number of features per signal per vertex # 也就是输入通道数。
        <span class="token string">""</span>"
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>Fin<span class="token punctuation">)</span>
        <span class="token macro property"># Rescale Laplacian. Copy to not modify the shared L.</span>
        L <span class="token operator">=</span> scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">csr_matrix</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
        L <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">rescale_L</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> lmax<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token macro property"># Transform to Chebyshev basis</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin x N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fin<span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin<span class="token operator">*</span>N
        def <span class="token function">chebyshev</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span><span class="token function">chebyshev</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> x<span class="token punctuation">,</span> K<span class="token punctuation">)</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">py_func</span><span class="token punctuation">(</span>chebyshev<span class="token punctuation">,</span> <span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  # K x M x Fin<span class="token operator">*</span>N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>K<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin<span class="token punctuation">,</span> N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # K x M x Fin x N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M x Fin x K
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token operator">*</span>M<span class="token punctuation">,</span> Fin<span class="token operator">*</span>K<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N<span class="token operator">*</span>M x Fin<span class="token operator">*</span>K
        <span class="token macro property"># Filter: Fin*Fout filters of order K, i.e. one filterbank per feature.</span>
        W <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_weight_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span>Fin<span class="token operator">*</span>K<span class="token punctuation">,</span> Fout<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  # N<span class="token operator">*</span>M x Fout
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fout<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M x Fout

    def <span class="token function">chebyshev5</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> L<span class="token punctuation">,</span> Fout<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin <span class="token operator">=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>Fin<span class="token punctuation">)</span>
        <span class="token macro property"># Rescale Laplacian and store as a TF sparse tensor. Copy to not modify the shared L.</span>
        L <span class="token operator">=</span> scipy<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span><span class="token function">csr_matrix</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
        L <span class="token operator">=</span> graph<span class="token punctuation">.</span><span class="token function">rescale_L</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> lmax<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        L <span class="token operator">=</span> L<span class="token punctuation">.</span><span class="token function">tocoo</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        indices <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">column_stack</span><span class="token punctuation">(</span><span class="token punctuation">(</span>L<span class="token punctuation">.</span>row<span class="token punctuation">,</span> L<span class="token punctuation">.</span>col<span class="token punctuation">)</span><span class="token punctuation">)</span>
        L <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">SparseTensor</span><span class="token punctuation">(</span>indices<span class="token punctuation">,</span> L<span class="token punctuation">.</span>data<span class="token punctuation">,</span> L<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        L <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">sparse_reorder</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span>
        <span class="token macro property"># Transform to Chebyshev basis</span>
        x0 <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin x N
        x0 <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x0<span class="token punctuation">,</span> <span class="token punctuation">[</span>M<span class="token punctuation">,</span> Fin<span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # M x Fin<span class="token operator">*</span>N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>x0<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>  # <span class="token number">1</span> x M x Fin<span class="token operator">*</span>N
        def <span class="token function">concat</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x_ <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>x_<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>  # <span class="token number">1</span> x M x Fin<span class="token operator">*</span>N
            <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> x_<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  # K x M x Fin<span class="token operator">*</span>N
        <span class="token keyword">if</span> K <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
            x1 <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">sparse_tensor_dense_matmul</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> x0<span class="token punctuation">)</span>
            x <span class="token operator">=</span> <span class="token function">concat</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x1<span class="token punctuation">)</span>
        <span class="token keyword">for</span> k in <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x2 <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span><span class="token function">sparse_tensor_dense_matmul</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> x1<span class="token punctuation">)</span> <span class="token operator">-</span> x0  # M x Fin<span class="token operator">*</span>N
            x <span class="token operator">=</span> <span class="token function">concat</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x2<span class="token punctuation">)</span>
            x0<span class="token punctuation">,</span> x1 <span class="token operator">=</span> x1<span class="token punctuation">,</span> x2
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>K<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fin<span class="token punctuation">,</span> N<span class="token punctuation">]</span><span class="token punctuation">)</span>  # K x M x Fin x N
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M x Fin x K
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token operator">*</span>M<span class="token punctuation">,</span> Fin<span class="token operator">*</span>K<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N<span class="token operator">*</span>M x Fin<span class="token operator">*</span>K
        <span class="token macro property"># Filter: Fin*Fout filters of order K, i.e. one filterbank per feature pair.</span>
        W <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_weight_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span>Fin<span class="token operator">*</span>K<span class="token punctuation">,</span> Fout<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  # N<span class="token operator">*</span>M x Fout
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> Fout<span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M x Fout

    def <span class="token function">b1relu</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span><span class="token string">"Bias and ReLU. One bias per filter."</span><span class="token string">""</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> F <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_bias_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>F<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">relu</span><span class="token punctuation">(</span>x <span class="token operator">+</span> b<span class="token punctuation">)</span>

    def <span class="token function">b2relu</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span><span class="token string">"Bias and ReLU. One bias per vertex per filter."</span><span class="token string">""</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> F <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_bias_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>F<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>False<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">relu</span><span class="token punctuation">(</span>x <span class="token operator">+</span> b<span class="token punctuation">)</span>

    def <span class="token function">mpool1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span><span class="token string">"Max pooling of size p. Should be a power of 2."</span><span class="token string">""</span>
        <span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  # N x M x F x <span class="token number">1</span>
            x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">max_pool</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>p<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>p<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
            <span class="token macro property">#tf.maximum</span>
            <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M<span class="token operator">/</span>p x F
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> x

    def <span class="token function">apool1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span><span class="token string">"Average pooling of size p. Should be a power of 2."</span><span class="token string">""</span>
        <span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  # N x M x F x <span class="token number">1</span>
            x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">avg_pool</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>p<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>p<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> tf<span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M<span class="token operator">/</span>p x F
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> x

    def <span class="token function">fc</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> Mout<span class="token punctuation">,</span> relu<span class="token operator">=</span>True<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token string">""</span><span class="token string">"Fully connected layer with Mout features."</span><span class="token string">""</span>
        N<span class="token punctuation">,</span> Min <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        W <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_weight_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token keyword">int</span><span class="token punctuation">(</span>Min<span class="token punctuation">)</span><span class="token punctuation">,</span> Mout<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>True<span class="token punctuation">)</span>
        b <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">_bias_variable</span><span class="token punctuation">(</span><span class="token punctuation">[</span>Mout<span class="token punctuation">]</span><span class="token punctuation">,</span> regularization<span class="token operator">=</span>True<span class="token punctuation">)</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">matmul</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token operator">+</span> b
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">if</span> relu <span class="token keyword">else</span> x

    def <span class="token function">_inference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token macro property"># Graph convolutional layers.</span>
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  # N x M x F<span class="token operator">=</span><span class="token number">1</span>
        <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>p<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            with tf<span class="token punctuation">.</span><span class="token function">variable_scope</span><span class="token punctuation">(</span><span class="token string">'conv{}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                with tf<span class="token punctuation">.</span><span class="token function">name_scope</span><span class="token punctuation">(</span><span class="token string">'filter'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>F<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>K<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  # 这一步其实就完成了？？？？
                    # 卷积完成。
                with tf<span class="token punctuation">.</span><span class="token function">name_scope</span><span class="token punctuation">(</span><span class="token string">'bias_relu'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">brelu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
                    # 激活完成。
                with tf<span class="token punctuation">.</span><span class="token function">name_scope</span><span class="token punctuation">(</span><span class="token string">'pooling'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">pool</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>p<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  # p 每次 都是<span class="token number">2</span> <span class="token operator">?</span><span class="token operator">?</span><span class="token operator">?</span>
                    # 池化完成。
                    # 循环<span class="token function">len</span><span class="token punctuation">(</span>layers<span class="token punctuation">)</span> 次。
        
        <span class="token macro property"># Fully connected hidden layers.</span>
        N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> F <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">get_shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  # 输入为batch，顶点数， 通道数。也就是每个顶点数据的维度。
        x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token keyword">int</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">(</span>M<span class="token operator">*</span>F<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # N x M
        <span class="token keyword">for</span> i<span class="token punctuation">,</span>M in <span class="token function">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>M<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span> # 最后几层全连接？
            with tf<span class="token punctuation">.</span><span class="token function">variable_scope</span><span class="token punctuation">(</span><span class="token string">'fc{}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">fc</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> M<span class="token punctuation">)</span>
                x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">dropout</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>
        
        <span class="token macro property"># Logits linear layer, i.e. softmax without normalization.</span>
        with tf<span class="token punctuation">.</span><span class="token function">variable_scope</span><span class="token punctuation">(</span><span class="token string">'logits'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">fc</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>M<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> relu<span class="token operator">=</span>False<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7354abc07fce91ae29910dd5b55ee88d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">hive与sqoop</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/131b0dd7dee684e517b4e6408624a0cc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">logstash 7.10安装</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>