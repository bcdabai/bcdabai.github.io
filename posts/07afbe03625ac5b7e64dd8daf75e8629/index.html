<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>第十一周：机器学习周报 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="第十一周：机器学习周报" />
<meta property="og:description" content="目录
摘要
Abstract
What is GNN？
Why need GNN？
Spatial-based GNN
模型一：NN4G（Neural Network for Graph）
模型二：DCNN（Diffusion-Convolution Neural Network）
模型三：DGC（Diffusion Graph Convolution）
模型四：MoNET（Mixture Model Networks）
模型五：GAT（Graph Attention Networks）
Spectral-based GNN
图信号的傅里叶变换
GNN模型例子分析
摘要 GNN可以将graph的结构和图中每个节点和边的特征转化为一般的神经网络的输入，而GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）Spatial-based GNN方法采用类似CNN的卷积得到每个隐藏层的值，再将所有层的值集合成为整个graph的输出，Spectral-based GNN方法借助了信号与系统中的傅里叶变换，定义了一套Spectral Graph Theory，使用特征值等价频率，再构造傅里叶变换与逆傅里叶变换得到图神经网络的卷积输出。
Abstract What is GNN？ 简单来说GNN就是Graph &#43; Nerual Networks，而这里的Graph的粗略定义就是有节点有边的图形，并不是图片而是数据结构中的图，而是一种结构化的数据。关键问题就是将graph的结构和图中每个节点和边的特征转化为一般的神经网络的输入（张量）。
GNN考虑所有的特征并将其转化为神经网络可以输入的向量，就需要用到类似于CNN的Convolution（卷积），而GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）。
Why need GNN？ 当我们在做classfication的时候数据以图的形式出现，而这张图非常大，拥有很多的节点，并且节点之间互相影响，那数据集就会非常大，我们需要考虑节点之间的各种联系，因此需要用到GNN。
例如在一个故事中存在很多个角色，每个角色都有对应的特征，例如姓名职业等，要从这些角色中找到一个杀人凶手，寻找的这个过程可以看成是一个classfication的问题，训练一个分类器，将一个角色（即该角色的各个特征）放入训练出来的classifier，判断该角色是否是杀人凶手。
但是问题是角色之间存在一张庞大的关系网，两两角色之间都存在一定的关系，而这些关系在做classfication的时候可以得到额外的信息，帮助我们做更好的model。因此需要考虑全部的关系，这就必须要用到graph neural network。
Spatial-based GNN Spatial-based GNN需要做空间域的卷积，也就是在空间上的卷积，需要做两步，第一步是aggregate，aggregate类似于CNN中的convolution也就是卷积，CNN 中的卷积核在计算某一个像素点的 feature 的时候，可以看成把这个像素点周围的像素点的特征按照一定的权重加权求和，Spatial-GNN 想要把这种卷积操作直接推广到 Graph 上，即用邻节点的特征更新下一隐藏层的状态，第二步是readout，把所有节点的特征集合起来代表整个graph。
GNN的卷积和readout有很多种方法
模型一：NN4G（Neural Network for Graph） NN4G是在上一层的数据基础上更新下一层隐藏层的特征，我们可以认为它的计算方法 COMBINE 的就是上层自己的特征经过一个线性变换。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/07afbe03625ac5b7e64dd8daf75e8629/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-17T14:53:48+08:00" />
<meta property="article:modified_time" content="2024-01-17T14:53:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">第十一周：机器学习周报</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="%E6%91%98%E8%A6%81-toc" style="margin-left:0px;"><a href="#%E6%91%98%E8%A6%81" rel="nofollow">摘要</a></p> 
<p id="Abstract-toc" style="margin-left:0px;"><a href="#Abstract" rel="nofollow">Abstract</a></p> 
<p id="What%20is%20GNN%EF%BC%9F-toc" style="margin-left:0px;"><a href="#What%20is%20GNN%EF%BC%9F" rel="nofollow">What is GNN？</a></p> 
<p id="Why%20need%20GNN%EF%BC%9F-toc" style="margin-left:0px;"><a href="#Why%20need%20GNN%EF%BC%9F" rel="nofollow">Why need GNN？</a></p> 
<p id="Spatial-based%20GNN-toc" style="margin-left:0px;"><a href="#Spatial-based%20GNN" rel="nofollow">Spatial-based GNN</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E4%B8%80%EF%BC%9ANN4G%EF%BC%88Neural%20Network%20for%20Graph%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E4%B8%80%EF%BC%9ANN4G%EF%BC%88Neural%20Network%20for%20Graph%EF%BC%89" rel="nofollow">模型一：NN4G（Neural Network for Graph）</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E4%BA%8C%EF%BC%9ADCNN%EF%BC%88Diffusion-Convolution%20Neural%20Network%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E4%BA%8C%EF%BC%9ADCNN%EF%BC%88Diffusion-Convolution%20Neural%20Network%EF%BC%89" rel="nofollow">模型二：DCNN（Diffusion-Convolution Neural Network）</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E4%B8%89%EF%BC%9ADGC%EF%BC%88Diffusion%20Graph%20Convolution%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E4%B8%89%EF%BC%9ADGC%EF%BC%88Diffusion%20Graph%20Convolution%EF%BC%89" rel="nofollow">模型三：DGC（Diffusion Graph Convolution）</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E5%9B%9B%EF%BC%9AMoNET%EF%BC%88Mixture%20Model%20Networks%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E5%9B%9B%EF%BC%9AMoNET%EF%BC%88Mixture%20Model%20Networks%EF%BC%89" rel="nofollow">模型四：MoNET（Mixture Model Networks）</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E4%BA%94%EF%BC%9AGAT%EF%BC%88Graph%20Attention%20Networks%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E4%BA%94%EF%BC%9AGAT%EF%BC%88Graph%20Attention%20Networks%EF%BC%89" rel="nofollow">模型五：GAT（Graph Attention Networks）</a></p> 
<p id="Spectral-based%20GNN-toc" style="margin-left:0px;"><a href="#Spectral-based%20GNN" rel="nofollow">Spectral-based GNN</a></p> 
<p id="%E5%9B%BE%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2-toc" style="margin-left:40px;"><a href="#%E5%9B%BE%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2" rel="nofollow">图信号的傅里叶变换</a></p> 
<p id="GNN%E6%A8%A1%E5%9E%8B%E4%BE%8B%E5%AD%90%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#GNN%E6%A8%A1%E5%9E%8B%E4%BE%8B%E5%AD%90%E5%88%86%E6%9E%90" rel="nofollow">GNN模型例子分析</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E6%91%98%E8%A6%81">摘要</h2> 
<p>GNN可以将graph的结构和图中每个节点和边的特征转化为一般的神经网络的输入，而GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）Spatial-based GNN方法采用类似CNN的卷积得到每个隐藏层的值，再将所有层的值集合成为整个graph的输出，Spectral-based GNN方法借助了信号与系统中的傅里叶变换，定义了一套Spectral Graph Theory，使用特征值等价频率，再构造傅里叶变换与逆傅里叶变换得到图神经网络的卷积输出。</p> 
<h2 id="Abstract">Abstract</h2> 
<p></p> 
<h2 id="What%20is%20GNN%EF%BC%9F">What is GNN？</h2> 
<p>简单来说GNN就是Graph + Nerual Networks，而这里的Graph的粗略定义就是有节点有边的图形，并不是图片而是数据结构中的图，而是一种结构化的数据。<strong>关键问题就是将graph的结构和图中每个节点和边的特征转化为一般的神经网络的输入（张量）。</strong></p> 
<p><img alt="169ea0bf65a941c9a84007eb9eb9040f.png" src="https://images2.imgbox.com/20/a4/Bmubcs0j_o.png"></p> 
<p>GNN考虑所有的特征并将其转化为神经网络可以输入的向量，就需要用到类似于CNN的Convolution（卷积），而GNN中的卷积有两种方法，一种是Spatial-based（基于空间的），另一种是Spectral-based（基于谱域的）。</p> 
<p><img alt="08c49a8904ca4aaca16a6b14f11455fa.png" src="https://images2.imgbox.com/c1/fa/1cZk6BWL_o.png"></p> 
<p></p> 
<h2 id="Why%20need%20GNN%EF%BC%9F">Why need GNN？</h2> 
<p>当我们在做classfication的时候数据以图的形式出现，而这张图非常大，拥有很多的节点，并且节点之间互相影响，那数据集就会非常大，我们需要考虑节点之间的各种联系，因此需要用到GNN。</p> 
<p><img alt="ee15b9741b654c9e83f6f961531c0d0d.png" src="https://images2.imgbox.com/40/6e/U0jRVF7p_o.png"></p> 
<p>例如在一个故事中存在很多个角色，每个角色都有对应的特征，例如姓名职业等，要从这些角色中找到一个杀人凶手，寻找的这个过程可以看成是一个classfication的问题，训练一个分类器，将一个角色（即该角色的各个特征）放入训练出来的classifier，判断该角色是否是杀人凶手。</p> 
<p><img alt="b806c40685d54c19822ba34274f513a5.png" src="https://images2.imgbox.com/f1/16/oC0I03Ay_o.png"></p> 
<p>但是问题是角色之间存在一张庞大的关系网，两两角色之间都存在一定的关系，而这些关系在做classfication的时候可以得到额外的信息，帮助我们做更好的model。因此需要考虑全部的关系，这就必须要用到graph neural network。</p> 
<p> <img alt="991ae18952a14c2e85f90d2c66ab3389.png" src="https://images2.imgbox.com/b2/50/jBAoUTss_o.png"></p> 
<h2 id="Spatial-based%20GNN">Spatial-based GNN</h2> 
<p> Spatial-based GNN需要做空间域的卷积，也就是在空间上的卷积，需要做两步，第一步是aggregate，aggregate类似于CNN中的convolution也就是卷积，CNN 中的卷积核在计算某一个像素点的 feature 的时候，可以看成把这个像素点周围的像素点的特征按照一定的权重加权求和，Spatial-GNN 想要把这种卷积操作直接推广到 Graph 上，即用邻节点的特征更新下一隐藏层的状态，第二步是readout，把所有节点的特征集合起来代表整个graph。</p> 
<p><img alt="733601a4f2024b9bac505f712ed6745c.png" src="https://images2.imgbox.com/6f/8c/jh4cbm6u_o.png"></p> 
<p> GNN的卷积和readout有很多种方法</p> 
<h3 id="%E6%A8%A1%E5%9E%8B%E4%B8%80%EF%BC%9ANN4G%EF%BC%88Neural%20Network%20for%20Graph%EF%BC%89">模型一：NN4G（Neural Network for Graph）</h3> 
<p>NN4G是在<strong>上一层</strong>的数据基础上更新下一层隐藏层的特征，我们可以认为它的计算方法 COMBINE 的就是上层自己的特征经过一个线性变换。</p> 
<p>每个隐藏层都是一个图，有若干个节点，每个节点都有一个对应的权值，权值与上一层相联系，某一节点的权值=（上一层该节点的所有相邻节点的权值之和）✖一个待学习的参数+该点本身的值与一个参数矩阵的乘积（<img alt="eq?x_%7B3%7D" src="https://images2.imgbox.com/d9/af/WZ2BEm4a_o.png">是这个节点本来值）。</p> 
<p></p> 
<p><img alt="c289cf6ef81741bdb9100ab0081ee084.png" src="https://images2.imgbox.com/89/3f/tZxHOBJ2_o.png"></p> 
<p>Readout的计算方法：对每一个隐藏层计算均值，然后分别乘以可训练矩阵后加起来。</p> 
<p><img alt="046f9abc622045ba8c0014c5a234ded0.png" src="https://images2.imgbox.com/20/2b/PjRzR44c_o.png"></p> 
<p>通过卷积的过程可以将各种特征作为输入放入全连接网络中，但是全连接网络中的神经元是固定的，因此对于每个输入的图来说，通过卷积之后的输入网络的向量维度都应该是一样。对于每个图NN4G都是使用固定数量的隐藏层对应固定的神经元，然后将每层的均值输入全连接神经网络。</p> 
<blockquote> 
 <p>AGGREGATE：求和之后做一个 Transform<br> COMBINE：求和之后再加上自身做一个 Transform 的结果。<br> READOUT：先通过平均操作求除每一层的图的表示方式，然后将所有层的图表示加权求和得到最终的图的表示。</p> 
</blockquote> 
<h3 id="%E6%A8%A1%E5%9E%8B%E4%BA%8C%EF%BC%9ADCNN%EF%BC%88Diffusion-Convolution%20Neural%20Network%EF%BC%89">模型二：DCNN（Diffusion-Convolution Neural Network）</h3> 
<p>DCNN的每一层都是以<strong>原始的</strong>数据进行更新，第K个隐藏层的某一点的值=原图中与这个点距离为K的点的值取平均值✖待学习的参数。（mean(d(3,.)=1)代表距离节点<img alt="eq?v_%7B3%7D" class="mathcode" src="https://images2.imgbox.com/2e/5c/lM9GgKQ7_o.png"> 为1，mean(d(3,.)=2)代表距离节点<img alt="eq?v_%7B3%7D" class="mathcode" src="https://images2.imgbox.com/5f/a6/GPkE3WSI_o.png"> 为2的所有节点特征的均值）</p> 
<p><img alt="ddb654a4602b4c38ba03141636fe7513.png" src="https://images2.imgbox.com/c8/7d/OxUFTKpu_o.png"></p> 
<p>通过上面的方法求得每一层网络中所有节点，将这些向量组成一个矩阵<img alt="eq?H%5E%7Bi%7D" class="mathcode" src="https://images2.imgbox.com/06/15/8raSnfpF_o.png">以后，<img alt="eq?H%5E%7Bi%7D" class="mathcode" src="https://images2.imgbox.com/2d/79/fQqSOUrk_o.png">代表第 i层的矩阵，假设有 n 个节点，特征维度为 d ，那么这个矩阵就是一个 <img alt="eq?n%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/e6/78/JJSPFiLx_o.png"> 的矩阵，然后i层，就有一个<img alt="eq?i%5Ctimes%20n%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/20/47/XVOPksz6_o.png"> 的一个张量。</p> 
<p>把每个<img alt="eq?H%5E%7Bi%7D" class="mathcode" src="https://images2.imgbox.com/88/b1/TDGb1tCm_o.png">中对应的节点<img alt="eq?h_%7Bj%7D%5E%7Bi%7D" class="mathcode" src="https://images2.imgbox.com/8e/48/I9vfyTCd_o.png">都串起来，也就是将<img alt="eq?i%5Ctimes%20n%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/18/b3/nHcyU6Q7_o.png">张量中的取出长度为<img alt="eq?i" class="mathcode" src="https://images2.imgbox.com/e2/3b/2FFORDF2_o.png">的一行，也就是某一节点的特征，然后 <img alt="eq?i%5Ctimes%20n%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/cd/00/ZjEqAXpP_o.png">张量就成了一个 <img alt="eq?i%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/5f/94/xMAUerrC_o.png">的矩阵，然后做一个 Transform （乘以一个参数矩阵<img alt="eq?w" class="mathcode" src="https://images2.imgbox.com/7f/95/uoT852Yn_o.png">），最后得到这个节点的特征向量<img alt="eq?y%5E%7Bi%7D" class="mathcode" src="https://images2.imgbox.com/42/f5/peHhoY4g_o.png">。</p> 
<p><img alt="" height="968" src="https://images2.imgbox.com/94/5d/DfvgoWLl_o.png" width="1200"></p> 
<p>最后像NN4G一样将结果放入一个全连接网络，最后得到一个数值。</p> 
<h3 id="%E6%A8%A1%E5%9E%8B%E4%B8%89%EF%BC%9ADGC%EF%BC%88Diffusion%20Graph%20Convolution%EF%BC%89">模型三：DGC（Diffusion Graph Convolution）</h3> 
<p>与DCNN不同的是将所有层的结果进行相加，即<img alt="eq?i" class="mathcode" src="https://images2.imgbox.com/14/15/9zq1uke2_o.png">个<img alt="eq?n%5Ctimes%20d" class="mathcode" src="https://images2.imgbox.com/6a/41/yjkCBH6l_o.png">的矩阵进行相加，与DCNN的区别是一个结果是得到一张图一个结果是得到一个数值。</p> 
<p><img alt="" height="1036" src="https://images2.imgbox.com/c3/ce/4ouCwiTO_o.png" width="1200"></p> 
<h3 id="%E6%A8%A1%E5%9E%8B%E5%9B%9B%EF%BC%9AMoNET%EF%BC%88Mixture%20Model%20Networks%EF%BC%89">模型四：MoNET（Mixture Model Networks）</h3> 
<p><strong>之前只是简单的相加，并没有考虑到一个节点的邻居跟邻居之间的区别（有的邻居可能更重要一点，每个邻居对该点的影响程度不一样）。</strong></p> 
<p><img alt="77cc67a5f1ca4c548bec5bff2496eaf5.png" src="https://images2.imgbox.com/44/d0/2v9GViyX_o.png"></p> 
<h3 id="%E6%A8%A1%E5%9E%8B%E4%BA%94%EF%BC%9AGAT%EF%BC%88Graph%20Attention%20Networks%EF%BC%89">模型五：GAT（Graph Attention Networks）</h3> 
<p><strong>不止是简单的weighted sum, 不是像之前那样定的weight ，而且要让他自己去学习这个weight。<strong>对邻居做</strong>Attention</strong>，就是不同的邻居给出不同的weight。</p> 
<p><img alt="49bf64ddcdda448b81efe053fd08e59a.png" src="https://images2.imgbox.com/fd/83/kM07XBaJ_o.png"></p> 
<p><img alt="9f3a4e8ba931432b9f955d2cc96f93e6.png" src="https://images2.imgbox.com/ef/28/zuJZN6Ry_o.png"></p> 
<h2 id="Spectral-based%20GNN">Spectral-based GNN</h2> 
<p>CNN在卷积的时候会确定一个卷积核，这就是一个特定大小的过滤器，每次只需要考虑kernel范围的信息。但是GNN不行，因为每个节点的邻居都不一样，无法想CNN一样用一个九宫格定义图中某一节点的邻居节点。所以要把图在空间的结构进行思想转换，<strong>将输入的图进行傅里叶转换，采用谱域实现类似的过滤器来做卷积，在给定的卷积核再做傅立叶变化，对两次傅立叶变化的结果相乘，再将结果做反的傅立叶变化得到下一层的图。</strong></p> 
<p><img alt="d752aa2ca50649c3a502fe82995b7707.png" src="https://images2.imgbox.com/a0/0c/tZrff03d_o.png"></p> 
<p> 那如何进行傅里叶变换呢？需要用到信号系统相关知识。</p> 
<h3 id="%E5%9B%BE%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2">图信号的傅里叶变换</h3> 
<p>任何一个周期函数都能等价为一系列的正（余）弦函数的和，这就是傅里叶级数。将一个周期函数经过傅里叶变换，也就是将一个时域上的函数表达，转换为其频域和相位的表示。通过对图片的傅里叶变换，可以根据变化后数据的频率特征，提取图片中的特征，如低频率的轮廓特征，高频率的细节特征。最后结果的输出只要将这些数据再做一次傅里叶反变换即可。</p> 
<p><img alt="" height="1023" src="https://images2.imgbox.com/50/da/77aaC6Av_o.png" width="1200"></p> 
<p>拉普拉斯变化是傅里叶变换的一种改进，与傅里叶相比，它能处理信号函数趋向于无穷大及振幅越来越大的情况，它有两种理解方式：一是这种变换引进了衰减因子，使原信号函数趋于平缓稳定；二是其通过增大傅里叶变换的正弦波，从而改变最后输出函数的振幅。</p> 
<blockquote> 
 <p><strong>定义</strong></p> 
 <p>D为度矩阵，它对角线上的值是从 i 节点出发的所有边的权重之和（对角矩阵）。</p> 
 <p>拉普拉斯矩阵（L）是度矩阵（D）减去邻接矩阵（A），即L = D - A。拉普拉斯矩阵是对称半正定矩阵，因此该矩阵的特征值一定非负，一定有n个线性无关的特征向量，它们是n维空间中的一组标准正交基，组成正交矩阵。</p> 
 <p>将拉普拉斯矩阵（L）进行特征分解即谱分解，是将矩阵分解为其特征值和特征向量表示的矩阵之积的方法。<img alt="L=U\Lambda U^{T}" class="mathcode" src="https://images2.imgbox.com/e0/ee/V7owYE8x_o.png">，其中<img alt="\Lambda" class="mathcode" src="https://images2.imgbox.com/0c/89/76LW8aH6_o.png">为特征值矩阵，<img alt="U" class="mathcode" src="https://images2.imgbox.com/de/b3/Yo8Ljner_o.png">为特征向量。</p> 
</blockquote> 
<p></p> 
<p><img alt="" height="990" src="https://images2.imgbox.com/87/75/fOBGcqVH_o.png" width="1200"></p> 
<p></p> 
<p>在如下的图中，我们把<img alt="f(i)" class="mathcode" src="https://images2.imgbox.com/70/9d/8NfIVlQr_o.png">看做是一个信号的属性大小，，<strong>它可以是一个向量也可以是一个标量</strong>（此文中假定f(0)、f(1)等4个信号都是标量）</p> 
<p class="img-center"><img alt="745a789cf75f4972a56cb3f62a705ee4.png" height="227" src="https://images2.imgbox.com/ed/80/pXYJdfUt_o.png" width="300"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/79/ce/iiD2A6Js_o.png" width="1200"></p> 
<p>上图中每个特征值<img alt="\lambda _{i}" class="mathcode" src="https://images2.imgbox.com/ca/4e/Q8SnRMeb_o.png">对应的特征向量<img alt="U" class="mathcode" src="https://images2.imgbox.com/f4/da/pRhRDLmH_o.png">都对应其相应点在该特征值频率下的强度大小。将信号乘以一个拉普拉斯矩阵<img alt="L" class="mathcode" src="https://images2.imgbox.com/3a/5f/oOJ42Uxj_o.png">，即对其做拉普拉斯变化。下面计算表明，对信号做拉普拉斯变换得到的结果，可以表示某节点与其所有邻域节点的能量差之和。<br>  </p> 
<p>将图做傅里叶变化后，将矩阵L进行特征分解得到的特征向量看做是一组信号值，可根据上图计算的特征值<img alt="\lambda _{i}" class="mathcode" src="https://images2.imgbox.com/c1/ee/fRrjQo5n_o.png">和特征向量<img alt="u_{i}" class="mathcode" src="https://images2.imgbox.com/27/9d/kayxe11C_o.png">将原图在频率上表达。</p> 
<p><img alt="" height="890" src="https://images2.imgbox.com/01/9d/WJZXVyzn_o.png" width="1200"></p> 
<p> 对应的每个特征值就是频率的大小，而每个特征值对应的特征向量的数值就是对应特征值频率下的强度大小（这里暂时不考虑正交的概念）。</p> 
<p></p> 
<p></p> 
<h2 id="GNN%E6%A8%A1%E5%9E%8B%E4%BE%8B%E5%AD%90%E5%88%86%E6%9E%90" style="background-color:transparent;">GNN模型例子分析</h2> 
<pre><code class="language-python">import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv
class GraphConvNet(nn.Module):
def init(self, input_dim, hidden_dim, output_dim):
super(GraphConvNet, self).init()
self.conv1 = GCNConv(input_dim, hidden_dim)
self.conv2 = GCNConv(hidden_dim, output_dim)

def forward(self, x, edge_index):
    x = self.conv1(x, edge_index)
    x = torch.relu(x)
    x = self.conv2(x, edge_index)
    return x

input_dim = 5 # Dimensionality of input features
hidden_dim = 64 # Dimensionality of hidden features
output_dim = 32 # Dimensionality of output features
num_nodes = 100 # Number of nodes in the graph
num_edges = 200 # Number of edges in the graph

x = torch.randn(num_nodes, input_dim)
edge_index = torch.randint(num_nodes, (2, num_edges))

model = GraphConvNet(input_dim, hidden_dim, output_dim)

output = model(x, edge_index)
print(“Output shape:”, output.shape)
</code></pre> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bd4b4db9630fe7b4b7d77575e4dc099c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言经典练习3——[NOIP2008]ISBN号码与圣诞树</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b4172d134eb5d725eed328a609583864/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">软考系分之计算机网络通信方向、同步和交换</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>