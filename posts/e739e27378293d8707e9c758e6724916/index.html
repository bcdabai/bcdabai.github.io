<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>关于Hadoop的Windows环境中本地运行和上传到Linux系统中运行--以员工工资总和序列化为例 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="关于Hadoop的Windows环境中本地运行和上传到Linux系统中运行--以员工工资总和序列化为例" />
<meta property="og:description" content="第一部分：Windows本地运行时 （一）配置环境 （1）准备的东西(版本可以以自己的为准) 可以将以下内容下载到同一个文件夹，容易找到并方便配置环境变量。
①jdk1.8.0_141
②maven3.8.6 链接：maven官网
③hadoop2.7.7 链接：hadoop下载
④hadoop.dll和winutils.exe 提取码：2222 网盘链接：https://pan.baidu.com/s/19IupLMvcDM2R51oKOvBmhQ
⑤IDEA2020.1.2
1.1环境变量的配置 1.1.1：找到环境变量设置，在系统变量中新建以下内容（注意使用自己的路径） 1.1.2 在系统变量的path中添加如下内容： 1.1.3 在cmd中确认安装成功，每个命令都出现相应版本内容即成功： java -version mvn -version hadoop -version 1.1.4 将hadoop.dll和winutils.exe复制到hadoop的bin文件夹下，并将hadoop.dll复制到C:\Windows\System32目录下 1.1.5 修改Maven仓库下载镜像及修改仓库位置 1.1.5.1可以在Maven路径下新建一个叫repository的文件夹,用来存放相关配置 1.1.5.2打开Maven的安装目录–&gt;conf文件夹–&gt;setting.xml，用记事本打开就行，并修改代码如下： &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;settings xmlns=&#34;http://maven.apache.org/SETTINGS/1.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&#34;&gt; &lt;!-- 本地仓库的位置 ，==注意这里的路径改成自己的==--&gt; &lt;localRepository&gt;D:\Linux\apache-maven\repository&lt;/localRepository&gt; &lt;!-- Apache Maven 配置 --&gt; &lt;pluginGroups/&gt; &lt;proxies/&gt; &lt;!-- 私服发布的用户名密码 --&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;deployment&lt;/username&gt; &lt;password&gt;He2019&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;deployment&lt;/username&gt; &lt;password&gt;He2019&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;!-- 阿里云镜像 --&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/e739e27378293d8707e9c758e6724916/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-28T18:32:56+08:00" />
<meta property="article:modified_time" content="2022-10-28T18:32:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">关于Hadoop的Windows环境中本地运行和上传到Linux系统中运行--以员工工资总和序列化为例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Windows_0"></a>第一部分：Windows本地运行时</h2> 
<h2><a id="_1"></a>（一）配置环境</h2> 
<h3><a id="1_2"></a>（1）准备的东西(版本可以以自己的为准)</h3> 
<p>可以将以下内容下载到同一个文件夹，容易找到并方便配置环境变量。<br> ①jdk1.8.0_141<br> ②maven3.8.6 链接：<a href="https://maven.apache.org/download.cgi" rel="nofollow">maven官网</a><br> ③hadoop2.7.7 链接：<a href="http://archive.apache.org/dist/hadoop/core/hadoop-2.7.7/" rel="nofollow">hadoop下载</a><br> ④hadoop.dll和winutils.exe 提取码：2222 网盘链接：https://pan.baidu.com/s/19IupLMvcDM2R51oKOvBmhQ<br> ⑤IDEA2020.1.2</p> 
<h4><a id="11_10"></a>1.1环境变量的配置</h4> 
<h4><a id="111_11"></a>1.1.1：找到环境变量设置，在系统变量中新建以下内容（<mark>注意使用自己的路径</mark>）</h4> 
<p><img src="https://images2.imgbox.com/28/bc/KrUQnDxn_o.png" alt="jdk配置"><br> <img src="https://images2.imgbox.com/8f/bf/m9878Ln7_o.png" alt="maven配置"> <img src="https://images2.imgbox.com/10/f5/3yQPY6lQ_o.png" alt="hadoop配置"></p> 
<h4><a id="112_path_14"></a>1.1.2 在系统变量的path中添加如下内容：</h4> 
<p><img src="https://images2.imgbox.com/cc/b0/tGkCZIwU_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="113_cmd_16"></a>1.1.3 在cmd中确认安装成功，每个命令都出现相应版本内容即成功：</h4> 
<pre><code>java  -version
mvn  -version
hadoop -version
</code></pre> 
<h4><a id="114_hadoopdllwinutilsexehadoopbinhadoopdllCWindowsSystem32_22"></a>1.1.4 将hadoop.dll和winutils.exe复制到hadoop的bin文件夹下，并将hadoop.dll复制到<mark>C:\Windows\System32</mark>目录下</h4> 
<h4><a id="115_Maven_23"></a>1.1.5 修改Maven仓库下载镜像及修改仓库位置</h4> 
<h5><a id="1151Mavenrepository_24"></a>1.1.5.1可以在Maven路径下新建一个叫repository的文件夹,用来存放相关配置</h5> 
<h5><a id="1152Mavenconfsettingxml_25"></a>1.1.5.2打开Maven的安装目录–&gt;conf文件夹–&gt;setting.xml，用记事本打开就行，并修改代码如下：</h5> 
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" 
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt;

    &lt;!-- 本地仓库的位置 ，==注意这里的路径改成自己的==--&gt;
    &lt;localRepository&gt;D:\Linux\apache-maven\repository&lt;/localRepository&gt;
  
    &lt;!-- Apache Maven 配置 --&gt;
    &lt;pluginGroups/&gt;
    &lt;proxies/&gt;

    &lt;!-- 私服发布的用户名密码 --&gt;
    &lt;servers&gt;
        &lt;server&gt;
            &lt;id&gt;releases&lt;/id&gt;
            &lt;username&gt;deployment&lt;/username&gt;
            &lt;password&gt;He2019&lt;/password&gt;
        &lt;/server&gt;
        &lt;server&gt;
            &lt;id&gt;snapshots&lt;/id&gt;
            &lt;username&gt;deployment&lt;/username&gt;
            &lt;password&gt;He2019&lt;/password&gt;
        &lt;/server&gt;
    &lt;/servers&gt;
    
    &lt;!-- 阿里云镜像 --&gt;
    &lt;mirrors&gt;
        &lt;mirror&gt;
            &lt;id&gt;alimaven&lt;/id&gt;
            &lt;name&gt;aliyun maven&lt;/name&gt;
            &lt;!-- https://maven.aliyun.com/repository/public/ --&gt;
            &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
            &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
        &lt;/mirror&gt;
    &lt;/mirrors&gt;

    &lt;!-- 配置: java8, 先从阿里云下载, 没有再去私服下载  --&gt;
    &lt;!-- 20190929 hepengju 测试结果: 影响下载顺序的是profiles标签的配置顺序(后面配置的ali仓库先下载), 而不是activeProfiles的顺序 --&gt;
    &lt;profiles&gt;
        &lt;!-- 全局JDK1.8配置 --&gt;
        &lt;profile&gt;
            &lt;id&gt;jdk1.8&lt;/id&gt;
            &lt;activation&gt;
                &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
                &lt;jdk&gt;1.8&lt;/jdk&gt;
            &lt;/activation&gt;
            &lt;properties&gt;
                &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
                &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
                &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
                &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;

        
        &lt;!-- Nexus私服配置: 第三方jar包下载, 比如oracle的jdbc驱动等 --&gt;
        &lt;profile&gt;
            &lt;id&gt;dev&lt;/id&gt;
            &lt;repositories&gt;
                &lt;repository&gt;
                    &lt;id&gt;nexus&lt;/id&gt;
                    &lt;url&gt;http://nexus.hepengju.cn:8081/nexus/content/groups/public/&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/snapshots&gt;
                &lt;/repository&gt;
            &lt;/repositories&gt;
            &lt;pluginRepositories&gt;
                &lt;pluginRepository&gt;
                    &lt;id&gt;public&lt;/id&gt;
                    &lt;name&gt;Public Repositories&lt;/name&gt;
                    &lt;url&gt;http://nexus.hepengju.cn:8081/nexus/content/groups/public/&lt;/url&gt;
                &lt;/pluginRepository&gt;
            &lt;/pluginRepositories&gt;
        &lt;/profile&gt;
        
        &lt;!-- 阿里云配置: 提高国内的jar包下载速度 --&gt;
        &lt;profile&gt;
            &lt;id&gt;ali&lt;/id&gt;
            &lt;repositories&gt;
                &lt;repository&gt;
                    &lt;id&gt;alimaven&lt;/id&gt;
                    &lt;name&gt;aliyun maven&lt;/name&gt;
                    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/snapshots&gt;
                &lt;/repository&gt;
            &lt;/repositories&gt;
            &lt;pluginRepositories&gt;
                &lt;pluginRepository&gt;
                    &lt;id&gt;alimaven&lt;/id&gt;
                    &lt;name&gt;aliyun maven&lt;/name&gt;
                    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
                &lt;/pluginRepository&gt;
            &lt;/pluginRepositories&gt;
        &lt;/profile&gt;

    &lt;/profiles&gt;
    
    &lt;!-- 激活配置 --&gt; 
    &lt;activeProfiles&gt;
        &lt;activeProfile&gt;jdk1.8&lt;/activeProfile&gt;
        &lt;activeProfile&gt;dev&lt;/activeProfile&gt;
        &lt;activeProfile&gt;ali&lt;/activeProfile&gt;
    &lt;/activeProfiles&gt;
&lt;/settings&gt;
</code></pre> 
<h4><a id="116_hadoop77datadatadatanodenamenodeetchadoop_142"></a>1.1.6 在hadoop-.7.7目录下创建data文件夹，并在data下再创建datanode和namenode文件夹，并在etc/hadoop目录下修改以下文件</h4> 
<h5><a id="1161_coresitexml_143"></a>1.1.6.1 修改core-site.xml</h5> 
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
       &lt;name&gt;fs.defaultFS&lt;/name&gt;
       &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h5><a id="1162_mapredsitexmltemplate_152"></a>1.1.6.2 修改mapred-site.xml.template</h5> 
<pre><code>&lt;configuration&gt;
	&lt;property&gt;
       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
       &lt;value&gt;yarn&lt;/value&gt;
   	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h5><a id="1163_hdfssitexml_161"></a>1.1.6.3 修改hdfs-site.xml</h5> 
<pre><code>&lt;configuration&gt;
   &lt;property&gt;
	  &lt;name&gt;dfs.replication&lt;/name&gt;
	  &lt;value&gt;1&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
	  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
	  &lt;value&gt;/D:/Linux/hadoop-2.7.7/data/namenode&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;/D:/Linux/hadoop-2.7.7/data/datanode&lt;/value&gt;
   &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h5><a id="1164_yarnsitexml_178"></a>1.1.6.4 修改yarn-site.xml</h5> 
<pre><code>&lt;configuration&gt;
&lt;!-- Site specific YARN configuration properties --&gt;
	&lt;property&gt;
		 &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		 &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		 &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
		 &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		 &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
		 &lt;value&gt;1024&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		  &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
		  &lt;value&gt;4096&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		  &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
		  &lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h5><a id="1165_hadoopenvcmdJAVA_HOMEProgram__FilesPROGRA1_204"></a>1.1.6.5 双击打开hadoop-env.cmd，如果打不开就用记事本打开，注意：如果你的JAVA_HOME路径中含有空格，如你放在了Program Files文件夹下，需要把空格替换成PROGRA~1</h5> 
<pre><code>set JAVA_HOME=D:\Java\jdk1.8.0_212        //没有空格时
set JAVA_HOME=D:\PROGRA~1\jdk1.8.0_212     //有空格时
</code></pre> 
<h4><a id="117_cmdhdfs_209"></a>1.1.7 打开cmd，格式化hdfs</h4> 
<pre><code>hdfs namenode -format
</code></pre> 
<h4><a id="118_hadoop_213"></a>1.1.8 启动hadoop。弹出四个页面，并出现如下进程才算成功</h4> 
<pre><code>&gt;d: 
&gt;cd %HADOOP_HOME%\sbin 
&gt;start-all     //此时会弹出四个命令框
&gt;jps
18096 DataNode
15012 ResourceManager
15268 NodeManager
11944 Jps
15564 NameNode
</code></pre> 
<h2><a id="WindowsIDEAmaven_225"></a>(二)Windows环境下，IDEA中创建maven工程，以各部门员工工资总和为例</h2> 
<h3><a id="21IDEAmaven_226"></a>2.1配置IDEA的maven</h3> 
<h4><a id="211FilesettingsMaven_227"></a>2.1.1点击File—&gt;settings—&gt;Maven,注意使用自己的路径</h4> 
<p><img src="https://images2.imgbox.com/6b/70/xMi8AzXz_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_229"></a>2.2创建项目</h3> 
<h4><a id="221_230"></a>2.2.1数据准备</h4> 
<h5><a id="2211hadoop277datainput_231"></a>2.2.1.1可以在hadoop-2.7.7的目录下创建data—&gt;input文件夹,用来保存数据源</h5> 
<p><img src="https://images2.imgbox.com/1f/a0/HQNBYQS7_o.png" alt=""></p> 
<h4><a id="222maven_233"></a>2.2.2创建项目，选择maven</h4> 
<h4><a id="223pomxml_mavenhttpsmvnrepositorycom_234"></a>2.2.3修改pom.xml，添加相关依赖，可以在 <a href="https://mvnrepository.com/" rel="nofollow">maven相关配置</a>中搜索自己需要的，如下图所示：</h4> 
<p><img src="https://images2.imgbox.com/c8/c8/EOubQHzK_o.png" alt="搜索hadoop"><br> <img src="https://images2.imgbox.com/b0/cf/D5PELI9d_o.png" alt="找到对应版本"><br> <img src="https://images2.imgbox.com/e8/40/12tdQrbX_o.png" alt="复制代码"></p> 
<h4><a id="224_238"></a>2.2.4目录创建，代码运行</h4> 
<p><img src="https://images2.imgbox.com/83/e6/ionu3tEe_o.png" alt="建目录"></p> 
<h5><a id="2241_Employee_240"></a>2.2.4.1 创建Employee类：</h5> 
<pre><code>package cn.zf.mapreduce;

import org.apache.hadoop.io.Writable;

import javax.jnlp.JNLPRandomAccessFile;
import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

public class Employee implements Writable {
    private int empno;
    private String ename;
    private String job;
    private int mgr;
    private String hiredate;
    private int sal;
    private int comm;
    private int deptno;

    @Override
    public void readFields(DataInput input) throws IOException {
        this.empno = input.readInt();
        this.ename = input.readUTF();
        this.job = input.readUTF();
        this.mgr = input.readInt();
        this.hiredate = input.readUTF();
        this.sal = input.readInt();
        this.comm = input.readInt();
        this.deptno = input.readInt();
    }
    @Override
    public void write(DataOutput output) throws IOException {
        output.writeInt(this.empno);
        output.writeUTF(this.ename);
        output.writeUTF(this.job);
        output.writeInt(this.mgr);
        output.writeUTF(this.hiredate);
        output.writeInt(this.sal);
        output.writeInt(this.comm);
        output.writeInt(this.deptno);

    }
    public int getEmpno() {
        return empno;
    }

    public void setEmpno(int empno) {
        this.empno = empno;
    }

    public String getEname() {
        return ename;
    }

    public void setEname(String ename) {
        this.ename = ename;
    }

    public String getJob() {
        return job;
    }

    public void setJob(String job) {
        this.job = job;
    }

    public int getMgr() {
        return mgr;
    }

    public void setMgr(int mgr) {
        this.mgr = mgr;
    }

    public String getHiredate() {
        return hiredate;
    }

    public void setHiredate(String hiredate) {
        this.hiredate = hiredate;
    }

    public int getSal() {
        return sal;
    }

    public void setSal(int sal) {
        this.sal = sal;
    }

    public int getComm() {
        return comm;
    }

    public void setComm(int comm) {
        this.comm = comm;
    }

    public int getDeptno() {
        return deptno;
    }

    public void setDeptno(int deptno) {
        this.deptno = deptno;
    }


}
</code></pre> 
<h5><a id="2242_EmployeeMapper_351"></a>2.2.4.2 创建EmployeeMapper类：</h5> 
<pre><code>package cn.zf.mapreduce;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class EmployeeMapper extends Mapper&lt;LongWritable, Text, IntWritable, Employee&gt; {

    @Override
    protected void map(LongWritable key1, Text value1,Context context)
            throws IOException, InterruptedException {
        String data = value1.toString();
        String[] words = data.split(",");
        Employee e = new Employee();
        e.setEmpno(Integer.parseInt(words[0]));
        e.setEname(words[1]);
        e.setJob(words[2]);
        try{
            e.setMgr(Integer.parseInt(words[3]));
        }catch(Exception ex){
            e.setMgr(-1);
        }
        e.setHiredate(words[4]);
        e.setSal(Integer.parseInt(words[5]));
        try{
            e.setComm(Integer.parseInt(words[6]));
        }catch(Exception ex){
            e.setComm(0);
        }
        e.setDeptno(Integer.parseInt(words[7]));
        context.write(new IntWritable(e.getDeptno()),
                e);
    }

}


</code></pre> 
<h5><a id="2243_EmployeeReducer_394"></a>2.2.4.3 创建EmployeeReducer类：</h5> 
<pre><code>package cn.zf.mapreduce;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class EmployeeReducer extends Reducer&lt;IntWritable, Employee, IntWritable, IntWritable&gt; {

    @Override
    protected void reduce(IntWritable k3, Iterable&lt;Employee&gt; v3,Context context)
            throws IOException, InterruptedException {
        //取出v3中的每个员工 进行工资求和
        int total = 0;
        for(Employee e:v3){
            total = total + e.getSal();
        }

        //输出
        context.write(k3, new IntWritable(total));
    }

}




</code></pre> 
<h5><a id="2244_EmployeeMain_424"></a>2.2.4.4 创建EmployeeMain类：</h5> 
<pre><code>package cn.zf.mapreduce;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class EmployeeMain {
    public static void main(String[] args) throws Exception {
        //  创建一个job
        Job job = Job.getInstance(new Configuration());
        job.setJarByClass(EmployeeMain.class);

        //指定job的mapper和输出的类型   k2  v2
        job.setMapperClass(EmployeeMapper.class);
        job.setMapOutputKeyClass(IntWritable.class);
        job.setMapOutputValueClass(Employee.class);

        //指定job的reducer和输出的类型  k4   v4
        job.setReducerClass(EmployeeReducer.class);
        job.setOutputKeyClass(IntWritable.class);
        job.setOutputValueClass(IntWritable.class);
        
        //Windows本地运行下，指定job的输入和输出的路径
        FileInputFormat.setInputPaths(job, new Path("D:\\Linux\\hadoop-2.7.7\\data\\input\\emp.csv"));
        FileOutputFormat.setOutputPath(job, new Path("D:\\Linux\\hadoop-2.7.7\\data\\out\\salary_out3"));
        /** 上传到Ubuntu时用如下代码
        FileInputFormat.setInputPaths(job, new Path(args[1]));
		FileOutputFormat.setOutputPath(job, new Path(args[2]));
        */

        //执行任务
        job.waitForCompletion(true);
    }

}

</code></pre> 
<h4><a id="225_466"></a>2.2.5运行结果</h4> 
<p><img src="https://images2.imgbox.com/ef/78/OEWGrR4i_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/35/72/j14hINpw_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="WindowsIDEALinux_470"></a>第二部分：将在Windows的IDEA中写的代码，上传到Linux环境中运行</h2> 
<h2><a id="_471"></a>（一）准备工作和思路</h2> 
<h3><a id="11_Xshell5Xftp5_472"></a>1.1 上传时需要的工具：Xshell5、Xftp5</h3> 
<h3><a id="12_WindowsIDEAjarLinux_473"></a>1.2 思路：在Windows的IDEA中开发，写代码，然后打成jar包上传的你的Linux中</h3> 
<h2><a id="IDEAjar__2244EmployeeMain_474"></a>（二）在IDEA中完成项目代码后，打成jar包并上传。 <mark>注意：主类的文件输入输出路径的改变，在第一部分的2.2.4.4创建EmployeeMain时，代码注释中有写</mark></h2> 
<h3><a id="1IDEAjar_475"></a>1.在IDEA中依次点击如下内容，生成jar包</h3> 
<h4><a id="111FileProject_StructureArtifacts_476"></a>1.1.1点击File–&gt;Project Structure–&gt;Artifacts,接下来根据图片依次点击</h4> 
<p><img src="https://images2.imgbox.com/4e/f4/0g1RsaZ5_o.jpg" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/fd/6b/mRQS7JWb_o.jpg" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/45/f6/kLcmdfHs_o.jpg" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/7e/51/V74Amf2C_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="112__111Apply_482"></a>1.1.2 根据1.1.1步骤生成的结果形式如下图，点击Apply</h4> 
<p><img src="https://images2.imgbox.com/68/ea/a2a3RLTx_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="113Rebuild_ProjectIDEA_485"></a>1.1.3如图位置，点击Rebuild Project,然后在IDEA的左下角会出现第二张图所示内容</h4> 
<p><img src="https://images2.imgbox.com/a9/4f/Y185T7eQ_o.jpg" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d8/19/S2PDAZO8_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="114__Build_Artifactshttpsimgblogcsdnimgcn736bc7ee3cf140518dbec5380020e685jpeg_490"></a>1.1.4 点击Build Artifacts,会弹出如第二张图所示<img src="https://images2.imgbox.com/40/17/yYuzp40b_o.jpg" alt="在这里插入图片描述"></h4> 
<p><img src="https://images2.imgbox.com/b2/01/MBtyVzhp_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="115_out_492"></a>1.1.5 在左侧会生成out文件夹</h4> 
<p><img src="https://images2.imgbox.com/1b/2e/fGl1aviS_o.jpg" alt="在这里插入图片描述"></p> 
<h3><a id="2Xshell5_495"></a>2.打开Xshell5</h3> 
<p>(1)成功连接上自己的Ubuntu之后，点击下面的图标即Xftp,将自己生成的jar包拖拽到Ubuntu中，生成的jar包可以在自己的IDEA项目工作环境中找到。<br> (2)将数据源emp.csv也上传到Ubuntu中<br> <img src="https://images2.imgbox.com/5e/89/pL84nvG6_o.jpg" alt="在这里插入图片描述"></p> 
<h3><a id="21Ubuntu_500"></a>2.1上传成功后，可以在Ubuntu中查看</h3> 
<p><img src="https://images2.imgbox.com/1e/b8/BUHyvOZW_o.jpg" alt="在这里插入图片描述"></p> 
<h3><a id="22_UbuntuWindowsXshell5_503"></a>2.2 在Ubuntu的终端或者Windows的Xshell5中执行接下来的代码都可以</h3> 
<h4><a id="221_empcsvhdfsWindowsUbuntu50070hdfsB18041739_504"></a>2.2.1 需要将数据源emp.csv上传到hdfs文件系统中，并且可以在Windows的浏览器中，输入网址：你的Ubuntu用户名：50070，查看hdfs文件系统更直观。例如，我的用户名为B18041739</h4> 
<p><img src="https://images2.imgbox.com/c1/8d/FbKa3wfj_o.png" alt="在这里插入图片描述"></p> 
<pre><code>hdfs dfs -put emp.csv /input/   //上传到hdfs的代码
</code></pre> 
<p><img src="https://images2.imgbox.com/ea/57/ef0V3V0R_o.png" alt=""></p> 
<h4><a id="222_hadoop__jar__jar__IDEA_____512"></a>2.2.2 代码格式：hadoop jar jar包名字 IDEA项目中主类所在路径 数据源所在位置 输出路径，例如：</h4> 
<pre><code>hadoop jar serialsalarytol.jar cn.zf.mapreduce.EmployeeMain  /input/emp.csv /output/salary_out
</code></pre> 
<h4><a id="223___516"></a>2.2.3 查看输出结果</h4> 
<p><img src="https://images2.imgbox.com/17/0e/WqLvncGj_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f1/8f/IetR6kF9_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/030d12c9a23801984a6623e0f358d8c5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">贪吃蛇小项目C语言版（基于LINUX操作系统下）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3a6b3573270ad112065aa541ae139926/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">每天五分钟机器学习：如何计算模型的假阳性率和真阳性率？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>