<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>word2vec之 cbow 和skip-gram - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="word2vec之 cbow 和skip-gram" />
<meta property="og:description" content="word2vec是google在2013年推出的一个NLP工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。
Cbow和skip-gram 是word2vec中两种关键模型，它们从不同角度来描述了周围词与当前词的关系；
在cbow方法中，是用周围词预测中心词（多对一，后验），从而利用中心词的预测结果情况，使用梯度下降法，不断的去调整周围词的向量。当训练完成之后，每个词都会作为中心词。把周围词的词向量进行了调整，这样也就获得了整个文本里面所有词的词向量。cbow的对周围词的调整是统一的：求出的梯度的值会同样的作用到每个周围词的词向量当中去，cbow预测行为的次数跟整个文本的词数几乎是相等的（每次预测行为才会进行一次反向传播, 而往往这也是最耗时的部分），复杂度大概是O(V);
skip-gram 与之相反，使用中心词预测周围词（一对多，先验），skip-gram会利用周围的词的预测结果情况，使用梯度下降不断的调整中心词的词向量，最终所有的文本遍历完毕之后，也就得到了文本所有词的词向量。对比而言，skip-gram进行预测的次数多于cbow的：因每个词作为中心词时，皆需使用周围词进行预测一回。因此相当于比cbow多进行了K次（假设K为窗口大小），时间的复杂度约为O(KV)，训练时间相对比cbow要长。
but在skip-gram当中，每个词皆受都要收到周围的词的影响，每个词在作为中心词时，都要进行K次的预测、调整。因此， 当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确。因为尽管cbow从另外一个角度来说，某个词也是会受到多次周围词的影响（多次将其包含在内的窗口移动），进行词向量的跳帧，但是他的调整是跟周围的词一起调整的，分值会平均分到该词上， 相当于该生僻词没有收到专门的训练，它只是沾周围词的光。
Cbow和skip-gram 通常可分为三层，输入层(input)，映射层(projection)和输出层(output)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/fa45d1d0c838a9245842fb03686862b6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-02T19:35:23+08:00" />
<meta property="article:modified_time" content="2018-08-02T19:35:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">word2vec之 cbow 和skip-gram</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>word2vec是google在2013年推出的一个NLP工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。</p> 
<p>Cbow和skip-gram 是word2vec中两种关键模型，它们从不同角度来描述了周围词与当前词的关系；</p> 
<p>在cbow方法中，是用周围词预测中心词（多对一，后验），从而利用中心词的预测结果情况，使用梯度下降法，不断的去调整周围词的向量。当训练完成之后，每个词都会作为中心词。把周围词的词向量进行了调整，这样也就获得了整个文本里面所有词的词向量。cbow的对周围词的调整是统一的：求出的梯度的值会同样的作用到每个周围词的词向量当中去，cbow预测行为的次数跟整个文本的词数几乎是相等的（每次预测行为才会进行一次反向传播, 而往往这也是最耗时的部分），复杂度大概是O(V);</p> 
<p>skip-gram 与之相反，使用中心词预测周围词（一对多，先验），skip-gram会利用周围的词的预测结果情况，使用梯度下降不断的调整中心词的词向量，最终所有的文本遍历完毕之后，也就得到了文本所有词的词向量。对比而言，skip-gram进行预测的次数多于cbow的：因每个词作为中心词时，皆需使用周围词进行预测一回。因此相当于比cbow多进行了K次（假设K为窗口大小），时间的复杂度约为O(KV)，训练时间相对比cbow要长。<br><span style="color:#3399ea;">but在skip-gram当中，每个词皆受都要收到周围的词的影响，每个词在作为中心词时，都要进行K次的预测、调整。因此， 当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确。因为尽管cbow从另外一个角度来说，某个词也是会受到多次周围词的影响（多次将其包含在内的窗口移动），进行词向量的跳帧，但是他的调整是跟周围的词一起调整的，分值会平均分到该词上， 相当于该生僻词没有收到专门的训练，它只是沾周围词的光。</span></p> 
<p>Cbow和skip-gram 通常可分为三层，输入层(input)，映射层(projection)和输出层(output)</p> 
<p><img alt="" class="has" height="486" src="https://images2.imgbox.com/60/67/hAkN0ceM_o.png" width="728"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3aeb785e7b64fdcaad8f95f2f428ee4c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">前后端分离的前生今世</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f4a0d5c45b7d701d63d8181d97ade3fb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">scrapy框架之custom_settings讲解（详细）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>