<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Scrapy爬虫小技巧02：HTTP status code is not handled or not allowed的解决方法 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Scrapy爬虫小技巧02：HTTP status code is not handled or not allowed的解决方法" />
<meta property="og:description" content=" 在scrapy爬虫的过程中出现 HTTP status code is not handled or not allowed 的问题导致爬虫无法继续，如下截图：
解决方式：
在settings.py文件中添加： HTTPERROR_ALLOWED_CODES = [302]
截图中报错302，就在括号里添加302。若报错403就添加403。 附加说明：
scrapy框架中有许多默认设置可参阅：scrapy的settings设置（一） 相关笔记：
Python相关实用技巧01：安装Python库超实用方法，轻松告别失败！Python相关实用技巧02：Python2和Python3的区别Python相关实用技巧03：14个对数据科学最有用的Python库Python相关实用技巧04：网络爬虫之Scrapy框架及案例分析Python相关实用技巧05：yield关键字的使用Scrapy爬虫小技巧01：轻松获取cookiesScrapy爬虫小技巧02：HTTP status code is not handled or not allowed的解决方法数据分析学习总结笔记01：情感分析数据分析学习总结笔记02：聚类分析及其R语言实现数据分析学习总结笔记03：数据降维经典方法数据分析学习总结笔记04：异常值处理数据分析学习总结笔记05：缺失值分析及处理数据分析学习总结笔记06：T检验的原理和步骤数据分析学习总结笔记07：方差分析数据分析学习总结笔记07：回归分析概述数据分析学习总结笔记08：数据分类典型方法及其R语言实现数据分析学习总结笔记09：文本分析数据分析学习总结笔记10：网络分析 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/2dc27e017680a62d88d49620373d85af/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-08T11:37:06+08:00" />
<meta property="article:modified_time" content="2020-04-08T11:37:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Scrapy爬虫小技巧02：HTTP status code is not handled or not allowed的解决方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>在scrapy爬虫的过程中出现 <strong>HTTP status code is not handled or not allowed</strong> 的问题导致爬虫无法继续，如下截图：<br> <img src="https://images2.imgbox.com/4a/76/tTuD5gHU_o.png" alt="302"><br> <strong>解决方式：</strong></p> 
<ul><li>在settings.py文件中添加：</li></ul> 
<blockquote> 
 <p>HTTPERROR_ALLOWED_CODES = [302]</p> 
</blockquote> 
<ul><li>截图中报错302，就在括号里添加302。若报错403就添加403。</li></ul> 
<p><strong>附加说明：</strong></p> 
<ul><li>scrapy框架中有许多默认设置</li><li>可参阅：<a href="https://blog.csdn.net/Lan_cer/article/details/87554025?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1">scrapy的settings设置（一）</a></li></ul> 
<p><strong>相关笔记：</strong></p> 
<ol><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105319079">Python相关实用技巧01：安装Python库超实用方法，轻松告别失败！</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105321886">Python相关实用技巧02：Python2和Python3的区别</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105322144">Python相关实用技巧03：14个对数据科学最有用的Python库</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105358734">Python相关实用技巧04：网络爬虫之Scrapy框架及案例分析</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105365367">Python相关实用技巧05：yield关键字的使用</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105375145">Scrapy爬虫小技巧01：轻松获取cookies</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105382622">Scrapy爬虫小技巧02：HTTP status code is not handled or not allowed的解决方法</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105237852">数据分析学习总结笔记01：情感分析</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105245544">数据分析学习总结笔记02：聚类分析及其R语言实现</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105254450">数据分析学习总结笔记03：数据降维经典方法</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105262138">数据分析学习总结笔记04：异常值处理</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105280345">数据分析学习总结笔记05：缺失值分析及处理</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105280691">数据分析学习总结笔记06：T检验的原理和步骤</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105284577">数据分析学习总结笔记07：方差分析</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105285569">数据分析学习总结笔记07：回归分析概述</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105287543">数据分析学习总结笔记08：数据分类典型方法及其R语言实现</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105301138">数据分析学习总结笔记09：文本分析</a></li><li><a href="https://blog.csdn.net/weixin_41961559/article/details/105306033">数据分析学习总结笔记10：网络分析</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1f3ba71da4b2af1b2b95f799ca7c8dde/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">React 入门 02 - JSX</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d6d74f85173ec4900a6fae91a0b54f35/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python 去除所有的中文 英文标点符号</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>