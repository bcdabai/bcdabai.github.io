<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Mask R-CNN详解 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Mask R-CNN详解" />
<meta property="og:description" content="论文题目：Mask R-CNN
论文链接：论文链接
论文代码：Facebook代码链接；Tensorflow版本代码链接； Keras and TensorFlow版本代码链接；MxNet版本代码链接
一、Mask R-CNN是什么，可以做哪些任务？
图1 Mask R-CNN整体架构
Mask R-CNN是一个实例分割（Instance segmentation）算法，可以用来做“目标检测”、“目标实例分割”、“目标关键点检测”。
1. 实例分割（Instance segmentation）和语义分割（Semantic segmentation）的区别与联系
联系：语义分割和实例分割都是目标分割中的两个小的领域，都是用来对输入的图片做分割处理；
区别：
图2 实例分割与语义分割区别
1. 通常意义上的目标分割指的是语义分割，语义分割已经有很长的发展历史，已经取得了很好地进展，目前有很多的学者在做这方面的研究；然而实例分割是一个从目标分割领域独立出来的一个小领域，是最近几年才发展起来的，与前者相比，后者更加复杂，当前研究的学者也比较少，是一个有研究空间的热门领域，如图1所示，这是一个正在探索中的领域；
图3 实例分割与语义分割区别
2. 观察图3中的c和d图，c图是对a图进行语义分割的结果，d图是对a图进行实例分割的结果。两者最大的区别就是图中的&#34;cube对象&#34;，在语义分割中给了它们相同的颜色，而在实例分割中却给了不同的颜色。即实例分割需要在语义分割的基础上对同类物体进行更精细的分割。
注：很多博客中都没有完全理解清楚这个问题，很多人将这个算法看做语义分割，其实它是一个实例分割算法。
2. Mask R-CNN可以完成的任务
图4 Mask R-CNN进行目标检测与实例分割
图5 Mask R-CNN进行人体姿态识别
总之，Mask R-CNN是一个非常灵活的框架，可以增加不同的分支完成不同的任务，可以完成目标分类、目标检测、语义分割、实例分割、人体姿势识别等多种任务，真不愧是一个好算法！
3. Mask R-CNN预期达到的目标
高速高准确率（高的分类准确率、高的检测准确率、高的实例分割准确率等）简单直观易于使用 4. 如何实现这些目标
高速和高准确率：为了实现这个目的，作者选用了经典的目标检测算法Faster-rcnn和经典的语义分割算法FCN。Faster-rcnn可以既快又准的完成目标检测的功能；FCN可以精准的完成语义分割的功能，这两个算法都是对应领域中的经典之作。Mask R-CNN比Faster-rcnn复杂，但是最终仍然可以达到5fps的速度，这和原始的Faster-rcnn的速度相当。由于发现了ROI Pooling中所存在的像素偏差问题，提出了对应的ROIAlign策略，加上FCN精准的像素MASK，使得其可以获得高准确率。
简单直观：整个Mask R-CNN算法的思路很简单，就是在原始Faster-rcnn算法的基础上面增加了FCN来产生对应的MASK分支。即Faster-rcnn &#43; FCN，更细致的是 RPN &#43; ROIAlign &#43; Fast-rcnn &#43; FCN。
易于使用：整个Mask R-CNN算法非常的灵活，可以用来完成多种任务，包括目标分类、目标检测、语义分割、实例分割、人体姿态识别等多个任务，这将其易于使用的特点展现的淋漓尽致。我很少见到有哪个算法有这么好的扩展性和易用性，值得我们学习和借鉴。除此之外，我们可以更换不同的backbone architecture和Head Architecture来获得不同性能的结果。
二、Mask R-CNN框架解析
图6 Mask R-CNN算法框架" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/4cd7e519d5a932af81f2d10c574c8d3b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-15T22:12:52+08:00" />
<meta property="article:modified_time" content="2023-03-15T22:12:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Mask R-CNN详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>论文题目：</strong>Mask R-CNN</p> 
<p><strong>论文链接：</strong><a href="https://arxiv.org/abs/1703.06870" rel="nofollow" title="论文链接">论文链接</a></p> 
<p><strong>论文代码：</strong>Facebook<a href="https://github.com/facebookresearch/Detectron" title="代码链接">代码链接</a>；Tensorflow版本<a href="https://github.com/CharlesShang/FastMaskRCNN" title="代码链接">代码链接</a>；<span style="color:#24292e;"> Keras and TensorFlow版本<a href="https://github.com/matterport/Mask_RCNN" title="代码链接">代码链接</a>；MxNet版本<a href="https://github.com/TuSimple/mx-maskrcnn" title="代码链接">代码链接</a></span></p> 
<p></p> 
<p><strong>一、Mask R-CNN是什么，可以做哪些任务？</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/30/89/eVIiGVo4_o.png"></p> 
<p>图1 Mask R-CNN整体架构</p> 
<p><strong>Mask R-CNN是一个实例分割（Instance segmentation）算法，可以用来做“目标检测”、“目标实例分割”、“目标关键点检测”。</strong></p> 
<p><strong>1. 实例分割（Instance segmentation）和语义分割（Semantic segmentation）的区别与联系</strong></p> 
<p><strong>联系：</strong>语义分割和实例分割都是目标分割中的两个小的领域，都是用来对输入的图片做分割处理；</p> 
<p><strong>区别：</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/41/de/RfDy6nlO_o.jpg"></p> 
<p>图2 实例分割与语义分割区别</p> 
<p>1.  通常意义上的目标分割指的是语义分割，语义分割已经有很长的发展历史，已经取得了很好地进展，目前有很多的学者在做这方面的研究；然而实例分割是一个从目标分割领域独立出来的一个小领域，是最近几年才发展起来的，与前者相比，后者更加复杂，当前研究的学者也比较少，是一个有研究空间的热门领域，如图1所示，这是一个正在探索中的领域；</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/46/23/gVtEDS4R_o.jpg"></p> 
<p>图3 实例分割与语义分割区别</p> 
<p>2.  观察图3中的c和d图，c图是对a图进行语义分割的结果，d图是对a图进行实例分割的结果。两者最大的区别就是图中的"cube对象"，在语义分割中给了它们相同的颜色，而在实例分割中却给了不同的颜色。<strong>即实例分割需要在语义分割的基础上对同类物体进行更精细的分割。</strong></p> 
<p>注：很多博客中都没有完全理解清楚这个问题，很多人将这个算法看做语义分割，其实它是一个实例分割算法。</p> 
<p><strong>2. Mask R-CNN可以完成的任务</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/71/4f/UwktZBUi_o.jpg"></p> 
<p>图4 Mask R-CNN进行目标检测与实例分割</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/02/32/8x7RpVTB_o.jpg"></p> 
<p>图5 Mask R-CNN进行人体姿态识别</p> 
<p><strong>总之，Mask R-CNN是一个非常灵活的框架，可以增加不同的分支完成不同的任务，可以完成目标分类、目标检测、语义分割、实例分割、人体姿势识别等多种任务，真不愧是一个好算法！</strong></p> 
<p><strong>3. Mask R-CNN预期达到的目标</strong></p> 
<ul><li><strong>高速</strong></li><li><strong>高准确率（高的分类准确率、高的检测准确率、高的实例分割准确率等）</strong></li><li><strong>简单直观</strong></li><li><strong>易于使用</strong></li></ul> 
<p><strong>4. 如何实现这些目标</strong></p> 
<p><strong>高速和高准确率：</strong>为了实现这个目的，作者选用了经典的目标检测算法Faster-rcnn和经典的语义分割算法FCN。Faster-rcnn可以既快又准的完成目标检测的功能；FCN可以精准的完成语义分割的功能，这两个算法都是对应领域中的经典之作。Mask R-CNN比Faster-rcnn复杂，但是最终仍然可以达到5fps的速度，这和原始的Faster-rcnn的速度相当。由于发现了ROI Pooling中所存在的像素偏差问题，提出了对应的ROIAlign策略，加上FCN精准的像素MASK，使得其可以获得高准确率。</p> 
<p><strong>简单直观：</strong>整个Mask R-CNN算法的思路很简单，就是在原始Faster-rcnn算法的基础上面增加了FCN来产生对应的MASK分支。即Faster-rcnn + FCN，更细致的是 RPN + ROIAlign + Fast-rcnn + FCN。</p> 
<p><strong>易于使用：</strong>整个Mask R-CNN算法非常的灵活，可以用来完成多种任务，包括目标分类、目标检测、语义分割、实例分割、人体姿态识别等多个任务，这将其易于使用的特点展现的淋漓尽致。我很少见到有哪个算法有这么好的扩展性和易用性，值得我们学习和借鉴。除此之外，我们可以更换不同的backbone architecture和Head Architecture来获得不同性能的结果。<br>  </p> 
<p><strong>二、Mask R-CNN框架解析</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/27/84/oag3L9Zt_o.jpg"></p> 
<p>图6 Mask R-CNN算法框架</p> 
<p><strong>1. Mask R-CNN算法步骤</strong></p> 
<ul><li>首先，输入一幅你想处理的图片，然后进行对应的预处理操作，或者预处理后的图片；</li><li>然后，将其输入到一个预训练好的神经网络中（ResNeXt等）获得对应的feature map；</li><li>接着，对这个feature map中的每一点设定预定个的ROI，从而获得多个候选ROI；</li><li>接着，将这些候选的ROI送入RPN网络进行二值分类（前景或背景）和BB回归，过滤掉一部分候选的ROI；</li><li>接着，对这些剩下的ROI进行ROIAlign操作（即先将原图和feature map的pixel对应起来，然后将feature map和固定的feature对应起来）；</li><li>最后，对这些ROI进行分类（N类别分类）、BB回归和MASK生成（在每一个ROI里面进行FCN操作）。</li></ul> 
<p><strong>2. Mask R-CNN架构分解</strong></p> 
<p>在这里，我将Mask R-CNN分解为如下的3个模块，Faster-rcnn、ROIAlign和FCN。然后分别对这3个模块进行讲解，这也是该算法的核心<strong>。</strong></p> 
<p><strong>3. Faster-rcnn（该算法请参考<a href="http://blog.csdn.net/WZZ18191171661/article/details/79439212" title="该链接">该链接</a>，我进行了详细的分析）</strong></p> 
<p><strong>4. FCN</strong></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/fb/cb/T76QwPe0_o.jpg"></strong></p> 
<p>图7 FCN网络架构</p> 
<p>FCN算法是一个经典的语义分割算法，可以对图片中的目标进行准确的分割。其总体架构如上图所示，它是一个端到端的网络，主要的模快包括卷积和去卷积，即先对图像进行卷积和池化，使其feature map的大小不断减小；然后进行反卷积操作，即进行插值操作，不断的增大其feature map，最后对每一个像素值进行分类。从而实现对输入图像的准确分割。具体的细节请参考<a href="https://arxiv.org/abs/1411.4038" rel="nofollow" title="该链接">该链接</a>。</p> 
<p><strong>5. ROIPooling和ROIAlign的分析与比较</strong></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/1a/f2/KmwHxI7K_o.jpg"></strong></p> 
<p>图8 ROIPooling和ROIAlign的比较</p> 
<p></p> 
<p></p> 
<p><strong>如图8所示，ROI Pooling和ROIAlign最大的区别是：前者使用了两次量化操作，而后者并没有采用量化操作，使用了线性插值算法，具体的解释如下所示。</strong></p> 
<p></p> 
<p></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/7e/07/V5KJj7Ul_o.png"></strong></p> 
<p>图9 ROI Pooling技术</p> 
<p>如图9所示，为了得到固定大小（7X7）的feature map，我们需要做两次量化操作：1）图像坐标 — feature map坐标，2）feature map坐标 — ROI feature坐标。我们来说一下具体的细节，如图我们输入的是一张800x800的图像，在图像中有两个目标（猫和狗），狗的BB大小为665x665，经过VGG16网络后，我们可以获得对应的feature map，如果我们对卷积层进行Padding操作，我们的图片经过卷积层后保持原来的大小，但是由于池化层的存在，我们最终获得feature map 会比原图缩小一定的比例，这和Pooling层的个数和大小有关。在该VGG16中，我们使用了5个池化操作，每个池化操作都是2Pooling，因此我们最终获得feature map的大小为800/32 x 800/32 = 25x25（是整数），但是将狗的BB对应到feature map上面，我们得到的结果是665/32 x 665/32 = 20.78 x 20.78，结果是浮点数，含有小数，但是我们的像素值可没有小数，那么作者就对其进行了量化操作（即取整操作），即其结果变为20 x 20，在这里引入了第一次的量化误差；然而我们的feature map中有不同大小的ROI，但是我们后面的网络却要求我们有固定的输入，因此，我们需要将不同大小的ROI转化为固定的ROI feature，在这里使用的是7x7的ROI feature，那么我们需要将20 x 20的ROI映射成7 x 7的ROI feature，其结果是 20 /7 x 20/7 = 2.86 x 2.86，同样是浮点数，含有小数点，我们采取同样的操作对其进行取整吧，在这里引入了第二次量化误差。其实，这里引入的误差会导致图像中的像素和特征中的像素的偏差，即将feature空间的ROI对应到原图上面会出现很大的偏差。原因如下：比如用我们第二次引入的误差来分析，本来是2,86，我们将其量化为2，这期间引入了0.86的误差，看起来是一个很小的误差呀，但是你要记得这是在feature空间，我们的feature空间和图像空间是有比例关系的，在这里是1:32，那么对应到原图上面的差距就是0.86 x 32 = 27.52。这个差距不小吧，这还是仅仅考虑了第二次的量化误差。这会大大影响整个检测算法的性能，因此是一个严重的问题。好的，应该解释清楚了吧，好累！</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/9c/e5/oQUQZKYa_o.png"></p> 
<p>图10 ROIAlign技术</p> 
<p>如图10所示，为了得到为了得到固定大小（7X7）的feature map，ROIAlign技术并没有使用量化操作，即我们不想引入量化误差，比如665 / 32 = 20.78，我们就用20.78，不用什么20来替代它，比如20.78 / 7 = 2.97，我们就用2.97，而不用2来代替它。这就是ROIAlign的初衷。那么我们如何处理这些浮点数呢，我们的解决思路是使用“双线性插值”算法。双线性插值是一种比较好的图像缩放算法，它充分的利用了原图中虚拟点（比如20.56这个浮点数，像素位置都是整数值，没有浮点值）四周的四个真实存在的像素值来共同决定目标图中的一个像素值，即可以将20.56这个虚拟的位置点对应的像素值估计出来。厉害哈。如图11所示，蓝色的虚线框表示卷积后获得的feature map，黑色实线框表示ROI feature，最后需要输出的大小是2x2，那么我们就利用双线性插值来估计这些蓝点（虚拟坐标点，又称双线性插值的网格点）处所对应的像素值，最后得到相应的输出。这些蓝点是2x2Cell中的随机采样的普通点，作者指出，这些采样点的个数和位置不会对性能产生很大的影响，你也可以用其它的方法获得。然后在每一个橘红色的区域里面进行max pooling或者average pooling操作，获得最终2x2的输出结果。我们的整个过程中没有用到量化操作，没有引入误差，即原图中的像素和feature map中的像素是完全对齐的，没有偏差，这不仅会提高检测的精度，同时也会有利于实例分割。<strong>这么细心，做科研就应该关注细节，细节决定成败。</strong></p> 
<p>we propose an RoIAlign layer that removes the harsh quantization of RoIPool, properly aligning the extracted features with the input. Our proposed change is simple: we avoid any quantization of the RoI boundaries or bins (i.e., we use x=16 instead of [x=16]). We use bilinear interpolation [<span style="color:#228b22;">22</span>] to compute the exact values of the input features at four regularly sampled locations in each RoI bin, and aggregate the result (using max or average), see Figure <span style="color:#ff0000;">3 </span>for details. We note that the results are not sensitive to the exact sampling locations, or how many points are sampled, as long as no quantization is performed。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/51/c0/sm4oKynU_o.jpg"></p> 
<p>图11 双线性插值</p> 
<p><strong>6. LOSS计算与分析</strong></p> 
<p>由于增加了mask分支，每个ROI的Loss函数如下所示：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/61/90/MuUrej8Q_o.jpg"></p> 
<p>其中Lcls和Lbox和Faster r-cnn中定义的相同。对于每一个ROI，mask分支有Km*m维度的输出，其对K个大小为m*m的mask进行编码，每一个mask有K个类别。我们使用了per-pixel sigmoid，并且将Lmask定义为the average binary cross-entropy loss 。对应一个属于GT中的第k类的ROI，Lmask仅仅在第k个mask上面有定义（其它的k-1个mask输出对整个Loss没有贡献）。我们定义的Lmask允许网络为每一类生成一个mask，而不用和其它类进行竞争；我们依赖于分类分支所预测的类别标签来选择输出的mask。这样将分类和mask生成分解开来。这与利用FCN进行语义分割的有所不同，它通常使用一个per-pixel sigmoid和一个multinomial cross-entropy loss ，在这种情况下mask之间存在竞争关系；而由于我们使用了一个per-pixel sigmoid 和一个binary loss ，不同的mask之间不存在竞争关系。经验表明，这可以提高实例分割的效果。</p> 
<p>一个mask对一个目标的输入空间布局进行编码，与类别标签和BB偏置不同，它们通常需要通过FC层而导致其以短向量的形式输出。我们可以通过由卷积提供的像素和像素的对应关系来获得mask的空间结构信息。具体的来说，我们使用FCN从每一个ROI中预测出一个m*m大小的mask，这使得mask分支中的每个层能够明确的保持m×m空间布局，而不将其折叠成缺少空间维度的向量表示。和以前用fc层做mask预测的方法不同的是，我们的实验表明我们的mask表示需要更少的参数，而且更加准确。这些像素到像素的行为需要我们的ROI特征，而我们的ROI特征通常是比较小的feature map，其已经进行了对其操作，为了一致的较好的保持明确的单像素空间对应关系，我们提出了ROIAlign操作。</p> 
<p></p> 
<p><strong>三、Mask R-CNN细节分析</strong></p> 
<p><strong>1. Head Architecture </strong></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/d3/7b/7TsgJk9W_o.jpg"></strong></p> 
<p></p> 
<p>图12 Head Architecture</p> 
<p>如上图所示，为了产生对应的Mask，文中提出了两种架构，即左边的Faster R-CNN/ResNet和右边的Faster R-CNN/FPN。对于左边的架构，我们的backbone使用的是预训练好的ResNet，使用了ResNet倒数第4层的网络。输入的ROI首先获得7x7x1024的ROI feature，然后将其升维到2048个通道（这里修改了原始的ResNet网络架构），然后有两个分支，上面的分支负责分类和回归，下面的分支负责生成对应的mask。由于前面进行了多次卷积和池化，减小了对应的分辨率，mask分支开始利用反卷积进行分辨率的提升，同时减少通道的个数，变为14x14x256，最后输出了14x14x80的mask模板。而右边使用到的backbone是FPN网络，这是一个新的网络，通过输入单一尺度的图片，最后可以对应的特征金字塔，如果想要了解它的细节，请参考<a href="https://arxiv.org/abs/1612.03144" rel="nofollow" title="该链接">该链接</a>。得到证实的是，该网络可以在一定程度上面提高检测的精度，当前很多的方法都用到了它。由于FPN网络已经包含了res5，可以更加高效的使用特征，因此这里使用了较少的filters。该架构也分为两个分支，作用于前者相同，但是分类分支和mask分支和前者相比有很大的区别。可能是因为FPN网络可以在不同尺度的特征上面获得许多有用信息，因此分类时使用了更少的滤波器。而mask分支中进行了多次卷积操作，首先将ROI变化为14x14x256的feature，然后进行了5次相同的操作（不清楚这里的原理，期待着你的解释），然后进行反卷积操作，最后输出28x28x80的mask。即输出了更大的mask，与前者相比可以获得更细致的mask。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/2c/15/bDHZwnIs_o.jpg"></p> 
<p>图13 BB输出的mask结果</p> 
<p>如上图所示，图像中红色的BB表示检测到的目标，我们可以用肉眼可以观察到检测结果并不是很好，即整个BB稍微偏右，左边的一部分像素并没有包括在BB之内，但是右边显示的最终结果却很完美。</p> 
<p><strong>2. Equivariance in Mask R-CNN </strong><br> Equivariance 指随着输入的变化输出也会发生变化。<br>  </p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/ed/19/1ooLWpRc_o.jpg"></p> 
<p>图14 Equivariance 1</p> 
<p>即全卷积特征（Faster R-CNN网络）和图像的变换具有同变形，即随着图像的变换，全卷积的特征也会发生对应的变化；</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/55/b7/LGnOJBUL_o.jpg"></p> 
<p>图15 Equivariance2</p> 
<p>在ROI上面的全卷积操作（FCN网络）和在ROI中的变换具有同变性；</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/79/e1/rIRroktK_o.jpg"></p> 
<p>图16 Equivariance3</p> 
<p></p> 
<p>ROIAlign操作保持了ROI变换前后的同变性；</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/91/c1/qHSB8B6l_o.jpg"></p> 
<p>图17 ROI中的全卷积</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/ad/70/qNhYdqkL_o.jpg"></p> 
<p>图18 ROIAlign的尺度同变性</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/1f/de/0GtFMlNc_o.jpg"></p> 
<p>图19 Mask R-CNN中的同变性总结</p> 
<p><strong>3. 算法实现细节</strong></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/21/40/fvGP3HOl_o.jpg"></strong></p> 
<p>图20 算法实现细节</p> 
<p>观察上图，我们可以得到以下的信息：</p> 
<ul><li>Mask R-CNN中的超参数都是用了Faster r-cnn中的值，机智，省时省力，效果还好，别人已经替你调节过啦，哈哈哈；</li><li>使用到的预训练网络包括ResNet50、ResNet101、FPN，都是一些性能很好地网络，尤其是FPN，后面会有分析；</li><li>对于过大的图片，它会将其裁剪成800x800大小，图像太大的话会大大的增加计算量的；</li><li>利用8个GPU同时训练，开始的学习率是0.01，经过18k次将其衰减为0.001，ResNet50-FPN网络训练了32小时，ResNet101-FPN训练了44小时；</li><li>在Nvidia Tesla M40 GPU上面的测试时间是195ms/张；</li><li>使用了MS COCO数据集，将120k的数据集划分为80k的训练集、35k的验证集和5k的测试集；</li></ul> 
<p></p> 
<p><strong>四、性能比较</strong></p> 
<p></p> 
<p><strong>1. 定量结果分析</strong></p> 
<p><strong><img alt="" class="has" src="https://images2.imgbox.com/b0/f5/oE62Uyev_o.jpg"></strong></p> 
<p>表1 ROI Pool和ROIAlign性能比较</p> 
<p>由前面的分析，我们就可以定性的得到一个结论，ROIAlign会使得目标检测的效果有很大的性能提升。根据上表，我们进行定量的分析，结果表明，ROIAlign使得mask的AP值提升了10.5个百分点，使得box的AP值提升了9.5个百分点。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/e1/8b/v80AXpAK_o.jpg"></p> 
<p>表2 Multinomial和Binary loss比较</p> 
<p>根据上表的分析，我们知道Mask R-CNN利用两个分支将分类和mask生成解耦出来，然后利用Binary Loss代替Multinomial Loss，使得不同类别的mask之间消除了竞争。依赖于分类分支所预测的类别标签来选择输出对应的mask。使得mask分支不需要进行重新的分类工作，使得性能得到了提升。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/a9/91/H1KxYzXa_o.jpg"></p> 
<p>表3 MLP与FCN mask性能比较</p> 
<p>如上表所示，MLP即利用FC来生成对应的mask，而FCN利用Conv来生成对应的mask，仅仅从参数量上来讲，后者比前者少了很多，这样不仅会节约大量的内存空间，同时会加速整个训练过程（因此需要进行推理、更新的参数更少啦）。除此之外，由于MLP获得的特征比较抽象，使得最终的mask中丢失了一部分有用信息，我们可以直观的从右边看到差别。从定性角度来讲，FCN使得mask AP值提升了2.1个百分点。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/a4/36/W5KIo5F9_o.jpg"></p> 
<p>表4 实例分割的结果</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/a9/33/1l45VOZN_o.jpg"></p> 
<p>表5 目标检测的结果</p> 
<p>观察目标检测的表格，我们可以发现使用了ROIAlign操作的Faster R-CNN算法性能得到了0.9个百分点，Mask R-CNN比最好的Faster R-CNN高出了2.6个百分点。</p> 
<p><strong>2. 定性结果分析</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/b0/8f/57tPOvfk_o.jpg"></p> 
<p>图21 实例分割结果1</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/33/34/SsbxkTXU_o.jpg"></p> 
<p>图22 实例分割结果2</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/5d/ba/Ywd6gwgA_o.jpg"></p> 
<p>图23 人体姿势识别结果</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/94/bf/gC6sCQfV_o.jpg"></p> 
<p>图24 失败检测案例1</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/4d/ad/MdsrkFJl_o.jpg"></p> 
<p>图25 失败检测案例2</p> 
<p></p> 
<p><strong>五、总结</strong></p> 
<p>Mask R-CNN论文的主要贡献包括以下几点：</p> 
<ul><li><strong>分析了ROI Pool的不足，提升了ROIAlign，提升了检测和实例分割的效果；</strong></li><li><strong>将实例分割分解为分类和mask生成两个分支，依赖于分类分支所预测的类别标签来选择输出对应的mask。同时利用Binary Loss代替Multinomial Loss，消除了不同类别的mask之间的竞争，生成了准确的二值mask；</strong></li><li><strong>并行进行分类和mask生成任务，对模型进行了加速。</strong></li></ul> 
<p></p> 
<p><strong>参考文献：</strong></p> 
<p>[1] 何铠明大神在ICCV2017上在的Slides，<a href="https://www.youtube.com/watch?v=g7z4mkfRjI4&amp;t=601s" rel="nofollow" title="视频链接">视频链接</a></p> 
<p>[2] Ardian Umam对Mask R-CNN的讲解，<a href="https://www.bilibili.com/video/av15949583/?p=6" rel="nofollow" title="视频链接">视频链接</a></p> 
<p></p> 
<p><strong>注意事项：</strong></p> 
<p>[1] 如果您对AI、自动驾驶、AR、ChatGPT等技术感兴趣，欢迎关注我的微信公众号<strong>“AI产品汇”</strong>，有问题可以在公众号中私聊我！</p> 
<p>[2] 该博客是本人原创博客，如果您对该博客感兴趣，想要转载该博客，请与我联系（qq邮箱：1575262785@qq.com）,我会在第一时间回复大家，谢谢大家。</p> 
<p>[3] 由于个人能力有限，该博客可能存在很多的问题，希望大家能够提出改进意见。</p> 
<p>[4] 如果您在阅读本博客时遇到不理解的地方，希望可以联系我，我会及时的回复您，和您交流想法和意见，谢谢。</p> 
<p><strong>[5] 本人业余时间承接各种本科毕设设计和各种小项目，包括图像处理（数据挖掘、机器学习、深度学习等）、matlab仿真、python算法及仿真等，有需要的请加QQ：1575262785详聊！！！</strong></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fd07e0d13fadb233312abe452ac93f65/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Apache Log4j2漏洞 (CVE-2021-44228) 分析与复现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3174057d0bebdf0877dc01e6fd8c127c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2023·新星计划 - 为什么头部博主们写的内容有那么多人追捧？他们是掌握了什么流量密码？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>