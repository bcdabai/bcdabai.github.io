<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多目标跟踪（MOT）数据集资源整理分享 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多目标跟踪（MOT）数据集资源整理分享" />
<meta property="og:description" content="我们已经生活在一个被摄像头和视频包围的世界里，从手机、汽车、无人机到各类监控设备，随处可见摄像头的“身影”。据前瞻产业研究院2020年的报告分析，预计到2025年全球摄像头镜头的出货量将超过120亿颗。 面对海量的摄像头及其产生的视频素材，如何利用具有深度学习功能的 AI 技术，高效、智能地处理、挖掘信息，已成为一项非常有价值的课题。
一、目标跟踪简介 视频目标跟踪技术（也称为：目标跟踪、视觉跟踪），作为计算机视觉领域中基础的、重要的研究方向之一，可广泛应用在交通管理、安防监控、自动驾驶、机器人、体育赛事转播等领域，其已成为一大研究热点。
图源：网络
二、目标跟踪分类 ● 根据跟踪的目标数量，目标跟踪任务可分为单目标跟踪（SOT）和多目标跟踪（MOT）；
● 根据背景状态，可分为静态背景下的目标跟踪和动态背景下的目标跟踪；
● 根据摄像头数量，可分为单摄像头跟踪和多摄像头跟踪；
● 根据任务计算类型，可分为在线跟踪、离线跟踪；
更多分类可参考下图：
目标跟踪纵览（图源：参考资料[1]）
其中，多目标跟踪作为计算机视觉中的一项中级任务，仍然是一项具有挑战性的任务，因为它需要同时解决目标检测、轨迹估计、数据关联和重识别问题。另外它也是许多高级任务的基础，如姿态估计、动作识别和行为分析等。
让我们一起来看看。
三、什么是多目标跟踪任务 多目标跟踪与单目标跟踪是一组相对的概念。
单目标跟踪是指，在视频的初始帧画面上框出单个目标，预测后续帧中该目标的大小与位置。该目标始终位于视场中，并且对目标种类无限制。
单目标跟踪示意（图源：网络）
而多目标跟踪是在事先不知道目标数量的情况下，对视频中的行人、汽车、动物等多个目标进行检测并赋予ID进行轨迹跟踪。不同的目标拥有不同的ID，以便实现后续的轨迹预测、精准查找等工作。[2]
多目跟踪示意（图源：网络）
四、多目标跟踪方法步骤 多目标跟踪主要分为以下四个步骤：[3]
1. 对象初始化
首先对各个视频帧中的新出现的对象进行建模，即对象初始化；
2. 检测与特征提取
其次根据建立的模型进行对象检测，获得初始对象序列的特征；
3. 相似度计算
根据得到的特征，在后续帧中重复寻找目标对象进行相似度度量；
4. 数据关联
根据相似度度量结果对目标进行关联，获得一系列的对象轨迹。
五、多目标跟踪任务难点 相对于单目标跟踪，多目标跟踪面临着更加复杂的问题包括频繁的遮挡、轨迹的管理、相似的外观和多目标间的相互影响。
在实际的应用场景中，需要面对存在的各种复杂变化（以行人跟踪为例）：
1. 目标自身的变化
目标的颜色变化（行人的衣服颜色变化），目标的尺度变化（离摄像头的远近）和目标的形态变化（行人的站立、蹲与躺）等。
2. 外界环境的变化
光线明暗的变化、目标所处环境的多样性、目标的消失与出现和目标的遮挡问题。
这些复杂变化会影响跟踪对象与背景环境的区分度，从而进一步影响多目标跟踪算法的跟踪效果和结果的好坏，所以需要恰当地处理这些变化来提高多目标跟踪的准确性。
六、多目标跟踪常用数据集 目前多目标跟踪领域的重要基准是MOTChallenge，作为上传并公布多目标跟踪方法研究成果的公共平台，其拥有最大的公开行人跟踪数据集。[4]
其提供的数据集包括：MOT 15、MOT 16、 MOT 17、MOT 20，这些数据集都提供了训练集的标注，训练集与测试集的检测，以及数据集的目标检测结果，主要侧重于密集场景下行人跟踪任务。
MOT系列数据集的视频序列及其主要属性（图源：参考资料[4]）
另外还有近几年出的TAO数据集，是一个类似COCO的多样化的MOT数据集，其中包含2907个不同环境的高清视频，平均长度半分钟，包含833个类别，比现有的数据集高出一个数量级。
七、多目标跟踪数据集资源 OpenDataLab平台已经上架了多目标跟踪（MOT）系列数据集，提供了丰富的数据集信息、流畅的下载速度，快来体验吧！
· MOT15 https://opendatalab.com/MOT15
· MOT16 https://opendatalab.com/MOT16
· MOT17 https://opendatalab." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/7ac963da83364261ab05d853145600eb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-11T10:59:21+08:00" />
<meta property="article:modified_time" content="2022-07-11T10:59:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多目标跟踪（MOT）数据集资源整理分享</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>我们已经生活在一个被摄像头和视频包围的世界里，从手机、汽车、无人机到各类监控设备，随处可见摄像头的“身影”。据前瞻产业研究院2020年的报告分析，预计到2025年全球摄像头镜头的出货量将超过120亿颗。 </p> 
<p>面对海量的摄像头及其产生的视频素材，如何利用具有深度学习功能的 AI 技术，高效、智能地处理、挖掘信息，已成为一项非常有价值的课题。</p> 
<p></p> 
<h2><strong>一、目标跟踪简介</strong></h2> 
<p>视频目标跟踪技术（也称为：目标跟踪、视觉跟踪），作为计算机视觉领域中基础的、重要的研究方向之一，可广泛应用在交通管理、安防监控、自动驾驶、机器人、体育赛事转播等领域，其已成为一大研究热点。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/0e/ce/hCMsVFMU_o.gif"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">图源：网络</span></p> 
<p style="text-align:center;"></p> 
<h2><strong>二、目标跟踪分类</strong></h2> 
<p>● 根据跟踪的目标数量，目标跟踪任务可分为<strong>单目标跟踪（SOT）</strong>和<strong>多目标跟踪（MOT）</strong>；</p> 
<p>● 根据背景状态，可分为<strong>静态背景</strong>下的目标跟踪和<strong>动态背景</strong>下的目标跟踪；</p> 
<p>● 根据摄像头数量，可分为<strong>单摄像头跟踪</strong>和<strong>多摄像头跟踪</strong>；</p> 
<p>● 根据任务计算类型，可分为<strong>在线跟踪</strong>、<strong>离线跟踪</strong>；</p> 
<p></p> 
<p>更多分类可参考下图：</p> 
<p class="img-center"><img alt="" height="601" src="https://images2.imgbox.com/5c/ed/kLd4b55Z_o.png" width="642"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">目标跟踪纵览（图源：参考资料[1]）</span></p> 
<p></p> 
<p>其中，多目标跟踪作为计算机视觉中的一项中级任务，仍然是一项具有挑战性的任务，因为它需要同时解决目标检测、轨迹估计、数据关联和重识别问题。另外它也是许多高级任务的基础，如姿态估计、动作识别和行为分析等。</p> 
<p></p> 
<p>让我们一起来看看。</p> 
<p></p> 
<h2><strong>三、什么是多目标跟踪任务</strong></h2> 
<p>多目标跟踪与单目标跟踪是一组相对的概念。</p> 
<p>单目标跟踪是指，在视频的初始帧画面上框出单个目标，预测后续帧中该目标的大小与位置。该目标始终位于视场中，并且对目标种类无限制。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/34/92/NHGEnF6N_o.gif"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">单目标跟踪示意（图源：网络）</span></p> 
<p></p> 
<p>而多目标跟踪是在事先不知道目标数量的情况下，对视频中的行人、汽车、动物等多个目标进行检测并赋予ID进行轨迹跟踪。不同的目标拥有不同的ID，以便实现后续的轨迹预测、精准查找等工作。[2]</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b1/cb/S0OyqyPJ_o.gif"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">多目跟踪示意（图源：网络）</span></p> 
<p></p> 
<h2><strong>四、多目标跟踪方法步骤</strong></h2> 
<p>多目标跟踪主要分为以下四个步骤：[3]</p> 
<p><strong>1. 对象初始化</strong></p> 
<p>首先对各个视频帧中的新出现的对象进行建模，即对象初始化；</p> 
<p><strong>2. 检测与特征提取</strong></p> 
<p>其次根据建立的模型进行对象检测，获得初始对象序列的特征；</p> 
<p><strong>3. 相似度计算</strong></p> 
<p>根据得到的特征，在后续帧中重复寻找目标对象进行相似度度量；</p> 
<p><strong>4. 数据关联</strong></p> 
<p>根据相似度度量结果对目标进行关联，获得一系列的对象轨迹。</p> 
<p></p> 
<h2><strong>五、多目标跟踪任务难点</strong></h2> 
<p>相对于单目标跟踪，多目标跟踪面临着更加复杂的问题包括频繁的遮挡、轨迹的管理、相似的外观和多目标间的相互影响。</p> 
<p>在实际的应用场景中，需要面对存在的各种复杂变化（以行人跟踪为例）：</p> 
<p><strong>1. 目标自身的变化</strong></p> 
<p>目标的颜色变化（行人的衣服颜色变化），目标的尺度变化（离摄像头的远近）和目标的形态变化（行人的站立、蹲与躺）等。</p> 
<p></p> 
<p><strong>2. 外界环境的变化</strong></p> 
<p>光线明暗的变化、目标所处环境的多样性、目标的消失与出现和目标的遮挡问题。</p> 
<p>这些复杂变化会影响跟踪对象与背景环境的区分度，从而进一步影响多目标跟踪算法的跟踪效果和结果的好坏，所以需要恰当地处理这些变化来提高多目标跟踪的准确性。</p> 
<p></p> 
<h2><strong>六、多目标跟踪常用数据集</strong></h2> 
<p>目前多目标跟踪领域的重要基准是MOTChallenge，作为上传并公布多目标跟踪方法研究成果的公共平台，其拥有最大的公开行人跟踪数据集。[4]</p> 
<p>其提供的数据集包括：MOT 15、MOT 16、 MOT 17、MOT 20，这些数据集都提供了训练集的标注，训练集与测试集的检测，以及数据集的目标检测结果，主要侧重于密集场景下行人跟踪任务。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/1a/38/jNK6iijF_o.png"></p> 
<p style="text-align:center;"><span style="color:#7b7f82;">MOT系列数据集的视频序列及其主要属性（图源：参考资料[4]）</span></p> 
<p>另外还有近几年出的TAO数据集，是一个类似COCO的多样化的MOT数据集，其中包含2907个不同环境的高清视频，平均长度半分钟，包含833个类别，比现有的数据集高出一个数量级。</p> 
<p></p> 
<h2><strong>七、多目标跟踪数据集资源</strong></h2> 
<p>OpenDataLab平台已经上架了多目标跟踪（MOT）系列数据集，提供了丰富的数据集信息、流畅的下载速度，快来体验吧！</p> 
<h3><strong>· </strong><strong>MOT15</strong></h3> 
<p><a class="link-info" href="https://opendatalab.com/MOT15" rel="nofollow" title="https://opendatalab.com/MOT15">https://opendatalab.com/MOT15</a></p> 
<h3><strong>· MOT16</strong></h3> 
<p><a class="link-info" href="https://opendatalab.com/MOT16" rel="nofollow" title="https://opendatalab.com/MOT16">https://opendatalab.com/MOT16</a></p> 
<h3><strong>· MOT17</strong></h3> 
<p><a class="link-info" href="https://opendatalab.com/MOT17" rel="nofollow" title="https://opendatalab.com/MOT17">https://opendatalab.com/MOT17</a></p> 
<h3><strong>· MOT20</strong></h3> 
<p><a class="link-info" href="https://opendatalab.com/MOT20" rel="nofollow" title="https://opendatalab.com/MOT20">https://opendatalab.com/MOT20</a></p> 
<h3><strong>· TAO</strong></h3> 
<p><a class="link-info" href="https://opendatalab.com/TAO" rel="nofollow" title="https://opendatalab.com/TAO">https://opendatalab.com/TAO</a></p> 
<p></p> 
<p></p> 
<p><strong>参考资料：</strong></p> 
<p>[1]https://arxiv.org/abs/1912.00535</p> 
<p>[2]https://www.bilibili.com/read/cv12115742</p> 
<p>[3]文成宇. 复杂场景行人的多目标跟踪方法[D].中国矿业大学,2021.</p> 
<p>[4]徐涛,马克,刘才华. 基于深度学习的行人多目标跟踪方法[J]. 吉林大学学报(工学版),2021,51(01):27-38.</p> 
<p></p> 
<p>更多数据集上架动态、更全面的数据集内容解读、最牛大佬在线答疑、最活跃的同行圈子……欢迎添加微信<strong>opendatalab_yunying </strong>加入OpenDataLab官方交流群。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e655efb8f20e0cd18b52109160ad319d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">详细解读：MIT经典的语义分割数据集ADE20K，附下载链接</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2e1cbb2ab61cb088cc52aef9d5861b25/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">element el-dialog组件嵌套时遮罩层显示异常</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>