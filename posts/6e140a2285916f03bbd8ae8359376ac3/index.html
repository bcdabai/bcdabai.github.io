<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pandas 性能优化 - 编程大白的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pandas 性能优化" />
<meta property="og:description" content="1. 过早的优化是万恶之源 开发的时候尽量先保证可读性和松耦合，性能的问题稍微考虑一下就行。开发完成后出现了性能问题后再进行tuning。
2. 优化前使用工具进行性能分析 个人更喜欢line_profiler。看每一行执行的时间占比，也大概知道原因出在什么地方了。自带的profile会深入到包的底层运算逻辑，不是特别清晰。下面是line_profiler的使用方法，个人感觉比装饰器的方式好用太多：
from line_profiler import LineProfiler import random def do_stuff(numbers): s = sum(numbers) l = [numbers[i]/43 for i in range(len(numbers))] m = [&#39;hello&#39;&#43;str(numbers[i]) for i in range(len(numbers))] numbers = [random.randint(1,100) for i in range(1000)] lp = LineProfiler() lp_wrapper = lp(do_stuff) lp_wrapper(numbers) lp.print_stats() 3. 尽量不要在pandas中使用循环（行遍历） pandas作为一个非常“高级”的包，为了易用性牺牲了很多效率。在使用循环时，会产生类型推断等额外的操作，而且没法利用到pandas内部的特殊优化。
4. 如果循环很难避免，在循环体中使用numpy做计算 numpy的底层使用C构建的，而且anaconda的中numpy包使用了MKL，可以针对CPU的指令集进行优化，针对于数值或者矩阵运算，还有相当优秀的算法算法来优化，所以效率是相当高的。在很多情景之下，如果核心部分改为numpy的话，说不定就已经解决了问题。
5. 如果numpy效率还是不够理想 可以试试cython，你可以把cython当做新的语言，是python的一个超集。结合了C和python的特性，比如变量声明等要符合C的特性，但是又可以使用numpy的一些包。当编译器事先知道变量的类型可以很好的优化代码，这是纯解释语言天生的缺陷。但是在个人的实际使用中，发现仅仅增加类型声明并没有特别多的提升，可能是相关的计算逻辑已经被numpy优化的差不多了吧。但是这种方法的坏处显而易见，代码的可读性明显降低了。。。
6. 不要使用.ix操作符 尽量使用.loc和.iloc来获取数据。而且.ix未来很快就会在pandas中移除。
7. 在有序列中查找使用pandas.Series.searchsorted 这种查找底层使用二分查找，效率会高很多。
8. 统计某个值出现的次数时 尽量不要使用len(df[df[‘report_month’]==3)这种方式，使用pandas.Series.value_counts效率会更高一点。最快的还是numpy：
np.in1d(normal_reports[&#39;report_month&#39;],3).sum() 9. 不要做重复的计算 tickerdateclose0000012016010111000001201801011200000220160101130000022018010114 假设有3000多只股票，每个股票都取了同样时间范围的2年数据。我现在要把date字段从string类型转化为datetime类型。如果直接用pd.to_datetime(date)，那么其实效率奇慢。日期的转化需要一些推断的操作，非常耗时。其实只要第一只股票对于的日期转化后，后面的时间区间都是一样的，不需要做重复的转化，幸好pandas支持map操作，下面的代码会极大的提升效率：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcdabai.github.io/posts/6e140a2285916f03bbd8ae8359376ac3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-03-23T16:59:27+08:00" />
<meta property="article:modified_time" content="2018-03-23T16:59:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大白的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大白的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pandas 性能优化</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3 id="1-过早的优化是万恶之源">1. 过早的优化是万恶之源</h3> 
<p>开发的时候尽量先保证可读性和松耦合，性能的问题稍微考虑一下就行。开发完成后出现了性能问题后再进行tuning。</p> 
<h3 id="2-优化前使用工具进行性能分析">2. 优化前使用工具进行性能分析</h3> 
<p>个人更喜欢line_profiler。看每一行执行的时间占比，也大概知道原因出在什么地方了。自带的profile会深入到包的底层运算逻辑，不是特别清晰。下面是<a href="https://stackoverflow.com/questions/22328183/python-line-profiler-code-example" rel="nofollow">line_profiler</a>的使用方法，个人感觉比装饰器的方式好用太多：</p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-keyword">from</span> line_profiler <span class="hljs-keyword">import</span> LineProfiler
<span class="hljs-keyword">import</span> random

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_stuff</span><span class="hljs-params">(numbers)</span>:</span>
    s = sum(numbers)
    l = [numbers[i]/<span class="hljs-number">43</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(numbers))]
    m = [<span class="hljs-string">'hello'</span>+str(numbers[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(numbers))]

numbers = [random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">100</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>)]
lp = LineProfiler()
lp_wrapper = lp(do_stuff)
lp_wrapper(numbers)
lp.print_stats()</code></pre> 
<h3 id="3-尽量不要在pandas中使用循环行遍历">3. 尽量不要在pandas中使用循环（行遍历）</h3> 
<p>pandas作为一个非常“高级”的包，为了易用性牺牲了很多效率。在使用循环时，会产生类型推断等额外的操作，而且没法利用到pandas内部的特殊优化。</p> 
<h3 id="4-如果循环很难避免在循环体中使用numpy做计算">4. 如果循环很难避免，在循环体中使用numpy做计算</h3> 
<p>numpy的底层使用C构建的，而且anaconda的中numpy包使用了MKL，可以针对CPU的指令集进行优化，针对于数值或者矩阵运算，还有相当优秀的算法算法来优化，所以效率是相当高的。在很多情景之下，如果核心部分改为numpy的话，说不定就已经解决了问题。</p> 
<h3 id="5-如果numpy效率还是不够理想">5. 如果numpy效率还是不够理想</h3> 
<p>可以试试cython，你可以把cython当做新的语言，是python的一个超集。结合了C和python的特性，比如变量声明等要符合C的特性，但是又可以使用numpy的一些包。当编译器事先知道变量的类型可以很好的优化代码，这是纯解释语言天生的缺陷。但是在个人的实际使用中，发现仅仅增加类型声明并没有特别多的提升，可能是相关的计算逻辑已经被numpy优化的差不多了吧。但是这种方法的坏处显而易见，代码的可读性明显降低了。。。</p> 
<h3 id="6-不要使用ix操作符">6. 不要使用.ix操作符</h3> 
<p>尽量使用.loc和.iloc来获取数据。而且.ix未来很快就会在pandas中移除。</p> 
<h3 id="7-在有序列中查找使用pandasseriessearchsorted">7. 在有序列中查找使用pandas.Series.searchsorted</h3> 
<p>这种查找底层使用二分查找，效率会高很多。</p> 
<h3 id="8-统计某个值出现的次数时">8. 统计某个值出现的次数时</h3> 
<p>尽量不要使用len(df[df[‘report_month’]==3)这种方式，使用pandas.Series.value_counts效率会更高一点。最快的还是numpy：</p> 
<pre class="prettyprint"><code class=" hljs livecodeserver">np.in1d(normal_reports[<span class="hljs-string">'report_month'</span>],<span class="hljs-number">3</span>).<span class="hljs-built_in">sum</span>()</code></pre> 
<h3 id="9-不要做重复的计算">9. 不要做重复的计算</h3> 
<table><thead><tr><th>ticker</th><th>date</th><th>close</th></tr></thead><tbody><tr><td>000001</td><td>20160101</td><td>11</td></tr><tr><td>000001</td><td>20180101</td><td>12</td></tr><tr><td>000002</td><td>20160101</td><td>13</td></tr><tr><td>000002</td><td>20180101</td><td>14</td></tr></tbody></table> 
<p>假设有3000多只股票，每个股票都取了<strong>同样时间范围的2年数据</strong>。我现在要把date字段从string类型转化为datetime类型。如果直接用pd.to_datetime(date)，那么其实效率奇慢。日期的转化需要一些推断的操作，非常耗时。其实只要第一只股票对于的日期转化后，后面的时间区间都是一样的，不需要做重复的转化，幸好pandas支持map操作，下面的<a href="https://stackoverflow.com/questions/29882573/pandas-slow-date-conversion/29882676#29882676" rel="nofollow">代码</a>会极大的提升效率：</p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lookup</span><span class="hljs-params">(s)</span>:</span>
    <span class="hljs-string">"""
    This is an extremely fast approach to datetime parsing.
    For large data, the same dates are often repeated. Rather than
    re-parse these, we store all unique dates, parse them, and
    use a lookup to convert all dates.
    """</span>
    dates = {date:pd.to_datetime(date) <span class="hljs-keyword">for</span> date <span class="hljs-keyword">in</span> s.unique()}
    <span class="hljs-keyword">return</span> s.map(dates)</code></pre> 
<p>注意： <br> 1. 上面的一些建议是在本人的开发工作中遇到的情况，有些性能问题是在大量的循环中才会暴露出来。所以在没有实际应用场景的情况下扯性能都是耍流氓。 <br> 2. 后面遇到新的case会持续更新，希望不要踩到这么多坑。。。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/72a3af304c735f6e71191a3bfad9af81/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Unable to parse template &#34;Class&#34; Error message: Selected class file name &#39;ProductServlet.java&#39; mappe</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2aee5eea0941d75077126cec8023037a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">matlab二维特殊函数柱状图bar()函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大白的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>